[
  {
    "function_name": "TEST",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "348-356",
    "snippet": "TEST(Lexer, Utf8Bom) {\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 3, endByte = 6), \"\n        \"(identifier = 'bar', startByte = 7, endByte = 10), \"\n        \"(identifier = 'baz', startByte = 13, endByte = 16)\"\n      \"])\",\n      doLex<LexedTokens>(\"\\xef\\xbb\\xbf\"\"foo bar\\xef\\xbb\\xbf\"\"baz\").cStr());\n}",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(identifier = 'foo', startByte = 3, endByte = 6), \"\n        \"(identifier = 'bar', startByte = 7, endByte = 10), \"\n        \"(identifier = 'baz', startByte = 13, endByte = 16)\"\n      \"])\"",
            "doLex<LexedTokens>(\"\\xef\\xbb\\xbf\"\"foo bar\\xef\\xbb\\xbf\"\"baz\").cStr()"
          ],
          "line": 349
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 355
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [
            "\"\\xef\\xbb\\xbf\"\"foo bar\\xef\\xbb\\xbf\"\"baz\""
          ],
          "line": 355
        },
        "resolved": true,
        "details": {
          "function_name": "doLex",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
          "lines": "43-68",
          "snippet": "kj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}",
          "includes": [
            "#include <kj/compat/gtest.h>",
            "#include \"../message.h\"",
            "#include \"lexer.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nkj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nTEST(Lexer, Utf8Bom) {\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 3, endByte = 6), \"\n        \"(identifier = 'bar', startByte = 7, endByte = 10), \"\n        \"(identifier = 'baz', startByte = 13, endByte = 16)\"\n      \"])\",\n      doLex<LexedTokens>(\"\\xef\\xbb\\xbf\"\"foo bar\\xef\\xbb\\xbf\"\"baz\").cStr());\n}"
  },
  {
    "function_name": "TEST",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "223-346",
    "snippet": "TEST(Lexer, DocComments) {\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 16\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; # blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 15\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; #blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = ' blah blah\\\\n', \"\n          \"startByte = 0, endByte = 17\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; #  blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 16\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo;\\n# blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"startByte = 0, endByte = 4\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo;\\n\\n# blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'bar baz\\\\nqux corge\\\\n', \"\n          \"startByte = 0, endByte = 30\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo;\\n # bar baz\\n  # qux corge\\n\\n# grault\\n# garply\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 17, endByte = 20)\"\n            \"], line = void, docComment = 'hi\\\\n', startByte = 17, endByte = 27), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 28, endByte = 31)\"\n            \"], line = void, startByte = 28, endByte = 32)\"\n          \"], \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 44\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 44, endByte = 47)\"\n        \"], line = void, startByte = 44, endByte = 48)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo {# blah blah\\nbar; # hi\\n baz;} # ignored\\nqux;\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n            \"], line = void, startByte = 5, endByte = 9), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n            \"], line = void, startByte = 10, endByte = 14)\"\n          \"], \"\n          \"docComment = 'late comment\\\\n', \"\n          \"startByte = 0, endByte = 31\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 31, endByte = 34)\"\n        \"], line = void, startByte = 31, endByte = 35)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo {bar; baz;}\\n# late comment\\nqux;\").cStr());\n}",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n            \"], line = void, startByte = 5, endByte = 9), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n            \"], line = void, startByte = 10, endByte = 14)\"\n          \"], \"\n          \"docComment = 'late comment\\\\n', \"\n          \"startByte = 0, endByte = 31\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 31, endByte = 34)\"\n        \"], line = void, startByte = 31, endByte = 35)\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo {bar; baz;}\\n# late comment\\nqux;\").cStr()"
          ],
          "line": 324
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 345
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [
            "\"foo {bar; baz;}\\n# late comment\\nqux;\""
          ],
          "line": 345
        },
        "resolved": true,
        "details": {
          "function_name": "doLex",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
          "lines": "43-68",
          "snippet": "kj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}",
          "includes": [
            "#include <kj/compat/gtest.h>",
            "#include \"../message.h\"",
            "#include \"lexer.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nkj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}"
        }
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 17, endByte = 20)\"\n            \"], line = void, docComment = 'hi\\\\n', startByte = 17, endByte = 27), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 28, endByte = 31)\"\n            \"], line = void, startByte = 28, endByte = 32)\"\n          \"], \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 44\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 44, endByte = 47)\"\n        \"], line = void, startByte = 44, endByte = 48)\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo {# blah blah\\nbar; # hi\\n baz;} # ignored\\nqux;\").cStr()"
          ],
          "line": 301
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 322
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'bar baz\\\\nqux corge\\\\n', \"\n          \"startByte = 0, endByte = 30\"\n        \")\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo;\\n # bar baz\\n  # qux corge\\n\\n# grault\\n# garply\").cStr()"
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 299
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"startByte = 0, endByte = 4\"\n        \")\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo;\\n\\n# blah blah\").cStr()"
          ],
          "line": 276
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 16\"\n        \")\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo;\\n# blah blah\").cStr()"
          ],
          "line": 263
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 274
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = ' blah blah\\\\n', \"\n          \"startByte = 0, endByte = 17\"\n        \")\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo; #  blah blah\").cStr()"
          ],
          "line": 250
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 261
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 15\"\n        \")\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo; #blah blah\").cStr()"
          ],
          "line": 237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 248
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 16\"\n        \")\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo; # blah blah\").cStr()"
          ],
          "line": 224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 235
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nTEST(Lexer, DocComments) {\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 16\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; # blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 15\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; #blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = ' blah blah\\\\n', \"\n          \"startByte = 0, endByte = 17\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; #  blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 16\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo;\\n# blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"startByte = 0, endByte = 4\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo;\\n\\n# blah blah\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"line = void, \"\n          \"docComment = 'bar baz\\\\nqux corge\\\\n', \"\n          \"startByte = 0, endByte = 30\"\n        \")\"\n      \"])\",\n      doLex<LexedStatements>(\"foo;\\n # bar baz\\n  # qux corge\\n\\n# grault\\n# garply\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 17, endByte = 20)\"\n            \"], line = void, docComment = 'hi\\\\n', startByte = 17, endByte = 27), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 28, endByte = 31)\"\n            \"], line = void, startByte = 28, endByte = 32)\"\n          \"], \"\n          \"docComment = 'blah blah\\\\n', \"\n          \"startByte = 0, endByte = 44\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 44, endByte = 47)\"\n        \"], line = void, startByte = 44, endByte = 48)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo {# blah blah\\nbar; # hi\\n baz;} # ignored\\nqux;\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n            \"], line = void, startByte = 5, endByte = 9), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n            \"], line = void, startByte = 10, endByte = 14)\"\n          \"], \"\n          \"docComment = 'late comment\\\\n', \"\n          \"startByte = 0, endByte = 31\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 31, endByte = 34)\"\n        \"], line = void, startByte = 31, endByte = 35)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo {bar; baz;}\\n# late comment\\nqux;\").cStr());\n}"
  },
  {
    "function_name": "TEST",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "176-221",
    "snippet": "TEST(Lexer, Statements) {\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(tokens = [\"\n          \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n          \"(identifier = 'bar', startByte = 4, endByte = 7)\"\n        \"], line = void, startByte = 0, endByte = 8)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo bar;\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(tokens = [\"\n          \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n        \"], line = void, startByte = 0, endByte = 4), \"\n        \"(tokens = [\"\n          \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n        \"], line = void, startByte = 5, endByte = 9), \"\n        \"(tokens = [\"\n          \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n        \"], line = void, startByte = 10, endByte = 14)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; bar; baz; \").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n            \"], line = void, startByte = 5, endByte = 9), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n            \"], line = void, startByte = 10, endByte = 14)\"\n          \"], \"\n          \"startByte = 0, endByte = 15\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 16, endByte = 19)\"\n        \"], line = void, startByte = 16, endByte = 20)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo {bar; baz;} qux;\").cStr());\n}",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n            \"], line = void, startByte = 5, endByte = 9), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n            \"], line = void, startByte = 10, endByte = 14)\"\n          \"], \"\n          \"startByte = 0, endByte = 15\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 16, endByte = 19)\"\n        \"], line = void, startByte = 16, endByte = 20)\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo {bar; baz;} qux;\").cStr()"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 220
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [
            "\"foo {bar; baz;} qux;\""
          ],
          "line": 220
        },
        "resolved": true,
        "details": {
          "function_name": "doLex",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
          "lines": "43-68",
          "snippet": "kj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}",
          "includes": [
            "#include <kj/compat/gtest.h>",
            "#include \"../message.h\"",
            "#include \"lexer.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nkj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}"
        }
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(tokens = [\"\n          \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n        \"], line = void, startByte = 0, endByte = 4), \"\n        \"(tokens = [\"\n          \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n        \"], line = void, startByte = 5, endByte = 9), \"\n        \"(tokens = [\"\n          \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n        \"], line = void, startByte = 10, endByte = 14)\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo; bar; baz; \").cStr()"
          ],
          "line": 186
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(statements = [\"\n        \"(tokens = [\"\n          \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n          \"(identifier = 'bar', startByte = 4, endByte = 7)\"\n        \"], line = void, startByte = 0, endByte = 8)\"\n      \"])\"",
            "doLex<LexedStatements>(\"foo bar;\").cStr()"
          ],
          "line": 177
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedStatements>",
          "args": [],
          "line": 184
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nTEST(Lexer, Statements) {\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(tokens = [\"\n          \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n          \"(identifier = 'bar', startByte = 4, endByte = 7)\"\n        \"], line = void, startByte = 0, endByte = 8)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo bar;\").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(tokens = [\"\n          \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n        \"], line = void, startByte = 0, endByte = 4), \"\n        \"(tokens = [\"\n          \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n        \"], line = void, startByte = 5, endByte = 9), \"\n        \"(tokens = [\"\n          \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n        \"], line = void, startByte = 10, endByte = 14)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo; bar; baz; \").cStr());\n\n  EXPECT_STREQ(\n      \"(statements = [\"\n        \"(\"\n          \"tokens = [\"\n            \"(identifier = 'foo', startByte = 0, endByte = 3)\"\n          \"], \"\n          \"block = [\"\n            \"(tokens = [\"\n              \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n            \"], line = void, startByte = 5, endByte = 9), \"\n            \"(tokens = [\"\n              \"(identifier = 'baz', startByte = 10, endByte = 13)\"\n            \"], line = void, startByte = 10, endByte = 14)\"\n          \"], \"\n          \"startByte = 0, endByte = 15\"\n        \"), \"\n        \"(tokens = [\"\n          \"(identifier = 'qux', startByte = 16, endByte = 19)\"\n        \"], line = void, startByte = 16, endByte = 20)\"\n      \"])\",\n      doLex<LexedStatements>(\"foo {bar; baz;} qux;\").cStr());\n}"
  },
  {
    "function_name": "TEST",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "70-174",
    "snippet": "TEST(Lexer, Tokens) {\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 4, endByte = 7)\"\n      \"])\",\n      doLex<LexedTokens>(\"foo bar\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 15, endByte = 18)\"\n      \"])\",\n      doLex<LexedTokens>(\"foo # comment\\n bar\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(stringLiteral = 'foo ', startByte = 2, endByte = 11), \"\n        \"(integerLiteral = 123, startByte = 12, endByte = 15), \"\n        \"(floatLiteral = 2.75, startByte = 16, endByte = 20), \"\n        \"(floatLiteral = 60000, startByte = 21, endByte = 24), \"\n        \"(operator = '+', startByte = 25, endByte = 26), \"\n        \"(operator = '-=', startByte = 27, endByte = 29)\"\n      \"])\",\n      doLex<LexedTokens>(\"  'foo\\\\x20' 123 2.75 6e4 + -=  \").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(parenthesizedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"], [\"\n            \"(identifier = 'baz', startByte = 10, endByte = 13), \"\n            \"(identifier = 'qux', startByte = 14, endByte = 17)\"\n          \"], [\"\n            \"(identifier = 'corge', startByte = 19, endByte = 24), \"\n            \"(identifier = 'grault', startByte = 25, endByte = 31)\"\n          \"]\"\n        \"], startByte = 0, endByte = 32)\"\n      \"])\",\n      doLex<LexedTokens>(\"(foo bar, baz qux, corge grault)\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(parenthesizedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"]\"\n        \"], startByte = 0, endByte = 9)\"\n      \"])\",\n      doLex<LexedTokens>(\"(foo bar)\").cStr());\n\n  // Empty parentheses should result in an empty list-of-lists, *not* a list containing an empty\n  // list.\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(parenthesizedList = [], startByte = 0, endByte = 4)\"\n      \"])\",\n      doLex<LexedTokens>(\"(  )\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(bracketedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"], [\"\n            \"(identifier = 'baz', startByte = 10, endByte = 13), \"\n            \"(identifier = 'qux', startByte = 14, endByte = 17)\"\n          \"], [\"\n            \"(identifier = 'corge', startByte = 19, endByte = 24), \"\n            \"(identifier = 'grault', startByte = 25, endByte = 31)\"\n          \"]\"\n        \"], startByte = 0, endByte = 32)\"\n      \"])\",\n      doLex<LexedTokens>(\"[foo bar, baz qux, corge grault]\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(bracketedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4)\"\n          \"], [\"\n            \"(parenthesizedList = [\"\n              \"[\"\n                \"(identifier = 'bar', startByte = 7, endByte = 10)\"\n              \"], [\"\n                \"(identifier = 'baz', startByte = 12, endByte = 15)\"\n              \"]\"\n            \"], startByte = 6, endByte = 16)\"\n          \"]\"\n        \"], startByte = 0, endByte = 17), \"\n        \"(identifier = 'qux', startByte = 18, endByte = 21)\"\n      \"])\",\n      doLex<LexedTokens>(\"[foo, (bar, baz)] qux\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 7, endByte = 10)\"\n      \"])\",\n      doLex<LexedTokens>(\"foo\\n\\r\\t\\vbar\").cStr());\n}",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 7, endByte = 10)\"\n      \"])\"",
            "doLex<LexedTokens>(\"foo\\n\\r\\t\\vbar\").cStr()"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 173
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [
            "\"foo\\n\\r\\t\\vbar\""
          ],
          "line": 173
        },
        "resolved": true,
        "details": {
          "function_name": "doLex",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
          "lines": "43-68",
          "snippet": "kj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}",
          "includes": [
            "#include <kj/compat/gtest.h>",
            "#include \"../message.h\"",
            "#include \"lexer.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nkj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}"
        }
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(bracketedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4)\"\n          \"], [\"\n            \"(parenthesizedList = [\"\n              \"[\"\n                \"(identifier = 'bar', startByte = 7, endByte = 10)\"\n              \"], [\"\n                \"(identifier = 'baz', startByte = 12, endByte = 15)\"\n              \"]\"\n            \"], startByte = 6, endByte = 16)\"\n          \"]\"\n        \"], startByte = 0, endByte = 17), \"\n        \"(identifier = 'qux', startByte = 18, endByte = 21)\"\n      \"])\"",
            "doLex<LexedTokens>(\"[foo, (bar, baz)] qux\").cStr()"
          ],
          "line": 149
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 166
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(bracketedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"], [\"\n            \"(identifier = 'baz', startByte = 10, endByte = 13), \"\n            \"(identifier = 'qux', startByte = 14, endByte = 17)\"\n          \"], [\"\n            \"(identifier = 'corge', startByte = 19, endByte = 24), \"\n            \"(identifier = 'grault', startByte = 25, endByte = 31)\"\n          \"]\"\n        \"], startByte = 0, endByte = 32)\"\n      \"])\"",
            "doLex<LexedTokens>(\"[foo bar, baz qux, corge grault]\").cStr()"
          ],
          "line": 132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 147
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(parenthesizedList = [], startByte = 0, endByte = 4)\"\n      \"])\"",
            "doLex<LexedTokens>(\"(  )\").cStr()"
          ],
          "line": 126
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 130
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(parenthesizedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"]\"\n        \"], startByte = 0, endByte = 9)\"\n      \"])\"",
            "doLex<LexedTokens>(\"(foo bar)\").cStr()"
          ],
          "line": 113
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(parenthesizedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"], [\"\n            \"(identifier = 'baz', startByte = 10, endByte = 13), \"\n            \"(identifier = 'qux', startByte = 14, endByte = 17)\"\n          \"], [\"\n            \"(identifier = 'corge', startByte = 19, endByte = 24), \"\n            \"(identifier = 'grault', startByte = 25, endByte = 31)\"\n          \"]\"\n        \"], startByte = 0, endByte = 32)\"\n      \"])\"",
            "doLex<LexedTokens>(\"(foo bar, baz qux, corge grault)\").cStr()"
          ],
          "line": 96
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 111
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(stringLiteral = 'foo ', startByte = 2, endByte = 11), \"\n        \"(integerLiteral = 123, startByte = 12, endByte = 15), \"\n        \"(floatLiteral = 2.75, startByte = 16, endByte = 20), \"\n        \"(floatLiteral = 60000, startByte = 21, endByte = 24), \"\n        \"(operator = '+', startByte = 25, endByte = 26), \"\n        \"(operator = '-=', startByte = 27, endByte = 29)\"\n      \"])\"",
            "doLex<LexedTokens>(\"  'foo\\\\x20' 123 2.75 6e4 + -=  \").cStr()"
          ],
          "line": 85
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 94
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 15, endByte = 18)\"\n      \"])\"",
            "doLex<LexedTokens>(\"foo # comment\\n bar\").cStr()"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 83
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EXPECT_STREQ",
          "args": [
            "\"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 4, endByte = 7)\"\n      \"])\"",
            "doLex<LexedTokens>(\"foo bar\").cStr()"
          ],
          "line": 71
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "doLex<LexedTokens>",
          "args": [],
          "line": 76
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nTEST(Lexer, Tokens) {\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 4, endByte = 7)\"\n      \"])\",\n      doLex<LexedTokens>(\"foo bar\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 15, endByte = 18)\"\n      \"])\",\n      doLex<LexedTokens>(\"foo # comment\\n bar\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(stringLiteral = 'foo ', startByte = 2, endByte = 11), \"\n        \"(integerLiteral = 123, startByte = 12, endByte = 15), \"\n        \"(floatLiteral = 2.75, startByte = 16, endByte = 20), \"\n        \"(floatLiteral = 60000, startByte = 21, endByte = 24), \"\n        \"(operator = '+', startByte = 25, endByte = 26), \"\n        \"(operator = '-=', startByte = 27, endByte = 29)\"\n      \"])\",\n      doLex<LexedTokens>(\"  'foo\\\\x20' 123 2.75 6e4 + -=  \").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(parenthesizedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"], [\"\n            \"(identifier = 'baz', startByte = 10, endByte = 13), \"\n            \"(identifier = 'qux', startByte = 14, endByte = 17)\"\n          \"], [\"\n            \"(identifier = 'corge', startByte = 19, endByte = 24), \"\n            \"(identifier = 'grault', startByte = 25, endByte = 31)\"\n          \"]\"\n        \"], startByte = 0, endByte = 32)\"\n      \"])\",\n      doLex<LexedTokens>(\"(foo bar, baz qux, corge grault)\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(parenthesizedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"]\"\n        \"], startByte = 0, endByte = 9)\"\n      \"])\",\n      doLex<LexedTokens>(\"(foo bar)\").cStr());\n\n  // Empty parentheses should result in an empty list-of-lists, *not* a list containing an empty\n  // list.\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(parenthesizedList = [], startByte = 0, endByte = 4)\"\n      \"])\",\n      doLex<LexedTokens>(\"(  )\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(bracketedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4), \"\n            \"(identifier = 'bar', startByte = 5, endByte = 8)\"\n          \"], [\"\n            \"(identifier = 'baz', startByte = 10, endByte = 13), \"\n            \"(identifier = 'qux', startByte = 14, endByte = 17)\"\n          \"], [\"\n            \"(identifier = 'corge', startByte = 19, endByte = 24), \"\n            \"(identifier = 'grault', startByte = 25, endByte = 31)\"\n          \"]\"\n        \"], startByte = 0, endByte = 32)\"\n      \"])\",\n      doLex<LexedTokens>(\"[foo bar, baz qux, corge grault]\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(bracketedList = [\"\n          \"[\"\n            \"(identifier = 'foo', startByte = 1, endByte = 4)\"\n          \"], [\"\n            \"(parenthesizedList = [\"\n              \"[\"\n                \"(identifier = 'bar', startByte = 7, endByte = 10)\"\n              \"], [\"\n                \"(identifier = 'baz', startByte = 12, endByte = 15)\"\n              \"]\"\n            \"], startByte = 6, endByte = 16)\"\n          \"]\"\n        \"], startByte = 0, endByte = 17), \"\n        \"(identifier = 'qux', startByte = 18, endByte = 21)\"\n      \"])\",\n      doLex<LexedTokens>(\"[foo, (bar, baz)] qux\").cStr());\n\n  EXPECT_STREQ(\n      \"(tokens = [\"\n        \"(identifier = 'foo', startByte = 0, endByte = 3), \"\n        \"(identifier = 'bar', startByte = 7, endByte = 10)\"\n      \"])\",\n      doLex<LexedTokens>(\"foo\\n\\r\\t\\vbar\").cStr());\n}"
  },
  {
    "function_name": "doLex",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "43-68",
    "snippet": "kj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kj::str",
          "args": [
            "file"
          ],
          "line": 62
        },
        "resolved": true,
        "details": {
          "function_name": "str",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/kj/string.h",
          "lines": "341-341",
          "snippet": "inline String str(String&& s) { return mv(s); }",
          "includes": [
            "#include <string.h>",
            "#include \"array.h\"",
            "#include <initializer_list>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <string.h>\n#include \"array.h\"\n#include <initializer_list>\n\ninline String str(String&& s) { return mv(s); }"
        }
      },
      {
        "call_info": {
          "callee": "EXPECT_TRUE",
          "args": [
            "lex(text, file, errorReporter)"
          ],
          "line": 61
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lex",
          "args": [
            "text",
            "file",
            "errorReporter"
          ],
          "line": 61
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "message.initRoot<LexResult>",
          "args": [],
          "line": 59
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "heapString",
          "args": [
            "constText"
          ],
          "line": 53
        },
        "resolved": true,
        "details": {
          "function_name": "heapString",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/kj/string.c++",
          "lines": "36-40",
          "snippet": "String heapString(size_t size) {\n  char* buffer = _::HeapArrayDisposer::allocate<char>(size + 1);\n  buffer[size] = '\\0';\n  return String(buffer, size, _::HeapArrayDisposer::instance);\n}",
          "includes": [
            "#include <stdlib.h>",
            "#include <errno.h>",
            "#include <float.h>",
            "#include <stdio.h>",
            "#include \"debug.h\"",
            "#include \"string.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <stdlib.h>\n#include <errno.h>\n#include <float.h>\n#include <stdio.h>\n#include \"debug.h\"\n#include \"string.h\"\n\nString heapString(size_t size) {\n  char* buffer = _::HeapArrayDisposer::allocate<char>(size + 1);\n  buffer[size] = '\\0';\n  return String(buffer, size, _::HeapArrayDisposer::instance);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nkj::String doLex(kj::StringPtr constText) {\n  // Parse the given string into the given Cap'n Proto struct type using lex(), then stringify the\n  // result and return that string.  Additionally, single quotes in the input are converted to\n  // double quotes, and double quotes in the output are converted to single quotes, to reduce the\n  // amount of escaping needed in the test strings.\n  //\n  // Comparing stringifications against golden strings is ugly and brittle.  If we had a\n  // text-format parser we could use that.  Except that said parser would probably be built on\n  // the very lexer being tested here, so...  maybe this is the best we can reasonably do.\n\n  kj::String text = heapString(constText);\n  for (char& c: text) {\n    // Make it easier to write input strings below.\n    if (c == '\\'') c = '\\\"';\n  }\n  MallocMessageBuilder message;\n  auto file = message.initRoot<LexResult>();\n  TestFailingErrorReporter errorReporter;\n  EXPECT_TRUE(lex(text, file, errorReporter));\n  kj::String result = kj::str(file);\n  for (char& c: result) {\n    // Make it easier to write golden strings below.\n    if (c == '\\\"') c = '\\'';\n  }\n  return result;\n}"
  },
  {
    "function_name": "hadErrors",
    "container": "TestFailingErrorReporter",
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "36-39",
    "snippet": "bool hadErrors() override {\n    // Not used by lexer.\n    return false;\n  }",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nTestFailingErrorReporter {\n  bool hadErrors() override {\n      // Not used by lexer.\n      return false;\n    }\n}"
  },
  {
    "function_name": "addError",
    "container": "TestFailingErrorReporter",
    "file": "/home/michele/Desktop/ricerca/output_repos_cpp/CVE-2015-2313/repo/c++/src/capnp/compiler/lexer-test.c++",
    "lines": "32-34",
    "snippet": "void addError(uint32_t startByte, uint32_t endByte, kj::StringPtr message) override {\n    KJ_FAIL_EXPECT(\"Parse failed.\", startByte, endByte, message);\n  }",
    "includes": [
      "#include <kj/compat/gtest.h>",
      "#include \"../message.h\"",
      "#include \"lexer.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "KJ_FAIL_EXPECT",
          "args": [
            "\"Parse failed.\"",
            "startByte",
            "endByte",
            "message"
          ],
          "line": 33
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <kj/compat/gtest.h>\n#include \"../message.h\"\n#include \"lexer.h\"\n\nTestFailingErrorReporter {\n  void addError(uint32_t startByte, uint32_t endByte, kj::StringPtr message) override {\n      KJ_FAIL_EXPECT(\"Parse failed.\", startByte, endByte, message);\n    }\n}"
  }
]