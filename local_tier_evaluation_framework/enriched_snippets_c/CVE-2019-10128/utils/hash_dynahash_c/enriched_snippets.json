[
  {
    "function_name": "AtEOSubXact_HashTables",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1859-1881",
    "snippet": "void\nAtEOSubXact_HashTables(bool isCommit, int nestDepth)\n{\n\tint\t\t\ti;\n\n\t/*\n\t * Search backward to make cleanup easy.  Note we must check all entries,\n\t * not only those at the end of the array, because deletion technique\n\t * doesn't keep them in order.\n\t */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_level[i] >= nestDepth)\n\t\t{\n\t\t\tif (isCommit)\n\t\t\t\telog(WARNING, \"leaked hash_seq_search scan for hash table %p\",\n\t\t\t\t\t seq_scan_tables[i]);\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
      "static int\tseq_scan_level[MAX_SEQ_SCANS];",
      "static int\tnum_seq_scans = 0;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "WARNING",
            "\"leaked hash_seq_search scan for hash table %p\"",
            "seq_scan_tables[i]"
          ],
          "line": 1874
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tseq_scan_level[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nvoid\nAtEOSubXact_HashTables(bool isCommit, int nestDepth)\n{\n\tint\t\t\ti;\n\n\t/*\n\t * Search backward to make cleanup easy.  Note we must check all entries,\n\t * not only those at the end of the array, because deletion technique\n\t * doesn't keep them in order.\n\t */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_level[i] >= nestDepth)\n\t\t{\n\t\t\tif (isCommit)\n\t\t\t\telog(WARNING, \"leaked hash_seq_search scan for hash table %p\",\n\t\t\t\t\t seq_scan_tables[i]);\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "AtEOXact_HashTables",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1833-1856",
    "snippet": "void\nAtEOXact_HashTables(bool isCommit)\n{\n\t/*\n\t * During abort cleanup, open scans are expected; just silently clean 'em\n\t * out.  An open scan at commit means someone forgot a hash_seq_term()\n\t * call, so complain.\n\t *\n\t * Note: it's tempting to try to print the tabname here, but refrain for\n\t * fear of touching deallocated memory.  This isn't a user-facing message\n\t * anyway, so it needn't be pretty.\n\t */\n\tif (isCommit)\n\t{\n\t\tint\t\t\ti;\n\n\t\tfor (i = 0; i < num_seq_scans; i++)\n\t\t{\n\t\t\telog(WARNING, \"leaked hash_seq_search scan for hash table %p\",\n\t\t\t\t seq_scan_tables[i]);\n\t\t}\n\t}\n\tnum_seq_scans = 0;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
      "static int\tnum_seq_scans = 0;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "WARNING",
            "\"leaked hash_seq_search scan for hash table %p\"",
            "seq_scan_tables[i]"
          ],
          "line": 1851
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nvoid\nAtEOXact_HashTables(bool isCommit)\n{\n\t/*\n\t * During abort cleanup, open scans are expected; just silently clean 'em\n\t * out.  An open scan at commit means someone forgot a hash_seq_term()\n\t * call, so complain.\n\t *\n\t * Note: it's tempting to try to print the tabname here, but refrain for\n\t * fear of touching deallocated memory.  This isn't a user-facing message\n\t * anyway, so it needn't be pretty.\n\t */\n\tif (isCommit)\n\t{\n\t\tint\t\t\ti;\n\n\t\tfor (i = 0; i < num_seq_scans; i++)\n\t\t{\n\t\t\telog(WARNING, \"leaked hash_seq_search scan for hash table %p\",\n\t\t\t\t seq_scan_tables[i]);\n\t\t}\n\t}\n\tnum_seq_scans = 0;\n}"
  },
  {
    "function_name": "has_seq_scans",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1819-1830",
    "snippet": "static bool\nhas_seq_scans(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\tfor (i = 0; i < num_seq_scans; i++)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t\treturn true;\n\t}\n\treturn false;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
      "static int\tnum_seq_scans = 0;"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic bool\nhas_seq_scans(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\tfor (i = 0; i < num_seq_scans; i++)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t\treturn true;\n\t}\n\treturn false;\n}"
  },
  {
    "function_name": "deregister_seq_scan",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1798-1816",
    "snippet": "static void\nderegister_seq_scan(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\t/* Search backward since it's most likely at the stack top */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t{\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t\treturn;\n\t\t}\n\t}\n\telog(ERROR, \"no hash_seq_search scan for hash table \\\"%s\\\"\",\n\t\t hashp->tabname);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
      "static int\tseq_scan_level[MAX_SEQ_SCANS];",
      "static int\tnum_seq_scans = 0;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "ERROR",
            "\"no hash_seq_search scan for hash table \\\"%s\\\"\"",
            "hashp->tabname"
          ],
          "line": 1814
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tseq_scan_level[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic void\nderegister_seq_scan(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\t/* Search backward since it's most likely at the stack top */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t{\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t\treturn;\n\t\t}\n\t}\n\telog(ERROR, \"no hash_seq_search scan for hash table \\\"%s\\\"\",\n\t\t hashp->tabname);\n}"
  },
  {
    "function_name": "register_seq_scan",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1786-1795",
    "snippet": "static void\nregister_seq_scan(HTAB *hashp)\n{\n\tif (num_seq_scans >= MAX_SEQ_SCANS)\n\t\telog(ERROR, \"too many active hash_seq_search scans, cannot start one on \\\"%s\\\"\",\n\t\t\t hashp->tabname);\n\tseq_scan_tables[num_seq_scans] = hashp;\n\tseq_scan_level[num_seq_scans] = GetCurrentTransactionNestLevel();\n\tnum_seq_scans++;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define MAX_SEQ_SCANS 100"
    ],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
      "static int\tseq_scan_level[MAX_SEQ_SCANS];",
      "static int\tnum_seq_scans = 0;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "GetCurrentTransactionNestLevel",
          "args": [],
          "line": 1793
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "ERROR",
            "\"too many active hash_seq_search scans, cannot start one on \\\"%s\\\"\"",
            "hashp->tabname"
          ],
          "line": 1790
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define MAX_SEQ_SCANS 100\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tseq_scan_level[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic void\nregister_seq_scan(HTAB *hashp)\n{\n\tif (num_seq_scans >= MAX_SEQ_SCANS)\n\t\telog(ERROR, \"too many active hash_seq_search scans, cannot start one on \\\"%s\\\"\",\n\t\t\t hashp->tabname);\n\tseq_scan_tables[num_seq_scans] = hashp;\n\tseq_scan_level[num_seq_scans] = GetCurrentTransactionNestLevel();\n\tnum_seq_scans++;\n}"
  },
  {
    "function_name": "next_pow2_int",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1741-1747",
    "snippet": "static int\nnext_pow2_int(long num)\n{\n\tif (num > INT_MAX / 2)\n\t\tnum = INT_MAX / 2;\n\treturn 1 << my_log2(num);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static long next_pow2_long(long num);",
      "static int\tnext_pow2_int(long num);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "my_log2",
          "args": [
            "num"
          ],
          "line": 1746
        },
        "resolved": true,
        "details": {
          "function_name": "my_log2",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1717-1730",
          "snippet": "int\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nint\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nstatic int\nnext_pow2_int(long num)\n{\n\tif (num > INT_MAX / 2)\n\t\tnum = INT_MAX / 2;\n\treturn 1 << my_log2(num);\n}"
  },
  {
    "function_name": "next_pow2_long",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1733-1738",
    "snippet": "static long\nnext_pow2_long(long num)\n{\n\t/* my_log2's internal range check is sufficient */\n\treturn 1L << my_log2(num);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static long next_pow2_long(long num);",
      "static int\tnext_pow2_int(long num);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "my_log2",
          "args": [
            "num"
          ],
          "line": 1737
        },
        "resolved": true,
        "details": {
          "function_name": "my_log2",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1717-1730",
          "snippet": "int\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nint\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nstatic long\nnext_pow2_long(long num)\n{\n\t/* my_log2's internal range check is sufficient */\n\treturn 1L << my_log2(num);\n}"
  },
  {
    "function_name": "my_log2",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1717-1730",
    "snippet": "int\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static long next_pow2_long(long num);",
      "static int\tnext_pow2_int(long num);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nint\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}"
  },
  {
    "function_name": "hash_corrupted",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1703-1714",
    "snippet": "static void\nhash_corrupted(HTAB *hashp)\n{\n\t/*\n\t * If the corruption is in a shared hashtable, we'd better force a\n\t * systemwide restart.  Otherwise, just shut down this one backend.\n\t */\n\tif (hashp->isshared)\n\t\telog(PANIC, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n\telse\n\t\telog(FATAL, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "FATAL",
            "\"hash table \\\"%s\\\" corrupted\"",
            "hashp->tabname"
          ],
          "line": 1713
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic void\nhash_corrupted(HTAB *hashp)\n{\n\t/*\n\t * If the corruption is in a shared hashtable, we'd better force a\n\t * systemwide restart.  Otherwise, just shut down this one backend.\n\t */\n\tif (hashp->isshared)\n\t\telog(PANIC, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n\telse\n\t\telog(FATAL, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n}"
  },
  {
    "function_name": "element_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1656-1700",
    "snippet": "static bool\nelement_alloc(HTAB *hashp, int nelem, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tSize\t\telementSize;\n\tHASHELEMENT *firstElement;\n\tHASHELEMENT *tmpElement;\n\tHASHELEMENT *prevElement;\n\tint\t\t\ti;\n\n\tif (hashp->isfixed)\n\t\treturn false;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(hctl->entrysize);\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tfirstElement = (HASHELEMENT *) hashp->alloc(nelem * elementSize);\n\n\tif (!firstElement)\n\t\treturn false;\n\n\t/* prepare to link all the new entries into the freelist */\n\tprevElement = NULL;\n\ttmpElement = firstElement;\n\tfor (i = 0; i < nelem; i++)\n\t{\n\t\ttmpElement->link = prevElement;\n\t\tprevElement = tmpElement;\n\t\ttmpElement = (HASHELEMENT *) (((char *) tmpElement) + elementSize);\n\t}\n\n\t/* if partitioned, must lock to touch freeList */\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t/* freelist could be nonempty if two backends did this concurrently */\n\tfirstElement->link = hctl->freeList[freelist_idx].freeList;\n\thctl->freeList[freelist_idx].freeList = prevElement;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn true;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
      "static void hdefault(HTAB *hashp);",
      "static int\tchoose_nelem_alloc(Size entrysize);",
      "static bool init_htab(HTAB *hashp, long nelem);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static MemoryContext CurrentDynaHashCxt = NULL;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1697
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1696
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockAcquire",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1690
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1689
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hashp->alloc",
          "args": [
            "nelem * elementSize"
          ],
          "line": 1673
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "hctl->entrysize"
          ],
          "line": 1670
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "sizeof(HASHELEMENT)"
          ],
          "line": 1670
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic bool init_htab(HTAB *hashp, long nelem);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\nelement_alloc(HTAB *hashp, int nelem, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tSize\t\telementSize;\n\tHASHELEMENT *firstElement;\n\tHASHELEMENT *tmpElement;\n\tHASHELEMENT *prevElement;\n\tint\t\t\ti;\n\n\tif (hashp->isfixed)\n\t\treturn false;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(hctl->entrysize);\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tfirstElement = (HASHELEMENT *) hashp->alloc(nelem * elementSize);\n\n\tif (!firstElement)\n\t\treturn false;\n\n\t/* prepare to link all the new entries into the freelist */\n\tprevElement = NULL;\n\ttmpElement = firstElement;\n\tfor (i = 0; i < nelem; i++)\n\t{\n\t\ttmpElement->link = prevElement;\n\t\tprevElement = tmpElement;\n\t\ttmpElement = (HASHELEMENT *) (((char *) tmpElement) + elementSize);\n\t}\n\n\t/* if partitioned, must lock to touch freeList */\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t/* freelist could be nonempty if two backends did this concurrently */\n\tfirstElement->link = hctl->freeList[freelist_idx].freeList;\n\thctl->freeList[freelist_idx].freeList = prevElement;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn true;\n}"
  },
  {
    "function_name": "seg_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1637-1651",
    "snippet": "static HASHSEGMENT\nseg_alloc(HTAB *hashp)\n{\n\tHASHSEGMENT segp;\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tsegp = (HASHSEGMENT) hashp->alloc(sizeof(HASHBUCKET) * hashp->ssize);\n\n\tif (!segp)\n\t\treturn NULL;\n\n\tMemSet(segp, 0, sizeof(HASHBUCKET) * hashp->ssize);\n\n\treturn segp;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static MemoryContext CurrentDynaHashCxt = NULL;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "MemSet",
          "args": [
            "segp",
            "0",
            "sizeof(HASHBUCKET) * hashp->ssize"
          ],
          "line": 1648
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hashp->alloc",
          "args": [
            "sizeof(HASHBUCKET) * hashp->ssize"
          ],
          "line": 1643
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic HASHSEGMENT\nseg_alloc(HTAB *hashp)\n{\n\tHASHSEGMENT segp;\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tsegp = (HASHSEGMENT) hashp->alloc(sizeof(HASHBUCKET) * hashp->ssize);\n\n\tif (!segp)\n\t\treturn NULL;\n\n\tMemSet(segp, 0, sizeof(HASHBUCKET) * hashp->ssize);\n\n\treturn segp;\n}"
  },
  {
    "function_name": "dir_realloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1598-1634",
    "snippet": "static bool\ndir_realloc(HTAB *hashp)\n{\n\tHASHSEGMENT *p;\n\tHASHSEGMENT *old_p;\n\tlong\t\tnew_dsize;\n\tlong\t\told_dirsize;\n\tlong\t\tnew_dirsize;\n\n\tif (hashp->hctl->max_dsize != NO_MAX_DSIZE)\n\t\treturn false;\n\n\t/* Reallocate directory */\n\tnew_dsize = hashp->hctl->dsize << 1;\n\told_dirsize = hashp->hctl->dsize * sizeof(HASHSEGMENT);\n\tnew_dirsize = new_dsize * sizeof(HASHSEGMENT);\n\n\told_p = hashp->dir;\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tp = (HASHSEGMENT *) hashp->alloc((Size) new_dirsize);\n\n\tif (p != NULL)\n\t{\n\t\tmemcpy(p, old_p, old_dirsize);\n\t\tMemSet(((char *) p) + old_dirsize, 0, new_dirsize - old_dirsize);\n\t\thashp->dir = p;\n\t\thashp->hctl->dsize = new_dsize;\n\n\t\t/* XXX assume the allocator is palloc, so we know how to free */\n\t\tAssert(hashp->alloc == DynaHashAlloc);\n\t\tpfree(old_p);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static MemoryContext CurrentDynaHashCxt = NULL;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "pfree",
          "args": [
            "old_p"
          ],
          "line": 1628
        },
        "resolved": true,
        "details": {
          "function_name": "pfree",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/mmgr/mcxt.c",
          "lines": "1030-1037",
          "snippet": "void\npfree(void *pointer)\n{\n\tMemoryContext context = GetMemoryChunkContext(pointer);\n\n\tcontext->methods->free_p(context, pointer);\n\tVALGRIND_MEMPOOL_FREE(context, pointer);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/memdebug.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void MemoryContextCallResetCallbacks(MemoryContext context);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/memdebug.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"postgres.h\"\n\nstatic void MemoryContextCallResetCallbacks(MemoryContext context);\n\nvoid\npfree(void *pointer)\n{\n\tMemoryContext context = GetMemoryChunkContext(pointer);\n\n\tcontext->methods->free_p(context, pointer);\n\tVALGRIND_MEMPOOL_FREE(context, pointer);\n}"
        }
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "hashp->alloc == DynaHashAlloc"
          ],
          "line": 1627
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MemSet",
          "args": [
            "((char *) p) + old_dirsize",
            "0",
            "new_dirsize - old_dirsize"
          ],
          "line": 1622
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "p",
            "old_p",
            "old_dirsize"
          ],
          "line": 1621
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hashp->alloc",
          "args": [
            "(Size) new_dirsize"
          ],
          "line": 1617
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\ndir_realloc(HTAB *hashp)\n{\n\tHASHSEGMENT *p;\n\tHASHSEGMENT *old_p;\n\tlong\t\tnew_dsize;\n\tlong\t\told_dirsize;\n\tlong\t\tnew_dirsize;\n\n\tif (hashp->hctl->max_dsize != NO_MAX_DSIZE)\n\t\treturn false;\n\n\t/* Reallocate directory */\n\tnew_dsize = hashp->hctl->dsize << 1;\n\told_dirsize = hashp->hctl->dsize * sizeof(HASHSEGMENT);\n\tnew_dirsize = new_dsize * sizeof(HASHSEGMENT);\n\n\told_p = hashp->dir;\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tp = (HASHSEGMENT *) hashp->alloc((Size) new_dirsize);\n\n\tif (p != NULL)\n\t{\n\t\tmemcpy(p, old_p, old_dirsize);\n\t\tMemSet(((char *) p) + old_dirsize, 0, new_dirsize - old_dirsize);\n\t\thashp->dir = p;\n\t\thashp->hctl->dsize = new_dsize;\n\n\t\t/* XXX assume the allocator is palloc, so we know how to free */\n\t\tAssert(hashp->alloc == DynaHashAlloc);\n\t\tpfree(old_p);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
  },
  {
    "function_name": "expand_table",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1501-1595",
    "snippet": "static bool\nexpand_table(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT old_seg,\n\t\t\t\tnew_seg;\n\tlong\t\told_bucket,\n\t\t\t\tnew_bucket;\n\tlong\t\tnew_segnum,\n\t\t\t\tnew_segndx;\n\tlong\t\told_segnum,\n\t\t\t\told_segndx;\n\tHASHBUCKET *oldlink,\n\t\t\t   *newlink;\n\tHASHBUCKET\tcurrElement,\n\t\t\t\tnextElement;\n\n\tAssert(!IS_PARTITIONED(hctl));\n\n#ifdef HASH_STATISTICS\n\thash_expansions++;\n#endif\n\n\tnew_bucket = hctl->max_bucket + 1;\n\tnew_segnum = new_bucket >> hashp->sshift;\n\tnew_segndx = MOD(new_bucket, hashp->ssize);\n\n\tif (new_segnum >= hctl->nsegs)\n\t{\n\t\t/* Allocate new segment if necessary -- could fail if dir full */\n\t\tif (new_segnum >= hctl->dsize)\n\t\t\tif (!dir_realloc(hashp))\n\t\t\t\treturn false;\n\t\tif (!(hashp->dir[new_segnum] = seg_alloc(hashp)))\n\t\t\treturn false;\n\t\thctl->nsegs++;\n\t}\n\n\t/* OK, we created a new bucket */\n\thctl->max_bucket++;\n\n\t/*\n\t * *Before* changing masks, find old bucket corresponding to same hash\n\t * values; values in that bucket may need to be relocated to new bucket.\n\t * Note that new_bucket is certainly larger than low_mask at this point,\n\t * so we can skip the first step of the regular hash mask calc.\n\t */\n\told_bucket = (new_bucket & hctl->low_mask);\n\n\t/*\n\t * If we crossed a power of 2, readjust masks.\n\t */\n\tif ((uint32) new_bucket > hctl->high_mask)\n\t{\n\t\thctl->low_mask = hctl->high_mask;\n\t\thctl->high_mask = (uint32) new_bucket | hctl->low_mask;\n\t}\n\n\t/*\n\t * Relocate records to the new bucket.  NOTE: because of the way the hash\n\t * masking is done in calc_bucket, only one old bucket can need to be\n\t * split at this point.  With a different way of reducing the hash value,\n\t * that might not be true!\n\t */\n\told_segnum = old_bucket >> hashp->sshift;\n\told_segndx = MOD(old_bucket, hashp->ssize);\n\n\told_seg = hashp->dir[old_segnum];\n\tnew_seg = hashp->dir[new_segnum];\n\n\toldlink = &old_seg[old_segndx];\n\tnewlink = &new_seg[new_segndx];\n\n\tfor (currElement = *oldlink;\n\t\t currElement != NULL;\n\t\t currElement = nextElement)\n\t{\n\t\tnextElement = currElement->link;\n\t\tif ((long) calc_bucket(hctl, currElement->hashvalue) == old_bucket)\n\t\t{\n\t\t\t*oldlink = currElement;\n\t\t\toldlink = &currElement->link;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t*newlink = currElement;\n\t\t\tnewlink = &currElement->link;\n\t\t}\n\t}\n\t/* don't forget to terminate the rebuilt hash chains... */\n\t*oldlink = NULL;\n\t*newlink = NULL;\n\n\treturn true;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "calc_bucket",
          "args": [
            "hctl",
            "currElement->hashvalue"
          ],
          "line": 1579
        },
        "resolved": true,
        "details": {
          "function_name": "calc_bucket",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "866-876",
          "snippet": "static inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}"
        }
      },
      {
        "call_info": {
          "callee": "MOD",
          "args": [
            "old_bucket",
            "hashp->ssize"
          ],
          "line": 1566
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "seg_alloc",
          "args": [
            "hashp"
          ],
          "line": 1534
        },
        "resolved": true,
        "details": {
          "function_name": "seg_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1637-1651",
          "snippet": "static HASHSEGMENT\nseg_alloc(HTAB *hashp)\n{\n\tHASHSEGMENT segp;\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tsegp = (HASHSEGMENT) hashp->alloc(sizeof(HASHBUCKET) * hashp->ssize);\n\n\tif (!segp)\n\t\treturn NULL;\n\n\tMemSet(segp, 0, sizeof(HASHBUCKET) * hashp->ssize);\n\n\treturn segp;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic HASHSEGMENT\nseg_alloc(HTAB *hashp)\n{\n\tHASHSEGMENT segp;\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tsegp = (HASHSEGMENT) hashp->alloc(sizeof(HASHBUCKET) * hashp->ssize);\n\n\tif (!segp)\n\t\treturn NULL;\n\n\tMemSet(segp, 0, sizeof(HASHBUCKET) * hashp->ssize);\n\n\treturn segp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "dir_realloc",
          "args": [
            "hashp"
          ],
          "line": 1532
        },
        "resolved": true,
        "details": {
          "function_name": "dir_realloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1598-1634",
          "snippet": "static bool\ndir_realloc(HTAB *hashp)\n{\n\tHASHSEGMENT *p;\n\tHASHSEGMENT *old_p;\n\tlong\t\tnew_dsize;\n\tlong\t\told_dirsize;\n\tlong\t\tnew_dirsize;\n\n\tif (hashp->hctl->max_dsize != NO_MAX_DSIZE)\n\t\treturn false;\n\n\t/* Reallocate directory */\n\tnew_dsize = hashp->hctl->dsize << 1;\n\told_dirsize = hashp->hctl->dsize * sizeof(HASHSEGMENT);\n\tnew_dirsize = new_dsize * sizeof(HASHSEGMENT);\n\n\told_p = hashp->dir;\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tp = (HASHSEGMENT *) hashp->alloc((Size) new_dirsize);\n\n\tif (p != NULL)\n\t{\n\t\tmemcpy(p, old_p, old_dirsize);\n\t\tMemSet(((char *) p) + old_dirsize, 0, new_dirsize - old_dirsize);\n\t\thashp->dir = p;\n\t\thashp->hctl->dsize = new_dsize;\n\n\t\t/* XXX assume the allocator is palloc, so we know how to free */\n\t\tAssert(hashp->alloc == DynaHashAlloc);\n\t\tpfree(old_p);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\ndir_realloc(HTAB *hashp)\n{\n\tHASHSEGMENT *p;\n\tHASHSEGMENT *old_p;\n\tlong\t\tnew_dsize;\n\tlong\t\told_dirsize;\n\tlong\t\tnew_dirsize;\n\n\tif (hashp->hctl->max_dsize != NO_MAX_DSIZE)\n\t\treturn false;\n\n\t/* Reallocate directory */\n\tnew_dsize = hashp->hctl->dsize << 1;\n\told_dirsize = hashp->hctl->dsize * sizeof(HASHSEGMENT);\n\tnew_dirsize = new_dsize * sizeof(HASHSEGMENT);\n\n\told_p = hashp->dir;\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tp = (HASHSEGMENT *) hashp->alloc((Size) new_dirsize);\n\n\tif (p != NULL)\n\t{\n\t\tmemcpy(p, old_p, old_dirsize);\n\t\tMemSet(((char *) p) + old_dirsize, 0, new_dirsize - old_dirsize);\n\t\thashp->dir = p;\n\t\thashp->hctl->dsize = new_dsize;\n\n\t\t/* XXX assume the allocator is palloc, so we know how to free */\n\t\tAssert(hashp->alloc == DynaHashAlloc);\n\t\tpfree(old_p);\n\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "MOD",
          "args": [
            "new_bucket",
            "hashp->ssize"
          ],
          "line": 1526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "!IS_PARTITIONED(hctl)"
          ],
          "line": 1518
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1518
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic bool\nexpand_table(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT old_seg,\n\t\t\t\tnew_seg;\n\tlong\t\told_bucket,\n\t\t\t\tnew_bucket;\n\tlong\t\tnew_segnum,\n\t\t\t\tnew_segndx;\n\tlong\t\told_segnum,\n\t\t\t\told_segndx;\n\tHASHBUCKET *oldlink,\n\t\t\t   *newlink;\n\tHASHBUCKET\tcurrElement,\n\t\t\t\tnextElement;\n\n\tAssert(!IS_PARTITIONED(hctl));\n\n#ifdef HASH_STATISTICS\n\thash_expansions++;\n#endif\n\n\tnew_bucket = hctl->max_bucket + 1;\n\tnew_segnum = new_bucket >> hashp->sshift;\n\tnew_segndx = MOD(new_bucket, hashp->ssize);\n\n\tif (new_segnum >= hctl->nsegs)\n\t{\n\t\t/* Allocate new segment if necessary -- could fail if dir full */\n\t\tif (new_segnum >= hctl->dsize)\n\t\t\tif (!dir_realloc(hashp))\n\t\t\t\treturn false;\n\t\tif (!(hashp->dir[new_segnum] = seg_alloc(hashp)))\n\t\t\treturn false;\n\t\thctl->nsegs++;\n\t}\n\n\t/* OK, we created a new bucket */\n\thctl->max_bucket++;\n\n\t/*\n\t * *Before* changing masks, find old bucket corresponding to same hash\n\t * values; values in that bucket may need to be relocated to new bucket.\n\t * Note that new_bucket is certainly larger than low_mask at this point,\n\t * so we can skip the first step of the regular hash mask calc.\n\t */\n\told_bucket = (new_bucket & hctl->low_mask);\n\n\t/*\n\t * If we crossed a power of 2, readjust masks.\n\t */\n\tif ((uint32) new_bucket > hctl->high_mask)\n\t{\n\t\thctl->low_mask = hctl->high_mask;\n\t\thctl->high_mask = (uint32) new_bucket | hctl->low_mask;\n\t}\n\n\t/*\n\t * Relocate records to the new bucket.  NOTE: because of the way the hash\n\t * masking is done in calc_bucket, only one old bucket can need to be\n\t * split at this point.  With a different way of reducing the hash value,\n\t * that might not be true!\n\t */\n\told_segnum = old_bucket >> hashp->sshift;\n\told_segndx = MOD(old_bucket, hashp->ssize);\n\n\told_seg = hashp->dir[old_segnum];\n\tnew_seg = hashp->dir[new_segnum];\n\n\toldlink = &old_seg[old_segndx];\n\tnewlink = &new_seg[new_segndx];\n\n\tfor (currElement = *oldlink;\n\t\t currElement != NULL;\n\t\t currElement = nextElement)\n\t{\n\t\tnextElement = currElement->link;\n\t\tif ((long) calc_bucket(hctl, currElement->hashvalue) == old_bucket)\n\t\t{\n\t\t\t*oldlink = currElement;\n\t\t\toldlink = &currElement->link;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t*newlink = currElement;\n\t\t\tnewlink = &currElement->link;\n\t\t}\n\t}\n\t/* don't forget to terminate the rebuilt hash chains... */\n\t*oldlink = NULL;\n\t*newlink = NULL;\n\n\treturn true;\n}"
  },
  {
    "function_name": "hash_freeze",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1484-1493",
    "snippet": "void\nhash_freeze(HTAB *hashp)\n{\n\tif (hashp->isshared)\n\t\telog(ERROR, \"cannot freeze shared hashtable \\\"%s\\\"\", hashp->tabname);\n\tif (!hashp->frozen && has_seq_scans(hashp))\n\t\telog(ERROR, \"cannot freeze hashtable \\\"%s\\\" because it has active scans\",\n\t\t\t hashp->tabname);\n\thashp->frozen = true;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "ERROR",
            "\"cannot freeze hashtable \\\"%s\\\" because it has active scans\"",
            "hashp->tabname"
          ],
          "line": 1490
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      },
      {
        "call_info": {
          "callee": "has_seq_scans",
          "args": [
            "hashp"
          ],
          "line": 1489
        },
        "resolved": true,
        "details": {
          "function_name": "has_seq_scans",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1819-1830",
          "snippet": "static bool\nhas_seq_scans(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\tfor (i = 0; i < num_seq_scans; i++)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t\treturn true;\n\t}\n\treturn false;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
            "static int\tnum_seq_scans = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic bool\nhas_seq_scans(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\tfor (i = 0; i < num_seq_scans; i++)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t\treturn true;\n\t}\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_freeze(HTAB *hashp)\n{\n\tif (hashp->isshared)\n\t\telog(ERROR, \"cannot freeze shared hashtable \\\"%s\\\"\", hashp->tabname);\n\tif (!hashp->frozen && has_seq_scans(hashp))\n\t\telog(ERROR, \"cannot freeze hashtable \\\"%s\\\" because it has active scans\",\n\t\t\t hashp->tabname);\n\thashp->frozen = true;\n}"
  },
  {
    "function_name": "hash_seq_term",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1464-1469",
    "snippet": "void\nhash_seq_term(HASH_SEQ_STATUS *status)\n{\n\tif (!status->hashp->frozen)\n\t\tderegister_seq_scan(status->hashp);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "deregister_seq_scan",
          "args": [
            "status->hashp"
          ],
          "line": 1468
        },
        "resolved": true,
        "details": {
          "function_name": "deregister_seq_scan",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1798-1816",
          "snippet": "static void\nderegister_seq_scan(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\t/* Search backward since it's most likely at the stack top */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t{\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t\treturn;\n\t\t}\n\t}\n\telog(ERROR, \"no hash_seq_search scan for hash table \\\"%s\\\"\",\n\t\t hashp->tabname);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
            "static int\tseq_scan_level[MAX_SEQ_SCANS];",
            "static int\tnum_seq_scans = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tseq_scan_level[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic void\nderegister_seq_scan(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\t/* Search backward since it's most likely at the stack top */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t{\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t\treturn;\n\t\t}\n\t}\n\telog(ERROR, \"no hash_seq_search scan for hash table \\\"%s\\\"\",\n\t\t hashp->tabname);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_seq_term(HASH_SEQ_STATUS *status)\n{\n\tif (!status->hashp->frozen)\n\t\tderegister_seq_scan(status->hashp);\n}"
  },
  {
    "function_name": "hash_seq_search",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1388-1462",
    "snippet": "void *\nhash_seq_search(HASH_SEQ_STATUS *status)\n{\n\tHTAB\t   *hashp;\n\tHASHHDR    *hctl;\n\tuint32\t\tmax_bucket;\n\tlong\t\tssize;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tuint32\t\tcurBucket;\n\tHASHELEMENT *curElem;\n\n\tif ((curElem = status->curEntry) != NULL)\n\t{\n\t\t/* Continuing scan of curBucket... */\n\t\tstatus->curEntry = curElem->link;\n\t\tif (status->curEntry == NULL)\t/* end of this bucket */\n\t\t\t++status->curBucket;\n\t\treturn (void *) ELEMENTKEY(curElem);\n\t}\n\n\t/*\n\t * Search for next nonempty bucket starting at curBucket.\n\t */\n\tcurBucket = status->curBucket;\n\thashp = status->hashp;\n\thctl = hashp->hctl;\n\tssize = hashp->ssize;\n\tmax_bucket = hctl->max_bucket;\n\n\tif (curBucket > max_bucket)\n\t{\n\t\thash_seq_term(status);\n\t\treturn NULL;\t\t\t/* search is done */\n\t}\n\n\t/*\n\t * first find the right segment in the table directory.\n\t */\n\tsegment_num = curBucket >> hashp->sshift;\n\tsegment_ndx = MOD(curBucket, ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\t/*\n\t * Pick up the first item in this bucket's chain.  If chain is not empty\n\t * we can begin searching it.  Otherwise we have to advance to find the\n\t * next nonempty bucket.  We try to optimize that case since searching a\n\t * near-empty hashtable has to iterate this loop a lot.\n\t */\n\twhile ((curElem = segp[segment_ndx]) == NULL)\n\t{\n\t\t/* empty bucket, advance to next */\n\t\tif (++curBucket > max_bucket)\n\t\t{\n\t\t\tstatus->curBucket = curBucket;\n\t\t\thash_seq_term(status);\n\t\t\treturn NULL;\t\t/* search is done */\n\t\t}\n\t\tif (++segment_ndx >= ssize)\n\t\t{\n\t\t\tsegment_num++;\n\t\t\tsegment_ndx = 0;\n\t\t\tsegp = hashp->dir[segment_num];\n\t\t}\n\t}\n\n\t/* Begin scan of curBucket... */\n\tstatus->curEntry = curElem->link;\n\tif (status->curEntry == NULL)\t/* end of this bucket */\n\t\t++curBucket;\n\tstatus->curBucket = curBucket;\n\treturn (void *) ELEMENTKEY(curElem);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "curElem"
          ],
          "line": 1461
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hash_seq_term",
          "args": [
            "status"
          ],
          "line": 1445
        },
        "resolved": true,
        "details": {
          "function_name": "hash_seq_term",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1464-1469",
          "snippet": "void\nhash_seq_term(HASH_SEQ_STATUS *status)\n{\n\tif (!status->hashp->frozen)\n\t\tderegister_seq_scan(status->hashp);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_seq_term(HASH_SEQ_STATUS *status)\n{\n\tif (!status->hashp->frozen)\n\t\tderegister_seq_scan(status->hashp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "MOD",
          "args": [
            "curBucket",
            "ssize"
          ],
          "line": 1429
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "curElem"
          ],
          "line": 1407
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid *\nhash_seq_search(HASH_SEQ_STATUS *status)\n{\n\tHTAB\t   *hashp;\n\tHASHHDR    *hctl;\n\tuint32\t\tmax_bucket;\n\tlong\t\tssize;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tuint32\t\tcurBucket;\n\tHASHELEMENT *curElem;\n\n\tif ((curElem = status->curEntry) != NULL)\n\t{\n\t\t/* Continuing scan of curBucket... */\n\t\tstatus->curEntry = curElem->link;\n\t\tif (status->curEntry == NULL)\t/* end of this bucket */\n\t\t\t++status->curBucket;\n\t\treturn (void *) ELEMENTKEY(curElem);\n\t}\n\n\t/*\n\t * Search for next nonempty bucket starting at curBucket.\n\t */\n\tcurBucket = status->curBucket;\n\thashp = status->hashp;\n\thctl = hashp->hctl;\n\tssize = hashp->ssize;\n\tmax_bucket = hctl->max_bucket;\n\n\tif (curBucket > max_bucket)\n\t{\n\t\thash_seq_term(status);\n\t\treturn NULL;\t\t\t/* search is done */\n\t}\n\n\t/*\n\t * first find the right segment in the table directory.\n\t */\n\tsegment_num = curBucket >> hashp->sshift;\n\tsegment_ndx = MOD(curBucket, ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\t/*\n\t * Pick up the first item in this bucket's chain.  If chain is not empty\n\t * we can begin searching it.  Otherwise we have to advance to find the\n\t * next nonempty bucket.  We try to optimize that case since searching a\n\t * near-empty hashtable has to iterate this loop a lot.\n\t */\n\twhile ((curElem = segp[segment_ndx]) == NULL)\n\t{\n\t\t/* empty bucket, advance to next */\n\t\tif (++curBucket > max_bucket)\n\t\t{\n\t\t\tstatus->curBucket = curBucket;\n\t\t\thash_seq_term(status);\n\t\t\treturn NULL;\t\t/* search is done */\n\t\t}\n\t\tif (++segment_ndx >= ssize)\n\t\t{\n\t\t\tsegment_num++;\n\t\t\tsegment_ndx = 0;\n\t\t\tsegp = hashp->dir[segment_num];\n\t\t}\n\t}\n\n\t/* Begin scan of curBucket... */\n\tstatus->curEntry = curElem->link;\n\tif (status->curEntry == NULL)\t/* end of this bucket */\n\t\t++curBucket;\n\tstatus->curBucket = curBucket;\n\treturn (void *) ELEMENTKEY(curElem);\n}"
  },
  {
    "function_name": "hash_seq_init",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1378-1386",
    "snippet": "void\nhash_seq_init(HASH_SEQ_STATUS *status, HTAB *hashp)\n{\n\tstatus->hashp = hashp;\n\tstatus->curBucket = 0;\n\tstatus->curEntry = NULL;\n\tif (!hashp->frozen)\n\t\tregister_seq_scan(hashp);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "register_seq_scan",
          "args": [
            "hashp"
          ],
          "line": 1385
        },
        "resolved": true,
        "details": {
          "function_name": "deregister_seq_scan",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1798-1816",
          "snippet": "static void\nderegister_seq_scan(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\t/* Search backward since it's most likely at the stack top */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t{\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t\treturn;\n\t\t}\n\t}\n\telog(ERROR, \"no hash_seq_search scan for hash table \\\"%s\\\"\",\n\t\t hashp->tabname);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
            "static int\tseq_scan_level[MAX_SEQ_SCANS];",
            "static int\tnum_seq_scans = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tseq_scan_level[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic void\nderegister_seq_scan(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\t/* Search backward since it's most likely at the stack top */\n\tfor (i = num_seq_scans - 1; i >= 0; i--)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t{\n\t\t\tseq_scan_tables[i] = seq_scan_tables[num_seq_scans - 1];\n\t\t\tseq_scan_level[i] = seq_scan_level[num_seq_scans - 1];\n\t\t\tnum_seq_scans--;\n\t\t\treturn;\n\t\t}\n\t}\n\telog(ERROR, \"no hash_seq_search scan for hash table \\\"%s\\\"\",\n\t\t hashp->tabname);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_seq_init(HASH_SEQ_STATUS *status, HTAB *hashp)\n{\n\tstatus->hashp = hashp;\n\tstatus->curBucket = 0;\n\tstatus->curEntry = NULL;\n\tif (!hashp->frozen)\n\t\tregister_seq_scan(hashp);\n}"
  },
  {
    "function_name": "hash_get_num_entries",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1334-1352",
    "snippet": "long\nhash_get_num_entries(HTAB *hashp)\n{\n\tint\t\t\ti;\n\tlong\t\tsum = hashp->hctl->freeList[0].nentries;\n\n\t/*\n\t * We currently don't bother with acquiring the mutexes; it's only\n\t * sensible to call this function if you've got lock on all partitions of\n\t * the table.\n\t */\n\tif (IS_PARTITIONED(hashp->hctl))\n\t{\n\t\tfor (i = 1; i < NUM_FREELISTS; i++)\n\t\t\tsum += hashp->hctl->freeList[i].nentries;\n\t}\n\n\treturn sum;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define NUM_FREELISTS\t\t\t32"
    ],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hashp->hctl"
          ],
          "line": 1345
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nlong\nhash_get_num_entries(HTAB *hashp)\n{\n\tint\t\t\ti;\n\tlong\t\tsum = hashp->hctl->freeList[0].nentries;\n\n\t/*\n\t * We currently don't bother with acquiring the mutexes; it's only\n\t * sensible to call this function if you've got lock on all partitions of\n\t * the table.\n\t */\n\tif (IS_PARTITIONED(hashp->hctl))\n\t{\n\t\tfor (i = 1; i < NUM_FREELISTS; i++)\n\t\t\tsum += hashp->hctl->freeList[i].nentries;\n\t}\n\n\treturn sum;\n}"
  },
  {
    "function_name": "get_hash_entry",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1249-1329",
    "snippet": "static HASHBUCKET\nget_hash_entry(HTAB *hashp, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHBUCKET\tnewElement;\n\n\tfor (;;)\n\t{\n\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/* try to get an entry from the freelist */\n\t\tnewElement = hctl->freeList[freelist_idx].freeList;\n\n\t\tif (newElement != NULL)\n\t\t\tbreak;\n\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/*\n\t\t * No free elements in this freelist.  In a partitioned table, there\n\t\t * might be entries in other freelists, but to reduce contention we\n\t\t * prefer to first try to get another chunk of buckets from the main\n\t\t * shmem allocator.  If that fails, though, we *MUST* root through all\n\t\t * the other freelists before giving up.  There are multiple callers\n\t\t * that assume that they can allocate every element in the initially\n\t\t * requested table size, or that deleting an element guarantees they\n\t\t * can insert a new element, even if shared memory is entirely full.\n\t\t * Failing because the needed element is in a different freelist is\n\t\t * not acceptable.\n\t\t */\n\t\tif (!element_alloc(hashp, hctl->nelem_alloc, freelist_idx))\n\t\t{\n\t\t\tint\t\t\tborrow_from_idx;\n\n\t\t\tif (!IS_PARTITIONED(hctl))\n\t\t\t\treturn NULL;\t/* out of memory */\n\n\t\t\t/* try to borrow element from another freelist */\n\t\t\tborrow_from_idx = freelist_idx;\n\t\t\tfor (;;)\n\t\t\t{\n\t\t\t\tborrow_from_idx = (borrow_from_idx + 1) % NUM_FREELISTS;\n\t\t\t\tif (borrow_from_idx == freelist_idx)\n\t\t\t\t\tbreak;\t\t/* examined all freelists, fail */\n\n\t\t\t\tSpinLockAcquire(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t\tnewElement = hctl->freeList[borrow_from_idx].freeList;\n\n\t\t\t\tif (newElement != NULL)\n\t\t\t\t{\n\t\t\t\t\thctl->freeList[borrow_from_idx].freeList = newElement->link;\n\t\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\n\t\t\t\t\t/* careful: count the new element in its proper freelist */\n\t\t\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\t\t\t\t\thctl->freeList[freelist_idx].nentries++;\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t\treturn newElement;\n\t\t\t\t}\n\n\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t}\n\n\t\t\t/* no elements available to borrow either, so out of memory */\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* remove entry from freelist, bump nentries */\n\thctl->freeList[freelist_idx].freeList = newElement->link;\n\thctl->freeList[freelist_idx].nentries++;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn newElement;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define NUM_FREELISTS\t\t\t32"
    ],
    "globals_used": [
      "static void *DynaHashAlloc(Size size);",
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1326
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1325
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&(hctl->freeList[borrow_from_idx].mutex)"
          ],
          "line": 1313
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1308
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockAcquire",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1306
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&(hctl->freeList[borrow_from_idx].mutex)"
          ],
          "line": 1303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockAcquire",
          "args": [
            "&(hctl->freeList[borrow_from_idx].mutex)"
          ],
          "line": 1297
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "element_alloc",
          "args": [
            "hashp",
            "hctl->nelem_alloc",
            "freelist_idx"
          ],
          "line": 1282
        },
        "resolved": true,
        "details": {
          "function_name": "element_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1656-1700",
          "snippet": "static bool\nelement_alloc(HTAB *hashp, int nelem, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tSize\t\telementSize;\n\tHASHELEMENT *firstElement;\n\tHASHELEMENT *tmpElement;\n\tHASHELEMENT *prevElement;\n\tint\t\t\ti;\n\n\tif (hashp->isfixed)\n\t\treturn false;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(hctl->entrysize);\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tfirstElement = (HASHELEMENT *) hashp->alloc(nelem * elementSize);\n\n\tif (!firstElement)\n\t\treturn false;\n\n\t/* prepare to link all the new entries into the freelist */\n\tprevElement = NULL;\n\ttmpElement = firstElement;\n\tfor (i = 0; i < nelem; i++)\n\t{\n\t\ttmpElement->link = prevElement;\n\t\tprevElement = tmpElement;\n\t\ttmpElement = (HASHELEMENT *) (((char *) tmpElement) + elementSize);\n\t}\n\n\t/* if partitioned, must lock to touch freeList */\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t/* freelist could be nonempty if two backends did this concurrently */\n\tfirstElement->link = hctl->freeList[freelist_idx].freeList;\n\thctl->freeList[freelist_idx].freeList = prevElement;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn true;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
            "static void hdefault(HTAB *hashp);",
            "static int\tchoose_nelem_alloc(Size entrysize);",
            "static bool init_htab(HTAB *hashp, long nelem);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic bool init_htab(HTAB *hashp, long nelem);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\nelement_alloc(HTAB *hashp, int nelem, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tSize\t\telementSize;\n\tHASHELEMENT *firstElement;\n\tHASHELEMENT *tmpElement;\n\tHASHELEMENT *prevElement;\n\tint\t\t\ti;\n\n\tif (hashp->isfixed)\n\t\treturn false;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(hctl->entrysize);\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tfirstElement = (HASHELEMENT *) hashp->alloc(nelem * elementSize);\n\n\tif (!firstElement)\n\t\treturn false;\n\n\t/* prepare to link all the new entries into the freelist */\n\tprevElement = NULL;\n\ttmpElement = firstElement;\n\tfor (i = 0; i < nelem; i++)\n\t{\n\t\ttmpElement->link = prevElement;\n\t\tprevElement = tmpElement;\n\t\ttmpElement = (HASHELEMENT *) (((char *) tmpElement) + elementSize);\n\t}\n\n\t/* if partitioned, must lock to touch freeList */\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t/* freelist could be nonempty if two backends did this concurrently */\n\tfirstElement->link = hctl->freeList[freelist_idx].freeList;\n\thctl->freeList[freelist_idx].freeList = prevElement;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1268
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1267
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockAcquire",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1258
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic void *DynaHashAlloc(Size size);\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic HASHBUCKET\nget_hash_entry(HTAB *hashp, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHBUCKET\tnewElement;\n\n\tfor (;;)\n\t{\n\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/* try to get an entry from the freelist */\n\t\tnewElement = hctl->freeList[freelist_idx].freeList;\n\n\t\tif (newElement != NULL)\n\t\t\tbreak;\n\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/*\n\t\t * No free elements in this freelist.  In a partitioned table, there\n\t\t * might be entries in other freelists, but to reduce contention we\n\t\t * prefer to first try to get another chunk of buckets from the main\n\t\t * shmem allocator.  If that fails, though, we *MUST* root through all\n\t\t * the other freelists before giving up.  There are multiple callers\n\t\t * that assume that they can allocate every element in the initially\n\t\t * requested table size, or that deleting an element guarantees they\n\t\t * can insert a new element, even if shared memory is entirely full.\n\t\t * Failing because the needed element is in a different freelist is\n\t\t * not acceptable.\n\t\t */\n\t\tif (!element_alloc(hashp, hctl->nelem_alloc, freelist_idx))\n\t\t{\n\t\t\tint\t\t\tborrow_from_idx;\n\n\t\t\tif (!IS_PARTITIONED(hctl))\n\t\t\t\treturn NULL;\t/* out of memory */\n\n\t\t\t/* try to borrow element from another freelist */\n\t\t\tborrow_from_idx = freelist_idx;\n\t\t\tfor (;;)\n\t\t\t{\n\t\t\t\tborrow_from_idx = (borrow_from_idx + 1) % NUM_FREELISTS;\n\t\t\t\tif (borrow_from_idx == freelist_idx)\n\t\t\t\t\tbreak;\t\t/* examined all freelists, fail */\n\n\t\t\t\tSpinLockAcquire(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t\tnewElement = hctl->freeList[borrow_from_idx].freeList;\n\n\t\t\t\tif (newElement != NULL)\n\t\t\t\t{\n\t\t\t\t\thctl->freeList[borrow_from_idx].freeList = newElement->link;\n\t\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\n\t\t\t\t\t/* careful: count the new element in its proper freelist */\n\t\t\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\t\t\t\t\thctl->freeList[freelist_idx].nentries++;\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t\treturn newElement;\n\t\t\t\t}\n\n\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t}\n\n\t\t\t/* no elements available to borrow either, so out of memory */\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* remove entry from freelist, bump nentries */\n\thctl->freeList[freelist_idx].freeList = newElement->link;\n\thctl->freeList[freelist_idx].nentries++;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn newElement;\n}"
  },
  {
    "function_name": "hash_update_hash_key",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "1114-1242",
    "snippet": "bool\nhash_update_hash_key(HTAB *hashp,\n\t\t\t\t\t void *existingEntry,\n\t\t\t\t\t const void *newKeyPtr)\n{\n\tHASHELEMENT *existingElement = ELEMENT_FROM_KEY(existingEntry);\n\tHASHHDR    *hctl = hashp->hctl;\n\tuint32\t\tnewhashvalue;\n\tSize\t\tkeysize;\n\tuint32\t\tbucket;\n\tuint32\t\tnewbucket;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tHASHBUCKET\tcurrBucket;\n\tHASHBUCKET *prevBucketPtr;\n\tHASHBUCKET *oldPrevPtr;\n\tHashCompareFunc match;\n\n#if HASH_STATISTICS\n\thash_accesses++;\n\thctl->accesses++;\n#endif\n\n\t/* disallow updates if frozen */\n\tif (hashp->frozen)\n\t\telog(ERROR, \"cannot update in frozen hashtable \\\"%s\\\"\",\n\t\t\t hashp->tabname);\n\n\t/*\n\t * Lookup the existing element using its saved hash value.  We need to do\n\t * this to be able to unlink it from its hash chain, but as a side benefit\n\t * we can verify the validity of the passed existingEntry pointer.\n\t */\n\tbucket = calc_bucket(hctl, existingElement->hashvalue);\n\n\tsegment_num = bucket >> hashp->sshift;\n\tsegment_ndx = MOD(bucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket == existingElement)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n\t}\n\n\tif (currBucket == NULL)\n\t\telog(ERROR, \"hash_update_hash_key argument is not in hashtable \\\"%s\\\"\",\n\t\t\t hashp->tabname);\n\n\toldPrevPtr = prevBucketPtr;\n\n\t/*\n\t * Now perform the equivalent of a HASH_ENTER operation to locate the hash\n\t * chain we want to put the entry into.\n\t */\n\tnewhashvalue = hashp->hash(newKeyPtr, hashp->keysize);\n\n\tnewbucket = calc_bucket(hctl, newhashvalue);\n\n\tsegment_num = newbucket >> hashp->sshift;\n\tsegment_ndx = MOD(newbucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\t/*\n\t * Follow collision chain looking for matching key\n\t */\n\tmatch = hashp->match;\t\t/* save one fetch in inner loop */\n\tkeysize = hashp->keysize;\t/* ditto */\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket->hashvalue == newhashvalue &&\n\t\t\tmatch(ELEMENTKEY(currBucket), newKeyPtr, keysize) == 0)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n#if HASH_STATISTICS\n\t\thash_collisions++;\n\t\thctl->collisions++;\n#endif\n\t}\n\n\tif (currBucket != NULL)\n\t\treturn false;\t\t\t/* collision with an existing entry */\n\n\tcurrBucket = existingElement;\n\n\t/*\n\t * If old and new hash values belong to the same bucket, we need not\n\t * change any chain links, and indeed should not since this simplistic\n\t * update will corrupt the list if currBucket is the last element.  (We\n\t * cannot fall out earlier, however, since we need to scan the bucket to\n\t * check for duplicate keys.)\n\t */\n\tif (bucket != newbucket)\n\t{\n\t\t/* OK to remove record from old hash bucket's chain. */\n\t\t*oldPrevPtr = currBucket->link;\n\n\t\t/* link into new hashbucket chain */\n\t\t*prevBucketPtr = currBucket;\n\t\tcurrBucket->link = NULL;\n\t}\n\n\t/* copy new key into record */\n\tcurrBucket->hashvalue = newhashvalue;\n\thashp->keycopy(ELEMENTKEY(currBucket), newKeyPtr, keysize);\n\n\t/* rest of record is untouched */\n\n\treturn true;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "hashp->keycopy",
          "args": [
            "ELEMENTKEY(currBucket)",
            "newKeyPtr",
            "keysize"
          ],
          "line": 1237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "match",
          "args": [
            "ELEMENTKEY(currBucket)",
            "newKeyPtr",
            "keysize"
          ],
          "line": 1203
        },
        "resolved": true,
        "details": {
          "function_name": "bitmap_match",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/hashfn.c",
          "lines": "85-91",
          "snippet": "int\nbitmap_match(const void *key1, const void *key2, Size keysize)\n{\n\tAssert(keysize == sizeof(Bitmapset *));\n\treturn !bms_equal(*((const Bitmapset *const *) key1),\n\t\t\t\t\t  *((const Bitmapset *const *) key2));\n}",
          "includes": [
            "#include \"utils/hsearch.h\"",
            "#include \"access/hash.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/hsearch.h\"\n#include \"access/hash.h\"\n#include \"postgres.h\"\n\nint\nbitmap_match(const void *key1, const void *key2, Size keysize)\n{\n\tAssert(keysize == sizeof(Bitmapset *));\n\treturn !bms_equal(*((const Bitmapset *const *) key1),\n\t\t\t\t\t  *((const Bitmapset *const *) key2));\n}"
        }
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hash_corrupted",
          "args": [
            "hashp"
          ],
          "line": 1189
        },
        "resolved": true,
        "details": {
          "function_name": "hash_corrupted",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1703-1714",
          "snippet": "static void\nhash_corrupted(HTAB *hashp)\n{\n\t/*\n\t * If the corruption is in a shared hashtable, we'd better force a\n\t * systemwide restart.  Otherwise, just shut down this one backend.\n\t */\n\tif (hashp->isshared)\n\t\telog(PANIC, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n\telse\n\t\telog(FATAL, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic void\nhash_corrupted(HTAB *hashp)\n{\n\t/*\n\t * If the corruption is in a shared hashtable, we'd better force a\n\t * systemwide restart.  Otherwise, just shut down this one backend.\n\t */\n\tif (hashp->isshared)\n\t\telog(PANIC, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n\telse\n\t\telog(FATAL, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n}"
        }
      },
      {
        "call_info": {
          "callee": "MOD",
          "args": [
            "newbucket",
            "hashp->ssize"
          ],
          "line": 1184
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "calc_bucket",
          "args": [
            "hctl",
            "newhashvalue"
          ],
          "line": 1181
        },
        "resolved": true,
        "details": {
          "function_name": "calc_bucket",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "866-876",
          "snippet": "static inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hashp->hash",
          "args": [
            "newKeyPtr",
            "hashp->keysize"
          ],
          "line": 1179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "ERROR",
            "\"hash_update_hash_key argument is not in hashtable \\\"%s\\\"\"",
            "hashp->tabname"
          ],
          "line": 1170
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      },
      {
        "call_info": {
          "callee": "MOD",
          "args": [
            "bucket",
            "hashp->ssize"
          ],
          "line": 1151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ELEMENT_FROM_KEY",
          "args": [
            "existingEntry"
          ],
          "line": 1119
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nbool\nhash_update_hash_key(HTAB *hashp,\n\t\t\t\t\t void *existingEntry,\n\t\t\t\t\t const void *newKeyPtr)\n{\n\tHASHELEMENT *existingElement = ELEMENT_FROM_KEY(existingEntry);\n\tHASHHDR    *hctl = hashp->hctl;\n\tuint32\t\tnewhashvalue;\n\tSize\t\tkeysize;\n\tuint32\t\tbucket;\n\tuint32\t\tnewbucket;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tHASHBUCKET\tcurrBucket;\n\tHASHBUCKET *prevBucketPtr;\n\tHASHBUCKET *oldPrevPtr;\n\tHashCompareFunc match;\n\n#if HASH_STATISTICS\n\thash_accesses++;\n\thctl->accesses++;\n#endif\n\n\t/* disallow updates if frozen */\n\tif (hashp->frozen)\n\t\telog(ERROR, \"cannot update in frozen hashtable \\\"%s\\\"\",\n\t\t\t hashp->tabname);\n\n\t/*\n\t * Lookup the existing element using its saved hash value.  We need to do\n\t * this to be able to unlink it from its hash chain, but as a side benefit\n\t * we can verify the validity of the passed existingEntry pointer.\n\t */\n\tbucket = calc_bucket(hctl, existingElement->hashvalue);\n\n\tsegment_num = bucket >> hashp->sshift;\n\tsegment_ndx = MOD(bucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket == existingElement)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n\t}\n\n\tif (currBucket == NULL)\n\t\telog(ERROR, \"hash_update_hash_key argument is not in hashtable \\\"%s\\\"\",\n\t\t\t hashp->tabname);\n\n\toldPrevPtr = prevBucketPtr;\n\n\t/*\n\t * Now perform the equivalent of a HASH_ENTER operation to locate the hash\n\t * chain we want to put the entry into.\n\t */\n\tnewhashvalue = hashp->hash(newKeyPtr, hashp->keysize);\n\n\tnewbucket = calc_bucket(hctl, newhashvalue);\n\n\tsegment_num = newbucket >> hashp->sshift;\n\tsegment_ndx = MOD(newbucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\t/*\n\t * Follow collision chain looking for matching key\n\t */\n\tmatch = hashp->match;\t\t/* save one fetch in inner loop */\n\tkeysize = hashp->keysize;\t/* ditto */\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket->hashvalue == newhashvalue &&\n\t\t\tmatch(ELEMENTKEY(currBucket), newKeyPtr, keysize) == 0)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n#if HASH_STATISTICS\n\t\thash_collisions++;\n\t\thctl->collisions++;\n#endif\n\t}\n\n\tif (currBucket != NULL)\n\t\treturn false;\t\t\t/* collision with an existing entry */\n\n\tcurrBucket = existingElement;\n\n\t/*\n\t * If old and new hash values belong to the same bucket, we need not\n\t * change any chain links, and indeed should not since this simplistic\n\t * update will corrupt the list if currBucket is the last element.  (We\n\t * cannot fall out earlier, however, since we need to scan the bucket to\n\t * check for duplicate keys.)\n\t */\n\tif (bucket != newbucket)\n\t{\n\t\t/* OK to remove record from old hash bucket's chain. */\n\t\t*oldPrevPtr = currBucket->link;\n\n\t\t/* link into new hashbucket chain */\n\t\t*prevBucketPtr = currBucket;\n\t\tcurrBucket->link = NULL;\n\t}\n\n\t/* copy new key into record */\n\tcurrBucket->hashvalue = newhashvalue;\n\thashp->keycopy(ELEMENTKEY(currBucket), newKeyPtr, keysize);\n\n\t/* rest of record is untouched */\n\n\treturn true;\n}"
  },
  {
    "function_name": "hash_search_with_hash_value",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "918-1093",
    "snippet": "void *\nhash_search_with_hash_value(HTAB *hashp,\n\t\t\t\t\t\t\tconst void *keyPtr,\n\t\t\t\t\t\t\tuint32 hashvalue,\n\t\t\t\t\t\t\tHASHACTION action,\n\t\t\t\t\t\t\tbool *foundPtr)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tint\t\t\tfreelist_idx = FREELIST_IDX(hctl, hashvalue);\n\tSize\t\tkeysize;\n\tuint32\t\tbucket;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tHASHBUCKET\tcurrBucket;\n\tHASHBUCKET *prevBucketPtr;\n\tHashCompareFunc match;\n\n#if HASH_STATISTICS\n\thash_accesses++;\n\thctl->accesses++;\n#endif\n\n\t/*\n\t * If inserting, check if it is time to split a bucket.\n\t *\n\t * NOTE: failure to expand table is not a fatal error, it just means we\n\t * have to run at higher fill factor than we wanted.  However, if we're\n\t * using the palloc allocator then it will throw error anyway on\n\t * out-of-memory, so we must do this before modifying the table.\n\t */\n\tif (action == HASH_ENTER || action == HASH_ENTER_NULL)\n\t{\n\t\t/*\n\t\t * Can't split if running in partitioned mode, nor if frozen, nor if\n\t\t * table is the subject of any active hash_seq_search scans.  Strange\n\t\t * order of these tests is to try to check cheaper conditions first.\n\t\t */\n\t\tif (!IS_PARTITIONED(hctl) && !hashp->frozen &&\n\t\t\thctl->freeList[0].nentries / (long) (hctl->max_bucket + 1) >= hctl->ffactor &&\n\t\t\t!has_seq_scans(hashp))\n\t\t\t(void) expand_table(hashp);\n\t}\n\n\t/*\n\t * Do the initial lookup\n\t */\n\tbucket = calc_bucket(hctl, hashvalue);\n\n\tsegment_num = bucket >> hashp->sshift;\n\tsegment_ndx = MOD(bucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\t/*\n\t * Follow collision chain looking for matching key\n\t */\n\tmatch = hashp->match;\t\t/* save one fetch in inner loop */\n\tkeysize = hashp->keysize;\t/* ditto */\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket->hashvalue == hashvalue &&\n\t\t\tmatch(ELEMENTKEY(currBucket), keyPtr, keysize) == 0)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n#if HASH_STATISTICS\n\t\thash_collisions++;\n\t\thctl->collisions++;\n#endif\n\t}\n\n\tif (foundPtr)\n\t\t*foundPtr = (bool) (currBucket != NULL);\n\n\t/*\n\t * OK, now what?\n\t */\n\tswitch (action)\n\t{\n\t\tcase HASH_FIND:\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\treturn NULL;\n\n\t\tcase HASH_REMOVE:\n\t\t\tif (currBucket != NULL)\n\t\t\t{\n\t\t\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockAcquire(&(hctl->freeList[freelist_idx].mutex));\n\n\t\t\t\t/* delete the record from the appropriate nentries counter. */\n\t\t\t\tAssert(hctl->freeList[freelist_idx].nentries > 0);\n\t\t\t\thctl->freeList[freelist_idx].nentries--;\n\n\t\t\t\t/* remove record from hash bucket's chain. */\n\t\t\t\t*prevBucketPtr = currBucket->link;\n\n\t\t\t\t/* add the record to the appropriate freelist. */\n\t\t\t\tcurrBucket->link = hctl->freeList[freelist_idx].freeList;\n\t\t\t\thctl->freeList[freelist_idx].freeList = currBucket;\n\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t/*\n\t\t\t\t * better hope the caller is synchronizing access to this\n\t\t\t\t * element, because someone else is going to reuse it the next\n\t\t\t\t * time something is added to the table\n\t\t\t\t */\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\t}\n\t\t\treturn NULL;\n\n\t\tcase HASH_ENTER_NULL:\n\t\t\t/* ENTER_NULL does not work with palloc-based allocator */\n\t\t\tAssert(hashp->alloc != DynaHashAlloc);\n\t\t\t/* FALL THRU */\n\n\t\tcase HASH_ENTER:\n\t\t\t/* Return existing element if found, else create one */\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\n\t\t\t/* disallow inserts if frozen */\n\t\t\tif (hashp->frozen)\n\t\t\t\telog(ERROR, \"cannot insert into frozen hashtable \\\"%s\\\"\",\n\t\t\t\t\t hashp->tabname);\n\n\t\t\tcurrBucket = get_hash_entry(hashp, freelist_idx);\n\t\t\tif (currBucket == NULL)\n\t\t\t{\n\t\t\t\t/* out of memory */\n\t\t\t\tif (action == HASH_ENTER_NULL)\n\t\t\t\t\treturn NULL;\n\t\t\t\t/* report a generic message */\n\t\t\t\tif (hashp->isshared)\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of shared memory\")));\n\t\t\t\telse\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t\t}\n\n\t\t\t/* link into hashbucket chain */\n\t\t\t*prevBucketPtr = currBucket;\n\t\t\tcurrBucket->link = NULL;\n\n\t\t\t/* copy key into record */\n\t\t\tcurrBucket->hashvalue = hashvalue;\n\t\t\thashp->keycopy(ELEMENTKEY(currBucket), keyPtr, keysize);\n\n\t\t\t/*\n\t\t\t * Caller is expected to fill the data field on return.  DO NOT\n\t\t\t * insert any code that could possibly throw error here, as doing\n\t\t\t * so would leave the table entry incomplete and hence corrupt the\n\t\t\t * caller's data structure.\n\t\t\t */\n\n\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t}\n\n\telog(ERROR, \"unrecognized hash action code: %d\", (int) action);\n\n\treturn NULL;\t\t\t\t/* keep compiler quiet */\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "ERROR",
            "\"unrecognized hash action code: %d\"",
            "(int) action"
          ],
          "line": 1090
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1087
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hashp->keycopy",
          "args": [
            "ELEMENTKEY(currBucket)",
            "keyPtr",
            "keysize"
          ],
          "line": 1078
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1078
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ereport",
          "args": [
            "ERROR",
            "(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of memory\"))"
          ],
          "line": 1067
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "errmsg",
          "args": [
            "\"out of memory\""
          ],
          "line": 1069
        },
        "resolved": true,
        "details": {
          "function_name": "errmsg_internal",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "824-840",
          "snippet": "int\nerrmsg_internal(const char *fmt,...)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\tMemoryContext oldcontext;\n\n\trecursion_depth++;\n\tCHECK_STACK_DEPTH();\n\toldcontext = MemoryContextSwitchTo(edata->assoc_context);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, false);\n\n\tMemoryContextSwitchTo(oldcontext);\n\trecursion_depth--;\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static ErrorData errordata[ERRORDATA_STACK_SIZE];",
            "static int\terrordata_stack_depth = -1;",
            "static int\trecursion_depth = 0;",
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic ErrorData errordata[ERRORDATA_STACK_SIZE];\nstatic int\terrordata_stack_depth = -1;\nstatic int\trecursion_depth = 0;\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\n\nint\nerrmsg_internal(const char *fmt,...)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\tMemoryContext oldcontext;\n\n\trecursion_depth++;\n\tCHECK_STACK_DEPTH();\n\toldcontext = MemoryContextSwitchTo(edata->assoc_context);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, false);\n\n\tMemoryContextSwitchTo(oldcontext);\n\trecursion_depth--;\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}"
        }
      },
      {
        "call_info": {
          "callee": "errcode",
          "args": [
            "ERRCODE_OUT_OF_MEMORY"
          ],
          "line": 1068
        },
        "resolved": true,
        "details": {
          "function_name": "errcode",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "572-583",
          "snippet": "int\nerrcode(int sqlerrcode)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\n\t/* we don't bother incrementing recursion_depth */\n\tCHECK_STACK_DEPTH();\n\n\tedata->sqlerrcode = sqlerrcode;\n\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static ErrorData errordata[ERRORDATA_STACK_SIZE];",
            "static int\terrordata_stack_depth = -1;",
            "static int\trecursion_depth = 0;",
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic ErrorData errordata[ERRORDATA_STACK_SIZE];\nstatic int\terrordata_stack_depth = -1;\nstatic int\trecursion_depth = 0;\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\n\nint\nerrcode(int sqlerrcode)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\n\t/* we don't bother incrementing recursion_depth */\n\tCHECK_STACK_DEPTH();\n\n\tedata->sqlerrcode = sqlerrcode;\n\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}"
        }
      },
      {
        "call_info": {
          "callee": "ereport",
          "args": [
            "ERROR",
            "(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of shared memory\"))"
          ],
          "line": 1063
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_hash_entry",
          "args": [
            "hashp",
            "freelist_idx"
          ],
          "line": 1055
        },
        "resolved": true,
        "details": {
          "function_name": "get_hash_entry",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1249-1329",
          "snippet": "static HASHBUCKET\nget_hash_entry(HTAB *hashp, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHBUCKET\tnewElement;\n\n\tfor (;;)\n\t{\n\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/* try to get an entry from the freelist */\n\t\tnewElement = hctl->freeList[freelist_idx].freeList;\n\n\t\tif (newElement != NULL)\n\t\t\tbreak;\n\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/*\n\t\t * No free elements in this freelist.  In a partitioned table, there\n\t\t * might be entries in other freelists, but to reduce contention we\n\t\t * prefer to first try to get another chunk of buckets from the main\n\t\t * shmem allocator.  If that fails, though, we *MUST* root through all\n\t\t * the other freelists before giving up.  There are multiple callers\n\t\t * that assume that they can allocate every element in the initially\n\t\t * requested table size, or that deleting an element guarantees they\n\t\t * can insert a new element, even if shared memory is entirely full.\n\t\t * Failing because the needed element is in a different freelist is\n\t\t * not acceptable.\n\t\t */\n\t\tif (!element_alloc(hashp, hctl->nelem_alloc, freelist_idx))\n\t\t{\n\t\t\tint\t\t\tborrow_from_idx;\n\n\t\t\tif (!IS_PARTITIONED(hctl))\n\t\t\t\treturn NULL;\t/* out of memory */\n\n\t\t\t/* try to borrow element from another freelist */\n\t\t\tborrow_from_idx = freelist_idx;\n\t\t\tfor (;;)\n\t\t\t{\n\t\t\t\tborrow_from_idx = (borrow_from_idx + 1) % NUM_FREELISTS;\n\t\t\t\tif (borrow_from_idx == freelist_idx)\n\t\t\t\t\tbreak;\t\t/* examined all freelists, fail */\n\n\t\t\t\tSpinLockAcquire(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t\tnewElement = hctl->freeList[borrow_from_idx].freeList;\n\n\t\t\t\tif (newElement != NULL)\n\t\t\t\t{\n\t\t\t\t\thctl->freeList[borrow_from_idx].freeList = newElement->link;\n\t\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\n\t\t\t\t\t/* careful: count the new element in its proper freelist */\n\t\t\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\t\t\t\t\thctl->freeList[freelist_idx].nentries++;\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t\treturn newElement;\n\t\t\t\t}\n\n\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t}\n\n\t\t\t/* no elements available to borrow either, so out of memory */\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* remove entry from freelist, bump nentries */\n\thctl->freeList[freelist_idx].freeList = newElement->link;\n\thctl->freeList[freelist_idx].nentries++;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn newElement;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [
            "#define NUM_FREELISTS\t\t\t32"
          ],
          "globals_used": [
            "static void *DynaHashAlloc(Size size);",
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic void *DynaHashAlloc(Size size);\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic HASHBUCKET\nget_hash_entry(HTAB *hashp, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHBUCKET\tnewElement;\n\n\tfor (;;)\n\t{\n\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/* try to get an entry from the freelist */\n\t\tnewElement = hctl->freeList[freelist_idx].freeList;\n\n\t\tif (newElement != NULL)\n\t\t\tbreak;\n\n\t\tif (IS_PARTITIONED(hctl))\n\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t/*\n\t\t * No free elements in this freelist.  In a partitioned table, there\n\t\t * might be entries in other freelists, but to reduce contention we\n\t\t * prefer to first try to get another chunk of buckets from the main\n\t\t * shmem allocator.  If that fails, though, we *MUST* root through all\n\t\t * the other freelists before giving up.  There are multiple callers\n\t\t * that assume that they can allocate every element in the initially\n\t\t * requested table size, or that deleting an element guarantees they\n\t\t * can insert a new element, even if shared memory is entirely full.\n\t\t * Failing because the needed element is in a different freelist is\n\t\t * not acceptable.\n\t\t */\n\t\tif (!element_alloc(hashp, hctl->nelem_alloc, freelist_idx))\n\t\t{\n\t\t\tint\t\t\tborrow_from_idx;\n\n\t\t\tif (!IS_PARTITIONED(hctl))\n\t\t\t\treturn NULL;\t/* out of memory */\n\n\t\t\t/* try to borrow element from another freelist */\n\t\t\tborrow_from_idx = freelist_idx;\n\t\t\tfor (;;)\n\t\t\t{\n\t\t\t\tborrow_from_idx = (borrow_from_idx + 1) % NUM_FREELISTS;\n\t\t\t\tif (borrow_from_idx == freelist_idx)\n\t\t\t\t\tbreak;\t\t/* examined all freelists, fail */\n\n\t\t\t\tSpinLockAcquire(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t\tnewElement = hctl->freeList[borrow_from_idx].freeList;\n\n\t\t\t\tif (newElement != NULL)\n\t\t\t\t{\n\t\t\t\t\thctl->freeList[borrow_from_idx].freeList = newElement->link;\n\t\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\n\t\t\t\t\t/* careful: count the new element in its proper freelist */\n\t\t\t\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\t\t\t\t\thctl->freeList[freelist_idx].nentries++;\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t\treturn newElement;\n\t\t\t\t}\n\n\t\t\t\tSpinLockRelease(&(hctl->freeList[borrow_from_idx].mutex));\n\t\t\t}\n\n\t\t\t/* no elements available to borrow either, so out of memory */\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* remove entry from freelist, bump nentries */\n\thctl->freeList[freelist_idx].freeList = newElement->link;\n\thctl->freeList[freelist_idx].nentries++;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn newElement;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1048
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "hashp->alloc != DynaHashAlloc"
          ],
          "line": 1042
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1036
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockRelease",
          "args": [
            "&hctl->freeList[freelist_idx].mutex"
          ],
          "line": 1029
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1028
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "hctl->freeList[freelist_idx].nentries > 0"
          ],
          "line": 1018
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SpinLockAcquire",
          "args": [
            "&(hctl->freeList[freelist_idx].mutex)"
          ],
          "line": 1015
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 1014
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 1007
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "match",
          "args": [
            "ELEMENTKEY(currBucket)",
            "keyPtr",
            "keysize"
          ],
          "line": 987
        },
        "resolved": true,
        "details": {
          "function_name": "bitmap_match",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/hashfn.c",
          "lines": "85-91",
          "snippet": "int\nbitmap_match(const void *key1, const void *key2, Size keysize)\n{\n\tAssert(keysize == sizeof(Bitmapset *));\n\treturn !bms_equal(*((const Bitmapset *const *) key1),\n\t\t\t\t\t  *((const Bitmapset *const *) key2));\n}",
          "includes": [
            "#include \"utils/hsearch.h\"",
            "#include \"access/hash.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/hsearch.h\"\n#include \"access/hash.h\"\n#include \"postgres.h\"\n\nint\nbitmap_match(const void *key1, const void *key2, Size keysize)\n{\n\tAssert(keysize == sizeof(Bitmapset *));\n\treturn !bms_equal(*((const Bitmapset *const *) key1),\n\t\t\t\t\t  *((const Bitmapset *const *) key2));\n}"
        }
      },
      {
        "call_info": {
          "callee": "ELEMENTKEY",
          "args": [
            "currBucket"
          ],
          "line": 987
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hash_corrupted",
          "args": [
            "hashp"
          ],
          "line": 973
        },
        "resolved": true,
        "details": {
          "function_name": "hash_corrupted",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1703-1714",
          "snippet": "static void\nhash_corrupted(HTAB *hashp)\n{\n\t/*\n\t * If the corruption is in a shared hashtable, we'd better force a\n\t * systemwide restart.  Otherwise, just shut down this one backend.\n\t */\n\tif (hashp->isshared)\n\t\telog(PANIC, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n\telse\n\t\telog(FATAL, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic void\nhash_corrupted(HTAB *hashp)\n{\n\t/*\n\t * If the corruption is in a shared hashtable, we'd better force a\n\t * systemwide restart.  Otherwise, just shut down this one backend.\n\t */\n\tif (hashp->isshared)\n\t\telog(PANIC, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n\telse\n\t\telog(FATAL, \"hash table \\\"%s\\\" corrupted\", hashp->tabname);\n}"
        }
      },
      {
        "call_info": {
          "callee": "MOD",
          "args": [
            "bucket",
            "hashp->ssize"
          ],
          "line": 968
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "calc_bucket",
          "args": [
            "hctl",
            "hashvalue"
          ],
          "line": 965
        },
        "resolved": true,
        "details": {
          "function_name": "calc_bucket",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "866-876",
          "snippet": "static inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}"
        }
      },
      {
        "call_info": {
          "callee": "expand_table",
          "args": [
            "hashp"
          ],
          "line": 959
        },
        "resolved": true,
        "details": {
          "function_name": "expand_table",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1501-1595",
          "snippet": "static bool\nexpand_table(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT old_seg,\n\t\t\t\tnew_seg;\n\tlong\t\told_bucket,\n\t\t\t\tnew_bucket;\n\tlong\t\tnew_segnum,\n\t\t\t\tnew_segndx;\n\tlong\t\told_segnum,\n\t\t\t\told_segndx;\n\tHASHBUCKET *oldlink,\n\t\t\t   *newlink;\n\tHASHBUCKET\tcurrElement,\n\t\t\t\tnextElement;\n\n\tAssert(!IS_PARTITIONED(hctl));\n\n#ifdef HASH_STATISTICS\n\thash_expansions++;\n#endif\n\n\tnew_bucket = hctl->max_bucket + 1;\n\tnew_segnum = new_bucket >> hashp->sshift;\n\tnew_segndx = MOD(new_bucket, hashp->ssize);\n\n\tif (new_segnum >= hctl->nsegs)\n\t{\n\t\t/* Allocate new segment if necessary -- could fail if dir full */\n\t\tif (new_segnum >= hctl->dsize)\n\t\t\tif (!dir_realloc(hashp))\n\t\t\t\treturn false;\n\t\tif (!(hashp->dir[new_segnum] = seg_alloc(hashp)))\n\t\t\treturn false;\n\t\thctl->nsegs++;\n\t}\n\n\t/* OK, we created a new bucket */\n\thctl->max_bucket++;\n\n\t/*\n\t * *Before* changing masks, find old bucket corresponding to same hash\n\t * values; values in that bucket may need to be relocated to new bucket.\n\t * Note that new_bucket is certainly larger than low_mask at this point,\n\t * so we can skip the first step of the regular hash mask calc.\n\t */\n\told_bucket = (new_bucket & hctl->low_mask);\n\n\t/*\n\t * If we crossed a power of 2, readjust masks.\n\t */\n\tif ((uint32) new_bucket > hctl->high_mask)\n\t{\n\t\thctl->low_mask = hctl->high_mask;\n\t\thctl->high_mask = (uint32) new_bucket | hctl->low_mask;\n\t}\n\n\t/*\n\t * Relocate records to the new bucket.  NOTE: because of the way the hash\n\t * masking is done in calc_bucket, only one old bucket can need to be\n\t * split at this point.  With a different way of reducing the hash value,\n\t * that might not be true!\n\t */\n\told_segnum = old_bucket >> hashp->sshift;\n\told_segndx = MOD(old_bucket, hashp->ssize);\n\n\told_seg = hashp->dir[old_segnum];\n\tnew_seg = hashp->dir[new_segnum];\n\n\toldlink = &old_seg[old_segndx];\n\tnewlink = &new_seg[new_segndx];\n\n\tfor (currElement = *oldlink;\n\t\t currElement != NULL;\n\t\t currElement = nextElement)\n\t{\n\t\tnextElement = currElement->link;\n\t\tif ((long) calc_bucket(hctl, currElement->hashvalue) == old_bucket)\n\t\t{\n\t\t\t*oldlink = currElement;\n\t\t\toldlink = &currElement->link;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t*newlink = currElement;\n\t\t\tnewlink = &currElement->link;\n\t\t}\n\t}\n\t/* don't forget to terminate the rebuilt hash chains... */\n\t*oldlink = NULL;\n\t*newlink = NULL;\n\n\treturn true;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic bool\nexpand_table(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT old_seg,\n\t\t\t\tnew_seg;\n\tlong\t\told_bucket,\n\t\t\t\tnew_bucket;\n\tlong\t\tnew_segnum,\n\t\t\t\tnew_segndx;\n\tlong\t\told_segnum,\n\t\t\t\told_segndx;\n\tHASHBUCKET *oldlink,\n\t\t\t   *newlink;\n\tHASHBUCKET\tcurrElement,\n\t\t\t\tnextElement;\n\n\tAssert(!IS_PARTITIONED(hctl));\n\n#ifdef HASH_STATISTICS\n\thash_expansions++;\n#endif\n\n\tnew_bucket = hctl->max_bucket + 1;\n\tnew_segnum = new_bucket >> hashp->sshift;\n\tnew_segndx = MOD(new_bucket, hashp->ssize);\n\n\tif (new_segnum >= hctl->nsegs)\n\t{\n\t\t/* Allocate new segment if necessary -- could fail if dir full */\n\t\tif (new_segnum >= hctl->dsize)\n\t\t\tif (!dir_realloc(hashp))\n\t\t\t\treturn false;\n\t\tif (!(hashp->dir[new_segnum] = seg_alloc(hashp)))\n\t\t\treturn false;\n\t\thctl->nsegs++;\n\t}\n\n\t/* OK, we created a new bucket */\n\thctl->max_bucket++;\n\n\t/*\n\t * *Before* changing masks, find old bucket corresponding to same hash\n\t * values; values in that bucket may need to be relocated to new bucket.\n\t * Note that new_bucket is certainly larger than low_mask at this point,\n\t * so we can skip the first step of the regular hash mask calc.\n\t */\n\told_bucket = (new_bucket & hctl->low_mask);\n\n\t/*\n\t * If we crossed a power of 2, readjust masks.\n\t */\n\tif ((uint32) new_bucket > hctl->high_mask)\n\t{\n\t\thctl->low_mask = hctl->high_mask;\n\t\thctl->high_mask = (uint32) new_bucket | hctl->low_mask;\n\t}\n\n\t/*\n\t * Relocate records to the new bucket.  NOTE: because of the way the hash\n\t * masking is done in calc_bucket, only one old bucket can need to be\n\t * split at this point.  With a different way of reducing the hash value,\n\t * that might not be true!\n\t */\n\told_segnum = old_bucket >> hashp->sshift;\n\told_segndx = MOD(old_bucket, hashp->ssize);\n\n\told_seg = hashp->dir[old_segnum];\n\tnew_seg = hashp->dir[new_segnum];\n\n\toldlink = &old_seg[old_segndx];\n\tnewlink = &new_seg[new_segndx];\n\n\tfor (currElement = *oldlink;\n\t\t currElement != NULL;\n\t\t currElement = nextElement)\n\t{\n\t\tnextElement = currElement->link;\n\t\tif ((long) calc_bucket(hctl, currElement->hashvalue) == old_bucket)\n\t\t{\n\t\t\t*oldlink = currElement;\n\t\t\toldlink = &currElement->link;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t*newlink = currElement;\n\t\t\tnewlink = &currElement->link;\n\t\t}\n\t}\n\t/* don't forget to terminate the rebuilt hash chains... */\n\t*oldlink = NULL;\n\t*newlink = NULL;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "has_seq_scans",
          "args": [
            "hashp"
          ],
          "line": 958
        },
        "resolved": true,
        "details": {
          "function_name": "has_seq_scans",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1819-1830",
          "snippet": "static bool\nhas_seq_scans(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\tfor (i = 0; i < num_seq_scans; i++)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t\treturn true;\n\t}\n\treturn false;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static HTAB *seq_scan_tables[MAX_SEQ_SCANS];",
            "static int\tnum_seq_scans = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic HTAB *seq_scan_tables[MAX_SEQ_SCANS];\nstatic int\tnum_seq_scans = 0;\n\nstatic bool\nhas_seq_scans(HTAB *hashp)\n{\n\tint\t\t\ti;\n\n\tfor (i = 0; i < num_seq_scans; i++)\n\t{\n\t\tif (seq_scan_tables[i] == hashp)\n\t\t\treturn true;\n\t}\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 956
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FREELIST_IDX",
          "args": [
            "hctl",
            "hashvalue"
          ],
          "line": 926
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid *\nhash_search_with_hash_value(HTAB *hashp,\n\t\t\t\t\t\t\tconst void *keyPtr,\n\t\t\t\t\t\t\tuint32 hashvalue,\n\t\t\t\t\t\t\tHASHACTION action,\n\t\t\t\t\t\t\tbool *foundPtr)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tint\t\t\tfreelist_idx = FREELIST_IDX(hctl, hashvalue);\n\tSize\t\tkeysize;\n\tuint32\t\tbucket;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tHASHBUCKET\tcurrBucket;\n\tHASHBUCKET *prevBucketPtr;\n\tHashCompareFunc match;\n\n#if HASH_STATISTICS\n\thash_accesses++;\n\thctl->accesses++;\n#endif\n\n\t/*\n\t * If inserting, check if it is time to split a bucket.\n\t *\n\t * NOTE: failure to expand table is not a fatal error, it just means we\n\t * have to run at higher fill factor than we wanted.  However, if we're\n\t * using the palloc allocator then it will throw error anyway on\n\t * out-of-memory, so we must do this before modifying the table.\n\t */\n\tif (action == HASH_ENTER || action == HASH_ENTER_NULL)\n\t{\n\t\t/*\n\t\t * Can't split if running in partitioned mode, nor if frozen, nor if\n\t\t * table is the subject of any active hash_seq_search scans.  Strange\n\t\t * order of these tests is to try to check cheaper conditions first.\n\t\t */\n\t\tif (!IS_PARTITIONED(hctl) && !hashp->frozen &&\n\t\t\thctl->freeList[0].nentries / (long) (hctl->max_bucket + 1) >= hctl->ffactor &&\n\t\t\t!has_seq_scans(hashp))\n\t\t\t(void) expand_table(hashp);\n\t}\n\n\t/*\n\t * Do the initial lookup\n\t */\n\tbucket = calc_bucket(hctl, hashvalue);\n\n\tsegment_num = bucket >> hashp->sshift;\n\tsegment_ndx = MOD(bucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\t/*\n\t * Follow collision chain looking for matching key\n\t */\n\tmatch = hashp->match;\t\t/* save one fetch in inner loop */\n\tkeysize = hashp->keysize;\t/* ditto */\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket->hashvalue == hashvalue &&\n\t\t\tmatch(ELEMENTKEY(currBucket), keyPtr, keysize) == 0)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n#if HASH_STATISTICS\n\t\thash_collisions++;\n\t\thctl->collisions++;\n#endif\n\t}\n\n\tif (foundPtr)\n\t\t*foundPtr = (bool) (currBucket != NULL);\n\n\t/*\n\t * OK, now what?\n\t */\n\tswitch (action)\n\t{\n\t\tcase HASH_FIND:\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\treturn NULL;\n\n\t\tcase HASH_REMOVE:\n\t\t\tif (currBucket != NULL)\n\t\t\t{\n\t\t\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockAcquire(&(hctl->freeList[freelist_idx].mutex));\n\n\t\t\t\t/* delete the record from the appropriate nentries counter. */\n\t\t\t\tAssert(hctl->freeList[freelist_idx].nentries > 0);\n\t\t\t\thctl->freeList[freelist_idx].nentries--;\n\n\t\t\t\t/* remove record from hash bucket's chain. */\n\t\t\t\t*prevBucketPtr = currBucket->link;\n\n\t\t\t\t/* add the record to the appropriate freelist. */\n\t\t\t\tcurrBucket->link = hctl->freeList[freelist_idx].freeList;\n\t\t\t\thctl->freeList[freelist_idx].freeList = currBucket;\n\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t/*\n\t\t\t\t * better hope the caller is synchronizing access to this\n\t\t\t\t * element, because someone else is going to reuse it the next\n\t\t\t\t * time something is added to the table\n\t\t\t\t */\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\t}\n\t\t\treturn NULL;\n\n\t\tcase HASH_ENTER_NULL:\n\t\t\t/* ENTER_NULL does not work with palloc-based allocator */\n\t\t\tAssert(hashp->alloc != DynaHashAlloc);\n\t\t\t/* FALL THRU */\n\n\t\tcase HASH_ENTER:\n\t\t\t/* Return existing element if found, else create one */\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\n\t\t\t/* disallow inserts if frozen */\n\t\t\tif (hashp->frozen)\n\t\t\t\telog(ERROR, \"cannot insert into frozen hashtable \\\"%s\\\"\",\n\t\t\t\t\t hashp->tabname);\n\n\t\t\tcurrBucket = get_hash_entry(hashp, freelist_idx);\n\t\t\tif (currBucket == NULL)\n\t\t\t{\n\t\t\t\t/* out of memory */\n\t\t\t\tif (action == HASH_ENTER_NULL)\n\t\t\t\t\treturn NULL;\n\t\t\t\t/* report a generic message */\n\t\t\t\tif (hashp->isshared)\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of shared memory\")));\n\t\t\t\telse\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t\t}\n\n\t\t\t/* link into hashbucket chain */\n\t\t\t*prevBucketPtr = currBucket;\n\t\t\tcurrBucket->link = NULL;\n\n\t\t\t/* copy key into record */\n\t\t\tcurrBucket->hashvalue = hashvalue;\n\t\t\thashp->keycopy(ELEMENTKEY(currBucket), keyPtr, keysize);\n\n\t\t\t/*\n\t\t\t * Caller is expected to fill the data field on return.  DO NOT\n\t\t\t * insert any code that could possibly throw error here, as doing\n\t\t\t * so would leave the table entry incomplete and hence corrupt the\n\t\t\t * caller's data structure.\n\t\t\t */\n\n\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t}\n\n\telog(ERROR, \"unrecognized hash action code: %d\", (int) action);\n\n\treturn NULL;\t\t\t\t/* keep compiler quiet */\n}"
  },
  {
    "function_name": "hash_search",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "905-916",
    "snippet": "void *\nhash_search(HTAB *hashp,\n\t\t\tconst void *keyPtr,\n\t\t\tHASHACTION action,\n\t\t\tbool *foundPtr)\n{\n\treturn hash_search_with_hash_value(hashp,\n\t\t\t\t\t\t\t\t\t   keyPtr,\n\t\t\t\t\t\t\t\t\t   hashp->hash(keyPtr, hashp->keysize),\n\t\t\t\t\t\t\t\t\t   action,\n\t\t\t\t\t\t\t\t\t   foundPtr);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "hash_search_with_hash_value",
          "args": [
            "hashp",
            "keyPtr",
            "hashp->hash(keyPtr, hashp->keysize)",
            "action",
            "foundPtr"
          ],
          "line": 911
        },
        "resolved": true,
        "details": {
          "function_name": "hash_search_with_hash_value",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "918-1093",
          "snippet": "void *\nhash_search_with_hash_value(HTAB *hashp,\n\t\t\t\t\t\t\tconst void *keyPtr,\n\t\t\t\t\t\t\tuint32 hashvalue,\n\t\t\t\t\t\t\tHASHACTION action,\n\t\t\t\t\t\t\tbool *foundPtr)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tint\t\t\tfreelist_idx = FREELIST_IDX(hctl, hashvalue);\n\tSize\t\tkeysize;\n\tuint32\t\tbucket;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tHASHBUCKET\tcurrBucket;\n\tHASHBUCKET *prevBucketPtr;\n\tHashCompareFunc match;\n\n#if HASH_STATISTICS\n\thash_accesses++;\n\thctl->accesses++;\n#endif\n\n\t/*\n\t * If inserting, check if it is time to split a bucket.\n\t *\n\t * NOTE: failure to expand table is not a fatal error, it just means we\n\t * have to run at higher fill factor than we wanted.  However, if we're\n\t * using the palloc allocator then it will throw error anyway on\n\t * out-of-memory, so we must do this before modifying the table.\n\t */\n\tif (action == HASH_ENTER || action == HASH_ENTER_NULL)\n\t{\n\t\t/*\n\t\t * Can't split if running in partitioned mode, nor if frozen, nor if\n\t\t * table is the subject of any active hash_seq_search scans.  Strange\n\t\t * order of these tests is to try to check cheaper conditions first.\n\t\t */\n\t\tif (!IS_PARTITIONED(hctl) && !hashp->frozen &&\n\t\t\thctl->freeList[0].nentries / (long) (hctl->max_bucket + 1) >= hctl->ffactor &&\n\t\t\t!has_seq_scans(hashp))\n\t\t\t(void) expand_table(hashp);\n\t}\n\n\t/*\n\t * Do the initial lookup\n\t */\n\tbucket = calc_bucket(hctl, hashvalue);\n\n\tsegment_num = bucket >> hashp->sshift;\n\tsegment_ndx = MOD(bucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\t/*\n\t * Follow collision chain looking for matching key\n\t */\n\tmatch = hashp->match;\t\t/* save one fetch in inner loop */\n\tkeysize = hashp->keysize;\t/* ditto */\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket->hashvalue == hashvalue &&\n\t\t\tmatch(ELEMENTKEY(currBucket), keyPtr, keysize) == 0)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n#if HASH_STATISTICS\n\t\thash_collisions++;\n\t\thctl->collisions++;\n#endif\n\t}\n\n\tif (foundPtr)\n\t\t*foundPtr = (bool) (currBucket != NULL);\n\n\t/*\n\t * OK, now what?\n\t */\n\tswitch (action)\n\t{\n\t\tcase HASH_FIND:\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\treturn NULL;\n\n\t\tcase HASH_REMOVE:\n\t\t\tif (currBucket != NULL)\n\t\t\t{\n\t\t\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockAcquire(&(hctl->freeList[freelist_idx].mutex));\n\n\t\t\t\t/* delete the record from the appropriate nentries counter. */\n\t\t\t\tAssert(hctl->freeList[freelist_idx].nentries > 0);\n\t\t\t\thctl->freeList[freelist_idx].nentries--;\n\n\t\t\t\t/* remove record from hash bucket's chain. */\n\t\t\t\t*prevBucketPtr = currBucket->link;\n\n\t\t\t\t/* add the record to the appropriate freelist. */\n\t\t\t\tcurrBucket->link = hctl->freeList[freelist_idx].freeList;\n\t\t\t\thctl->freeList[freelist_idx].freeList = currBucket;\n\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t/*\n\t\t\t\t * better hope the caller is synchronizing access to this\n\t\t\t\t * element, because someone else is going to reuse it the next\n\t\t\t\t * time something is added to the table\n\t\t\t\t */\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\t}\n\t\t\treturn NULL;\n\n\t\tcase HASH_ENTER_NULL:\n\t\t\t/* ENTER_NULL does not work with palloc-based allocator */\n\t\t\tAssert(hashp->alloc != DynaHashAlloc);\n\t\t\t/* FALL THRU */\n\n\t\tcase HASH_ENTER:\n\t\t\t/* Return existing element if found, else create one */\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\n\t\t\t/* disallow inserts if frozen */\n\t\t\tif (hashp->frozen)\n\t\t\t\telog(ERROR, \"cannot insert into frozen hashtable \\\"%s\\\"\",\n\t\t\t\t\t hashp->tabname);\n\n\t\t\tcurrBucket = get_hash_entry(hashp, freelist_idx);\n\t\t\tif (currBucket == NULL)\n\t\t\t{\n\t\t\t\t/* out of memory */\n\t\t\t\tif (action == HASH_ENTER_NULL)\n\t\t\t\t\treturn NULL;\n\t\t\t\t/* report a generic message */\n\t\t\t\tif (hashp->isshared)\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of shared memory\")));\n\t\t\t\telse\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t\t}\n\n\t\t\t/* link into hashbucket chain */\n\t\t\t*prevBucketPtr = currBucket;\n\t\t\tcurrBucket->link = NULL;\n\n\t\t\t/* copy key into record */\n\t\t\tcurrBucket->hashvalue = hashvalue;\n\t\t\thashp->keycopy(ELEMENTKEY(currBucket), keyPtr, keysize);\n\n\t\t\t/*\n\t\t\t * Caller is expected to fill the data field on return.  DO NOT\n\t\t\t * insert any code that could possibly throw error here, as doing\n\t\t\t * so would leave the table entry incomplete and hence corrupt the\n\t\t\t * caller's data structure.\n\t\t\t */\n\n\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t}\n\n\telog(ERROR, \"unrecognized hash action code: %d\", (int) action);\n\n\treturn NULL;\t\t\t\t/* keep compiler quiet */\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid *\nhash_search_with_hash_value(HTAB *hashp,\n\t\t\t\t\t\t\tconst void *keyPtr,\n\t\t\t\t\t\t\tuint32 hashvalue,\n\t\t\t\t\t\t\tHASHACTION action,\n\t\t\t\t\t\t\tbool *foundPtr)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tint\t\t\tfreelist_idx = FREELIST_IDX(hctl, hashvalue);\n\tSize\t\tkeysize;\n\tuint32\t\tbucket;\n\tlong\t\tsegment_num;\n\tlong\t\tsegment_ndx;\n\tHASHSEGMENT segp;\n\tHASHBUCKET\tcurrBucket;\n\tHASHBUCKET *prevBucketPtr;\n\tHashCompareFunc match;\n\n#if HASH_STATISTICS\n\thash_accesses++;\n\thctl->accesses++;\n#endif\n\n\t/*\n\t * If inserting, check if it is time to split a bucket.\n\t *\n\t * NOTE: failure to expand table is not a fatal error, it just means we\n\t * have to run at higher fill factor than we wanted.  However, if we're\n\t * using the palloc allocator then it will throw error anyway on\n\t * out-of-memory, so we must do this before modifying the table.\n\t */\n\tif (action == HASH_ENTER || action == HASH_ENTER_NULL)\n\t{\n\t\t/*\n\t\t * Can't split if running in partitioned mode, nor if frozen, nor if\n\t\t * table is the subject of any active hash_seq_search scans.  Strange\n\t\t * order of these tests is to try to check cheaper conditions first.\n\t\t */\n\t\tif (!IS_PARTITIONED(hctl) && !hashp->frozen &&\n\t\t\thctl->freeList[0].nentries / (long) (hctl->max_bucket + 1) >= hctl->ffactor &&\n\t\t\t!has_seq_scans(hashp))\n\t\t\t(void) expand_table(hashp);\n\t}\n\n\t/*\n\t * Do the initial lookup\n\t */\n\tbucket = calc_bucket(hctl, hashvalue);\n\n\tsegment_num = bucket >> hashp->sshift;\n\tsegment_ndx = MOD(bucket, hashp->ssize);\n\n\tsegp = hashp->dir[segment_num];\n\n\tif (segp == NULL)\n\t\thash_corrupted(hashp);\n\n\tprevBucketPtr = &segp[segment_ndx];\n\tcurrBucket = *prevBucketPtr;\n\n\t/*\n\t * Follow collision chain looking for matching key\n\t */\n\tmatch = hashp->match;\t\t/* save one fetch in inner loop */\n\tkeysize = hashp->keysize;\t/* ditto */\n\n\twhile (currBucket != NULL)\n\t{\n\t\tif (currBucket->hashvalue == hashvalue &&\n\t\t\tmatch(ELEMENTKEY(currBucket), keyPtr, keysize) == 0)\n\t\t\tbreak;\n\t\tprevBucketPtr = &(currBucket->link);\n\t\tcurrBucket = *prevBucketPtr;\n#if HASH_STATISTICS\n\t\thash_collisions++;\n\t\thctl->collisions++;\n#endif\n\t}\n\n\tif (foundPtr)\n\t\t*foundPtr = (bool) (currBucket != NULL);\n\n\t/*\n\t * OK, now what?\n\t */\n\tswitch (action)\n\t{\n\t\tcase HASH_FIND:\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\treturn NULL;\n\n\t\tcase HASH_REMOVE:\n\t\t\tif (currBucket != NULL)\n\t\t\t{\n\t\t\t\t/* if partitioned, must lock to touch nentries and freeList */\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockAcquire(&(hctl->freeList[freelist_idx].mutex));\n\n\t\t\t\t/* delete the record from the appropriate nentries counter. */\n\t\t\t\tAssert(hctl->freeList[freelist_idx].nentries > 0);\n\t\t\t\thctl->freeList[freelist_idx].nentries--;\n\n\t\t\t\t/* remove record from hash bucket's chain. */\n\t\t\t\t*prevBucketPtr = currBucket->link;\n\n\t\t\t\t/* add the record to the appropriate freelist. */\n\t\t\t\tcurrBucket->link = hctl->freeList[freelist_idx].freeList;\n\t\t\t\thctl->freeList[freelist_idx].freeList = currBucket;\n\n\t\t\t\tif (IS_PARTITIONED(hctl))\n\t\t\t\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\t\t\t\t/*\n\t\t\t\t * better hope the caller is synchronizing access to this\n\t\t\t\t * element, because someone else is going to reuse it the next\n\t\t\t\t * time something is added to the table\n\t\t\t\t */\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t\t\t}\n\t\t\treturn NULL;\n\n\t\tcase HASH_ENTER_NULL:\n\t\t\t/* ENTER_NULL does not work with palloc-based allocator */\n\t\t\tAssert(hashp->alloc != DynaHashAlloc);\n\t\t\t/* FALL THRU */\n\n\t\tcase HASH_ENTER:\n\t\t\t/* Return existing element if found, else create one */\n\t\t\tif (currBucket != NULL)\n\t\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\n\t\t\t/* disallow inserts if frozen */\n\t\t\tif (hashp->frozen)\n\t\t\t\telog(ERROR, \"cannot insert into frozen hashtable \\\"%s\\\"\",\n\t\t\t\t\t hashp->tabname);\n\n\t\t\tcurrBucket = get_hash_entry(hashp, freelist_idx);\n\t\t\tif (currBucket == NULL)\n\t\t\t{\n\t\t\t\t/* out of memory */\n\t\t\t\tif (action == HASH_ENTER_NULL)\n\t\t\t\t\treturn NULL;\n\t\t\t\t/* report a generic message */\n\t\t\t\tif (hashp->isshared)\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of shared memory\")));\n\t\t\t\telse\n\t\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t\t}\n\n\t\t\t/* link into hashbucket chain */\n\t\t\t*prevBucketPtr = currBucket;\n\t\t\tcurrBucket->link = NULL;\n\n\t\t\t/* copy key into record */\n\t\t\tcurrBucket->hashvalue = hashvalue;\n\t\t\thashp->keycopy(ELEMENTKEY(currBucket), keyPtr, keysize);\n\n\t\t\t/*\n\t\t\t * Caller is expected to fill the data field on return.  DO NOT\n\t\t\t * insert any code that could possibly throw error here, as doing\n\t\t\t * so would leave the table entry incomplete and hence corrupt the\n\t\t\t * caller's data structure.\n\t\t\t */\n\n\t\t\treturn (void *) ELEMENTKEY(currBucket);\n\t}\n\n\telog(ERROR, \"unrecognized hash action code: %d\", (int) action);\n\n\treturn NULL;\t\t\t\t/* keep compiler quiet */\n}"
        }
      },
      {
        "call_info": {
          "callee": "hashp->hash",
          "args": [
            "keyPtr",
            "hashp->keysize"
          ],
          "line": 913
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid *\nhash_search(HTAB *hashp,\n\t\t\tconst void *keyPtr,\n\t\t\tHASHACTION action,\n\t\t\tbool *foundPtr)\n{\n\treturn hash_search_with_hash_value(hashp,\n\t\t\t\t\t\t\t\t\t   keyPtr,\n\t\t\t\t\t\t\t\t\t   hashp->hash(keyPtr, hashp->keysize),\n\t\t\t\t\t\t\t\t\t   action,\n\t\t\t\t\t\t\t\t\t   foundPtr);\n}"
  },
  {
    "function_name": "calc_bucket",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "866-876",
    "snippet": "static inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic inline uint32\ncalc_bucket(HASHHDR *hctl, uint32 hash_val)\n{\n\tuint32\t\tbucket;\n\n\tbucket = hash_val & hctl->high_mask;\n\tif (bucket > hctl->max_bucket)\n\t\tbucket = bucket & hctl->low_mask;\n\n\treturn bucket;\n}"
  },
  {
    "function_name": "get_hash_value",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "859-863",
    "snippet": "uint32\nget_hash_value(HTAB *hashp, const void *keyPtr)\n{\n\treturn hashp->hash(keyPtr, hashp->keysize);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "hashp->hash",
          "args": [
            "keyPtr",
            "hashp->keysize"
          ],
          "line": 862
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nuint32\nget_hash_value(HTAB *hashp, const void *keyPtr)\n{\n\treturn hashp->hash(keyPtr, hashp->keysize);\n}"
  },
  {
    "function_name": "hash_stats",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "832-847",
    "snippet": "void\nhash_stats(const char *where, HTAB *hashp)\n{\n#if HASH_STATISTICS\n\tfprintf(stderr, \"%s: this HTAB -- accesses %ld collisions %ld\\n\",\n\t\t\twhere, hashp->hctl->accesses, hashp->hctl->collisions);\n\n\tfprintf(stderr, \"hash_stats: entries %ld keysize %ld maxp %u segmentcount %ld\\n\",\n\t\t\thash_get_num_entries(hashp), (long) hashp->hctl->keysize,\n\t\t\thashp->hctl->max_bucket, hashp->hctl->nsegs);\n\tfprintf(stderr, \"%s: total accesses %ld total collisions %ld\\n\",\n\t\t\twhere, hash_accesses, hash_collisions);\n\tfprintf(stderr, \"hash_stats: total expansions %ld\\n\",\n\t\t\thash_expansions);\n#endif\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "fprintf",
          "args": [
            "stderr",
            "\"hash_stats: total expansions %ld\\n\"",
            "hash_expansions"
          ],
          "line": 844
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fprintf",
          "args": [
            "stderr",
            "\"%s: total accesses %ld total collisions %ld\\n\"",
            "where",
            "hash_accesses",
            "hash_collisions"
          ],
          "line": 842
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fprintf",
          "args": [
            "stderr",
            "\"hash_stats: entries %ld keysize %ld maxp %u segmentcount %ld\\n\"",
            "hash_get_num_entries(hashp)",
            "(long) hashp->hctl->keysize",
            "hashp->hctl->max_bucket",
            "hashp->hctl->nsegs"
          ],
          "line": 839
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hash_get_num_entries",
          "args": [
            "hashp"
          ],
          "line": 840
        },
        "resolved": true,
        "details": {
          "function_name": "hash_get_num_entries",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1334-1352",
          "snippet": "long\nhash_get_num_entries(HTAB *hashp)\n{\n\tint\t\t\ti;\n\tlong\t\tsum = hashp->hctl->freeList[0].nentries;\n\n\t/*\n\t * We currently don't bother with acquiring the mutexes; it's only\n\t * sensible to call this function if you've got lock on all partitions of\n\t * the table.\n\t */\n\tif (IS_PARTITIONED(hashp->hctl))\n\t{\n\t\tfor (i = 1; i < NUM_FREELISTS; i++)\n\t\t\tsum += hashp->hctl->freeList[i].nentries;\n\t}\n\n\treturn sum;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [
            "#define NUM_FREELISTS\t\t\t32"
          ],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nlong\nhash_get_num_entries(HTAB *hashp)\n{\n\tint\t\t\ti;\n\tlong\t\tsum = hashp->hctl->freeList[0].nentries;\n\n\t/*\n\t * We currently don't bother with acquiring the mutexes; it's only\n\t * sensible to call this function if you've got lock on all partitions of\n\t * the table.\n\t */\n\tif (IS_PARTITIONED(hashp->hctl))\n\t{\n\t\tfor (i = 1; i < NUM_FREELISTS; i++)\n\t\t\tsum += hashp->hctl->freeList[i].nentries;\n\t}\n\n\treturn sum;\n}"
        }
      },
      {
        "call_info": {
          "callee": "fprintf",
          "args": [
            "stderr",
            "\"%s: this HTAB -- accesses %ld collisions %ld\\n\"",
            "where",
            "hashp->hctl->accesses",
            "hashp->hctl->collisions"
          ],
          "line": 836
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_stats(const char *where, HTAB *hashp)\n{\n#if HASH_STATISTICS\n\tfprintf(stderr, \"%s: this HTAB -- accesses %ld collisions %ld\\n\",\n\t\t\twhere, hashp->hctl->accesses, hashp->hctl->collisions);\n\n\tfprintf(stderr, \"hash_stats: entries %ld keysize %ld maxp %u segmentcount %ld\\n\",\n\t\t\thash_get_num_entries(hashp), (long) hashp->hctl->keysize,\n\t\t\thashp->hctl->max_bucket, hashp->hctl->nsegs);\n\tfprintf(stderr, \"%s: total accesses %ld total collisions %ld\\n\",\n\t\t\twhere, hash_accesses, hash_collisions);\n\tfprintf(stderr, \"hash_stats: total expansions %ld\\n\",\n\t\t\thash_expansions);\n#endif\n}"
  },
  {
    "function_name": "hash_destroy",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "813-830",
    "snippet": "void\nhash_destroy(HTAB *hashp)\n{\n\tif (hashp != NULL)\n\t{\n\t\t/* allocation method must be one we know how to free, too */\n\t\tAssert(hashp->alloc == DynaHashAlloc);\n\t\t/* so this hashtable must have it's own context */\n\t\tAssert(hashp->hcxt != NULL);\n\n\t\thash_stats(\"destroy\", hashp);\n\n\t\t/*\n\t\t * Free everything by destroying the hash table's memory context.\n\t\t */\n\t\tMemoryContextDelete(hashp->hcxt);\n\t}\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "MemoryContextDelete",
          "args": [
            "hashp->hcxt"
          ],
          "line": 828
        },
        "resolved": true,
        "details": {
          "function_name": "MemoryContextDeleteChildren",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/mmgr/mcxt.c",
          "lines": "255-266",
          "snippet": "void\nMemoryContextDeleteChildren(MemoryContext context)\n{\n\tAssertArg(MemoryContextIsValid(context));\n\n\t/*\n\t * MemoryContextDelete will delink the child from me, so just iterate as\n\t * long as there is a child.\n\t */\n\twhile (context->firstchild != NULL)\n\t\tMemoryContextDelete(context->firstchild);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/memdebug.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void MemoryContextCallResetCallbacks(MemoryContext context);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/memdebug.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"postgres.h\"\n\nstatic void MemoryContextCallResetCallbacks(MemoryContext context);\n\nvoid\nMemoryContextDeleteChildren(MemoryContext context)\n{\n\tAssertArg(MemoryContextIsValid(context));\n\n\t/*\n\t * MemoryContextDelete will delink the child from me, so just iterate as\n\t * long as there is a child.\n\t */\n\twhile (context->firstchild != NULL)\n\t\tMemoryContextDelete(context->firstchild);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hash_stats",
          "args": [
            "\"destroy\"",
            "hashp"
          ],
          "line": 823
        },
        "resolved": true,
        "details": {
          "function_name": "hash_stats",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "832-847",
          "snippet": "void\nhash_stats(const char *where, HTAB *hashp)\n{\n#if HASH_STATISTICS\n\tfprintf(stderr, \"%s: this HTAB -- accesses %ld collisions %ld\\n\",\n\t\t\twhere, hashp->hctl->accesses, hashp->hctl->collisions);\n\n\tfprintf(stderr, \"hash_stats: entries %ld keysize %ld maxp %u segmentcount %ld\\n\",\n\t\t\thash_get_num_entries(hashp), (long) hashp->hctl->keysize,\n\t\t\thashp->hctl->max_bucket, hashp->hctl->nsegs);\n\tfprintf(stderr, \"%s: total accesses %ld total collisions %ld\\n\",\n\t\t\twhere, hash_accesses, hash_collisions);\n\tfprintf(stderr, \"hash_stats: total expansions %ld\\n\",\n\t\t\thash_expansions);\n#endif\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_stats(const char *where, HTAB *hashp)\n{\n#if HASH_STATISTICS\n\tfprintf(stderr, \"%s: this HTAB -- accesses %ld collisions %ld\\n\",\n\t\t\twhere, hashp->hctl->accesses, hashp->hctl->collisions);\n\n\tfprintf(stderr, \"hash_stats: entries %ld keysize %ld maxp %u segmentcount %ld\\n\",\n\t\t\thash_get_num_entries(hashp), (long) hashp->hctl->keysize,\n\t\t\thashp->hctl->max_bucket, hashp->hctl->nsegs);\n\tfprintf(stderr, \"%s: total accesses %ld total collisions %ld\\n\",\n\t\t\twhere, hash_accesses, hash_collisions);\n\tfprintf(stderr, \"hash_stats: total expansions %ld\\n\",\n\t\t\thash_expansions);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "hashp->hcxt != NULL"
          ],
          "line": 821
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "hashp->alloc == DynaHashAlloc"
          ],
          "line": 819
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nvoid\nhash_destroy(HTAB *hashp)\n{\n\tif (hashp != NULL)\n\t{\n\t\t/* allocation method must be one we know how to free, too */\n\t\tAssert(hashp->alloc == DynaHashAlloc);\n\t\t/* so this hashtable must have it's own context */\n\t\tAssert(hashp->hcxt != NULL);\n\n\t\thash_stats(\"destroy\", hashp);\n\n\t\t/*\n\t\t * Free everything by destroying the hash table's memory context.\n\t\t */\n\t\tMemoryContextDelete(hashp->hcxt);\n\t}\n}"
  },
  {
    "function_name": "hash_get_shared_size",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "802-808",
    "snippet": "Size\nhash_get_shared_size(HASHCTL *info, int flags)\n{\n\tAssert(flags & HASH_DIRSIZE);\n\tAssert(info->dsize == info->max_dsize);\n\treturn sizeof(HASHHDR) + info->dsize * sizeof(HASHSEGMENT);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "info->dsize == info->max_dsize"
          ],
          "line": 806
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "flags & HASH_DIRSIZE"
          ],
          "line": 805
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nSize\nhash_get_shared_size(HASHCTL *info, int flags)\n{\n\tAssert(flags & HASH_DIRSIZE);\n\tAssert(info->dsize == info->max_dsize);\n\treturn sizeof(HASHHDR) + info->dsize * sizeof(HASHSEGMENT);\n}"
  },
  {
    "function_name": "hash_select_dirsize",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "778-795",
    "snippet": "long\nhash_select_dirsize(long num_entries)\n{\n\tlong\t\tnBuckets,\n\t\t\t\tnSegments,\n\t\t\t\tnDirEntries;\n\n\t/* estimate number of buckets wanted */\n\tnBuckets = next_pow2_long((num_entries - 1) / DEF_FFACTOR + 1);\n\t/* # of segments needed for nBuckets */\n\tnSegments = next_pow2_long((nBuckets - 1) / DEF_SEGSIZE + 1);\n\t/* directory entries */\n\tnDirEntries = DEF_DIRSIZE;\n\twhile (nDirEntries < nSegments)\n\t\tnDirEntries <<= 1;\t\t/* dir_alloc doubles dsize at each call */\n\n\treturn nDirEntries;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */",
      "#define DEF_DIRSIZE\t\t\t   256",
      "#define DEF_SEGSIZE\t\t\t   256"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "next_pow2_long",
          "args": [
            "(nBuckets - 1) / DEF_SEGSIZE + 1"
          ],
          "line": 788
        },
        "resolved": true,
        "details": {
          "function_name": "next_pow2_long",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1733-1738",
          "snippet": "static long\nnext_pow2_long(long num)\n{\n\t/* my_log2's internal range check is sufficient */\n\treturn 1L << my_log2(num);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nstatic long\nnext_pow2_long(long num)\n{\n\t/* my_log2's internal range check is sufficient */\n\treturn 1L << my_log2(num);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */\n#define DEF_DIRSIZE\t\t\t   256\n#define DEF_SEGSIZE\t\t\t   256\n\nlong\nhash_select_dirsize(long num_entries)\n{\n\tlong\t\tnBuckets,\n\t\t\t\tnSegments,\n\t\t\t\tnDirEntries;\n\n\t/* estimate number of buckets wanted */\n\tnBuckets = next_pow2_long((num_entries - 1) / DEF_FFACTOR + 1);\n\t/* # of segments needed for nBuckets */\n\tnSegments = next_pow2_long((nBuckets - 1) / DEF_SEGSIZE + 1);\n\t/* directory entries */\n\tnDirEntries = DEF_DIRSIZE;\n\twhile (nDirEntries < nSegments)\n\t\tnDirEntries <<= 1;\t\t/* dir_alloc doubles dsize at each call */\n\n\treturn nDirEntries;\n}"
  },
  {
    "function_name": "hash_estimate_size",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "731-767",
    "snippet": "Size\nhash_estimate_size(long num_entries, Size entrysize)\n{\n\tSize\t\tsize;\n\tlong\t\tnBuckets,\n\t\t\t\tnSegments,\n\t\t\t\tnDirEntries,\n\t\t\t\tnElementAllocs,\n\t\t\t\telementSize,\n\t\t\t\telementAllocCnt;\n\n\t/* estimate number of buckets wanted */\n\tnBuckets = next_pow2_long((num_entries - 1) / DEF_FFACTOR + 1);\n\t/* # of segments needed for nBuckets */\n\tnSegments = next_pow2_long((nBuckets - 1) / DEF_SEGSIZE + 1);\n\t/* directory entries */\n\tnDirEntries = DEF_DIRSIZE;\n\twhile (nDirEntries < nSegments)\n\t\tnDirEntries <<= 1;\t\t/* dir_alloc doubles dsize at each call */\n\n\t/* fixed control info */\n\tsize = MAXALIGN(sizeof(HASHHDR));\t/* but not HTAB, per above */\n\t/* directory */\n\tsize = add_size(size, mul_size(nDirEntries, sizeof(HASHSEGMENT)));\n\t/* segments */\n\tsize = add_size(size, mul_size(nSegments,\n\t\t\t\t\t\t\t\t   MAXALIGN(DEF_SEGSIZE * sizeof(HASHBUCKET))));\n\t/* elements --- allocated in groups of choose_nelem_alloc() entries */\n\telementAllocCnt = choose_nelem_alloc(entrysize);\n\tnElementAllocs = (num_entries - 1) / elementAllocCnt + 1;\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\tsize = add_size(size,\n\t\t\t\t\tmul_size(nElementAllocs,\n\t\t\t\t\t\t\t mul_size(elementAllocCnt, elementSize)));\n\n\treturn size;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */",
      "#define DEF_DIRSIZE\t\t\t   256",
      "#define DEF_SEGSIZE\t\t\t   256"
    ],
    "globals_used": [
      "static void *DynaHashAlloc(Size size);",
      "static int\tchoose_nelem_alloc(Size entrysize);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "add_size",
          "args": [
            "size",
            "mul_size(nElementAllocs,\n\t\t\t\t\t\t\t mul_size(elementAllocCnt, elementSize))"
          ],
          "line": 762
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mul_size",
          "args": [
            "nElementAllocs",
            "mul_size(elementAllocCnt, elementSize)"
          ],
          "line": 763
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mul_size",
          "args": [
            "elementAllocCnt",
            "elementSize"
          ],
          "line": 764
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "entrysize"
          ],
          "line": 761
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "sizeof(HASHELEMENT)"
          ],
          "line": 761
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "choose_nelem_alloc",
          "args": [
            "entrysize"
          ],
          "line": 759
        },
        "resolved": true,
        "details": {
          "function_name": "choose_nelem_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "602-629",
          "snippet": "static int\nchoose_nelem_alloc(Size entrysize)\n{\n\tint\t\t\tnelem_alloc;\n\tSize\t\telementSize;\n\tSize\t\tallocSize;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\t/* NB: this had better match element_alloc() */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\n\t/*\n\t * The idea here is to choose nelem_alloc at least 32, but round up so\n\t * that the allocation request will be a power of 2 or just less. This\n\t * makes little difference for hash tables in shared memory, but for hash\n\t * tables managed by palloc, the allocation request will be rounded up to\n\t * a power of 2 anyway.  If we fail to take this into account, we'll waste\n\t * as much as half the allocated space.\n\t */\n\tallocSize = 32 * 4;\t\t\t/* assume elementSize at least 8 */\n\tdo\n\t{\n\t\tallocSize <<= 1;\n\t\tnelem_alloc = allocSize / elementSize;\n\t} while (nelem_alloc < 32);\n\n\treturn nelem_alloc;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int\tchoose_nelem_alloc(Size entrysize);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic int\tchoose_nelem_alloc(Size entrysize);\n\nstatic int\nchoose_nelem_alloc(Size entrysize)\n{\n\tint\t\t\tnelem_alloc;\n\tSize\t\telementSize;\n\tSize\t\tallocSize;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\t/* NB: this had better match element_alloc() */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\n\t/*\n\t * The idea here is to choose nelem_alloc at least 32, but round up so\n\t * that the allocation request will be a power of 2 or just less. This\n\t * makes little difference for hash tables in shared memory, but for hash\n\t * tables managed by palloc, the allocation request will be rounded up to\n\t * a power of 2 anyway.  If we fail to take this into account, we'll waste\n\t * as much as half the allocated space.\n\t */\n\tallocSize = 32 * 4;\t\t\t/* assume elementSize at least 8 */\n\tdo\n\t{\n\t\tallocSize <<= 1;\n\t\tnelem_alloc = allocSize / elementSize;\n\t} while (nelem_alloc < 32);\n\n\treturn nelem_alloc;\n}"
        }
      },
      {
        "call_info": {
          "callee": "add_size",
          "args": [
            "size",
            "mul_size(nSegments,\n\t\t\t\t\t\t\t\t   MAXALIGN(DEF_SEGSIZE * sizeof(HASHBUCKET)))"
          ],
          "line": 756
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mul_size",
          "args": [
            "nSegments",
            "MAXALIGN(DEF_SEGSIZE * sizeof(HASHBUCKET))"
          ],
          "line": 756
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "DEF_SEGSIZE * sizeof(HASHBUCKET)"
          ],
          "line": 757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "add_size",
          "args": [
            "size",
            "mul_size(nDirEntries, sizeof(HASHSEGMENT))"
          ],
          "line": 754
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mul_size",
          "args": [
            "nDirEntries",
            "sizeof(HASHSEGMENT)"
          ],
          "line": 754
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "sizeof(HASHHDR)"
          ],
          "line": 752
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "next_pow2_long",
          "args": [
            "(nBuckets - 1) / DEF_SEGSIZE + 1"
          ],
          "line": 745
        },
        "resolved": true,
        "details": {
          "function_name": "next_pow2_long",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1733-1738",
          "snippet": "static long\nnext_pow2_long(long num)\n{\n\t/* my_log2's internal range check is sufficient */\n\treturn 1L << my_log2(num);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nstatic long\nnext_pow2_long(long num)\n{\n\t/* my_log2's internal range check is sufficient */\n\treturn 1L << my_log2(num);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */\n#define DEF_DIRSIZE\t\t\t   256\n#define DEF_SEGSIZE\t\t\t   256\n\nstatic void *DynaHashAlloc(Size size);\nstatic int\tchoose_nelem_alloc(Size entrysize);\n\nSize\nhash_estimate_size(long num_entries, Size entrysize)\n{\n\tSize\t\tsize;\n\tlong\t\tnBuckets,\n\t\t\t\tnSegments,\n\t\t\t\tnDirEntries,\n\t\t\t\tnElementAllocs,\n\t\t\t\telementSize,\n\t\t\t\telementAllocCnt;\n\n\t/* estimate number of buckets wanted */\n\tnBuckets = next_pow2_long((num_entries - 1) / DEF_FFACTOR + 1);\n\t/* # of segments needed for nBuckets */\n\tnSegments = next_pow2_long((nBuckets - 1) / DEF_SEGSIZE + 1);\n\t/* directory entries */\n\tnDirEntries = DEF_DIRSIZE;\n\twhile (nDirEntries < nSegments)\n\t\tnDirEntries <<= 1;\t\t/* dir_alloc doubles dsize at each call */\n\n\t/* fixed control info */\n\tsize = MAXALIGN(sizeof(HASHHDR));\t/* but not HTAB, per above */\n\t/* directory */\n\tsize = add_size(size, mul_size(nDirEntries, sizeof(HASHSEGMENT)));\n\t/* segments */\n\tsize = add_size(size, mul_size(nSegments,\n\t\t\t\t\t\t\t\t   MAXALIGN(DEF_SEGSIZE * sizeof(HASHBUCKET))));\n\t/* elements --- allocated in groups of choose_nelem_alloc() entries */\n\telementAllocCnt = choose_nelem_alloc(entrysize);\n\tnElementAllocs = (num_entries - 1) / elementAllocCnt + 1;\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\tsize = add_size(size,\n\t\t\t\t\tmul_size(nElementAllocs,\n\t\t\t\t\t\t\t mul_size(elementAllocCnt, elementSize)));\n\n\treturn size;\n}"
  },
  {
    "function_name": "init_htab",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "635-722",
    "snippet": "static bool\ninit_htab(HTAB *hashp, long nelem)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT *segp;\n\tint\t\t\tnbuckets;\n\tint\t\t\tnsegs;\n\tint\t\t\ti;\n\n\t/*\n\t * initialize mutexes if it's a partitioned table\n\t */\n\tif (IS_PARTITIONED(hctl))\n\t\tfor (i = 0; i < NUM_FREELISTS; i++)\n\t\t\tSpinLockInit(&(hctl->freeList[i].mutex));\n\n\t/*\n\t * Divide number of elements by the fill factor to determine a desired\n\t * number of buckets.  Allocate space for the next greater power of two\n\t * number of buckets\n\t */\n\tnbuckets = next_pow2_int((nelem - 1) / hctl->ffactor + 1);\n\n\t/*\n\t * In a partitioned table, nbuckets must be at least equal to\n\t * num_partitions; were it less, keys with apparently different partition\n\t * numbers would map to the same bucket, breaking partition independence.\n\t * (Normally nbuckets will be much bigger; this is just a safety check.)\n\t */\n\twhile (nbuckets < hctl->num_partitions)\n\t\tnbuckets <<= 1;\n\n\thctl->max_bucket = hctl->low_mask = nbuckets - 1;\n\thctl->high_mask = (nbuckets << 1) - 1;\n\n\t/*\n\t * Figure number of directory segments needed, round up to a power of 2\n\t */\n\tnsegs = (nbuckets - 1) / hctl->ssize + 1;\n\tnsegs = next_pow2_int(nsegs);\n\n\t/*\n\t * Make sure directory is big enough. If pre-allocated directory is too\n\t * small, choke (caller screwed up).\n\t */\n\tif (nsegs > hctl->dsize)\n\t{\n\t\tif (!(hashp->dir))\n\t\t\thctl->dsize = nsegs;\n\t\telse\n\t\t\treturn false;\n\t}\n\n\t/* Allocate a directory */\n\tif (!(hashp->dir))\n\t{\n\t\tCurrentDynaHashCxt = hashp->hcxt;\n\t\thashp->dir = (HASHSEGMENT *)\n\t\t\thashp->alloc(hctl->dsize * sizeof(HASHSEGMENT));\n\t\tif (!hashp->dir)\n\t\t\treturn false;\n\t}\n\n\t/* Allocate initial segments */\n\tfor (segp = hashp->dir; hctl->nsegs < nsegs; hctl->nsegs++, segp++)\n\t{\n\t\t*segp = seg_alloc(hashp);\n\t\tif (*segp == NULL)\n\t\t\treturn false;\n\t}\n\n\t/* Choose number of entries to allocate at a time */\n\thctl->nelem_alloc = choose_nelem_alloc(hctl->entrysize);\n\n#if HASH_DEBUG\n\tfprintf(stderr, \"init_htab:\\n%s%p\\n%s%ld\\n%s%ld\\n%s%d\\n%s%ld\\n%s%u\\n%s%x\\n%s%x\\n%s%ld\\n\",\n\t\t\t\"TABLE POINTER   \", hashp,\n\t\t\t\"DIRECTORY SIZE  \", hctl->dsize,\n\t\t\t\"SEGMENT SIZE    \", hctl->ssize,\n\t\t\t\"SEGMENT SHIFT   \", hctl->sshift,\n\t\t\t\"FILL FACTOR     \", hctl->ffactor,\n\t\t\t\"MAX BUCKET      \", hctl->max_bucket,\n\t\t\t\"HIGH MASK       \", hctl->high_mask,\n\t\t\t\"LOW  MASK       \", hctl->low_mask,\n\t\t\t\"NSEGS           \", hctl->nsegs);\n#endif\n\treturn true;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define NUM_FREELISTS\t\t\t32"
    ],
    "globals_used": [
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static int\tchoose_nelem_alloc(Size entrysize);",
      "static bool init_htab(HTAB *hashp, long nelem);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static MemoryContext CurrentDynaHashCxt = NULL;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "fprintf",
          "args": [
            "stderr",
            "\"init_htab:\\n%s%p\\n%s%ld\\n%s%ld\\n%s%d\\n%s%ld\\n%s%u\\n%s%x\\n%s%x\\n%s%ld\\n\"",
            "\"TABLE POINTER   \"",
            "hashp",
            "\"DIRECTORY SIZE  \"",
            "hctl->dsize",
            "\"SEGMENT SIZE    \"",
            "hctl->ssize",
            "\"SEGMENT SHIFT   \"",
            "hctl->sshift",
            "\"FILL FACTOR     \"",
            "hctl->ffactor",
            "\"MAX BUCKET      \"",
            "hctl->max_bucket",
            "\"HIGH MASK       \"",
            "hctl->high_mask",
            "\"LOW  MASK       \"",
            "hctl->low_mask",
            "\"NSEGS           \"",
            "hctl->nsegs"
          ],
          "line": 710
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "choose_nelem_alloc",
          "args": [
            "hctl->entrysize"
          ],
          "line": 707
        },
        "resolved": true,
        "details": {
          "function_name": "choose_nelem_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "602-629",
          "snippet": "static int\nchoose_nelem_alloc(Size entrysize)\n{\n\tint\t\t\tnelem_alloc;\n\tSize\t\telementSize;\n\tSize\t\tallocSize;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\t/* NB: this had better match element_alloc() */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\n\t/*\n\t * The idea here is to choose nelem_alloc at least 32, but round up so\n\t * that the allocation request will be a power of 2 or just less. This\n\t * makes little difference for hash tables in shared memory, but for hash\n\t * tables managed by palloc, the allocation request will be rounded up to\n\t * a power of 2 anyway.  If we fail to take this into account, we'll waste\n\t * as much as half the allocated space.\n\t */\n\tallocSize = 32 * 4;\t\t\t/* assume elementSize at least 8 */\n\tdo\n\t{\n\t\tallocSize <<= 1;\n\t\tnelem_alloc = allocSize / elementSize;\n\t} while (nelem_alloc < 32);\n\n\treturn nelem_alloc;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int\tchoose_nelem_alloc(Size entrysize);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic int\tchoose_nelem_alloc(Size entrysize);\n\nstatic int\nchoose_nelem_alloc(Size entrysize)\n{\n\tint\t\t\tnelem_alloc;\n\tSize\t\telementSize;\n\tSize\t\tallocSize;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\t/* NB: this had better match element_alloc() */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\n\t/*\n\t * The idea here is to choose nelem_alloc at least 32, but round up so\n\t * that the allocation request will be a power of 2 or just less. This\n\t * makes little difference for hash tables in shared memory, but for hash\n\t * tables managed by palloc, the allocation request will be rounded up to\n\t * a power of 2 anyway.  If we fail to take this into account, we'll waste\n\t * as much as half the allocated space.\n\t */\n\tallocSize = 32 * 4;\t\t\t/* assume elementSize at least 8 */\n\tdo\n\t{\n\t\tallocSize <<= 1;\n\t\tnelem_alloc = allocSize / elementSize;\n\t} while (nelem_alloc < 32);\n\n\treturn nelem_alloc;\n}"
        }
      },
      {
        "call_info": {
          "callee": "seg_alloc",
          "args": [
            "hashp"
          ],
          "line": 701
        },
        "resolved": true,
        "details": {
          "function_name": "seg_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1637-1651",
          "snippet": "static HASHSEGMENT\nseg_alloc(HTAB *hashp)\n{\n\tHASHSEGMENT segp;\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tsegp = (HASHSEGMENT) hashp->alloc(sizeof(HASHBUCKET) * hashp->ssize);\n\n\tif (!segp)\n\t\treturn NULL;\n\n\tMemSet(segp, 0, sizeof(HASHBUCKET) * hashp->ssize);\n\n\treturn segp;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic HASHSEGMENT\nseg_alloc(HTAB *hashp)\n{\n\tHASHSEGMENT segp;\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tsegp = (HASHSEGMENT) hashp->alloc(sizeof(HASHBUCKET) * hashp->ssize);\n\n\tif (!segp)\n\t\treturn NULL;\n\n\tMemSet(segp, 0, sizeof(HASHBUCKET) * hashp->ssize);\n\n\treturn segp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hashp->alloc",
          "args": [
            "hctl->dsize * sizeof(HASHSEGMENT)"
          ],
          "line": 693
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "next_pow2_int",
          "args": [
            "nsegs"
          ],
          "line": 674
        },
        "resolved": true,
        "details": {
          "function_name": "next_pow2_int",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1741-1747",
          "snippet": "static int\nnext_pow2_int(long num)\n{\n\tif (num > INT_MAX / 2)\n\t\tnum = INT_MAX / 2;\n\treturn 1 << my_log2(num);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nstatic int\nnext_pow2_int(long num)\n{\n\tif (num > INT_MAX / 2)\n\t\tnum = INT_MAX / 2;\n\treturn 1 << my_log2(num);\n}"
        }
      },
      {
        "call_info": {
          "callee": "SpinLockInit",
          "args": [
            "&(hctl->freeList[i].mutex)"
          ],
          "line": 649
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hctl"
          ],
          "line": 647
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic bool init_htab(HTAB *hashp, long nelem);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\ninit_htab(HTAB *hashp, long nelem)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT *segp;\n\tint\t\t\tnbuckets;\n\tint\t\t\tnsegs;\n\tint\t\t\ti;\n\n\t/*\n\t * initialize mutexes if it's a partitioned table\n\t */\n\tif (IS_PARTITIONED(hctl))\n\t\tfor (i = 0; i < NUM_FREELISTS; i++)\n\t\t\tSpinLockInit(&(hctl->freeList[i].mutex));\n\n\t/*\n\t * Divide number of elements by the fill factor to determine a desired\n\t * number of buckets.  Allocate space for the next greater power of two\n\t * number of buckets\n\t */\n\tnbuckets = next_pow2_int((nelem - 1) / hctl->ffactor + 1);\n\n\t/*\n\t * In a partitioned table, nbuckets must be at least equal to\n\t * num_partitions; were it less, keys with apparently different partition\n\t * numbers would map to the same bucket, breaking partition independence.\n\t * (Normally nbuckets will be much bigger; this is just a safety check.)\n\t */\n\twhile (nbuckets < hctl->num_partitions)\n\t\tnbuckets <<= 1;\n\n\thctl->max_bucket = hctl->low_mask = nbuckets - 1;\n\thctl->high_mask = (nbuckets << 1) - 1;\n\n\t/*\n\t * Figure number of directory segments needed, round up to a power of 2\n\t */\n\tnsegs = (nbuckets - 1) / hctl->ssize + 1;\n\tnsegs = next_pow2_int(nsegs);\n\n\t/*\n\t * Make sure directory is big enough. If pre-allocated directory is too\n\t * small, choke (caller screwed up).\n\t */\n\tif (nsegs > hctl->dsize)\n\t{\n\t\tif (!(hashp->dir))\n\t\t\thctl->dsize = nsegs;\n\t\telse\n\t\t\treturn false;\n\t}\n\n\t/* Allocate a directory */\n\tif (!(hashp->dir))\n\t{\n\t\tCurrentDynaHashCxt = hashp->hcxt;\n\t\thashp->dir = (HASHSEGMENT *)\n\t\t\thashp->alloc(hctl->dsize * sizeof(HASHSEGMENT));\n\t\tif (!hashp->dir)\n\t\t\treturn false;\n\t}\n\n\t/* Allocate initial segments */\n\tfor (segp = hashp->dir; hctl->nsegs < nsegs; hctl->nsegs++, segp++)\n\t{\n\t\t*segp = seg_alloc(hashp);\n\t\tif (*segp == NULL)\n\t\t\treturn false;\n\t}\n\n\t/* Choose number of entries to allocate at a time */\n\thctl->nelem_alloc = choose_nelem_alloc(hctl->entrysize);\n\n#if HASH_DEBUG\n\tfprintf(stderr, \"init_htab:\\n%s%p\\n%s%ld\\n%s%ld\\n%s%d\\n%s%ld\\n%s%u\\n%s%x\\n%s%x\\n%s%ld\\n\",\n\t\t\t\"TABLE POINTER   \", hashp,\n\t\t\t\"DIRECTORY SIZE  \", hctl->dsize,\n\t\t\t\"SEGMENT SIZE    \", hctl->ssize,\n\t\t\t\"SEGMENT SHIFT   \", hctl->sshift,\n\t\t\t\"FILL FACTOR     \", hctl->ffactor,\n\t\t\t\"MAX BUCKET      \", hctl->max_bucket,\n\t\t\t\"HIGH MASK       \", hctl->high_mask,\n\t\t\t\"LOW  MASK       \", hctl->low_mask,\n\t\t\t\"NSEGS           \", hctl->nsegs);\n#endif\n\treturn true;\n}"
  },
  {
    "function_name": "choose_nelem_alloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "602-629",
    "snippet": "static int\nchoose_nelem_alloc(Size entrysize)\n{\n\tint\t\t\tnelem_alloc;\n\tSize\t\telementSize;\n\tSize\t\tallocSize;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\t/* NB: this had better match element_alloc() */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\n\t/*\n\t * The idea here is to choose nelem_alloc at least 32, but round up so\n\t * that the allocation request will be a power of 2 or just less. This\n\t * makes little difference for hash tables in shared memory, but for hash\n\t * tables managed by palloc, the allocation request will be rounded up to\n\t * a power of 2 anyway.  If we fail to take this into account, we'll waste\n\t * as much as half the allocated space.\n\t */\n\tallocSize = 32 * 4;\t\t\t/* assume elementSize at least 8 */\n\tdo\n\t{\n\t\tallocSize <<= 1;\n\t\tnelem_alloc = allocSize / elementSize;\n\t} while (nelem_alloc < 32);\n\n\treturn nelem_alloc;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static int\tchoose_nelem_alloc(Size entrysize);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "entrysize"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MAXALIGN",
          "args": [
            "sizeof(HASHELEMENT)"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic int\tchoose_nelem_alloc(Size entrysize);\n\nstatic int\nchoose_nelem_alloc(Size entrysize)\n{\n\tint\t\t\tnelem_alloc;\n\tSize\t\telementSize;\n\tSize\t\tallocSize;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\t/* NB: this had better match element_alloc() */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(entrysize);\n\n\t/*\n\t * The idea here is to choose nelem_alloc at least 32, but round up so\n\t * that the allocation request will be a power of 2 or just less. This\n\t * makes little difference for hash tables in shared memory, but for hash\n\t * tables managed by palloc, the allocation request will be rounded up to\n\t * a power of 2 anyway.  If we fail to take this into account, we'll waste\n\t * as much as half the allocated space.\n\t */\n\tallocSize = 32 * 4;\t\t\t/* assume elementSize at least 8 */\n\tdo\n\t{\n\t\tallocSize <<= 1;\n\t\tnelem_alloc = allocSize / elementSize;\n\t} while (nelem_alloc < 32);\n\n\treturn nelem_alloc;\n}"
  },
  {
    "function_name": "hdefault",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "569-596",
    "snippet": "static void\nhdefault(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\n\tMemSet(hctl, 0, sizeof(HASHHDR));\n\n\thctl->dsize = DEF_DIRSIZE;\n\thctl->nsegs = 0;\n\n\t/* rather pointless defaults for key & entry size */\n\thctl->keysize = sizeof(char *);\n\thctl->entrysize = 2 * sizeof(char *);\n\n\thctl->num_partitions = 0;\t/* not partitioned */\n\n\thctl->ffactor = DEF_FFACTOR;\n\n\t/* table has no fixed maximum size */\n\thctl->max_dsize = NO_MAX_DSIZE;\n\n\thctl->ssize = DEF_SEGSIZE;\n\thctl->sshift = DEF_SEGSIZE_SHIFT;\n\n#ifdef HASH_STATISTICS\n\thctl->accesses = hctl->collisions = 0;\n#endif\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */",
      "#define DEF_DIRSIZE\t\t\t   256",
      "#define DEF_SEGSIZE_SHIFT\t   8\t/* must be log2(DEF_SEGSIZE) */",
      "#define DEF_SEGSIZE\t\t\t   256"
    ],
    "globals_used": [
      "static void *DynaHashAlloc(Size size);",
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static int\tchoose_nelem_alloc(Size entrysize);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "MemSet",
          "args": [
            "hctl",
            "0",
            "sizeof(HASHHDR)"
          ],
          "line": 574
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */\n#define DEF_DIRSIZE\t\t\t   256\n#define DEF_SEGSIZE_SHIFT\t   8\t/* must be log2(DEF_SEGSIZE) */\n#define DEF_SEGSIZE\t\t\t   256\n\nstatic void *DynaHashAlloc(Size size);\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic void\nhdefault(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\n\tMemSet(hctl, 0, sizeof(HASHHDR));\n\n\thctl->dsize = DEF_DIRSIZE;\n\thctl->nsegs = 0;\n\n\t/* rather pointless defaults for key & entry size */\n\thctl->keysize = sizeof(char *);\n\thctl->entrysize = 2 * sizeof(char *);\n\n\thctl->num_partitions = 0;\t/* not partitioned */\n\n\thctl->ffactor = DEF_FFACTOR;\n\n\t/* table has no fixed maximum size */\n\thctl->max_dsize = NO_MAX_DSIZE;\n\n\thctl->ssize = DEF_SEGSIZE;\n\thctl->sshift = DEF_SEGSIZE_SHIFT;\n\n#ifdef HASH_STATISTICS\n\thctl->accesses = hctl->collisions = 0;\n#endif\n}"
  },
  {
    "function_name": "hash_create",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "315-564",
    "snippet": "HTAB *\nhash_create(const char *tabname, long nelem, HASHCTL *info, int flags)\n{\n\tHTAB\t   *hashp;\n\tHASHHDR    *hctl;\n\n\t/*\n\t * For shared hash tables, we have a local hash header (HTAB struct) that\n\t * we allocate in TopMemoryContext; all else is in shared memory.\n\t *\n\t * For non-shared hash tables, everything including the hash header is in\n\t * a memory context created specially for the hash table --- this makes\n\t * hash_destroy very simple.  The memory context is made a child of either\n\t * a context specified by the caller, or TopMemoryContext if nothing is\n\t * specified.\n\t */\n\tif (flags & HASH_SHARED_MEM)\n\t{\n\t\t/* Set up to allocate the hash header */\n\t\tCurrentDynaHashCxt = TopMemoryContext;\n\t}\n\telse\n\t{\n\t\t/* Create the hash table's private memory context */\n\t\tif (flags & HASH_CONTEXT)\n\t\t\tCurrentDynaHashCxt = info->hcxt;\n\t\telse\n\t\t\tCurrentDynaHashCxt = TopMemoryContext;\n\t\tCurrentDynaHashCxt = AllocSetContextCreate(CurrentDynaHashCxt,\n\t\t\t\t\t\t\t\t\t\t\t\t   \"dynahash\",\n\t\t\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_SIZES);\n\t}\n\n\t/* Initialize the hash header, plus a copy of the table name */\n\thashp = (HTAB *) DynaHashAlloc(sizeof(HTAB) + strlen(tabname) + 1);\n\tMemSet(hashp, 0, sizeof(HTAB));\n\n\thashp->tabname = (char *) (hashp + 1);\n\tstrcpy(hashp->tabname, tabname);\n\n\t/* If we have a private context, label it with hashtable's name */\n\tif (!(flags & HASH_SHARED_MEM))\n\t\tMemoryContextSetIdentifier(CurrentDynaHashCxt, hashp->tabname);\n\n\t/*\n\t * Select the appropriate hash function (see comments at head of file).\n\t */\n\tif (flags & HASH_FUNCTION)\n\t\thashp->hash = info->hash;\n\telse if (flags & HASH_BLOBS)\n\t{\n\t\t/* We can optimize hashing for common key sizes */\n\t\tAssert(flags & HASH_ELEM);\n\t\tif (info->keysize == sizeof(uint32))\n\t\t\thashp->hash = uint32_hash;\n\t\telse\n\t\t\thashp->hash = tag_hash;\n\t}\n\telse\n\t\thashp->hash = string_hash;\t/* default hash function */\n\n\t/*\n\t * If you don't specify a match function, it defaults to string_compare if\n\t * you used string_hash (either explicitly or by default) and to memcmp\n\t * otherwise.\n\t *\n\t * Note: explicitly specifying string_hash is deprecated, because this\n\t * might not work for callers in loadable modules on some platforms due to\n\t * referencing a trampoline instead of the string_hash function proper.\n\t * Just let it default, eh?\n\t */\n\tif (flags & HASH_COMPARE)\n\t\thashp->match = info->match;\n\telse if (hashp->hash == string_hash)\n\t\thashp->match = (HashCompareFunc) string_compare;\n\telse\n\t\thashp->match = memcmp;\n\n\t/*\n\t * Similarly, the key-copying function defaults to strlcpy or memcpy.\n\t */\n\tif (flags & HASH_KEYCOPY)\n\t\thashp->keycopy = info->keycopy;\n\telse if (hashp->hash == string_hash)\n\t\thashp->keycopy = (HashCopyFunc) strlcpy;\n\telse\n\t\thashp->keycopy = memcpy;\n\n\t/* And select the entry allocation function, too. */\n\tif (flags & HASH_ALLOC)\n\t\thashp->alloc = info->alloc;\n\telse\n\t\thashp->alloc = DynaHashAlloc;\n\n\tif (flags & HASH_SHARED_MEM)\n\t{\n\t\t/*\n\t\t * ctl structure and directory are preallocated for shared memory\n\t\t * tables.  Note that HASH_DIRSIZE and HASH_ALLOC had better be set as\n\t\t * well.\n\t\t */\n\t\thashp->hctl = info->hctl;\n\t\thashp->dir = (HASHSEGMENT *) (((char *) info->hctl) + sizeof(HASHHDR));\n\t\thashp->hcxt = NULL;\n\t\thashp->isshared = true;\n\n\t\t/* hash table already exists, we're just attaching to it */\n\t\tif (flags & HASH_ATTACH)\n\t\t{\n\t\t\t/* make local copies of some heavily-used values */\n\t\t\thctl = hashp->hctl;\n\t\t\thashp->keysize = hctl->keysize;\n\t\t\thashp->ssize = hctl->ssize;\n\t\t\thashp->sshift = hctl->sshift;\n\n\t\t\treturn hashp;\n\t\t}\n\t}\n\telse\n\t{\n\t\t/* setup hash table defaults */\n\t\thashp->hctl = NULL;\n\t\thashp->dir = NULL;\n\t\thashp->hcxt = CurrentDynaHashCxt;\n\t\thashp->isshared = false;\n\t}\n\n\tif (!hashp->hctl)\n\t{\n\t\thashp->hctl = (HASHHDR *) hashp->alloc(sizeof(HASHHDR));\n\t\tif (!hashp->hctl)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t errmsg(\"out of memory\")));\n\t}\n\n\thashp->frozen = false;\n\n\thdefault(hashp);\n\n\thctl = hashp->hctl;\n\n\tif (flags & HASH_PARTITION)\n\t{\n\t\t/* Doesn't make sense to partition a local hash table */\n\t\tAssert(flags & HASH_SHARED_MEM);\n\n\t\t/*\n\t\t * The number of partitions had better be a power of 2. Also, it must\n\t\t * be less than INT_MAX (see init_htab()), so call the int version of\n\t\t * next_pow2.\n\t\t */\n\t\tAssert(info->num_partitions == next_pow2_int(info->num_partitions));\n\n\t\thctl->num_partitions = info->num_partitions;\n\t}\n\n\tif (flags & HASH_SEGMENT)\n\t{\n\t\thctl->ssize = info->ssize;\n\t\thctl->sshift = my_log2(info->ssize);\n\t\t/* ssize had better be a power of 2 */\n\t\tAssert(hctl->ssize == (1L << hctl->sshift));\n\t}\n\tif (flags & HASH_FFACTOR)\n\t\thctl->ffactor = info->ffactor;\n\n\t/*\n\t * SHM hash tables have fixed directory size passed by the caller.\n\t */\n\tif (flags & HASH_DIRSIZE)\n\t{\n\t\thctl->max_dsize = info->max_dsize;\n\t\thctl->dsize = info->dsize;\n\t}\n\n\t/*\n\t * hash table now allocates space for key and data but you have to say how\n\t * much space to allocate\n\t */\n\tif (flags & HASH_ELEM)\n\t{\n\t\tAssert(info->entrysize >= info->keysize);\n\t\thctl->keysize = info->keysize;\n\t\thctl->entrysize = info->entrysize;\n\t}\n\n\t/* make local copies of heavily-used constant fields */\n\thashp->keysize = hctl->keysize;\n\thashp->ssize = hctl->ssize;\n\thashp->sshift = hctl->sshift;\n\n\t/* Build the hash directory structure */\n\tif (!init_htab(hashp, nelem))\n\t\telog(ERROR, \"failed to initialize hash table \\\"%s\\\"\", hashp->tabname);\n\n\t/*\n\t * For a shared hash table, preallocate the requested number of elements.\n\t * This reduces problems with run-time out-of-shared-memory conditions.\n\t *\n\t * For a non-shared hash table, preallocate the requested number of\n\t * elements if it's less than our chosen nelem_alloc.  This avoids wasting\n\t * space if the caller correctly estimates a small table size.\n\t */\n\tif ((flags & HASH_SHARED_MEM) ||\n\t\tnelem < hctl->nelem_alloc)\n\t{\n\t\tint\t\t\ti,\n\t\t\t\t\tfreelist_partitions,\n\t\t\t\t\tnelem_alloc,\n\t\t\t\t\tnelem_alloc_first;\n\n\t\t/*\n\t\t * If hash table is partitioned, give each freelist an equal share of\n\t\t * the initial allocation.  Otherwise only freeList[0] is used.\n\t\t */\n\t\tif (IS_PARTITIONED(hashp->hctl))\n\t\t\tfreelist_partitions = NUM_FREELISTS;\n\t\telse\n\t\t\tfreelist_partitions = 1;\n\n\t\tnelem_alloc = nelem / freelist_partitions;\n\t\tif (nelem_alloc <= 0)\n\t\t\tnelem_alloc = 1;\n\n\t\t/*\n\t\t * Make sure we'll allocate all the requested elements; freeList[0]\n\t\t * gets the excess if the request isn't divisible by NUM_FREELISTS.\n\t\t */\n\t\tif (nelem_alloc * freelist_partitions < nelem)\n\t\t\tnelem_alloc_first =\n\t\t\t\tnelem - nelem_alloc * (freelist_partitions - 1);\n\t\telse\n\t\t\tnelem_alloc_first = nelem_alloc;\n\n\t\tfor (i = 0; i < freelist_partitions; i++)\n\t\t{\n\t\t\tint\t\t\ttemp = (i == 0) ? nelem_alloc_first : nelem_alloc;\n\n\t\t\tif (!element_alloc(hashp, temp, i))\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t}\n\t}\n\n\tif (flags & HASH_FIXED_SIZE)\n\t\thashp->isfixed = true;\n\treturn hashp;\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [
      "#define NUM_FREELISTS\t\t\t32"
    ],
    "globals_used": [
      "static void *DynaHashAlloc(Size size);",
      "static HASHSEGMENT seg_alloc(HTAB *hashp);",
      "static bool dir_realloc(HTAB *hashp);",
      "static bool expand_table(HTAB *hashp);",
      "static void hdefault(HTAB *hashp);",
      "static int\tchoose_nelem_alloc(Size entrysize);",
      "static bool init_htab(HTAB *hashp, long nelem);",
      "static void hash_corrupted(HTAB *hashp);",
      "static void register_seq_scan(HTAB *hashp);",
      "static void deregister_seq_scan(HTAB *hashp);",
      "static bool has_seq_scans(HTAB *hashp);",
      "static MemoryContext CurrentDynaHashCxt = NULL;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ereport",
          "args": [
            "ERROR",
            "(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t errmsg(\"out of memory\"))"
          ],
          "line": 555
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "errmsg",
          "args": [
            "\"out of memory\""
          ],
          "line": 557
        },
        "resolved": true,
        "details": {
          "function_name": "errmsg_internal",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "824-840",
          "snippet": "int\nerrmsg_internal(const char *fmt,...)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\tMemoryContext oldcontext;\n\n\trecursion_depth++;\n\tCHECK_STACK_DEPTH();\n\toldcontext = MemoryContextSwitchTo(edata->assoc_context);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, false);\n\n\tMemoryContextSwitchTo(oldcontext);\n\trecursion_depth--;\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static ErrorData errordata[ERRORDATA_STACK_SIZE];",
            "static int\terrordata_stack_depth = -1;",
            "static int\trecursion_depth = 0;",
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic ErrorData errordata[ERRORDATA_STACK_SIZE];\nstatic int\terrordata_stack_depth = -1;\nstatic int\trecursion_depth = 0;\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\n\nint\nerrmsg_internal(const char *fmt,...)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\tMemoryContext oldcontext;\n\n\trecursion_depth++;\n\tCHECK_STACK_DEPTH();\n\toldcontext = MemoryContextSwitchTo(edata->assoc_context);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, false);\n\n\tMemoryContextSwitchTo(oldcontext);\n\trecursion_depth--;\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}"
        }
      },
      {
        "call_info": {
          "callee": "errcode",
          "args": [
            "ERRCODE_OUT_OF_MEMORY"
          ],
          "line": 556
        },
        "resolved": true,
        "details": {
          "function_name": "errcode",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "572-583",
          "snippet": "int\nerrcode(int sqlerrcode)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\n\t/* we don't bother incrementing recursion_depth */\n\tCHECK_STACK_DEPTH();\n\n\tedata->sqlerrcode = sqlerrcode;\n\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static ErrorData errordata[ERRORDATA_STACK_SIZE];",
            "static int\terrordata_stack_depth = -1;",
            "static int\trecursion_depth = 0;",
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic ErrorData errordata[ERRORDATA_STACK_SIZE];\nstatic int\terrordata_stack_depth = -1;\nstatic int\trecursion_depth = 0;\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\n\nint\nerrcode(int sqlerrcode)\n{\n\tErrorData  *edata = &errordata[errordata_stack_depth];\n\n\t/* we don't bother incrementing recursion_depth */\n\tCHECK_STACK_DEPTH();\n\n\tedata->sqlerrcode = sqlerrcode;\n\n\treturn 0;\t\t\t\t\t/* return value does not matter */\n}"
        }
      },
      {
        "call_info": {
          "callee": "element_alloc",
          "args": [
            "hashp",
            "temp",
            "i"
          ],
          "line": 554
        },
        "resolved": true,
        "details": {
          "function_name": "element_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1656-1700",
          "snippet": "static bool\nelement_alloc(HTAB *hashp, int nelem, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tSize\t\telementSize;\n\tHASHELEMENT *firstElement;\n\tHASHELEMENT *tmpElement;\n\tHASHELEMENT *prevElement;\n\tint\t\t\ti;\n\n\tif (hashp->isfixed)\n\t\treturn false;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(hctl->entrysize);\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tfirstElement = (HASHELEMENT *) hashp->alloc(nelem * elementSize);\n\n\tif (!firstElement)\n\t\treturn false;\n\n\t/* prepare to link all the new entries into the freelist */\n\tprevElement = NULL;\n\ttmpElement = firstElement;\n\tfor (i = 0; i < nelem; i++)\n\t{\n\t\ttmpElement->link = prevElement;\n\t\tprevElement = tmpElement;\n\t\ttmpElement = (HASHELEMENT *) (((char *) tmpElement) + elementSize);\n\t}\n\n\t/* if partitioned, must lock to touch freeList */\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t/* freelist could be nonempty if two backends did this concurrently */\n\tfirstElement->link = hctl->freeList[freelist_idx].freeList;\n\thctl->freeList[freelist_idx].freeList = prevElement;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn true;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);",
            "static void hdefault(HTAB *hashp);",
            "static int\tchoose_nelem_alloc(Size entrysize);",
            "static bool init_htab(HTAB *hashp, long nelem);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool element_alloc(HTAB *hashp, int nelem, int freelist_idx);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic HASHBUCKET get_hash_entry(HTAB *hashp, int freelist_idx);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic bool init_htab(HTAB *hashp, long nelem);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\nelement_alloc(HTAB *hashp, int nelem, int freelist_idx)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tSize\t\telementSize;\n\tHASHELEMENT *firstElement;\n\tHASHELEMENT *tmpElement;\n\tHASHELEMENT *prevElement;\n\tint\t\t\ti;\n\n\tif (hashp->isfixed)\n\t\treturn false;\n\n\t/* Each element has a HASHELEMENT header plus user data. */\n\telementSize = MAXALIGN(sizeof(HASHELEMENT)) + MAXALIGN(hctl->entrysize);\n\n\tCurrentDynaHashCxt = hashp->hcxt;\n\tfirstElement = (HASHELEMENT *) hashp->alloc(nelem * elementSize);\n\n\tif (!firstElement)\n\t\treturn false;\n\n\t/* prepare to link all the new entries into the freelist */\n\tprevElement = NULL;\n\ttmpElement = firstElement;\n\tfor (i = 0; i < nelem; i++)\n\t{\n\t\ttmpElement->link = prevElement;\n\t\tprevElement = tmpElement;\n\t\ttmpElement = (HASHELEMENT *) (((char *) tmpElement) + elementSize);\n\t}\n\n\t/* if partitioned, must lock to touch freeList */\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockAcquire(&hctl->freeList[freelist_idx].mutex);\n\n\t/* freelist could be nonempty if two backends did this concurrently */\n\tfirstElement->link = hctl->freeList[freelist_idx].freeList;\n\thctl->freeList[freelist_idx].freeList = prevElement;\n\n\tif (IS_PARTITIONED(hctl))\n\t\tSpinLockRelease(&hctl->freeList[freelist_idx].mutex);\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_PARTITIONED",
          "args": [
            "hashp->hctl"
          ],
          "line": 531
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "elog",
          "args": [
            "ERROR",
            "\"failed to initialize hash table \\\"%s\\\"\"",
            "hashp->tabname"
          ],
          "line": 509
        },
        "resolved": true,
        "details": {
          "function_name": "format_elog_string",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/error/elog.c",
          "lines": "1410-1433",
          "snippet": "char *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}",
          "includes": [
            "#include \"utils/ps_status.h\"",
            "#include \"utils/memutils.h\"",
            "#include \"utils/guc.h\"",
            "#include \"tcop/tcopprot.h\"",
            "#include \"storage/proc.h\"",
            "#include \"storage/ipc.h\"",
            "#include \"postmaster/syslogger.h\"",
            "#include \"postmaster/postmaster.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"libpq/libpq.h\"",
            "#include \"access/xact.h\"",
            "#include \"access/transam.h\"",
            "#include <syslog.h>",
            "#include <ctype.h>",
            "#include <signal.h>",
            "#include <unistd.h>",
            "#include <time.h>",
            "#include <fcntl.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void log_line_prefix(StringInfo buf, ErrorData *edata);",
            "static void write_csvlog(ErrorData *edata);",
            "static void send_message_to_server_log(ErrorData *edata);",
            "static void send_message_to_frontend(ErrorData *edata);",
            "static char *expand_fmt_string(const char *fmt, ErrorData *edata);",
            "static int\tsave_format_errnumber;",
            "static const char *save_format_domain;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/ps_status.h\"\n#include \"utils/memutils.h\"\n#include \"utils/guc.h\"\n#include \"tcop/tcopprot.h\"\n#include \"storage/proc.h\"\n#include \"storage/ipc.h\"\n#include \"postmaster/syslogger.h\"\n#include \"postmaster/postmaster.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"libpq/libpq.h\"\n#include \"access/xact.h\"\n#include \"access/transam.h\"\n#include <syslog.h>\n#include <ctype.h>\n#include <signal.h>\n#include <unistd.h>\n#include <time.h>\n#include <fcntl.h>\n#include \"postgres.h\"\n\nstatic void log_line_prefix(StringInfo buf, ErrorData *edata);\nstatic void write_csvlog(ErrorData *edata);\nstatic void send_message_to_server_log(ErrorData *edata);\nstatic void send_message_to_frontend(ErrorData *edata);\nstatic char *expand_fmt_string(const char *fmt, ErrorData *edata);\nstatic int\tsave_format_errnumber;\nstatic const char *save_format_domain;\n\nchar *\nformat_elog_string(const char *fmt,...)\n{\n\tErrorData\terrdata;\n\tErrorData  *edata;\n\tMemoryContext oldcontext;\n\n\t/* Initialize a mostly-dummy error frame */\n\tedata = &errdata;\n\tMemSet(edata, 0, sizeof(ErrorData));\n\t/* the default text domain is the backend's */\n\tedata->domain = save_format_domain ? save_format_domain : PG_TEXTDOMAIN(\"postgres\");\n\t/* set the errno to be used to interpret %m */\n\tedata->saved_errno = save_format_errnumber;\n\n\toldcontext = MemoryContextSwitchTo(ErrorContext);\n\n\tedata->message_id = fmt;\n\tEVALUATE_MESSAGE(edata->domain, message, false, true);\n\n\tMemoryContextSwitchTo(oldcontext);\n\n\treturn edata->message;\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_htab",
          "args": [
            "hashp",
            "nelem"
          ],
          "line": 508
        },
        "resolved": true,
        "details": {
          "function_name": "init_htab",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "635-722",
          "snippet": "static bool\ninit_htab(HTAB *hashp, long nelem)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT *segp;\n\tint\t\t\tnbuckets;\n\tint\t\t\tnsegs;\n\tint\t\t\ti;\n\n\t/*\n\t * initialize mutexes if it's a partitioned table\n\t */\n\tif (IS_PARTITIONED(hctl))\n\t\tfor (i = 0; i < NUM_FREELISTS; i++)\n\t\t\tSpinLockInit(&(hctl->freeList[i].mutex));\n\n\t/*\n\t * Divide number of elements by the fill factor to determine a desired\n\t * number of buckets.  Allocate space for the next greater power of two\n\t * number of buckets\n\t */\n\tnbuckets = next_pow2_int((nelem - 1) / hctl->ffactor + 1);\n\n\t/*\n\t * In a partitioned table, nbuckets must be at least equal to\n\t * num_partitions; were it less, keys with apparently different partition\n\t * numbers would map to the same bucket, breaking partition independence.\n\t * (Normally nbuckets will be much bigger; this is just a safety check.)\n\t */\n\twhile (nbuckets < hctl->num_partitions)\n\t\tnbuckets <<= 1;\n\n\thctl->max_bucket = hctl->low_mask = nbuckets - 1;\n\thctl->high_mask = (nbuckets << 1) - 1;\n\n\t/*\n\t * Figure number of directory segments needed, round up to a power of 2\n\t */\n\tnsegs = (nbuckets - 1) / hctl->ssize + 1;\n\tnsegs = next_pow2_int(nsegs);\n\n\t/*\n\t * Make sure directory is big enough. If pre-allocated directory is too\n\t * small, choke (caller screwed up).\n\t */\n\tif (nsegs > hctl->dsize)\n\t{\n\t\tif (!(hashp->dir))\n\t\t\thctl->dsize = nsegs;\n\t\telse\n\t\t\treturn false;\n\t}\n\n\t/* Allocate a directory */\n\tif (!(hashp->dir))\n\t{\n\t\tCurrentDynaHashCxt = hashp->hcxt;\n\t\thashp->dir = (HASHSEGMENT *)\n\t\t\thashp->alloc(hctl->dsize * sizeof(HASHSEGMENT));\n\t\tif (!hashp->dir)\n\t\t\treturn false;\n\t}\n\n\t/* Allocate initial segments */\n\tfor (segp = hashp->dir; hctl->nsegs < nsegs; hctl->nsegs++, segp++)\n\t{\n\t\t*segp = seg_alloc(hashp);\n\t\tif (*segp == NULL)\n\t\t\treturn false;\n\t}\n\n\t/* Choose number of entries to allocate at a time */\n\thctl->nelem_alloc = choose_nelem_alloc(hctl->entrysize);\n\n#if HASH_DEBUG\n\tfprintf(stderr, \"init_htab:\\n%s%p\\n%s%ld\\n%s%ld\\n%s%d\\n%s%ld\\n%s%u\\n%s%x\\n%s%x\\n%s%ld\\n\",\n\t\t\t\"TABLE POINTER   \", hashp,\n\t\t\t\"DIRECTORY SIZE  \", hctl->dsize,\n\t\t\t\"SEGMENT SIZE    \", hctl->ssize,\n\t\t\t\"SEGMENT SHIFT   \", hctl->sshift,\n\t\t\t\"FILL FACTOR     \", hctl->ffactor,\n\t\t\t\"MAX BUCKET      \", hctl->max_bucket,\n\t\t\t\"HIGH MASK       \", hctl->high_mask,\n\t\t\t\"LOW  MASK       \", hctl->low_mask,\n\t\t\t\"NSEGS           \", hctl->nsegs);\n#endif\n\treturn true;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [
            "#define NUM_FREELISTS\t\t\t32"
          ],
          "globals_used": [
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static int\tchoose_nelem_alloc(Size entrysize);",
            "static bool init_htab(HTAB *hashp, long nelem);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic bool init_htab(HTAB *hashp, long nelem);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic bool\ninit_htab(HTAB *hashp, long nelem)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\tHASHSEGMENT *segp;\n\tint\t\t\tnbuckets;\n\tint\t\t\tnsegs;\n\tint\t\t\ti;\n\n\t/*\n\t * initialize mutexes if it's a partitioned table\n\t */\n\tif (IS_PARTITIONED(hctl))\n\t\tfor (i = 0; i < NUM_FREELISTS; i++)\n\t\t\tSpinLockInit(&(hctl->freeList[i].mutex));\n\n\t/*\n\t * Divide number of elements by the fill factor to determine a desired\n\t * number of buckets.  Allocate space for the next greater power of two\n\t * number of buckets\n\t */\n\tnbuckets = next_pow2_int((nelem - 1) / hctl->ffactor + 1);\n\n\t/*\n\t * In a partitioned table, nbuckets must be at least equal to\n\t * num_partitions; were it less, keys with apparently different partition\n\t * numbers would map to the same bucket, breaking partition independence.\n\t * (Normally nbuckets will be much bigger; this is just a safety check.)\n\t */\n\twhile (nbuckets < hctl->num_partitions)\n\t\tnbuckets <<= 1;\n\n\thctl->max_bucket = hctl->low_mask = nbuckets - 1;\n\thctl->high_mask = (nbuckets << 1) - 1;\n\n\t/*\n\t * Figure number of directory segments needed, round up to a power of 2\n\t */\n\tnsegs = (nbuckets - 1) / hctl->ssize + 1;\n\tnsegs = next_pow2_int(nsegs);\n\n\t/*\n\t * Make sure directory is big enough. If pre-allocated directory is too\n\t * small, choke (caller screwed up).\n\t */\n\tif (nsegs > hctl->dsize)\n\t{\n\t\tif (!(hashp->dir))\n\t\t\thctl->dsize = nsegs;\n\t\telse\n\t\t\treturn false;\n\t}\n\n\t/* Allocate a directory */\n\tif (!(hashp->dir))\n\t{\n\t\tCurrentDynaHashCxt = hashp->hcxt;\n\t\thashp->dir = (HASHSEGMENT *)\n\t\t\thashp->alloc(hctl->dsize * sizeof(HASHSEGMENT));\n\t\tif (!hashp->dir)\n\t\t\treturn false;\n\t}\n\n\t/* Allocate initial segments */\n\tfor (segp = hashp->dir; hctl->nsegs < nsegs; hctl->nsegs++, segp++)\n\t{\n\t\t*segp = seg_alloc(hashp);\n\t\tif (*segp == NULL)\n\t\t\treturn false;\n\t}\n\n\t/* Choose number of entries to allocate at a time */\n\thctl->nelem_alloc = choose_nelem_alloc(hctl->entrysize);\n\n#if HASH_DEBUG\n\tfprintf(stderr, \"init_htab:\\n%s%p\\n%s%ld\\n%s%ld\\n%s%d\\n%s%ld\\n%s%u\\n%s%x\\n%s%x\\n%s%ld\\n\",\n\t\t\t\"TABLE POINTER   \", hashp,\n\t\t\t\"DIRECTORY SIZE  \", hctl->dsize,\n\t\t\t\"SEGMENT SIZE    \", hctl->ssize,\n\t\t\t\"SEGMENT SHIFT   \", hctl->sshift,\n\t\t\t\"FILL FACTOR     \", hctl->ffactor,\n\t\t\t\"MAX BUCKET      \", hctl->max_bucket,\n\t\t\t\"HIGH MASK       \", hctl->high_mask,\n\t\t\t\"LOW  MASK       \", hctl->low_mask,\n\t\t\t\"NSEGS           \", hctl->nsegs);\n#endif\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "info->entrysize >= info->keysize"
          ],
          "line": 497
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "hctl->ssize == (1L << hctl->sshift)"
          ],
          "line": 477
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "my_log2",
          "args": [
            "info->ssize"
          ],
          "line": 475
        },
        "resolved": true,
        "details": {
          "function_name": "my_log2",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1717-1730",
          "snippet": "int\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nint\nmy_log2(long num)\n{\n\tint\t\t\ti;\n\tlong\t\tlimit;\n\n\t/* guard against too-large input, which would put us into infinite loop */\n\tif (num > LONG_MAX / 2)\n\t\tnum = LONG_MAX / 2;\n\n\tfor (i = 0, limit = 1; limit < num; i++, limit <<= 1)\n\t\t;\n\treturn i;\n}"
        }
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "info->num_partitions == next_pow2_int(info->num_partitions)"
          ],
          "line": 467
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "next_pow2_int",
          "args": [
            "info->num_partitions"
          ],
          "line": 467
        },
        "resolved": true,
        "details": {
          "function_name": "next_pow2_int",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "1741-1747",
          "snippet": "static int\nnext_pow2_int(long num)\n{\n\tif (num > INT_MAX / 2)\n\t\tnum = INT_MAX / 2;\n\treturn 1 << my_log2(num);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static long next_pow2_long(long num);",
            "static int\tnext_pow2_int(long num);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic long next_pow2_long(long num);\nstatic int\tnext_pow2_int(long num);\n\nstatic int\nnext_pow2_int(long num)\n{\n\tif (num > INT_MAX / 2)\n\t\tnum = INT_MAX / 2;\n\treturn 1 << my_log2(num);\n}"
        }
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "flags & HASH_SHARED_MEM"
          ],
          "line": 460
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hdefault",
          "args": [
            "hashp"
          ],
          "line": 453
        },
        "resolved": true,
        "details": {
          "function_name": "hdefault",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "569-596",
          "snippet": "static void\nhdefault(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\n\tMemSet(hctl, 0, sizeof(HASHHDR));\n\n\thctl->dsize = DEF_DIRSIZE;\n\thctl->nsegs = 0;\n\n\t/* rather pointless defaults for key & entry size */\n\thctl->keysize = sizeof(char *);\n\thctl->entrysize = 2 * sizeof(char *);\n\n\thctl->num_partitions = 0;\t/* not partitioned */\n\n\thctl->ffactor = DEF_FFACTOR;\n\n\t/* table has no fixed maximum size */\n\thctl->max_dsize = NO_MAX_DSIZE;\n\n\thctl->ssize = DEF_SEGSIZE;\n\thctl->sshift = DEF_SEGSIZE_SHIFT;\n\n#ifdef HASH_STATISTICS\n\thctl->accesses = hctl->collisions = 0;\n#endif\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [
            "#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */",
            "#define DEF_DIRSIZE\t\t\t   256",
            "#define DEF_SEGSIZE_SHIFT\t   8\t/* must be log2(DEF_SEGSIZE) */",
            "#define DEF_SEGSIZE\t\t\t   256"
          ],
          "globals_used": [
            "static void *DynaHashAlloc(Size size);",
            "static HASHSEGMENT seg_alloc(HTAB *hashp);",
            "static bool dir_realloc(HTAB *hashp);",
            "static bool expand_table(HTAB *hashp);",
            "static void hdefault(HTAB *hashp);",
            "static int\tchoose_nelem_alloc(Size entrysize);",
            "static void hash_corrupted(HTAB *hashp);",
            "static void register_seq_scan(HTAB *hashp);",
            "static void deregister_seq_scan(HTAB *hashp);",
            "static bool has_seq_scans(HTAB *hashp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define DEF_FFACTOR\t\t\t   1\t/* default fill factor */\n#define DEF_DIRSIZE\t\t\t   256\n#define DEF_SEGSIZE_SHIFT\t   8\t/* must be log2(DEF_SEGSIZE) */\n#define DEF_SEGSIZE\t\t\t   256\n\nstatic void *DynaHashAlloc(Size size);\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\n\nstatic void\nhdefault(HTAB *hashp)\n{\n\tHASHHDR    *hctl = hashp->hctl;\n\n\tMemSet(hctl, 0, sizeof(HASHHDR));\n\n\thctl->dsize = DEF_DIRSIZE;\n\thctl->nsegs = 0;\n\n\t/* rather pointless defaults for key & entry size */\n\thctl->keysize = sizeof(char *);\n\thctl->entrysize = 2 * sizeof(char *);\n\n\thctl->num_partitions = 0;\t/* not partitioned */\n\n\thctl->ffactor = DEF_FFACTOR;\n\n\t/* table has no fixed maximum size */\n\thctl->max_dsize = NO_MAX_DSIZE;\n\n\thctl->ssize = DEF_SEGSIZE;\n\thctl->sshift = DEF_SEGSIZE_SHIFT;\n\n#ifdef HASH_STATISTICS\n\thctl->accesses = hctl->collisions = 0;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "ereport",
          "args": [
            "ERROR",
            "(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t errmsg(\"out of memory\"))"
          ],
          "line": 446
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hashp->alloc",
          "args": [
            "sizeof(HASHHDR)"
          ],
          "line": 444
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "flags & HASH_ELEM"
          ],
          "line": 367
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MemoryContextSetIdentifier",
          "args": [
            "CurrentDynaHashCxt",
            "hashp->tabname"
          ],
          "line": 357
        },
        "resolved": true,
        "details": {
          "function_name": "MemoryContextSetIdentifier",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/mmgr/mcxt.c",
          "lines": "328-333",
          "snippet": "void\nMemoryContextSetIdentifier(MemoryContext context, const char *id)\n{\n\tAssertArg(MemoryContextIsValid(context));\n\tcontext->ident = id;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/memdebug.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void MemoryContextCallResetCallbacks(MemoryContext context);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/memdebug.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"postgres.h\"\n\nstatic void MemoryContextCallResetCallbacks(MemoryContext context);\n\nvoid\nMemoryContextSetIdentifier(MemoryContext context, const char *id)\n{\n\tAssertArg(MemoryContextIsValid(context));\n\tcontext->ident = id;\n}"
        }
      },
      {
        "call_info": {
          "callee": "strcpy",
          "args": [
            "hashp->tabname",
            "tabname"
          ],
          "line": 353
        },
        "resolved": true,
        "details": {
          "function_name": "namestrcpy",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/adt/name.c",
          "lines": "215-222",
          "snippet": "int\nnamestrcpy(Name name, const char *str)\n{\n\tif (!name || !str)\n\t\treturn -1;\n\tStrNCpy(NameStr(*name), str, NAMEDATALEN);\n\treturn 0;\n}",
          "includes": [
            "#include \"utils/lsyscache.h\"",
            "#include \"utils/builtins.h\"",
            "#include \"utils/array.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"libpq/pqformat.h\"",
            "#include \"catalog/pg_type.h\"",
            "#include \"catalog/namespace.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/lsyscache.h\"\n#include \"utils/builtins.h\"\n#include \"utils/array.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"libpq/pqformat.h\"\n#include \"catalog/pg_type.h\"\n#include \"catalog/namespace.h\"\n#include \"postgres.h\"\n\nint\nnamestrcpy(Name name, const char *str)\n{\n\tif (!name || !str)\n\t\treturn -1;\n\tStrNCpy(NameStr(*name), str, NAMEDATALEN);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "MemSet",
          "args": [
            "hashp",
            "0",
            "sizeof(HTAB)"
          ],
          "line": 350
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DynaHashAlloc",
          "args": [
            "sizeof(HTAB) + strlen(tabname) + 1"
          ],
          "line": 349
        },
        "resolved": true,
        "details": {
          "function_name": "DynaHashAlloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
          "lines": "277-282",
          "snippet": "static void *\nDynaHashAlloc(Size size)\n{\n\tAssert(MemoryContextIsValid(CurrentDynaHashCxt));\n\treturn MemoryContextAlloc(CurrentDynaHashCxt, size);\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/dynahash.h\"",
            "#include \"storage/spin.h\"",
            "#include \"storage/shmem.h\"",
            "#include \"access/xact.h\"",
            "#include <limits.h>",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void *DynaHashAlloc(Size size);",
            "static MemoryContext CurrentDynaHashCxt = NULL;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic void *DynaHashAlloc(Size size);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic void *\nDynaHashAlloc(Size size)\n{\n\tAssert(MemoryContextIsValid(CurrentDynaHashCxt));\n\treturn MemoryContextAlloc(CurrentDynaHashCxt, size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "strlen",
          "args": [
            "tabname"
          ],
          "line": 349
        },
        "resolved": true,
        "details": {
          "function_name": "calcstrlen",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/adt/tsquery_cleanup.c",
          "lines": "361-380",
          "snippet": "static int32\ncalcstrlen(NODE *node)\n{\n\tint32\t\tsize = 0;\n\n\tif (node->valnode->type == QI_VAL)\n\t{\n\t\tsize = node->valnode->qoperand.length + 1;\n\t}\n\telse\n\t{\n\t\tAssert(node->valnode->type == QI_OPR);\n\n\t\tsize = calcstrlen(node->right);\n\t\tif (node->valnode->qoperator.oper != OP_NOT)\n\t\t\tsize += calcstrlen(node->left);\n\t}\n\n\treturn size;\n}",
          "includes": [
            "#include \"miscadmin.h\"",
            "#include \"tsearch/ts_utils.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"miscadmin.h\"\n#include \"tsearch/ts_utils.h\"\n#include \"postgres.h\"\n\nstatic int32\ncalcstrlen(NODE *node)\n{\n\tint32\t\tsize = 0;\n\n\tif (node->valnode->type == QI_VAL)\n\t{\n\t\tsize = node->valnode->qoperand.length + 1;\n\t}\n\telse\n\t{\n\t\tAssert(node->valnode->type == QI_OPR);\n\n\t\tsize = calcstrlen(node->right);\n\t\tif (node->valnode->qoperator.oper != OP_NOT)\n\t\t\tsize += calcstrlen(node->left);\n\t}\n\n\treturn size;\n}"
        }
      },
      {
        "call_info": {
          "callee": "AllocSetContextCreate",
          "args": [
            "CurrentDynaHashCxt",
            "\"dynahash\"",
            "ALLOCSET_DEFAULT_SIZES"
          ],
          "line": 343
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\n#define NUM_FREELISTS\t\t\t32\n\nstatic void *DynaHashAlloc(Size size);\nstatic HASHSEGMENT seg_alloc(HTAB *hashp);\nstatic bool dir_realloc(HTAB *hashp);\nstatic bool expand_table(HTAB *hashp);\nstatic void hdefault(HTAB *hashp);\nstatic int\tchoose_nelem_alloc(Size entrysize);\nstatic bool init_htab(HTAB *hashp, long nelem);\nstatic void hash_corrupted(HTAB *hashp);\nstatic void register_seq_scan(HTAB *hashp);\nstatic void deregister_seq_scan(HTAB *hashp);\nstatic bool has_seq_scans(HTAB *hashp);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nHTAB *\nhash_create(const char *tabname, long nelem, HASHCTL *info, int flags)\n{\n\tHTAB\t   *hashp;\n\tHASHHDR    *hctl;\n\n\t/*\n\t * For shared hash tables, we have a local hash header (HTAB struct) that\n\t * we allocate in TopMemoryContext; all else is in shared memory.\n\t *\n\t * For non-shared hash tables, everything including the hash header is in\n\t * a memory context created specially for the hash table --- this makes\n\t * hash_destroy very simple.  The memory context is made a child of either\n\t * a context specified by the caller, or TopMemoryContext if nothing is\n\t * specified.\n\t */\n\tif (flags & HASH_SHARED_MEM)\n\t{\n\t\t/* Set up to allocate the hash header */\n\t\tCurrentDynaHashCxt = TopMemoryContext;\n\t}\n\telse\n\t{\n\t\t/* Create the hash table's private memory context */\n\t\tif (flags & HASH_CONTEXT)\n\t\t\tCurrentDynaHashCxt = info->hcxt;\n\t\telse\n\t\t\tCurrentDynaHashCxt = TopMemoryContext;\n\t\tCurrentDynaHashCxt = AllocSetContextCreate(CurrentDynaHashCxt,\n\t\t\t\t\t\t\t\t\t\t\t\t   \"dynahash\",\n\t\t\t\t\t\t\t\t\t\t\t\t   ALLOCSET_DEFAULT_SIZES);\n\t}\n\n\t/* Initialize the hash header, plus a copy of the table name */\n\thashp = (HTAB *) DynaHashAlloc(sizeof(HTAB) + strlen(tabname) + 1);\n\tMemSet(hashp, 0, sizeof(HTAB));\n\n\thashp->tabname = (char *) (hashp + 1);\n\tstrcpy(hashp->tabname, tabname);\n\n\t/* If we have a private context, label it with hashtable's name */\n\tif (!(flags & HASH_SHARED_MEM))\n\t\tMemoryContextSetIdentifier(CurrentDynaHashCxt, hashp->tabname);\n\n\t/*\n\t * Select the appropriate hash function (see comments at head of file).\n\t */\n\tif (flags & HASH_FUNCTION)\n\t\thashp->hash = info->hash;\n\telse if (flags & HASH_BLOBS)\n\t{\n\t\t/* We can optimize hashing for common key sizes */\n\t\tAssert(flags & HASH_ELEM);\n\t\tif (info->keysize == sizeof(uint32))\n\t\t\thashp->hash = uint32_hash;\n\t\telse\n\t\t\thashp->hash = tag_hash;\n\t}\n\telse\n\t\thashp->hash = string_hash;\t/* default hash function */\n\n\t/*\n\t * If you don't specify a match function, it defaults to string_compare if\n\t * you used string_hash (either explicitly or by default) and to memcmp\n\t * otherwise.\n\t *\n\t * Note: explicitly specifying string_hash is deprecated, because this\n\t * might not work for callers in loadable modules on some platforms due to\n\t * referencing a trampoline instead of the string_hash function proper.\n\t * Just let it default, eh?\n\t */\n\tif (flags & HASH_COMPARE)\n\t\thashp->match = info->match;\n\telse if (hashp->hash == string_hash)\n\t\thashp->match = (HashCompareFunc) string_compare;\n\telse\n\t\thashp->match = memcmp;\n\n\t/*\n\t * Similarly, the key-copying function defaults to strlcpy or memcpy.\n\t */\n\tif (flags & HASH_KEYCOPY)\n\t\thashp->keycopy = info->keycopy;\n\telse if (hashp->hash == string_hash)\n\t\thashp->keycopy = (HashCopyFunc) strlcpy;\n\telse\n\t\thashp->keycopy = memcpy;\n\n\t/* And select the entry allocation function, too. */\n\tif (flags & HASH_ALLOC)\n\t\thashp->alloc = info->alloc;\n\telse\n\t\thashp->alloc = DynaHashAlloc;\n\n\tif (flags & HASH_SHARED_MEM)\n\t{\n\t\t/*\n\t\t * ctl structure and directory are preallocated for shared memory\n\t\t * tables.  Note that HASH_DIRSIZE and HASH_ALLOC had better be set as\n\t\t * well.\n\t\t */\n\t\thashp->hctl = info->hctl;\n\t\thashp->dir = (HASHSEGMENT *) (((char *) info->hctl) + sizeof(HASHHDR));\n\t\thashp->hcxt = NULL;\n\t\thashp->isshared = true;\n\n\t\t/* hash table already exists, we're just attaching to it */\n\t\tif (flags & HASH_ATTACH)\n\t\t{\n\t\t\t/* make local copies of some heavily-used values */\n\t\t\thctl = hashp->hctl;\n\t\t\thashp->keysize = hctl->keysize;\n\t\t\thashp->ssize = hctl->ssize;\n\t\t\thashp->sshift = hctl->sshift;\n\n\t\t\treturn hashp;\n\t\t}\n\t}\n\telse\n\t{\n\t\t/* setup hash table defaults */\n\t\thashp->hctl = NULL;\n\t\thashp->dir = NULL;\n\t\thashp->hcxt = CurrentDynaHashCxt;\n\t\thashp->isshared = false;\n\t}\n\n\tif (!hashp->hctl)\n\t{\n\t\thashp->hctl = (HASHHDR *) hashp->alloc(sizeof(HASHHDR));\n\t\tif (!hashp->hctl)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t errmsg(\"out of memory\")));\n\t}\n\n\thashp->frozen = false;\n\n\thdefault(hashp);\n\n\thctl = hashp->hctl;\n\n\tif (flags & HASH_PARTITION)\n\t{\n\t\t/* Doesn't make sense to partition a local hash table */\n\t\tAssert(flags & HASH_SHARED_MEM);\n\n\t\t/*\n\t\t * The number of partitions had better be a power of 2. Also, it must\n\t\t * be less than INT_MAX (see init_htab()), so call the int version of\n\t\t * next_pow2.\n\t\t */\n\t\tAssert(info->num_partitions == next_pow2_int(info->num_partitions));\n\n\t\thctl->num_partitions = info->num_partitions;\n\t}\n\n\tif (flags & HASH_SEGMENT)\n\t{\n\t\thctl->ssize = info->ssize;\n\t\thctl->sshift = my_log2(info->ssize);\n\t\t/* ssize had better be a power of 2 */\n\t\tAssert(hctl->ssize == (1L << hctl->sshift));\n\t}\n\tif (flags & HASH_FFACTOR)\n\t\thctl->ffactor = info->ffactor;\n\n\t/*\n\t * SHM hash tables have fixed directory size passed by the caller.\n\t */\n\tif (flags & HASH_DIRSIZE)\n\t{\n\t\thctl->max_dsize = info->max_dsize;\n\t\thctl->dsize = info->dsize;\n\t}\n\n\t/*\n\t * hash table now allocates space for key and data but you have to say how\n\t * much space to allocate\n\t */\n\tif (flags & HASH_ELEM)\n\t{\n\t\tAssert(info->entrysize >= info->keysize);\n\t\thctl->keysize = info->keysize;\n\t\thctl->entrysize = info->entrysize;\n\t}\n\n\t/* make local copies of heavily-used constant fields */\n\thashp->keysize = hctl->keysize;\n\thashp->ssize = hctl->ssize;\n\thashp->sshift = hctl->sshift;\n\n\t/* Build the hash directory structure */\n\tif (!init_htab(hashp, nelem))\n\t\telog(ERROR, \"failed to initialize hash table \\\"%s\\\"\", hashp->tabname);\n\n\t/*\n\t * For a shared hash table, preallocate the requested number of elements.\n\t * This reduces problems with run-time out-of-shared-memory conditions.\n\t *\n\t * For a non-shared hash table, preallocate the requested number of\n\t * elements if it's less than our chosen nelem_alloc.  This avoids wasting\n\t * space if the caller correctly estimates a small table size.\n\t */\n\tif ((flags & HASH_SHARED_MEM) ||\n\t\tnelem < hctl->nelem_alloc)\n\t{\n\t\tint\t\t\ti,\n\t\t\t\t\tfreelist_partitions,\n\t\t\t\t\tnelem_alloc,\n\t\t\t\t\tnelem_alloc_first;\n\n\t\t/*\n\t\t * If hash table is partitioned, give each freelist an equal share of\n\t\t * the initial allocation.  Otherwise only freeList[0] is used.\n\t\t */\n\t\tif (IS_PARTITIONED(hashp->hctl))\n\t\t\tfreelist_partitions = NUM_FREELISTS;\n\t\telse\n\t\t\tfreelist_partitions = 1;\n\n\t\tnelem_alloc = nelem / freelist_partitions;\n\t\tif (nelem_alloc <= 0)\n\t\t\tnelem_alloc = 1;\n\n\t\t/*\n\t\t * Make sure we'll allocate all the requested elements; freeList[0]\n\t\t * gets the excess if the request isn't divisible by NUM_FREELISTS.\n\t\t */\n\t\tif (nelem_alloc * freelist_partitions < nelem)\n\t\t\tnelem_alloc_first =\n\t\t\t\tnelem - nelem_alloc * (freelist_partitions - 1);\n\t\telse\n\t\t\tnelem_alloc_first = nelem_alloc;\n\n\t\tfor (i = 0; i < freelist_partitions; i++)\n\t\t{\n\t\t\tint\t\t\ttemp = (i == 0) ? nelem_alloc_first : nelem_alloc;\n\n\t\t\tif (!element_alloc(hashp, temp, i))\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t\t\t errmsg(\"out of memory\")));\n\t\t}\n\t}\n\n\tif (flags & HASH_FIXED_SIZE)\n\t\thashp->isfixed = true;\n\treturn hashp;\n}"
  },
  {
    "function_name": "string_compare",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "292-296",
    "snippet": "static int\nstring_compare(const char *key1, const char *key2, Size keysize)\n{\n\treturn strncmp(key1, key2, keysize - 1);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "strncmp",
          "args": [
            "key1",
            "key2",
            "keysize - 1"
          ],
          "line": 295
        },
        "resolved": true,
        "details": {
          "function_name": "pg_char_and_wchar_strncmp",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/mb/wstrncmp.c",
          "lines": "54-67",
          "snippet": "int\npg_char_and_wchar_strncmp(const char *s1, const pg_wchar *s2, size_t n)\n{\n\tif (n == 0)\n\t\treturn 0;\n\tdo\n\t{\n\t\tif ((pg_wchar) ((unsigned char) *s1) != *s2++)\n\t\t\treturn ((pg_wchar) ((unsigned char) *s1) - *(s2 - 1));\n\t\tif (*s1++ == 0)\n\t\t\tbreak;\n\t} while (--n != 0);\n\treturn 0;\n}",
          "includes": [
            "#include \"mb/pg_wchar.h\"",
            "#include \"postgres_fe.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mb/pg_wchar.h\"\n#include \"postgres_fe.h\"\n\nint\npg_char_and_wchar_strncmp(const char *s1, const pg_wchar *s2, size_t n)\n{\n\tif (n == 0)\n\t\treturn 0;\n\tdo\n\t{\n\t\tif ((pg_wchar) ((unsigned char) *s1) != *s2++)\n\t\t\treturn ((pg_wchar) ((unsigned char) *s1) - *(s2 - 1));\n\t\tif (*s1++ == 0)\n\t\t\tbreak;\n\t} while (--n != 0);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic int\nstring_compare(const char *key1, const char *key2, Size keysize)\n{\n\treturn strncmp(key1, key2, keysize - 1);\n}"
  },
  {
    "function_name": "DynaHashAlloc",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/hash/dynahash.c",
    "lines": "277-282",
    "snippet": "static void *\nDynaHashAlloc(Size size)\n{\n\tAssert(MemoryContextIsValid(CurrentDynaHashCxt));\n\treturn MemoryContextAlloc(CurrentDynaHashCxt, size);\n}",
    "includes": [
      "#include \"utils/memutils.h\"",
      "#include \"utils/dynahash.h\"",
      "#include \"storage/spin.h\"",
      "#include \"storage/shmem.h\"",
      "#include \"access/xact.h\"",
      "#include <limits.h>",
      "#include \"postgres.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void *DynaHashAlloc(Size size);",
      "static MemoryContext CurrentDynaHashCxt = NULL;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "MemoryContextAlloc",
          "args": [
            "CurrentDynaHashCxt",
            "size"
          ],
          "line": 281
        },
        "resolved": true,
        "details": {
          "function_name": "MemoryContextAllocHuge",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2019-10128/repo/src/backend/utils/mmgr/mcxt.c",
          "lines": "1079-1106",
          "snippet": "void *\nMemoryContextAllocHuge(MemoryContext context, Size size)\n{\n\tvoid\t   *ret;\n\n\tAssertArg(MemoryContextIsValid(context));\n\tAssertNotInCriticalSection(context);\n\n\tif (!AllocHugeSizeIsValid(size))\n\t\telog(ERROR, \"invalid memory alloc request size %zu\", size);\n\n\tcontext->isReset = false;\n\n\tret = context->methods->alloc(context, size);\n\tif (unlikely(ret == NULL))\n\t{\n\t\tMemoryContextStats(TopMemoryContext);\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t errmsg(\"out of memory\"),\n\t\t\t\t errdetail(\"Failed on request of size %zu in memory context \\\"%s\\\".\",\n\t\t\t\t\t\t   size, context->name)));\n\t}\n\n\tVALGRIND_MEMPOOL_ALLOC(context, ret, size);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"utils/memutils.h\"",
            "#include \"utils/memdebug.h\"",
            "#include \"miscadmin.h\"",
            "#include \"mb/pg_wchar.h\"",
            "#include \"postgres.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "MemoryContext TopMemoryContext = NULL;",
            "static void MemoryContextCallResetCallbacks(MemoryContext context);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/memdebug.h\"\n#include \"miscadmin.h\"\n#include \"mb/pg_wchar.h\"\n#include \"postgres.h\"\n\nMemoryContext TopMemoryContext = NULL;\nstatic void MemoryContextCallResetCallbacks(MemoryContext context);\n\nvoid *\nMemoryContextAllocHuge(MemoryContext context, Size size)\n{\n\tvoid\t   *ret;\n\n\tAssertArg(MemoryContextIsValid(context));\n\tAssertNotInCriticalSection(context);\n\n\tif (!AllocHugeSizeIsValid(size))\n\t\telog(ERROR, \"invalid memory alloc request size %zu\", size);\n\n\tcontext->isReset = false;\n\n\tret = context->methods->alloc(context, size);\n\tif (unlikely(ret == NULL))\n\t{\n\t\tMemoryContextStats(TopMemoryContext);\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_OUT_OF_MEMORY),\n\t\t\t\t errmsg(\"out of memory\"),\n\t\t\t\t errdetail(\"Failed on request of size %zu in memory context \\\"%s\\\".\",\n\t\t\t\t\t\t   size, context->name)));\n\t}\n\n\tVALGRIND_MEMPOOL_ALLOC(context, ret, size);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "Assert",
          "args": [
            "MemoryContextIsValid(CurrentDynaHashCxt)"
          ],
          "line": 280
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MemoryContextIsValid",
          "args": [
            "CurrentDynaHashCxt"
          ],
          "line": 280
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"utils/memutils.h\"\n#include \"utils/dynahash.h\"\n#include \"storage/spin.h\"\n#include \"storage/shmem.h\"\n#include \"access/xact.h\"\n#include <limits.h>\n#include \"postgres.h\"\n\nstatic void *DynaHashAlloc(Size size);\nstatic MemoryContext CurrentDynaHashCxt = NULL;\n\nstatic void *\nDynaHashAlloc(Size size)\n{\n\tAssert(MemoryContextIsValid(CurrentDynaHashCxt));\n\treturn MemoryContextAlloc(CurrentDynaHashCxt, size);\n}"
  }
]