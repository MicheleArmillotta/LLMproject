[
  {
    "function_name": "nested_svm_exit_special",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "799-823",
    "snippet": "int nested_svm_exit_special(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_INTR:\n\tcase SVM_EXIT_NMI:\n\tcase SVM_EXIT_EXCP_BASE + MC_VECTOR:\n\t\treturn NESTED_EXIT_HOST;\n\tcase SVM_EXIT_NPF:\n\t\t/* For now we are always handling NPFs when using them */\n\t\tif (npt_enabled)\n\t\t\treturn NESTED_EXIT_HOST;\n\t\tbreak;\n\tcase SVM_EXIT_EXCP_BASE + PF_VECTOR:\n\t\t/* When we're shadowing, trap PFs, but not async PF */\n\t\tif (!npt_enabled && svm->vcpu.arch.apf.host_apf_reason == 0)\n\t\t\treturn NESTED_EXIT_HOST;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn NESTED_EXIT_CONTINUE;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_exit_special(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_INTR:\n\tcase SVM_EXIT_NMI:\n\tcase SVM_EXIT_EXCP_BASE + MC_VECTOR:\n\t\treturn NESTED_EXIT_HOST;\n\tcase SVM_EXIT_NPF:\n\t\t/* For now we are always handling NPFs when using them */\n\t\tif (npt_enabled)\n\t\t\treturn NESTED_EXIT_HOST;\n\t\tbreak;\n\tcase SVM_EXIT_EXCP_BASE + PF_VECTOR:\n\t\t/* When we're shadowing, trap PFs, but not async PF */\n\t\tif (!npt_enabled && svm->vcpu.arch.apf.host_apf_reason == 0)\n\t\t\treturn NESTED_EXIT_HOST;\n\t\tbreak;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn NESTED_EXIT_CONTINUE;\n}"
  },
  {
    "function_name": "svm_check_nested_events",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "783-797",
    "snippet": "int svm_check_nested_events(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\tbool block_nested_events =\n\t\tkvm_event_needs_reinjection(vcpu) || svm->nested.exit_required;\n\n\tif (kvm_cpu_has_interrupt(vcpu) && nested_exit_on_intr(svm)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tnested_svm_intr(svm);\n\t\treturn 0;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "nested_svm_intr",
          "args": [
            "svm"
          ],
          "line": 792
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_intr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "767-776",
          "snippet": "static void nested_svm_intr(struct vcpu_svm *svm)\n{\n\tsvm->vmcb->control.exit_code   = SVM_EXIT_INTR;\n\tsvm->vmcb->control.exit_info_1 = 0;\n\tsvm->vmcb->control.exit_info_2 = 0;\n\n\t/* nested_svm_vmexit this gets called afterwards from handle_exit */\n\tsvm->nested.exit_required = true;\n\ttrace_kvm_nested_intr_vmexit(svm->vmcb->save.rip);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_intr(struct vcpu_svm *svm)\n{\n\tsvm->vmcb->control.exit_code   = SVM_EXIT_INTR;\n\tsvm->vmcb->control.exit_info_1 = 0;\n\tsvm->vmcb->control.exit_info_2 = 0;\n\n\t/* nested_svm_vmexit this gets called afterwards from handle_exit */\n\tsvm->nested.exit_required = true;\n\ttrace_kvm_nested_intr_vmexit(svm->vmcb->save.rip);\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_exit_on_intr",
          "args": [
            "svm"
          ],
          "line": 789
        },
        "resolved": true,
        "details": {
          "function_name": "nested_exit_on_intr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "778-781",
          "snippet": "static bool nested_exit_on_intr(struct vcpu_svm *svm)\n{\n\treturn (svm->nested.intercept & 1ULL);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic bool nested_exit_on_intr(struct vcpu_svm *svm)\n{\n\treturn (svm->nested.intercept & 1ULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_cpu_has_interrupt",
          "args": [
            "vcpu"
          ],
          "line": 789
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_cpu_has_interrupt",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/irq.c",
          "lines": "91-111",
          "snippet": "int kvm_cpu_has_interrupt(struct kvm_vcpu *v)\n{\n\t/*\n\t * FIXME: interrupt.injected represents an interrupt that it's\n\t * side-effects have already been applied (e.g. bit from IRR\n\t * already moved to ISR). Therefore, it is incorrect to rely\n\t * on interrupt.injected to know if there is a pending\n\t * interrupt in the user-mode LAPIC.\n\t * This leads to nVMX/nSVM not be able to distinguish\n\t * if it should exit from L2 to L1 on EXTERNAL_INTERRUPT on\n\t * pending interrupt or should re-inject an injected\n\t * interrupt.\n\t */\n\tif (!lapic_in_kernel(v))\n\t\treturn v->arch.interrupt.injected;\n\n\tif (kvm_cpu_has_extint(v))\n\t\treturn 1;\n\n\treturn kvm_apic_has_interrupt(v) != -1;\t/* LAPIC */\n}",
          "includes": [
            "#include \"x86.h\"",
            "#include \"i8254.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"x86.h\"\n#include \"i8254.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n#include <linux/export.h>\n\nint kvm_cpu_has_interrupt(struct kvm_vcpu *v)\n{\n\t/*\n\t * FIXME: interrupt.injected represents an interrupt that it's\n\t * side-effects have already been applied (e.g. bit from IRR\n\t * already moved to ISR). Therefore, it is incorrect to rely\n\t * on interrupt.injected to know if there is a pending\n\t * interrupt in the user-mode LAPIC.\n\t * This leads to nVMX/nSVM not be able to distinguish\n\t * if it should exit from L2 to L1 on EXTERNAL_INTERRUPT on\n\t * pending interrupt or should re-inject an injected\n\t * interrupt.\n\t */\n\tif (!lapic_in_kernel(v))\n\t\treturn v->arch.interrupt.injected;\n\n\tif (kvm_cpu_has_extint(v))\n\t\treturn 1;\n\n\treturn kvm_apic_has_interrupt(v) != -1;\t/* LAPIC */\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_event_needs_reinjection",
          "args": [
            "vcpu"
          ],
          "line": 787
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_event_needs_reinjection",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "69-73",
          "snippet": "static inline bool kvm_event_needs_reinjection(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.exception.injected || vcpu->arch.interrupt.injected ||\n\t\tvcpu->arch.nmi_injected;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline bool kvm_event_needs_reinjection(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.exception.injected || vcpu->arch.interrupt.injected ||\n\t\tvcpu->arch.nmi_injected;\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_svm",
          "args": [
            "vcpu"
          ],
          "line": 785
        },
        "resolved": true,
        "details": {
          "function_name": "to_svm",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "192-195",
          "snippet": "static inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint svm_check_nested_events(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\tbool block_nested_events =\n\t\tkvm_event_needs_reinjection(vcpu) || svm->nested.exit_required;\n\n\tif (kvm_cpu_has_interrupt(vcpu) && nested_exit_on_intr(svm)) {\n\t\tif (block_nested_events)\n\t\t\treturn -EBUSY;\n\t\tnested_svm_intr(svm);\n\t\treturn 0;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "nested_exit_on_intr",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "778-781",
    "snippet": "static bool nested_exit_on_intr(struct vcpu_svm *svm)\n{\n\treturn (svm->nested.intercept & 1ULL);\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic bool nested_exit_on_intr(struct vcpu_svm *svm)\n{\n\treturn (svm->nested.intercept & 1ULL);\n}"
  },
  {
    "function_name": "nested_svm_intr",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "767-776",
    "snippet": "static void nested_svm_intr(struct vcpu_svm *svm)\n{\n\tsvm->vmcb->control.exit_code   = SVM_EXIT_INTR;\n\tsvm->vmcb->control.exit_info_1 = 0;\n\tsvm->vmcb->control.exit_info_2 = 0;\n\n\t/* nested_svm_vmexit this gets called afterwards from handle_exit */\n\tsvm->nested.exit_required = true;\n\ttrace_kvm_nested_intr_vmexit(svm->vmcb->save.rip);\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_kvm_nested_intr_vmexit",
          "args": [
            "svm->vmcb->save.rip"
          ],
          "line": 775
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_intr(struct vcpu_svm *svm)\n{\n\tsvm->vmcb->control.exit_code   = SVM_EXIT_INTR;\n\tsvm->vmcb->control.exit_info_1 = 0;\n\tsvm->vmcb->control.exit_info_2 = 0;\n\n\t/* nested_svm_vmexit this gets called afterwards from handle_exit */\n\tsvm->nested.exit_required = true;\n\ttrace_kvm_nested_intr_vmexit(svm->vmcb->save.rip);\n}"
  },
  {
    "function_name": "nested_svm_check_exception",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "736-765",
    "snippet": "int nested_svm_check_exception(struct vcpu_svm *svm, unsigned nr,\n\t\t\t       bool has_error_code, u32 error_code)\n{\n\tint vmexit;\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn 0;\n\n\tvmexit = nested_svm_intercept(svm);\n\tif (vmexit != NESTED_EXIT_DONE)\n\t\treturn 0;\n\n\tsvm->vmcb->control.exit_code = SVM_EXIT_EXCP_BASE + nr;\n\tsvm->vmcb->control.exit_code_hi = 0;\n\tsvm->vmcb->control.exit_info_1 = error_code;\n\n\t/*\n\t * EXITINFO2 is undefined for all exception intercepts other\n\t * than #PF.\n\t */\n\tif (svm->vcpu.arch.exception.nested_apf)\n\t\tsvm->vmcb->control.exit_info_2 = svm->vcpu.arch.apf.nested_apf_token;\n\telse if (svm->vcpu.arch.exception.has_payload)\n\t\tsvm->vmcb->control.exit_info_2 = svm->vcpu.arch.exception.payload;\n\telse\n\t\tsvm->vmcb->control.exit_info_2 = svm->vcpu.arch.cr2;\n\n\tsvm->nested.exit_required = true;\n\treturn vmexit;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "nested_svm_intercept",
          "args": [
            "svm"
          ],
          "line": 744
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_intercept",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "656-706",
          "snippet": "static int nested_svm_intercept(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\tint vmexit = NESTED_EXIT_HOST;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_MSR:\n\t\tvmexit = nested_svm_exit_handled_msr(svm);\n\t\tbreak;\n\tcase SVM_EXIT_IOIO:\n\t\tvmexit = nested_svm_intercept_ioio(svm);\n\t\tbreak;\n\tcase SVM_EXIT_READ_CR0 ... SVM_EXIT_WRITE_CR8: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_CR0);\n\t\tif (svm->nested.intercept_cr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_READ_DR0 ... SVM_EXIT_WRITE_DR7: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_DR0);\n\t\tif (svm->nested.intercept_dr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_EXCP_BASE ... SVM_EXIT_EXCP_BASE + 0x1f: {\n\t\tu32 excp_bits = 1 << (exit_code - SVM_EXIT_EXCP_BASE);\n\t\tif (svm->nested.intercept_exceptions & excp_bits) {\n\t\t\tif (exit_code == SVM_EXIT_EXCP_BASE + DB_VECTOR)\n\t\t\t\tvmexit = nested_svm_intercept_db(svm);\n\t\t\telse\n\t\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\t}\n\t\t/* async page fault always cause vmexit */\n\t\telse if ((exit_code == SVM_EXIT_EXCP_BASE + PF_VECTOR) &&\n\t\t\t svm->vcpu.arch.exception.nested_apf != 0)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_ERR: {\n\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tdefault: {\n\t\tu64 exit_bits = 1ULL << (exit_code - SVM_EXIT_INTR);\n\t\tif (svm->nested.intercept & exit_bits)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t}\n\t}\n\n\treturn vmexit;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\tint vmexit = NESTED_EXIT_HOST;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_MSR:\n\t\tvmexit = nested_svm_exit_handled_msr(svm);\n\t\tbreak;\n\tcase SVM_EXIT_IOIO:\n\t\tvmexit = nested_svm_intercept_ioio(svm);\n\t\tbreak;\n\tcase SVM_EXIT_READ_CR0 ... SVM_EXIT_WRITE_CR8: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_CR0);\n\t\tif (svm->nested.intercept_cr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_READ_DR0 ... SVM_EXIT_WRITE_DR7: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_DR0);\n\t\tif (svm->nested.intercept_dr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_EXCP_BASE ... SVM_EXIT_EXCP_BASE + 0x1f: {\n\t\tu32 excp_bits = 1 << (exit_code - SVM_EXIT_EXCP_BASE);\n\t\tif (svm->nested.intercept_exceptions & excp_bits) {\n\t\t\tif (exit_code == SVM_EXIT_EXCP_BASE + DB_VECTOR)\n\t\t\t\tvmexit = nested_svm_intercept_db(svm);\n\t\t\telse\n\t\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\t}\n\t\t/* async page fault always cause vmexit */\n\t\telse if ((exit_code == SVM_EXIT_EXCP_BASE + PF_VECTOR) &&\n\t\t\t svm->vcpu.arch.exception.nested_apf != 0)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_ERR: {\n\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tdefault: {\n\t\tu64 exit_bits = 1ULL << (exit_code - SVM_EXIT_INTR);\n\t\tif (svm->nested.intercept & exit_bits)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t}\n\t}\n\n\treturn vmexit;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_guest_mode",
          "args": [
            "&svm->vcpu"
          ],
          "line": 741
        },
        "resolved": true,
        "details": {
          "function_name": "is_guest_mode",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "170-173",
          "snippet": "static inline bool is_guest_mode(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.hflags & HF_GUEST_MASK;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline bool is_guest_mode(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.hflags & HF_GUEST_MASK;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_check_exception(struct vcpu_svm *svm, unsigned nr,\n\t\t\t       bool has_error_code, u32 error_code)\n{\n\tint vmexit;\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn 0;\n\n\tvmexit = nested_svm_intercept(svm);\n\tif (vmexit != NESTED_EXIT_DONE)\n\t\treturn 0;\n\n\tsvm->vmcb->control.exit_code = SVM_EXIT_EXCP_BASE + nr;\n\tsvm->vmcb->control.exit_code_hi = 0;\n\tsvm->vmcb->control.exit_info_1 = error_code;\n\n\t/*\n\t * EXITINFO2 is undefined for all exception intercepts other\n\t * than #PF.\n\t */\n\tif (svm->vcpu.arch.exception.nested_apf)\n\t\tsvm->vmcb->control.exit_info_2 = svm->vcpu.arch.apf.nested_apf_token;\n\telse if (svm->vcpu.arch.exception.has_payload)\n\t\tsvm->vmcb->control.exit_info_2 = svm->vcpu.arch.exception.payload;\n\telse\n\t\tsvm->vmcb->control.exit_info_2 = svm->vcpu.arch.cr2;\n\n\tsvm->nested.exit_required = true;\n\treturn vmexit;\n}"
  },
  {
    "function_name": "nested_svm_check_permissions",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "720-734",
    "snippet": "int nested_svm_check_permissions(struct vcpu_svm *svm)\n{\n\tif (!(svm->vcpu.arch.efer & EFER_SVME) ||\n\t    !is_paging(&svm->vcpu)) {\n\t\tkvm_queue_exception(&svm->vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (svm->vmcb->save.cpl) {\n\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_inject_gp",
          "args": [
            "&svm->vcpu",
            "0"
          ],
          "line": 729
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_queue_exception",
          "args": [
            "&svm->vcpu",
            "UD_VECTOR"
          ],
          "line": 724
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_queue_exception",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "563-566",
          "snippet": "void kvm_queue_exception(struct kvm_vcpu *vcpu, unsigned nr)\n{\n\tkvm_multiple_exception(vcpu, nr, false, 0, false, 0, false);\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nvoid kvm_queue_exception(struct kvm_vcpu *vcpu, unsigned nr)\n{\n\tkvm_multiple_exception(vcpu, nr, false, 0, false, 0, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_paging",
          "args": [
            "&svm->vcpu"
          ],
          "line": 723
        },
        "resolved": true,
        "details": {
          "function_name": "is_paging",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "138-141",
          "snippet": "static inline int is_paging(struct kvm_vcpu *vcpu)\n{\n\treturn likely(kvm_read_cr0_bits(vcpu, X86_CR0_PG));\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline int is_paging(struct kvm_vcpu *vcpu)\n{\n\treturn likely(kvm_read_cr0_bits(vcpu, X86_CR0_PG));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_check_permissions(struct vcpu_svm *svm)\n{\n\tif (!(svm->vcpu.arch.efer & EFER_SVME) ||\n\t    !is_paging(&svm->vcpu)) {\n\t\tkvm_queue_exception(&svm->vcpu, UD_VECTOR);\n\t\treturn 1;\n\t}\n\n\tif (svm->vmcb->save.cpl) {\n\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "nested_svm_exit_handled",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "708-718",
    "snippet": "int nested_svm_exit_handled(struct vcpu_svm *svm)\n{\n\tint vmexit;\n\n\tvmexit = nested_svm_intercept(svm);\n\n\tif (vmexit == NESTED_EXIT_DONE)\n\t\tnested_svm_vmexit(svm);\n\n\treturn vmexit;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "nested_svm_vmexit",
          "args": [
            "svm"
          ],
          "line": 715
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_vmexit",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "438-579",
          "snippet": "int nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_svm_intercept",
          "args": [
            "svm"
          ],
          "line": 712
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_intercept",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "656-706",
          "snippet": "static int nested_svm_intercept(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\tint vmexit = NESTED_EXIT_HOST;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_MSR:\n\t\tvmexit = nested_svm_exit_handled_msr(svm);\n\t\tbreak;\n\tcase SVM_EXIT_IOIO:\n\t\tvmexit = nested_svm_intercept_ioio(svm);\n\t\tbreak;\n\tcase SVM_EXIT_READ_CR0 ... SVM_EXIT_WRITE_CR8: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_CR0);\n\t\tif (svm->nested.intercept_cr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_READ_DR0 ... SVM_EXIT_WRITE_DR7: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_DR0);\n\t\tif (svm->nested.intercept_dr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_EXCP_BASE ... SVM_EXIT_EXCP_BASE + 0x1f: {\n\t\tu32 excp_bits = 1 << (exit_code - SVM_EXIT_EXCP_BASE);\n\t\tif (svm->nested.intercept_exceptions & excp_bits) {\n\t\t\tif (exit_code == SVM_EXIT_EXCP_BASE + DB_VECTOR)\n\t\t\t\tvmexit = nested_svm_intercept_db(svm);\n\t\t\telse\n\t\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\t}\n\t\t/* async page fault always cause vmexit */\n\t\telse if ((exit_code == SVM_EXIT_EXCP_BASE + PF_VECTOR) &&\n\t\t\t svm->vcpu.arch.exception.nested_apf != 0)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_ERR: {\n\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tdefault: {\n\t\tu64 exit_bits = 1ULL << (exit_code - SVM_EXIT_INTR);\n\t\tif (svm->nested.intercept & exit_bits)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t}\n\t}\n\n\treturn vmexit;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\tint vmexit = NESTED_EXIT_HOST;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_MSR:\n\t\tvmexit = nested_svm_exit_handled_msr(svm);\n\t\tbreak;\n\tcase SVM_EXIT_IOIO:\n\t\tvmexit = nested_svm_intercept_ioio(svm);\n\t\tbreak;\n\tcase SVM_EXIT_READ_CR0 ... SVM_EXIT_WRITE_CR8: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_CR0);\n\t\tif (svm->nested.intercept_cr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_READ_DR0 ... SVM_EXIT_WRITE_DR7: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_DR0);\n\t\tif (svm->nested.intercept_dr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_EXCP_BASE ... SVM_EXIT_EXCP_BASE + 0x1f: {\n\t\tu32 excp_bits = 1 << (exit_code - SVM_EXIT_EXCP_BASE);\n\t\tif (svm->nested.intercept_exceptions & excp_bits) {\n\t\t\tif (exit_code == SVM_EXIT_EXCP_BASE + DB_VECTOR)\n\t\t\t\tvmexit = nested_svm_intercept_db(svm);\n\t\t\telse\n\t\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\t}\n\t\t/* async page fault always cause vmexit */\n\t\telse if ((exit_code == SVM_EXIT_EXCP_BASE + PF_VECTOR) &&\n\t\t\t svm->vcpu.arch.exception.nested_apf != 0)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_ERR: {\n\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tdefault: {\n\t\tu64 exit_bits = 1ULL << (exit_code - SVM_EXIT_INTR);\n\t\tif (svm->nested.intercept & exit_bits)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t}\n\t}\n\n\treturn vmexit;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_exit_handled(struct vcpu_svm *svm)\n{\n\tint vmexit;\n\n\tvmexit = nested_svm_intercept(svm);\n\n\tif (vmexit == NESTED_EXIT_DONE)\n\t\tnested_svm_vmexit(svm);\n\n\treturn vmexit;\n}"
  },
  {
    "function_name": "nested_svm_intercept",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "656-706",
    "snippet": "static int nested_svm_intercept(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\tint vmexit = NESTED_EXIT_HOST;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_MSR:\n\t\tvmexit = nested_svm_exit_handled_msr(svm);\n\t\tbreak;\n\tcase SVM_EXIT_IOIO:\n\t\tvmexit = nested_svm_intercept_ioio(svm);\n\t\tbreak;\n\tcase SVM_EXIT_READ_CR0 ... SVM_EXIT_WRITE_CR8: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_CR0);\n\t\tif (svm->nested.intercept_cr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_READ_DR0 ... SVM_EXIT_WRITE_DR7: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_DR0);\n\t\tif (svm->nested.intercept_dr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_EXCP_BASE ... SVM_EXIT_EXCP_BASE + 0x1f: {\n\t\tu32 excp_bits = 1 << (exit_code - SVM_EXIT_EXCP_BASE);\n\t\tif (svm->nested.intercept_exceptions & excp_bits) {\n\t\t\tif (exit_code == SVM_EXIT_EXCP_BASE + DB_VECTOR)\n\t\t\t\tvmexit = nested_svm_intercept_db(svm);\n\t\t\telse\n\t\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\t}\n\t\t/* async page fault always cause vmexit */\n\t\telse if ((exit_code == SVM_EXIT_EXCP_BASE + PF_VECTOR) &&\n\t\t\t svm->vcpu.arch.exception.nested_apf != 0)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_ERR: {\n\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tdefault: {\n\t\tu64 exit_bits = 1ULL << (exit_code - SVM_EXIT_INTR);\n\t\tif (svm->nested.intercept & exit_bits)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t}\n\t}\n\n\treturn vmexit;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "nested_svm_intercept_db",
          "args": [
            "svm"
          ],
          "line": 684
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_intercept_db",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "607-629",
          "snippet": "static int nested_svm_intercept_db(struct vcpu_svm *svm)\n{\n\tunsigned long dr6;\n\n\t/* if we're not singlestepping, it's not ours */\n\tif (!svm->nmi_singlestep)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if it's not a singlestep exception, it's not ours */\n\tif (kvm_get_dr(&svm->vcpu, 6, &dr6))\n\t\treturn NESTED_EXIT_DONE;\n\tif (!(dr6 & DR6_BS))\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if the guest is singlestepping, it should get the vmexit */\n\tif (svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF) {\n\t\tdisable_nmi_singlestep(svm);\n\t\treturn NESTED_EXIT_DONE;\n\t}\n\n\t/* it's ours, the nested hypervisor must not see this one */\n\treturn NESTED_EXIT_HOST;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept_db(struct vcpu_svm *svm)\n{\n\tunsigned long dr6;\n\n\t/* if we're not singlestepping, it's not ours */\n\tif (!svm->nmi_singlestep)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if it's not a singlestep exception, it's not ours */\n\tif (kvm_get_dr(&svm->vcpu, 6, &dr6))\n\t\treturn NESTED_EXIT_DONE;\n\tif (!(dr6 & DR6_BS))\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if the guest is singlestepping, it should get the vmexit */\n\tif (svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF) {\n\t\tdisable_nmi_singlestep(svm);\n\t\treturn NESTED_EXIT_DONE;\n\t}\n\n\t/* it's ours, the nested hypervisor must not see this one */\n\treturn NESTED_EXIT_HOST;\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_svm_intercept_ioio",
          "args": [
            "svm"
          ],
          "line": 666
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_intercept_ioio",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "631-654",
          "snippet": "static int nested_svm_intercept_ioio(struct vcpu_svm *svm)\n{\n\tunsigned port, size, iopm_len;\n\tu16 val, mask;\n\tu8 start_bit;\n\tu64 gpa;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_IOIO_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tport = svm->vmcb->control.exit_info_1 >> 16;\n\tsize = (svm->vmcb->control.exit_info_1 & SVM_IOIO_SIZE_MASK) >>\n\t\tSVM_IOIO_SIZE_SHIFT;\n\tgpa  = svm->nested.vmcb_iopm + (port / 8);\n\tstart_bit = port % 8;\n\tiopm_len = (start_bit + size > 8) ? 2 : 1;\n\tmask = (0xf >> (4 - size)) << start_bit;\n\tval = 0;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, gpa, &val, iopm_len))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (val & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept_ioio(struct vcpu_svm *svm)\n{\n\tunsigned port, size, iopm_len;\n\tu16 val, mask;\n\tu8 start_bit;\n\tu64 gpa;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_IOIO_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tport = svm->vmcb->control.exit_info_1 >> 16;\n\tsize = (svm->vmcb->control.exit_info_1 & SVM_IOIO_SIZE_MASK) >>\n\t\tSVM_IOIO_SIZE_SHIFT;\n\tgpa  = svm->nested.vmcb_iopm + (port / 8);\n\tstart_bit = port % 8;\n\tiopm_len = (start_bit + size > 8) ? 2 : 1;\n\tmask = (0xf >> (4 - size)) << start_bit;\n\tval = 0;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, gpa, &val, iopm_len))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (val & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_svm_exit_handled_msr",
          "args": [
            "svm"
          ],
          "line": 663
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_exit_handled_msr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "581-604",
          "snippet": "static int nested_svm_exit_handled_msr(struct vcpu_svm *svm)\n{\n\tu32 offset, msr, value;\n\tint write, mask;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tmsr    = svm->vcpu.arch.regs[VCPU_REGS_RCX];\n\toffset = svm_msrpm_offset(msr);\n\twrite  = svm->vmcb->control.exit_info_1 & 1;\n\tmask   = 1 << ((2 * (msr & 0xf)) + write);\n\n\tif (offset == MSR_INVALID)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* Offset is in 32 bit units but need in 8 bit units */\n\toffset *= 4;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, svm->nested.vmcb_msrpm + offset, &value, 4))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (value & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_exit_handled_msr(struct vcpu_svm *svm)\n{\n\tu32 offset, msr, value;\n\tint write, mask;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tmsr    = svm->vcpu.arch.regs[VCPU_REGS_RCX];\n\toffset = svm_msrpm_offset(msr);\n\twrite  = svm->vmcb->control.exit_info_1 & 1;\n\tmask   = 1 << ((2 * (msr & 0xf)) + write);\n\n\tif (offset == MSR_INVALID)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* Offset is in 32 bit units but need in 8 bit units */\n\toffset *= 4;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, svm->nested.vmcb_msrpm + offset, &value, 4))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (value & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept(struct vcpu_svm *svm)\n{\n\tu32 exit_code = svm->vmcb->control.exit_code;\n\tint vmexit = NESTED_EXIT_HOST;\n\n\tswitch (exit_code) {\n\tcase SVM_EXIT_MSR:\n\t\tvmexit = nested_svm_exit_handled_msr(svm);\n\t\tbreak;\n\tcase SVM_EXIT_IOIO:\n\t\tvmexit = nested_svm_intercept_ioio(svm);\n\t\tbreak;\n\tcase SVM_EXIT_READ_CR0 ... SVM_EXIT_WRITE_CR8: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_CR0);\n\t\tif (svm->nested.intercept_cr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_READ_DR0 ... SVM_EXIT_WRITE_DR7: {\n\t\tu32 bit = 1U << (exit_code - SVM_EXIT_READ_DR0);\n\t\tif (svm->nested.intercept_dr & bit)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_EXCP_BASE ... SVM_EXIT_EXCP_BASE + 0x1f: {\n\t\tu32 excp_bits = 1 << (exit_code - SVM_EXIT_EXCP_BASE);\n\t\tif (svm->nested.intercept_exceptions & excp_bits) {\n\t\t\tif (exit_code == SVM_EXIT_EXCP_BASE + DB_VECTOR)\n\t\t\t\tvmexit = nested_svm_intercept_db(svm);\n\t\t\telse\n\t\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\t}\n\t\t/* async page fault always cause vmexit */\n\t\telse if ((exit_code == SVM_EXIT_EXCP_BASE + PF_VECTOR) &&\n\t\t\t svm->vcpu.arch.exception.nested_apf != 0)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tcase SVM_EXIT_ERR: {\n\t\tvmexit = NESTED_EXIT_DONE;\n\t\tbreak;\n\t}\n\tdefault: {\n\t\tu64 exit_bits = 1ULL << (exit_code - SVM_EXIT_INTR);\n\t\tif (svm->nested.intercept & exit_bits)\n\t\t\tvmexit = NESTED_EXIT_DONE;\n\t}\n\t}\n\n\treturn vmexit;\n}"
  },
  {
    "function_name": "nested_svm_intercept_ioio",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "631-654",
    "snippet": "static int nested_svm_intercept_ioio(struct vcpu_svm *svm)\n{\n\tunsigned port, size, iopm_len;\n\tu16 val, mask;\n\tu8 start_bit;\n\tu64 gpa;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_IOIO_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tport = svm->vmcb->control.exit_info_1 >> 16;\n\tsize = (svm->vmcb->control.exit_info_1 & SVM_IOIO_SIZE_MASK) >>\n\t\tSVM_IOIO_SIZE_SHIFT;\n\tgpa  = svm->nested.vmcb_iopm + (port / 8);\n\tstart_bit = port % 8;\n\tiopm_len = (start_bit + size > 8) ? 2 : 1;\n\tmask = (0xf >> (4 - size)) << start_bit;\n\tval = 0;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, gpa, &val, iopm_len))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (val & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest",
          "args": [
            "&svm->vcpu",
            "gpa",
            "&val",
            "iopm_len"
          ],
          "line": 650
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept_ioio(struct vcpu_svm *svm)\n{\n\tunsigned port, size, iopm_len;\n\tu16 val, mask;\n\tu8 start_bit;\n\tu64 gpa;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_IOIO_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tport = svm->vmcb->control.exit_info_1 >> 16;\n\tsize = (svm->vmcb->control.exit_info_1 & SVM_IOIO_SIZE_MASK) >>\n\t\tSVM_IOIO_SIZE_SHIFT;\n\tgpa  = svm->nested.vmcb_iopm + (port / 8);\n\tstart_bit = port % 8;\n\tiopm_len = (start_bit + size > 8) ? 2 : 1;\n\tmask = (0xf >> (4 - size)) << start_bit;\n\tval = 0;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, gpa, &val, iopm_len))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (val & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}"
  },
  {
    "function_name": "nested_svm_intercept_db",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "607-629",
    "snippet": "static int nested_svm_intercept_db(struct vcpu_svm *svm)\n{\n\tunsigned long dr6;\n\n\t/* if we're not singlestepping, it's not ours */\n\tif (!svm->nmi_singlestep)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if it's not a singlestep exception, it's not ours */\n\tif (kvm_get_dr(&svm->vcpu, 6, &dr6))\n\t\treturn NESTED_EXIT_DONE;\n\tif (!(dr6 & DR6_BS))\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if the guest is singlestepping, it should get the vmexit */\n\tif (svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF) {\n\t\tdisable_nmi_singlestep(svm);\n\t\treturn NESTED_EXIT_DONE;\n\t}\n\n\t/* it's ours, the nested hypervisor must not see this one */\n\treturn NESTED_EXIT_HOST;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "disable_nmi_singlestep",
          "args": [
            "svm"
          ],
          "line": 623
        },
        "resolved": true,
        "details": {
          "function_name": "disable_nmi_singlestep",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "843-854",
          "snippet": "void disable_nmi_singlestep(struct vcpu_svm *svm)\n{\n\tsvm->nmi_singlestep = false;\n\n\tif (!(svm->vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP)) {\n\t\t/* Clear our flags if they were not set by the guest */\n\t\tif (!(svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF))\n\t\t\tsvm->vmcb->save.rflags &= ~X86_EFLAGS_TF;\n\t\tif (!(svm->nmi_singlestep_guest_rflags & X86_EFLAGS_RF))\n\t\t\tsvm->vmcb->save.rflags &= ~X86_EFLAGS_RF;\n\t}\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void svm_complete_interrupts(struct vcpu_svm *svm);",
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void svm_complete_interrupts(struct vcpu_svm *svm);\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nvoid disable_nmi_singlestep(struct vcpu_svm *svm)\n{\n\tsvm->nmi_singlestep = false;\n\n\tif (!(svm->vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP)) {\n\t\t/* Clear our flags if they were not set by the guest */\n\t\tif (!(svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF))\n\t\t\tsvm->vmcb->save.rflags &= ~X86_EFLAGS_TF;\n\t\tif (!(svm->nmi_singlestep_guest_rflags & X86_EFLAGS_RF))\n\t\t\tsvm->vmcb->save.rflags &= ~X86_EFLAGS_RF;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_get_dr",
          "args": [
            "&svm->vcpu",
            "6",
            "&dr6"
          ],
          "line": 616
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_get_dr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "1131-1154",
          "snippet": "int kvm_get_dr(struct kvm_vcpu *vcpu, int dr, unsigned long *val)\n{\n\tsize_t size = ARRAY_SIZE(vcpu->arch.db);\n\n\tswitch (dr) {\n\tcase 0 ... 3:\n\t\t*val = vcpu->arch.db[array_index_nospec(dr, size)];\n\t\tbreak;\n\tcase 4:\n\t\t/* fall through */\n\tcase 6:\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP)\n\t\t\t*val = vcpu->arch.dr6;\n\t\telse\n\t\t\t*val = kvm_x86_ops.get_dr6(vcpu);\n\t\tbreak;\n\tcase 5:\n\t\t/* fall through */\n\tdefault: /* 7 */\n\t\t*val = vcpu->arch.dr7;\n\t\tbreak;\n\t}\n\treturn 0;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nint kvm_get_dr(struct kvm_vcpu *vcpu, int dr, unsigned long *val)\n{\n\tsize_t size = ARRAY_SIZE(vcpu->arch.db);\n\n\tswitch (dr) {\n\tcase 0 ... 3:\n\t\t*val = vcpu->arch.db[array_index_nospec(dr, size)];\n\t\tbreak;\n\tcase 4:\n\t\t/* fall through */\n\tcase 6:\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP)\n\t\t\t*val = vcpu->arch.dr6;\n\t\telse\n\t\t\t*val = kvm_x86_ops.get_dr6(vcpu);\n\t\tbreak;\n\tcase 5:\n\t\t/* fall through */\n\tdefault: /* 7 */\n\t\t*val = vcpu->arch.dr7;\n\t\tbreak;\n\t}\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_intercept_db(struct vcpu_svm *svm)\n{\n\tunsigned long dr6;\n\n\t/* if we're not singlestepping, it's not ours */\n\tif (!svm->nmi_singlestep)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if it's not a singlestep exception, it's not ours */\n\tif (kvm_get_dr(&svm->vcpu, 6, &dr6))\n\t\treturn NESTED_EXIT_DONE;\n\tif (!(dr6 & DR6_BS))\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* if the guest is singlestepping, it should get the vmexit */\n\tif (svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF) {\n\t\tdisable_nmi_singlestep(svm);\n\t\treturn NESTED_EXIT_DONE;\n\t}\n\n\t/* it's ours, the nested hypervisor must not see this one */\n\treturn NESTED_EXIT_HOST;\n}"
  },
  {
    "function_name": "nested_svm_exit_handled_msr",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "581-604",
    "snippet": "static int nested_svm_exit_handled_msr(struct vcpu_svm *svm)\n{\n\tu32 offset, msr, value;\n\tint write, mask;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tmsr    = svm->vcpu.arch.regs[VCPU_REGS_RCX];\n\toffset = svm_msrpm_offset(msr);\n\twrite  = svm->vmcb->control.exit_info_1 & 1;\n\tmask   = 1 << ((2 * (msr & 0xf)) + write);\n\n\tif (offset == MSR_INVALID)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* Offset is in 32 bit units but need in 8 bit units */\n\toffset *= 4;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, svm->nested.vmcb_msrpm + offset, &value, 4))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (value & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest",
          "args": [
            "&svm->vcpu",
            "svm->nested.vmcb_msrpm + offset",
            "&value",
            "4"
          ],
          "line": 600
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "svm_msrpm_offset",
          "args": [
            "msr"
          ],
          "line": 590
        },
        "resolved": true,
        "details": {
          "function_name": "svm_msrpm_offset",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "365-384",
          "snippet": "u32 svm_msrpm_offset(u32 msr)\n{\n\tu32 offset;\n\tint i;\n\n\tfor (i = 0; i < NUM_MSR_MAPS; i++) {\n\t\tif (msr < msrpm_ranges[i] ||\n\t\t    msr >= msrpm_ranges[i] + MSRS_IN_RANGE)\n\t\t\tcontinue;\n\n\t\toffset  = (msr - msrpm_ranges[i]) / 4; /* 4 msrs per u8 */\n\t\toffset += (i * MSRS_RANGE_SIZE);       /* add range offset */\n\n\t\t/* Now we have the u8 offset - but need the u32 offset */\n\t\treturn offset / 4;\n\t}\n\n\t/* MSR not in any range */\n\treturn MSR_INVALID;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define MSRS_IN_RANGE (MSRS_RANGE_SIZE * 8 / 2)",
            "#define MSRS_RANGE_SIZE 2048",
            "#define NUM_MSR_MAPS ARRAY_SIZE(msrpm_ranges)"
          ],
          "globals_used": [
            "static const u32 msrpm_ranges[] = {0, 0xc0000000, 0xc0010000};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\n#define MSRS_IN_RANGE (MSRS_RANGE_SIZE * 8 / 2)\n#define MSRS_RANGE_SIZE 2048\n#define NUM_MSR_MAPS ARRAY_SIZE(msrpm_ranges)\n\nstatic const u32 msrpm_ranges[] = {0, 0xc0000000, 0xc0010000};\n\nu32 svm_msrpm_offset(u32 msr)\n{\n\tu32 offset;\n\tint i;\n\n\tfor (i = 0; i < NUM_MSR_MAPS; i++) {\n\t\tif (msr < msrpm_ranges[i] ||\n\t\t    msr >= msrpm_ranges[i] + MSRS_IN_RANGE)\n\t\t\tcontinue;\n\n\t\toffset  = (msr - msrpm_ranges[i]) / 4; /* 4 msrs per u8 */\n\t\toffset += (i * MSRS_RANGE_SIZE);       /* add range offset */\n\n\t\t/* Now we have the u8 offset - but need the u32 offset */\n\t\treturn offset / 4;\n\t}\n\n\t/* MSR not in any range */\n\treturn MSR_INVALID;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic int nested_svm_exit_handled_msr(struct vcpu_svm *svm)\n{\n\tu32 offset, msr, value;\n\tint write, mask;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn NESTED_EXIT_HOST;\n\n\tmsr    = svm->vcpu.arch.regs[VCPU_REGS_RCX];\n\toffset = svm_msrpm_offset(msr);\n\twrite  = svm->vmcb->control.exit_info_1 & 1;\n\tmask   = 1 << ((2 * (msr & 0xf)) + write);\n\n\tif (offset == MSR_INVALID)\n\t\treturn NESTED_EXIT_DONE;\n\n\t/* Offset is in 32 bit units but need in 8 bit units */\n\toffset *= 4;\n\n\tif (kvm_vcpu_read_guest(&svm->vcpu, svm->nested.vmcb_msrpm + offset, &value, 4))\n\t\treturn NESTED_EXIT_DONE;\n\n\treturn (value & mask) ? NESTED_EXIT_DONE : NESTED_EXIT_HOST;\n}"
  },
  {
    "function_name": "nested_svm_vmexit",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "438-579",
    "snippet": "int nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_clear_interrupt_queue",
          "args": [
            "&svm->vcpu"
          ],
          "line": 576
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_clear_interrupt_queue",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "64-67",
          "snippet": "static inline void kvm_clear_interrupt_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.interrupt.injected = false;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_clear_interrupt_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.interrupt.injected = false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_clear_exception_queue",
          "args": [
            "&svm->vcpu"
          ],
          "line": 575
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_clear_exception_queue",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "50-54",
          "snippet": "static inline void kvm_clear_exception_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.exception.pending = false;\n\tvcpu->arch.exception.injected = false;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_clear_exception_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.exception.pending = false;\n\tvcpu->arch.exception.injected = false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_mmu_load",
          "args": [
            "&svm->vcpu"
          ],
          "line": 568
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_load_pgd",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "98-103",
          "snippet": "static inline void kvm_mmu_load_pgd(struct kvm_vcpu *vcpu)\n{\n\tif (VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\tkvm_x86_ops.load_mmu_pgd(vcpu, vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu));\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_mmu_load_pgd(struct kvm_vcpu *vcpu)\n{\n\tif (VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\tkvm_x86_ops.load_mmu_pgd(vcpu, vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu));\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_mmu_reset_context",
          "args": [
            "&svm->vcpu"
          ],
          "line": 567
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_reset_context",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "5167-5171",
          "snippet": "void kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nvoid kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_svm_uninit_mmu_context",
          "args": [
            "&svm->vcpu"
          ],
          "line": 566
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_uninit_mmu_context",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "93-97",
          "snippet": "static void nested_svm_uninit_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.mmu = &vcpu->arch.root_mmu;\n\tvcpu->arch.walk_mmu = &vcpu->arch.root_mmu;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_uninit_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.mmu = &vcpu->arch.root_mmu;\n\tvcpu->arch.walk_mmu = &vcpu->arch.root_mmu;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_unmap",
          "args": [
            "&svm->vcpu",
            "&map",
            "true"
          ],
          "line": 564
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mark_all_dirty",
          "args": [
            "svm->vmcb"
          ],
          "line": 562
        },
        "resolved": true,
        "details": {
          "function_name": "mark_all_dirty",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "176-179",
          "snippet": "static inline void mark_all_dirty(struct vmcb *vmcb)\n{\n\tvmcb->control.clean = 0;\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline void mark_all_dirty(struct vmcb *vmcb)\n{\n\tvmcb->control.clean = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rip_write",
          "args": [
            "&svm->vcpu",
            "hsave->save.rip"
          ],
          "line": 557
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_rip_write",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "91-94",
          "snippet": "static inline void kvm_rip_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RIP, val);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline void kvm_rip_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RIP, val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rsp_write",
          "args": [
            "&svm->vcpu",
            "hsave->save.rsp"
          ],
          "line": 556
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_rsp_write",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "101-104",
          "snippet": "static inline void kvm_rsp_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RSP, val);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline void kvm_rsp_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RSP, val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rax_write",
          "args": [
            "&svm->vcpu",
            "hsave->save.rax"
          ],
          "line": 555
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_set_cr3",
          "args": [
            "&svm->vcpu",
            "hsave->save.cr3"
          ],
          "line": 553
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_set_cr3",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "994-1026",
          "snippet": "int kvm_set_cr3(struct kvm_vcpu *vcpu, unsigned long cr3)\n{\n\tbool skip_tlb_flush = false;\n#ifdef CONFIG_X86_64\n\tbool pcid_enabled = kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE);\n\n\tif (pcid_enabled) {\n\t\tskip_tlb_flush = cr3 & X86_CR3_PCID_NOFLUSH;\n\t\tcr3 &= ~X86_CR3_PCID_NOFLUSH;\n\t}\n#endif\n\n\tif (cr3 == kvm_read_cr3(vcpu) && !pdptrs_changed(vcpu)) {\n\t\tif (!skip_tlb_flush) {\n\t\t\tkvm_mmu_sync_roots(vcpu);\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (is_long_mode(vcpu) &&\n\t    (cr3 & rsvd_bits(cpuid_maxphyaddr(vcpu), 63)))\n\t\treturn 1;\n\telse if (is_pae_paging(vcpu) &&\n\t\t !load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))\n\t\treturn 1;\n\n\tkvm_mmu_new_cr3(vcpu, cr3, skip_tlb_flush);\n\tvcpu->arch.cr3 = cr3;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR3);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nint kvm_set_cr3(struct kvm_vcpu *vcpu, unsigned long cr3)\n{\n\tbool skip_tlb_flush = false;\n#ifdef CONFIG_X86_64\n\tbool pcid_enabled = kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE);\n\n\tif (pcid_enabled) {\n\t\tskip_tlb_flush = cr3 & X86_CR3_PCID_NOFLUSH;\n\t\tcr3 &= ~X86_CR3_PCID_NOFLUSH;\n\t}\n#endif\n\n\tif (cr3 == kvm_read_cr3(vcpu) && !pdptrs_changed(vcpu)) {\n\t\tif (!skip_tlb_flush) {\n\t\t\tkvm_mmu_sync_roots(vcpu);\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (is_long_mode(vcpu) &&\n\t    (cr3 & rsvd_bits(cpuid_maxphyaddr(vcpu), 63)))\n\t\treturn 1;\n\telse if (is_pae_paging(vcpu) &&\n\t\t !load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))\n\t\treturn 1;\n\n\tkvm_mmu_new_cr3(vcpu, cr3, skip_tlb_flush);\n\tvcpu->arch.cr3 = cr3;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR3);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "svm_set_cr4",
          "args": [
            "&svm->vcpu",
            "hsave->save.cr4"
          ],
          "line": 548
        },
        "resolved": true,
        "details": {
          "function_name": "svm_set_cr4",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "2331-2349",
          "snippet": "int svm_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4)\n{\n\tunsigned long host_cr4_mce = cr4_read_shadow() & X86_CR4_MCE;\n\tunsigned long old_cr4 = to_svm(vcpu)->vmcb->save.cr4;\n\n\tif (cr4 & X86_CR4_VMXE)\n\t\treturn 1;\n\n\tif (npt_enabled && ((old_cr4 ^ cr4) & X86_CR4_PGE))\n\t\tsvm_flush_tlb(vcpu, true);\n\n\tvcpu->arch.cr4 = cr4;\n\tif (!npt_enabled)\n\t\tcr4 |= X86_CR4_PAE;\n\tcr4 |= host_cr4_mce;\n\tto_svm(vcpu)->vmcb->save.cr4 = cr4;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n\treturn 0;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nint svm_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4)\n{\n\tunsigned long host_cr4_mce = cr4_read_shadow() & X86_CR4_MCE;\n\tunsigned long old_cr4 = to_svm(vcpu)->vmcb->save.cr4;\n\n\tif (cr4 & X86_CR4_VMXE)\n\t\treturn 1;\n\n\tif (npt_enabled && ((old_cr4 ^ cr4) & X86_CR4_PGE))\n\t\tsvm_flush_tlb(vcpu, true);\n\n\tvcpu->arch.cr4 = cr4;\n\tif (!npt_enabled)\n\t\tcr4 |= X86_CR4_PAE;\n\tcr4 |= host_cr4_mce;\n\tto_svm(vcpu)->vmcb->save.cr4 = cr4;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "svm_set_cr0",
          "args": [
            "&svm->vcpu",
            "hsave->save.cr0 | X86_CR0_PE"
          ],
          "line": 547
        },
        "resolved": true,
        "details": {
          "function_name": "svm_set_cr0",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "2297-2329",
          "snippet": "void svm_set_cr0(struct kvm_vcpu *vcpu, unsigned long cr0)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n#ifdef CONFIG_X86_64\n\tif (vcpu->arch.efer & EFER_LME) {\n\t\tif (!is_paging(vcpu) && (cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer |= EFER_LMA;\n\t\t\tsvm->vmcb->save.efer |= EFER_LMA | EFER_LME;\n\t\t}\n\n\t\tif (is_paging(vcpu) && !(cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer &= ~EFER_LMA;\n\t\t\tsvm->vmcb->save.efer &= ~(EFER_LMA | EFER_LME);\n\t\t}\n\t}\n#endif\n\tvcpu->arch.cr0 = cr0;\n\n\tif (!npt_enabled)\n\t\tcr0 |= X86_CR0_PG | X86_CR0_WP;\n\n\t/*\n\t * re-enable caching here because the QEMU bios\n\t * does not do it - this results in some delay at\n\t * reboot\n\t */\n\tif (kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_CD_NW_CLEARED))\n\t\tcr0 &= ~(X86_CR0_CD | X86_CR0_NW);\n\tsvm->vmcb->save.cr0 = cr0;\n\tmark_dirty(svm->vmcb, VMCB_CR);\n\tupdate_cr0_intercept(svm);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void svm_complete_interrupts(struct vcpu_svm *svm);",
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void svm_complete_interrupts(struct vcpu_svm *svm);\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nvoid svm_set_cr0(struct kvm_vcpu *vcpu, unsigned long cr0)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n#ifdef CONFIG_X86_64\n\tif (vcpu->arch.efer & EFER_LME) {\n\t\tif (!is_paging(vcpu) && (cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer |= EFER_LMA;\n\t\t\tsvm->vmcb->save.efer |= EFER_LMA | EFER_LME;\n\t\t}\n\n\t\tif (is_paging(vcpu) && !(cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer &= ~EFER_LMA;\n\t\t\tsvm->vmcb->save.efer &= ~(EFER_LMA | EFER_LME);\n\t\t}\n\t}\n#endif\n\tvcpu->arch.cr0 = cr0;\n\n\tif (!npt_enabled)\n\t\tcr0 |= X86_CR0_PG | X86_CR0_WP;\n\n\t/*\n\t * re-enable caching here because the QEMU bios\n\t * does not do it - this results in some delay at\n\t * reboot\n\t */\n\tif (kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_CD_NW_CLEARED))\n\t\tcr0 &= ~(X86_CR0_CD | X86_CR0_NW);\n\tsvm->vmcb->save.cr0 = cr0;\n\tmark_dirty(svm->vmcb, VMCB_CR);\n\tupdate_cr0_intercept(svm);\n}"
        }
      },
      {
        "call_info": {
          "callee": "svm_set_efer",
          "args": [
            "&svm->vcpu",
            "hsave->save.efer"
          ],
          "line": 546
        },
        "resolved": true,
        "details": {
          "function_name": "svm_set_efer",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "412-426",
          "snippet": "void svm_set_efer(struct kvm_vcpu *vcpu, u64 efer)\n{\n\tvcpu->arch.efer = efer;\n\n\tif (!npt_enabled) {\n\t\t/* Shadow paging assumes NX to be available.  */\n\t\tefer |= EFER_NX;\n\n\t\tif (!(efer & EFER_LMA))\n\t\t\tefer &= ~EFER_LME;\n\t}\n\n\tto_svm(vcpu)->vmcb->save.efer = efer | EFER_SVME;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nvoid svm_set_efer(struct kvm_vcpu *vcpu, u64 efer)\n{\n\tvcpu->arch.efer = efer;\n\n\tif (!npt_enabled) {\n\t\t/* Shadow paging assumes NX to be available.  */\n\t\tefer |= EFER_NX;\n\n\t\tif (!(efer & EFER_LMA))\n\t\t\tefer &= ~EFER_LME;\n\t}\n\n\tto_svm(vcpu)->vmcb->save.efer = efer | EFER_SVME;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_set_rflags",
          "args": [
            "&svm->vcpu",
            "hsave->save.rflags"
          ],
          "line": 545
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_set_rflags",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "10240-10244",
          "snippet": "void kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)\n{\n\t__kvm_set_rflags(vcpu, rflags);\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nvoid kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)\n{\n\t__kvm_set_rflags(vcpu, rflags);\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_vmcb_control_area",
          "args": [
            "vmcb",
            "hsave"
          ],
          "line": 530
        },
        "resolved": true,
        "details": {
          "function_name": "copy_vmcb_control_area",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "140-170",
          "snippet": "static void copy_vmcb_control_area(struct vmcb *dst_vmcb, struct vmcb *from_vmcb)\n{\n\tstruct vmcb_control_area *dst  = &dst_vmcb->control;\n\tstruct vmcb_control_area *from = &from_vmcb->control;\n\n\tdst->intercept_cr         = from->intercept_cr;\n\tdst->intercept_dr         = from->intercept_dr;\n\tdst->intercept_exceptions = from->intercept_exceptions;\n\tdst->intercept            = from->intercept;\n\tdst->iopm_base_pa         = from->iopm_base_pa;\n\tdst->msrpm_base_pa        = from->msrpm_base_pa;\n\tdst->tsc_offset           = from->tsc_offset;\n\tdst->asid                 = from->asid;\n\tdst->tlb_ctl              = from->tlb_ctl;\n\tdst->int_ctl              = from->int_ctl;\n\tdst->int_vector           = from->int_vector;\n\tdst->int_state            = from->int_state;\n\tdst->exit_code            = from->exit_code;\n\tdst->exit_code_hi         = from->exit_code_hi;\n\tdst->exit_info_1          = from->exit_info_1;\n\tdst->exit_info_2          = from->exit_info_2;\n\tdst->exit_int_info        = from->exit_int_info;\n\tdst->exit_int_info_err    = from->exit_int_info_err;\n\tdst->nested_ctl           = from->nested_ctl;\n\tdst->event_inj            = from->event_inj;\n\tdst->event_inj_err        = from->event_inj_err;\n\tdst->nested_cr3           = from->nested_cr3;\n\tdst->virt_ext              = from->virt_ext;\n\tdst->pause_filter_count   = from->pause_filter_count;\n\tdst->pause_filter_thresh  = from->pause_filter_thresh;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void copy_vmcb_control_area(struct vmcb *dst_vmcb, struct vmcb *from_vmcb)\n{\n\tstruct vmcb_control_area *dst  = &dst_vmcb->control;\n\tstruct vmcb_control_area *from = &from_vmcb->control;\n\n\tdst->intercept_cr         = from->intercept_cr;\n\tdst->intercept_dr         = from->intercept_dr;\n\tdst->intercept_exceptions = from->intercept_exceptions;\n\tdst->intercept            = from->intercept;\n\tdst->iopm_base_pa         = from->iopm_base_pa;\n\tdst->msrpm_base_pa        = from->msrpm_base_pa;\n\tdst->tsc_offset           = from->tsc_offset;\n\tdst->asid                 = from->asid;\n\tdst->tlb_ctl              = from->tlb_ctl;\n\tdst->int_ctl              = from->int_ctl;\n\tdst->int_vector           = from->int_vector;\n\tdst->int_state            = from->int_state;\n\tdst->exit_code            = from->exit_code;\n\tdst->exit_code_hi         = from->exit_code_hi;\n\tdst->exit_info_1          = from->exit_info_1;\n\tdst->exit_info_2          = from->exit_info_2;\n\tdst->exit_int_info        = from->exit_int_info;\n\tdst->exit_int_info_err    = from->exit_int_info_err;\n\tdst->nested_ctl           = from->nested_ctl;\n\tdst->event_inj            = from->event_inj;\n\tdst->event_inj_err        = from->event_inj_err;\n\tdst->nested_cr3           = from->nested_cr3;\n\tdst->virt_ext              = from->virt_ext;\n\tdst->pause_filter_count   = from->pause_filter_count;\n\tdst->pause_filter_thresh  = from->pause_filter_thresh;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_get_rflags",
          "args": [
            "&svm->vcpu"
          ],
          "line": 480
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_get_rflags",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "10221-10229",
          "snippet": "unsigned long kvm_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags;\n\n\trflags = kvm_x86_ops.get_rflags(vcpu);\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\trflags &= ~X86_EFLAGS_TF;\n\treturn rflags;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nunsigned long kvm_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags;\n\n\trflags = kvm_x86_ops.get_rflags(vcpu);\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\trflags &= ~X86_EFLAGS_TF;\n\treturn rflags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_read_cr3",
          "args": [
            "&svm->vcpu"
          ],
          "line": 477
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr3",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "137-142",
          "snippet": "static inline ulong kvm_read_cr3(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tkvm_x86_ops.cache_reg(vcpu, VCPU_EXREG_CR3);\n\treturn vcpu->arch.cr3;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline ulong kvm_read_cr3(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tkvm_x86_ops.cache_reg(vcpu, VCPU_EXREG_CR3);\n\treturn vcpu->arch.cr3;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_read_cr0",
          "args": [
            "&svm->vcpu"
          ],
          "line": 476
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr0",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "124-127",
          "snippet": "static inline ulong kvm_read_cr0(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, ~0UL);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline ulong kvm_read_cr0(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, ~0UL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "disable_gif",
          "args": [
            "svm"
          ],
          "line": 467
        },
        "resolved": true,
        "details": {
          "function_name": "disable_gif",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "317-323",
          "snippet": "static inline void disable_gif(struct vcpu_svm *svm)\n{\n\tif (vgif_enabled(svm))\n\t\tsvm->vmcb->control.int_ctl &= ~V_GIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_GIF_MASK;\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline void disable_gif(struct vcpu_svm *svm)\n{\n\tif (vgif_enabled(svm))\n\t\tsvm->vmcb->control.int_ctl &= ~V_GIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_GIF_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "leave_guest_mode",
          "args": [
            "&svm->vcpu"
          ],
          "line": 463
        },
        "resolved": true,
        "details": {
          "function_name": "leave_guest_mode",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "160-168",
          "snippet": "static inline void leave_guest_mode(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.hflags &= ~HF_GUEST_MASK;\n\n\tif (vcpu->arch.load_eoi_exitmap_pending) {\n\t\tvcpu->arch.load_eoi_exitmap_pending = false;\n\t\tkvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);\n\t}\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline void leave_guest_mode(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.hflags &= ~HF_GUEST_MASK;\n\n\tif (vcpu->arch.load_eoi_exitmap_pending) {\n\t\tvcpu->arch.load_eoi_exitmap_pending = false;\n\t\tkvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_inject_gp",
          "args": [
            "&svm->vcpu",
            "0"
          ],
          "line": 456
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_map",
          "args": [
            "&svm->vcpu",
            "gpa_to_gfn(svm->nested.vmcb)",
            "&map"
          ],
          "line": 453
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpa_to_gfn",
          "args": [
            "svm->nested.vmcb"
          ],
          "line": 453
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_nested_vmexit_inject",
          "args": [
            "vmcb->control.exit_code",
            "vmcb->control.exit_info_1",
            "vmcb->control.exit_info_2",
            "vmcb->control.exit_int_info",
            "vmcb->control.exit_int_info_err",
            "KVM_ISA_SVM"
          ],
          "line": 446
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "nested_svm_vmloadsave",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "422-436",
    "snippet": "void nested_svm_vmloadsave(struct vmcb *from_vmcb, struct vmcb *to_vmcb)\n{\n\tto_vmcb->save.fs = from_vmcb->save.fs;\n\tto_vmcb->save.gs = from_vmcb->save.gs;\n\tto_vmcb->save.tr = from_vmcb->save.tr;\n\tto_vmcb->save.ldtr = from_vmcb->save.ldtr;\n\tto_vmcb->save.kernel_gs_base = from_vmcb->save.kernel_gs_base;\n\tto_vmcb->save.star = from_vmcb->save.star;\n\tto_vmcb->save.lstar = from_vmcb->save.lstar;\n\tto_vmcb->save.cstar = from_vmcb->save.cstar;\n\tto_vmcb->save.sfmask = from_vmcb->save.sfmask;\n\tto_vmcb->save.sysenter_cs = from_vmcb->save.sysenter_cs;\n\tto_vmcb->save.sysenter_esp = from_vmcb->save.sysenter_esp;\n\tto_vmcb->save.sysenter_eip = from_vmcb->save.sysenter_eip;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nvoid nested_svm_vmloadsave(struct vmcb *from_vmcb, struct vmcb *to_vmcb)\n{\n\tto_vmcb->save.fs = from_vmcb->save.fs;\n\tto_vmcb->save.gs = from_vmcb->save.gs;\n\tto_vmcb->save.tr = from_vmcb->save.tr;\n\tto_vmcb->save.ldtr = from_vmcb->save.ldtr;\n\tto_vmcb->save.kernel_gs_base = from_vmcb->save.kernel_gs_base;\n\tto_vmcb->save.star = from_vmcb->save.star;\n\tto_vmcb->save.lstar = from_vmcb->save.lstar;\n\tto_vmcb->save.cstar = from_vmcb->save.cstar;\n\tto_vmcb->save.sfmask = from_vmcb->save.sfmask;\n\tto_vmcb->save.sysenter_cs = from_vmcb->save.sysenter_cs;\n\tto_vmcb->save.sysenter_esp = from_vmcb->save.sysenter_esp;\n\tto_vmcb->save.sysenter_eip = from_vmcb->save.sysenter_eip;\n}"
  },
  {
    "function_name": "nested_svm_vmrun",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "335-420",
    "snippet": "int nested_svm_vmrun(struct vcpu_svm *svm)\n{\n\tint ret;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\tu64 vmcb_gpa;\n\n\tvmcb_gpa = svm->vmcb->save.rax;\n\n\tret = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(vmcb_gpa), &map);\n\tif (ret == -EINVAL) {\n\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t} else if (ret) {\n\t\treturn kvm_skip_emulated_instruction(&svm->vcpu);\n\t}\n\n\tret = kvm_skip_emulated_instruction(&svm->vcpu);\n\n\tnested_vmcb = map.hva;\n\n\tif (!nested_vmcb_checks(nested_vmcb)) {\n\t\tnested_vmcb->control.exit_code    = SVM_EXIT_ERR;\n\t\tnested_vmcb->control.exit_code_hi = 0;\n\t\tnested_vmcb->control.exit_info_1  = 0;\n\t\tnested_vmcb->control.exit_info_2  = 0;\n\n\t\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\t\treturn ret;\n\t}\n\n\ttrace_kvm_nested_vmrun(svm->vmcb->save.rip, vmcb_gpa,\n\t\t\t       nested_vmcb->save.rip,\n\t\t\t       nested_vmcb->control.int_ctl,\n\t\t\t       nested_vmcb->control.event_inj,\n\t\t\t       nested_vmcb->control.nested_ctl);\n\n\ttrace_kvm_nested_intercepts(nested_vmcb->control.intercept_cr & 0xffff,\n\t\t\t\t    nested_vmcb->control.intercept_cr >> 16,\n\t\t\t\t    nested_vmcb->control.intercept_exceptions,\n\t\t\t\t    nested_vmcb->control.intercept);\n\n\t/* Clear internal status */\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\t/*\n\t * Save the old vmcb, so we don't need to pick what we save, but can\n\t * restore everything when a VMEXIT occurs\n\t */\n\thsave->save.es     = vmcb->save.es;\n\thsave->save.cs     = vmcb->save.cs;\n\thsave->save.ss     = vmcb->save.ss;\n\thsave->save.ds     = vmcb->save.ds;\n\thsave->save.gdtr   = vmcb->save.gdtr;\n\thsave->save.idtr   = vmcb->save.idtr;\n\thsave->save.efer   = svm->vcpu.arch.efer;\n\thsave->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\thsave->save.cr4    = svm->vcpu.arch.cr4;\n\thsave->save.rflags = kvm_get_rflags(&svm->vcpu);\n\thsave->save.rip    = kvm_rip_read(&svm->vcpu);\n\thsave->save.rsp    = vmcb->save.rsp;\n\thsave->save.rax    = vmcb->save.rax;\n\tif (npt_enabled)\n\t\thsave->save.cr3    = vmcb->save.cr3;\n\telse\n\t\thsave->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\n\tcopy_vmcb_control_area(hsave, vmcb);\n\n\tenter_svm_guest_mode(svm, vmcb_gpa, nested_vmcb, &map);\n\n\tif (!nested_svm_vmrun_msrpm(svm)) {\n\t\tsvm->vmcb->control.exit_code    = SVM_EXIT_ERR;\n\t\tsvm->vmcb->control.exit_code_hi = 0;\n\t\tsvm->vmcb->control.exit_info_1  = 0;\n\t\tsvm->vmcb->control.exit_info_2  = 0;\n\n\t\tnested_svm_vmexit(svm);\n\t}\n\n\treturn ret;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "nested_svm_vmexit",
          "args": [
            "svm"
          ],
          "line": 416
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_vmexit",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "438-579",
          "snippet": "int nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_svm_vmrun_msrpm",
          "args": [
            "svm"
          ],
          "line": 410
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_vmrun_msrpm",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "172-203",
          "snippet": "static bool nested_svm_vmrun_msrpm(struct vcpu_svm *svm)\n{\n\t/*\n\t * This function merges the msr permission bitmaps of kvm and the\n\t * nested vmcb. It is optimized in that it only merges the parts where\n\t * the kvm msr permission bitmap may contain zero bits\n\t */\n\tint i;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn true;\n\n\tfor (i = 0; i < MSRPM_OFFSETS; i++) {\n\t\tu32 value, p;\n\t\tu64 offset;\n\n\t\tif (msrpm_offsets[i] == 0xffffffff)\n\t\t\tbreak;\n\n\t\tp      = msrpm_offsets[i];\n\t\toffset = svm->nested.vmcb_msrpm + (p * 4);\n\n\t\tif (kvm_vcpu_read_guest(&svm->vcpu, offset, &value, 4))\n\t\t\treturn false;\n\n\t\tsvm->nested.msrpm[p] = svm->msrpm[p] | value;\n\t}\n\n\tsvm->vmcb->control.msrpm_base_pa = __sme_set(__pa(svm->nested.msrpm));\n\n\treturn true;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic bool nested_svm_vmrun_msrpm(struct vcpu_svm *svm)\n{\n\t/*\n\t * This function merges the msr permission bitmaps of kvm and the\n\t * nested vmcb. It is optimized in that it only merges the parts where\n\t * the kvm msr permission bitmap may contain zero bits\n\t */\n\tint i;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn true;\n\n\tfor (i = 0; i < MSRPM_OFFSETS; i++) {\n\t\tu32 value, p;\n\t\tu64 offset;\n\n\t\tif (msrpm_offsets[i] == 0xffffffff)\n\t\t\tbreak;\n\n\t\tp      = msrpm_offsets[i];\n\t\toffset = svm->nested.vmcb_msrpm + (p * 4);\n\n\t\tif (kvm_vcpu_read_guest(&svm->vcpu, offset, &value, 4))\n\t\t\treturn false;\n\n\t\tsvm->nested.msrpm[p] = svm->msrpm[p] | value;\n\t}\n\n\tsvm->vmcb->control.msrpm_base_pa = __sme_set(__pa(svm->nested.msrpm));\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "enter_svm_guest_mode",
          "args": [
            "svm",
            "vmcb_gpa",
            "nested_vmcb",
            "&map"
          ],
          "line": 408
        },
        "resolved": true,
        "details": {
          "function_name": "enter_svm_guest_mode",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "223-333",
          "snippet": "void enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,\n\t\t\t  struct vmcb *nested_vmcb, struct kvm_host_map *map)\n{\n\tbool evaluate_pending_interrupts =\n\t\tis_intercept(svm, INTERCEPT_VINTR) ||\n\t\tis_intercept(svm, INTERCEPT_IRET);\n\n\tif (kvm_get_rflags(&svm->vcpu) & X86_EFLAGS_IF)\n\t\tsvm->vcpu.arch.hflags |= HF_HIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_HIF_MASK;\n\n\tif (nested_vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) {\n\t\tsvm->nested.nested_cr3 = nested_vmcb->control.nested_cr3;\n\t\tnested_svm_init_mmu_context(&svm->vcpu);\n\t}\n\n\t/* Load the nested guest state */\n\tsvm->vmcb->save.es = nested_vmcb->save.es;\n\tsvm->vmcb->save.cs = nested_vmcb->save.cs;\n\tsvm->vmcb->save.ss = nested_vmcb->save.ss;\n\tsvm->vmcb->save.ds = nested_vmcb->save.ds;\n\tsvm->vmcb->save.gdtr = nested_vmcb->save.gdtr;\n\tsvm->vmcb->save.idtr = nested_vmcb->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, nested_vmcb->save.rflags);\n\tsvm_set_efer(&svm->vcpu, nested_vmcb->save.efer);\n\tsvm_set_cr0(&svm->vcpu, nested_vmcb->save.cr0);\n\tsvm_set_cr4(&svm->vcpu, nested_vmcb->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = nested_vmcb->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = nested_vmcb->save.cr3;\n\t} else\n\t\t(void)kvm_set_cr3(&svm->vcpu, nested_vmcb->save.cr3);\n\n\t/* Guest paging mode is active - reset mmu */\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsvm->vmcb->save.cr2 = svm->vcpu.arch.cr2 = nested_vmcb->save.cr2;\n\tkvm_rax_write(&svm->vcpu, nested_vmcb->save.rax);\n\tkvm_rsp_write(&svm->vcpu, nested_vmcb->save.rsp);\n\tkvm_rip_write(&svm->vcpu, nested_vmcb->save.rip);\n\n\t/* In case we don't even reach vcpu_run, the fields are not updated */\n\tsvm->vmcb->save.rax = nested_vmcb->save.rax;\n\tsvm->vmcb->save.rsp = nested_vmcb->save.rsp;\n\tsvm->vmcb->save.rip = nested_vmcb->save.rip;\n\tsvm->vmcb->save.dr7 = nested_vmcb->save.dr7;\n\tsvm->vmcb->save.dr6 = nested_vmcb->save.dr6;\n\tsvm->vmcb->save.cpl = nested_vmcb->save.cpl;\n\n\tsvm->nested.vmcb_msrpm = nested_vmcb->control.msrpm_base_pa & ~0x0fffULL;\n\tsvm->nested.vmcb_iopm  = nested_vmcb->control.iopm_base_pa  & ~0x0fffULL;\n\n\t/* cache intercepts */\n\tsvm->nested.intercept_cr         = nested_vmcb->control.intercept_cr;\n\tsvm->nested.intercept_dr         = nested_vmcb->control.intercept_dr;\n\tsvm->nested.intercept_exceptions = nested_vmcb->control.intercept_exceptions;\n\tsvm->nested.intercept            = nested_vmcb->control.intercept;\n\n\tsvm_flush_tlb(&svm->vcpu, true);\n\tsvm->vmcb->control.int_ctl = nested_vmcb->control.int_ctl | V_INTR_MASKING_MASK;\n\tif (nested_vmcb->control.int_ctl & V_INTR_MASKING_MASK)\n\t\tsvm->vcpu.arch.hflags |= HF_VINTR_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_VINTR_MASK;\n\n\tsvm->vcpu.arch.tsc_offset += nested_vmcb->control.tsc_offset;\n\tsvm->vmcb->control.tsc_offset = svm->vcpu.arch.tsc_offset;\n\n\tsvm->vmcb->control.virt_ext = nested_vmcb->control.virt_ext;\n\tsvm->vmcb->control.int_vector = nested_vmcb->control.int_vector;\n\tsvm->vmcb->control.int_state = nested_vmcb->control.int_state;\n\tsvm->vmcb->control.event_inj = nested_vmcb->control.event_inj;\n\tsvm->vmcb->control.event_inj_err = nested_vmcb->control.event_inj_err;\n\n\tsvm->vmcb->control.pause_filter_count =\n\t\tnested_vmcb->control.pause_filter_count;\n\tsvm->vmcb->control.pause_filter_thresh =\n\t\tnested_vmcb->control.pause_filter_thresh;\n\n\tkvm_vcpu_unmap(&svm->vcpu, map, true);\n\n\t/* Enter Guest-Mode */\n\tenter_guest_mode(&svm->vcpu);\n\n\t/*\n\t * Merge guest and host intercepts - must be called  with vcpu in\n\t * guest-mode to take affect here\n\t */\n\trecalc_intercepts(svm);\n\n\tsvm->nested.vmcb = vmcb_gpa;\n\n\t/*\n\t * If L1 had a pending IRQ/NMI before executing VMRUN,\n\t * which wasn't delivered because it was disallowed (e.g.\n\t * interrupts disabled), L0 needs to evaluate if this pending\n\t * event should cause an exit from L2 to L1 or be delivered\n\t * directly to L2.\n\t *\n\t * Usually this would be handled by the processor noticing an\n\t * IRQ/NMI window request.  However, VMRUN can unblock interrupts\n\t * by implicitly setting GIF, so force L0 to perform pending event\n\t * evaluation by requesting a KVM_REQ_EVENT.\n\t */\n\tenable_gif(svm);\n\tif (unlikely(evaluate_pending_interrupts))\n\t\tkvm_make_request(KVM_REQ_EVENT, &svm->vcpu);\n\n\tmark_all_dirty(svm->vmcb);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nvoid enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,\n\t\t\t  struct vmcb *nested_vmcb, struct kvm_host_map *map)\n{\n\tbool evaluate_pending_interrupts =\n\t\tis_intercept(svm, INTERCEPT_VINTR) ||\n\t\tis_intercept(svm, INTERCEPT_IRET);\n\n\tif (kvm_get_rflags(&svm->vcpu) & X86_EFLAGS_IF)\n\t\tsvm->vcpu.arch.hflags |= HF_HIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_HIF_MASK;\n\n\tif (nested_vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) {\n\t\tsvm->nested.nested_cr3 = nested_vmcb->control.nested_cr3;\n\t\tnested_svm_init_mmu_context(&svm->vcpu);\n\t}\n\n\t/* Load the nested guest state */\n\tsvm->vmcb->save.es = nested_vmcb->save.es;\n\tsvm->vmcb->save.cs = nested_vmcb->save.cs;\n\tsvm->vmcb->save.ss = nested_vmcb->save.ss;\n\tsvm->vmcb->save.ds = nested_vmcb->save.ds;\n\tsvm->vmcb->save.gdtr = nested_vmcb->save.gdtr;\n\tsvm->vmcb->save.idtr = nested_vmcb->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, nested_vmcb->save.rflags);\n\tsvm_set_efer(&svm->vcpu, nested_vmcb->save.efer);\n\tsvm_set_cr0(&svm->vcpu, nested_vmcb->save.cr0);\n\tsvm_set_cr4(&svm->vcpu, nested_vmcb->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = nested_vmcb->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = nested_vmcb->save.cr3;\n\t} else\n\t\t(void)kvm_set_cr3(&svm->vcpu, nested_vmcb->save.cr3);\n\n\t/* Guest paging mode is active - reset mmu */\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsvm->vmcb->save.cr2 = svm->vcpu.arch.cr2 = nested_vmcb->save.cr2;\n\tkvm_rax_write(&svm->vcpu, nested_vmcb->save.rax);\n\tkvm_rsp_write(&svm->vcpu, nested_vmcb->save.rsp);\n\tkvm_rip_write(&svm->vcpu, nested_vmcb->save.rip);\n\n\t/* In case we don't even reach vcpu_run, the fields are not updated */\n\tsvm->vmcb->save.rax = nested_vmcb->save.rax;\n\tsvm->vmcb->save.rsp = nested_vmcb->save.rsp;\n\tsvm->vmcb->save.rip = nested_vmcb->save.rip;\n\tsvm->vmcb->save.dr7 = nested_vmcb->save.dr7;\n\tsvm->vmcb->save.dr6 = nested_vmcb->save.dr6;\n\tsvm->vmcb->save.cpl = nested_vmcb->save.cpl;\n\n\tsvm->nested.vmcb_msrpm = nested_vmcb->control.msrpm_base_pa & ~0x0fffULL;\n\tsvm->nested.vmcb_iopm  = nested_vmcb->control.iopm_base_pa  & ~0x0fffULL;\n\n\t/* cache intercepts */\n\tsvm->nested.intercept_cr         = nested_vmcb->control.intercept_cr;\n\tsvm->nested.intercept_dr         = nested_vmcb->control.intercept_dr;\n\tsvm->nested.intercept_exceptions = nested_vmcb->control.intercept_exceptions;\n\tsvm->nested.intercept            = nested_vmcb->control.intercept;\n\n\tsvm_flush_tlb(&svm->vcpu, true);\n\tsvm->vmcb->control.int_ctl = nested_vmcb->control.int_ctl | V_INTR_MASKING_MASK;\n\tif (nested_vmcb->control.int_ctl & V_INTR_MASKING_MASK)\n\t\tsvm->vcpu.arch.hflags |= HF_VINTR_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_VINTR_MASK;\n\n\tsvm->vcpu.arch.tsc_offset += nested_vmcb->control.tsc_offset;\n\tsvm->vmcb->control.tsc_offset = svm->vcpu.arch.tsc_offset;\n\n\tsvm->vmcb->control.virt_ext = nested_vmcb->control.virt_ext;\n\tsvm->vmcb->control.int_vector = nested_vmcb->control.int_vector;\n\tsvm->vmcb->control.int_state = nested_vmcb->control.int_state;\n\tsvm->vmcb->control.event_inj = nested_vmcb->control.event_inj;\n\tsvm->vmcb->control.event_inj_err = nested_vmcb->control.event_inj_err;\n\n\tsvm->vmcb->control.pause_filter_count =\n\t\tnested_vmcb->control.pause_filter_count;\n\tsvm->vmcb->control.pause_filter_thresh =\n\t\tnested_vmcb->control.pause_filter_thresh;\n\n\tkvm_vcpu_unmap(&svm->vcpu, map, true);\n\n\t/* Enter Guest-Mode */\n\tenter_guest_mode(&svm->vcpu);\n\n\t/*\n\t * Merge guest and host intercepts - must be called  with vcpu in\n\t * guest-mode to take affect here\n\t */\n\trecalc_intercepts(svm);\n\n\tsvm->nested.vmcb = vmcb_gpa;\n\n\t/*\n\t * If L1 had a pending IRQ/NMI before executing VMRUN,\n\t * which wasn't delivered because it was disallowed (e.g.\n\t * interrupts disabled), L0 needs to evaluate if this pending\n\t * event should cause an exit from L2 to L1 or be delivered\n\t * directly to L2.\n\t *\n\t * Usually this would be handled by the processor noticing an\n\t * IRQ/NMI window request.  However, VMRUN can unblock interrupts\n\t * by implicitly setting GIF, so force L0 to perform pending event\n\t * evaluation by requesting a KVM_REQ_EVENT.\n\t */\n\tenable_gif(svm);\n\tif (unlikely(evaluate_pending_interrupts))\n\t\tkvm_make_request(KVM_REQ_EVENT, &svm->vcpu);\n\n\tmark_all_dirty(svm->vmcb);\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_vmcb_control_area",
          "args": [
            "hsave",
            "vmcb"
          ],
          "line": 406
        },
        "resolved": true,
        "details": {
          "function_name": "copy_vmcb_control_area",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "140-170",
          "snippet": "static void copy_vmcb_control_area(struct vmcb *dst_vmcb, struct vmcb *from_vmcb)\n{\n\tstruct vmcb_control_area *dst  = &dst_vmcb->control;\n\tstruct vmcb_control_area *from = &from_vmcb->control;\n\n\tdst->intercept_cr         = from->intercept_cr;\n\tdst->intercept_dr         = from->intercept_dr;\n\tdst->intercept_exceptions = from->intercept_exceptions;\n\tdst->intercept            = from->intercept;\n\tdst->iopm_base_pa         = from->iopm_base_pa;\n\tdst->msrpm_base_pa        = from->msrpm_base_pa;\n\tdst->tsc_offset           = from->tsc_offset;\n\tdst->asid                 = from->asid;\n\tdst->tlb_ctl              = from->tlb_ctl;\n\tdst->int_ctl              = from->int_ctl;\n\tdst->int_vector           = from->int_vector;\n\tdst->int_state            = from->int_state;\n\tdst->exit_code            = from->exit_code;\n\tdst->exit_code_hi         = from->exit_code_hi;\n\tdst->exit_info_1          = from->exit_info_1;\n\tdst->exit_info_2          = from->exit_info_2;\n\tdst->exit_int_info        = from->exit_int_info;\n\tdst->exit_int_info_err    = from->exit_int_info_err;\n\tdst->nested_ctl           = from->nested_ctl;\n\tdst->event_inj            = from->event_inj;\n\tdst->event_inj_err        = from->event_inj_err;\n\tdst->nested_cr3           = from->nested_cr3;\n\tdst->virt_ext              = from->virt_ext;\n\tdst->pause_filter_count   = from->pause_filter_count;\n\tdst->pause_filter_thresh  = from->pause_filter_thresh;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void copy_vmcb_control_area(struct vmcb *dst_vmcb, struct vmcb *from_vmcb)\n{\n\tstruct vmcb_control_area *dst  = &dst_vmcb->control;\n\tstruct vmcb_control_area *from = &from_vmcb->control;\n\n\tdst->intercept_cr         = from->intercept_cr;\n\tdst->intercept_dr         = from->intercept_dr;\n\tdst->intercept_exceptions = from->intercept_exceptions;\n\tdst->intercept            = from->intercept;\n\tdst->iopm_base_pa         = from->iopm_base_pa;\n\tdst->msrpm_base_pa        = from->msrpm_base_pa;\n\tdst->tsc_offset           = from->tsc_offset;\n\tdst->asid                 = from->asid;\n\tdst->tlb_ctl              = from->tlb_ctl;\n\tdst->int_ctl              = from->int_ctl;\n\tdst->int_vector           = from->int_vector;\n\tdst->int_state            = from->int_state;\n\tdst->exit_code            = from->exit_code;\n\tdst->exit_code_hi         = from->exit_code_hi;\n\tdst->exit_info_1          = from->exit_info_1;\n\tdst->exit_info_2          = from->exit_info_2;\n\tdst->exit_int_info        = from->exit_int_info;\n\tdst->exit_int_info_err    = from->exit_int_info_err;\n\tdst->nested_ctl           = from->nested_ctl;\n\tdst->event_inj            = from->event_inj;\n\tdst->event_inj_err        = from->event_inj_err;\n\tdst->nested_cr3           = from->nested_cr3;\n\tdst->virt_ext              = from->virt_ext;\n\tdst->pause_filter_count   = from->pause_filter_count;\n\tdst->pause_filter_thresh  = from->pause_filter_thresh;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_read_cr3",
          "args": [
            "&svm->vcpu"
          ],
          "line": 404
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr3",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "137-142",
          "snippet": "static inline ulong kvm_read_cr3(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tkvm_x86_ops.cache_reg(vcpu, VCPU_EXREG_CR3);\n\treturn vcpu->arch.cr3;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline ulong kvm_read_cr3(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tkvm_x86_ops.cache_reg(vcpu, VCPU_EXREG_CR3);\n\treturn vcpu->arch.cr3;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rip_read",
          "args": [
            "&svm->vcpu"
          ],
          "line": 398
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_rip_read",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "86-89",
          "snippet": "static inline unsigned long kvm_rip_read(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_register_read(vcpu, VCPU_REGS_RIP);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline unsigned long kvm_rip_read(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_register_read(vcpu, VCPU_REGS_RIP);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_get_rflags",
          "args": [
            "&svm->vcpu"
          ],
          "line": 397
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_get_rflags",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "10221-10229",
          "snippet": "unsigned long kvm_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags;\n\n\trflags = kvm_x86_ops.get_rflags(vcpu);\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\trflags &= ~X86_EFLAGS_TF;\n\treturn rflags;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nunsigned long kvm_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags;\n\n\trflags = kvm_x86_ops.get_rflags(vcpu);\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\trflags &= ~X86_EFLAGS_TF;\n\treturn rflags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_read_cr0",
          "args": [
            "&svm->vcpu"
          ],
          "line": 395
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr0",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "124-127",
          "snippet": "static inline ulong kvm_read_cr0(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, ~0UL);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline ulong kvm_read_cr0(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, ~0UL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_clear_interrupt_queue",
          "args": [
            "&svm->vcpu"
          ],
          "line": 382
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_clear_interrupt_queue",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "64-67",
          "snippet": "static inline void kvm_clear_interrupt_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.interrupt.injected = false;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_clear_interrupt_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.interrupt.injected = false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_clear_exception_queue",
          "args": [
            "&svm->vcpu"
          ],
          "line": 381
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_clear_exception_queue",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "50-54",
          "snippet": "static inline void kvm_clear_exception_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.exception.pending = false;\n\tvcpu->arch.exception.injected = false;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_clear_exception_queue(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.exception.pending = false;\n\tvcpu->arch.exception.injected = false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kvm_nested_intercepts",
          "args": [
            "nested_vmcb->control.intercept_cr & 0xffff",
            "nested_vmcb->control.intercept_cr >> 16",
            "nested_vmcb->control.intercept_exceptions",
            "nested_vmcb->control.intercept"
          ],
          "line": 375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_nested_vmrun",
          "args": [
            "svm->vmcb->save.rip",
            "vmcb_gpa",
            "nested_vmcb->save.rip",
            "nested_vmcb->control.int_ctl",
            "nested_vmcb->control.event_inj",
            "nested_vmcb->control.nested_ctl"
          ],
          "line": 369
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_unmap",
          "args": [
            "&svm->vcpu",
            "&map",
            "true"
          ],
          "line": 364
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "nested_vmcb_checks",
          "args": [
            "nested_vmcb"
          ],
          "line": 358
        },
        "resolved": true,
        "details": {
          "function_name": "nested_vmcb_checks",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "205-221",
          "snippet": "static bool nested_vmcb_checks(struct vmcb *vmcb)\n{\n\tif ((vmcb->save.efer & EFER_SVME) == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.intercept & (1ULL << INTERCEPT_VMRUN)) == 0)\n\t\treturn false;\n\n\tif (vmcb->control.asid == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) &&\n\t    !npt_enabled)\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic bool nested_vmcb_checks(struct vmcb *vmcb)\n{\n\tif ((vmcb->save.efer & EFER_SVME) == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.intercept & (1ULL << INTERCEPT_VMRUN)) == 0)\n\t\treturn false;\n\n\tif (vmcb->control.asid == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) &&\n\t    !npt_enabled)\n\t\treturn false;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_skip_emulated_instruction",
          "args": [
            "&svm->vcpu"
          ],
          "line": 354
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_skip_emulated_instruction",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "6655-6675",
          "snippet": "int kvm_skip_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\tint r;\n\n\tr = kvm_x86_ops.skip_emulated_instruction(vcpu);\n\tif (unlikely(!r))\n\t\treturn 0;\n\n\t/*\n\t * rflags is the old, \"raw\" value of the flags.  The new value has\n\t * not been saved yet.\n\t *\n\t * This is correct even for TF set by the guest, because \"the\n\t * processor will not generate this exception after the instruction\n\t * that sets the TF flag\".\n\t */\n\tif (unlikely(rflags & X86_EFLAGS_TF))\n\t\tr = kvm_vcpu_do_singlestep(vcpu);\n\treturn r;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nint kvm_skip_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\tint r;\n\n\tr = kvm_x86_ops.skip_emulated_instruction(vcpu);\n\tif (unlikely(!r))\n\t\treturn 0;\n\n\t/*\n\t * rflags is the old, \"raw\" value of the flags.  The new value has\n\t * not been saved yet.\n\t *\n\t * This is correct even for TF set by the guest, because \"the\n\t * processor will not generate this exception after the instruction\n\t * that sets the TF flag\".\n\t */\n\tif (unlikely(rflags & X86_EFLAGS_TF))\n\t\tr = kvm_vcpu_do_singlestep(vcpu);\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_inject_gp",
          "args": [
            "&svm->vcpu",
            "0"
          ],
          "line": 348
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_map",
          "args": [
            "&svm->vcpu",
            "gpa_to_gfn(vmcb_gpa)",
            "&map"
          ],
          "line": 346
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpa_to_gfn",
          "args": [
            "vmcb_gpa"
          ],
          "line": 346
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_vmrun(struct vcpu_svm *svm)\n{\n\tint ret;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\tu64 vmcb_gpa;\n\n\tvmcb_gpa = svm->vmcb->save.rax;\n\n\tret = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(vmcb_gpa), &map);\n\tif (ret == -EINVAL) {\n\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t} else if (ret) {\n\t\treturn kvm_skip_emulated_instruction(&svm->vcpu);\n\t}\n\n\tret = kvm_skip_emulated_instruction(&svm->vcpu);\n\n\tnested_vmcb = map.hva;\n\n\tif (!nested_vmcb_checks(nested_vmcb)) {\n\t\tnested_vmcb->control.exit_code    = SVM_EXIT_ERR;\n\t\tnested_vmcb->control.exit_code_hi = 0;\n\t\tnested_vmcb->control.exit_info_1  = 0;\n\t\tnested_vmcb->control.exit_info_2  = 0;\n\n\t\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\t\treturn ret;\n\t}\n\n\ttrace_kvm_nested_vmrun(svm->vmcb->save.rip, vmcb_gpa,\n\t\t\t       nested_vmcb->save.rip,\n\t\t\t       nested_vmcb->control.int_ctl,\n\t\t\t       nested_vmcb->control.event_inj,\n\t\t\t       nested_vmcb->control.nested_ctl);\n\n\ttrace_kvm_nested_intercepts(nested_vmcb->control.intercept_cr & 0xffff,\n\t\t\t\t    nested_vmcb->control.intercept_cr >> 16,\n\t\t\t\t    nested_vmcb->control.intercept_exceptions,\n\t\t\t\t    nested_vmcb->control.intercept);\n\n\t/* Clear internal status */\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\t/*\n\t * Save the old vmcb, so we don't need to pick what we save, but can\n\t * restore everything when a VMEXIT occurs\n\t */\n\thsave->save.es     = vmcb->save.es;\n\thsave->save.cs     = vmcb->save.cs;\n\thsave->save.ss     = vmcb->save.ss;\n\thsave->save.ds     = vmcb->save.ds;\n\thsave->save.gdtr   = vmcb->save.gdtr;\n\thsave->save.idtr   = vmcb->save.idtr;\n\thsave->save.efer   = svm->vcpu.arch.efer;\n\thsave->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\thsave->save.cr4    = svm->vcpu.arch.cr4;\n\thsave->save.rflags = kvm_get_rflags(&svm->vcpu);\n\thsave->save.rip    = kvm_rip_read(&svm->vcpu);\n\thsave->save.rsp    = vmcb->save.rsp;\n\thsave->save.rax    = vmcb->save.rax;\n\tif (npt_enabled)\n\t\thsave->save.cr3    = vmcb->save.cr3;\n\telse\n\t\thsave->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\n\tcopy_vmcb_control_area(hsave, vmcb);\n\n\tenter_svm_guest_mode(svm, vmcb_gpa, nested_vmcb, &map);\n\n\tif (!nested_svm_vmrun_msrpm(svm)) {\n\t\tsvm->vmcb->control.exit_code    = SVM_EXIT_ERR;\n\t\tsvm->vmcb->control.exit_code_hi = 0;\n\t\tsvm->vmcb->control.exit_info_1  = 0;\n\t\tsvm->vmcb->control.exit_info_2  = 0;\n\n\t\tnested_svm_vmexit(svm);\n\t}\n\n\treturn ret;\n}"
  },
  {
    "function_name": "enter_svm_guest_mode",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "223-333",
    "snippet": "void enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,\n\t\t\t  struct vmcb *nested_vmcb, struct kvm_host_map *map)\n{\n\tbool evaluate_pending_interrupts =\n\t\tis_intercept(svm, INTERCEPT_VINTR) ||\n\t\tis_intercept(svm, INTERCEPT_IRET);\n\n\tif (kvm_get_rflags(&svm->vcpu) & X86_EFLAGS_IF)\n\t\tsvm->vcpu.arch.hflags |= HF_HIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_HIF_MASK;\n\n\tif (nested_vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) {\n\t\tsvm->nested.nested_cr3 = nested_vmcb->control.nested_cr3;\n\t\tnested_svm_init_mmu_context(&svm->vcpu);\n\t}\n\n\t/* Load the nested guest state */\n\tsvm->vmcb->save.es = nested_vmcb->save.es;\n\tsvm->vmcb->save.cs = nested_vmcb->save.cs;\n\tsvm->vmcb->save.ss = nested_vmcb->save.ss;\n\tsvm->vmcb->save.ds = nested_vmcb->save.ds;\n\tsvm->vmcb->save.gdtr = nested_vmcb->save.gdtr;\n\tsvm->vmcb->save.idtr = nested_vmcb->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, nested_vmcb->save.rflags);\n\tsvm_set_efer(&svm->vcpu, nested_vmcb->save.efer);\n\tsvm_set_cr0(&svm->vcpu, nested_vmcb->save.cr0);\n\tsvm_set_cr4(&svm->vcpu, nested_vmcb->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = nested_vmcb->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = nested_vmcb->save.cr3;\n\t} else\n\t\t(void)kvm_set_cr3(&svm->vcpu, nested_vmcb->save.cr3);\n\n\t/* Guest paging mode is active - reset mmu */\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsvm->vmcb->save.cr2 = svm->vcpu.arch.cr2 = nested_vmcb->save.cr2;\n\tkvm_rax_write(&svm->vcpu, nested_vmcb->save.rax);\n\tkvm_rsp_write(&svm->vcpu, nested_vmcb->save.rsp);\n\tkvm_rip_write(&svm->vcpu, nested_vmcb->save.rip);\n\n\t/* In case we don't even reach vcpu_run, the fields are not updated */\n\tsvm->vmcb->save.rax = nested_vmcb->save.rax;\n\tsvm->vmcb->save.rsp = nested_vmcb->save.rsp;\n\tsvm->vmcb->save.rip = nested_vmcb->save.rip;\n\tsvm->vmcb->save.dr7 = nested_vmcb->save.dr7;\n\tsvm->vmcb->save.dr6 = nested_vmcb->save.dr6;\n\tsvm->vmcb->save.cpl = nested_vmcb->save.cpl;\n\n\tsvm->nested.vmcb_msrpm = nested_vmcb->control.msrpm_base_pa & ~0x0fffULL;\n\tsvm->nested.vmcb_iopm  = nested_vmcb->control.iopm_base_pa  & ~0x0fffULL;\n\n\t/* cache intercepts */\n\tsvm->nested.intercept_cr         = nested_vmcb->control.intercept_cr;\n\tsvm->nested.intercept_dr         = nested_vmcb->control.intercept_dr;\n\tsvm->nested.intercept_exceptions = nested_vmcb->control.intercept_exceptions;\n\tsvm->nested.intercept            = nested_vmcb->control.intercept;\n\n\tsvm_flush_tlb(&svm->vcpu, true);\n\tsvm->vmcb->control.int_ctl = nested_vmcb->control.int_ctl | V_INTR_MASKING_MASK;\n\tif (nested_vmcb->control.int_ctl & V_INTR_MASKING_MASK)\n\t\tsvm->vcpu.arch.hflags |= HF_VINTR_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_VINTR_MASK;\n\n\tsvm->vcpu.arch.tsc_offset += nested_vmcb->control.tsc_offset;\n\tsvm->vmcb->control.tsc_offset = svm->vcpu.arch.tsc_offset;\n\n\tsvm->vmcb->control.virt_ext = nested_vmcb->control.virt_ext;\n\tsvm->vmcb->control.int_vector = nested_vmcb->control.int_vector;\n\tsvm->vmcb->control.int_state = nested_vmcb->control.int_state;\n\tsvm->vmcb->control.event_inj = nested_vmcb->control.event_inj;\n\tsvm->vmcb->control.event_inj_err = nested_vmcb->control.event_inj_err;\n\n\tsvm->vmcb->control.pause_filter_count =\n\t\tnested_vmcb->control.pause_filter_count;\n\tsvm->vmcb->control.pause_filter_thresh =\n\t\tnested_vmcb->control.pause_filter_thresh;\n\n\tkvm_vcpu_unmap(&svm->vcpu, map, true);\n\n\t/* Enter Guest-Mode */\n\tenter_guest_mode(&svm->vcpu);\n\n\t/*\n\t * Merge guest and host intercepts - must be called  with vcpu in\n\t * guest-mode to take affect here\n\t */\n\trecalc_intercepts(svm);\n\n\tsvm->nested.vmcb = vmcb_gpa;\n\n\t/*\n\t * If L1 had a pending IRQ/NMI before executing VMRUN,\n\t * which wasn't delivered because it was disallowed (e.g.\n\t * interrupts disabled), L0 needs to evaluate if this pending\n\t * event should cause an exit from L2 to L1 or be delivered\n\t * directly to L2.\n\t *\n\t * Usually this would be handled by the processor noticing an\n\t * IRQ/NMI window request.  However, VMRUN can unblock interrupts\n\t * by implicitly setting GIF, so force L0 to perform pending event\n\t * evaluation by requesting a KVM_REQ_EVENT.\n\t */\n\tenable_gif(svm);\n\tif (unlikely(evaluate_pending_interrupts))\n\t\tkvm_make_request(KVM_REQ_EVENT, &svm->vcpu);\n\n\tmark_all_dirty(svm->vmcb);\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mark_all_dirty",
          "args": [
            "svm->vmcb"
          ],
          "line": 332
        },
        "resolved": true,
        "details": {
          "function_name": "mark_all_dirty",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "176-179",
          "snippet": "static inline void mark_all_dirty(struct vmcb *vmcb)\n{\n\tvmcb->control.clean = 0;\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline void mark_all_dirty(struct vmcb *vmcb)\n{\n\tvmcb->control.clean = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_make_request",
          "args": [
            "KVM_REQ_EVENT",
            "&svm->vcpu"
          ],
          "line": 330
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "evaluate_pending_interrupts"
          ],
          "line": 329
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "enable_gif",
          "args": [
            "svm"
          ],
          "line": 328
        },
        "resolved": true,
        "details": {
          "function_name": "enable_gif",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "309-315",
          "snippet": "static inline void enable_gif(struct vcpu_svm *svm)\n{\n\tif (vgif_enabled(svm))\n\t\tsvm->vmcb->control.int_ctl |= V_GIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags |= HF_GIF_MASK;\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline void enable_gif(struct vcpu_svm *svm)\n{\n\tif (vgif_enabled(svm))\n\t\tsvm->vmcb->control.int_ctl |= V_GIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags |= HF_GIF_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "recalc_intercepts",
          "args": [
            "svm"
          ],
          "line": 312
        },
        "resolved": true,
        "details": {
          "function_name": "recalc_intercepts",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "99-138",
          "snippet": "void recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h;\n\tstruct nested_state *g;\n\n\tmark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->nested.hsave->control;\n\tg = &svm->nested;\n\n\tc->intercept_cr = h->intercept_cr;\n\tc->intercept_dr = h->intercept_dr;\n\tc->intercept_exceptions = h->intercept_exceptions;\n\tc->intercept = h->intercept;\n\n\tif (svm->vcpu.arch.hflags & HF_VINTR_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_READ);\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tc->intercept &= ~(1ULL << INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tc->intercept &= ~(1ULL << INTERCEPT_VMMCALL);\n\n\tc->intercept_cr |= g->intercept_cr;\n\tc->intercept_dr |= g->intercept_dr;\n\tc->intercept_exceptions |= g->intercept_exceptions;\n\tc->intercept |= g->intercept;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nvoid recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h;\n\tstruct nested_state *g;\n\n\tmark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->nested.hsave->control;\n\tg = &svm->nested;\n\n\tc->intercept_cr = h->intercept_cr;\n\tc->intercept_dr = h->intercept_dr;\n\tc->intercept_exceptions = h->intercept_exceptions;\n\tc->intercept = h->intercept;\n\n\tif (svm->vcpu.arch.hflags & HF_VINTR_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_READ);\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tc->intercept &= ~(1ULL << INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tc->intercept &= ~(1ULL << INTERCEPT_VMMCALL);\n\n\tc->intercept_cr |= g->intercept_cr;\n\tc->intercept_dr |= g->intercept_dr;\n\tc->intercept_exceptions |= g->intercept_exceptions;\n\tc->intercept |= g->intercept;\n}"
        }
      },
      {
        "call_info": {
          "callee": "enter_guest_mode",
          "args": [
            "&svm->vcpu"
          ],
          "line": 306
        },
        "resolved": true,
        "details": {
          "function_name": "enter_guest_mode",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "155-158",
          "snippet": "static inline void enter_guest_mode(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.hflags |= HF_GUEST_MASK;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline void enter_guest_mode(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.hflags |= HF_GUEST_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_unmap",
          "args": [
            "&svm->vcpu",
            "map",
            "true"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "svm_flush_tlb",
          "args": [
            "&svm->vcpu",
            "true"
          ],
          "line": 282
        },
        "resolved": true,
        "details": {
          "function_name": "svm_flush_tlb_gva",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "4512-4517",
          "snippet": "static void svm_flush_tlb_gva(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\tinvlpga(gva, svm->vmcb->control.asid);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void svm_complete_interrupts(struct vcpu_svm *svm);",
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void svm_complete_interrupts(struct vcpu_svm *svm);\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nstatic void svm_flush_tlb_gva(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\tinvlpga(gva, svm->vmcb->control.asid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rip_write",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.rip"
          ],
          "line": 263
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_rip_write",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "91-94",
          "snippet": "static inline void kvm_rip_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RIP, val);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline void kvm_rip_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RIP, val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rsp_write",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.rsp"
          ],
          "line": 262
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_rsp_write",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "101-104",
          "snippet": "static inline void kvm_rsp_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RSP, val);\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline void kvm_rsp_write(struct kvm_vcpu *vcpu, unsigned long val)\n{\n\tkvm_register_write(vcpu, VCPU_REGS_RSP, val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rax_write",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.rax"
          ],
          "line": 261
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_mmu_reset_context",
          "args": [
            "&svm->vcpu"
          ],
          "line": 258
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_reset_context",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "5167-5171",
          "snippet": "void kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nvoid kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_set_cr3",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.cr3"
          ],
          "line": 255
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_set_cr3",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "994-1026",
          "snippet": "int kvm_set_cr3(struct kvm_vcpu *vcpu, unsigned long cr3)\n{\n\tbool skip_tlb_flush = false;\n#ifdef CONFIG_X86_64\n\tbool pcid_enabled = kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE);\n\n\tif (pcid_enabled) {\n\t\tskip_tlb_flush = cr3 & X86_CR3_PCID_NOFLUSH;\n\t\tcr3 &= ~X86_CR3_PCID_NOFLUSH;\n\t}\n#endif\n\n\tif (cr3 == kvm_read_cr3(vcpu) && !pdptrs_changed(vcpu)) {\n\t\tif (!skip_tlb_flush) {\n\t\t\tkvm_mmu_sync_roots(vcpu);\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (is_long_mode(vcpu) &&\n\t    (cr3 & rsvd_bits(cpuid_maxphyaddr(vcpu), 63)))\n\t\treturn 1;\n\telse if (is_pae_paging(vcpu) &&\n\t\t !load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))\n\t\treturn 1;\n\n\tkvm_mmu_new_cr3(vcpu, cr3, skip_tlb_flush);\n\tvcpu->arch.cr3 = cr3;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR3);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nint kvm_set_cr3(struct kvm_vcpu *vcpu, unsigned long cr3)\n{\n\tbool skip_tlb_flush = false;\n#ifdef CONFIG_X86_64\n\tbool pcid_enabled = kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE);\n\n\tif (pcid_enabled) {\n\t\tskip_tlb_flush = cr3 & X86_CR3_PCID_NOFLUSH;\n\t\tcr3 &= ~X86_CR3_PCID_NOFLUSH;\n\t}\n#endif\n\n\tif (cr3 == kvm_read_cr3(vcpu) && !pdptrs_changed(vcpu)) {\n\t\tif (!skip_tlb_flush) {\n\t\t\tkvm_mmu_sync_roots(vcpu);\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (is_long_mode(vcpu) &&\n\t    (cr3 & rsvd_bits(cpuid_maxphyaddr(vcpu), 63)))\n\t\treturn 1;\n\telse if (is_pae_paging(vcpu) &&\n\t\t !load_pdptrs(vcpu, vcpu->arch.walk_mmu, cr3))\n\t\treturn 1;\n\n\tkvm_mmu_new_cr3(vcpu, cr3, skip_tlb_flush);\n\tvcpu->arch.cr3 = cr3;\n\tkvm_register_mark_available(vcpu, VCPU_EXREG_CR3);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "svm_set_cr4",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.cr4"
          ],
          "line": 250
        },
        "resolved": true,
        "details": {
          "function_name": "svm_set_cr4",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "2331-2349",
          "snippet": "int svm_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4)\n{\n\tunsigned long host_cr4_mce = cr4_read_shadow() & X86_CR4_MCE;\n\tunsigned long old_cr4 = to_svm(vcpu)->vmcb->save.cr4;\n\n\tif (cr4 & X86_CR4_VMXE)\n\t\treturn 1;\n\n\tif (npt_enabled && ((old_cr4 ^ cr4) & X86_CR4_PGE))\n\t\tsvm_flush_tlb(vcpu, true);\n\n\tvcpu->arch.cr4 = cr4;\n\tif (!npt_enabled)\n\t\tcr4 |= X86_CR4_PAE;\n\tcr4 |= host_cr4_mce;\n\tto_svm(vcpu)->vmcb->save.cr4 = cr4;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n\treturn 0;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nint svm_set_cr4(struct kvm_vcpu *vcpu, unsigned long cr4)\n{\n\tunsigned long host_cr4_mce = cr4_read_shadow() & X86_CR4_MCE;\n\tunsigned long old_cr4 = to_svm(vcpu)->vmcb->save.cr4;\n\n\tif (cr4 & X86_CR4_VMXE)\n\t\treturn 1;\n\n\tif (npt_enabled && ((old_cr4 ^ cr4) & X86_CR4_PGE))\n\t\tsvm_flush_tlb(vcpu, true);\n\n\tvcpu->arch.cr4 = cr4;\n\tif (!npt_enabled)\n\t\tcr4 |= X86_CR4_PAE;\n\tcr4 |= host_cr4_mce;\n\tto_svm(vcpu)->vmcb->save.cr4 = cr4;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "svm_set_cr0",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.cr0"
          ],
          "line": 249
        },
        "resolved": true,
        "details": {
          "function_name": "svm_set_cr0",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "2297-2329",
          "snippet": "void svm_set_cr0(struct kvm_vcpu *vcpu, unsigned long cr0)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n#ifdef CONFIG_X86_64\n\tif (vcpu->arch.efer & EFER_LME) {\n\t\tif (!is_paging(vcpu) && (cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer |= EFER_LMA;\n\t\t\tsvm->vmcb->save.efer |= EFER_LMA | EFER_LME;\n\t\t}\n\n\t\tif (is_paging(vcpu) && !(cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer &= ~EFER_LMA;\n\t\t\tsvm->vmcb->save.efer &= ~(EFER_LMA | EFER_LME);\n\t\t}\n\t}\n#endif\n\tvcpu->arch.cr0 = cr0;\n\n\tif (!npt_enabled)\n\t\tcr0 |= X86_CR0_PG | X86_CR0_WP;\n\n\t/*\n\t * re-enable caching here because the QEMU bios\n\t * does not do it - this results in some delay at\n\t * reboot\n\t */\n\tif (kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_CD_NW_CLEARED))\n\t\tcr0 &= ~(X86_CR0_CD | X86_CR0_NW);\n\tsvm->vmcb->save.cr0 = cr0;\n\tmark_dirty(svm->vmcb, VMCB_CR);\n\tupdate_cr0_intercept(svm);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void svm_complete_interrupts(struct vcpu_svm *svm);",
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void svm_complete_interrupts(struct vcpu_svm *svm);\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nvoid svm_set_cr0(struct kvm_vcpu *vcpu, unsigned long cr0)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n#ifdef CONFIG_X86_64\n\tif (vcpu->arch.efer & EFER_LME) {\n\t\tif (!is_paging(vcpu) && (cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer |= EFER_LMA;\n\t\t\tsvm->vmcb->save.efer |= EFER_LMA | EFER_LME;\n\t\t}\n\n\t\tif (is_paging(vcpu) && !(cr0 & X86_CR0_PG)) {\n\t\t\tvcpu->arch.efer &= ~EFER_LMA;\n\t\t\tsvm->vmcb->save.efer &= ~(EFER_LMA | EFER_LME);\n\t\t}\n\t}\n#endif\n\tvcpu->arch.cr0 = cr0;\n\n\tif (!npt_enabled)\n\t\tcr0 |= X86_CR0_PG | X86_CR0_WP;\n\n\t/*\n\t * re-enable caching here because the QEMU bios\n\t * does not do it - this results in some delay at\n\t * reboot\n\t */\n\tif (kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_CD_NW_CLEARED))\n\t\tcr0 &= ~(X86_CR0_CD | X86_CR0_NW);\n\tsvm->vmcb->save.cr0 = cr0;\n\tmark_dirty(svm->vmcb, VMCB_CR);\n\tupdate_cr0_intercept(svm);\n}"
        }
      },
      {
        "call_info": {
          "callee": "svm_set_efer",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.efer"
          ],
          "line": 248
        },
        "resolved": true,
        "details": {
          "function_name": "svm_set_efer",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.c",
          "lines": "412-426",
          "snippet": "void svm_set_efer(struct kvm_vcpu *vcpu, u64 efer)\n{\n\tvcpu->arch.efer = efer;\n\n\tif (!npt_enabled) {\n\t\t/* Shadow paging assumes NX to be available.  */\n\t\tefer |= EFER_NX;\n\n\t\tif (!(efer & EFER_LMA))\n\t\t\tefer &= ~EFER_LME;\n\t}\n\n\tto_svm(vcpu)->vmcb->save.efer = efer | EFER_SVME;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"trace.h\"",
            "#include <asm/virtext.h>",
            "#include <asm/cpu_device_id.h>",
            "#include <asm/spec-ctrl.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/kvm_para.h>",
            "#include <asm/debugreg.h>",
            "#include <asm/desc.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/perf_event.h>",
            "#include <asm/apic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/file.h>",
            "#include <linux/psp-sev.h>",
            "#include <linux/frame.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/amd-iommu.h>",
            "#include <linux/slab.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/sched.h>",
            "#include <linux/highmem.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mod_devicetable.h>",
            "#include <linux/module.h>",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static inline void avic_post_state_restore(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"trace.h\"\n#include <asm/virtext.h>\n#include <asm/cpu_device_id.h>\n#include <asm/spec-ctrl.h>\n#include <asm/irq_remapping.h>\n#include <asm/kvm_para.h>\n#include <asm/debugreg.h>\n#include <asm/desc.h>\n#include <asm/tlbflush.h>\n#include <asm/perf_event.h>\n#include <asm/apic.h>\n#include <linux/rwsem.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/file.h>\n#include <linux/psp-sev.h>\n#include <linux/frame.h>\n#include <linux/hashtable.h>\n#include <linux/amd-iommu.h>\n#include <linux/slab.h>\n#include <linux/trace_events.h>\n#include <linux/sched.h>\n#include <linux/highmem.h>\n#include <linux/vmalloc.h>\n#include <linux/kernel.h>\n#include <linux/mod_devicetable.h>\n#include <linux/module.h>\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_cache_regs.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void avic_post_state_restore(struct kvm_vcpu *vcpu);\n\nvoid svm_set_efer(struct kvm_vcpu *vcpu, u64 efer)\n{\n\tvcpu->arch.efer = efer;\n\n\tif (!npt_enabled) {\n\t\t/* Shadow paging assumes NX to be available.  */\n\t\tefer |= EFER_NX;\n\n\t\tif (!(efer & EFER_LMA))\n\t\t\tefer &= ~EFER_LME;\n\t}\n\n\tto_svm(vcpu)->vmcb->save.efer = efer | EFER_SVME;\n\tmark_dirty(to_svm(vcpu)->vmcb, VMCB_CR);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_set_rflags",
          "args": [
            "&svm->vcpu",
            "nested_vmcb->save.rflags"
          ],
          "line": 247
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_set_rflags",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "10240-10244",
          "snippet": "void kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)\n{\n\t__kvm_set_rflags(vcpu, rflags);\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nvoid kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags)\n{\n\t__kvm_set_rflags(vcpu, rflags);\n\tkvm_make_request(KVM_REQ_EVENT, vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "nested_svm_init_mmu_context",
          "args": [
            "&svm->vcpu"
          ],
          "line": 237
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_init_mmu_context",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "79-91",
          "snippet": "static void nested_svm_init_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON(mmu_is_nested(vcpu));\n\n\tvcpu->arch.mmu = &vcpu->arch.guest_mmu;\n\tkvm_init_shadow_mmu(vcpu);\n\tvcpu->arch.mmu->get_guest_pgd     = nested_svm_get_tdp_cr3;\n\tvcpu->arch.mmu->get_pdptr         = nested_svm_get_tdp_pdptr;\n\tvcpu->arch.mmu->inject_page_fault = nested_svm_inject_npf_exit;\n\tvcpu->arch.mmu->shadow_root_level = kvm_x86_ops.get_tdp_level(vcpu);\n\treset_shadow_zero_bits_mask(vcpu, vcpu->arch.mmu);\n\tvcpu->arch.walk_mmu              = &vcpu->arch.nested_mmu;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_init_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON(mmu_is_nested(vcpu));\n\n\tvcpu->arch.mmu = &vcpu->arch.guest_mmu;\n\tkvm_init_shadow_mmu(vcpu);\n\tvcpu->arch.mmu->get_guest_pgd     = nested_svm_get_tdp_cr3;\n\tvcpu->arch.mmu->get_pdptr         = nested_svm_get_tdp_pdptr;\n\tvcpu->arch.mmu->inject_page_fault = nested_svm_inject_npf_exit;\n\tvcpu->arch.mmu->shadow_root_level = kvm_x86_ops.get_tdp_level(vcpu);\n\treset_shadow_zero_bits_mask(vcpu, vcpu->arch.mmu);\n\tvcpu->arch.walk_mmu              = &vcpu->arch.nested_mmu;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_get_rflags",
          "args": [
            "&svm->vcpu"
          ],
          "line": 230
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_get_rflags",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "10221-10229",
          "snippet": "unsigned long kvm_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags;\n\n\trflags = kvm_x86_ops.get_rflags(vcpu);\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\trflags &= ~X86_EFLAGS_TF;\n\treturn rflags;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nunsigned long kvm_get_rflags(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags;\n\n\trflags = kvm_x86_ops.get_rflags(vcpu);\n\tif (vcpu->guest_debug & KVM_GUESTDBG_SINGLESTEP)\n\t\trflags &= ~X86_EFLAGS_TF;\n\treturn rflags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_intercept",
          "args": [
            "svm",
            "INTERCEPT_IRET"
          ],
          "line": 228
        },
        "resolved": true,
        "details": {
          "function_name": "is_intercept",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "299-302",
          "snippet": "static inline bool is_intercept(struct vcpu_svm *svm, int bit)\n{\n\treturn (svm->vmcb->control.intercept & (1ULL << bit)) != 0;\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline bool is_intercept(struct vcpu_svm *svm, int bit)\n{\n\treturn (svm->vmcb->control.intercept & (1ULL << bit)) != 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nvoid enter_svm_guest_mode(struct vcpu_svm *svm, u64 vmcb_gpa,\n\t\t\t  struct vmcb *nested_vmcb, struct kvm_host_map *map)\n{\n\tbool evaluate_pending_interrupts =\n\t\tis_intercept(svm, INTERCEPT_VINTR) ||\n\t\tis_intercept(svm, INTERCEPT_IRET);\n\n\tif (kvm_get_rflags(&svm->vcpu) & X86_EFLAGS_IF)\n\t\tsvm->vcpu.arch.hflags |= HF_HIF_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_HIF_MASK;\n\n\tif (nested_vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) {\n\t\tsvm->nested.nested_cr3 = nested_vmcb->control.nested_cr3;\n\t\tnested_svm_init_mmu_context(&svm->vcpu);\n\t}\n\n\t/* Load the nested guest state */\n\tsvm->vmcb->save.es = nested_vmcb->save.es;\n\tsvm->vmcb->save.cs = nested_vmcb->save.cs;\n\tsvm->vmcb->save.ss = nested_vmcb->save.ss;\n\tsvm->vmcb->save.ds = nested_vmcb->save.ds;\n\tsvm->vmcb->save.gdtr = nested_vmcb->save.gdtr;\n\tsvm->vmcb->save.idtr = nested_vmcb->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, nested_vmcb->save.rflags);\n\tsvm_set_efer(&svm->vcpu, nested_vmcb->save.efer);\n\tsvm_set_cr0(&svm->vcpu, nested_vmcb->save.cr0);\n\tsvm_set_cr4(&svm->vcpu, nested_vmcb->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = nested_vmcb->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = nested_vmcb->save.cr3;\n\t} else\n\t\t(void)kvm_set_cr3(&svm->vcpu, nested_vmcb->save.cr3);\n\n\t/* Guest paging mode is active - reset mmu */\n\tkvm_mmu_reset_context(&svm->vcpu);\n\n\tsvm->vmcb->save.cr2 = svm->vcpu.arch.cr2 = nested_vmcb->save.cr2;\n\tkvm_rax_write(&svm->vcpu, nested_vmcb->save.rax);\n\tkvm_rsp_write(&svm->vcpu, nested_vmcb->save.rsp);\n\tkvm_rip_write(&svm->vcpu, nested_vmcb->save.rip);\n\n\t/* In case we don't even reach vcpu_run, the fields are not updated */\n\tsvm->vmcb->save.rax = nested_vmcb->save.rax;\n\tsvm->vmcb->save.rsp = nested_vmcb->save.rsp;\n\tsvm->vmcb->save.rip = nested_vmcb->save.rip;\n\tsvm->vmcb->save.dr7 = nested_vmcb->save.dr7;\n\tsvm->vmcb->save.dr6 = nested_vmcb->save.dr6;\n\tsvm->vmcb->save.cpl = nested_vmcb->save.cpl;\n\n\tsvm->nested.vmcb_msrpm = nested_vmcb->control.msrpm_base_pa & ~0x0fffULL;\n\tsvm->nested.vmcb_iopm  = nested_vmcb->control.iopm_base_pa  & ~0x0fffULL;\n\n\t/* cache intercepts */\n\tsvm->nested.intercept_cr         = nested_vmcb->control.intercept_cr;\n\tsvm->nested.intercept_dr         = nested_vmcb->control.intercept_dr;\n\tsvm->nested.intercept_exceptions = nested_vmcb->control.intercept_exceptions;\n\tsvm->nested.intercept            = nested_vmcb->control.intercept;\n\n\tsvm_flush_tlb(&svm->vcpu, true);\n\tsvm->vmcb->control.int_ctl = nested_vmcb->control.int_ctl | V_INTR_MASKING_MASK;\n\tif (nested_vmcb->control.int_ctl & V_INTR_MASKING_MASK)\n\t\tsvm->vcpu.arch.hflags |= HF_VINTR_MASK;\n\telse\n\t\tsvm->vcpu.arch.hflags &= ~HF_VINTR_MASK;\n\n\tsvm->vcpu.arch.tsc_offset += nested_vmcb->control.tsc_offset;\n\tsvm->vmcb->control.tsc_offset = svm->vcpu.arch.tsc_offset;\n\n\tsvm->vmcb->control.virt_ext = nested_vmcb->control.virt_ext;\n\tsvm->vmcb->control.int_vector = nested_vmcb->control.int_vector;\n\tsvm->vmcb->control.int_state = nested_vmcb->control.int_state;\n\tsvm->vmcb->control.event_inj = nested_vmcb->control.event_inj;\n\tsvm->vmcb->control.event_inj_err = nested_vmcb->control.event_inj_err;\n\n\tsvm->vmcb->control.pause_filter_count =\n\t\tnested_vmcb->control.pause_filter_count;\n\tsvm->vmcb->control.pause_filter_thresh =\n\t\tnested_vmcb->control.pause_filter_thresh;\n\n\tkvm_vcpu_unmap(&svm->vcpu, map, true);\n\n\t/* Enter Guest-Mode */\n\tenter_guest_mode(&svm->vcpu);\n\n\t/*\n\t * Merge guest and host intercepts - must be called  with vcpu in\n\t * guest-mode to take affect here\n\t */\n\trecalc_intercepts(svm);\n\n\tsvm->nested.vmcb = vmcb_gpa;\n\n\t/*\n\t * If L1 had a pending IRQ/NMI before executing VMRUN,\n\t * which wasn't delivered because it was disallowed (e.g.\n\t * interrupts disabled), L0 needs to evaluate if this pending\n\t * event should cause an exit from L2 to L1 or be delivered\n\t * directly to L2.\n\t *\n\t * Usually this would be handled by the processor noticing an\n\t * IRQ/NMI window request.  However, VMRUN can unblock interrupts\n\t * by implicitly setting GIF, so force L0 to perform pending event\n\t * evaluation by requesting a KVM_REQ_EVENT.\n\t */\n\tenable_gif(svm);\n\tif (unlikely(evaluate_pending_interrupts))\n\t\tkvm_make_request(KVM_REQ_EVENT, &svm->vcpu);\n\n\tmark_all_dirty(svm->vmcb);\n}"
  },
  {
    "function_name": "nested_vmcb_checks",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "205-221",
    "snippet": "static bool nested_vmcb_checks(struct vmcb *vmcb)\n{\n\tif ((vmcb->save.efer & EFER_SVME) == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.intercept & (1ULL << INTERCEPT_VMRUN)) == 0)\n\t\treturn false;\n\n\tif (vmcb->control.asid == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) &&\n\t    !npt_enabled)\n\t\treturn false;\n\n\treturn true;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic bool nested_vmcb_checks(struct vmcb *vmcb)\n{\n\tif ((vmcb->save.efer & EFER_SVME) == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.intercept & (1ULL << INTERCEPT_VMRUN)) == 0)\n\t\treturn false;\n\n\tif (vmcb->control.asid == 0)\n\t\treturn false;\n\n\tif ((vmcb->control.nested_ctl & SVM_NESTED_CTL_NP_ENABLE) &&\n\t    !npt_enabled)\n\t\treturn false;\n\n\treturn true;\n}"
  },
  {
    "function_name": "nested_svm_vmrun_msrpm",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "172-203",
    "snippet": "static bool nested_svm_vmrun_msrpm(struct vcpu_svm *svm)\n{\n\t/*\n\t * This function merges the msr permission bitmaps of kvm and the\n\t * nested vmcb. It is optimized in that it only merges the parts where\n\t * the kvm msr permission bitmap may contain zero bits\n\t */\n\tint i;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn true;\n\n\tfor (i = 0; i < MSRPM_OFFSETS; i++) {\n\t\tu32 value, p;\n\t\tu64 offset;\n\n\t\tif (msrpm_offsets[i] == 0xffffffff)\n\t\t\tbreak;\n\n\t\tp      = msrpm_offsets[i];\n\t\toffset = svm->nested.vmcb_msrpm + (p * 4);\n\n\t\tif (kvm_vcpu_read_guest(&svm->vcpu, offset, &value, 4))\n\t\t\treturn false;\n\n\t\tsvm->nested.msrpm[p] = svm->msrpm[p] | value;\n\t}\n\n\tsvm->vmcb->control.msrpm_base_pa = __sme_set(__pa(svm->nested.msrpm));\n\n\treturn true;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__sme_set",
          "args": [
            "__pa(svm->nested.msrpm)"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pa",
          "args": [
            "svm->nested.msrpm"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest",
          "args": [
            "&svm->vcpu",
            "offset",
            "&value",
            "4"
          ],
          "line": 194
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic bool nested_svm_vmrun_msrpm(struct vcpu_svm *svm)\n{\n\t/*\n\t * This function merges the msr permission bitmaps of kvm and the\n\t * nested vmcb. It is optimized in that it only merges the parts where\n\t * the kvm msr permission bitmap may contain zero bits\n\t */\n\tint i;\n\n\tif (!(svm->nested.intercept & (1ULL << INTERCEPT_MSR_PROT)))\n\t\treturn true;\n\n\tfor (i = 0; i < MSRPM_OFFSETS; i++) {\n\t\tu32 value, p;\n\t\tu64 offset;\n\n\t\tif (msrpm_offsets[i] == 0xffffffff)\n\t\t\tbreak;\n\n\t\tp      = msrpm_offsets[i];\n\t\toffset = svm->nested.vmcb_msrpm + (p * 4);\n\n\t\tif (kvm_vcpu_read_guest(&svm->vcpu, offset, &value, 4))\n\t\t\treturn false;\n\n\t\tsvm->nested.msrpm[p] = svm->msrpm[p] | value;\n\t}\n\n\tsvm->vmcb->control.msrpm_base_pa = __sme_set(__pa(svm->nested.msrpm));\n\n\treturn true;\n}"
  },
  {
    "function_name": "copy_vmcb_control_area",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "140-170",
    "snippet": "static void copy_vmcb_control_area(struct vmcb *dst_vmcb, struct vmcb *from_vmcb)\n{\n\tstruct vmcb_control_area *dst  = &dst_vmcb->control;\n\tstruct vmcb_control_area *from = &from_vmcb->control;\n\n\tdst->intercept_cr         = from->intercept_cr;\n\tdst->intercept_dr         = from->intercept_dr;\n\tdst->intercept_exceptions = from->intercept_exceptions;\n\tdst->intercept            = from->intercept;\n\tdst->iopm_base_pa         = from->iopm_base_pa;\n\tdst->msrpm_base_pa        = from->msrpm_base_pa;\n\tdst->tsc_offset           = from->tsc_offset;\n\tdst->asid                 = from->asid;\n\tdst->tlb_ctl              = from->tlb_ctl;\n\tdst->int_ctl              = from->int_ctl;\n\tdst->int_vector           = from->int_vector;\n\tdst->int_state            = from->int_state;\n\tdst->exit_code            = from->exit_code;\n\tdst->exit_code_hi         = from->exit_code_hi;\n\tdst->exit_info_1          = from->exit_info_1;\n\tdst->exit_info_2          = from->exit_info_2;\n\tdst->exit_int_info        = from->exit_int_info;\n\tdst->exit_int_info_err    = from->exit_int_info_err;\n\tdst->nested_ctl           = from->nested_ctl;\n\tdst->event_inj            = from->event_inj;\n\tdst->event_inj_err        = from->event_inj_err;\n\tdst->nested_cr3           = from->nested_cr3;\n\tdst->virt_ext              = from->virt_ext;\n\tdst->pause_filter_count   = from->pause_filter_count;\n\tdst->pause_filter_thresh  = from->pause_filter_thresh;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void copy_vmcb_control_area(struct vmcb *dst_vmcb, struct vmcb *from_vmcb)\n{\n\tstruct vmcb_control_area *dst  = &dst_vmcb->control;\n\tstruct vmcb_control_area *from = &from_vmcb->control;\n\n\tdst->intercept_cr         = from->intercept_cr;\n\tdst->intercept_dr         = from->intercept_dr;\n\tdst->intercept_exceptions = from->intercept_exceptions;\n\tdst->intercept            = from->intercept;\n\tdst->iopm_base_pa         = from->iopm_base_pa;\n\tdst->msrpm_base_pa        = from->msrpm_base_pa;\n\tdst->tsc_offset           = from->tsc_offset;\n\tdst->asid                 = from->asid;\n\tdst->tlb_ctl              = from->tlb_ctl;\n\tdst->int_ctl              = from->int_ctl;\n\tdst->int_vector           = from->int_vector;\n\tdst->int_state            = from->int_state;\n\tdst->exit_code            = from->exit_code;\n\tdst->exit_code_hi         = from->exit_code_hi;\n\tdst->exit_info_1          = from->exit_info_1;\n\tdst->exit_info_2          = from->exit_info_2;\n\tdst->exit_int_info        = from->exit_int_info;\n\tdst->exit_int_info_err    = from->exit_int_info_err;\n\tdst->nested_ctl           = from->nested_ctl;\n\tdst->event_inj            = from->event_inj;\n\tdst->event_inj_err        = from->event_inj_err;\n\tdst->nested_cr3           = from->nested_cr3;\n\tdst->virt_ext              = from->virt_ext;\n\tdst->pause_filter_count   = from->pause_filter_count;\n\tdst->pause_filter_thresh  = from->pause_filter_thresh;\n}"
  },
  {
    "function_name": "recalc_intercepts",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "99-138",
    "snippet": "void recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h;\n\tstruct nested_state *g;\n\n\tmark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->nested.hsave->control;\n\tg = &svm->nested;\n\n\tc->intercept_cr = h->intercept_cr;\n\tc->intercept_dr = h->intercept_dr;\n\tc->intercept_exceptions = h->intercept_exceptions;\n\tc->intercept = h->intercept;\n\n\tif (svm->vcpu.arch.hflags & HF_VINTR_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_READ);\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tc->intercept &= ~(1ULL << INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tc->intercept &= ~(1ULL << INTERCEPT_VMMCALL);\n\n\tc->intercept_cr |= g->intercept_cr;\n\tc->intercept_dr |= g->intercept_dr;\n\tc->intercept_exceptions |= g->intercept_exceptions;\n\tc->intercept |= g->intercept;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "is_guest_mode",
          "args": [
            "&svm->vcpu"
          ],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "is_guest_mode",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "170-173",
          "snippet": "static inline bool is_guest_mode(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.hflags & HF_GUEST_MASK;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline bool is_guest_mode(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.hflags & HF_GUEST_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mark_dirty",
          "args": [
            "svm->vmcb",
            "VMCB_INTERCEPTS"
          ],
          "line": 104
        },
        "resolved": true,
        "details": {
          "function_name": "mark_dirty",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "187-190",
          "snippet": "static inline void mark_dirty(struct vmcb *vmcb, int bit)\n{\n\tvmcb->control.clean &= ~(1 << bit);\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline void mark_dirty(struct vmcb *vmcb, int bit)\n{\n\tvmcb->control.clean &= ~(1 << bit);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nvoid recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h;\n\tstruct nested_state *g;\n\n\tmark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->nested.hsave->control;\n\tg = &svm->nested;\n\n\tc->intercept_cr = h->intercept_cr;\n\tc->intercept_dr = h->intercept_dr;\n\tc->intercept_exceptions = h->intercept_exceptions;\n\tc->intercept = h->intercept;\n\n\tif (svm->vcpu.arch.hflags & HF_VINTR_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_READ);\n\t\tc->intercept_cr &= ~(1U << INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tc->intercept &= ~(1ULL << INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tc->intercept &= ~(1ULL << INTERCEPT_VMMCALL);\n\n\tc->intercept_cr |= g->intercept_cr;\n\tc->intercept_dr |= g->intercept_dr;\n\tc->intercept_exceptions |= g->intercept_exceptions;\n\tc->intercept |= g->intercept;\n}"
  },
  {
    "function_name": "nested_svm_uninit_mmu_context",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "93-97",
    "snippet": "static void nested_svm_uninit_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.mmu = &vcpu->arch.root_mmu;\n\tvcpu->arch.walk_mmu = &vcpu->arch.root_mmu;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_uninit_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tvcpu->arch.mmu = &vcpu->arch.root_mmu;\n\tvcpu->arch.walk_mmu = &vcpu->arch.root_mmu;\n}"
  },
  {
    "function_name": "nested_svm_init_mmu_context",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "79-91",
    "snippet": "static void nested_svm_init_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON(mmu_is_nested(vcpu));\n\n\tvcpu->arch.mmu = &vcpu->arch.guest_mmu;\n\tkvm_init_shadow_mmu(vcpu);\n\tvcpu->arch.mmu->get_guest_pgd     = nested_svm_get_tdp_cr3;\n\tvcpu->arch.mmu->get_pdptr         = nested_svm_get_tdp_pdptr;\n\tvcpu->arch.mmu->inject_page_fault = nested_svm_inject_npf_exit;\n\tvcpu->arch.mmu->shadow_root_level = kvm_x86_ops.get_tdp_level(vcpu);\n\treset_shadow_zero_bits_mask(vcpu, vcpu->arch.mmu);\n\tvcpu->arch.walk_mmu              = &vcpu->arch.nested_mmu;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "reset_shadow_zero_bits_mask",
          "args": [
            "vcpu",
            "vcpu->arch.mmu"
          ],
          "line": 89
        },
        "resolved": true,
        "details": {
          "function_name": "reset_shadow_zero_bits_mask",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4566-4593",
          "snippet": "void\nreset_shadow_zero_bits_mask(struct kvm_vcpu *vcpu, struct kvm_mmu *context)\n{\n\tbool uses_nx = context->nx ||\n\t\tcontext->mmu_role.base.smep_andnot_wp;\n\tstruct rsvd_bits_validate *shadow_zero_check;\n\tint i;\n\n\t/*\n\t * Passing \"true\" to the last argument is okay; it adds a check\n\t * on bit 8 of the SPTEs which KVM doesn't use anyway.\n\t */\n\tshadow_zero_check = &context->shadow_zero_check;\n\t__reset_rsvds_bits_mask(vcpu, shadow_zero_check,\n\t\t\t\tshadow_phys_bits,\n\t\t\t\tcontext->shadow_root_level, uses_nx,\n\t\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_GBPAGES),\n\t\t\t\tis_pse(vcpu), true);\n\n\tif (!shadow_me_mask)\n\t\treturn;\n\n\tfor (i = context->shadow_root_level; --i >= 0;) {\n\t\tshadow_zero_check->rsvd_bits_mask[0][i] &= ~shadow_me_mask;\n\t\tshadow_zero_check->rsvd_bits_mask[1][i] &= ~shadow_me_mask;\n\t}\n\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nvoid\nreset_shadow_zero_bits_mask(struct kvm_vcpu *vcpu, struct kvm_mmu *context)\n{\n\tbool uses_nx = context->nx ||\n\t\tcontext->mmu_role.base.smep_andnot_wp;\n\tstruct rsvd_bits_validate *shadow_zero_check;\n\tint i;\n\n\t/*\n\t * Passing \"true\" to the last argument is okay; it adds a check\n\t * on bit 8 of the SPTEs which KVM doesn't use anyway.\n\t */\n\tshadow_zero_check = &context->shadow_zero_check;\n\t__reset_rsvds_bits_mask(vcpu, shadow_zero_check,\n\t\t\t\tshadow_phys_bits,\n\t\t\t\tcontext->shadow_root_level, uses_nx,\n\t\t\t\tguest_cpuid_has(vcpu, X86_FEATURE_GBPAGES),\n\t\t\t\tis_pse(vcpu), true);\n\n\tif (!shadow_me_mask)\n\t\treturn;\n\n\tfor (i = context->shadow_root_level; --i >= 0;) {\n\t\tshadow_zero_check->rsvd_bits_mask[0][i] &= ~shadow_me_mask;\n\t\tshadow_zero_check->rsvd_bits_mask[1][i] &= ~shadow_me_mask;\n\t}\n\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops.get_tdp_level",
          "args": [
            "vcpu"
          ],
          "line": 88
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_init_shadow_mmu",
          "args": [
            "vcpu"
          ],
          "line": 84
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_init_shadow_mmu",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4989-5009",
          "snippet": "void kvm_init_shadow_mmu(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *context = vcpu->arch.mmu;\n\tunion kvm_mmu_role new_role =\n\t\tkvm_calc_shadow_mmu_root_page_role(vcpu, false);\n\n\tif (new_role.as_u64 == context->mmu_role.as_u64)\n\t\treturn;\n\n\tif (!is_paging(vcpu))\n\t\tnonpaging_init_context(vcpu, context);\n\telse if (is_long_mode(vcpu))\n\t\tpaging64_init_context(vcpu, context);\n\telse if (is_pae(vcpu))\n\t\tpaging32E_init_context(vcpu, context);\n\telse\n\t\tpaging32_init_context(vcpu, context);\n\n\tcontext->mmu_role.as_u64 = new_role.as_u64;\n\treset_shadow_zero_bits_mask(vcpu, context);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nvoid kvm_init_shadow_mmu(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu *context = vcpu->arch.mmu;\n\tunion kvm_mmu_role new_role =\n\t\tkvm_calc_shadow_mmu_root_page_role(vcpu, false);\n\n\tif (new_role.as_u64 == context->mmu_role.as_u64)\n\t\treturn;\n\n\tif (!is_paging(vcpu))\n\t\tnonpaging_init_context(vcpu, context);\n\telse if (is_long_mode(vcpu))\n\t\tpaging64_init_context(vcpu, context);\n\telse if (is_pae(vcpu))\n\t\tpaging32E_init_context(vcpu, context);\n\telse\n\t\tpaging32_init_context(vcpu, context);\n\n\tcontext->mmu_role.as_u64 = new_role.as_u64;\n\treset_shadow_zero_bits_mask(vcpu, context);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "mmu_is_nested(vcpu)"
          ],
          "line": 81
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_is_nested",
          "args": [
            "vcpu"
          ],
          "line": 81
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_is_nested",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "123-126",
          "snippet": "static inline bool mmu_is_nested(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.walk_mmu == &vcpu->arch.nested_mmu;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline bool mmu_is_nested(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.walk_mmu == &vcpu->arch.nested_mmu;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_init_mmu_context(struct kvm_vcpu *vcpu)\n{\n\tWARN_ON(mmu_is_nested(vcpu));\n\n\tvcpu->arch.mmu = &vcpu->arch.guest_mmu;\n\tkvm_init_shadow_mmu(vcpu);\n\tvcpu->arch.mmu->get_guest_pgd     = nested_svm_get_tdp_cr3;\n\tvcpu->arch.mmu->get_pdptr         = nested_svm_get_tdp_pdptr;\n\tvcpu->arch.mmu->inject_page_fault = nested_svm_inject_npf_exit;\n\tvcpu->arch.mmu->shadow_root_level = kvm_x86_ops.get_tdp_level(vcpu);\n\treset_shadow_zero_bits_mask(vcpu, vcpu->arch.mmu);\n\tvcpu->arch.walk_mmu              = &vcpu->arch.nested_mmu;\n}"
  },
  {
    "function_name": "nested_svm_get_tdp_cr3",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "72-77",
    "snippet": "static unsigned long nested_svm_get_tdp_cr3(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\treturn svm->nested.nested_cr3;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "to_svm",
          "args": [
            "vcpu"
          ],
          "line": 74
        },
        "resolved": true,
        "details": {
          "function_name": "to_svm",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "192-195",
          "snippet": "static inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic unsigned long nested_svm_get_tdp_cr3(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\treturn svm->nested.nested_cr3;\n}"
  },
  {
    "function_name": "nested_svm_get_tdp_pdptr",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "58-70",
    "snippet": "static u64 nested_svm_get_tdp_pdptr(struct kvm_vcpu *vcpu, int index)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\tu64 cr3 = svm->nested.nested_cr3;\n\tu64 pdpte;\n\tint ret;\n\n\tret = kvm_vcpu_read_guest_page(vcpu, gpa_to_gfn(__sme_clr(cr3)), &pdpte,\n\t\t\t\t       offset_in_page(cr3) + index * 8, 8);\n\tif (ret)\n\t\treturn 0;\n\treturn pdpte;\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_page",
          "args": [
            "vcpu",
            "gpa_to_gfn(__sme_clr(cr3))",
            "&pdpte",
            "offset_in_page(cr3) + index * 8",
            "8"
          ],
          "line": 65
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "offset_in_page",
          "args": [
            "cr3"
          ],
          "line": 66
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpa_to_gfn",
          "args": [
            "__sme_clr(cr3)"
          ],
          "line": 65
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__sme_clr",
          "args": [
            "cr3"
          ],
          "line": 65
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_svm",
          "args": [
            "vcpu"
          ],
          "line": 60
        },
        "resolved": true,
        "details": {
          "function_name": "to_svm",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "192-195",
          "snippet": "static inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic u64 nested_svm_get_tdp_pdptr(struct kvm_vcpu *vcpu, int index)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\tu64 cr3 = svm->nested.nested_cr3;\n\tu64 pdpte;\n\tint ret;\n\n\tret = kvm_vcpu_read_guest_page(vcpu, gpa_to_gfn(__sme_clr(cr3)), &pdpte,\n\t\t\t\t       offset_in_page(cr3) + index * 8, 8);\n\tif (ret)\n\t\treturn 0;\n\treturn pdpte;\n}"
  },
  {
    "function_name": "nested_svm_inject_npf_exit",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
    "lines": "29-56",
    "snippet": "static void nested_svm_inject_npf_exit(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct x86_exception *fault)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\tif (svm->vmcb->control.exit_code != SVM_EXIT_NPF) {\n\t\t/*\n\t\t * TODO: track the cause of the nested page fault, and\n\t\t * correctly fill in the high bits of exit_info_1.\n\t\t */\n\t\tsvm->vmcb->control.exit_code = SVM_EXIT_NPF;\n\t\tsvm->vmcb->control.exit_code_hi = 0;\n\t\tsvm->vmcb->control.exit_info_1 = (1ULL << 32);\n\t\tsvm->vmcb->control.exit_info_2 = fault->address;\n\t}\n\n\tsvm->vmcb->control.exit_info_1 &= ~0xffffffffULL;\n\tsvm->vmcb->control.exit_info_1 |= fault->error_code;\n\n\t/*\n\t * The present bit is always zero for page structure faults on real\n\t * hardware.\n\t */\n\tif (svm->vmcb->control.exit_info_1 & (2ULL << 32))\n\t\tsvm->vmcb->control.exit_info_1 &= ~1;\n\n\tnested_svm_vmexit(svm);\n}",
    "includes": [
      "#include \"svm.h\"",
      "#include \"x86.h\"",
      "#include \"mmu.h\"",
      "#include \"trace.h\"",
      "#include \"kvm_emulate.h\"",
      "#include <asm/msr-index.h>",
      "#include <linux/kernel.h>",
      "#include <linux/kvm_host.h>",
      "#include <linux/kvm_types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "nested_svm_vmexit",
          "args": [
            "svm"
          ],
          "line": 55
        },
        "resolved": true,
        "details": {
          "function_name": "nested_svm_vmexit",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/nested.c",
          "lines": "438-579",
          "snippet": "int nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"svm.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"trace.h\"",
            "#include \"kvm_emulate.h\"",
            "#include <asm/msr-index.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nint nested_svm_vmexit(struct vcpu_svm *svm)\n{\n\tint rc;\n\tstruct vmcb *nested_vmcb;\n\tstruct vmcb *hsave = svm->nested.hsave;\n\tstruct vmcb *vmcb = svm->vmcb;\n\tstruct kvm_host_map map;\n\n\ttrace_kvm_nested_vmexit_inject(vmcb->control.exit_code,\n\t\t\t\t       vmcb->control.exit_info_1,\n\t\t\t\t       vmcb->control.exit_info_2,\n\t\t\t\t       vmcb->control.exit_int_info,\n\t\t\t\t       vmcb->control.exit_int_info_err,\n\t\t\t\t       KVM_ISA_SVM);\n\n\trc = kvm_vcpu_map(&svm->vcpu, gpa_to_gfn(svm->nested.vmcb), &map);\n\tif (rc) {\n\t\tif (rc == -EINVAL)\n\t\t\tkvm_inject_gp(&svm->vcpu, 0);\n\t\treturn 1;\n\t}\n\n\tnested_vmcb = map.hva;\n\n\t/* Exit Guest-Mode */\n\tleave_guest_mode(&svm->vcpu);\n\tsvm->nested.vmcb = 0;\n\n\t/* Give the current vmcb to the guest */\n\tdisable_gif(svm);\n\n\tnested_vmcb->save.es     = vmcb->save.es;\n\tnested_vmcb->save.cs     = vmcb->save.cs;\n\tnested_vmcb->save.ss     = vmcb->save.ss;\n\tnested_vmcb->save.ds     = vmcb->save.ds;\n\tnested_vmcb->save.gdtr   = vmcb->save.gdtr;\n\tnested_vmcb->save.idtr   = vmcb->save.idtr;\n\tnested_vmcb->save.efer   = svm->vcpu.arch.efer;\n\tnested_vmcb->save.cr0    = kvm_read_cr0(&svm->vcpu);\n\tnested_vmcb->save.cr3    = kvm_read_cr3(&svm->vcpu);\n\tnested_vmcb->save.cr2    = vmcb->save.cr2;\n\tnested_vmcb->save.cr4    = svm->vcpu.arch.cr4;\n\tnested_vmcb->save.rflags = kvm_get_rflags(&svm->vcpu);\n\tnested_vmcb->save.rip    = vmcb->save.rip;\n\tnested_vmcb->save.rsp    = vmcb->save.rsp;\n\tnested_vmcb->save.rax    = vmcb->save.rax;\n\tnested_vmcb->save.dr7    = vmcb->save.dr7;\n\tnested_vmcb->save.dr6    = vmcb->save.dr6;\n\tnested_vmcb->save.cpl    = vmcb->save.cpl;\n\n\tnested_vmcb->control.int_ctl           = vmcb->control.int_ctl;\n\tnested_vmcb->control.int_vector        = vmcb->control.int_vector;\n\tnested_vmcb->control.int_state         = vmcb->control.int_state;\n\tnested_vmcb->control.exit_code         = vmcb->control.exit_code;\n\tnested_vmcb->control.exit_code_hi      = vmcb->control.exit_code_hi;\n\tnested_vmcb->control.exit_info_1       = vmcb->control.exit_info_1;\n\tnested_vmcb->control.exit_info_2       = vmcb->control.exit_info_2;\n\tnested_vmcb->control.exit_int_info     = vmcb->control.exit_int_info;\n\tnested_vmcb->control.exit_int_info_err = vmcb->control.exit_int_info_err;\n\n\tif (svm->nrips_enabled)\n\t\tnested_vmcb->control.next_rip  = vmcb->control.next_rip;\n\n\t/*\n\t * If we emulate a VMRUN/#VMEXIT in the same host #vmexit cycle we have\n\t * to make sure that we do not lose injected events. So check event_inj\n\t * here and copy it to exit_int_info if it is valid.\n\t * Exit_int_info and event_inj can't be both valid because the case\n\t * below only happens on a VMRUN instruction intercept which has\n\t * no valid exit_int_info set.\n\t */\n\tif (vmcb->control.event_inj & SVM_EVTINJ_VALID) {\n\t\tstruct vmcb_control_area *nc = &nested_vmcb->control;\n\n\t\tnc->exit_int_info     = vmcb->control.event_inj;\n\t\tnc->exit_int_info_err = vmcb->control.event_inj_err;\n\t}\n\n\tnested_vmcb->control.tlb_ctl           = 0;\n\tnested_vmcb->control.event_inj         = 0;\n\tnested_vmcb->control.event_inj_err     = 0;\n\n\tnested_vmcb->control.pause_filter_count =\n\t\tsvm->vmcb->control.pause_filter_count;\n\tnested_vmcb->control.pause_filter_thresh =\n\t\tsvm->vmcb->control.pause_filter_thresh;\n\n\t/* We always set V_INTR_MASKING and remember the old value in hflags */\n\tif (!(svm->vcpu.arch.hflags & HF_VINTR_MASK))\n\t\tnested_vmcb->control.int_ctl &= ~V_INTR_MASKING_MASK;\n\n\t/* Restore the original control entries */\n\tcopy_vmcb_control_area(vmcb, hsave);\n\n\tsvm->vcpu.arch.tsc_offset = svm->vmcb->control.tsc_offset;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\tsvm->nested.nested_cr3 = 0;\n\n\t/* Restore selected save entries */\n\tsvm->vmcb->save.es = hsave->save.es;\n\tsvm->vmcb->save.cs = hsave->save.cs;\n\tsvm->vmcb->save.ss = hsave->save.ss;\n\tsvm->vmcb->save.ds = hsave->save.ds;\n\tsvm->vmcb->save.gdtr = hsave->save.gdtr;\n\tsvm->vmcb->save.idtr = hsave->save.idtr;\n\tkvm_set_rflags(&svm->vcpu, hsave->save.rflags);\n\tsvm_set_efer(&svm->vcpu, hsave->save.efer);\n\tsvm_set_cr0(&svm->vcpu, hsave->save.cr0 | X86_CR0_PE);\n\tsvm_set_cr4(&svm->vcpu, hsave->save.cr4);\n\tif (npt_enabled) {\n\t\tsvm->vmcb->save.cr3 = hsave->save.cr3;\n\t\tsvm->vcpu.arch.cr3 = hsave->save.cr3;\n\t} else {\n\t\t(void)kvm_set_cr3(&svm->vcpu, hsave->save.cr3);\n\t}\n\tkvm_rax_write(&svm->vcpu, hsave->save.rax);\n\tkvm_rsp_write(&svm->vcpu, hsave->save.rsp);\n\tkvm_rip_write(&svm->vcpu, hsave->save.rip);\n\tsvm->vmcb->save.dr7 = 0;\n\tsvm->vmcb->save.cpl = 0;\n\tsvm->vmcb->control.exit_int_info = 0;\n\n\tmark_all_dirty(svm->vmcb);\n\n\tkvm_vcpu_unmap(&svm->vcpu, &map, true);\n\n\tnested_svm_uninit_mmu_context(&svm->vcpu);\n\tkvm_mmu_reset_context(&svm->vcpu);\n\tkvm_mmu_load(&svm->vcpu);\n\n\t/*\n\t * Drop what we picked up for L2 via svm_complete_interrupts() so it\n\t * doesn't end up in L1.\n\t */\n\tsvm->vcpu.arch.nmi_injected = false;\n\tkvm_clear_exception_queue(&svm->vcpu);\n\tkvm_clear_interrupt_queue(&svm->vcpu);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_svm",
          "args": [
            "vcpu"
          ],
          "line": 32
        },
        "resolved": true,
        "details": {
          "function_name": "to_svm",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/svm/svm.h",
          "lines": "192-195",
          "snippet": "static inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}",
          "includes": [
            "#include <asm/svm.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/kvm_types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/svm.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic inline struct vcpu_svm *to_svm(struct kvm_vcpu *vcpu)\n{\n\treturn container_of(vcpu, struct vcpu_svm, vcpu);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"svm.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"trace.h\"\n#include \"kvm_emulate.h\"\n#include <asm/msr-index.h>\n#include <linux/kernel.h>\n#include <linux/kvm_host.h>\n#include <linux/kvm_types.h>\n\nstatic void nested_svm_inject_npf_exit(struct kvm_vcpu *vcpu,\n\t\t\t\t       struct x86_exception *fault)\n{\n\tstruct vcpu_svm *svm = to_svm(vcpu);\n\n\tif (svm->vmcb->control.exit_code != SVM_EXIT_NPF) {\n\t\t/*\n\t\t * TODO: track the cause of the nested page fault, and\n\t\t * correctly fill in the high bits of exit_info_1.\n\t\t */\n\t\tsvm->vmcb->control.exit_code = SVM_EXIT_NPF;\n\t\tsvm->vmcb->control.exit_code_hi = 0;\n\t\tsvm->vmcb->control.exit_info_1 = (1ULL << 32);\n\t\tsvm->vmcb->control.exit_info_2 = fault->address;\n\t}\n\n\tsvm->vmcb->control.exit_info_1 &= ~0xffffffffULL;\n\tsvm->vmcb->control.exit_info_1 |= fault->error_code;\n\n\t/*\n\t * The present bit is always zero for page structure faults on real\n\t * hardware.\n\t */\n\tif (svm->vmcb->control.exit_info_1 & (2ULL << 32))\n\t\tsvm->vmcb->control.exit_info_1 &= ~1;\n\n\tnested_svm_vmexit(svm);\n}"
  }
]