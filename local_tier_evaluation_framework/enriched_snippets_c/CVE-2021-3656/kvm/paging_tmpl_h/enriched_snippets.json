[
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "1010-1082",
    "snippet": "static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\tint set_spte_ret = 0;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(gpte);\n\t\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte_ret |= set_spte(vcpu, &sp->spt[i],\n\t\t\t\t\t pte_access, PT_PAGE_TABLE_LEVEL,\n\t\t\t\t\t gfn, spte_to_pfn(sp->spt[i]),\n\t\t\t\t\t true, false, host_writable);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH)\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\treturn nr_present;\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_flush_remote_tlbs",
          "args": [
            "vcpu->kvm"
          ],
          "line": 1079
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_spte",
          "args": [
            "vcpu",
            "&sp->spt[i]",
            "pte_access",
            "PT_PAGE_TABLE_LEVEL",
            "gfn",
            "spte_to_pfn(sp->spt[i])",
            "true",
            "false",
            "host_writable"
          ],
          "line": 1072
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_set_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3087-3152",
          "snippet": "static int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, int write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_RETRY;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define SET_SPTE_NEED_REMOTE_TLB_FLUSH\tBIT(1)",
            "#define SET_SPTE_WRITE_PROTECTED_PT\tBIT(0)",
            "#define RMAP_RECYCLE_THRESHOLD 1000",
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))",
            "#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define SET_SPTE_NEED_REMOTE_TLB_FLUSH\tBIT(1)\n#define SET_SPTE_WRITE_PROTECTED_PT\tBIT(0)\n#define RMAP_RECYCLE_THRESHOLD 1000\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, int write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_RETRY;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "spte_to_pfn",
          "args": [
            "sp->spt[i]"
          ],
          "line": 1074
        },
        "resolved": true,
        "details": {
          "function_name": "spte_to_pfn",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "635-638",
          "snippet": "static kvm_pfn_t spte_to_pfn(u64 pte)\n{\n\treturn (pte & PT64_BASE_ADDR_MASK) >> PAGE_SHIFT;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))",
            "#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))\n\nstatic kvm_pfn_t spte_to_pfn(u64 pte)\n{\n\treturn (pte & PT64_BASE_ADDR_MASK) >> PAGE_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 1063
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "drop_spte",
          "args": [
            "vcpu->kvm",
            "&sp->spt[i]"
          ],
          "line": 1058
        },
        "resolved": true,
        "details": {
          "function_name": "drop_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1522-1526",
          "snippet": "static void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sync_mmio_spte",
          "args": [
            "vcpu",
            "&sp->spt[i]",
            "gfn",
            "pte_access",
            "&nr_present"
          ],
          "line": 1053
        },
        "resolved": true,
        "details": {
          "function_name": "sync_mmio_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4366-4381",
          "snippet": "static bool sync_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, gfn_t gfn,\n\t\t\t   unsigned int access, int *nr_present)\n{\n\tif (unlikely(is_mmio_spte(*sptep))) {\n\t\tif (gfn != get_mmio_spte_gfn(*sptep)) {\n\t\t\tmmu_spte_clear_no_track(sptep);\n\t\t\treturn true;\n\t\t}\n\n\t\t(*nr_present)++;\n\t\tmark_mmio_spte(vcpu, sptep, gfn, access);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic bool sync_mmio_spte(struct kvm_vcpu *vcpu, u64 *sptep, gfn_t gfn,\n\t\t\t   unsigned int access, int *nr_present)\n{\n\tif (unlikely(is_mmio_spte(*sptep))) {\n\t\tif (gfn != get_mmio_spte_gfn(*sptep)) {\n\t\t\tmmu_spte_clear_no_track(sptep);\n\t\t\treturn true;\n\t\t}\n\n\t\t(*nr_present)++;\n\t\tmark_mmio_spte(vcpu, sptep, gfn, access);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu->arch.mmu",
            "&pte_access",
            "gpte"
          ],
          "line": 1051
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "895-949",
          "snippet": "static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry_using_root(vcpu, root_hpa, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm,\n\t\t\t\t\tsp->gfn, KVM_PAGES_PER_HPAGE(sp->role.level));\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn",
          "args": [
            "gpte"
          ],
          "line": 1048
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 1043
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "pte_gpa",
            "&gpte",
            "sizeof(pt_element_t)"
          ],
          "line": 1033
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "sp->role.direct"
          ],
          "line": 1018
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\tint set_spte_ret = 0;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(gpte);\n\t\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte_ret |= set_spte(vcpu, &sp->spt[i],\n\t\t\t\t\t pte_access, PT_PAGE_TABLE_LEVEL,\n\t\t\t\t\t gfn, spte_to_pfn(sp->spt[i]),\n\t\t\t\t\t true, false, host_writable);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH)\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\treturn nr_present;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "972-994",
    "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit GVA should be impossible on 32-bit KVM. */\n\tWARN_ON_ONCE(vaddr >> 32);\n#endif\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "walker.gfn"
          ],
          "line": 988
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&walker",
            "vcpu",
            "vaddr",
            "access"
          ],
          "line": 985
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "972-994",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit GVA should be impossible on 32-bit KVM. */\n\tWARN_ON_ONCE(vaddr >> 32);\n#endif\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "vaddr >> 32"
          ],
          "line": 982
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit GVA should be impossible on 32-bit KVM. */\n\tWARN_ON_ONCE(vaddr >> 32);\n#endif\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "952-968",
    "snippet": "static gpa_t FNAME(gva_to_gpa)(struct kvm_vcpu *vcpu, gpa_t addr, u32 access,\n\t\t\t       struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr)(&walker, vcpu, addr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= addr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "walker.gfn"
          ],
          "line": 962
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&walker",
            "vcpu",
            "addr",
            "access"
          ],
          "line": 959
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "972-994",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit GVA should be impossible on 32-bit KVM. */\n\tWARN_ON_ONCE(vaddr >> 32);\n#endif\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic gpa_t FNAME(gva_to_gpa)(struct kvm_vcpu *vcpu, gpa_t addr, u32 access,\n\t\t\t       struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n\tr = FNAME(walk_addr)(&walker, vcpu, addr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= addr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "895-949",
    "snippet": "static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry_using_root(vcpu, root_hpa, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm,\n\t\t\t\t\tsp->gfn, KVM_PAGES_PER_HPAGE(sp->role.level));\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 948
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_shadow_present_pte",
          "args": [
            "*sptep"
          ],
          "line": 945
        },
        "resolved": true,
        "details": {
          "function_name": "is_shadow_present_pte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "611-614",
          "snippet": "static int is_shadow_present_pte(u64 pte)\n{\n\treturn (pte != 0) && !is_mmio_spte(pte);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_shadow_present_pte(u64 pte)\n{\n\treturn (pte != 0) && !is_mmio_spte(pte);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "sp",
            "sptep",
            "&gpte"
          ],
          "line": 942
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "972-994",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit GVA should be impossible on 32-bit KVM. */\n\tWARN_ON_ONCE(vaddr >> 32);\n#endif\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "pte_gpa",
            "&gpte",
            "sizeof(pt_element_t)"
          ],
          "line": 938
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rmap_can_add",
          "args": [
            "vcpu"
          ],
          "line": 935
        },
        "resolved": true,
        "details": {
          "function_name": "rmap_can_add",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1415-1421",
          "snippet": "static bool rmap_can_add(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu_memory_cache *cache;\n\n\tcache = &vcpu->arch.mmu_pte_list_desc_cache;\n\treturn mmu_memory_cache_free_objects(cache);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic bool rmap_can_add(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_mmu_memory_cache *cache;\n\n\tcache = &vcpu->arch.mmu_pte_list_desc_cache;\n\treturn mmu_memory_cache_free_objects(cache);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_flush_remote_tlbs_with_address",
          "args": [
            "vcpu->kvm",
            "sp->gfn",
            "KVM_PAGES_PER_HPAGE(sp->role.level)"
          ],
          "line": 932
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_flush_remote_tlbs_with_address",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "323-332",
          "snippet": "static void kvm_flush_remote_tlbs_with_address(struct kvm *kvm,\n\t\tu64 start_gfn, u64 pages)\n{\n\tstruct kvm_tlb_range range;\n\n\trange.start_gfn = start_gfn;\n\trange.pages = pages;\n\n\tkvm_flush_remote_tlbs_with_range(kvm, &range);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void kvm_flush_remote_tlbs_with_address(struct kvm *kvm,\n\t\tu64 start_gfn, u64 pages)\n{\n\tstruct kvm_tlb_range range;\n\n\trange.start_gfn = start_gfn;\n\trange.pages = pages;\n\n\tkvm_flush_remote_tlbs_with_range(kvm, &range);\n}"
        }
      },
      {
        "call_info": {
          "callee": "KVM_PAGES_PER_HPAGE",
          "args": [
            "sp->role.level"
          ],
          "line": 933
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_page_zap_pte",
          "args": [
            "vcpu->kvm",
            "sp",
            "sptep"
          ],
          "line": 931
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_page_zap_pte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2674-2697",
          "snippet": "static bool mmu_page_zap_pte(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t     u64 *spte)\n{\n\tu64 pte;\n\tstruct kvm_mmu_page *child;\n\n\tpte = *spte;\n\tif (is_shadow_present_pte(pte)) {\n\t\tif (is_last_spte(pte, sp->role.level)) {\n\t\t\tdrop_spte(kvm, spte);\n\t\t\tif (is_large_pte(pte))\n\t\t\t\t--kvm->stat.lpages;\n\t\t} else {\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, spte);\n\t\t}\n\t\treturn true;\n\t}\n\n\tif (is_mmio_spte(pte))\n\t\tmmu_spte_clear_no_track(spte);\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))",
            "#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic void mark_unsync(u64 *spte);\n\nstatic bool mmu_page_zap_pte(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t     u64 *spte)\n{\n\tu64 pte;\n\tstruct kvm_mmu_page *child;\n\n\tpte = *spte;\n\tif (is_shadow_present_pte(pte)) {\n\t\tif (is_last_spte(pte, sp->role.level)) {\n\t\t\tdrop_spte(kvm, spte);\n\t\t\tif (is_large_pte(pte))\n\t\t\t\t--kvm->stat.lpages;\n\t\t} else {\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, spte);\n\t\t}\n\t\treturn true;\n\t}\n\n\tif (is_mmio_spte(pte))\n\t\tmmu_spte_clear_no_track(spte);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_last_spte",
          "args": [
            "*sptep",
            "level"
          ],
          "line": 921
        },
        "resolved": true,
        "details": {
          "function_name": "is_last_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "621-628",
          "snippet": "static int is_last_spte(u64 pte, int level)\n{\n\tif (level == PT_PAGE_TABLE_LEVEL)\n\t\treturn 1;\n\tif (is_large_pte(pte))\n\t\treturn 1;\n\treturn 0;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_last_spte(u64 pte, int level)\n{\n\tif (level == PT_PAGE_TABLE_LEVEL)\n\t\treturn 1;\n\tif (is_large_pte(pte))\n\t\treturn 1;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_header",
          "args": [
            "__pa(sptep)"
          ],
          "line": 920
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pa",
          "args": [
            "sptep"
          ],
          "line": 920
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_shadow_entry_using_root",
          "args": [
            "vcpu",
            "root_hpa",
            "gva",
            "iterator"
          ],
          "line": 916
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 915
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "1"
          ],
          "line": 911
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "VALID_PAGE",
          "args": [
            "root_hpa"
          ],
          "line": 910
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_topup_memory_caches",
          "args": [
            "vcpu"
          ],
          "line": 908
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_topup_memory_caches",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1112-1127",
          "snippet": "static int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PTE_PREFETCH_NUM\t\t8"
          ],
          "globals_used": [
            "static struct kmem_cache *pte_list_desc_cache;",
            "static struct kmem_cache *mmu_page_header_cache;",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PTE_PREFETCH_NUM\t\t8\n\nstatic struct kmem_cache *pte_list_desc_cache;\nstatic struct kmem_cache *mmu_page_header_cache;\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "vcpu_clear_mmio_info",
          "args": [
            "vcpu",
            "gva"
          ],
          "line": 902
        },
        "resolved": true,
        "details": {
          "function_name": "vcpu_clear_mmio_info",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "192-198",
          "snippet": "static inline void vcpu_clear_mmio_info(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tif (gva != MMIO_GVA_ANY && vcpu->arch.mmio_gva != (gva & PAGE_MASK))\n\t\treturn;\n\n\tvcpu->arch.mmio_gva = 0;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define MMIO_GVA_ANY (~(gva_t)0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\n#define MMIO_GVA_ANY (~(gva_t)0)\n\nstatic inline void vcpu_clear_mmio_info(struct kvm_vcpu *vcpu, gva_t gva)\n{\n\tif (gva != MMIO_GVA_ANY && vcpu->arch.mmio_gva != (gva & PAGE_MASK))\n\t\treturn;\n\n\tvcpu->arch.mmio_gva = 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry_using_root(vcpu, root_hpa, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm,\n\t\t\t\t\tsp->gfn, KVM_PAGES_PER_HPAGE(sp->role.level));\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "883-893",
    "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "sp->gfn"
          ],
          "line": 892
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "sp->role.level != PT_PAGE_TABLE_LEVEL"
          ],
          "line": 887
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "778-881",
    "snippet": "static int FNAME(page_fault)(struct kvm_vcpu *vcpu, gpa_t addr, u32 error_code,\n\t\t\t     bool prefault)\n{\n\tint write_fault = error_code & PFERR_WRITE_MASK;\n\tint user_fault = error_code & PFERR_USER_MASK;\n\tstruct guest_walker walker;\n\tint r;\n\tkvm_pfn_t pfn;\n\tunsigned long mmu_seq;\n\tbool map_writable, is_self_change_mapping;\n\tbool lpage_disallowed = (error_code & PFERR_FETCH_MASK) &&\n\t\t\t\tis_nx_huge_page_enabled();\n\tint max_level;\n\n\tpgprintk(\"%s: addr %lx err %x\\n\", __func__, addr, error_code);\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * If PFEC.RSVD is set, this is a shadow page fault.\n\t * The bit needs to be cleared before walking guest page tables.\n\t */\n\terror_code &= ~PFERR_RSVD_MASK;\n\n\t/*\n\t * Look up the guest pte for the faulting address.\n\t */\n\tr = FNAME(walk_addr)(&walker, vcpu, addr, error_code);\n\n\t/*\n\t * The page is not mapped by the guest.  Let the guest handle it.\n\t */\n\tif (!r) {\n\t\tpgprintk(\"%s: guest page fault\\n\", __func__);\n\t\tif (!prefault)\n\t\t\tinject_page_fault(vcpu, &walker.fault);\n\n\t\treturn RET_PF_RETRY;\n\t}\n\n\tif (page_fault_handle_page_track(vcpu, error_code, walker.gfn)) {\n\t\tshadow_page_table_clear_flood(vcpu, addr);\n\t\treturn RET_PF_EMULATE;\n\t}\n\n\tvcpu->arch.write_fault_to_shadow_pgtable = false;\n\n\tis_self_change_mapping = FNAME(is_self_change_mapping)(vcpu,\n\t      &walker, user_fault, &vcpu->arch.write_fault_to_shadow_pgtable);\n\n\tif (lpage_disallowed || is_self_change_mapping)\n\t\tmax_level = PT_PAGE_TABLE_LEVEL;\n\telse\n\t\tmax_level = walker.level;\n\n\tmmu_seq = vcpu->kvm->mmu_notifier_seq;\n\tsmp_rmb();\n\n\tif (try_async_pf(vcpu, prefault, walker.gfn, addr, &pfn, write_fault,\n\t\t\t &map_writable))\n\t\treturn RET_PF_RETRY;\n\n\tif (handle_abnormal_pfn(vcpu, addr, walker.gfn, pfn, walker.pte_access, &r))\n\t\treturn r;\n\n\t/*\n\t * Do not change pte_access if the pfn is a mmio page, otherwise\n\t * we will cache the incorrect access into mmio spte.\n\t */\n\tif (write_fault && !(walker.pte_access & ACC_WRITE_MASK) &&\n\t     !is_write_protection(vcpu) && !user_fault &&\n\t      !is_noslot_pfn(pfn)) {\n\t\twalker.pte_access |= ACC_WRITE_MASK;\n\t\twalker.pte_access &= ~ACC_USER_MASK;\n\n\t\t/*\n\t\t * If we converted a user page to a kernel page,\n\t\t * so that the kernel can write to it when cr0.wp=0,\n\t\t * then we should prevent the kernel from executing it\n\t\t * if SMEP is enabled.\n\t\t */\n\t\tif (kvm_read_cr4_bits(vcpu, X86_CR4_SMEP))\n\t\t\twalker.pte_access &= ~ACC_EXEC_MASK;\n\t}\n\n\tr = RET_PF_RETRY;\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tif (mmu_notifier_retry(vcpu->kvm, mmu_seq))\n\t\tgoto out_unlock;\n\n\tkvm_mmu_audit(vcpu, AUDIT_PRE_PAGE_FAULT);\n\tif (make_mmu_pages_available(vcpu) < 0)\n\t\tgoto out_unlock;\n\tr = FNAME(fetch)(vcpu, addr, &walker, write_fault, max_level, pfn,\n\t\t\t map_writable, prefault, lpage_disallowed);\n\tkvm_mmu_audit(vcpu, AUDIT_POST_PAGE_FAULT);\n\nout_unlock:\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\tkvm_release_pfn_clean(pfn);\n\treturn r;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_release_pfn_clean",
          "args": [
            "pfn"
          ],
          "line": 879
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 878
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_mmu_audit",
          "args": [
            "vcpu",
            "AUDIT_POST_PAGE_FAULT"
          ],
          "line": 875
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_audit",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2322-2322",
          "snippet": "static void kvm_mmu_audit(struct kvm_vcpu *vcpu, int point) { }",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic void kvm_mmu_audit(struct kvm_vcpu *vcpu, int point) { }"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "addr",
            "&walker",
            "write_fault",
            "max_level",
            "pfn",
            "map_writable",
            "prefault",
            "lpage_disallowed"
          ],
          "line": 873
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "629-722",
          "snippet": "static int FNAME(fetch)(struct kvm_vcpu *vcpu, gpa_t addr,\n\t\t\t struct guest_walker *gw,\n\t\t\t int write_fault, int max_level,\n\t\t\t kvm_pfn_t pfn, bool map_writable, bool prefault,\n\t\t\t bool lpage_disallowed)\n{\n\tstruct kvm_mmu_page *sp = NULL;\n\tstruct kvm_shadow_walk_iterator it;\n\tunsigned direct_access, access = gw->pt_access;\n\tint top_level, hlevel, ret;\n\tgfn_t base_gfn = gw->gfn;\n\n\tdirect_access = gw->pte_access;\n\n\ttop_level = vcpu->arch.mmu->root_level;\n\tif (top_level == PT32E_ROOT_LEVEL)\n\t\ttop_level = PT32_ROOT_LEVEL;\n\t/*\n\t * Verify that the top-level gpte is still there.  Since the page\n\t * is a root page, it is either write protected (and cannot be\n\t * changed from now on) or it is invalid (in which case, we don't\n\t * really care if it changes underneath us after this point).\n\t */\n\tif (FNAME(gpte_changed)(vcpu, gw, top_level))\n\t\tgoto out_gpte_changed;\n\n\tif (WARN_ON(!VALID_PAGE(vcpu->arch.mmu->root_hpa)))\n\t\tgoto out_gpte_changed;\n\n\tfor (shadow_walk_init(&it, vcpu, addr);\n\t     shadow_walk_okay(&it) && it.level > gw->level;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t table_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tsp = NULL;\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\ttable_gfn = gw->table_gfn[it.level - 2];\n\t\t\tsp = kvm_mmu_get_page(vcpu, table_gfn, addr, it.level-1,\n\t\t\t\t\t      false, access);\n\t\t}\n\n\t\t/*\n\t\t * Verify that the gpte in the page we've just write\n\t\t * protected is still there.\n\t\t */\n\t\tif (FNAME(gpte_changed)(vcpu, gw, it.level - 1))\n\t\t\tgoto out_gpte_changed;\n\n\t\tif (sp)\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\thlevel = kvm_mmu_hugepage_adjust(vcpu, gw->gfn, max_level, &pfn);\n\n\ttrace_kvm_mmu_spte_requested(addr, gw->level, pfn);\n\n\tfor (; shadow_walk_okay(&it); shadow_walk_next(&it)) {\n\t\tclear_sp_write_flooding_count(it.sptep);\n\n\t\t/*\n\t\t * We cannot overwrite existing page tables with an NX\n\t\t * large page, as the leaf could be executable.\n\t\t */\n\t\tdisallowed_hugepage_adjust(it, gw->gfn, &pfn, &hlevel);\n\n\t\tbase_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\t\tif (it.level == hlevel)\n\t\t\tbreak;\n\n\t\tvalidate_direct_spte(vcpu, it.sptep, direct_access);\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\tsp = kvm_mmu_get_page(vcpu, base_gfn, addr,\n\t\t\t\t\t      it.level - 1, true, direct_access);\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t\t\tif (lpage_disallowed)\n\t\t\t\taccount_huge_nx_page(vcpu->kvm, sp);\n\t\t}\n\t}\n\n\tret = mmu_set_spte(vcpu, it.sptep, gw->pte_access, write_fault,\n\t\t\t   it.level, base_gfn, pfn, prefault, map_writable);\n\tFNAME(pte_prefetch)(vcpu, gw, it.sptep);\n\t++vcpu->stat.pf_fixed;\n\treturn ret;\n\nout_gpte_changed:\n\treturn RET_PF_RETRY;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "make_mmu_pages_available",
          "args": [
            "vcpu"
          ],
          "line": 871
        },
        "resolved": true,
        "details": {
          "function_name": "make_mmu_pages_available",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2833-2851",
          "snippet": "static int make_mmu_pages_available(struct kvm_vcpu *vcpu)\n{\n\tLIST_HEAD(invalid_list);\n\n\tif (likely(kvm_mmu_available_pages(vcpu->kvm) >= KVM_MIN_FREE_MMU_PAGES))\n\t\treturn 0;\n\n\twhile (kvm_mmu_available_pages(vcpu->kvm) < KVM_REFILL_PAGES) {\n\t\tif (!prepare_zap_oldest_mmu_page(vcpu->kvm, &invalid_list))\n\t\t\tbreak;\n\n\t\t++vcpu->kvm->stat.mmu_recycled;\n\t}\n\tkvm_mmu_commit_zap_page(vcpu->kvm, &invalid_list);\n\n\tif (!kvm_mmu_available_pages(vcpu->kvm))\n\t\treturn -ENOSPC;\n\treturn 0;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static bool kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t     struct list_head *invalid_list);",
            "static void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic bool kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t     struct list_head *invalid_list);\nstatic void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);\n\nstatic int make_mmu_pages_available(struct kvm_vcpu *vcpu)\n{\n\tLIST_HEAD(invalid_list);\n\n\tif (likely(kvm_mmu_available_pages(vcpu->kvm) >= KVM_MIN_FREE_MMU_PAGES))\n\t\treturn 0;\n\n\twhile (kvm_mmu_available_pages(vcpu->kvm) < KVM_REFILL_PAGES) {\n\t\tif (!prepare_zap_oldest_mmu_page(vcpu->kvm, &invalid_list))\n\t\t\tbreak;\n\n\t\t++vcpu->kvm->stat.mmu_recycled;\n\t}\n\tkvm_mmu_commit_zap_page(vcpu->kvm, &invalid_list);\n\n\tif (!kvm_mmu_available_pages(vcpu->kvm))\n\t\treturn -ENOSPC;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mmu_notifier_retry",
          "args": [
            "vcpu->kvm",
            "mmu_seq"
          ],
          "line": 867
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&vcpu->kvm->mmu_lock"
          ],
          "line": 866
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_read_cr4_bits",
          "args": [
            "vcpu",
            "X86_CR4_SMEP"
          ],
          "line": 861
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr4_bits",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "129-135",
          "snippet": "static inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\n#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)\n\nstatic inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_noslot_pfn",
          "args": [
            "pfn"
          ],
          "line": 851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_write_protection",
          "args": [
            "vcpu"
          ],
          "line": 850
        },
        "resolved": true,
        "details": {
          "function_name": "is_write_protection",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "156-159",
          "snippet": "static inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}"
        }
      },
      {
        "call_info": {
          "callee": "handle_abnormal_pfn",
          "args": [
            "vcpu",
            "addr",
            "walker.gfn",
            "pfn",
            "walker.pte_access",
            "&r"
          ],
          "line": 842
        },
        "resolved": true,
        "details": {
          "function_name": "handle_abnormal_pfn",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3406-3421",
          "snippet": "static bool handle_abnormal_pfn(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,\n\t\t\t\tkvm_pfn_t pfn, unsigned int access,\n\t\t\t\tint *ret_val)\n{\n\t/* The pfn is invalid, report the error! */\n\tif (unlikely(is_error_pfn(pfn))) {\n\t\t*ret_val = kvm_handle_bad_page(vcpu, gfn, pfn);\n\t\treturn true;\n\t}\n\n\tif (unlikely(is_noslot_pfn(pfn)))\n\t\tvcpu_cache_mmio_info(vcpu, gva, gfn,\n\t\t\t\t     access & shadow_mmio_access_mask);\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic bool handle_abnormal_pfn(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,\n\t\t\t\tkvm_pfn_t pfn, unsigned int access,\n\t\t\t\tint *ret_val)\n{\n\t/* The pfn is invalid, report the error! */\n\tif (unlikely(is_error_pfn(pfn))) {\n\t\t*ret_val = kvm_handle_bad_page(vcpu, gfn, pfn);\n\t\treturn true;\n\t}\n\n\tif (unlikely(is_noslot_pfn(pfn)))\n\t\tvcpu_cache_mmio_info(vcpu, gva, gfn,\n\t\t\t\t     access & shadow_mmio_access_mask);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "try_async_pf",
          "args": [
            "vcpu",
            "prefault",
            "walker.gfn",
            "addr",
            "&pfn",
            "write_fault",
            "&map_writable"
          ],
          "line": 838
        },
        "resolved": true,
        "details": {
          "function_name": "try_async_pf",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4082-4115",
          "snippet": "static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gpa_t cr2_or_gpa, kvm_pfn_t *pfn, bool write,\n\t\t\t bool *writable)\n{\n\tstruct kvm_memory_slot *slot;\n\tbool async;\n\n\t/*\n\t * Don't expose private memslots to L2.\n\t */\n\tif (is_guest_mode(vcpu) && !kvm_is_visible_gfn(vcpu->kvm, gfn)) {\n\t\t*pfn = KVM_PFN_NOSLOT;\n\t\treturn false;\n\t}\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tasync = false;\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, &async, write, writable);\n\tif (!async)\n\t\treturn false; /* *pfn has correct page already */\n\n\tif (!prefault && kvm_can_do_async_pf(vcpu)) {\n\t\ttrace_kvm_try_async_get_page(cr2_or_gpa, gfn);\n\t\tif (kvm_find_async_pf_gfn(vcpu, gfn)) {\n\t\t\ttrace_kvm_async_pf_doublefault(cr2_or_gpa, gfn);\n\t\t\tkvm_make_request(KVM_REQ_APF_HALT, vcpu);\n\t\t\treturn true;\n\t\t} else if (kvm_arch_setup_async_pf(vcpu, cr2_or_gpa, gfn))\n\t\t\treturn true;\n\t}\n\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, NULL, write, writable);\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,\n\t\t\t gpa_t cr2_or_gpa, kvm_pfn_t *pfn, bool write,\n\t\t\t bool *writable)\n{\n\tstruct kvm_memory_slot *slot;\n\tbool async;\n\n\t/*\n\t * Don't expose private memslots to L2.\n\t */\n\tif (is_guest_mode(vcpu) && !kvm_is_visible_gfn(vcpu->kvm, gfn)) {\n\t\t*pfn = KVM_PFN_NOSLOT;\n\t\treturn false;\n\t}\n\n\tslot = kvm_vcpu_gfn_to_memslot(vcpu, gfn);\n\tasync = false;\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, &async, write, writable);\n\tif (!async)\n\t\treturn false; /* *pfn has correct page already */\n\n\tif (!prefault && kvm_can_do_async_pf(vcpu)) {\n\t\ttrace_kvm_try_async_get_page(cr2_or_gpa, gfn);\n\t\tif (kvm_find_async_pf_gfn(vcpu, gfn)) {\n\t\t\ttrace_kvm_async_pf_doublefault(cr2_or_gpa, gfn);\n\t\t\tkvm_make_request(KVM_REQ_APF_HALT, vcpu);\n\t\t\treturn true;\n\t\t} else if (kvm_arch_setup_async_pf(vcpu, cr2_or_gpa, gfn))\n\t\t\treturn true;\n\t}\n\n\t*pfn = __gfn_to_pfn_memslot(slot, gfn, false, NULL, write, writable);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 836
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "shadow_page_table_clear_flood",
          "args": [
            "vcpu",
            "addr"
          ],
          "line": 821
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_page_table_clear_flood",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4054-4066",
          "snippet": "static void shadow_page_table_clear_flood(struct kvm_vcpu *vcpu, gva_t addr)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tu64 spte;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\tfor_each_shadow_entry_lockless(vcpu, addr, iterator, spte) {\n\t\tclear_sp_write_flooding_count(iterator.sptep);\n\t\tif (!is_shadow_present_pte(spte))\n\t\t\tbreak;\n\t}\n\twalk_shadow_page_lockless_end(vcpu);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic void shadow_page_table_clear_flood(struct kvm_vcpu *vcpu, gva_t addr)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tu64 spte;\n\n\twalk_shadow_page_lockless_begin(vcpu);\n\tfor_each_shadow_entry_lockless(vcpu, addr, iterator, spte) {\n\t\tclear_sp_write_flooding_count(iterator.sptep);\n\t\tif (!is_shadow_present_pte(spte))\n\t\t\tbreak;\n\t}\n\twalk_shadow_page_lockless_end(vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_fault_handle_page_track",
          "args": [
            "vcpu",
            "error_code",
            "walker.gfn"
          ],
          "line": 820
        },
        "resolved": true,
        "details": {
          "function_name": "page_fault_handle_page_track",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4034-4052",
          "snippet": "static bool page_fault_handle_page_track(struct kvm_vcpu *vcpu,\n\t\t\t\t\t u32 error_code, gfn_t gfn)\n{\n\tif (unlikely(error_code & PFERR_RSVD_MASK))\n\t\treturn false;\n\n\tif (!(error_code & PFERR_PRESENT_MASK) ||\n\t      !(error_code & PFERR_WRITE_MASK))\n\t\treturn false;\n\n\t/*\n\t * guest is writing the page which is write tracked which can\n\t * not be fixed by page fault handler.\n\t */\n\tif (kvm_page_track_is_active(vcpu, gfn, KVM_PAGE_TRACK_WRITE))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic bool page_fault_handle_page_track(struct kvm_vcpu *vcpu,\n\t\t\t\t\t u32 error_code, gfn_t gfn)\n{\n\tif (unlikely(error_code & PFERR_RSVD_MASK))\n\t\treturn false;\n\n\tif (!(error_code & PFERR_PRESENT_MASK) ||\n\t      !(error_code & PFERR_WRITE_MASK))\n\t\treturn false;\n\n\t/*\n\t * guest is writing the page which is write tracked which can\n\t * not be fixed by page fault handler.\n\t */\n\tif (kvm_page_track_is_active(vcpu, gfn, KVM_PAGE_TRACK_WRITE))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "inject_page_fault",
          "args": [
            "vcpu",
            "&walker.fault"
          ],
          "line": 815
        },
        "resolved": true,
        "details": {
          "function_name": "inject_page_fault",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4360-4364",
          "snippet": "static void inject_page_fault(struct kvm_vcpu *vcpu,\n\t\t\t      struct x86_exception *fault)\n{\n\tvcpu->arch.mmu->inject_page_fault(vcpu, fault);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic void inject_page_fault(struct kvm_vcpu *vcpu,\n\t\t\t      struct x86_exception *fault)\n{\n\tvcpu->arch.mmu->inject_page_fault(vcpu, fault);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: guest page fault\\n\"",
            "__func__"
          ],
          "line": 813
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_topup_memory_caches",
          "args": [
            "vcpu"
          ],
          "line": 794
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_topup_memory_caches",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1112-1127",
          "snippet": "static int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PTE_PREFETCH_NUM\t\t8"
          ],
          "globals_used": [
            "static struct kmem_cache *pte_list_desc_cache;",
            "static struct kmem_cache *mmu_page_header_cache;",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PTE_PREFETCH_NUM\t\t8\n\nstatic struct kmem_cache *pte_list_desc_cache;\nstatic struct kmem_cache *mmu_page_header_cache;\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic int mmu_topup_memory_caches(struct kvm_vcpu *vcpu)\n{\n\tint r;\n\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_pte_list_desc_cache,\n\t\t\t\t   pte_list_desc_cache, 8 + PTE_PREFETCH_NUM);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache_page(&vcpu->arch.mmu_page_cache, 8);\n\tif (r)\n\t\tgoto out;\n\tr = mmu_topup_memory_cache(&vcpu->arch.mmu_page_header_cache,\n\t\t\t\t   mmu_page_header_cache, 4);\nout:\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: addr %lx err %x\\n\"",
            "__func__",
            "addr",
            "error_code"
          ],
          "line": 792
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_nx_huge_page_enabled",
          "args": [],
          "line": 789
        },
        "resolved": true,
        "details": {
          "function_name": "is_nx_huge_page_enabled",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "377-380",
          "snippet": "static bool is_nx_huge_page_enabled(void)\n{\n\treturn READ_ONCE(nx_huge_pages);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool is_nx_huge_page_enabled(void)\n{\n\treturn READ_ONCE(nx_huge_pages);\n}"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(page_fault)(struct kvm_vcpu *vcpu, gpa_t addr, u32 error_code,\n\t\t\t     bool prefault)\n{\n\tint write_fault = error_code & PFERR_WRITE_MASK;\n\tint user_fault = error_code & PFERR_USER_MASK;\n\tstruct guest_walker walker;\n\tint r;\n\tkvm_pfn_t pfn;\n\tunsigned long mmu_seq;\n\tbool map_writable, is_self_change_mapping;\n\tbool lpage_disallowed = (error_code & PFERR_FETCH_MASK) &&\n\t\t\t\tis_nx_huge_page_enabled();\n\tint max_level;\n\n\tpgprintk(\"%s: addr %lx err %x\\n\", __func__, addr, error_code);\n\n\tr = mmu_topup_memory_caches(vcpu);\n\tif (r)\n\t\treturn r;\n\n\t/*\n\t * If PFEC.RSVD is set, this is a shadow page fault.\n\t * The bit needs to be cleared before walking guest page tables.\n\t */\n\terror_code &= ~PFERR_RSVD_MASK;\n\n\t/*\n\t * Look up the guest pte for the faulting address.\n\t */\n\tr = FNAME(walk_addr)(&walker, vcpu, addr, error_code);\n\n\t/*\n\t * The page is not mapped by the guest.  Let the guest handle it.\n\t */\n\tif (!r) {\n\t\tpgprintk(\"%s: guest page fault\\n\", __func__);\n\t\tif (!prefault)\n\t\t\tinject_page_fault(vcpu, &walker.fault);\n\n\t\treturn RET_PF_RETRY;\n\t}\n\n\tif (page_fault_handle_page_track(vcpu, error_code, walker.gfn)) {\n\t\tshadow_page_table_clear_flood(vcpu, addr);\n\t\treturn RET_PF_EMULATE;\n\t}\n\n\tvcpu->arch.write_fault_to_shadow_pgtable = false;\n\n\tis_self_change_mapping = FNAME(is_self_change_mapping)(vcpu,\n\t      &walker, user_fault, &vcpu->arch.write_fault_to_shadow_pgtable);\n\n\tif (lpage_disallowed || is_self_change_mapping)\n\t\tmax_level = PT_PAGE_TABLE_LEVEL;\n\telse\n\t\tmax_level = walker.level;\n\n\tmmu_seq = vcpu->kvm->mmu_notifier_seq;\n\tsmp_rmb();\n\n\tif (try_async_pf(vcpu, prefault, walker.gfn, addr, &pfn, write_fault,\n\t\t\t &map_writable))\n\t\treturn RET_PF_RETRY;\n\n\tif (handle_abnormal_pfn(vcpu, addr, walker.gfn, pfn, walker.pte_access, &r))\n\t\treturn r;\n\n\t/*\n\t * Do not change pte_access if the pfn is a mmio page, otherwise\n\t * we will cache the incorrect access into mmio spte.\n\t */\n\tif (write_fault && !(walker.pte_access & ACC_WRITE_MASK) &&\n\t     !is_write_protection(vcpu) && !user_fault &&\n\t      !is_noslot_pfn(pfn)) {\n\t\twalker.pte_access |= ACC_WRITE_MASK;\n\t\twalker.pte_access &= ~ACC_USER_MASK;\n\n\t\t/*\n\t\t * If we converted a user page to a kernel page,\n\t\t * so that the kernel can write to it when cr0.wp=0,\n\t\t * then we should prevent the kernel from executing it\n\t\t * if SMEP is enabled.\n\t\t */\n\t\tif (kvm_read_cr4_bits(vcpu, X86_CR4_SMEP))\n\t\t\twalker.pte_access &= ~ACC_EXEC_MASK;\n\t}\n\n\tr = RET_PF_RETRY;\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tif (mmu_notifier_retry(vcpu->kvm, mmu_seq))\n\t\tgoto out_unlock;\n\n\tkvm_mmu_audit(vcpu, AUDIT_PRE_PAGE_FAULT);\n\tif (make_mmu_pages_available(vcpu) < 0)\n\t\tgoto out_unlock;\n\tr = FNAME(fetch)(vcpu, addr, &walker, write_fault, max_level, pfn,\n\t\t\t map_writable, prefault, lpage_disallowed);\n\tkvm_mmu_audit(vcpu, AUDIT_POST_PAGE_FAULT);\n\nout_unlock:\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n\tkvm_release_pfn_clean(pfn);\n\treturn r;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "741-762",
    "snippet": "static bool\nFNAME(is_self_change_mapping)(struct kvm_vcpu *vcpu,\n\t\t\t      struct guest_walker *walker, int user_fault,\n\t\t\t      bool *write_fault_to_shadow_pgtable)\n{\n\tint level;\n\tgfn_t mask = ~(KVM_PAGES_PER_HPAGE(walker->level) - 1);\n\tbool self_changed = false;\n\n\tif (!(walker->pte_access & ACC_WRITE_MASK ||\n\t      (!is_write_protection(vcpu) && !user_fault)))\n\t\treturn false;\n\n\tfor (level = walker->level; level <= walker->max_level; level++) {\n\t\tgfn_t gfn = walker->gfn ^ walker->table_gfn[level - 1];\n\n\t\tself_changed |= !(gfn & mask);\n\t\t*write_fault_to_shadow_pgtable |= !gfn;\n\t}\n\n\treturn self_changed;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "is_write_protection",
          "args": [
            "vcpu"
          ],
          "line": 751
        },
        "resolved": true,
        "details": {
          "function_name": "is_write_protection",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "156-159",
          "snippet": "static inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}"
        }
      },
      {
        "call_info": {
          "callee": "KVM_PAGES_PER_HPAGE",
          "args": [
            "walker->level"
          ],
          "line": 747
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic bool\nFNAME(is_self_change_mapping)(struct kvm_vcpu *vcpu,\n\t\t\t      struct guest_walker *walker, int user_fault,\n\t\t\t      bool *write_fault_to_shadow_pgtable)\n{\n\tint level;\n\tgfn_t mask = ~(KVM_PAGES_PER_HPAGE(walker->level) - 1);\n\tbool self_changed = false;\n\n\tif (!(walker->pte_access & ACC_WRITE_MASK ||\n\t      (!is_write_protection(vcpu) && !user_fault)))\n\t\treturn false;\n\n\tfor (level = walker->level; level <= walker->max_level; level++) {\n\t\tgfn_t gfn = walker->gfn ^ walker->table_gfn[level - 1];\n\n\t\tself_changed |= !(gfn & mask);\n\t\t*write_fault_to_shadow_pgtable |= !gfn;\n\t}\n\n\treturn self_changed;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "629-722",
    "snippet": "static int FNAME(fetch)(struct kvm_vcpu *vcpu, gpa_t addr,\n\t\t\t struct guest_walker *gw,\n\t\t\t int write_fault, int max_level,\n\t\t\t kvm_pfn_t pfn, bool map_writable, bool prefault,\n\t\t\t bool lpage_disallowed)\n{\n\tstruct kvm_mmu_page *sp = NULL;\n\tstruct kvm_shadow_walk_iterator it;\n\tunsigned direct_access, access = gw->pt_access;\n\tint top_level, hlevel, ret;\n\tgfn_t base_gfn = gw->gfn;\n\n\tdirect_access = gw->pte_access;\n\n\ttop_level = vcpu->arch.mmu->root_level;\n\tif (top_level == PT32E_ROOT_LEVEL)\n\t\ttop_level = PT32_ROOT_LEVEL;\n\t/*\n\t * Verify that the top-level gpte is still there.  Since the page\n\t * is a root page, it is either write protected (and cannot be\n\t * changed from now on) or it is invalid (in which case, we don't\n\t * really care if it changes underneath us after this point).\n\t */\n\tif (FNAME(gpte_changed)(vcpu, gw, top_level))\n\t\tgoto out_gpte_changed;\n\n\tif (WARN_ON(!VALID_PAGE(vcpu->arch.mmu->root_hpa)))\n\t\tgoto out_gpte_changed;\n\n\tfor (shadow_walk_init(&it, vcpu, addr);\n\t     shadow_walk_okay(&it) && it.level > gw->level;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t table_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tsp = NULL;\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\ttable_gfn = gw->table_gfn[it.level - 2];\n\t\t\tsp = kvm_mmu_get_page(vcpu, table_gfn, addr, it.level-1,\n\t\t\t\t\t      false, access);\n\t\t}\n\n\t\t/*\n\t\t * Verify that the gpte in the page we've just write\n\t\t * protected is still there.\n\t\t */\n\t\tif (FNAME(gpte_changed)(vcpu, gw, it.level - 1))\n\t\t\tgoto out_gpte_changed;\n\n\t\tif (sp)\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\thlevel = kvm_mmu_hugepage_adjust(vcpu, gw->gfn, max_level, &pfn);\n\n\ttrace_kvm_mmu_spte_requested(addr, gw->level, pfn);\n\n\tfor (; shadow_walk_okay(&it); shadow_walk_next(&it)) {\n\t\tclear_sp_write_flooding_count(it.sptep);\n\n\t\t/*\n\t\t * We cannot overwrite existing page tables with an NX\n\t\t * large page, as the leaf could be executable.\n\t\t */\n\t\tdisallowed_hugepage_adjust(it, gw->gfn, &pfn, &hlevel);\n\n\t\tbase_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\t\tif (it.level == hlevel)\n\t\t\tbreak;\n\n\t\tvalidate_direct_spte(vcpu, it.sptep, direct_access);\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\tsp = kvm_mmu_get_page(vcpu, base_gfn, addr,\n\t\t\t\t\t      it.level - 1, true, direct_access);\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t\t\tif (lpage_disallowed)\n\t\t\t\taccount_huge_nx_page(vcpu->kvm, sp);\n\t\t}\n\t}\n\n\tret = mmu_set_spte(vcpu, it.sptep, gw->pte_access, write_fault,\n\t\t\t   it.level, base_gfn, pfn, prefault, map_writable);\n\tFNAME(pte_prefetch)(vcpu, gw, it.sptep);\n\t++vcpu->stat.pf_fixed;\n\treturn ret;\n\nout_gpte_changed:\n\treturn RET_PF_RETRY;\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "gw",
            "it.sptep"
          ],
          "line": 716
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "895-949",
          "snippet": "static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry_using_root(vcpu, root_hpa, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm,\n\t\t\t\t\tsp->gfn, KVM_PAGES_PER_HPAGE(sp->role.level));\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "mmu_set_spte",
          "args": [
            "vcpu",
            "it.sptep",
            "gw->pte_access",
            "write_fault",
            "it.level",
            "base_gfn",
            "pfn",
            "prefault",
            "map_writable"
          ],
          "line": 714
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_set_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3087-3152",
          "snippet": "static int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, int write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_RETRY;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define SET_SPTE_NEED_REMOTE_TLB_FLUSH\tBIT(1)",
            "#define SET_SPTE_WRITE_PROTECTED_PT\tBIT(0)",
            "#define RMAP_RECYCLE_THRESHOLD 1000",
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))",
            "#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define SET_SPTE_NEED_REMOTE_TLB_FLUSH\tBIT(1)\n#define SET_SPTE_WRITE_PROTECTED_PT\tBIT(0)\n#define RMAP_RECYCLE_THRESHOLD 1000\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, int write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_RETRY;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "account_huge_nx_page",
          "args": [
            "vcpu->kvm",
            "sp"
          ],
          "line": 710
        },
        "resolved": true,
        "details": {
          "function_name": "unaccount_huge_nx_page",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1263-1268",
          "snippet": "static void unaccount_huge_nx_page(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\t--kvm->stat.nx_lpage_splits;\n\tsp->lpage_disallowed = false;\n\tlist_del(&sp->lpage_disallowed_link);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void unaccount_huge_nx_page(struct kvm *kvm, struct kvm_mmu_page *sp)\n{\n\t--kvm->stat.nx_lpage_splits;\n\tsp->lpage_disallowed = false;\n\tlist_del(&sp->lpage_disallowed_link);\n}"
        }
      },
      {
        "call_info": {
          "callee": "link_shadow_page",
          "args": [
            "vcpu",
            "it.sptep",
            "sp"
          ],
          "line": 708
        },
        "resolved": true,
        "details": {
          "function_name": "link_shadow_page",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2629-2650",
          "snippet": "static void link_shadow_page(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t     struct kvm_mmu_page *sp)\n{\n\tu64 spte;\n\n\tBUILD_BUG_ON(VMX_EPT_WRITABLE_MASK != PT_WRITABLE_MASK);\n\n\tspte = __pa(sp->spt) | shadow_present_mask | PT_WRITABLE_MASK |\n\t       shadow_user_mask | shadow_x_mask | shadow_me_mask;\n\n\tif (sp_ad_disabled(sp))\n\t\tspte |= SPTE_AD_DISABLED_MASK;\n\telse\n\t\tspte |= shadow_accessed_mask;\n\n\tmmu_spte_set(sptep, spte);\n\n\tmmu_page_add_parent_pte(vcpu, sp, sptep);\n\n\tif (sp->unsync_children || sp->unsync)\n\t\tmark_unsync(sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define SPTE_AD_DISABLED_MASK (1ULL << 52)"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define SPTE_AD_DISABLED_MASK (1ULL << 52)\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic void link_shadow_page(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t     struct kvm_mmu_page *sp)\n{\n\tu64 spte;\n\n\tBUILD_BUG_ON(VMX_EPT_WRITABLE_MASK != PT_WRITABLE_MASK);\n\n\tspte = __pa(sp->spt) | shadow_present_mask | PT_WRITABLE_MASK |\n\t       shadow_user_mask | shadow_x_mask | shadow_me_mask;\n\n\tif (sp_ad_disabled(sp))\n\t\tspte |= SPTE_AD_DISABLED_MASK;\n\telse\n\t\tspte |= shadow_accessed_mask;\n\n\tmmu_spte_set(sptep, spte);\n\n\tmmu_page_add_parent_pte(vcpu, sp, sptep);\n\n\tif (sp->unsync_children || sp->unsync)\n\t\tmark_unsync(sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_mmu_get_page",
          "args": [
            "vcpu",
            "base_gfn",
            "addr",
            "it.level - 1",
            "true",
            "direct_access"
          ],
          "line": 706
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_get_page",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2476-2564",
          "snippet": "static struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     gfn_t gfn,\n\t\t\t\t\t     gva_t gaddr,\n\t\t\t\t\t     unsigned level,\n\t\t\t\t\t     int direct,\n\t\t\t\t\t     unsigned int access)\n{\n\tunion kvm_mmu_page_role role;\n\tunsigned quadrant;\n\tstruct kvm_mmu_page *sp;\n\tbool need_sync = false;\n\tbool flush = false;\n\tint collisions = 0;\n\tLIST_HEAD(invalid_list);\n\n\trole = vcpu->arch.mmu->mmu_role.base;\n\trole.level = level;\n\trole.direct = direct;\n\tif (role.direct)\n\t\trole.gpte_is_8_bytes = true;\n\trole.access = access;\n\tif (!vcpu->arch.mmu->direct_map\n\t    && vcpu->arch.mmu->root_level <= PT32_ROOT_LEVEL) {\n\t\tquadrant = gaddr >> (PAGE_SHIFT + (PT64_PT_BITS * level));\n\t\tquadrant &= (1 << ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;\n\t\trole.quadrant = quadrant;\n\t}\n\tfor_each_valid_sp(vcpu->kvm, sp, gfn) {\n\t\tif (sp->gfn != gfn) {\n\t\t\tcollisions++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!need_sync && sp->unsync)\n\t\t\tneed_sync = true;\n\n\t\tif (sp->role.word != role.word)\n\t\t\tcontinue;\n\n\t\tif (sp->unsync) {\n\t\t\t/* The page is good, but __kvm_sync_page might still end\n\t\t\t * up zapping it.  If so, break in order to rebuild it.\n\t\t\t */\n\t\t\tif (!__kvm_sync_page(vcpu, sp, &invalid_list))\n\t\t\t\tbreak;\n\n\t\t\tWARN_ON(!list_empty(&invalid_list));\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\n\t\tif (sp->unsync_children)\n\t\t\tkvm_make_request(KVM_REQ_MMU_SYNC, vcpu);\n\n\t\t__clear_sp_write_flooding_count(sp);\n\t\ttrace_kvm_mmu_get_page(sp, false);\n\t\tgoto out;\n\t}\n\n\t++vcpu->kvm->stat.mmu_cache_miss;\n\n\tsp = kvm_mmu_alloc_page(vcpu, direct);\n\n\tsp->gfn = gfn;\n\tsp->role = role;\n\thlist_add_head(&sp->hash_link,\n\t\t&vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)]);\n\tif (!direct) {\n\t\t/*\n\t\t * we should do write protection before syncing pages\n\t\t * otherwise the content of the synced shadow page may\n\t\t * be inconsistent with guest page table.\n\t\t */\n\t\taccount_shadowed(vcpu->kvm, sp);\n\t\tif (level == PT_PAGE_TABLE_LEVEL &&\n\t\t      rmap_write_protect(vcpu, gfn))\n\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn, 1);\n\n\t\tif (level > PT_PAGE_TABLE_LEVEL && need_sync)\n\t\t\tflush |= kvm_sync_pages(vcpu, gfn, &invalid_list);\n\t}\n\tclear_page(sp->spt);\n\ttrace_kvm_mmu_get_page(sp, true);\n\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\nout:\n\tif (collisions > vcpu->kvm->stat.max_mmu_page_hash_collisions)\n\t\tvcpu->kvm->stat.max_mmu_page_hash_collisions = collisions;\n\treturn sp;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static bool kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t     struct list_head *invalid_list);",
            "static void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic bool kvm_mmu_prepare_zap_page(struct kvm *kvm, struct kvm_mmu_page *sp,\n\t\t\t\t     struct list_head *invalid_list);\nstatic void kvm_mmu_commit_zap_page(struct kvm *kvm,\n\t\t\t\t    struct list_head *invalid_list);\n\nstatic struct kvm_mmu_page *kvm_mmu_get_page(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     gfn_t gfn,\n\t\t\t\t\t     gva_t gaddr,\n\t\t\t\t\t     unsigned level,\n\t\t\t\t\t     int direct,\n\t\t\t\t\t     unsigned int access)\n{\n\tunion kvm_mmu_page_role role;\n\tunsigned quadrant;\n\tstruct kvm_mmu_page *sp;\n\tbool need_sync = false;\n\tbool flush = false;\n\tint collisions = 0;\n\tLIST_HEAD(invalid_list);\n\n\trole = vcpu->arch.mmu->mmu_role.base;\n\trole.level = level;\n\trole.direct = direct;\n\tif (role.direct)\n\t\trole.gpte_is_8_bytes = true;\n\trole.access = access;\n\tif (!vcpu->arch.mmu->direct_map\n\t    && vcpu->arch.mmu->root_level <= PT32_ROOT_LEVEL) {\n\t\tquadrant = gaddr >> (PAGE_SHIFT + (PT64_PT_BITS * level));\n\t\tquadrant &= (1 << ((PT32_PT_BITS - PT64_PT_BITS) * level)) - 1;\n\t\trole.quadrant = quadrant;\n\t}\n\tfor_each_valid_sp(vcpu->kvm, sp, gfn) {\n\t\tif (sp->gfn != gfn) {\n\t\t\tcollisions++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!need_sync && sp->unsync)\n\t\t\tneed_sync = true;\n\n\t\tif (sp->role.word != role.word)\n\t\t\tcontinue;\n\n\t\tif (sp->unsync) {\n\t\t\t/* The page is good, but __kvm_sync_page might still end\n\t\t\t * up zapping it.  If so, break in order to rebuild it.\n\t\t\t */\n\t\t\tif (!__kvm_sync_page(vcpu, sp, &invalid_list))\n\t\t\t\tbreak;\n\n\t\t\tWARN_ON(!list_empty(&invalid_list));\n\t\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t\t}\n\n\t\tif (sp->unsync_children)\n\t\t\tkvm_make_request(KVM_REQ_MMU_SYNC, vcpu);\n\n\t\t__clear_sp_write_flooding_count(sp);\n\t\ttrace_kvm_mmu_get_page(sp, false);\n\t\tgoto out;\n\t}\n\n\t++vcpu->kvm->stat.mmu_cache_miss;\n\n\tsp = kvm_mmu_alloc_page(vcpu, direct);\n\n\tsp->gfn = gfn;\n\tsp->role = role;\n\thlist_add_head(&sp->hash_link,\n\t\t&vcpu->kvm->arch.mmu_page_hash[kvm_page_table_hashfn(gfn)]);\n\tif (!direct) {\n\t\t/*\n\t\t * we should do write protection before syncing pages\n\t\t * otherwise the content of the synced shadow page may\n\t\t * be inconsistent with guest page table.\n\t\t */\n\t\taccount_shadowed(vcpu->kvm, sp);\n\t\tif (level == PT_PAGE_TABLE_LEVEL &&\n\t\t      rmap_write_protect(vcpu, gfn))\n\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn, 1);\n\n\t\tif (level > PT_PAGE_TABLE_LEVEL && need_sync)\n\t\t\tflush |= kvm_sync_pages(vcpu, gfn, &invalid_list);\n\t}\n\tclear_page(sp->spt);\n\ttrace_kvm_mmu_get_page(sp, true);\n\n\tkvm_mmu_flush_or_zap(vcpu, &invalid_list, false, flush);\nout:\n\tif (collisions > vcpu->kvm->stat.max_mmu_page_hash_collisions)\n\t\tvcpu->kvm->stat.max_mmu_page_hash_collisions = collisions;\n\treturn sp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_shadow_present_pte",
          "args": [
            "*it.sptep"
          ],
          "line": 705
        },
        "resolved": true,
        "details": {
          "function_name": "is_shadow_present_pte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "611-614",
          "snippet": "static int is_shadow_present_pte(u64 pte)\n{\n\treturn (pte != 0) && !is_mmio_spte(pte);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_shadow_present_pte(u64 pte)\n{\n\treturn (pte != 0) && !is_mmio_spte(pte);\n}"
        }
      },
      {
        "call_info": {
          "callee": "drop_large_spte",
          "args": [
            "vcpu",
            "it.sptep"
          ],
          "line": 703
        },
        "resolved": true,
        "details": {
          "function_name": "drop_large_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1542-1550",
          "snippet": "static void drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)\n{\n\tif (__drop_large_spte(vcpu->kvm, sptep)) {\n\t\tstruct kvm_mmu_page *sp = page_header(__pa(sptep));\n\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, sp->gfn,\n\t\t\tKVM_PAGES_PER_HPAGE(sp->role.level));\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic void drop_large_spte(struct kvm_vcpu *vcpu, u64 *sptep)\n{\n\tif (__drop_large_spte(vcpu->kvm, sptep)) {\n\t\tstruct kvm_mmu_page *sp = page_header(__pa(sptep));\n\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, sp->gfn,\n\t\t\tKVM_PAGES_PER_HPAGE(sp->role.level));\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "validate_direct_spte",
          "args": [
            "vcpu",
            "it.sptep",
            "direct_access"
          ],
          "line": 701
        },
        "resolved": true,
        "details": {
          "function_name": "validate_direct_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2652-2672",
          "snippet": "static void validate_direct_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t\t   unsigned direct_access)\n{\n\tif (is_shadow_present_pte(*sptep) && !is_large_pte(*sptep)) {\n\t\tstruct kvm_mmu_page *child;\n\n\t\t/*\n\t\t * For the direct sp, if the guest pte's dirty bit\n\t\t * changed form clean to dirty, it will corrupt the\n\t\t * sp's access: allow writable in the read-only sp,\n\t\t * so we should update the spte at this point to get\n\t\t * a new sp with the correct access.\n\t\t */\n\t\tchild = page_header(*sptep & PT64_BASE_ADDR_MASK);\n\t\tif (child->role.access == direct_access)\n\t\t\treturn;\n\n\t\tdrop_parent_pte(child, sptep);\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, child->gfn, 1);\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))",
            "#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic void validate_direct_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\t\t   unsigned direct_access)\n{\n\tif (is_shadow_present_pte(*sptep) && !is_large_pte(*sptep)) {\n\t\tstruct kvm_mmu_page *child;\n\n\t\t/*\n\t\t * For the direct sp, if the guest pte's dirty bit\n\t\t * changed form clean to dirty, it will corrupt the\n\t\t * sp's access: allow writable in the read-only sp,\n\t\t * so we should update the spte at this point to get\n\t\t * a new sp with the correct access.\n\t\t */\n\t\tchild = page_header(*sptep & PT64_BASE_ADDR_MASK);\n\t\tif (child->role.access == direct_access)\n\t\t\treturn;\n\n\t\tdrop_parent_pte(child, sptep);\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, child->gfn, 1);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "KVM_PAGES_PER_HPAGE",
          "args": [
            "it.level"
          ],
          "line": 697
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "disallowed_hugepage_adjust",
          "args": [
            "it",
            "gw->gfn",
            "&pfn",
            "&hlevel"
          ],
          "line": 695
        },
        "resolved": true,
        "details": {
          "function_name": "disallowed_hugepage_adjust",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3314-3335",
          "snippet": "static void disallowed_hugepage_adjust(struct kvm_shadow_walk_iterator it,\n\t\t\t\t       gfn_t gfn, kvm_pfn_t *pfnp, int *levelp)\n{\n\tint level = *levelp;\n\tu64 spte = *it.sptep;\n\n\tif (it.level == level && level > PT_PAGE_TABLE_LEVEL &&\n\t    is_nx_huge_page_enabled() &&\n\t    is_shadow_present_pte(spte) &&\n\t    !is_large_pte(spte)) {\n\t\t/*\n\t\t * A small SPTE exists for this pfn, but FNAME(fetch)\n\t\t * and __direct_map would like to create a large PTE\n\t\t * instead: just force them to go down another level,\n\t\t * patching back for them into pfn the next 9 bits of\n\t\t * the address.\n\t\t */\n\t\tu64 page_mask = KVM_PAGES_PER_HPAGE(level) - KVM_PAGES_PER_HPAGE(level - 1);\n\t\t*pfnp |= gfn & page_mask;\n\t\t(*levelp)--;\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic void mark_unsync(u64 *spte);\n\nstatic void disallowed_hugepage_adjust(struct kvm_shadow_walk_iterator it,\n\t\t\t\t       gfn_t gfn, kvm_pfn_t *pfnp, int *levelp)\n{\n\tint level = *levelp;\n\tu64 spte = *it.sptep;\n\n\tif (it.level == level && level > PT_PAGE_TABLE_LEVEL &&\n\t    is_nx_huge_page_enabled() &&\n\t    is_shadow_present_pte(spte) &&\n\t    !is_large_pte(spte)) {\n\t\t/*\n\t\t * A small SPTE exists for this pfn, but FNAME(fetch)\n\t\t * and __direct_map would like to create a large PTE\n\t\t * instead: just force them to go down another level,\n\t\t * patching back for them into pfn the next 9 bits of\n\t\t * the address.\n\t\t */\n\t\tu64 page_mask = KVM_PAGES_PER_HPAGE(level) - KVM_PAGES_PER_HPAGE(level - 1);\n\t\t*pfnp |= gfn & page_mask;\n\t\t(*levelp)--;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "clear_sp_write_flooding_count",
          "args": [
            "it.sptep"
          ],
          "line": 689
        },
        "resolved": true,
        "details": {
          "function_name": "clear_sp_write_flooding_count",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2469-2474",
          "snippet": "static void clear_sp_write_flooding_count(u64 *spte)\n{\n\tstruct kvm_mmu_page *sp =  page_header(__pa(spte));\n\n\t__clear_sp_write_flooding_count(sp);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic void mark_unsync(u64 *spte);\n\nstatic void clear_sp_write_flooding_count(u64 *spte)\n{\n\tstruct kvm_mmu_page *sp =  page_header(__pa(spte));\n\n\t__clear_sp_write_flooding_count(sp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_walk_next",
          "args": [
            "&it"
          ],
          "line": 688
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_walk_next",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2624-2627",
          "snippet": "static void shadow_walk_next(struct kvm_shadow_walk_iterator *iterator)\n{\n\t__shadow_walk_next(iterator, *iterator->sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void shadow_walk_next(struct kvm_shadow_walk_iterator *iterator)\n{\n\t__shadow_walk_next(iterator, *iterator->sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_walk_okay",
          "args": [
            "&it"
          ],
          "line": 688
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_walk_okay",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2602-2610",
          "snippet": "static bool shadow_walk_okay(struct kvm_shadow_walk_iterator *iterator)\n{\n\tif (iterator->level < PT_PAGE_TABLE_LEVEL)\n\t\treturn false;\n\n\titerator->index = SHADOW_PT_INDEX(iterator->addr, iterator->level);\n\titerator->sptep\t= ((u64 *)__va(iterator->shadow_addr)) + iterator->index;\n\treturn true;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool shadow_walk_okay(struct kvm_shadow_walk_iterator *iterator)\n{\n\tif (iterator->level < PT_PAGE_TABLE_LEVEL)\n\t\treturn false;\n\n\titerator->index = SHADOW_PT_INDEX(iterator->addr, iterator->level);\n\titerator->sptep\t= ((u64 *)__va(iterator->shadow_addr)) + iterator->index;\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_spte_requested",
          "args": [
            "addr",
            "gw->level",
            "pfn"
          ],
          "line": 686
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_mmu_hugepage_adjust",
          "args": [
            "vcpu",
            "gw->gfn",
            "max_level",
            "&pfn"
          ],
          "line": 684
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_hugepage_adjust",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3268-3312",
          "snippet": "static int kvm_mmu_hugepage_adjust(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t   int max_level, kvm_pfn_t *pfnp)\n{\n\tstruct kvm_memory_slot *slot;\n\tstruct kvm_lpage_info *linfo;\n\tkvm_pfn_t pfn = *pfnp;\n\tkvm_pfn_t mask;\n\tint level;\n\n\tif (unlikely(max_level == PT_PAGE_TABLE_LEVEL))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tif (is_error_noslot_pfn(pfn) || kvm_is_reserved_pfn(pfn))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, true);\n\tif (!slot)\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tmax_level = min(max_level, max_page_level);\n\tfor ( ; max_level > PT_PAGE_TABLE_LEVEL; max_level--) {\n\t\tlinfo = lpage_info_slot(gfn, slot, max_level);\n\t\tif (!linfo->disallow_lpage)\n\t\t\tbreak;\n\t}\n\n\tif (max_level == PT_PAGE_TABLE_LEVEL)\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tlevel = host_pfn_mapping_level(vcpu, gfn, pfn, slot);\n\tif (level == PT_PAGE_TABLE_LEVEL)\n\t\treturn level;\n\n\tlevel = min(level, max_level);\n\n\t/*\n\t * mmu_notifier_retry() was successful and mmu_lock is held, so\n\t * the pmd can't be split from under us.\n\t */\n\tmask = KVM_PAGES_PER_HPAGE(level) - 1;\n\tVM_BUG_ON((gfn & mask) != (pfn & mask));\n\t*pfnp = pfn & ~mask;\n\n\treturn level;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int max_page_level",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int max_page_level;\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic int kvm_mmu_hugepage_adjust(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t   int max_level, kvm_pfn_t *pfnp)\n{\n\tstruct kvm_memory_slot *slot;\n\tstruct kvm_lpage_info *linfo;\n\tkvm_pfn_t pfn = *pfnp;\n\tkvm_pfn_t mask;\n\tint level;\n\n\tif (unlikely(max_level == PT_PAGE_TABLE_LEVEL))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tif (is_error_noslot_pfn(pfn) || kvm_is_reserved_pfn(pfn))\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, true);\n\tif (!slot)\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tmax_level = min(max_level, max_page_level);\n\tfor ( ; max_level > PT_PAGE_TABLE_LEVEL; max_level--) {\n\t\tlinfo = lpage_info_slot(gfn, slot, max_level);\n\t\tif (!linfo->disallow_lpage)\n\t\t\tbreak;\n\t}\n\n\tif (max_level == PT_PAGE_TABLE_LEVEL)\n\t\treturn PT_PAGE_TABLE_LEVEL;\n\n\tlevel = host_pfn_mapping_level(vcpu, gfn, pfn, slot);\n\tif (level == PT_PAGE_TABLE_LEVEL)\n\t\treturn level;\n\n\tlevel = min(level, max_level);\n\n\t/*\n\t * mmu_notifier_retry() was successful and mmu_lock is held, so\n\t * the pmd can't be split from under us.\n\t */\n\tmask = KVM_PAGES_PER_HPAGE(level) - 1;\n\tVM_BUG_ON((gfn & mask) != (pfn & mask));\n\t*pfnp = pfn & ~mask;\n\n\treturn level;\n}"
        }
      },
      {
        "call_info": {
          "callee": "shadow_walk_init",
          "args": [
            "&it",
            "vcpu",
            "addr"
          ],
          "line": 658
        },
        "resolved": true,
        "details": {
          "function_name": "shadow_walk_init",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "2595-2600",
          "snippet": "static void shadow_walk_init(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t     struct kvm_vcpu *vcpu, u64 addr)\n{\n\tshadow_walk_init_using_root(iterator, vcpu, vcpu->arch.mmu->root_hpa,\n\t\t\t\t    addr);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic void shadow_walk_init(struct kvm_shadow_walk_iterator *iterator,\n\t\t\t     struct kvm_vcpu *vcpu, u64 addr)\n{\n\tshadow_walk_init_using_root(iterator, vcpu, vcpu->arch.mmu->root_hpa,\n\t\t\t\t    addr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!VALID_PAGE(vcpu->arch.mmu->root_hpa)"
          ],
          "line": 655
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "VALID_PAGE",
          "args": [
            "vcpu->arch.mmu->root_hpa"
          ],
          "line": 655
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(fetch)(struct kvm_vcpu *vcpu, gpa_t addr,\n\t\t\t struct guest_walker *gw,\n\t\t\t int write_fault, int max_level,\n\t\t\t kvm_pfn_t pfn, bool map_writable, bool prefault,\n\t\t\t bool lpage_disallowed)\n{\n\tstruct kvm_mmu_page *sp = NULL;\n\tstruct kvm_shadow_walk_iterator it;\n\tunsigned direct_access, access = gw->pt_access;\n\tint top_level, hlevel, ret;\n\tgfn_t base_gfn = gw->gfn;\n\n\tdirect_access = gw->pte_access;\n\n\ttop_level = vcpu->arch.mmu->root_level;\n\tif (top_level == PT32E_ROOT_LEVEL)\n\t\ttop_level = PT32_ROOT_LEVEL;\n\t/*\n\t * Verify that the top-level gpte is still there.  Since the page\n\t * is a root page, it is either write protected (and cannot be\n\t * changed from now on) or it is invalid (in which case, we don't\n\t * really care if it changes underneath us after this point).\n\t */\n\tif (FNAME(gpte_changed)(vcpu, gw, top_level))\n\t\tgoto out_gpte_changed;\n\n\tif (WARN_ON(!VALID_PAGE(vcpu->arch.mmu->root_hpa)))\n\t\tgoto out_gpte_changed;\n\n\tfor (shadow_walk_init(&it, vcpu, addr);\n\t     shadow_walk_okay(&it) && it.level > gw->level;\n\t     shadow_walk_next(&it)) {\n\t\tgfn_t table_gfn;\n\n\t\tclear_sp_write_flooding_count(it.sptep);\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tsp = NULL;\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\ttable_gfn = gw->table_gfn[it.level - 2];\n\t\t\tsp = kvm_mmu_get_page(vcpu, table_gfn, addr, it.level-1,\n\t\t\t\t\t      false, access);\n\t\t}\n\n\t\t/*\n\t\t * Verify that the gpte in the page we've just write\n\t\t * protected is still there.\n\t\t */\n\t\tif (FNAME(gpte_changed)(vcpu, gw, it.level - 1))\n\t\t\tgoto out_gpte_changed;\n\n\t\tif (sp)\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t}\n\n\thlevel = kvm_mmu_hugepage_adjust(vcpu, gw->gfn, max_level, &pfn);\n\n\ttrace_kvm_mmu_spte_requested(addr, gw->level, pfn);\n\n\tfor (; shadow_walk_okay(&it); shadow_walk_next(&it)) {\n\t\tclear_sp_write_flooding_count(it.sptep);\n\n\t\t/*\n\t\t * We cannot overwrite existing page tables with an NX\n\t\t * large page, as the leaf could be executable.\n\t\t */\n\t\tdisallowed_hugepage_adjust(it, gw->gfn, &pfn, &hlevel);\n\n\t\tbase_gfn = gw->gfn & ~(KVM_PAGES_PER_HPAGE(it.level) - 1);\n\t\tif (it.level == hlevel)\n\t\t\tbreak;\n\n\t\tvalidate_direct_spte(vcpu, it.sptep, direct_access);\n\n\t\tdrop_large_spte(vcpu, it.sptep);\n\n\t\tif (!is_shadow_present_pte(*it.sptep)) {\n\t\t\tsp = kvm_mmu_get_page(vcpu, base_gfn, addr,\n\t\t\t\t\t      it.level - 1, true, direct_access);\n\t\t\tlink_shadow_page(vcpu, it.sptep, sp);\n\t\t\tif (lpage_disallowed)\n\t\t\t\taccount_huge_nx_page(vcpu->kvm, sp);\n\t\t}\n\t}\n\n\tret = mmu_set_spte(vcpu, it.sptep, gw->pte_access, write_fault,\n\t\t\t   it.level, base_gfn, pfn, prefault, map_writable);\n\tFNAME(pte_prefetch)(vcpu, gw, it.sptep);\n\t++vcpu->stat.pf_fixed;\n\treturn ret;\n\nout_gpte_changed:\n\treturn RET_PF_RETRY;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "593-622",
    "snippet": "static void FNAME(pte_prefetch)(struct kvm_vcpu *vcpu, struct guest_walker *gw,\n\t\t\t\tu64 *sptep)\n{\n\tstruct kvm_mmu_page *sp;\n\tpt_element_t *gptep = gw->prefetch_ptes;\n\tu64 *spte;\n\tint i;\n\n\tsp = page_header(__pa(sptep));\n\n\tif (sp->role.level > PT_PAGE_TABLE_LEVEL)\n\t\treturn;\n\n\tif (sp->role.direct)\n\t\treturn __direct_pte_prefetch(vcpu, sp, sptep);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (spte == sptep)\n\t\t\tcontinue;\n\n\t\tif (is_shadow_present_pte(*spte))\n\t\t\tcontinue;\n\n\t\tif (!FNAME(prefetch_gpte)(vcpu, sp, spte, gptep[i], true))\n\t\t\tbreak;\n\t}\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "sp",
            "spte",
            "gptep[i]",
            "true"
          ],
          "line": 619
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "530-560",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(gpte);\n\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\tkvm_release_pfn_clean(pfn);\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "is_shadow_present_pte",
          "args": [
            "*spte"
          ],
          "line": 616
        },
        "resolved": true,
        "details": {
          "function_name": "is_shadow_present_pte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "611-614",
          "snippet": "static int is_shadow_present_pte(u64 pte)\n{\n\treturn (pte != 0) && !is_mmio_spte(pte);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_shadow_present_pte(u64 pte)\n{\n\treturn (pte != 0) && !is_mmio_spte(pte);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__direct_pte_prefetch",
          "args": [
            "vcpu",
            "sp",
            "sptep"
          ],
          "line": 607
        },
        "resolved": true,
        "details": {
          "function_name": "__direct_pte_prefetch",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3194-3215",
          "snippet": "static void __direct_pte_prefetch(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *sptep)\n{\n\tu64 *spte, *start = NULL;\n\tint i;\n\n\tWARN_ON(!sp->role.direct);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (is_shadow_present_pte(*spte) || spte == sptep) {\n\t\t\tif (!start)\n\t\t\t\tcontinue;\n\t\t\tif (direct_pte_prefetch_many(vcpu, sp, start, spte) < 0)\n\t\t\t\tbreak;\n\t\t\tstart = NULL;\n\t\t} else if (!start)\n\t\t\tstart = spte;\n\t}\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define PTE_PREFETCH_NUM\t\t8"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define PTE_PREFETCH_NUM\t\t8\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic void __direct_pte_prefetch(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *sptep)\n{\n\tu64 *spte, *start = NULL;\n\tint i;\n\n\tWARN_ON(!sp->role.direct);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (is_shadow_present_pte(*spte) || spte == sptep) {\n\t\t\tif (!start)\n\t\t\t\tcontinue;\n\t\t\tif (direct_pte_prefetch_many(vcpu, sp, start, spte) < 0)\n\t\t\t\tbreak;\n\t\t\tstart = NULL;\n\t\t} else if (!start)\n\t\t\tstart = spte;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_header",
          "args": [
            "__pa(sptep)"
          ],
          "line": 601
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pa",
          "args": [
            "sptep"
          ],
          "line": 601
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic void FNAME(pte_prefetch)(struct kvm_vcpu *vcpu, struct guest_walker *gw,\n\t\t\t\tu64 *sptep)\n{\n\tstruct kvm_mmu_page *sp;\n\tpt_element_t *gptep = gw->prefetch_ptes;\n\tu64 *spte;\n\tint i;\n\n\tsp = page_header(__pa(sptep));\n\n\tif (sp->role.level > PT_PAGE_TABLE_LEVEL)\n\t\treturn;\n\n\tif (sp->role.direct)\n\t\treturn __direct_pte_prefetch(vcpu, sp, sptep);\n\n\ti = (sptep - sp->spt) & ~(PTE_PREFETCH_NUM - 1);\n\tspte = sp->spt + i;\n\n\tfor (i = 0; i < PTE_PREFETCH_NUM; i++, spte++) {\n\t\tif (spte == sptep)\n\t\t\tcontinue;\n\n\t\tif (is_shadow_present_pte(*spte))\n\t\t\tcontinue;\n\n\t\tif (!FNAME(prefetch_gpte)(vcpu, sp, spte, gptep[i], true))\n\t\t\tbreak;\n\t}\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "570-591",
    "snippet": "static bool FNAME(gpte_changed)(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct guest_walker *gw, int level)\n{\n\tpt_element_t curr_pte;\n\tgpa_t base_gpa, pte_gpa = gw->pte_gpa[level - 1];\n\tu64 mask;\n\tint r, index;\n\n\tif (level == PT_PAGE_TABLE_LEVEL) {\n\t\tmask = PTE_PREFETCH_NUM * sizeof(pt_element_t) - 1;\n\t\tbase_gpa = pte_gpa & ~mask;\n\t\tindex = (pte_gpa - base_gpa) / sizeof(pt_element_t);\n\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, base_gpa,\n\t\t\t\tgw->prefetch_ptes, sizeof(gw->prefetch_ptes));\n\t\tcurr_pte = gw->prefetch_ptes[index];\n\t} else\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, pte_gpa,\n\t\t\t\t  &curr_pte, sizeof(curr_pte));\n\n\treturn r || curr_pte != gw->ptes[level - 1];\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "pte_gpa",
            "&curr_pte",
            "sizeof(curr_pte)"
          ],
          "line": 587
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_read_guest_atomic",
          "args": [
            "vcpu",
            "base_gpa",
            "gw->prefetch_ptes",
            "sizeof(gw->prefetch_ptes)"
          ],
          "line": 583
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic bool FNAME(gpte_changed)(struct kvm_vcpu *vcpu,\n\t\t\t\tstruct guest_walker *gw, int level)\n{\n\tpt_element_t curr_pte;\n\tgpa_t base_gpa, pte_gpa = gw->pte_gpa[level - 1];\n\tu64 mask;\n\tint r, index;\n\n\tif (level == PT_PAGE_TABLE_LEVEL) {\n\t\tmask = PTE_PREFETCH_NUM * sizeof(pt_element_t) - 1;\n\t\tbase_gpa = pte_gpa & ~mask;\n\t\tindex = (pte_gpa - base_gpa) / sizeof(pt_element_t);\n\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, base_gpa,\n\t\t\t\tgw->prefetch_ptes, sizeof(gw->prefetch_ptes));\n\t\tcurr_pte = gw->prefetch_ptes[index];\n\t} else\n\t\tr = kvm_vcpu_read_guest_atomic(vcpu, pte_gpa,\n\t\t\t\t  &curr_pte, sizeof(curr_pte));\n\n\treturn r || curr_pte != gw->ptes[level - 1];\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "562-568",
    "snippet": "static void FNAME(update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\t      u64 *spte, const void *pte)\n{\n\tpt_element_t gpte = *(const pt_element_t *)pte;\n\n\tFNAME(prefetch_gpte)(vcpu, sp, spte, gpte, false);\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "sp",
            "spte",
            "gpte",
            "false"
          ],
          "line": 567
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "530-560",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(gpte);\n\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\tkvm_release_pfn_clean(pfn);\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic void FNAME(update_pte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t\t      u64 *spte, const void *pte)\n{\n\tpt_element_t gpte = *(const pt_element_t *)pte;\n\n\tFNAME(prefetch_gpte)(vcpu, sp, spte, gpte, false);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "530-560",
    "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(gpte);\n\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\tkvm_release_pfn_clean(pfn);\n\treturn true;\n}",
    "includes": [],
    "macros_used": [
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_release_pfn_clean",
          "args": [
            "pfn"
          ],
          "line": 558
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu_set_spte",
          "args": [
            "vcpu",
            "spte",
            "pte_access",
            "0",
            "PT_PAGE_TABLE_LEVEL",
            "gfn",
            "pfn",
            "true",
            "true"
          ],
          "line": 555
        },
        "resolved": true,
        "details": {
          "function_name": "mmu_set_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3087-3152",
          "snippet": "static int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, int write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_RETRY;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [
            "#define SET_SPTE_NEED_REMOTE_TLB_FLUSH\tBIT(1)",
            "#define SET_SPTE_WRITE_PROTECTED_PT\tBIT(0)",
            "#define RMAP_RECYCLE_THRESHOLD 1000",
            "#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))",
            "#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))"
          ],
          "globals_used": [
            "static void mmu_spte_set(u64 *sptep, u64 spte);",
            "static bool is_executable_pte(u64 spte);",
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);",
            "static void mark_unsync(u64 *spte);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\n#define SET_SPTE_NEED_REMOTE_TLB_FLUSH\tBIT(1)\n#define SET_SPTE_WRITE_PROTECTED_PT\tBIT(0)\n#define RMAP_RECYCLE_THRESHOLD 1000\n#define PT64_BASE_ADDR_MASK (((1ULL << 52) - 1) & ~(u64)(PAGE_SIZE-1))\n#define PT64_BASE_ADDR_MASK (physical_mask & ~(u64)(PAGE_SIZE-1))\n\nstatic void mmu_spte_set(u64 *sptep, u64 spte);\nstatic bool is_executable_pte(u64 spte);\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\nstatic void mark_unsync(u64 *spte);\n\nstatic int mmu_set_spte(struct kvm_vcpu *vcpu, u64 *sptep,\n\t\t\tunsigned int pte_access, int write_fault, int level,\n\t\t\tgfn_t gfn, kvm_pfn_t pfn, bool speculative,\n\t\t\tbool host_writable)\n{\n\tint was_rmapped = 0;\n\tint rmap_count;\n\tint set_spte_ret;\n\tint ret = RET_PF_RETRY;\n\tbool flush = false;\n\n\tpgprintk(\"%s: spte %llx write_fault %d gfn %llx\\n\", __func__,\n\t\t *sptep, write_fault, gfn);\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\t/*\n\t\t * If we overwrite a PTE page pointer with a 2MB PMD, unlink\n\t\t * the parent of the now unreachable PTE.\n\t\t */\n\t\tif (level > PT_PAGE_TABLE_LEVEL &&\n\t\t    !is_large_pte(*sptep)) {\n\t\t\tstruct kvm_mmu_page *child;\n\t\t\tu64 pte = *sptep;\n\n\t\t\tchild = page_header(pte & PT64_BASE_ADDR_MASK);\n\t\t\tdrop_parent_pte(child, sptep);\n\t\t\tflush = true;\n\t\t} else if (pfn != spte_to_pfn(*sptep)) {\n\t\t\tpgprintk(\"hfn old %llx new %llx\\n\",\n\t\t\t\t spte_to_pfn(*sptep), pfn);\n\t\t\tdrop_spte(vcpu->kvm, sptep);\n\t\t\tflush = true;\n\t\t} else\n\t\t\twas_rmapped = 1;\n\t}\n\n\tset_spte_ret = set_spte(vcpu, sptep, pte_access, level, gfn, pfn,\n\t\t\t\tspeculative, true, host_writable);\n\tif (set_spte_ret & SET_SPTE_WRITE_PROTECTED_PT) {\n\t\tif (write_fault)\n\t\t\tret = RET_PF_EMULATE;\n\t\tkvm_make_request(KVM_REQ_TLB_FLUSH, vcpu);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH || flush)\n\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm, gfn,\n\t\t\t\tKVM_PAGES_PER_HPAGE(level));\n\n\tif (unlikely(is_mmio_spte(*sptep)))\n\t\tret = RET_PF_EMULATE;\n\n\tpgprintk(\"%s: setting spte %llx\\n\", __func__, *sptep);\n\ttrace_kvm_mmu_set_spte(level, gfn, sptep);\n\tif (!was_rmapped && is_large_pte(*sptep))\n\t\t++vcpu->kvm->stat.lpages;\n\n\tif (is_shadow_present_pte(*sptep)) {\n\t\tif (!was_rmapped) {\n\t\t\trmap_count = rmap_add(vcpu, sptep, gfn);\n\t\t\tif (rmap_count > RMAP_RECYCLE_THRESHOLD)\n\t\t\t\trmap_recycle(vcpu, sptep, gfn);\n\t\t}\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_error_pfn",
          "args": [
            "pfn"
          ],
          "line": 548
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_prefetch_gfn_to_pfn",
          "args": [
            "vcpu",
            "gfn",
            "no_dirty_log && (pte_access & ACC_WRITE_MASK)"
          ],
          "line": 546
        },
        "resolved": true,
        "details": {
          "function_name": "pte_prefetch_gfn_to_pfn",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3154-3164",
          "snippet": "static kvm_pfn_t pte_prefetch_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t     bool no_dirty_log)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, no_dirty_log);\n\tif (!slot)\n\t\treturn KVM_PFN_ERR_FAULT;\n\n\treturn gfn_to_pfn_memslot_atomic(slot, gfn);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nstatic kvm_pfn_t pte_prefetch_gfn_to_pfn(struct kvm_vcpu *vcpu, gfn_t gfn,\n\t\t\t\t     bool no_dirty_log)\n{\n\tstruct kvm_memory_slot *slot;\n\n\tslot = gfn_to_memslot_dirty_bitmap(vcpu, gfn, no_dirty_log);\n\tif (!slot)\n\t\treturn KVM_PFN_ERR_FAULT;\n\n\treturn gfn_to_pfn_memslot_atomic(slot, gfn);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu->arch.mmu",
            "&pte_access",
            "gpte"
          ],
          "line": 545
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "895-949",
          "snippet": "static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry_using_root(vcpu, root_hpa, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm,\n\t\t\t\t\tsp->gfn, KVM_PAGES_PER_HPAGE(sp->role.level));\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn",
          "args": [
            "gpte"
          ],
          "line": 543
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: gpte %llx spte %p\\n\"",
            "__func__",
            "(u64)gpte",
            "spte"
          ],
          "line": 541
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(gpte);\n\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\tkvm_release_pfn_clean(pfn);\n\treturn true;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "521-527",
    "snippet": "static int FNAME(walk_addr_nested)(struct guest_walker *walker,\n\t\t\t\t   struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t\t   u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, &vcpu->arch.nested_mmu,\n\t\t\t\t\taddr, access);\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "walker",
            "vcpu",
            "&vcpu->arch.nested_mmu",
            "addr",
            "access"
          ],
          "line": 525
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "530-560",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(gpte);\n\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\tkvm_release_pfn_clean(pfn);\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(walk_addr_nested)(struct guest_walker *walker,\n\t\t\t\t   struct kvm_vcpu *vcpu, gva_t addr,\n\t\t\t\t   u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, &vcpu->arch.nested_mmu,\n\t\t\t\t\taddr, access);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "513-518",
    "snippet": "static int FNAME(walk_addr)(struct guest_walker *walker,\n\t\t\t    struct kvm_vcpu *vcpu, gpa_t addr, u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, vcpu->arch.mmu, addr,\n\t\t\t\t\taccess);\n}",
    "includes": [],
    "macros_used": [
      "#define guest_walker guest_walkerEPT",
      "#define guest_walker guest_walker32",
      "#define guest_walker guest_walker64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "walker",
            "vcpu",
            "vcpu->arch.mmu",
            "addr",
            "access"
          ],
          "line": 516
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "530-560",
          "snippet": "static bool\nFNAME(prefetch_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp,\n\t\t     u64 *spte, pt_element_t gpte, bool no_dirty_log)\n{\n\tunsigned pte_access;\n\tgfn_t gfn;\n\tkvm_pfn_t pfn;\n\n\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, spte, gpte))\n\t\treturn false;\n\n\tpgprintk(\"%s: gpte %llx spte %p\\n\", __func__, (u64)gpte, spte);\n\n\tgfn = gpte_to_gfn(gpte);\n\tpte_access = sp->role.access & FNAME(gpte_access)(gpte);\n\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\tpfn = pte_prefetch_gfn_to_pfn(vcpu, gfn,\n\t\t\tno_dirty_log && (pte_access & ACC_WRITE_MASK));\n\tif (is_error_pfn(pfn))\n\t\treturn false;\n\n\t/*\n\t * we call mmu_set_spte() with host_writable = true because\n\t * pte_prefetch_gfn_to_pfn always gets a writable pfn.\n\t */\n\tmmu_set_spte(vcpu, spte, pte_access, 0, PT_PAGE_TABLE_LEVEL, gfn, pfn,\n\t\t     true, true);\n\n\tkvm_release_pfn_clean(pfn);\n\treturn true;\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#define guest_walker guest_walkerEPT\n#define guest_walker guest_walker32\n#define guest_walker guest_walker64\n\nstatic int FNAME(walk_addr)(struct guest_walker *walker,\n\t\t\t    struct kvm_vcpu *vcpu, gpa_t addr, u32 access)\n{\n\treturn FNAME(walk_addr_generic)(walker, vcpu, vcpu->arch.mmu, addr,\n\t\t\t\t\taccess);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "311-511",
    "snippet": "static int FNAME(walk_addr_generic)(struct guest_walker *walker,\n\t\t\t\t    struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t    gpa_t addr, u32 access)\n{\n\tint ret;\n\tpt_element_t pte;\n\tpt_element_t __user *uninitialized_var(ptep_user);\n\tgfn_t table_gfn;\n\tu64 pt_access, pte_access;\n\tunsigned index, accessed_dirty, pte_pkey;\n\tunsigned nested_access;\n\tgpa_t pte_gpa;\n\tbool have_ad;\n\tint offset;\n\tu64 walk_nx_mask = 0;\n\tconst int write_fault = access & PFERR_WRITE_MASK;\n\tconst int user_fault  = access & PFERR_USER_MASK;\n\tconst int fetch_fault = access & PFERR_FETCH_MASK;\n\tu16 errcode = 0;\n\tgpa_t real_gpa;\n\tgfn_t gfn;\n\n\ttrace_kvm_mmu_pagetable_walk(addr, access);\nretry_walk:\n\twalker->level = mmu->root_level;\n\tpte           = mmu->get_guest_pgd(vcpu);\n\thave_ad       = PT_HAVE_ACCESSED_DIRTY(mmu);\n\n#if PTTYPE == 64\n\twalk_nx_mask = 1ULL << PT64_NX_SHIFT;\n\tif (walker->level == PT32E_ROOT_LEVEL) {\n\t\tpte = mmu->get_pdptr(vcpu, (addr >> 30) & 3);\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\t\tif (!FNAME(is_present_gpte)(pte))\n\t\t\tgoto error;\n\t\t--walker->level;\n\t}\n#endif\n\twalker->max_level = walker->level;\n\tASSERT(!(is_long_mode(vcpu) && !is_pae(vcpu)));\n\n\t/*\n\t * FIXME: on Intel processors, loads of the PDPTE registers for PAE paging\n\t * by the MOV to CR instruction are treated as reads and do not cause the\n\t * processor to set the dirty flag in any EPT paging-structure entry.\n\t */\n\tnested_access = (have_ad ? PFERR_WRITE_MASK : 0) | PFERR_USER_MASK;\n\n\tpte_access = ~0;\n\t++walker->level;\n\n\tdo {\n\t\tgfn_t real_gfn;\n\t\tunsigned long host_addr;\n\n\t\tpt_access = pte_access;\n\t\t--walker->level;\n\n\t\tindex = PT_INDEX(addr, walker->level);\n\t\ttable_gfn = gpte_to_gfn(pte);\n\t\toffset    = index * sizeof(pt_element_t);\n\t\tpte_gpa   = gfn_to_gpa(table_gfn) + offset;\n\n\t\tBUG_ON(walker->level < 1);\n\t\twalker->table_gfn[walker->level - 1] = table_gfn;\n\t\twalker->pte_gpa[walker->level - 1] = pte_gpa;\n\n\t\treal_gfn = mmu->translate_gpa(vcpu, gfn_to_gpa(table_gfn),\n\t\t\t\t\t      nested_access,\n\t\t\t\t\t      &walker->fault);\n\n\t\t/*\n\t\t * FIXME: This can happen if emulation (for of an INS/OUTS\n\t\t * instruction) triggers a nested page fault.  The exit\n\t\t * qualification / exit info field will incorrectly have\n\t\t * \"guest page access\" as the nested page fault's cause,\n\t\t * instead of \"guest page structure access\".  To fix this,\n\t\t * the x86_exception struct should be augmented with enough\n\t\t * information to fix the exit_qualification or exit_info_1\n\t\t * fields.\n\t\t */\n\t\tif (unlikely(real_gfn == UNMAPPED_GVA))\n\t\t\treturn 0;\n\n\t\treal_gfn = gpa_to_gfn(real_gfn);\n\n\t\thost_addr = kvm_vcpu_gfn_to_hva_prot(vcpu, real_gfn,\n\t\t\t\t\t    &walker->pte_writable[walker->level - 1]);\n\t\tif (unlikely(kvm_is_error_hva(host_addr)))\n\t\t\tgoto error;\n\n\t\tptep_user = (pt_element_t __user *)((void *)host_addr + offset);\n\t\tif (unlikely(__get_user(pte, ptep_user)))\n\t\t\tgoto error;\n\t\twalker->ptep_user[walker->level - 1] = ptep_user;\n\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\n\t\t/*\n\t\t * Inverting the NX it lets us AND it like other\n\t\t * permission bits.\n\t\t */\n\t\tpte_access = pt_access & (pte ^ walk_nx_mask);\n\n\t\tif (unlikely(!FNAME(is_present_gpte)(pte)))\n\t\t\tgoto error;\n\n\t\tif (unlikely(FNAME(is_rsvd_bits_set)(mmu, pte, walker->level))) {\n\t\t\terrcode = PFERR_RSVD_MASK | PFERR_PRESENT_MASK;\n\t\t\tgoto error;\n\t\t}\n\n\t\twalker->ptes[walker->level - 1] = pte;\n\t} while (!is_last_gpte(mmu, walker->level, pte));\n\n\tpte_pkey = FNAME(gpte_pkeys)(vcpu, pte);\n\taccessed_dirty = have_ad ? pte_access & PT_GUEST_ACCESSED_MASK : 0;\n\n\t/* Convert to ACC_*_MASK flags for struct guest_walker.  */\n\twalker->pt_access = FNAME(gpte_access)(pt_access ^ walk_nx_mask);\n\twalker->pte_access = FNAME(gpte_access)(pte_access ^ walk_nx_mask);\n\terrcode = permission_fault(vcpu, mmu, walker->pte_access, pte_pkey, access);\n\tif (unlikely(errcode))\n\t\tgoto error;\n\n\tgfn = gpte_to_gfn_lvl(pte, walker->level);\n\tgfn += (addr & PT_LVL_OFFSET_MASK(walker->level)) >> PAGE_SHIFT;\n\n\tif (PTTYPE == 32 && walker->level == PT_DIRECTORY_LEVEL && is_cpuid_PSE36())\n\t\tgfn += pse36_gfn_delta(pte);\n\n\treal_gpa = mmu->translate_gpa(vcpu, gfn_to_gpa(gfn), access, &walker->fault);\n\tif (real_gpa == UNMAPPED_GVA)\n\t\treturn 0;\n\n\twalker->gfn = real_gpa >> PAGE_SHIFT;\n\n\tif (!write_fault)\n\t\tFNAME(protect_clean_gpte)(mmu, &walker->pte_access, pte);\n\telse\n\t\t/*\n\t\t * On a write fault, fold the dirty bit into accessed_dirty.\n\t\t * For modes without A/D bits support accessed_dirty will be\n\t\t * always clear.\n\t\t */\n\t\taccessed_dirty &= pte >>\n\t\t\t(PT_GUEST_DIRTY_SHIFT - PT_GUEST_ACCESSED_SHIFT);\n\n\tif (unlikely(!accessed_dirty)) {\n\t\tret = FNAME(update_accessed_dirty_bits)(vcpu, mmu, walker, write_fault);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto error;\n\t\telse if (ret)\n\t\t\tgoto retry_walk;\n\t}\n\n\tpgprintk(\"%s: pte %llx pte_access %x pt_access %x\\n\",\n\t\t __func__, (u64)pte, walker->pte_access, walker->pt_access);\n\treturn 1;\n\nerror:\n\terrcode |= write_fault | user_fault;\n\tif (fetch_fault && (mmu->nx ||\n\t\t\t    kvm_read_cr4_bits(vcpu, X86_CR4_SMEP)))\n\t\terrcode |= PFERR_FETCH_MASK;\n\n\twalker->fault.vector = PF_VECTOR;\n\twalker->fault.error_code_valid = true;\n\twalker->fault.error_code = errcode;\n\n#if PTTYPE == PTTYPE_EPT\n\t/*\n\t * Use PFERR_RSVD_MASK in error_code to to tell if EPT\n\t * misconfiguration requires to be injected. The detection is\n\t * done by is_rsvd_bits_set() above.\n\t *\n\t * We set up the value of exit_qualification to inject:\n\t * [2:0] - Derive from the access bits. The exit_qualification might be\n\t *         out of date if it is serving an EPT misconfiguration.\n\t * [5:3] - Calculated by the page walk of the guest EPT page tables\n\t * [7:8] - Derived from [7:8] of real exit_qualification\n\t *\n\t * The other bits are set to 0.\n\t */\n\tif (!(errcode & PFERR_RSVD_MASK)) {\n\t\tvcpu->arch.exit_qualification &= 0x180;\n\t\tif (write_fault)\n\t\t\tvcpu->arch.exit_qualification |= EPT_VIOLATION_ACC_WRITE;\n\t\tif (user_fault)\n\t\t\tvcpu->arch.exit_qualification |= EPT_VIOLATION_ACC_READ;\n\t\tif (fetch_fault)\n\t\t\tvcpu->arch.exit_qualification |= EPT_VIOLATION_ACC_INSTR;\n\t\tvcpu->arch.exit_qualification |= (pte_access & 0x7) << 3;\n\t}\n#endif\n\twalker->fault.address = addr;\n\twalker->fault.nested_page_fault = mmu != vcpu->arch.walk_mmu;\n\n\ttrace_kvm_mmu_walker_error(walker->fault.error_code);\n\treturn 0;\n}",
    "includes": [],
    "macros_used": [
      "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)",
      "#define PT_GUEST_ACCESSED_MASK (1 << PT_GUEST_ACCESSED_SHIFT)",
      "#define PT_GUEST_ACCESSED_SHIFT 8",
      "#define PT_GUEST_DIRTY_SHIFT 9",
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_kvm_mmu_walker_error",
          "args": [
            "walker->fault.error_code"
          ],
          "line": 509
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_read_cr4_bits",
          "args": [
            "vcpu",
            "X86_CR4_SMEP"
          ],
          "line": 474
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr4_bits",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "129-135",
          "snippet": "static inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\n#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)\n\nstatic inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgprintk",
          "args": [
            "\"%s: pte %llx pte_access %x pt_access %x\\n\"",
            "__func__",
            "(u64)pte",
            "walker->pte_access",
            "walker->pt_access"
          ],
          "line": 467
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret < 0"
          ],
          "line": 461
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "mmu",
            "walker",
            "write_fault"
          ],
          "line": 460
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "972-994",
          "snippet": "static gpa_t FNAME(gva_to_gpa_nested)(struct kvm_vcpu *vcpu, gpa_t vaddr,\n\t\t\t\t      u32 access,\n\t\t\t\t      struct x86_exception *exception)\n{\n\tstruct guest_walker walker;\n\tgpa_t gpa = UNMAPPED_GVA;\n\tint r;\n\n#ifndef CONFIG_X86_64\n\t/* A 64-bit GVA should be impossible on 32-bit KVM. */\n\tWARN_ON_ONCE(vaddr >> 32);\n#endif\n\n\tr = FNAME(walk_addr_nested)(&walker, vcpu, vaddr, access);\n\n\tif (r) {\n\t\tgpa = gfn_to_gpa(walker.gfn);\n\t\tgpa |= vaddr & ~PAGE_MASK;\n\t} else if (exception)\n\t\t*exception = walker.fault;\n\n\treturn gpa;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!accessed_dirty"
          ],
          "line": 459
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->translate_gpa",
          "args": [
            "vcpu",
            "gfn_to_gpa(gfn)",
            "access",
            "&walker->fault"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "gfn"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pse36_gfn_delta",
          "args": [
            "pte"
          ],
          "line": 440
        },
        "resolved": true,
        "details": {
          "function_name": "pse36_gfn_delta",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "640-645",
          "snippet": "static gfn_t pse36_gfn_delta(u32 gpte)\n{\n\tint shift = 32 - PT32_DIR_PSE36_SHIFT - PAGE_SHIFT;\n\n\treturn (gpte & PT32_DIR_PSE36_MASK) << shift;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic gfn_t pse36_gfn_delta(u32 gpte)\n{\n\tint shift = 32 - PT32_DIR_PSE36_SHIFT - PAGE_SHIFT;\n\n\treturn (gpte & PT32_DIR_PSE36_MASK) << shift;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_cpuid_PSE36",
          "args": [],
          "line": 439
        },
        "resolved": true,
        "details": {
          "function_name": "is_cpuid_PSE36",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "601-604",
          "snippet": "static int is_cpuid_PSE36(void)\n{\n\treturn 1;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic int is_cpuid_PSE36(void)\n{\n\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "PT_LVL_OFFSET_MASK",
          "args": [
            "walker->level"
          ],
          "line": 437
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn_lvl",
          "args": [
            "pte",
            "walker->level"
          ],
          "line": 436
        },
        "resolved": true,
        "details": {
          "function_name": "gpte_to_gfn_lvl",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "99-102",
          "snippet": "static gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}",
          "includes": [],
          "macros_used": [
            "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)",
            "#define pt_element_t u64",
            "#define pt_element_t u32",
            "#define pt_element_t u64"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)\n#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "errcode"
          ],
          "line": 433
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "permission_fault",
          "args": [
            "vcpu",
            "mmu",
            "walker->pte_access",
            "pte_pkey",
            "access"
          ],
          "line": 432
        },
        "resolved": true,
        "details": {
          "function_name": "permission_fault",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "169-217",
          "snippet": "static inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops.get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (vcpu->arch.pkru >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define PT_USER_MASK (1ULL << PT_USER_SHIFT)",
            "#define PT_USER_SHIFT 2"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_USER_MASK (1ULL << PT_USER_SHIFT)\n#define PT_USER_SHIFT 2\n\nstatic inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops.get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (vcpu->arch.pkru >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_last_gpte",
          "args": [
            "mmu",
            "walker->level",
            "pte"
          ],
          "line": 424
        },
        "resolved": true,
        "details": {
          "function_name": "is_last_gpte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4383-4401",
          "snippet": "static inline bool is_last_gpte(struct kvm_mmu *mmu,\n\t\t\t\tunsigned level, unsigned gpte)\n{\n\t/*\n\t * The RHS has bit 7 set iff level < mmu->last_nonleaf_level.\n\t * If it is clear, there are no large pages at this level, so clear\n\t * PT_PAGE_SIZE_MASK in gpte if that is the case.\n\t */\n\tgpte &= level - mmu->last_nonleaf_level;\n\n\t/*\n\t * PT_PAGE_TABLE_LEVEL always terminates.  The RHS has bit 7 set\n\t * iff level <= PT_PAGE_TABLE_LEVEL, which for our purpose means\n\t * level == PT_PAGE_TABLE_LEVEL; set PT_PAGE_SIZE_MASK in gpte then.\n\t */\n\tgpte |= level - PT_PAGE_TABLE_LEVEL - 1;\n\n\treturn gpte & PT_PAGE_SIZE_MASK;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic inline bool is_last_gpte(struct kvm_mmu *mmu,\n\t\t\t\tunsigned level, unsigned gpte)\n{\n\t/*\n\t * The RHS has bit 7 set iff level < mmu->last_nonleaf_level.\n\t * If it is clear, there are no large pages at this level, so clear\n\t * PT_PAGE_SIZE_MASK in gpte if that is the case.\n\t */\n\tgpte &= level - mmu->last_nonleaf_level;\n\n\t/*\n\t * PT_PAGE_TABLE_LEVEL always terminates.  The RHS has bit 7 set\n\t * iff level <= PT_PAGE_TABLE_LEVEL, which for our purpose means\n\t * level == PT_PAGE_TABLE_LEVEL; set PT_PAGE_SIZE_MASK in gpte then.\n\t */\n\tgpte |= level - PT_PAGE_TABLE_LEVEL - 1;\n\n\treturn gpte & PT_PAGE_SIZE_MASK;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "FNAME(is_rsvd_bits_set)(mmu, pte, walker->level)"
          ],
          "line": 418
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!FNAME(is_present_gpte)(pte)"
          ],
          "line": 415
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_paging_element",
          "args": [
            "pte",
            "walker->level"
          ],
          "line": 407
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "__get_user(pte, ptep_user)"
          ],
          "line": 403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__get_user",
          "args": [
            "pte",
            "ptep_user"
          ],
          "line": 403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "kvm_is_error_hva(host_addr)"
          ],
          "line": 399
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_is_error_hva",
          "args": [
            "host_addr"
          ],
          "line": 399
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_vcpu_gfn_to_hva_prot",
          "args": [
            "vcpu",
            "real_gfn",
            "&walker->pte_writable[walker->level - 1]"
          ],
          "line": 397
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpa_to_gfn",
          "args": [
            "real_gfn"
          ],
          "line": 395
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "real_gfn == UNMAPPED_GVA"
          ],
          "line": 392
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->translate_gpa",
          "args": [
            "vcpu",
            "gfn_to_gpa(table_gfn)",
            "nested_access",
            "&walker->fault"
          ],
          "line": 378
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "table_gfn"
          ],
          "line": 378
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "walker->level < 1"
          ],
          "line": 374
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gfn_to_gpa",
          "args": [
            "table_gfn"
          ],
          "line": 372
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gpte_to_gfn",
          "args": [
            "pte"
          ],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PT_INDEX",
          "args": [
            "addr",
            "walker->level"
          ],
          "line": 369
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ASSERT",
          "args": [
            "!(is_long_mode(vcpu) && !is_pae(vcpu))"
          ],
          "line": 350
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_pae",
          "args": [
            "vcpu"
          ],
          "line": 350
        },
        "resolved": true,
        "details": {
          "function_name": "is_pae_paging",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "143-146",
          "snippet": "static inline bool is_pae_paging(struct kvm_vcpu *vcpu)\n{\n\treturn !is_long_mode(vcpu) && is_pae(vcpu) && is_paging(vcpu);\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline bool is_pae_paging(struct kvm_vcpu *vcpu)\n{\n\treturn !is_long_mode(vcpu) && is_pae(vcpu) && is_paging(vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_long_mode",
          "args": [
            "vcpu"
          ],
          "line": 350
        },
        "resolved": true,
        "details": {
          "function_name": "is_long_mode",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "85-92",
          "snippet": "static inline int is_long_mode(struct kvm_vcpu *vcpu)\n{\n#ifdef CONFIG_X86_64\n\treturn vcpu->arch.efer & EFER_LMA;\n#else\n\treturn 0;\n#endif\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline int is_long_mode(struct kvm_vcpu *vcpu)\n{\n#ifdef CONFIG_X86_64\n\treturn vcpu->arch.efer & EFER_LMA;\n#else\n\treturn 0;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_paging_element",
          "args": [
            "pte",
            "walker->level"
          ],
          "line": 343
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->get_pdptr",
          "args": [
            "vcpu",
            "(addr >> 30) & 3"
          ],
          "line": 342
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PT_HAVE_ACCESSED_DIRTY",
          "args": [
            "mmu"
          ],
          "line": 337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmu->get_guest_pgd",
          "args": [
            "vcpu"
          ],
          "line": 336
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_pagetable_walk",
          "args": [
            "addr",
            "access"
          ],
          "line": 333
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)\n#define PT_GUEST_ACCESSED_MASK (1 << PT_GUEST_ACCESSED_SHIFT)\n#define PT_GUEST_ACCESSED_SHIFT 8\n#define PT_GUEST_DIRTY_SHIFT 9\n#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define PT_GUEST_ACCESSED_SHIFT PT_ACCESSED_SHIFT\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic int FNAME(walk_addr_generic)(struct guest_walker *walker,\n\t\t\t\t    struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t    gpa_t addr, u32 access)\n{\n\tint ret;\n\tpt_element_t pte;\n\tpt_element_t __user *uninitialized_var(ptep_user);\n\tgfn_t table_gfn;\n\tu64 pt_access, pte_access;\n\tunsigned index, accessed_dirty, pte_pkey;\n\tunsigned nested_access;\n\tgpa_t pte_gpa;\n\tbool have_ad;\n\tint offset;\n\tu64 walk_nx_mask = 0;\n\tconst int write_fault = access & PFERR_WRITE_MASK;\n\tconst int user_fault  = access & PFERR_USER_MASK;\n\tconst int fetch_fault = access & PFERR_FETCH_MASK;\n\tu16 errcode = 0;\n\tgpa_t real_gpa;\n\tgfn_t gfn;\n\n\ttrace_kvm_mmu_pagetable_walk(addr, access);\nretry_walk:\n\twalker->level = mmu->root_level;\n\tpte           = mmu->get_guest_pgd(vcpu);\n\thave_ad       = PT_HAVE_ACCESSED_DIRTY(mmu);\n\n#if PTTYPE == 64\n\twalk_nx_mask = 1ULL << PT64_NX_SHIFT;\n\tif (walker->level == PT32E_ROOT_LEVEL) {\n\t\tpte = mmu->get_pdptr(vcpu, (addr >> 30) & 3);\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\t\tif (!FNAME(is_present_gpte)(pte))\n\t\t\tgoto error;\n\t\t--walker->level;\n\t}\n#endif\n\twalker->max_level = walker->level;\n\tASSERT(!(is_long_mode(vcpu) && !is_pae(vcpu)));\n\n\t/*\n\t * FIXME: on Intel processors, loads of the PDPTE registers for PAE paging\n\t * by the MOV to CR instruction are treated as reads and do not cause the\n\t * processor to set the dirty flag in any EPT paging-structure entry.\n\t */\n\tnested_access = (have_ad ? PFERR_WRITE_MASK : 0) | PFERR_USER_MASK;\n\n\tpte_access = ~0;\n\t++walker->level;\n\n\tdo {\n\t\tgfn_t real_gfn;\n\t\tunsigned long host_addr;\n\n\t\tpt_access = pte_access;\n\t\t--walker->level;\n\n\t\tindex = PT_INDEX(addr, walker->level);\n\t\ttable_gfn = gpte_to_gfn(pte);\n\t\toffset    = index * sizeof(pt_element_t);\n\t\tpte_gpa   = gfn_to_gpa(table_gfn) + offset;\n\n\t\tBUG_ON(walker->level < 1);\n\t\twalker->table_gfn[walker->level - 1] = table_gfn;\n\t\twalker->pte_gpa[walker->level - 1] = pte_gpa;\n\n\t\treal_gfn = mmu->translate_gpa(vcpu, gfn_to_gpa(table_gfn),\n\t\t\t\t\t      nested_access,\n\t\t\t\t\t      &walker->fault);\n\n\t\t/*\n\t\t * FIXME: This can happen if emulation (for of an INS/OUTS\n\t\t * instruction) triggers a nested page fault.  The exit\n\t\t * qualification / exit info field will incorrectly have\n\t\t * \"guest page access\" as the nested page fault's cause,\n\t\t * instead of \"guest page structure access\".  To fix this,\n\t\t * the x86_exception struct should be augmented with enough\n\t\t * information to fix the exit_qualification or exit_info_1\n\t\t * fields.\n\t\t */\n\t\tif (unlikely(real_gfn == UNMAPPED_GVA))\n\t\t\treturn 0;\n\n\t\treal_gfn = gpa_to_gfn(real_gfn);\n\n\t\thost_addr = kvm_vcpu_gfn_to_hva_prot(vcpu, real_gfn,\n\t\t\t\t\t    &walker->pte_writable[walker->level - 1]);\n\t\tif (unlikely(kvm_is_error_hva(host_addr)))\n\t\t\tgoto error;\n\n\t\tptep_user = (pt_element_t __user *)((void *)host_addr + offset);\n\t\tif (unlikely(__get_user(pte, ptep_user)))\n\t\t\tgoto error;\n\t\twalker->ptep_user[walker->level - 1] = ptep_user;\n\n\t\ttrace_kvm_mmu_paging_element(pte, walker->level);\n\n\t\t/*\n\t\t * Inverting the NX it lets us AND it like other\n\t\t * permission bits.\n\t\t */\n\t\tpte_access = pt_access & (pte ^ walk_nx_mask);\n\n\t\tif (unlikely(!FNAME(is_present_gpte)(pte)))\n\t\t\tgoto error;\n\n\t\tif (unlikely(FNAME(is_rsvd_bits_set)(mmu, pte, walker->level))) {\n\t\t\terrcode = PFERR_RSVD_MASK | PFERR_PRESENT_MASK;\n\t\t\tgoto error;\n\t\t}\n\n\t\twalker->ptes[walker->level - 1] = pte;\n\t} while (!is_last_gpte(mmu, walker->level, pte));\n\n\tpte_pkey = FNAME(gpte_pkeys)(vcpu, pte);\n\taccessed_dirty = have_ad ? pte_access & PT_GUEST_ACCESSED_MASK : 0;\n\n\t/* Convert to ACC_*_MASK flags for struct guest_walker.  */\n\twalker->pt_access = FNAME(gpte_access)(pt_access ^ walk_nx_mask);\n\twalker->pte_access = FNAME(gpte_access)(pte_access ^ walk_nx_mask);\n\terrcode = permission_fault(vcpu, mmu, walker->pte_access, pte_pkey, access);\n\tif (unlikely(errcode))\n\t\tgoto error;\n\n\tgfn = gpte_to_gfn_lvl(pte, walker->level);\n\tgfn += (addr & PT_LVL_OFFSET_MASK(walker->level)) >> PAGE_SHIFT;\n\n\tif (PTTYPE == 32 && walker->level == PT_DIRECTORY_LEVEL && is_cpuid_PSE36())\n\t\tgfn += pse36_gfn_delta(pte);\n\n\treal_gpa = mmu->translate_gpa(vcpu, gfn_to_gpa(gfn), access, &walker->fault);\n\tif (real_gpa == UNMAPPED_GVA)\n\t\treturn 0;\n\n\twalker->gfn = real_gpa >> PAGE_SHIFT;\n\n\tif (!write_fault)\n\t\tFNAME(protect_clean_gpte)(mmu, &walker->pte_access, pte);\n\telse\n\t\t/*\n\t\t * On a write fault, fold the dirty bit into accessed_dirty.\n\t\t * For modes without A/D bits support accessed_dirty will be\n\t\t * always clear.\n\t\t */\n\t\taccessed_dirty &= pte >>\n\t\t\t(PT_GUEST_DIRTY_SHIFT - PT_GUEST_ACCESSED_SHIFT);\n\n\tif (unlikely(!accessed_dirty)) {\n\t\tret = FNAME(update_accessed_dirty_bits)(vcpu, mmu, walker, write_fault);\n\t\tif (unlikely(ret < 0))\n\t\t\tgoto error;\n\t\telse if (ret)\n\t\t\tgoto retry_walk;\n\t}\n\n\tpgprintk(\"%s: pte %llx pte_access %x pt_access %x\\n\",\n\t\t __func__, (u64)pte, walker->pte_access, walker->pt_access);\n\treturn 1;\n\nerror:\n\terrcode |= write_fault | user_fault;\n\tif (fetch_fault && (mmu->nx ||\n\t\t\t    kvm_read_cr4_bits(vcpu, X86_CR4_SMEP)))\n\t\terrcode |= PFERR_FETCH_MASK;\n\n\twalker->fault.vector = PF_VECTOR;\n\twalker->fault.error_code_valid = true;\n\twalker->fault.error_code = errcode;\n\n#if PTTYPE == PTTYPE_EPT\n\t/*\n\t * Use PFERR_RSVD_MASK in error_code to to tell if EPT\n\t * misconfiguration requires to be injected. The detection is\n\t * done by is_rsvd_bits_set() above.\n\t *\n\t * We set up the value of exit_qualification to inject:\n\t * [2:0] - Derive from the access bits. The exit_qualification might be\n\t *         out of date if it is serving an EPT misconfiguration.\n\t * [5:3] - Calculated by the page walk of the guest EPT page tables\n\t * [7:8] - Derived from [7:8] of real exit_qualification\n\t *\n\t * The other bits are set to 0.\n\t */\n\tif (!(errcode & PFERR_RSVD_MASK)) {\n\t\tvcpu->arch.exit_qualification &= 0x180;\n\t\tif (write_fault)\n\t\t\tvcpu->arch.exit_qualification |= EPT_VIOLATION_ACC_WRITE;\n\t\tif (user_fault)\n\t\t\tvcpu->arch.exit_qualification |= EPT_VIOLATION_ACC_READ;\n\t\tif (fetch_fault)\n\t\t\tvcpu->arch.exit_qualification |= EPT_VIOLATION_ACC_INSTR;\n\t\tvcpu->arch.exit_qualification |= (pte_access & 0x7) << 3;\n\t}\n#endif\n\twalker->fault.address = addr;\n\twalker->fault.nested_page_fault = mmu != vcpu->arch.walk_mmu;\n\n\ttrace_kvm_mmu_walker_error(walker->fault.error_code);\n\treturn 0;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "297-306",
    "snippet": "static inline unsigned FNAME(gpte_pkeys)(struct kvm_vcpu *vcpu, u64 gpte)\n{\n\tunsigned pkeys = 0;\n#if PTTYPE == 64\n\tpte_t pte = {.pte = gpte};\n\n\tpkeys = pte_flags_pkey(pte_flags(pte));\n#endif\n\treturn pkeys;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pte_flags_pkey",
          "args": [
            "pte_flags(pte)"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_flags",
          "args": [
            "pte"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline unsigned FNAME(gpte_pkeys)(struct kvm_vcpu *vcpu, u64 gpte)\n{\n\tunsigned pkeys = 0;\n#if PTTYPE == 64\n\tpte_t pte = {.pte = gpte};\n\n\tpkeys = pte_flags_pkey(pte_flags(pte));\n#endif\n\treturn pkeys;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "235-295",
    "snippet": "static int FNAME(update_accessed_dirty_bits)(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     struct kvm_mmu *mmu,\n\t\t\t\t\t     struct guest_walker *walker,\n\t\t\t\t\t     int write_fault)\n{\n\tunsigned level, index;\n\tpt_element_t pte, orig_pte;\n\tpt_element_t __user *ptep_user;\n\tgfn_t table_gfn;\n\tint ret;\n\n\t/* dirty/accessed bits are not supported, so no need to update them */\n\tif (!PT_HAVE_ACCESSED_DIRTY(mmu))\n\t\treturn 0;\n\n\tfor (level = walker->max_level; level >= walker->level; --level) {\n\t\tpte = orig_pte = walker->ptes[level - 1];\n\t\ttable_gfn = walker->table_gfn[level - 1];\n\t\tptep_user = walker->ptep_user[level - 1];\n\t\tindex = offset_in_page(ptep_user) / sizeof(pt_element_t);\n\t\tif (!(pte & PT_GUEST_ACCESSED_MASK)) {\n\t\t\ttrace_kvm_mmu_set_accessed_bit(table_gfn, index, sizeof(pte));\n\t\t\tpte |= PT_GUEST_ACCESSED_MASK;\n\t\t}\n\t\tif (level == walker->level && write_fault &&\n\t\t\t\t!(pte & PT_GUEST_DIRTY_MASK)) {\n\t\t\ttrace_kvm_mmu_set_dirty_bit(table_gfn, index, sizeof(pte));\n#if PTTYPE == PTTYPE_EPT\n\t\t\tif (kvm_arch_write_log_dirty(vcpu))\n\t\t\t\treturn -EINVAL;\n#endif\n\t\t\tpte |= PT_GUEST_DIRTY_MASK;\n\t\t}\n\t\tif (pte == orig_pte)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If the slot is read-only, simply do not process the accessed\n\t\t * and dirty bits.  This is the correct thing to do if the slot\n\t\t * is ROM, and page tables in read-as-ROM/write-as-MMIO slots\n\t\t * are only supported if the accessed and dirty bits are already\n\t\t * set in the ROM (so that MMIO writes are never needed).\n\t\t *\n\t\t * Note that NPT does not allow this at all and faults, since\n\t\t * it always wants nested page table entries for the guest\n\t\t * page tables to be writable.  And EPT works but will simply\n\t\t * overwrite the read-only memory to set the accessed and dirty\n\t\t * bits.\n\t\t */\n\t\tif (unlikely(!walker->pte_writable[level - 1]))\n\t\t\tcontinue;\n\n\t\tret = FNAME(cmpxchg_gpte)(vcpu, mmu, ptep_user, index, orig_pte, pte);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tkvm_vcpu_mark_page_dirty(vcpu, table_gfn);\n\t\twalker->ptes[level - 1] = pte;\n\t}\n\treturn 0;\n}",
    "includes": [],
    "macros_used": [
      "#define PT_GUEST_ACCESSED_MASK (1 << PT_GUEST_ACCESSED_SHIFT)",
      "#define PT_GUEST_DIRTY_MASK    (1 << PT_GUEST_DIRTY_SHIFT)",
      "#define guest_walker guest_walkerEPT",
      "#define pt_element_t u64",
      "#define guest_walker guest_walker32",
      "#define pt_element_t u32",
      "#define guest_walker guest_walker64",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_vcpu_mark_page_dirty",
          "args": [
            "vcpu",
            "table_gfn"
          ],
          "line": 291
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu",
            "mmu",
            "ptep_user",
            "index",
            "orig_pte",
            "pte"
          ],
          "line": 287
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "146-187",
          "snippet": "static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n\tif (likely(npages == 1)) {\n\t\ttable = kmap_atomic(page);\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tkunmap_atomic(table);\n\n\t\tkvm_release_page_dirty(page);\n\t} else {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n\t\tunsigned long pfn;\n\t\tunsigned long paddr;\n\n\t\tdown_read(&current->mm->mmap_sem);\n\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n\t\t\tup_read(&current->mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n\t\tpaddr = pfn << PAGE_SHIFT;\n\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n\t\tif (!table) {\n\t\t\tup_read(&current->mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tmemunmap(table);\n\t\tup_read(&current->mm->mmap_sem);\n\t}\n\n\treturn (ret != orig_pte);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!walker->pte_writable[level - 1]"
          ],
          "line": 284
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_arch_write_log_dirty",
          "args": [
            "vcpu"
          ],
          "line": 263
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_arch_write_log_dirty",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1748-1754",
          "snippet": "int kvm_arch_write_log_dirty(struct kvm_vcpu *vcpu)\n{\n\tif (kvm_x86_ops.write_log_dirty)\n\t\treturn kvm_x86_ops.write_log_dirty(vcpu);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nint kvm_arch_write_log_dirty(struct kvm_vcpu *vcpu)\n{\n\tif (kvm_x86_ops.write_log_dirty)\n\t\treturn kvm_x86_ops.write_log_dirty(vcpu);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_set_dirty_bit",
          "args": [
            "table_gfn",
            "index",
            "sizeof(pte)"
          ],
          "line": 261
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_kvm_mmu_set_accessed_bit",
          "args": [
            "table_gfn",
            "index",
            "sizeof(pte)"
          ],
          "line": 256
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "offset_in_page",
          "args": [
            "ptep_user"
          ],
          "line": 254
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PT_HAVE_ACCESSED_DIRTY",
          "args": [
            "mmu"
          ],
          "line": 247
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define PT_GUEST_ACCESSED_MASK (1 << PT_GUEST_ACCESSED_SHIFT)\n#define PT_GUEST_DIRTY_MASK    (1 << PT_GUEST_DIRTY_SHIFT)\n#define guest_walker guest_walkerEPT\n#define pt_element_t u64\n#define guest_walker guest_walker32\n#define pt_element_t u32\n#define guest_walker guest_walker64\n#define pt_element_t u64\n\nstatic int FNAME(update_accessed_dirty_bits)(struct kvm_vcpu *vcpu,\n\t\t\t\t\t     struct kvm_mmu *mmu,\n\t\t\t\t\t     struct guest_walker *walker,\n\t\t\t\t\t     int write_fault)\n{\n\tunsigned level, index;\n\tpt_element_t pte, orig_pte;\n\tpt_element_t __user *ptep_user;\n\tgfn_t table_gfn;\n\tint ret;\n\n\t/* dirty/accessed bits are not supported, so no need to update them */\n\tif (!PT_HAVE_ACCESSED_DIRTY(mmu))\n\t\treturn 0;\n\n\tfor (level = walker->max_level; level >= walker->level; --level) {\n\t\tpte = orig_pte = walker->ptes[level - 1];\n\t\ttable_gfn = walker->table_gfn[level - 1];\n\t\tptep_user = walker->ptep_user[level - 1];\n\t\tindex = offset_in_page(ptep_user) / sizeof(pt_element_t);\n\t\tif (!(pte & PT_GUEST_ACCESSED_MASK)) {\n\t\t\ttrace_kvm_mmu_set_accessed_bit(table_gfn, index, sizeof(pte));\n\t\t\tpte |= PT_GUEST_ACCESSED_MASK;\n\t\t}\n\t\tif (level == walker->level && write_fault &&\n\t\t\t\t!(pte & PT_GUEST_DIRTY_MASK)) {\n\t\t\ttrace_kvm_mmu_set_dirty_bit(table_gfn, index, sizeof(pte));\n#if PTTYPE == PTTYPE_EPT\n\t\t\tif (kvm_arch_write_log_dirty(vcpu))\n\t\t\t\treturn -EINVAL;\n#endif\n\t\t\tpte |= PT_GUEST_DIRTY_MASK;\n\t\t}\n\t\tif (pte == orig_pte)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If the slot is read-only, simply do not process the accessed\n\t\t * and dirty bits.  This is the correct thing to do if the slot\n\t\t * is ROM, and page tables in read-as-ROM/write-as-MMIO slots\n\t\t * are only supported if the accessed and dirty bits are already\n\t\t * set in the ROM (so that MMIO writes are never needed).\n\t\t *\n\t\t * Note that NPT does not allow this at all and faults, since\n\t\t * it always wants nested page table entries for the guest\n\t\t * page tables to be writable.  And EPT works but will simply\n\t\t * overwrite the read-only memory to set the accessed and dirty\n\t\t * bits.\n\t\t */\n\t\tif (unlikely(!walker->pte_writable[level - 1]))\n\t\t\tcontinue;\n\n\t\tret = FNAME(cmpxchg_gpte)(vcpu, mmu, ptep_user, index, orig_pte, pte);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tkvm_vcpu_mark_page_dirty(vcpu, table_gfn);\n\t\twalker->ptes[level - 1] = pte;\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "217-233",
    "snippet": "static inline unsigned FNAME(gpte_access)(u64 gpte)\n{\n\tunsigned access;\n#if PTTYPE == PTTYPE_EPT\n\taccess = ((gpte & VMX_EPT_WRITABLE_MASK) ? ACC_WRITE_MASK : 0) |\n\t\t((gpte & VMX_EPT_EXECUTABLE_MASK) ? ACC_EXEC_MASK : 0) |\n\t\t((gpte & VMX_EPT_READABLE_MASK) ? ACC_USER_MASK : 0);\n#else\n\tBUILD_BUG_ON(ACC_EXEC_MASK != PT_PRESENT_MASK);\n\tBUILD_BUG_ON(ACC_EXEC_MASK != 1);\n\taccess = gpte & (PT_WRITABLE_MASK | PT_USER_MASK | PT_PRESENT_MASK);\n\t/* Combine NX with P (which is set here) to get ACC_EXEC_MASK.  */\n\taccess ^= (gpte >> PT64_NX_SHIFT);\n#endif\n\n\treturn access;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "ACC_EXEC_MASK != 1"
          ],
          "line": 226
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "ACC_EXEC_MASK != PT_PRESENT_MASK"
          ],
          "line": 225
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline unsigned FNAME(gpte_access)(u64 gpte)\n{\n\tunsigned access;\n#if PTTYPE == PTTYPE_EPT\n\taccess = ((gpte & VMX_EPT_WRITABLE_MASK) ? ACC_WRITE_MASK : 0) |\n\t\t((gpte & VMX_EPT_EXECUTABLE_MASK) ? ACC_EXEC_MASK : 0) |\n\t\t((gpte & VMX_EPT_READABLE_MASK) ? ACC_USER_MASK : 0);\n#else\n\tBUILD_BUG_ON(ACC_EXEC_MASK != PT_PRESENT_MASK);\n\tBUILD_BUG_ON(ACC_EXEC_MASK != 1);\n\taccess = gpte & (PT_WRITABLE_MASK | PT_USER_MASK | PT_PRESENT_MASK);\n\t/* Combine NX with P (which is set here) to get ACC_EXEC_MASK.  */\n\taccess ^= (gpte >> PT64_NX_SHIFT);\n#endif\n\n\treturn access;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "189-209",
    "snippet": "static bool FNAME(prefetch_invalid_gpte)(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *spte,\n\t\t\t\t  u64 gpte)\n{\n\tif (!FNAME(is_present_gpte)(gpte))\n\t\tgoto no_present;\n\n\t/* if accessed bit is not supported prefetch non accessed gpte */\n\tif (PT_HAVE_ACCESSED_DIRTY(vcpu->arch.mmu) &&\n\t    !(gpte & PT_GUEST_ACCESSED_MASK))\n\t\tgoto no_present;\n\n\tif (FNAME(is_rsvd_bits_set)(vcpu->arch.mmu, gpte, PT_PAGE_TABLE_LEVEL))\n\t\tgoto no_present;\n\n\treturn false;\n\nno_present:\n\tdrop_spte(vcpu->kvm, spte);\n\treturn true;\n}",
    "includes": [],
    "macros_used": [
      "#define PT_GUEST_ACCESSED_MASK (1 << PT_GUEST_ACCESSED_SHIFT)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "drop_spte",
          "args": [
            "vcpu->kvm",
            "spte"
          ],
          "line": 207
        },
        "resolved": true,
        "details": {
          "function_name": "drop_spte",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "1522-1526",
          "snippet": "static void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic void drop_spte(struct kvm *kvm, u64 *sptep)\n{\n\tif (mmu_spte_clear_track_bits(sptep))\n\t\trmap_remove(kvm, sptep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "vcpu->arch.mmu",
            "gpte",
            "PT_PAGE_TABLE_LEVEL"
          ],
          "line": 201
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "895-949",
          "snippet": "static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva, hpa_t root_hpa)\n{\n\tstruct kvm_shadow_walk_iterator iterator;\n\tstruct kvm_mmu_page *sp;\n\tint level;\n\tu64 *sptep;\n\n\tvcpu_clear_mmio_info(vcpu, gva);\n\n\t/*\n\t * No need to check return value here, rmap_can_add() can\n\t * help us to skip pte prefetch later.\n\t */\n\tmmu_topup_memory_caches(vcpu);\n\n\tif (!VALID_PAGE(root_hpa)) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\n\tspin_lock(&vcpu->kvm->mmu_lock);\n\tfor_each_shadow_entry_using_root(vcpu, root_hpa, gva, iterator) {\n\t\tlevel = iterator.level;\n\t\tsptep = iterator.sptep;\n\n\t\tsp = page_header(__pa(sptep));\n\t\tif (is_last_spte(*sptep, level)) {\n\t\t\tpt_element_t gpte;\n\t\t\tgpa_t pte_gpa;\n\n\t\t\tif (!sp->unsync)\n\t\t\t\tbreak;\n\n\t\t\tpte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\t\t\tpte_gpa += (sptep - sp->spt) * sizeof(pt_element_t);\n\n\t\t\tif (mmu_page_zap_pte(vcpu->kvm, sp, sptep))\n\t\t\t\tkvm_flush_remote_tlbs_with_address(vcpu->kvm,\n\t\t\t\t\tsp->gfn, KVM_PAGES_PER_HPAGE(sp->role.level));\n\n\t\t\tif (!rmap_can_add(vcpu))\n\t\t\t\tbreak;\n\n\t\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\t\tbreak;\n\n\t\t\tFNAME(update_pte)(vcpu, sp, sptep, &gpte);\n\t\t}\n\n\t\tif (!is_shadow_present_pte(*sptep) || !sp->unsync_children)\n\t\t\tbreak;\n\t}\n\tspin_unlock(&vcpu->kvm->mmu_lock);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "PT_HAVE_ACCESSED_DIRTY",
          "args": [
            "vcpu->arch.mmu"
          ],
          "line": 197
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define PT_GUEST_ACCESSED_MASK (1 << PT_GUEST_ACCESSED_SHIFT)\n\nstatic bool FNAME(prefetch_invalid_gpte)(struct kvm_vcpu *vcpu,\n\t\t\t\t  struct kvm_mmu_page *sp, u64 *spte,\n\t\t\t\t  u64 gpte)\n{\n\tif (!FNAME(is_present_gpte)(gpte))\n\t\tgoto no_present;\n\n\t/* if accessed bit is not supported prefetch non accessed gpte */\n\tif (PT_HAVE_ACCESSED_DIRTY(vcpu->arch.mmu) &&\n\t    !(gpte & PT_GUEST_ACCESSED_MASK))\n\t\tgoto no_present;\n\n\tif (FNAME(is_rsvd_bits_set)(vcpu->arch.mmu, gpte, PT_PAGE_TABLE_LEVEL))\n\t\tgoto no_present;\n\n\treturn false;\n\nno_present:\n\tdrop_spte(vcpu->kvm, spte);\n\treturn true;\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "146-187",
    "snippet": "static int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n\tif (likely(npages == 1)) {\n\t\ttable = kmap_atomic(page);\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tkunmap_atomic(table);\n\n\t\tkvm_release_page_dirty(page);\n\t} else {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n\t\tunsigned long pfn;\n\t\tunsigned long paddr;\n\n\t\tdown_read(&current->mm->mmap_sem);\n\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n\t\t\tup_read(&current->mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n\t\tpaddr = pfn << PAGE_SHIFT;\n\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n\t\tif (!table) {\n\t\t\tup_read(&current->mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tmemunmap(table);\n\t\tup_read(&current->mm->mmap_sem);\n\t}\n\n\treturn (ret != orig_pte);\n}",
    "includes": [],
    "macros_used": [
      "#define CMPXCHG cmpxchg64",
      "#define pt_element_t u64",
      "#define CMPXCHG cmpxchg",
      "#define pt_element_t u32",
      "#define CMPXCHG cmpxchg64",
      "#define CMPXCHG cmpxchg",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&current->mm->mmap_sem"
          ],
          "line": 183
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memunmap",
          "args": [
            "table"
          ],
          "line": 182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "CMPXCHG",
          "args": [
            "&table[index]",
            "orig_pte",
            "new_pte"
          ],
          "line": 181
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&current->mm->mmap_sem"
          ],
          "line": 178
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memremap",
          "args": [
            "paddr",
            "PAGE_SIZE",
            "MEMREMAP_WB"
          ],
          "line": 176
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&current->mm->mmap_sem"
          ],
          "line": 171
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "find_vma_intersection",
          "args": [
            "current->mm",
            "vaddr",
            "vaddr + PAGE_SIZE"
          ],
          "line": 169
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&current->mm->mmap_sem"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_release_page_dirty",
          "args": [
            "page"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kunmap_atomic",
          "args": [
            "table"
          ],
          "line": 159
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "CMPXCHG",
          "args": [
            "&table[index]",
            "orig_pte",
            "new_pte"
          ],
          "line": 158
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmap_atomic",
          "args": [
            "page"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "npages == 1"
          ],
          "line": 156
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_user_pages_fast",
          "args": [
            "(unsigned long)ptep_user",
            "1",
            "FOLL_WRITE",
            "&page"
          ],
          "line": 155
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define CMPXCHG cmpxchg64\n#define pt_element_t u64\n#define CMPXCHG cmpxchg\n#define pt_element_t u32\n#define CMPXCHG cmpxchg64\n#define CMPXCHG cmpxchg\n#define pt_element_t u64\n\nstatic int FNAME(cmpxchg_gpte)(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t       pt_element_t __user *ptep_user, unsigned index,\n\t\t\t       pt_element_t orig_pte, pt_element_t new_pte)\n{\n\tint npages;\n\tpt_element_t ret;\n\tpt_element_t *table;\n\tstruct page *page;\n\n\tnpages = get_user_pages_fast((unsigned long)ptep_user, 1, FOLL_WRITE, &page);\n\tif (likely(npages == 1)) {\n\t\ttable = kmap_atomic(page);\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tkunmap_atomic(table);\n\n\t\tkvm_release_page_dirty(page);\n\t} else {\n\t\tstruct vm_area_struct *vma;\n\t\tunsigned long vaddr = (unsigned long)ptep_user & PAGE_MASK;\n\t\tunsigned long pfn;\n\t\tunsigned long paddr;\n\n\t\tdown_read(&current->mm->mmap_sem);\n\t\tvma = find_vma_intersection(current->mm, vaddr, vaddr + PAGE_SIZE);\n\t\tif (!vma || !(vma->vm_flags & VM_PFNMAP)) {\n\t\t\tup_read(&current->mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tpfn = ((vaddr - vma->vm_start) >> PAGE_SHIFT) + vma->vm_pgoff;\n\t\tpaddr = pfn << PAGE_SHIFT;\n\t\ttable = memremap(paddr, PAGE_SIZE, MEMREMAP_WB);\n\t\tif (!table) {\n\t\t\tup_read(&current->mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tret = CMPXCHG(&table[index], orig_pte, new_pte);\n\t\tmemunmap(table);\n\t\tup_read(&current->mm->mmap_sem);\n\t}\n\n\treturn (ret != orig_pte);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "140-144",
    "snippet": "static bool FNAME(is_rsvd_bits_set)(struct kvm_mmu *mmu, u64 gpte, int level)\n{\n\treturn __is_rsvd_bits_set(&mmu->guest_rsvd_check, gpte, level) ||\n\t       FNAME(is_bad_mt_xwr)(&mmu->guest_rsvd_check, gpte);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "FNAME",
          "args": [
            "&mmu->guest_rsvd_check",
            "gpte"
          ],
          "line": 143
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "1010-1082",
          "snippet": "static int FNAME(sync_page)(struct kvm_vcpu *vcpu, struct kvm_mmu_page *sp)\n{\n\tint i, nr_present = 0;\n\tbool host_writable;\n\tgpa_t first_pte_gpa;\n\tint set_spte_ret = 0;\n\n\t/* direct kvm_mmu_page can not be unsync. */\n\tBUG_ON(sp->role.direct);\n\n\tfirst_pte_gpa = FNAME(get_level1_sp_gpa)(sp);\n\n\tfor (i = 0; i < PT64_ENT_PER_PAGE; i++) {\n\t\tunsigned pte_access;\n\t\tpt_element_t gpte;\n\t\tgpa_t pte_gpa;\n\t\tgfn_t gfn;\n\n\t\tif (!sp->spt[i])\n\t\t\tcontinue;\n\n\t\tpte_gpa = first_pte_gpa + i * sizeof(pt_element_t);\n\n\t\tif (kvm_vcpu_read_guest_atomic(vcpu, pte_gpa, &gpte,\n\t\t\t\t\t       sizeof(pt_element_t)))\n\t\t\treturn 0;\n\n\t\tif (FNAME(prefetch_invalid_gpte)(vcpu, sp, &sp->spt[i], gpte)) {\n\t\t\t/*\n\t\t\t * Update spte before increasing tlbs_dirty to make\n\t\t\t * sure no tlb flush is lost after spte is zapped; see\n\t\t\t * the comments in kvm_flush_remote_tlbs().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tgfn = gpte_to_gfn(gpte);\n\t\tpte_access = sp->role.access;\n\t\tpte_access &= FNAME(gpte_access)(gpte);\n\t\tFNAME(protect_clean_gpte)(vcpu->arch.mmu, &pte_access, gpte);\n\n\t\tif (sync_mmio_spte(vcpu, &sp->spt[i], gfn, pte_access,\n\t\t      &nr_present))\n\t\t\tcontinue;\n\n\t\tif (gfn != sp->gfns[i]) {\n\t\t\tdrop_spte(vcpu->kvm, &sp->spt[i]);\n\t\t\t/*\n\t\t\t * The same as above where we are doing\n\t\t\t * prefetch_invalid_gpte().\n\t\t\t */\n\t\t\tsmp_wmb();\n\t\t\tvcpu->kvm->tlbs_dirty++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tnr_present++;\n\n\t\thost_writable = sp->spt[i] & SPTE_HOST_WRITEABLE;\n\n\t\tset_spte_ret |= set_spte(vcpu, &sp->spt[i],\n\t\t\t\t\t pte_access, PT_PAGE_TABLE_LEVEL,\n\t\t\t\t\t gfn, spte_to_pfn(sp->spt[i]),\n\t\t\t\t\t true, false, host_writable);\n\t}\n\n\tif (set_spte_ret & SET_SPTE_NEED_REMOTE_TLB_FLUSH)\n\t\tkvm_flush_remote_tlbs(vcpu->kvm);\n\n\treturn nr_present;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "__is_rsvd_bits_set",
          "args": [
            "&mmu->guest_rsvd_check",
            "gpte",
            "level"
          ],
          "line": 142
        },
        "resolved": true,
        "details": {
          "function_name": "__is_rsvd_bits_set",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3921-3927",
          "snippet": "static bool\n__is_rsvd_bits_set(struct rsvd_bits_validate *rsvd_check, u64 pte, int level)\n{\n\tint bit7 = (pte >> 7) & 1;\n\n\treturn pte & rsvd_check->rsvd_bits_mask[bit7][level-1];\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool\n__is_rsvd_bits_set(struct rsvd_bits_validate *rsvd_check, u64 pte, int level)\n{\n\tint bit7 = (pte >> 7) & 1;\n\n\treturn pte & rsvd_check->rsvd_bits_mask[bit7][level-1];\n}"
        }
      }
    ],
    "contextual_snippet": "static bool FNAME(is_rsvd_bits_set)(struct kvm_mmu *mmu, u64 gpte, int level)\n{\n\treturn __is_rsvd_bits_set(&mmu->guest_rsvd_check, gpte, level) ||\n\t       FNAME(is_bad_mt_xwr)(&mmu->guest_rsvd_check, gpte);\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "131-138",
    "snippet": "static bool FNAME(is_bad_mt_xwr)(struct rsvd_bits_validate *rsvd_check, u64 gpte)\n{\n#if PTTYPE != PTTYPE_EPT\n\treturn false;\n#else\n\treturn __is_bad_mt_xwr(rsvd_check, gpte);\n#endif\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__is_bad_mt_xwr",
          "args": [
            "rsvd_check",
            "gpte"
          ],
          "line": 136
        },
        "resolved": true,
        "details": {
          "function_name": "__is_bad_mt_xwr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "3929-3932",
          "snippet": "static bool __is_bad_mt_xwr(struct rsvd_bits_validate *rsvd_check, u64 pte)\n{\n\treturn rsvd_check->bad_mt_xwr & BIT_ULL(pte & 0x3f);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic bool __is_bad_mt_xwr(struct rsvd_bits_validate *rsvd_check, u64 pte)\n{\n\treturn rsvd_check->bad_mt_xwr & BIT_ULL(pte & 0x3f);\n}"
        }
      }
    ],
    "contextual_snippet": "static bool FNAME(is_bad_mt_xwr)(struct rsvd_bits_validate *rsvd_check, u64 gpte)\n{\n#if PTTYPE != PTTYPE_EPT\n\treturn false;\n#else\n\treturn __is_bad_mt_xwr(rsvd_check, gpte);\n#endif\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "122-129",
    "snippet": "static inline int FNAME(is_present_gpte)(unsigned long pte)\n{\n#if PTTYPE != PTTYPE_EPT\n\treturn pte & PT_PRESENT_MASK;\n#else\n\treturn pte & 7;\n#endif\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline int FNAME(is_present_gpte)(unsigned long pte)\n{\n#if PTTYPE != PTTYPE_EPT\n\treturn pte & PT_PRESENT_MASK;\n#else\n\treturn pte & 7;\n#endif\n}"
  },
  {
    "function_name": "FNAME",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "104-120",
    "snippet": "static inline void FNAME(protect_clean_gpte)(struct kvm_mmu *mmu, unsigned *access,\n\t\t\t\t\t     unsigned gpte)\n{\n\tunsigned mask;\n\n\t/* dirty bit is not supported, so no need to track it */\n\tif (!PT_HAVE_ACCESSED_DIRTY(mmu))\n\t\treturn;\n\n\tBUILD_BUG_ON(PT_WRITABLE_MASK != ACC_WRITE_MASK);\n\n\tmask = (unsigned)~ACC_WRITE_MASK;\n\t/* Allow write access to dirty gptes */\n\tmask |= (gpte >> (PT_GUEST_DIRTY_SHIFT - PT_WRITABLE_SHIFT)) &\n\t\tPT_WRITABLE_MASK;\n\t*access &= mask;\n}",
    "includes": [],
    "macros_used": [
      "#define PT_GUEST_DIRTY_SHIFT 9",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT",
      "#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "PT_WRITABLE_MASK != ACC_WRITE_MASK"
          ],
          "line": 113
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PT_HAVE_ACCESSED_DIRTY",
          "args": [
            "mmu"
          ],
          "line": 110
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define PT_GUEST_DIRTY_SHIFT 9\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n#define PT_GUEST_DIRTY_SHIFT PT_DIRTY_SHIFT\n\nstatic inline void FNAME(protect_clean_gpte)(struct kvm_mmu *mmu, unsigned *access,\n\t\t\t\t\t     unsigned gpte)\n{\n\tunsigned mask;\n\n\t/* dirty bit is not supported, so no need to track it */\n\tif (!PT_HAVE_ACCESSED_DIRTY(mmu))\n\t\treturn;\n\n\tBUILD_BUG_ON(PT_WRITABLE_MASK != ACC_WRITE_MASK);\n\n\tmask = (unsigned)~ACC_WRITE_MASK;\n\t/* Allow write access to dirty gptes */\n\tmask |= (gpte >> (PT_GUEST_DIRTY_SHIFT - PT_WRITABLE_SHIFT)) &\n\t\tPT_WRITABLE_MASK;\n\t*access &= mask;\n}"
  },
  {
    "function_name": "gpte_to_gfn_lvl",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
    "lines": "99-102",
    "snippet": "static gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}",
    "includes": [],
    "macros_used": [
      "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)",
      "#define pt_element_t u64",
      "#define pt_element_t u32",
      "#define pt_element_t u64"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "PT_LVL_ADDR_MASK",
          "args": [
            "lvl"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#define gpte_to_gfn_lvl FNAME(gpte_to_gfn_lvl)\n#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gfn_t gpte_to_gfn_lvl(pt_element_t gpte, int lvl)\n{\n\treturn (gpte & PT_LVL_ADDR_MASK(lvl)) >> PAGE_SHIFT;\n}"
  }
]