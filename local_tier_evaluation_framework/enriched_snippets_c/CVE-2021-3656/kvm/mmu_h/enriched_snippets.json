[
  {
    "function_name": "permission_fault",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "169-217",
    "snippet": "static inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops.get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (vcpu->arch.pkru >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define PT_USER_MASK (1ULL << PT_USER_SHIFT)",
      "#define PT_USER_SHIFT 2"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "mmu->pkru_mask"
          ],
          "line": 196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK)"
          ],
          "line": 195
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops.get_rflags",
          "args": [
            "vcpu"
          ],
          "line": 174
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops.get_cpl",
          "args": [
            "vcpu"
          ],
          "line": 173
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_USER_MASK (1ULL << PT_USER_SHIFT)\n#define PT_USER_SHIFT 2\n\nstatic inline u8 permission_fault(struct kvm_vcpu *vcpu, struct kvm_mmu *mmu,\n\t\t\t\t  unsigned pte_access, unsigned pte_pkey,\n\t\t\t\t  unsigned pfec)\n{\n\tint cpl = kvm_x86_ops.get_cpl(vcpu);\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\n\t/*\n\t * If CPL < 3, SMAP prevention are disabled if EFLAGS.AC = 1.\n\t *\n\t * If CPL = 3, SMAP applies to all supervisor-mode data accesses\n\t * (these are implicit supervisor accesses) regardless of the value\n\t * of EFLAGS.AC.\n\t *\n\t * This computes (cpl < 3) && (rflags & X86_EFLAGS_AC), leaving\n\t * the result in X86_EFLAGS_AC. We then insert it in place of\n\t * the PFERR_RSVD_MASK bit; this bit will always be zero in pfec,\n\t * but it will be one in index if SMAP checks are being overridden.\n\t * It is important to keep this branchless.\n\t */\n\tunsigned long smap = (cpl - 3) & (rflags & X86_EFLAGS_AC);\n\tint index = (pfec >> 1) +\n\t\t    (smap >> (X86_EFLAGS_AC_BIT - PFERR_RSVD_BIT + 1));\n\tbool fault = (mmu->permissions[index] >> pte_access) & 1;\n\tu32 errcode = PFERR_PRESENT_MASK;\n\n\tWARN_ON(pfec & (PFERR_PK_MASK | PFERR_RSVD_MASK));\n\tif (unlikely(mmu->pkru_mask)) {\n\t\tu32 pkru_bits, offset;\n\n\t\t/*\n\t\t* PKRU defines 32 bits, there are 16 domains and 2\n\t\t* attribute bits per domain in pkru.  pte_pkey is the\n\t\t* index of the protection domain, so pte_pkey * 2 is\n\t\t* is the index of the first bit for the domain.\n\t\t*/\n\t\tpkru_bits = (vcpu->arch.pkru >> (pte_pkey * 2)) & 3;\n\n\t\t/* clear present bit, replace PFEC.RSVD with ACC_USER_MASK. */\n\t\toffset = (pfec & ~1) +\n\t\t\t((pte_access & PT_USER_MASK) << (PFERR_RSVD_BIT - PT_USER_SHIFT));\n\n\t\tpkru_bits &= mmu->pkru_mask >> offset;\n\t\terrcode |= -pkru_bits & PFERR_PK_MASK;\n\t\tfault |= (pkru_bits != 0);\n\t}\n\n\treturn -(u32)fault & errcode;\n}"
  },
  {
    "function_name": "is_write_protection",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "156-159",
    "snippet": "static inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_read_cr0_bits",
          "args": [
            "vcpu",
            "X86_CR0_WP"
          ],
          "line": 158
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr0_bits",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "116-122",
          "snippet": "static inline ulong kvm_read_cr0_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR0_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr0_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr0_guest_bits(vcpu);\n\treturn vcpu->arch.cr0 & mask;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define KVM_POSSIBLE_CR0_GUEST_BITS X86_CR0_TS"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\n#define KVM_POSSIBLE_CR0_GUEST_BITS X86_CR0_TS\n\nstatic inline ulong kvm_read_cr0_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR0_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr0_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr0_guest_bits(vcpu);\n\treturn vcpu->arch.cr0 & mask;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline bool is_write_protection(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_read_cr0_bits(vcpu, X86_CR0_WP);\n}"
  },
  {
    "function_name": "is_writable_pte",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "151-154",
    "snippet": "static inline int is_writable_pte(unsigned long pte)\n{\n\treturn pte & PT_WRITABLE_MASK;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define PT_WRITABLE_MASK (1ULL << PT_WRITABLE_SHIFT)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\n#define PT_WRITABLE_MASK (1ULL << PT_WRITABLE_SHIFT)\n\nstatic inline int is_writable_pte(unsigned long pte)\n{\n\treturn pte & PT_WRITABLE_MASK;\n}"
  },
  {
    "function_name": "kvm_mmu_do_page_fault",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "108-116",
    "snippet": "static inline int kvm_mmu_do_page_fault(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,\n\t\t\t\t\tu32 err, bool prefault)\n{\n#ifdef CONFIG_RETPOLINE\n\tif (likely(vcpu->arch.mmu->page_fault == kvm_tdp_page_fault))\n\t\treturn kvm_tdp_page_fault(vcpu, cr2_or_gpa, err, prefault);\n#endif\n\treturn vcpu->arch.mmu->page_fault(vcpu, cr2_or_gpa, err, prefault);\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "vcpu->arch.mmu->page_fault",
          "args": [
            "vcpu",
            "cr2_or_gpa",
            "err",
            "prefault"
          ],
          "line": 115
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_tdp_page_fault",
          "args": [
            "vcpu",
            "cr2_or_gpa",
            "err",
            "prefault"
          ],
          "line": 113
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_tdp_page_fault",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "4215-4232",
          "snippet": "int kvm_tdp_page_fault(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,\n\t\t       bool prefault)\n{\n\tint max_level;\n\n\tfor (max_level = PT_MAX_HUGEPAGE_LEVEL;\n\t     max_level > PT_PAGE_TABLE_LEVEL;\n\t     max_level--) {\n\t\tint page_num = KVM_PAGES_PER_HPAGE(max_level);\n\t\tgfn_t base = (gpa >> PAGE_SHIFT) & ~(page_num - 1);\n\n\t\tif (kvm_mtrr_check_gfn_range_consistency(vcpu, base, page_num))\n\t\t\tbreak;\n\t}\n\n\treturn direct_page_fault(vcpu, gpa, error_code, prefault,\n\t\t\t\t max_level, true);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nint kvm_tdp_page_fault(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,\n\t\t       bool prefault)\n{\n\tint max_level;\n\n\tfor (max_level = PT_MAX_HUGEPAGE_LEVEL;\n\t     max_level > PT_PAGE_TABLE_LEVEL;\n\t     max_level--) {\n\t\tint page_num = KVM_PAGES_PER_HPAGE(max_level);\n\t\tgfn_t base = (gpa >> PAGE_SHIFT) & ~(page_num - 1);\n\n\t\tif (kvm_mtrr_check_gfn_range_consistency(vcpu, base, page_num))\n\t\t\tbreak;\n\t}\n\n\treturn direct_page_fault(vcpu, gpa, error_code, prefault,\n\t\t\t\t max_level, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "vcpu->arch.mmu->page_fault == kvm_tdp_page_fault"
          ],
          "line": 112
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline int kvm_mmu_do_page_fault(struct kvm_vcpu *vcpu, gpa_t cr2_or_gpa,\n\t\t\t\t\tu32 err, bool prefault)\n{\n#ifdef CONFIG_RETPOLINE\n\tif (likely(vcpu->arch.mmu->page_fault == kvm_tdp_page_fault))\n\t\treturn kvm_tdp_page_fault(vcpu, cr2_or_gpa, err, prefault);\n#endif\n\treturn vcpu->arch.mmu->page_fault(vcpu, cr2_or_gpa, err, prefault);\n}"
  },
  {
    "function_name": "kvm_mmu_load_pgd",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "98-103",
    "snippet": "static inline void kvm_mmu_load_pgd(struct kvm_vcpu *vcpu)\n{\n\tif (VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\tkvm_x86_ops.load_mmu_pgd(vcpu, vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu));\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_x86_ops.load_mmu_pgd",
          "args": [
            "vcpu",
            "vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu)"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_get_active_pcid",
          "args": [
            "vcpu"
          ],
          "line": 102
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_get_active_pcid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "93-96",
          "snippet": "static inline unsigned long kvm_get_active_pcid(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_get_pcid(vcpu, kvm_read_cr3(vcpu));\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline unsigned long kvm_get_active_pcid(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_get_pcid(vcpu, kvm_read_cr3(vcpu));\n}"
        }
      },
      {
        "call_info": {
          "callee": "VALID_PAGE",
          "args": [
            "vcpu->arch.mmu->root_hpa"
          ],
          "line": 100
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_mmu_load_pgd(struct kvm_vcpu *vcpu)\n{\n\tif (VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\tkvm_x86_ops.load_mmu_pgd(vcpu, vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu));\n}"
  },
  {
    "function_name": "kvm_get_active_pcid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "93-96",
    "snippet": "static inline unsigned long kvm_get_active_pcid(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_get_pcid(vcpu, kvm_read_cr3(vcpu));\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_get_pcid",
          "args": [
            "vcpu",
            "kvm_read_cr3(vcpu)"
          ],
          "line": 95
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_get_pcid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "84-91",
          "snippet": "static inline unsigned long kvm_get_pcid(struct kvm_vcpu *vcpu, gpa_t cr3)\n{\n\tBUILD_BUG_ON((X86_CR3_PCID_MASK & PAGE_MASK) != 0);\n\n\treturn kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE)\n\t       ? cr3 & X86_CR3_PCID_MASK\n\t       : 0;\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline unsigned long kvm_get_pcid(struct kvm_vcpu *vcpu, gpa_t cr3)\n{\n\tBUILD_BUG_ON((X86_CR3_PCID_MASK & PAGE_MASK) != 0);\n\n\treturn kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE)\n\t       ? cr3 & X86_CR3_PCID_MASK\n\t       : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_read_cr3",
          "args": [
            "vcpu"
          ],
          "line": 95
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr3",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "137-142",
          "snippet": "static inline ulong kvm_read_cr3(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tkvm_x86_ops.cache_reg(vcpu, VCPU_EXREG_CR3);\n\treturn vcpu->arch.cr3;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\nstatic inline ulong kvm_read_cr3(struct kvm_vcpu *vcpu)\n{\n\tif (!kvm_register_is_available(vcpu, VCPU_EXREG_CR3))\n\t\tkvm_x86_ops.cache_reg(vcpu, VCPU_EXREG_CR3);\n\treturn vcpu->arch.cr3;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline unsigned long kvm_get_active_pcid(struct kvm_vcpu *vcpu)\n{\n\treturn kvm_get_pcid(vcpu, kvm_read_cr3(vcpu));\n}"
  },
  {
    "function_name": "kvm_get_pcid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "84-91",
    "snippet": "static inline unsigned long kvm_get_pcid(struct kvm_vcpu *vcpu, gpa_t cr3)\n{\n\tBUILD_BUG_ON((X86_CR3_PCID_MASK & PAGE_MASK) != 0);\n\n\treturn kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE)\n\t       ? cr3 & X86_CR3_PCID_MASK\n\t       : 0;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_read_cr4_bits",
          "args": [
            "vcpu",
            "X86_CR4_PCIDE"
          ],
          "line": 88
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr4_bits",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "129-135",
          "snippet": "static inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\n#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)\n\nstatic inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "(X86_CR3_PCID_MASK & PAGE_MASK) != 0"
          ],
          "line": 86
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline unsigned long kvm_get_pcid(struct kvm_vcpu *vcpu, gpa_t cr3)\n{\n\tBUILD_BUG_ON((X86_CR3_PCID_MASK & PAGE_MASK) != 0);\n\n\treturn kvm_read_cr4_bits(vcpu, X86_CR4_PCIDE)\n\t       ? cr3 & X86_CR3_PCID_MASK\n\t       : 0;\n}"
  },
  {
    "function_name": "kvm_mmu_reload",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "76-82",
    "snippet": "static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)\n{\n\tif (likely(vcpu->arch.mmu->root_hpa != INVALID_PAGE))\n\t\treturn 0;\n\n\treturn kvm_mmu_load(vcpu);\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_mmu_load",
          "args": [
            "vcpu"
          ],
          "line": 81
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_load_pgd",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
          "lines": "98-103",
          "snippet": "static inline void kvm_mmu_load_pgd(struct kvm_vcpu *vcpu)\n{\n\tif (VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\tkvm_x86_ops.load_mmu_pgd(vcpu, vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu));\n}",
          "includes": [
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline void kvm_mmu_load_pgd(struct kvm_vcpu *vcpu)\n{\n\tif (VALID_PAGE(vcpu->arch.mmu->root_hpa))\n\t\tkvm_x86_ops.load_mmu_pgd(vcpu, vcpu->arch.mmu->root_hpa |\n\t\t\t\t\t       kvm_get_active_pcid(vcpu));\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "vcpu->arch.mmu->root_hpa != INVALID_PAGE"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)\n{\n\tif (likely(vcpu->arch.mmu->root_hpa != INVALID_PAGE))\n\t\treturn 0;\n\n\treturn kvm_mmu_load(vcpu);\n}"
  },
  {
    "function_name": "kvm_mmu_available_pages",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "67-74",
    "snippet": "static inline unsigned long kvm_mmu_available_pages(struct kvm *kvm)\n{\n\tif (kvm->arch.n_max_mmu_pages > kvm->arch.n_used_mmu_pages)\n\t\treturn kvm->arch.n_max_mmu_pages -\n\t\t\tkvm->arch.n_used_mmu_pages;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline unsigned long kvm_mmu_available_pages(struct kvm *kvm)\n{\n\tif (kvm->arch.n_max_mmu_pages > kvm->arch.n_used_mmu_pages)\n\t\treturn kvm->arch.n_max_mmu_pages -\n\t\t\tkvm->arch.n_used_mmu_pages;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rsvd_bits",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu.h",
    "lines": "46-52",
    "snippet": "static inline u64 rsvd_bits(int s, int e)\n{\n\tif (e < s)\n\t\treturn 0;\n\n\treturn ((1ULL << (e - s + 1)) - 1) << s;\n}",
    "includes": [
      "#include \"kvm_cache_regs.h\"",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"kvm_cache_regs.h\"\n#include <linux/kvm_host.h>\n\nstatic inline u64 rsvd_bits(int s, int e)\n{\n\tif (e < s)\n\t\treturn 0;\n\n\treturn ((1ULL << (e - s + 1)) - 1) << s;\n}"
  }
]