[
  {
    "function_name": "kvm_emulate_cpuid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "1037-1052",
    "snippet": "int kvm_emulate_cpuid(struct kvm_vcpu *vcpu)\n{\n\tu32 eax, ebx, ecx, edx;\n\n\tif (cpuid_fault_enabled(vcpu) && !kvm_require_cpl(vcpu, 0))\n\t\treturn 1;\n\n\teax = kvm_rax_read(vcpu);\n\tecx = kvm_rcx_read(vcpu);\n\tkvm_cpuid(vcpu, &eax, &ebx, &ecx, &edx, false);\n\tkvm_rax_write(vcpu, eax);\n\tkvm_rbx_write(vcpu, ebx);\n\tkvm_rcx_write(vcpu, ecx);\n\tkvm_rdx_write(vcpu, edx);\n\treturn kvm_skip_emulated_instruction(vcpu);\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_skip_emulated_instruction",
          "args": [
            "vcpu"
          ],
          "line": 1051
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_skip_emulated_instruction",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "6655-6675",
          "snippet": "int kvm_skip_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\tint r;\n\n\tr = kvm_x86_ops.skip_emulated_instruction(vcpu);\n\tif (unlikely(!r))\n\t\treturn 0;\n\n\t/*\n\t * rflags is the old, \"raw\" value of the flags.  The new value has\n\t * not been saved yet.\n\t *\n\t * This is correct even for TF set by the guest, because \"the\n\t * processor will not generate this exception after the instruction\n\t * that sets the TF flag\".\n\t */\n\tif (unlikely(rflags & X86_EFLAGS_TF))\n\t\tr = kvm_vcpu_do_singlestep(vcpu);\n\treturn r;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void __kvm_set_rflags(struct kvm_vcpu *vcpu, unsigned long rflags);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nint kvm_skip_emulated_instruction(struct kvm_vcpu *vcpu)\n{\n\tunsigned long rflags = kvm_x86_ops.get_rflags(vcpu);\n\tint r;\n\n\tr = kvm_x86_ops.skip_emulated_instruction(vcpu);\n\tif (unlikely(!r))\n\t\treturn 0;\n\n\t/*\n\t * rflags is the old, \"raw\" value of the flags.  The new value has\n\t * not been saved yet.\n\t *\n\t * This is correct even for TF set by the guest, because \"the\n\t * processor will not generate this exception after the instruction\n\t * that sets the TF flag\".\n\t */\n\tif (unlikely(rflags & X86_EFLAGS_TF))\n\t\tr = kvm_vcpu_do_singlestep(vcpu);\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rdx_write",
          "args": [
            "vcpu",
            "edx"
          ],
          "line": 1050
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_rcx_write",
          "args": [
            "vcpu",
            "ecx"
          ],
          "line": 1049
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_rbx_write",
          "args": [
            "vcpu",
            "ebx"
          ],
          "line": 1048
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_rax_write",
          "args": [
            "vcpu",
            "eax"
          ],
          "line": 1047
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_cpuid",
          "args": [
            "vcpu",
            "&eax",
            "&ebx",
            "&ecx",
            "&edx",
            "false"
          ],
          "line": 1046
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_cpuid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "988-1034",
          "snippet": "bool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,\n\t       u32 *ecx, u32 *edx, bool exact_only)\n{\n\tu32 orig_function = *eax, function = *eax, index = *ecx;\n\tstruct kvm_cpuid_entry2 *entry;\n\tbool exact, used_max_basic = false;\n\n\tentry = kvm_find_cpuid_entry(vcpu, function, index);\n\texact = !!entry;\n\n\tif (!entry && !exact_only) {\n\t\tentry = get_out_of_range_cpuid_entry(vcpu, &function, index);\n\t\tused_max_basic = !!entry;\n\t}\n\n\tif (entry) {\n\t\t*eax = entry->eax;\n\t\t*ebx = entry->ebx;\n\t\t*ecx = entry->ecx;\n\t\t*edx = entry->edx;\n\t\tif (function == 7 && index == 0) {\n\t\t\tu64 data;\n\t\t        if (!__kvm_get_msr(vcpu, MSR_IA32_TSX_CTRL, &data, true) &&\n\t\t\t    (data & TSX_CTRL_CPUID_CLEAR))\n\t\t\t\t*ebx &= ~(F(RTM) | F(HLE));\n\t\t}\n\t} else {\n\t\t*eax = *ebx = *ecx = *edx = 0;\n\t\t/*\n\t\t * When leaf 0BH or 1FH is defined, CL is pass-through\n\t\t * and EDX is always the x2APIC ID, even for undefined\n\t\t * subleaves. Index 1 will exist iff the leaf is\n\t\t * implemented, so we pass through CL iff leaf 1\n\t\t * exists. EDX can be copied from any existing index.\n\t\t */\n\t\tif (function == 0xb || function == 0x1f) {\n\t\t\tentry = kvm_find_cpuid_entry(vcpu, function, 1);\n\t\t\tif (entry) {\n\t\t\t\t*ecx = index & 0xff;\n\t\t\t\t*edx = entry->edx;\n\t\t\t}\n\t\t}\n\t}\n\ttrace_kvm_cpuid(orig_function, index, *eax, *ebx, *ecx, *edx, exact,\n\t\t\tused_max_basic);\n\treturn exact;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define F feature_bit"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nbool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,\n\t       u32 *ecx, u32 *edx, bool exact_only)\n{\n\tu32 orig_function = *eax, function = *eax, index = *ecx;\n\tstruct kvm_cpuid_entry2 *entry;\n\tbool exact, used_max_basic = false;\n\n\tentry = kvm_find_cpuid_entry(vcpu, function, index);\n\texact = !!entry;\n\n\tif (!entry && !exact_only) {\n\t\tentry = get_out_of_range_cpuid_entry(vcpu, &function, index);\n\t\tused_max_basic = !!entry;\n\t}\n\n\tif (entry) {\n\t\t*eax = entry->eax;\n\t\t*ebx = entry->ebx;\n\t\t*ecx = entry->ecx;\n\t\t*edx = entry->edx;\n\t\tif (function == 7 && index == 0) {\n\t\t\tu64 data;\n\t\t        if (!__kvm_get_msr(vcpu, MSR_IA32_TSX_CTRL, &data, true) &&\n\t\t\t    (data & TSX_CTRL_CPUID_CLEAR))\n\t\t\t\t*ebx &= ~(F(RTM) | F(HLE));\n\t\t}\n\t} else {\n\t\t*eax = *ebx = *ecx = *edx = 0;\n\t\t/*\n\t\t * When leaf 0BH or 1FH is defined, CL is pass-through\n\t\t * and EDX is always the x2APIC ID, even for undefined\n\t\t * subleaves. Index 1 will exist iff the leaf is\n\t\t * implemented, so we pass through CL iff leaf 1\n\t\t * exists. EDX can be copied from any existing index.\n\t\t */\n\t\tif (function == 0xb || function == 0x1f) {\n\t\t\tentry = kvm_find_cpuid_entry(vcpu, function, 1);\n\t\t\tif (entry) {\n\t\t\t\t*ecx = index & 0xff;\n\t\t\t\t*edx = entry->edx;\n\t\t\t}\n\t\t}\n\t}\n\ttrace_kvm_cpuid(orig_function, index, *eax, *ebx, *ecx, *edx, exact,\n\t\t\tused_max_basic);\n\treturn exact;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_rcx_read",
          "args": [
            "vcpu"
          ],
          "line": 1045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_rax_read",
          "args": [
            "vcpu"
          ],
          "line": 1044
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_require_cpl",
          "args": [
            "vcpu",
            "0"
          ],
          "line": 1041
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_require_cpl",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "647-653",
          "snippet": "bool kvm_require_cpl(struct kvm_vcpu *vcpu, int required_cpl)\n{\n\tif (kvm_x86_ops.get_cpl(vcpu) <= required_cpl)\n\t\treturn true;\n\tkvm_queue_exception_e(vcpu, GP_VECTOR, 0);\n\treturn false;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nbool kvm_require_cpl(struct kvm_vcpu *vcpu, int required_cpl)\n{\n\tif (kvm_x86_ops.get_cpl(vcpu) <= required_cpl)\n\t\treturn true;\n\tkvm_queue_exception_e(vcpu, GP_VECTOR, 0);\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_fault_enabled",
          "args": [
            "vcpu"
          ],
          "line": 1041
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_fault_enabled",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "265-269",
          "snippet": "static inline bool cpuid_fault_enabled(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.msr_misc_features_enables &\n\t\t  MSR_MISC_FEATURES_ENABLES_CPUID_FAULT;\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic inline bool cpuid_fault_enabled(struct kvm_vcpu *vcpu)\n{\n\treturn vcpu->arch.msr_misc_features_enables &\n\t\t  MSR_MISC_FEATURES_ENABLES_CPUID_FAULT;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_emulate_cpuid(struct kvm_vcpu *vcpu)\n{\n\tu32 eax, ebx, ecx, edx;\n\n\tif (cpuid_fault_enabled(vcpu) && !kvm_require_cpl(vcpu, 0))\n\t\treturn 1;\n\n\teax = kvm_rax_read(vcpu);\n\tecx = kvm_rcx_read(vcpu);\n\tkvm_cpuid(vcpu, &eax, &ebx, &ecx, &edx, false);\n\tkvm_rax_write(vcpu, eax);\n\tkvm_rbx_write(vcpu, ebx);\n\tkvm_rcx_write(vcpu, ecx);\n\tkvm_rdx_write(vcpu, edx);\n\treturn kvm_skip_emulated_instruction(vcpu);\n}"
  },
  {
    "function_name": "kvm_cpuid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "988-1034",
    "snippet": "bool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,\n\t       u32 *ecx, u32 *edx, bool exact_only)\n{\n\tu32 orig_function = *eax, function = *eax, index = *ecx;\n\tstruct kvm_cpuid_entry2 *entry;\n\tbool exact, used_max_basic = false;\n\n\tentry = kvm_find_cpuid_entry(vcpu, function, index);\n\texact = !!entry;\n\n\tif (!entry && !exact_only) {\n\t\tentry = get_out_of_range_cpuid_entry(vcpu, &function, index);\n\t\tused_max_basic = !!entry;\n\t}\n\n\tif (entry) {\n\t\t*eax = entry->eax;\n\t\t*ebx = entry->ebx;\n\t\t*ecx = entry->ecx;\n\t\t*edx = entry->edx;\n\t\tif (function == 7 && index == 0) {\n\t\t\tu64 data;\n\t\t        if (!__kvm_get_msr(vcpu, MSR_IA32_TSX_CTRL, &data, true) &&\n\t\t\t    (data & TSX_CTRL_CPUID_CLEAR))\n\t\t\t\t*ebx &= ~(F(RTM) | F(HLE));\n\t\t}\n\t} else {\n\t\t*eax = *ebx = *ecx = *edx = 0;\n\t\t/*\n\t\t * When leaf 0BH or 1FH is defined, CL is pass-through\n\t\t * and EDX is always the x2APIC ID, even for undefined\n\t\t * subleaves. Index 1 will exist iff the leaf is\n\t\t * implemented, so we pass through CL iff leaf 1\n\t\t * exists. EDX can be copied from any existing index.\n\t\t */\n\t\tif (function == 0xb || function == 0x1f) {\n\t\t\tentry = kvm_find_cpuid_entry(vcpu, function, 1);\n\t\t\tif (entry) {\n\t\t\t\t*ecx = index & 0xff;\n\t\t\t\t*edx = entry->edx;\n\t\t\t}\n\t\t}\n\t}\n\ttrace_kvm_cpuid(orig_function, index, *eax, *ebx, *ecx, *edx, exact,\n\t\t\tused_max_basic);\n\treturn exact;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define F feature_bit"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_kvm_cpuid",
          "args": [
            "orig_function",
            "index",
            "*eax",
            "*ebx",
            "*ecx",
            "*edx",
            "exact",
            "used_max_basic"
          ],
          "line": 1031
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_find_cpuid_entry",
          "args": [
            "vcpu",
            "function",
            "1"
          ],
          "line": 1024
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_find_cpuid_entry",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "903-917",
          "snippet": "struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstruct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "F",
          "args": [
            "HLE"
          ],
          "line": 1012
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "883-893",
          "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
          "includes": [],
          "macros_used": [
            "#define pt_element_t u64",
            "#define pt_element_t u32",
            "#define pt_element_t u64"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__kvm_get_msr",
          "args": [
            "vcpu",
            "MSR_IA32_TSX_CTRL",
            "&data",
            "true"
          ],
          "line": 1010
        },
        "resolved": true,
        "details": {
          "function_name": "__kvm_get_msr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.c",
          "lines": "1513-1526",
          "snippet": "int __kvm_get_msr(struct kvm_vcpu *vcpu, u32 index, u64 *data,\n\t\t  bool host_initiated)\n{\n\tstruct msr_data msr;\n\tint ret;\n\n\tmsr.index = index;\n\tmsr.host_initiated = host_initiated;\n\n\tret = kvm_x86_ops.get_msr(vcpu, &msr);\n\tif (!ret)\n\t\t*data = msr.data;\n\treturn ret;\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include <clocksource/hyperv_timer.h>",
            "#include <asm/emulate_prefix.h>",
            "#include <asm/intel_pt.h>",
            "#include <asm/hypervisor.h>",
            "#include <asm/mshyperv.h>",
            "#include <asm/irq_remapping.h>",
            "#include <asm/div64.h>",
            "#include <asm/pvclock.h>",
            "#include <asm/fpu/internal.h> /* Ugh! */",
            "#include <linux/kernel_stat.h>",
            "#include <asm/mce.h>",
            "#include <asm/desc.h>",
            "#include <asm/msr.h>",
            "#include <asm/debugreg.h>",
            "#include <trace/events/kvm.h>",
            "#include <linux/mem_encrypt.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/irqbypass.h>",
            "#include <linux/kvm_irqfd.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/pci.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/intel-iommu.h>",
            "#include <linux/iommu.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mman.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/export.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/fs.h>",
            "#include <linux/kvm.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/clocksource.h>",
            "#include \"lapic.h\"",
            "#include \"hyperv.h\"",
            "#include \"pmu.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"tss.h\"",
            "#include \"i8254.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\"",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void update_cr8_intercept(struct kvm_vcpu *vcpu);",
            "static void process_nmi(struct kvm_vcpu *vcpu);",
            "static void enter_smm(struct kvm_vcpu *vcpu);",
            "static void store_regs(struct kvm_vcpu *vcpu);",
            "static int sync_regs(struct kvm_vcpu *vcpu);",
            "struct kvm_x86_ops kvm_x86_ops",
            "static void kvm_smm_changed(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_mmio(struct kvm_vcpu *vcpu);",
            "static int complete_emulated_pio(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include <clocksource/hyperv_timer.h>\n#include <asm/emulate_prefix.h>\n#include <asm/intel_pt.h>\n#include <asm/hypervisor.h>\n#include <asm/mshyperv.h>\n#include <asm/irq_remapping.h>\n#include <asm/div64.h>\n#include <asm/pvclock.h>\n#include <asm/fpu/internal.h> /* Ugh! */\n#include <linux/kernel_stat.h>\n#include <asm/mce.h>\n#include <asm/desc.h>\n#include <asm/msr.h>\n#include <asm/debugreg.h>\n#include <trace/events/kvm.h>\n#include <linux/mem_encrypt.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/stat.h>\n#include <linux/irqbypass.h>\n#include <linux/kvm_irqfd.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/pci.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/perf_event.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/user-return-notifier.h>\n#include <linux/cpufreq.h>\n#include <linux/intel-iommu.h>\n#include <linux/iommu.h>\n#include <linux/highmem.h>\n#include <linux/mman.h>\n#include <linux/moduleparam.h>\n#include <linux/export.h>\n#include <linux/vmalloc.h>\n#include <linux/fs.h>\n#include <linux/kvm.h>\n#include <linux/interrupt.h>\n#include <linux/clocksource.h>\n#include \"lapic.h\"\n#include \"hyperv.h\"\n#include \"pmu.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"tss.h\"\n#include \"i8254.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n#include <linux/kvm_host.h>\n\nstatic void update_cr8_intercept(struct kvm_vcpu *vcpu);\nstatic void process_nmi(struct kvm_vcpu *vcpu);\nstatic void enter_smm(struct kvm_vcpu *vcpu);\nstatic void store_regs(struct kvm_vcpu *vcpu);\nstatic int sync_regs(struct kvm_vcpu *vcpu);\nstruct kvm_x86_ops kvm_x86_ops;\nstatic void kvm_smm_changed(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_mmio(struct kvm_vcpu *vcpu);\nstatic int complete_emulated_pio(struct kvm_vcpu *vcpu);\n\nint __kvm_get_msr(struct kvm_vcpu *vcpu, u32 index, u64 *data,\n\t\t  bool host_initiated)\n{\n\tstruct msr_data msr;\n\tint ret;\n\n\tmsr.index = index;\n\tmsr.host_initiated = host_initiated;\n\n\tret = kvm_x86_ops.get_msr(vcpu, &msr);\n\tif (!ret)\n\t\t*data = msr.data;\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_out_of_range_cpuid_entry",
          "args": [
            "vcpu",
            "&function",
            "index"
          ],
          "line": 999
        },
        "resolved": true,
        "details": {
          "function_name": "get_out_of_range_cpuid_entry",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "948-986",
          "snippet": "static struct kvm_cpuid_entry2 *\nget_out_of_range_cpuid_entry(struct kvm_vcpu *vcpu, u32 *fn_ptr, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *basic, *class;\n\tu32 function = *fn_ptr;\n\n\tbasic = kvm_find_cpuid_entry(vcpu, 0, 0);\n\tif (!basic)\n\t\treturn NULL;\n\n\tif (is_guest_vendor_amd(basic->ebx, basic->ecx, basic->edx) ||\n\t    is_guest_vendor_hygon(basic->ebx, basic->ecx, basic->edx))\n\t\treturn NULL;\n\n\tif (function >= 0x40000000 && function <= 0x4fffffff)\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0xffffff00, 0);\n\telse if (function >= 0xc0000000)\n\t\tclass = kvm_find_cpuid_entry(vcpu, 0xc0000000, 0);\n\telse\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0x80000000, 0);\n\n\tif (class && function <= class->eax)\n\t\treturn NULL;\n\n\t/*\n\t * Leaf specific adjustments are also applied when redirecting to the\n\t * max basic entry, e.g. if the max basic leaf is 0xb but there is no\n\t * entry for CPUID.0xb.index (see below), then the output value for EDX\n\t * needs to be pulled from CPUID.0xb.1.\n\t */\n\t*fn_ptr = basic->eax;\n\n\t/*\n\t * The class does not exist or the requested function is out of range;\n\t * the effective CPUID entry is the max basic leaf.  Note, the index of\n\t * the original requested leaf is observed!\n\t */\n\treturn kvm_find_cpuid_entry(vcpu, basic->eax, index);\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic struct kvm_cpuid_entry2 *\nget_out_of_range_cpuid_entry(struct kvm_vcpu *vcpu, u32 *fn_ptr, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *basic, *class;\n\tu32 function = *fn_ptr;\n\n\tbasic = kvm_find_cpuid_entry(vcpu, 0, 0);\n\tif (!basic)\n\t\treturn NULL;\n\n\tif (is_guest_vendor_amd(basic->ebx, basic->ecx, basic->edx) ||\n\t    is_guest_vendor_hygon(basic->ebx, basic->ecx, basic->edx))\n\t\treturn NULL;\n\n\tif (function >= 0x40000000 && function <= 0x4fffffff)\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0xffffff00, 0);\n\telse if (function >= 0xc0000000)\n\t\tclass = kvm_find_cpuid_entry(vcpu, 0xc0000000, 0);\n\telse\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0x80000000, 0);\n\n\tif (class && function <= class->eax)\n\t\treturn NULL;\n\n\t/*\n\t * Leaf specific adjustments are also applied when redirecting to the\n\t * max basic entry, e.g. if the max basic leaf is 0xb but there is no\n\t * entry for CPUID.0xb.index (see below), then the output value for EDX\n\t * needs to be pulled from CPUID.0xb.1.\n\t */\n\t*fn_ptr = basic->eax;\n\n\t/*\n\t * The class does not exist or the requested function is out of range;\n\t * the effective CPUID entry is the max basic leaf.  Note, the index of\n\t * the original requested leaf is observed!\n\t */\n\treturn kvm_find_cpuid_entry(vcpu, basic->eax, index);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nbool kvm_cpuid(struct kvm_vcpu *vcpu, u32 *eax, u32 *ebx,\n\t       u32 *ecx, u32 *edx, bool exact_only)\n{\n\tu32 orig_function = *eax, function = *eax, index = *ecx;\n\tstruct kvm_cpuid_entry2 *entry;\n\tbool exact, used_max_basic = false;\n\n\tentry = kvm_find_cpuid_entry(vcpu, function, index);\n\texact = !!entry;\n\n\tif (!entry && !exact_only) {\n\t\tentry = get_out_of_range_cpuid_entry(vcpu, &function, index);\n\t\tused_max_basic = !!entry;\n\t}\n\n\tif (entry) {\n\t\t*eax = entry->eax;\n\t\t*ebx = entry->ebx;\n\t\t*ecx = entry->ecx;\n\t\t*edx = entry->edx;\n\t\tif (function == 7 && index == 0) {\n\t\t\tu64 data;\n\t\t        if (!__kvm_get_msr(vcpu, MSR_IA32_TSX_CTRL, &data, true) &&\n\t\t\t    (data & TSX_CTRL_CPUID_CLEAR))\n\t\t\t\t*ebx &= ~(F(RTM) | F(HLE));\n\t\t}\n\t} else {\n\t\t*eax = *ebx = *ecx = *edx = 0;\n\t\t/*\n\t\t * When leaf 0BH or 1FH is defined, CL is pass-through\n\t\t * and EDX is always the x2APIC ID, even for undefined\n\t\t * subleaves. Index 1 will exist iff the leaf is\n\t\t * implemented, so we pass through CL iff leaf 1\n\t\t * exists. EDX can be copied from any existing index.\n\t\t */\n\t\tif (function == 0xb || function == 0x1f) {\n\t\t\tentry = kvm_find_cpuid_entry(vcpu, function, 1);\n\t\t\tif (entry) {\n\t\t\t\t*ecx = index & 0xff;\n\t\t\t\t*edx = entry->edx;\n\t\t\t}\n\t\t}\n\t}\n\ttrace_kvm_cpuid(orig_function, index, *eax, *ebx, *ecx, *edx, exact,\n\t\t\tused_max_basic);\n\treturn exact;\n}"
  },
  {
    "function_name": "get_out_of_range_cpuid_entry",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "948-986",
    "snippet": "static struct kvm_cpuid_entry2 *\nget_out_of_range_cpuid_entry(struct kvm_vcpu *vcpu, u32 *fn_ptr, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *basic, *class;\n\tu32 function = *fn_ptr;\n\n\tbasic = kvm_find_cpuid_entry(vcpu, 0, 0);\n\tif (!basic)\n\t\treturn NULL;\n\n\tif (is_guest_vendor_amd(basic->ebx, basic->ecx, basic->edx) ||\n\t    is_guest_vendor_hygon(basic->ebx, basic->ecx, basic->edx))\n\t\treturn NULL;\n\n\tif (function >= 0x40000000 && function <= 0x4fffffff)\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0xffffff00, 0);\n\telse if (function >= 0xc0000000)\n\t\tclass = kvm_find_cpuid_entry(vcpu, 0xc0000000, 0);\n\telse\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0x80000000, 0);\n\n\tif (class && function <= class->eax)\n\t\treturn NULL;\n\n\t/*\n\t * Leaf specific adjustments are also applied when redirecting to the\n\t * max basic entry, e.g. if the max basic leaf is 0xb but there is no\n\t * entry for CPUID.0xb.index (see below), then the output value for EDX\n\t * needs to be pulled from CPUID.0xb.1.\n\t */\n\t*fn_ptr = basic->eax;\n\n\t/*\n\t * The class does not exist or the requested function is out of range;\n\t * the effective CPUID entry is the max basic leaf.  Note, the index of\n\t * the original requested leaf is observed!\n\t */\n\treturn kvm_find_cpuid_entry(vcpu, basic->eax, index);\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_find_cpuid_entry",
          "args": [
            "vcpu",
            "basic->eax",
            "index"
          ],
          "line": 985
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_find_cpuid_entry",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "903-917",
          "snippet": "struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstruct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_guest_vendor_hygon",
          "args": [
            "basic->ebx",
            "basic->ecx",
            "basic->edx"
          ],
          "line": 959
        },
        "resolved": true,
        "details": {
          "function_name": "is_guest_vendor_hygon",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_emulate.h",
          "lines": "419-424",
          "snippet": "static inline bool is_guest_vendor_hygon(u32 ebx, u32 ecx, u32 edx)\n{\n\treturn ebx == X86EMUL_CPUID_VENDOR_HygonGenuine_ebx &&\n\t       ecx == X86EMUL_CPUID_VENDOR_HygonGenuine_ecx &&\n\t       edx == X86EMUL_CPUID_VENDOR_HygonGenuine_edx;\n}",
          "includes": [
            "#include <asm/desc_defs.h>"
          ],
          "macros_used": [
            "#define X86EMUL_CPUID_VENDOR_HygonGenuine_edx 0x6e65476e",
            "#define X86EMUL_CPUID_VENDOR_HygonGenuine_ecx 0x656e6975",
            "#define X86EMUL_CPUID_VENDOR_HygonGenuine_ebx 0x6f677948"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/desc_defs.h>\n\n#define X86EMUL_CPUID_VENDOR_HygonGenuine_edx 0x6e65476e\n#define X86EMUL_CPUID_VENDOR_HygonGenuine_ecx 0x656e6975\n#define X86EMUL_CPUID_VENDOR_HygonGenuine_ebx 0x6f677948\n\nstatic inline bool is_guest_vendor_hygon(u32 ebx, u32 ecx, u32 edx)\n{\n\treturn ebx == X86EMUL_CPUID_VENDOR_HygonGenuine_ebx &&\n\t       ecx == X86EMUL_CPUID_VENDOR_HygonGenuine_ecx &&\n\t       edx == X86EMUL_CPUID_VENDOR_HygonGenuine_edx;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_guest_vendor_amd",
          "args": [
            "basic->ebx",
            "basic->ecx",
            "basic->edx"
          ],
          "line": 958
        },
        "resolved": true,
        "details": {
          "function_name": "is_guest_vendor_amd",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_emulate.h",
          "lines": "409-417",
          "snippet": "static inline bool is_guest_vendor_amd(u32 ebx, u32 ecx, u32 edx)\n{\n\treturn (ebx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx &&\n\t\tecx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ecx &&\n\t\tedx == X86EMUL_CPUID_VENDOR_AuthenticAMD_edx) ||\n\t       (ebx == X86EMUL_CPUID_VENDOR_AMDisbetterI_ebx &&\n\t\tecx == X86EMUL_CPUID_VENDOR_AMDisbetterI_ecx &&\n\t\tedx == X86EMUL_CPUID_VENDOR_AMDisbetterI_edx);\n}",
          "includes": [
            "#include <asm/desc_defs.h>"
          ],
          "macros_used": [
            "#define X86EMUL_CPUID_VENDOR_AMDisbetterI_edx 0x74656273",
            "#define X86EMUL_CPUID_VENDOR_AMDisbetterI_ecx 0x21726574",
            "#define X86EMUL_CPUID_VENDOR_AMDisbetterI_ebx 0x69444d41",
            "#define X86EMUL_CPUID_VENDOR_AuthenticAMD_edx 0x69746e65",
            "#define X86EMUL_CPUID_VENDOR_AuthenticAMD_ecx 0x444d4163",
            "#define X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx 0x68747541"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/desc_defs.h>\n\n#define X86EMUL_CPUID_VENDOR_AMDisbetterI_edx 0x74656273\n#define X86EMUL_CPUID_VENDOR_AMDisbetterI_ecx 0x21726574\n#define X86EMUL_CPUID_VENDOR_AMDisbetterI_ebx 0x69444d41\n#define X86EMUL_CPUID_VENDOR_AuthenticAMD_edx 0x69746e65\n#define X86EMUL_CPUID_VENDOR_AuthenticAMD_ecx 0x444d4163\n#define X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx 0x68747541\n\nstatic inline bool is_guest_vendor_amd(u32 ebx, u32 ecx, u32 edx)\n{\n\treturn (ebx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ebx &&\n\t\tecx == X86EMUL_CPUID_VENDOR_AuthenticAMD_ecx &&\n\t\tedx == X86EMUL_CPUID_VENDOR_AuthenticAMD_edx) ||\n\t       (ebx == X86EMUL_CPUID_VENDOR_AMDisbetterI_ebx &&\n\t\tecx == X86EMUL_CPUID_VENDOR_AMDisbetterI_ecx &&\n\t\tedx == X86EMUL_CPUID_VENDOR_AMDisbetterI_edx);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic struct kvm_cpuid_entry2 *\nget_out_of_range_cpuid_entry(struct kvm_vcpu *vcpu, u32 *fn_ptr, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *basic, *class;\n\tu32 function = *fn_ptr;\n\n\tbasic = kvm_find_cpuid_entry(vcpu, 0, 0);\n\tif (!basic)\n\t\treturn NULL;\n\n\tif (is_guest_vendor_amd(basic->ebx, basic->ecx, basic->edx) ||\n\t    is_guest_vendor_hygon(basic->ebx, basic->ecx, basic->edx))\n\t\treturn NULL;\n\n\tif (function >= 0x40000000 && function <= 0x4fffffff)\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0xffffff00, 0);\n\telse if (function >= 0xc0000000)\n\t\tclass = kvm_find_cpuid_entry(vcpu, 0xc0000000, 0);\n\telse\n\t\tclass = kvm_find_cpuid_entry(vcpu, function & 0x80000000, 0);\n\n\tif (class && function <= class->eax)\n\t\treturn NULL;\n\n\t/*\n\t * Leaf specific adjustments are also applied when redirecting to the\n\t * max basic entry, e.g. if the max basic leaf is 0xb but there is no\n\t * entry for CPUID.0xb.index (see below), then the output value for EDX\n\t * needs to be pulled from CPUID.0xb.1.\n\t */\n\t*fn_ptr = basic->eax;\n\n\t/*\n\t * The class does not exist or the requested function is out of range;\n\t * the effective CPUID entry is the max basic leaf.  Note, the index of\n\t * the original requested leaf is observed!\n\t */\n\treturn kvm_find_cpuid_entry(vcpu, basic->eax, index);\n}"
  },
  {
    "function_name": "kvm_find_cpuid_entry",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "903-917",
    "snippet": "struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstruct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}"
  },
  {
    "function_name": "kvm_dev_ioctl_get_cpuid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "860-901",
    "snippet": "int kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,\n\t\t\t    struct kvm_cpuid_entry2 __user *entries,\n\t\t\t    unsigned int type)\n{\n\tstatic const u32 funcs[] = {\n\t\t0, 0x80000000, CENTAUR_CPUID_SIGNATURE, KVM_CPUID_SIGNATURE,\n\t};\n\n\tstruct kvm_cpuid_array array = {\n\t\t.nent = 0,\n\t\t.maxnent = cpuid->nent,\n\t};\n\tint r, i;\n\n\tif (cpuid->nent < 1)\n\t\treturn -E2BIG;\n\tif (cpuid->nent > KVM_MAX_CPUID_ENTRIES)\n\t\tcpuid->nent = KVM_MAX_CPUID_ENTRIES;\n\n\tif (sanity_check_entries(entries, cpuid->nent, type))\n\t\treturn -EINVAL;\n\n\tarray.entries = vzalloc(array_size(sizeof(struct kvm_cpuid_entry2),\n\t\t\t\t\t   cpuid->nent));\n\tif (!array.entries)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < ARRAY_SIZE(funcs); i++) {\n\t\tr = get_cpuid_func(&array, funcs[i], type);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t}\n\tcpuid->nent = array.nent;\n\n\tif (copy_to_user(entries, array.entries,\n\t\t\t array.nent * sizeof(struct kvm_cpuid_entry2)))\n\t\tr = -EFAULT;\n\nout_free:\n\tvfree(array.entries);\n\treturn r;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define CENTAUR_CPUID_SIGNATURE 0xC0000000"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "vfree",
          "args": [
            "array.entries"
          ],
          "line": 899
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_to_user",
          "args": [
            "entries",
            "array.entries",
            "array.nent * sizeof(struct kvm_cpuid_entry2)"
          ],
          "line": 894
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_cpuid_func",
          "args": [
            "&array",
            "funcs[i]",
            "type"
          ],
          "line": 888
        },
        "resolved": true,
        "details": {
          "function_name": "get_cpuid_func",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "809-831",
          "snippet": "static int get_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t  unsigned int type)\n{\n\tu32 limit;\n\tint r;\n\n\tif (func == CENTAUR_CPUID_SIGNATURE &&\n\t    boot_cpu_data.x86_vendor != X86_VENDOR_CENTAUR)\n\t\treturn 0;\n\n\tr = do_cpuid_func(array, func, type);\n\tif (r)\n\t\treturn r;\n\n\tlimit = array->entries[array->nent - 1].eax;\n\tfor (func = func + 1; func <= limit; ++func) {\n\t\tr = do_cpuid_func(array, func, type);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\n\treturn r;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define CENTAUR_CPUID_SIGNATURE 0xC0000000"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define CENTAUR_CPUID_SIGNATURE 0xC0000000\n\nstatic int get_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t  unsigned int type)\n{\n\tu32 limit;\n\tint r;\n\n\tif (func == CENTAUR_CPUID_SIGNATURE &&\n\t    boot_cpu_data.x86_vendor != X86_VENDOR_CENTAUR)\n\t\treturn 0;\n\n\tr = do_cpuid_func(array, func, type);\n\tif (r)\n\t\treturn r;\n\n\tlimit = array->entries[array->nent - 1].eax;\n\tfor (func = func + 1; func <= limit; ++func) {\n\t\tr = do_cpuid_func(array, func, type);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ARRAY_SIZE",
          "args": [
            "funcs"
          ],
          "line": 887
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "vzalloc",
          "args": [
            "array_size(sizeof(struct kvm_cpuid_entry2),\n\t\t\t\t\t   cpuid->nent)"
          ],
          "line": 882
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "array_size",
          "args": [
            "sizeof(struct kvm_cpuid_entry2)",
            "cpuid->nent"
          ],
          "line": 882
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sanity_check_entries",
          "args": [
            "entries",
            "cpuid->nent",
            "type"
          ],
          "line": 879
        },
        "resolved": true,
        "details": {
          "function_name": "sanity_check_entries",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "833-858",
          "snippet": "static bool sanity_check_entries(struct kvm_cpuid_entry2 __user *entries,\n\t\t\t\t __u32 num_entries, unsigned int ioctl_type)\n{\n\tint i;\n\t__u32 pad[3];\n\n\tif (ioctl_type != KVM_GET_EMULATED_CPUID)\n\t\treturn false;\n\n\t/*\n\t * We want to make sure that ->padding is being passed clean from\n\t * userspace in case we want to use it for something in the future.\n\t *\n\t * Sadly, this wasn't enforced for KVM_GET_SUPPORTED_CPUID and so we\n\t * have to give ourselves satisfied only with the emulated side. /me\n\t * sheds a tear.\n\t */\n\tfor (i = 0; i < num_entries; i++) {\n\t\tif (copy_from_user(pad, entries[i].padding, sizeof(pad)))\n\t\t\treturn true;\n\n\t\tif (pad[0] || pad[1] || pad[2])\n\t\t\treturn true;\n\t}\n\treturn false;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic bool sanity_check_entries(struct kvm_cpuid_entry2 __user *entries,\n\t\t\t\t __u32 num_entries, unsigned int ioctl_type)\n{\n\tint i;\n\t__u32 pad[3];\n\n\tif (ioctl_type != KVM_GET_EMULATED_CPUID)\n\t\treturn false;\n\n\t/*\n\t * We want to make sure that ->padding is being passed clean from\n\t * userspace in case we want to use it for something in the future.\n\t *\n\t * Sadly, this wasn't enforced for KVM_GET_SUPPORTED_CPUID and so we\n\t * have to give ourselves satisfied only with the emulated side. /me\n\t * sheds a tear.\n\t */\n\tfor (i = 0; i < num_entries; i++) {\n\t\tif (copy_from_user(pad, entries[i].padding, sizeof(pad)))\n\t\t\treturn true;\n\n\t\tif (pad[0] || pad[1] || pad[2])\n\t\t\treturn true;\n\t}\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define CENTAUR_CPUID_SIGNATURE 0xC0000000\n\nint kvm_dev_ioctl_get_cpuid(struct kvm_cpuid2 *cpuid,\n\t\t\t    struct kvm_cpuid_entry2 __user *entries,\n\t\t\t    unsigned int type)\n{\n\tstatic const u32 funcs[] = {\n\t\t0, 0x80000000, CENTAUR_CPUID_SIGNATURE, KVM_CPUID_SIGNATURE,\n\t};\n\n\tstruct kvm_cpuid_array array = {\n\t\t.nent = 0,\n\t\t.maxnent = cpuid->nent,\n\t};\n\tint r, i;\n\n\tif (cpuid->nent < 1)\n\t\treturn -E2BIG;\n\tif (cpuid->nent > KVM_MAX_CPUID_ENTRIES)\n\t\tcpuid->nent = KVM_MAX_CPUID_ENTRIES;\n\n\tif (sanity_check_entries(entries, cpuid->nent, type))\n\t\treturn -EINVAL;\n\n\tarray.entries = vzalloc(array_size(sizeof(struct kvm_cpuid_entry2),\n\t\t\t\t\t   cpuid->nent));\n\tif (!array.entries)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < ARRAY_SIZE(funcs); i++) {\n\t\tr = get_cpuid_func(&array, funcs[i], type);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t}\n\tcpuid->nent = array.nent;\n\n\tif (copy_to_user(entries, array.entries,\n\t\t\t array.nent * sizeof(struct kvm_cpuid_entry2)))\n\t\tr = -EFAULT;\n\nout_free:\n\tvfree(array.entries);\n\treturn r;\n}"
  },
  {
    "function_name": "sanity_check_entries",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "833-858",
    "snippet": "static bool sanity_check_entries(struct kvm_cpuid_entry2 __user *entries,\n\t\t\t\t __u32 num_entries, unsigned int ioctl_type)\n{\n\tint i;\n\t__u32 pad[3];\n\n\tif (ioctl_type != KVM_GET_EMULATED_CPUID)\n\t\treturn false;\n\n\t/*\n\t * We want to make sure that ->padding is being passed clean from\n\t * userspace in case we want to use it for something in the future.\n\t *\n\t * Sadly, this wasn't enforced for KVM_GET_SUPPORTED_CPUID and so we\n\t * have to give ourselves satisfied only with the emulated side. /me\n\t * sheds a tear.\n\t */\n\tfor (i = 0; i < num_entries; i++) {\n\t\tif (copy_from_user(pad, entries[i].padding, sizeof(pad)))\n\t\t\treturn true;\n\n\t\tif (pad[0] || pad[1] || pad[2])\n\t\t\treturn true;\n\t}\n\treturn false;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "pad",
            "entries[i].padding",
            "sizeof(pad)"
          ],
          "line": 851
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic bool sanity_check_entries(struct kvm_cpuid_entry2 __user *entries,\n\t\t\t\t __u32 num_entries, unsigned int ioctl_type)\n{\n\tint i;\n\t__u32 pad[3];\n\n\tif (ioctl_type != KVM_GET_EMULATED_CPUID)\n\t\treturn false;\n\n\t/*\n\t * We want to make sure that ->padding is being passed clean from\n\t * userspace in case we want to use it for something in the future.\n\t *\n\t * Sadly, this wasn't enforced for KVM_GET_SUPPORTED_CPUID and so we\n\t * have to give ourselves satisfied only with the emulated side. /me\n\t * sheds a tear.\n\t */\n\tfor (i = 0; i < num_entries; i++) {\n\t\tif (copy_from_user(pad, entries[i].padding, sizeof(pad)))\n\t\t\treturn true;\n\n\t\tif (pad[0] || pad[1] || pad[2])\n\t\t\treturn true;\n\t}\n\treturn false;\n}"
  },
  {
    "function_name": "get_cpuid_func",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "809-831",
    "snippet": "static int get_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t  unsigned int type)\n{\n\tu32 limit;\n\tint r;\n\n\tif (func == CENTAUR_CPUID_SIGNATURE &&\n\t    boot_cpu_data.x86_vendor != X86_VENDOR_CENTAUR)\n\t\treturn 0;\n\n\tr = do_cpuid_func(array, func, type);\n\tif (r)\n\t\treturn r;\n\n\tlimit = array->entries[array->nent - 1].eax;\n\tfor (func = func + 1; func <= limit; ++func) {\n\t\tr = do_cpuid_func(array, func, type);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\n\treturn r;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define CENTAUR_CPUID_SIGNATURE 0xC0000000"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "do_cpuid_func",
          "args": [
            "array",
            "func",
            "type"
          ],
          "line": 825
        },
        "resolved": true,
        "details": {
          "function_name": "do_cpuid_func",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "798-805",
          "snippet": "static int do_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t unsigned int type)\n{\n\tif (type == KVM_GET_EMULATED_CPUID)\n\t\treturn __do_cpuid_func_emulated(array, func);\n\n\treturn __do_cpuid_func(array, func);\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic int do_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t unsigned int type)\n{\n\tif (type == KVM_GET_EMULATED_CPUID)\n\t\treturn __do_cpuid_func_emulated(array, func);\n\n\treturn __do_cpuid_func(array, func);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define CENTAUR_CPUID_SIGNATURE 0xC0000000\n\nstatic int get_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t  unsigned int type)\n{\n\tu32 limit;\n\tint r;\n\n\tif (func == CENTAUR_CPUID_SIGNATURE &&\n\t    boot_cpu_data.x86_vendor != X86_VENDOR_CENTAUR)\n\t\treturn 0;\n\n\tr = do_cpuid_func(array, func, type);\n\tif (r)\n\t\treturn r;\n\n\tlimit = array->entries[array->nent - 1].eax;\n\tfor (func = func + 1; func <= limit; ++func) {\n\t\tr = do_cpuid_func(array, func, type);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\n\treturn r;\n}"
  },
  {
    "function_name": "do_cpuid_func",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "798-805",
    "snippet": "static int do_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t unsigned int type)\n{\n\tif (type == KVM_GET_EMULATED_CPUID)\n\t\treturn __do_cpuid_func_emulated(array, func);\n\n\treturn __do_cpuid_func(array, func);\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__do_cpuid_func",
          "args": [
            "array",
            "func"
          ],
          "line": 804
        },
        "resolved": true,
        "details": {
          "function_name": "__do_cpuid_func",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "504-796",
          "snippet": "static inline int __do_cpuid_func(struct kvm_cpuid_array *array, u32 function)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\tint r, i, max_idx;\n\n\t/* all calls to cpuid_count() should be made on the same cpu */\n\tget_cpu();\n\n\tr = -E2BIG;\n\n\tentry = do_host_cpuid(array, function, 0);\n\tif (!entry)\n\t\tgoto out;\n\n\tswitch (function) {\n\tcase 0:\n\t\t/* Limited to the highest leaf implemented in KVM. */\n\t\tentry->eax = min(entry->eax, 0x1fU);\n\t\tbreak;\n\tcase 1:\n\t\tcpuid_entry_override(entry, CPUID_1_EDX);\n\t\tcpuid_entry_override(entry, CPUID_1_ECX);\n\t\tbreak;\n\tcase 2:\n\t\t/*\n\t\t * On ancient CPUs, function 2 entries are STATEFUL.  That is,\n\t\t * CPUID(function=2, index=0) may return different results each\n\t\t * time, with the least-significant byte in EAX enumerating the\n\t\t * number of times software should do CPUID(2, 0).\n\t\t *\n\t\t * Modern CPUs, i.e. every CPU KVM has *ever* run on are less\n\t\t * idiotic.  Intel's SDM states that EAX & 0xff \"will always\n\t\t * return 01H. Software should ignore this value and not\n\t\t * interpret it as an informational descriptor\", while AMD's\n\t\t * APM states that CPUID(2) is reserved.\n\t\t *\n\t\t * WARN if a frankenstein CPU that supports virtualization and\n\t\t * a stateful CPUID.0x2 is encountered.\n\t\t */\n\t\tWARN_ON_ONCE((entry->eax & 0xff) > 1);\n\t\tbreak;\n\t/* functions 4 and 0x8000001d have additional index. */\n\tcase 4:\n\tcase 0x8000001d:\n\t\t/*\n\t\t * Read entries until the cache type in the previous entry is\n\t\t * zero, i.e. indicates an invalid entry.\n\t\t */\n\t\tfor (i = 1; entry->eax & 0x1f; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 6: /* Thermal management */\n\t\tentry->eax = 0x4; /* allow ARAT */\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\t/* function 7 has additional index. */\n\tcase 7:\n\t\tentry->eax = min(entry->eax, 1u);\n\t\tcpuid_entry_override(entry, CPUID_7_0_EBX);\n\t\tcpuid_entry_override(entry, CPUID_7_ECX);\n\t\tcpuid_entry_override(entry, CPUID_7_EDX);\n\n\t\t/* KVM only supports 0x7.0 and 0x7.1, capped above via min(). */\n\t\tif (entry->eax == 1) {\n\t\t\tentry = do_host_cpuid(array, function, 1);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\tcpuid_entry_override(entry, CPUID_7_1_EAX);\n\t\t\tentry->ebx = 0;\n\t\t\tentry->ecx = 0;\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\tcase 9:\n\t\tbreak;\n\tcase 0xa: { /* Architectural Performance Monitoring */\n\t\tstruct x86_pmu_capability cap;\n\t\tunion cpuid10_eax eax;\n\t\tunion cpuid10_edx edx;\n\n\t\tperf_get_x86_pmu_capability(&cap);\n\n\t\t/*\n\t\t * Only support guest architectural pmu on a host\n\t\t * with architectural pmu.\n\t\t */\n\t\tif (!cap.version)\n\t\t\tmemset(&cap, 0, sizeof(cap));\n\n\t\teax.split.version_id = min(cap.version, 2);\n\t\teax.split.num_counters = cap.num_counters_gp;\n\t\teax.split.bit_width = cap.bit_width_gp;\n\t\teax.split.mask_length = cap.events_mask_len;\n\n\t\tedx.split.num_counters_fixed = cap.num_counters_fixed;\n\t\tedx.split.bit_width_fixed = cap.bit_width_fixed;\n\t\tedx.split.reserved = 0;\n\n\t\tentry->eax = eax.full;\n\t\tentry->ebx = cap.events_mask;\n\t\tentry->ecx = 0;\n\t\tentry->edx = edx.full;\n\t\tbreak;\n\t}\n\t/*\n\t * Per Intel's SDM, the 0x1f is a superset of 0xb,\n\t * thus they can be handled by common code.\n\t */\n\tcase 0x1f:\n\tcase 0xb:\n\t\t/*\n\t\t * Populate entries until the level type (ECX[15:8]) of the\n\t\t * previous entry is zero.  Note, CPUID EAX.{0x1f,0xb}.0 is\n\t\t * the starting entry, filled by the primary do_host_cpuid().\n\t\t */\n\t\tfor (i = 1; entry->ecx & 0xff00; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 0xd:\n\t\tentry->eax &= supported_xcr0;\n\t\tentry->ebx = xstate_required_size(supported_xcr0, false);\n\t\tentry->ecx = entry->ebx;\n\t\tentry->edx &= supported_xcr0 >> 32;\n\t\tif (!supported_xcr0)\n\t\t\tbreak;\n\n\t\tentry = do_host_cpuid(array, function, 1);\n\t\tif (!entry)\n\t\t\tgoto out;\n\n\t\tcpuid_entry_override(entry, CPUID_D_1_EAX);\n\t\tif (entry->eax & (F(XSAVES)|F(XSAVEC)))\n\t\t\tentry->ebx = xstate_required_size(supported_xcr0 | supported_xss,\n\t\t\t\t\t\t\t  true);\n\t\telse {\n\t\t\tWARN_ON_ONCE(supported_xss != 0);\n\t\t\tentry->ebx = 0;\n\t\t}\n\t\tentry->ecx &= supported_xss;\n\t\tentry->edx &= supported_xss >> 32;\n\n\t\tfor (i = 2; i < 64; ++i) {\n\t\t\tbool s_state;\n\t\t\tif (supported_xcr0 & BIT_ULL(i))\n\t\t\t\ts_state = false;\n\t\t\telse if (supported_xss & BIT_ULL(i))\n\t\t\t\ts_state = true;\n\t\t\telse\n\t\t\t\tcontinue;\n\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\t/*\n\t\t\t * The supported check above should have filtered out\n\t\t\t * invalid sub-leafs.  Only valid sub-leafs should\n\t\t\t * reach this point, and they should have a non-zero\n\t\t\t * save state size.  Furthermore, check whether the\n\t\t\t * processor agrees with supported_xcr0/supported_xss\n\t\t\t * on whether this is an XCR0- or IA32_XSS-managed area.\n\t\t\t */\n\t\t\tif (WARN_ON_ONCE(!entry->eax || (entry->ecx & 0x1) != s_state)) {\n\t\t\t\t--array->nent;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\t/* Intel PT */\n\tcase 0x14:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_INTEL_PT)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 1, max_idx = entry->eax; i <= max_idx; ++i) {\n\t\t\tif (!do_host_cpuid(array, function, i))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase KVM_CPUID_SIGNATURE: {\n\t\tstatic const char signature[12] = \"KVMKVMKVM\\0\\0\";\n\t\tconst u32 *sigptr = (const u32 *)signature;\n\t\tentry->eax = KVM_CPUID_FEATURES;\n\t\tentry->ebx = sigptr[0];\n\t\tentry->ecx = sigptr[1];\n\t\tentry->edx = sigptr[2];\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_FEATURES:\n\t\tentry->eax = (1 << KVM_FEATURE_CLOCKSOURCE) |\n\t\t\t     (1 << KVM_FEATURE_NOP_IO_DELAY) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE2) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF) |\n\t\t\t     (1 << KVM_FEATURE_PV_EOI) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE_STABLE_BIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_UNHALT) |\n\t\t\t     (1 << KVM_FEATURE_PV_TLB_FLUSH) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF_VMEXIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_SEND_IPI) |\n\t\t\t     (1 << KVM_FEATURE_POLL_CONTROL) |\n\t\t\t     (1 << KVM_FEATURE_PV_SCHED_YIELD);\n\n\t\tif (sched_info_on())\n\t\t\tentry->eax |= (1 << KVM_FEATURE_STEAL_TIME);\n\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\tcase 0x80000000:\n\t\tentry->eax = min(entry->eax, 0x8000001f);\n\t\tbreak;\n\tcase 0x80000001:\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_EDX);\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_ECX);\n\t\tbreak;\n\tcase 0x80000007: /* Advanced power management */\n\t\t/* invariant TSC is CPUID.80000007H:EDX[8] */\n\t\tentry->edx &= (1 << 8);\n\t\t/* mask against host */\n\t\tentry->edx &= boot_cpu_data.x86_power;\n\t\tentry->eax = entry->ebx = entry->ecx = 0;\n\t\tbreak;\n\tcase 0x80000008: {\n\t\tunsigned g_phys_as = (entry->eax >> 16) & 0xff;\n\t\tunsigned virt_as = max((entry->eax >> 8) & 0xff, 48U);\n\t\tunsigned phys_as = entry->eax & 0xff;\n\n\t\tif (!g_phys_as)\n\t\t\tg_phys_as = phys_as;\n\t\tentry->eax = g_phys_as | (virt_as << 8);\n\t\tentry->edx = 0;\n\t\tcpuid_entry_override(entry, CPUID_8000_0008_EBX);\n\t\tbreak;\n\t}\n\tcase 0x8000000A:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_SVM)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\t\tentry->eax = 1; /* SVM revision 1 */\n\t\tentry->ebx = 8; /* Lets support 8 ASIDs in case we add proper\n\t\t\t\t   ASID emulation to nested SVM */\n\t\tentry->ecx = 0; /* Reserved */\n\t\tcpuid_entry_override(entry, CPUID_8000_000A_EDX);\n\t\tbreak;\n\tcase 0x80000019:\n\t\tentry->ecx = entry->edx = 0;\n\t\tbreak;\n\tcase 0x8000001a:\n\tcase 0x8000001e:\n\t\tbreak;\n\t/* Support memory encryption cpuid if host supports it */\n\tcase 0x8000001F:\n\t\tif (!boot_cpu_has(X86_FEATURE_SEV))\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t/*Add support for Centaur's CPUID instruction*/\n\tcase 0xC0000000:\n\t\t/*Just support up to 0xC0000004 now*/\n\t\tentry->eax = min(entry->eax, 0xC0000004);\n\t\tbreak;\n\tcase 0xC0000001:\n\t\tcpuid_entry_override(entry, CPUID_C000_0001_EDX);\n\t\tbreak;\n\tcase 3: /* Processor serial number */\n\tcase 5: /* MONITOR/MWAIT */\n\tcase 0xC0000002:\n\tcase 0xC0000003:\n\tcase 0xC0000004:\n\tdefault:\n\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t}\n\n\tr = 0;\n\nout:\n\tput_cpu();\n\n\treturn r;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define F feature_bit"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nstatic inline int __do_cpuid_func(struct kvm_cpuid_array *array, u32 function)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\tint r, i, max_idx;\n\n\t/* all calls to cpuid_count() should be made on the same cpu */\n\tget_cpu();\n\n\tr = -E2BIG;\n\n\tentry = do_host_cpuid(array, function, 0);\n\tif (!entry)\n\t\tgoto out;\n\n\tswitch (function) {\n\tcase 0:\n\t\t/* Limited to the highest leaf implemented in KVM. */\n\t\tentry->eax = min(entry->eax, 0x1fU);\n\t\tbreak;\n\tcase 1:\n\t\tcpuid_entry_override(entry, CPUID_1_EDX);\n\t\tcpuid_entry_override(entry, CPUID_1_ECX);\n\t\tbreak;\n\tcase 2:\n\t\t/*\n\t\t * On ancient CPUs, function 2 entries are STATEFUL.  That is,\n\t\t * CPUID(function=2, index=0) may return different results each\n\t\t * time, with the least-significant byte in EAX enumerating the\n\t\t * number of times software should do CPUID(2, 0).\n\t\t *\n\t\t * Modern CPUs, i.e. every CPU KVM has *ever* run on are less\n\t\t * idiotic.  Intel's SDM states that EAX & 0xff \"will always\n\t\t * return 01H. Software should ignore this value and not\n\t\t * interpret it as an informational descriptor\", while AMD's\n\t\t * APM states that CPUID(2) is reserved.\n\t\t *\n\t\t * WARN if a frankenstein CPU that supports virtualization and\n\t\t * a stateful CPUID.0x2 is encountered.\n\t\t */\n\t\tWARN_ON_ONCE((entry->eax & 0xff) > 1);\n\t\tbreak;\n\t/* functions 4 and 0x8000001d have additional index. */\n\tcase 4:\n\tcase 0x8000001d:\n\t\t/*\n\t\t * Read entries until the cache type in the previous entry is\n\t\t * zero, i.e. indicates an invalid entry.\n\t\t */\n\t\tfor (i = 1; entry->eax & 0x1f; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 6: /* Thermal management */\n\t\tentry->eax = 0x4; /* allow ARAT */\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\t/* function 7 has additional index. */\n\tcase 7:\n\t\tentry->eax = min(entry->eax, 1u);\n\t\tcpuid_entry_override(entry, CPUID_7_0_EBX);\n\t\tcpuid_entry_override(entry, CPUID_7_ECX);\n\t\tcpuid_entry_override(entry, CPUID_7_EDX);\n\n\t\t/* KVM only supports 0x7.0 and 0x7.1, capped above via min(). */\n\t\tif (entry->eax == 1) {\n\t\t\tentry = do_host_cpuid(array, function, 1);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\tcpuid_entry_override(entry, CPUID_7_1_EAX);\n\t\t\tentry->ebx = 0;\n\t\t\tentry->ecx = 0;\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\tcase 9:\n\t\tbreak;\n\tcase 0xa: { /* Architectural Performance Monitoring */\n\t\tstruct x86_pmu_capability cap;\n\t\tunion cpuid10_eax eax;\n\t\tunion cpuid10_edx edx;\n\n\t\tperf_get_x86_pmu_capability(&cap);\n\n\t\t/*\n\t\t * Only support guest architectural pmu on a host\n\t\t * with architectural pmu.\n\t\t */\n\t\tif (!cap.version)\n\t\t\tmemset(&cap, 0, sizeof(cap));\n\n\t\teax.split.version_id = min(cap.version, 2);\n\t\teax.split.num_counters = cap.num_counters_gp;\n\t\teax.split.bit_width = cap.bit_width_gp;\n\t\teax.split.mask_length = cap.events_mask_len;\n\n\t\tedx.split.num_counters_fixed = cap.num_counters_fixed;\n\t\tedx.split.bit_width_fixed = cap.bit_width_fixed;\n\t\tedx.split.reserved = 0;\n\n\t\tentry->eax = eax.full;\n\t\tentry->ebx = cap.events_mask;\n\t\tentry->ecx = 0;\n\t\tentry->edx = edx.full;\n\t\tbreak;\n\t}\n\t/*\n\t * Per Intel's SDM, the 0x1f is a superset of 0xb,\n\t * thus they can be handled by common code.\n\t */\n\tcase 0x1f:\n\tcase 0xb:\n\t\t/*\n\t\t * Populate entries until the level type (ECX[15:8]) of the\n\t\t * previous entry is zero.  Note, CPUID EAX.{0x1f,0xb}.0 is\n\t\t * the starting entry, filled by the primary do_host_cpuid().\n\t\t */\n\t\tfor (i = 1; entry->ecx & 0xff00; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 0xd:\n\t\tentry->eax &= supported_xcr0;\n\t\tentry->ebx = xstate_required_size(supported_xcr0, false);\n\t\tentry->ecx = entry->ebx;\n\t\tentry->edx &= supported_xcr0 >> 32;\n\t\tif (!supported_xcr0)\n\t\t\tbreak;\n\n\t\tentry = do_host_cpuid(array, function, 1);\n\t\tif (!entry)\n\t\t\tgoto out;\n\n\t\tcpuid_entry_override(entry, CPUID_D_1_EAX);\n\t\tif (entry->eax & (F(XSAVES)|F(XSAVEC)))\n\t\t\tentry->ebx = xstate_required_size(supported_xcr0 | supported_xss,\n\t\t\t\t\t\t\t  true);\n\t\telse {\n\t\t\tWARN_ON_ONCE(supported_xss != 0);\n\t\t\tentry->ebx = 0;\n\t\t}\n\t\tentry->ecx &= supported_xss;\n\t\tentry->edx &= supported_xss >> 32;\n\n\t\tfor (i = 2; i < 64; ++i) {\n\t\t\tbool s_state;\n\t\t\tif (supported_xcr0 & BIT_ULL(i))\n\t\t\t\ts_state = false;\n\t\t\telse if (supported_xss & BIT_ULL(i))\n\t\t\t\ts_state = true;\n\t\t\telse\n\t\t\t\tcontinue;\n\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\t/*\n\t\t\t * The supported check above should have filtered out\n\t\t\t * invalid sub-leafs.  Only valid sub-leafs should\n\t\t\t * reach this point, and they should have a non-zero\n\t\t\t * save state size.  Furthermore, check whether the\n\t\t\t * processor agrees with supported_xcr0/supported_xss\n\t\t\t * on whether this is an XCR0- or IA32_XSS-managed area.\n\t\t\t */\n\t\t\tif (WARN_ON_ONCE(!entry->eax || (entry->ecx & 0x1) != s_state)) {\n\t\t\t\t--array->nent;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\t/* Intel PT */\n\tcase 0x14:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_INTEL_PT)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 1, max_idx = entry->eax; i <= max_idx; ++i) {\n\t\t\tif (!do_host_cpuid(array, function, i))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase KVM_CPUID_SIGNATURE: {\n\t\tstatic const char signature[12] = \"KVMKVMKVM\\0\\0\";\n\t\tconst u32 *sigptr = (const u32 *)signature;\n\t\tentry->eax = KVM_CPUID_FEATURES;\n\t\tentry->ebx = sigptr[0];\n\t\tentry->ecx = sigptr[1];\n\t\tentry->edx = sigptr[2];\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_FEATURES:\n\t\tentry->eax = (1 << KVM_FEATURE_CLOCKSOURCE) |\n\t\t\t     (1 << KVM_FEATURE_NOP_IO_DELAY) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE2) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF) |\n\t\t\t     (1 << KVM_FEATURE_PV_EOI) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE_STABLE_BIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_UNHALT) |\n\t\t\t     (1 << KVM_FEATURE_PV_TLB_FLUSH) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF_VMEXIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_SEND_IPI) |\n\t\t\t     (1 << KVM_FEATURE_POLL_CONTROL) |\n\t\t\t     (1 << KVM_FEATURE_PV_SCHED_YIELD);\n\n\t\tif (sched_info_on())\n\t\t\tentry->eax |= (1 << KVM_FEATURE_STEAL_TIME);\n\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\tcase 0x80000000:\n\t\tentry->eax = min(entry->eax, 0x8000001f);\n\t\tbreak;\n\tcase 0x80000001:\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_EDX);\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_ECX);\n\t\tbreak;\n\tcase 0x80000007: /* Advanced power management */\n\t\t/* invariant TSC is CPUID.80000007H:EDX[8] */\n\t\tentry->edx &= (1 << 8);\n\t\t/* mask against host */\n\t\tentry->edx &= boot_cpu_data.x86_power;\n\t\tentry->eax = entry->ebx = entry->ecx = 0;\n\t\tbreak;\n\tcase 0x80000008: {\n\t\tunsigned g_phys_as = (entry->eax >> 16) & 0xff;\n\t\tunsigned virt_as = max((entry->eax >> 8) & 0xff, 48U);\n\t\tunsigned phys_as = entry->eax & 0xff;\n\n\t\tif (!g_phys_as)\n\t\t\tg_phys_as = phys_as;\n\t\tentry->eax = g_phys_as | (virt_as << 8);\n\t\tentry->edx = 0;\n\t\tcpuid_entry_override(entry, CPUID_8000_0008_EBX);\n\t\tbreak;\n\t}\n\tcase 0x8000000A:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_SVM)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\t\tentry->eax = 1; /* SVM revision 1 */\n\t\tentry->ebx = 8; /* Lets support 8 ASIDs in case we add proper\n\t\t\t\t   ASID emulation to nested SVM */\n\t\tentry->ecx = 0; /* Reserved */\n\t\tcpuid_entry_override(entry, CPUID_8000_000A_EDX);\n\t\tbreak;\n\tcase 0x80000019:\n\t\tentry->ecx = entry->edx = 0;\n\t\tbreak;\n\tcase 0x8000001a:\n\tcase 0x8000001e:\n\t\tbreak;\n\t/* Support memory encryption cpuid if host supports it */\n\tcase 0x8000001F:\n\t\tif (!boot_cpu_has(X86_FEATURE_SEV))\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t/*Add support for Centaur's CPUID instruction*/\n\tcase 0xC0000000:\n\t\t/*Just support up to 0xC0000004 now*/\n\t\tentry->eax = min(entry->eax, 0xC0000004);\n\t\tbreak;\n\tcase 0xC0000001:\n\t\tcpuid_entry_override(entry, CPUID_C000_0001_EDX);\n\t\tbreak;\n\tcase 3: /* Processor serial number */\n\tcase 5: /* MONITOR/MWAIT */\n\tcase 0xC0000002:\n\tcase 0xC0000003:\n\tcase 0xC0000004:\n\tdefault:\n\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t}\n\n\tr = 0;\n\nout:\n\tput_cpu();\n\n\treturn r;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__do_cpuid_func_emulated",
          "args": [
            "array",
            "func"
          ],
          "line": 802
        },
        "resolved": true,
        "details": {
          "function_name": "__do_cpuid_func_emulated",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "471-502",
          "snippet": "static int __do_cpuid_func_emulated(struct kvm_cpuid_array *array, u32 func)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn -E2BIG;\n\n\tentry = &array->entries[array->nent];\n\tentry->function = func;\n\tentry->index = 0;\n\tentry->flags = 0;\n\n\tswitch (func) {\n\tcase 0:\n\t\tentry->eax = 7;\n\t\t++array->nent;\n\t\tbreak;\n\tcase 1:\n\t\tentry->ecx = F(MOVBE);\n\t\t++array->nent;\n\t\tbreak;\n\tcase 7:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tentry->eax = 0;\n\t\tentry->ecx = F(RDPID);\n\t\t++array->nent;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define F feature_bit"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nstatic int __do_cpuid_func_emulated(struct kvm_cpuid_array *array, u32 func)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn -E2BIG;\n\n\tentry = &array->entries[array->nent];\n\tentry->function = func;\n\tentry->index = 0;\n\tentry->flags = 0;\n\n\tswitch (func) {\n\tcase 0:\n\t\tentry->eax = 7;\n\t\t++array->nent;\n\t\tbreak;\n\tcase 1:\n\t\tentry->ecx = F(MOVBE);\n\t\t++array->nent;\n\t\tbreak;\n\tcase 7:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tentry->eax = 0;\n\t\tentry->ecx = F(RDPID);\n\t\t++array->nent;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic int do_cpuid_func(struct kvm_cpuid_array *array, u32 func,\n\t\t\t unsigned int type)\n{\n\tif (type == KVM_GET_EMULATED_CPUID)\n\t\treturn __do_cpuid_func_emulated(array, func);\n\n\treturn __do_cpuid_func(array, func);\n}"
  },
  {
    "function_name": "__do_cpuid_func",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "504-796",
    "snippet": "static inline int __do_cpuid_func(struct kvm_cpuid_array *array, u32 function)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\tint r, i, max_idx;\n\n\t/* all calls to cpuid_count() should be made on the same cpu */\n\tget_cpu();\n\n\tr = -E2BIG;\n\n\tentry = do_host_cpuid(array, function, 0);\n\tif (!entry)\n\t\tgoto out;\n\n\tswitch (function) {\n\tcase 0:\n\t\t/* Limited to the highest leaf implemented in KVM. */\n\t\tentry->eax = min(entry->eax, 0x1fU);\n\t\tbreak;\n\tcase 1:\n\t\tcpuid_entry_override(entry, CPUID_1_EDX);\n\t\tcpuid_entry_override(entry, CPUID_1_ECX);\n\t\tbreak;\n\tcase 2:\n\t\t/*\n\t\t * On ancient CPUs, function 2 entries are STATEFUL.  That is,\n\t\t * CPUID(function=2, index=0) may return different results each\n\t\t * time, with the least-significant byte in EAX enumerating the\n\t\t * number of times software should do CPUID(2, 0).\n\t\t *\n\t\t * Modern CPUs, i.e. every CPU KVM has *ever* run on are less\n\t\t * idiotic.  Intel's SDM states that EAX & 0xff \"will always\n\t\t * return 01H. Software should ignore this value and not\n\t\t * interpret it as an informational descriptor\", while AMD's\n\t\t * APM states that CPUID(2) is reserved.\n\t\t *\n\t\t * WARN if a frankenstein CPU that supports virtualization and\n\t\t * a stateful CPUID.0x2 is encountered.\n\t\t */\n\t\tWARN_ON_ONCE((entry->eax & 0xff) > 1);\n\t\tbreak;\n\t/* functions 4 and 0x8000001d have additional index. */\n\tcase 4:\n\tcase 0x8000001d:\n\t\t/*\n\t\t * Read entries until the cache type in the previous entry is\n\t\t * zero, i.e. indicates an invalid entry.\n\t\t */\n\t\tfor (i = 1; entry->eax & 0x1f; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 6: /* Thermal management */\n\t\tentry->eax = 0x4; /* allow ARAT */\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\t/* function 7 has additional index. */\n\tcase 7:\n\t\tentry->eax = min(entry->eax, 1u);\n\t\tcpuid_entry_override(entry, CPUID_7_0_EBX);\n\t\tcpuid_entry_override(entry, CPUID_7_ECX);\n\t\tcpuid_entry_override(entry, CPUID_7_EDX);\n\n\t\t/* KVM only supports 0x7.0 and 0x7.1, capped above via min(). */\n\t\tif (entry->eax == 1) {\n\t\t\tentry = do_host_cpuid(array, function, 1);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\tcpuid_entry_override(entry, CPUID_7_1_EAX);\n\t\t\tentry->ebx = 0;\n\t\t\tentry->ecx = 0;\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\tcase 9:\n\t\tbreak;\n\tcase 0xa: { /* Architectural Performance Monitoring */\n\t\tstruct x86_pmu_capability cap;\n\t\tunion cpuid10_eax eax;\n\t\tunion cpuid10_edx edx;\n\n\t\tperf_get_x86_pmu_capability(&cap);\n\n\t\t/*\n\t\t * Only support guest architectural pmu on a host\n\t\t * with architectural pmu.\n\t\t */\n\t\tif (!cap.version)\n\t\t\tmemset(&cap, 0, sizeof(cap));\n\n\t\teax.split.version_id = min(cap.version, 2);\n\t\teax.split.num_counters = cap.num_counters_gp;\n\t\teax.split.bit_width = cap.bit_width_gp;\n\t\teax.split.mask_length = cap.events_mask_len;\n\n\t\tedx.split.num_counters_fixed = cap.num_counters_fixed;\n\t\tedx.split.bit_width_fixed = cap.bit_width_fixed;\n\t\tedx.split.reserved = 0;\n\n\t\tentry->eax = eax.full;\n\t\tentry->ebx = cap.events_mask;\n\t\tentry->ecx = 0;\n\t\tentry->edx = edx.full;\n\t\tbreak;\n\t}\n\t/*\n\t * Per Intel's SDM, the 0x1f is a superset of 0xb,\n\t * thus they can be handled by common code.\n\t */\n\tcase 0x1f:\n\tcase 0xb:\n\t\t/*\n\t\t * Populate entries until the level type (ECX[15:8]) of the\n\t\t * previous entry is zero.  Note, CPUID EAX.{0x1f,0xb}.0 is\n\t\t * the starting entry, filled by the primary do_host_cpuid().\n\t\t */\n\t\tfor (i = 1; entry->ecx & 0xff00; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 0xd:\n\t\tentry->eax &= supported_xcr0;\n\t\tentry->ebx = xstate_required_size(supported_xcr0, false);\n\t\tentry->ecx = entry->ebx;\n\t\tentry->edx &= supported_xcr0 >> 32;\n\t\tif (!supported_xcr0)\n\t\t\tbreak;\n\n\t\tentry = do_host_cpuid(array, function, 1);\n\t\tif (!entry)\n\t\t\tgoto out;\n\n\t\tcpuid_entry_override(entry, CPUID_D_1_EAX);\n\t\tif (entry->eax & (F(XSAVES)|F(XSAVEC)))\n\t\t\tentry->ebx = xstate_required_size(supported_xcr0 | supported_xss,\n\t\t\t\t\t\t\t  true);\n\t\telse {\n\t\t\tWARN_ON_ONCE(supported_xss != 0);\n\t\t\tentry->ebx = 0;\n\t\t}\n\t\tentry->ecx &= supported_xss;\n\t\tentry->edx &= supported_xss >> 32;\n\n\t\tfor (i = 2; i < 64; ++i) {\n\t\t\tbool s_state;\n\t\t\tif (supported_xcr0 & BIT_ULL(i))\n\t\t\t\ts_state = false;\n\t\t\telse if (supported_xss & BIT_ULL(i))\n\t\t\t\ts_state = true;\n\t\t\telse\n\t\t\t\tcontinue;\n\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\t/*\n\t\t\t * The supported check above should have filtered out\n\t\t\t * invalid sub-leafs.  Only valid sub-leafs should\n\t\t\t * reach this point, and they should have a non-zero\n\t\t\t * save state size.  Furthermore, check whether the\n\t\t\t * processor agrees with supported_xcr0/supported_xss\n\t\t\t * on whether this is an XCR0- or IA32_XSS-managed area.\n\t\t\t */\n\t\t\tif (WARN_ON_ONCE(!entry->eax || (entry->ecx & 0x1) != s_state)) {\n\t\t\t\t--array->nent;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\t/* Intel PT */\n\tcase 0x14:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_INTEL_PT)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 1, max_idx = entry->eax; i <= max_idx; ++i) {\n\t\t\tif (!do_host_cpuid(array, function, i))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase KVM_CPUID_SIGNATURE: {\n\t\tstatic const char signature[12] = \"KVMKVMKVM\\0\\0\";\n\t\tconst u32 *sigptr = (const u32 *)signature;\n\t\tentry->eax = KVM_CPUID_FEATURES;\n\t\tentry->ebx = sigptr[0];\n\t\tentry->ecx = sigptr[1];\n\t\tentry->edx = sigptr[2];\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_FEATURES:\n\t\tentry->eax = (1 << KVM_FEATURE_CLOCKSOURCE) |\n\t\t\t     (1 << KVM_FEATURE_NOP_IO_DELAY) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE2) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF) |\n\t\t\t     (1 << KVM_FEATURE_PV_EOI) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE_STABLE_BIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_UNHALT) |\n\t\t\t     (1 << KVM_FEATURE_PV_TLB_FLUSH) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF_VMEXIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_SEND_IPI) |\n\t\t\t     (1 << KVM_FEATURE_POLL_CONTROL) |\n\t\t\t     (1 << KVM_FEATURE_PV_SCHED_YIELD);\n\n\t\tif (sched_info_on())\n\t\t\tentry->eax |= (1 << KVM_FEATURE_STEAL_TIME);\n\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\tcase 0x80000000:\n\t\tentry->eax = min(entry->eax, 0x8000001f);\n\t\tbreak;\n\tcase 0x80000001:\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_EDX);\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_ECX);\n\t\tbreak;\n\tcase 0x80000007: /* Advanced power management */\n\t\t/* invariant TSC is CPUID.80000007H:EDX[8] */\n\t\tentry->edx &= (1 << 8);\n\t\t/* mask against host */\n\t\tentry->edx &= boot_cpu_data.x86_power;\n\t\tentry->eax = entry->ebx = entry->ecx = 0;\n\t\tbreak;\n\tcase 0x80000008: {\n\t\tunsigned g_phys_as = (entry->eax >> 16) & 0xff;\n\t\tunsigned virt_as = max((entry->eax >> 8) & 0xff, 48U);\n\t\tunsigned phys_as = entry->eax & 0xff;\n\n\t\tif (!g_phys_as)\n\t\t\tg_phys_as = phys_as;\n\t\tentry->eax = g_phys_as | (virt_as << 8);\n\t\tentry->edx = 0;\n\t\tcpuid_entry_override(entry, CPUID_8000_0008_EBX);\n\t\tbreak;\n\t}\n\tcase 0x8000000A:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_SVM)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\t\tentry->eax = 1; /* SVM revision 1 */\n\t\tentry->ebx = 8; /* Lets support 8 ASIDs in case we add proper\n\t\t\t\t   ASID emulation to nested SVM */\n\t\tentry->ecx = 0; /* Reserved */\n\t\tcpuid_entry_override(entry, CPUID_8000_000A_EDX);\n\t\tbreak;\n\tcase 0x80000019:\n\t\tentry->ecx = entry->edx = 0;\n\t\tbreak;\n\tcase 0x8000001a:\n\tcase 0x8000001e:\n\t\tbreak;\n\t/* Support memory encryption cpuid if host supports it */\n\tcase 0x8000001F:\n\t\tif (!boot_cpu_has(X86_FEATURE_SEV))\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t/*Add support for Centaur's CPUID instruction*/\n\tcase 0xC0000000:\n\t\t/*Just support up to 0xC0000004 now*/\n\t\tentry->eax = min(entry->eax, 0xC0000004);\n\t\tbreak;\n\tcase 0xC0000001:\n\t\tcpuid_entry_override(entry, CPUID_C000_0001_EDX);\n\t\tbreak;\n\tcase 3: /* Processor serial number */\n\tcase 5: /* MONITOR/MWAIT */\n\tcase 0xC0000002:\n\tcase 0xC0000003:\n\tcase 0xC0000004:\n\tdefault:\n\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t}\n\n\tr = 0;\n\nout:\n\tput_cpu();\n\n\treturn r;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define F feature_bit"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_cpu",
          "args": [],
          "line": 793
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpuid_entry_override",
          "args": [
            "entry",
            "CPUID_C000_0001_EDX"
          ],
          "line": 778
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_entry_override",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "173-180",
          "snippet": "static __always_inline void cpuid_entry_override(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t\t enum cpuid_leafs leaf)\n{\n\tu32 *reg = cpuid_entry_get_reg(entry, leaf * 32);\n\n\tBUILD_BUG_ON(leaf >= ARRAY_SIZE(kvm_cpu_caps));\n\t*reg = kvm_cpu_caps[leaf];\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline void cpuid_entry_override(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t\t enum cpuid_leafs leaf)\n{\n\tu32 *reg = cpuid_entry_get_reg(entry, leaf * 32);\n\n\tBUILD_BUG_ON(leaf >= ARRAY_SIZE(kvm_cpu_caps));\n\t*reg = kvm_cpu_caps[leaf];\n}"
        }
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "entry->eax",
            "0xC0000004"
          ],
          "line": 775
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_SEV"
          ],
          "line": 769
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_cpu_cap_has",
          "args": [
            "X86_FEATURE_SVM"
          ],
          "line": 751
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_cpu_cap_has",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "295-298",
          "snippet": "static __always_inline bool kvm_cpu_cap_has(unsigned int x86_feature)\n{\n\treturn !!kvm_cpu_cap_get(x86_feature);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline bool kvm_cpu_cap_has(unsigned int x86_feature)\n{\n\treturn !!kvm_cpu_cap_get(x86_feature);\n}"
        }
      },
      {
        "call_info": {
          "callee": "max",
          "args": [
            "(entry->eax >> 8) & 0xff",
            "48U"
          ],
          "line": 740
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "entry->eax",
            "0x8000001f"
          ],
          "line": 725
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_info_on",
          "args": [],
          "line": 717
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "do_host_cpuid",
          "args": [
            "array",
            "function",
            "i"
          ],
          "line": 690
        },
        "resolved": true,
        "details": {
          "function_name": "do_host_cpuid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "434-469",
          "snippet": "static struct kvm_cpuid_entry2 *do_host_cpuid(struct kvm_cpuid_array *array,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn NULL;\n\n\tentry = &array->entries[array->nent++];\n\n\tentry->function = function;\n\tentry->index = index;\n\tentry->flags = 0;\n\n\tcpuid_count(entry->function, entry->index,\n\t\t    &entry->eax, &entry->ebx, &entry->ecx, &entry->edx);\n\n\tswitch (function) {\n\tcase 4:\n\tcase 7:\n\tcase 0xb:\n\tcase 0xd:\n\tcase 0xf:\n\tcase 0x10:\n\tcase 0x12:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x18:\n\tcase 0x1f:\n\tcase 0x8000001d:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tbreak;\n\t}\n\n\treturn entry;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic struct kvm_cpuid_entry2 *do_host_cpuid(struct kvm_cpuid_array *array,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn NULL;\n\n\tentry = &array->entries[array->nent++];\n\n\tentry->function = function;\n\tentry->index = index;\n\tentry->flags = 0;\n\n\tcpuid_count(entry->function, entry->index,\n\t\t    &entry->eax, &entry->ebx, &entry->ecx, &entry->edx);\n\n\tswitch (function) {\n\tcase 4:\n\tcase 7:\n\tcase 0xb:\n\tcase 0xd:\n\tcase 0xf:\n\tcase 0x10:\n\tcase 0x12:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x18:\n\tcase 0x1f:\n\tcase 0x8000001d:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tbreak;\n\t}\n\n\treturn entry;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!entry->eax || (entry->ecx & 0x1) != s_state"
          ],
          "line": 675
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BIT_ULL",
          "args": [
            "i"
          ],
          "line": 658
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BIT_ULL",
          "args": [
            "i"
          ],
          "line": 656
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "supported_xss != 0"
          ],
          "line": 648
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xstate_required_size",
          "args": [
            "supported_xcr0 | supported_xss",
            "true"
          ],
          "line": 645
        },
        "resolved": true,
        "details": {
          "function_name": "xstate_required_size",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "34-53",
          "snippet": "static u32 xstate_required_size(u64 xstate_bv, bool compacted)\n{\n\tint feature_bit = 0;\n\tu32 ret = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\n\txstate_bv &= XFEATURE_MASK_EXTEND;\n\twhile (xstate_bv) {\n\t\tif (xstate_bv & 0x1) {\n\t\t        u32 eax, ebx, ecx, edx, offset;\n\t\t        cpuid_count(0xD, feature_bit, &eax, &ebx, &ecx, &edx);\n\t\t\toffset = compacted ? ret : ebx;\n\t\t\tret = max(ret, offset + eax);\n\t\t}\n\n\t\txstate_bv >>= 1;\n\t\tfeature_bit++;\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic u32 xstate_required_size(u64 xstate_bv, bool compacted)\n{\n\tint feature_bit = 0;\n\tu32 ret = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\n\txstate_bv &= XFEATURE_MASK_EXTEND;\n\twhile (xstate_bv) {\n\t\tif (xstate_bv & 0x1) {\n\t\t        u32 eax, ebx, ecx, edx, offset;\n\t\t        cpuid_count(0xD, feature_bit, &eax, &ebx, &ecx, &edx);\n\t\t\toffset = compacted ? ret : ebx;\n\t\t\tret = max(ret, offset + eax);\n\t\t}\n\n\t\txstate_bv >>= 1;\n\t\tfeature_bit++;\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "F",
          "args": [
            "XSAVEC"
          ],
          "line": 644
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "883-893",
          "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
          "includes": [],
          "macros_used": [
            "#define pt_element_t u64",
            "#define pt_element_t u32",
            "#define pt_element_t u64"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "cap.version",
            "2"
          ],
          "line": 599
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "&cap",
            "0",
            "sizeof(cap)"
          ],
          "line": 597
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "perf_get_x86_pmu_capability",
          "args": [
            "&cap"
          ],
          "line": 590
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "entry->eax",
            "1u"
          ],
          "line": 566
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "(entry->eax & 0xff) > 1"
          ],
          "line": 543
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "entry->eax",
            "0x1fU"
          ],
          "line": 521
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_cpu",
          "args": [],
          "line": 510
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nstatic inline int __do_cpuid_func(struct kvm_cpuid_array *array, u32 function)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\tint r, i, max_idx;\n\n\t/* all calls to cpuid_count() should be made on the same cpu */\n\tget_cpu();\n\n\tr = -E2BIG;\n\n\tentry = do_host_cpuid(array, function, 0);\n\tif (!entry)\n\t\tgoto out;\n\n\tswitch (function) {\n\tcase 0:\n\t\t/* Limited to the highest leaf implemented in KVM. */\n\t\tentry->eax = min(entry->eax, 0x1fU);\n\t\tbreak;\n\tcase 1:\n\t\tcpuid_entry_override(entry, CPUID_1_EDX);\n\t\tcpuid_entry_override(entry, CPUID_1_ECX);\n\t\tbreak;\n\tcase 2:\n\t\t/*\n\t\t * On ancient CPUs, function 2 entries are STATEFUL.  That is,\n\t\t * CPUID(function=2, index=0) may return different results each\n\t\t * time, with the least-significant byte in EAX enumerating the\n\t\t * number of times software should do CPUID(2, 0).\n\t\t *\n\t\t * Modern CPUs, i.e. every CPU KVM has *ever* run on are less\n\t\t * idiotic.  Intel's SDM states that EAX & 0xff \"will always\n\t\t * return 01H. Software should ignore this value and not\n\t\t * interpret it as an informational descriptor\", while AMD's\n\t\t * APM states that CPUID(2) is reserved.\n\t\t *\n\t\t * WARN if a frankenstein CPU that supports virtualization and\n\t\t * a stateful CPUID.0x2 is encountered.\n\t\t */\n\t\tWARN_ON_ONCE((entry->eax & 0xff) > 1);\n\t\tbreak;\n\t/* functions 4 and 0x8000001d have additional index. */\n\tcase 4:\n\tcase 0x8000001d:\n\t\t/*\n\t\t * Read entries until the cache type in the previous entry is\n\t\t * zero, i.e. indicates an invalid entry.\n\t\t */\n\t\tfor (i = 1; entry->eax & 0x1f; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 6: /* Thermal management */\n\t\tentry->eax = 0x4; /* allow ARAT */\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\t/* function 7 has additional index. */\n\tcase 7:\n\t\tentry->eax = min(entry->eax, 1u);\n\t\tcpuid_entry_override(entry, CPUID_7_0_EBX);\n\t\tcpuid_entry_override(entry, CPUID_7_ECX);\n\t\tcpuid_entry_override(entry, CPUID_7_EDX);\n\n\t\t/* KVM only supports 0x7.0 and 0x7.1, capped above via min(). */\n\t\tif (entry->eax == 1) {\n\t\t\tentry = do_host_cpuid(array, function, 1);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\tcpuid_entry_override(entry, CPUID_7_1_EAX);\n\t\t\tentry->ebx = 0;\n\t\t\tentry->ecx = 0;\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\tcase 9:\n\t\tbreak;\n\tcase 0xa: { /* Architectural Performance Monitoring */\n\t\tstruct x86_pmu_capability cap;\n\t\tunion cpuid10_eax eax;\n\t\tunion cpuid10_edx edx;\n\n\t\tperf_get_x86_pmu_capability(&cap);\n\n\t\t/*\n\t\t * Only support guest architectural pmu on a host\n\t\t * with architectural pmu.\n\t\t */\n\t\tif (!cap.version)\n\t\t\tmemset(&cap, 0, sizeof(cap));\n\n\t\teax.split.version_id = min(cap.version, 2);\n\t\teax.split.num_counters = cap.num_counters_gp;\n\t\teax.split.bit_width = cap.bit_width_gp;\n\t\teax.split.mask_length = cap.events_mask_len;\n\n\t\tedx.split.num_counters_fixed = cap.num_counters_fixed;\n\t\tedx.split.bit_width_fixed = cap.bit_width_fixed;\n\t\tedx.split.reserved = 0;\n\n\t\tentry->eax = eax.full;\n\t\tentry->ebx = cap.events_mask;\n\t\tentry->ecx = 0;\n\t\tentry->edx = edx.full;\n\t\tbreak;\n\t}\n\t/*\n\t * Per Intel's SDM, the 0x1f is a superset of 0xb,\n\t * thus they can be handled by common code.\n\t */\n\tcase 0x1f:\n\tcase 0xb:\n\t\t/*\n\t\t * Populate entries until the level type (ECX[15:8]) of the\n\t\t * previous entry is zero.  Note, CPUID EAX.{0x1f,0xb}.0 is\n\t\t * the starting entry, filled by the primary do_host_cpuid().\n\t\t */\n\t\tfor (i = 1; entry->ecx & 0xff00; ++i) {\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase 0xd:\n\t\tentry->eax &= supported_xcr0;\n\t\tentry->ebx = xstate_required_size(supported_xcr0, false);\n\t\tentry->ecx = entry->ebx;\n\t\tentry->edx &= supported_xcr0 >> 32;\n\t\tif (!supported_xcr0)\n\t\t\tbreak;\n\n\t\tentry = do_host_cpuid(array, function, 1);\n\t\tif (!entry)\n\t\t\tgoto out;\n\n\t\tcpuid_entry_override(entry, CPUID_D_1_EAX);\n\t\tif (entry->eax & (F(XSAVES)|F(XSAVEC)))\n\t\t\tentry->ebx = xstate_required_size(supported_xcr0 | supported_xss,\n\t\t\t\t\t\t\t  true);\n\t\telse {\n\t\t\tWARN_ON_ONCE(supported_xss != 0);\n\t\t\tentry->ebx = 0;\n\t\t}\n\t\tentry->ecx &= supported_xss;\n\t\tentry->edx &= supported_xss >> 32;\n\n\t\tfor (i = 2; i < 64; ++i) {\n\t\t\tbool s_state;\n\t\t\tif (supported_xcr0 & BIT_ULL(i))\n\t\t\t\ts_state = false;\n\t\t\telse if (supported_xss & BIT_ULL(i))\n\t\t\t\ts_state = true;\n\t\t\telse\n\t\t\t\tcontinue;\n\n\t\t\tentry = do_host_cpuid(array, function, i);\n\t\t\tif (!entry)\n\t\t\t\tgoto out;\n\n\t\t\t/*\n\t\t\t * The supported check above should have filtered out\n\t\t\t * invalid sub-leafs.  Only valid sub-leafs should\n\t\t\t * reach this point, and they should have a non-zero\n\t\t\t * save state size.  Furthermore, check whether the\n\t\t\t * processor agrees with supported_xcr0/supported_xss\n\t\t\t * on whether this is an XCR0- or IA32_XSS-managed area.\n\t\t\t */\n\t\t\tif (WARN_ON_ONCE(!entry->eax || (entry->ecx & 0x1) != s_state)) {\n\t\t\t\t--array->nent;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tentry->edx = 0;\n\t\t}\n\t\tbreak;\n\t/* Intel PT */\n\tcase 0x14:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_INTEL_PT)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (i = 1, max_idx = entry->eax; i <= max_idx; ++i) {\n\t\t\tif (!do_host_cpuid(array, function, i))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase KVM_CPUID_SIGNATURE: {\n\t\tstatic const char signature[12] = \"KVMKVMKVM\\0\\0\";\n\t\tconst u32 *sigptr = (const u32 *)signature;\n\t\tentry->eax = KVM_CPUID_FEATURES;\n\t\tentry->ebx = sigptr[0];\n\t\tentry->ecx = sigptr[1];\n\t\tentry->edx = sigptr[2];\n\t\tbreak;\n\t}\n\tcase KVM_CPUID_FEATURES:\n\t\tentry->eax = (1 << KVM_FEATURE_CLOCKSOURCE) |\n\t\t\t     (1 << KVM_FEATURE_NOP_IO_DELAY) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE2) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF) |\n\t\t\t     (1 << KVM_FEATURE_PV_EOI) |\n\t\t\t     (1 << KVM_FEATURE_CLOCKSOURCE_STABLE_BIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_UNHALT) |\n\t\t\t     (1 << KVM_FEATURE_PV_TLB_FLUSH) |\n\t\t\t     (1 << KVM_FEATURE_ASYNC_PF_VMEXIT) |\n\t\t\t     (1 << KVM_FEATURE_PV_SEND_IPI) |\n\t\t\t     (1 << KVM_FEATURE_POLL_CONTROL) |\n\t\t\t     (1 << KVM_FEATURE_PV_SCHED_YIELD);\n\n\t\tif (sched_info_on())\n\t\t\tentry->eax |= (1 << KVM_FEATURE_STEAL_TIME);\n\n\t\tentry->ebx = 0;\n\t\tentry->ecx = 0;\n\t\tentry->edx = 0;\n\t\tbreak;\n\tcase 0x80000000:\n\t\tentry->eax = min(entry->eax, 0x8000001f);\n\t\tbreak;\n\tcase 0x80000001:\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_EDX);\n\t\tcpuid_entry_override(entry, CPUID_8000_0001_ECX);\n\t\tbreak;\n\tcase 0x80000007: /* Advanced power management */\n\t\t/* invariant TSC is CPUID.80000007H:EDX[8] */\n\t\tentry->edx &= (1 << 8);\n\t\t/* mask against host */\n\t\tentry->edx &= boot_cpu_data.x86_power;\n\t\tentry->eax = entry->ebx = entry->ecx = 0;\n\t\tbreak;\n\tcase 0x80000008: {\n\t\tunsigned g_phys_as = (entry->eax >> 16) & 0xff;\n\t\tunsigned virt_as = max((entry->eax >> 8) & 0xff, 48U);\n\t\tunsigned phys_as = entry->eax & 0xff;\n\n\t\tif (!g_phys_as)\n\t\t\tg_phys_as = phys_as;\n\t\tentry->eax = g_phys_as | (virt_as << 8);\n\t\tentry->edx = 0;\n\t\tcpuid_entry_override(entry, CPUID_8000_0008_EBX);\n\t\tbreak;\n\t}\n\tcase 0x8000000A:\n\t\tif (!kvm_cpu_cap_has(X86_FEATURE_SVM)) {\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\t\tbreak;\n\t\t}\n\t\tentry->eax = 1; /* SVM revision 1 */\n\t\tentry->ebx = 8; /* Lets support 8 ASIDs in case we add proper\n\t\t\t\t   ASID emulation to nested SVM */\n\t\tentry->ecx = 0; /* Reserved */\n\t\tcpuid_entry_override(entry, CPUID_8000_000A_EDX);\n\t\tbreak;\n\tcase 0x80000019:\n\t\tentry->ecx = entry->edx = 0;\n\t\tbreak;\n\tcase 0x8000001a:\n\tcase 0x8000001e:\n\t\tbreak;\n\t/* Support memory encryption cpuid if host supports it */\n\tcase 0x8000001F:\n\t\tif (!boot_cpu_has(X86_FEATURE_SEV))\n\t\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t/*Add support for Centaur's CPUID instruction*/\n\tcase 0xC0000000:\n\t\t/*Just support up to 0xC0000004 now*/\n\t\tentry->eax = min(entry->eax, 0xC0000004);\n\t\tbreak;\n\tcase 0xC0000001:\n\t\tcpuid_entry_override(entry, CPUID_C000_0001_EDX);\n\t\tbreak;\n\tcase 3: /* Processor serial number */\n\tcase 5: /* MONITOR/MWAIT */\n\tcase 0xC0000002:\n\tcase 0xC0000003:\n\tcase 0xC0000004:\n\tdefault:\n\t\tentry->eax = entry->ebx = entry->ecx = entry->edx = 0;\n\t\tbreak;\n\t}\n\n\tr = 0;\n\nout:\n\tput_cpu();\n\n\treturn r;\n}"
  },
  {
    "function_name": "__do_cpuid_func_emulated",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "471-502",
    "snippet": "static int __do_cpuid_func_emulated(struct kvm_cpuid_array *array, u32 func)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn -E2BIG;\n\n\tentry = &array->entries[array->nent];\n\tentry->function = func;\n\tentry->index = 0;\n\tentry->flags = 0;\n\n\tswitch (func) {\n\tcase 0:\n\t\tentry->eax = 7;\n\t\t++array->nent;\n\t\tbreak;\n\tcase 1:\n\t\tentry->ecx = F(MOVBE);\n\t\t++array->nent;\n\t\tbreak;\n\tcase 7:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tentry->eax = 0;\n\t\tentry->ecx = F(RDPID);\n\t\t++array->nent;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define F feature_bit"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "F",
          "args": [
            "RDPID"
          ],
          "line": 495
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "883-893",
          "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
          "includes": [],
          "macros_used": [
            "#define pt_element_t u64",
            "#define pt_element_t u32",
            "#define pt_element_t u64"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nstatic int __do_cpuid_func_emulated(struct kvm_cpuid_array *array, u32 func)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn -E2BIG;\n\n\tentry = &array->entries[array->nent];\n\tentry->function = func;\n\tentry->index = 0;\n\tentry->flags = 0;\n\n\tswitch (func) {\n\tcase 0:\n\t\tentry->eax = 7;\n\t\t++array->nent;\n\t\tbreak;\n\tcase 1:\n\t\tentry->ecx = F(MOVBE);\n\t\t++array->nent;\n\t\tbreak;\n\tcase 7:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tentry->eax = 0;\n\t\tentry->ecx = F(RDPID);\n\t\t++array->nent;\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "do_host_cpuid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "434-469",
    "snippet": "static struct kvm_cpuid_entry2 *do_host_cpuid(struct kvm_cpuid_array *array,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn NULL;\n\n\tentry = &array->entries[array->nent++];\n\n\tentry->function = function;\n\tentry->index = index;\n\tentry->flags = 0;\n\n\tcpuid_count(entry->function, entry->index,\n\t\t    &entry->eax, &entry->ebx, &entry->ecx, &entry->edx);\n\n\tswitch (function) {\n\tcase 4:\n\tcase 7:\n\tcase 0xb:\n\tcase 0xd:\n\tcase 0xf:\n\tcase 0x10:\n\tcase 0x12:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x18:\n\tcase 0x1f:\n\tcase 0x8000001d:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tbreak;\n\t}\n\n\treturn entry;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpuid_count",
          "args": [
            "entry->function",
            "entry->index",
            "&entry->eax",
            "&entry->ebx",
            "&entry->ecx",
            "&entry->edx"
          ],
          "line": 448
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic struct kvm_cpuid_entry2 *do_host_cpuid(struct kvm_cpuid_array *array,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *entry;\n\n\tif (array->nent >= array->maxnent)\n\t\treturn NULL;\n\n\tentry = &array->entries[array->nent++];\n\n\tentry->function = function;\n\tentry->index = index;\n\tentry->flags = 0;\n\n\tcpuid_count(entry->function, entry->index,\n\t\t    &entry->eax, &entry->ebx, &entry->ecx, &entry->edx);\n\n\tswitch (function) {\n\tcase 4:\n\tcase 7:\n\tcase 0xb:\n\tcase 0xd:\n\tcase 0xf:\n\tcase 0x10:\n\tcase 0x12:\n\tcase 0x14:\n\tcase 0x17:\n\tcase 0x18:\n\tcase 0x1f:\n\tcase 0x8000001d:\n\t\tentry->flags |= KVM_CPUID_FLAG_SIGNIFCANT_INDEX;\n\t\tbreak;\n\t}\n\n\treturn entry;\n}"
  },
  {
    "function_name": "kvm_set_cpu_caps",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "275-425",
    "snippet": "void kvm_set_cpu_caps(void)\n{\n\tunsigned int f_nx = is_efer_nx() ? F(NX) : 0;\n#ifdef CONFIG_X86_64\n\tunsigned int f_gbpages = F(GBPAGES);\n\tunsigned int f_lm = F(LM);\n#else\n\tunsigned int f_gbpages = 0;\n\tunsigned int f_lm = 0;\n#endif\n\n\tBUILD_BUG_ON(sizeof(kvm_cpu_caps) >\n\t\t     sizeof(boot_cpu_data.x86_capability));\n\n\tmemcpy(&kvm_cpu_caps, &boot_cpu_data.x86_capability,\n\t       sizeof(kvm_cpu_caps));\n\n\tkvm_cpu_cap_mask(CPUID_1_ECX,\n\t\t/*\n\t\t * NOTE: MONITOR (and MWAIT) are emulated as NOP, but *not*\n\t\t * advertised to guests via CPUID!\n\t\t */\n\t\tF(XMM3) | F(PCLMULQDQ) | 0 /* DTES64, MONITOR */ |\n\t\t0 /* DS-CPL, VMX, SMX, EST */ |\n\t\t0 /* TM2 */ | F(SSSE3) | 0 /* CNXT-ID */ | 0 /* Reserved */ |\n\t\tF(FMA) | F(CX16) | 0 /* xTPR Update, PDCM */ |\n\t\tF(PCID) | 0 /* Reserved, DCA */ | F(XMM4_1) |\n\t\tF(XMM4_2) | F(X2APIC) | F(MOVBE) | F(POPCNT) |\n\t\t0 /* Reserved*/ | F(AES) | F(XSAVE) | 0 /* OSXSAVE */ | F(AVX) |\n\t\tF(F16C) | F(RDRAND)\n\t);\n\t/* KVM emulates x2apic in software irrespective of host support. */\n\tkvm_cpu_cap_set(X86_FEATURE_X2APIC);\n\n\tkvm_cpu_cap_mask(CPUID_1_EDX,\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SEP) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* PSN */ | F(CLFLUSH) |\n\t\t0 /* Reserved, DS, ACPI */ | F(MMX) |\n\t\tF(FXSR) | F(XMM) | F(XMM2) | F(SELFSNOOP) |\n\t\t0 /* HTT, TM, Reserved, PBE */\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_7_0_EBX,\n\t\tF(FSGSBASE) | F(BMI1) | F(HLE) | F(AVX2) | F(SMEP) |\n\t\tF(BMI2) | F(ERMS) | 0 /*INVPCID*/ | F(RTM) | 0 /*MPX*/ | F(RDSEED) |\n\t\tF(ADX) | F(SMAP) | F(AVX512IFMA) | F(AVX512F) | F(AVX512PF) |\n\t\tF(AVX512ER) | F(AVX512CD) | F(CLFLUSHOPT) | F(CLWB) | F(AVX512DQ) |\n\t\tF(SHA_NI) | F(AVX512BW) | F(AVX512VL) | 0 /*INTEL_PT*/\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_7_ECX,\n\t\tF(AVX512VBMI) | F(LA57) | 0 /*PKU*/ | 0 /*OSPKE*/ | F(RDPID) |\n\t\tF(AVX512_VPOPCNTDQ) | F(UMIP) | F(AVX512_VBMI2) | F(GFNI) |\n\t\tF(VAES) | F(VPCLMULQDQ) | F(AVX512_VNNI) | F(AVX512_BITALG) |\n\t\tF(CLDEMOTE) | F(MOVDIRI) | F(MOVDIR64B) | 0 /*WAITPKG*/\n\t);\n\t/* Set LA57 based on hardware capability. */\n\tif (cpuid_ecx(7) & F(LA57))\n\t\tkvm_cpu_cap_set(X86_FEATURE_LA57);\n\n\tkvm_cpu_cap_mask(CPUID_7_EDX,\n\t\tF(AVX512_4VNNIW) | F(AVX512_4FMAPS) | F(SPEC_CTRL) |\n\t\tF(SPEC_CTRL_SSBD) | F(ARCH_CAPABILITIES) | F(INTEL_STIBP) |\n\t\tF(MD_CLEAR) | F(AVX512_VP2INTERSECT) | F(FSRM)\n\t);\n\n\t/* TSC_ADJUST and ARCH_CAPABILITIES are emulated in software. */\n\tkvm_cpu_cap_set(X86_FEATURE_TSC_ADJUST);\n\tkvm_cpu_cap_set(X86_FEATURE_ARCH_CAPABILITIES);\n\n\tif (boot_cpu_has(X86_FEATURE_IBPB) && boot_cpu_has(X86_FEATURE_IBRS))\n\t\tkvm_cpu_cap_set(X86_FEATURE_SPEC_CTRL);\n\tif (boot_cpu_has(X86_FEATURE_STIBP))\n\t\tkvm_cpu_cap_set(X86_FEATURE_INTEL_STIBP);\n\tif (boot_cpu_has(X86_FEATURE_AMD_SSBD))\n\t\tkvm_cpu_cap_set(X86_FEATURE_SPEC_CTRL_SSBD);\n\n\tkvm_cpu_cap_mask(CPUID_7_1_EAX,\n\t\tF(AVX512_BF16)\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_D_1_EAX,\n\t\tF(XSAVEOPT) | F(XSAVEC) | F(XGETBV1) | F(XSAVES)\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_8000_0001_ECX,\n\t\tF(LAHF_LM) | F(CMP_LEGACY) | 0 /*SVM*/ | 0 /* ExtApicSpace */ |\n\t\tF(CR8_LEGACY) | F(ABM) | F(SSE4A) | F(MISALIGNSSE) |\n\t\tF(3DNOWPREFETCH) | F(OSVW) | 0 /* IBS */ | F(XOP) |\n\t\t0 /* SKINIT, WDT, LWP */ | F(FMA4) | F(TBM) |\n\t\tF(TOPOEXT) | F(PERFCTR_CORE)\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_8000_0001_EDX,\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SYSCALL) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* Reserved */ |\n\t\tf_nx | 0 /* Reserved */ | F(MMXEXT) | F(MMX) |\n\t\tF(FXSR) | F(FXSR_OPT) | f_gbpages | F(RDTSCP) |\n\t\t0 /* Reserved */ | f_lm | F(3DNOWEXT) | F(3DNOW)\n\t);\n\n\tif (!tdp_enabled && IS_ENABLED(CONFIG_X86_64))\n\t\tkvm_cpu_cap_set(X86_FEATURE_GBPAGES);\n\n\tkvm_cpu_cap_mask(CPUID_8000_0008_EBX,\n\t\tF(CLZERO) | F(XSAVEERPTR) |\n\t\tF(WBNOINVD) | F(AMD_IBPB) | F(AMD_IBRS) | F(AMD_SSBD) | F(VIRT_SSBD) |\n\t\tF(AMD_SSB_NO) | F(AMD_STIBP) | F(AMD_STIBP_ALWAYS_ON)\n\t);\n\n\t/*\n\t * AMD has separate bits for each SPEC_CTRL bit.\n\t * arch/x86/kernel/cpu/bugs.c is kind enough to\n\t * record that in cpufeatures so use them.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_IBPB))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_IBPB);\n\tif (boot_cpu_has(X86_FEATURE_IBRS))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_IBRS);\n\tif (boot_cpu_has(X86_FEATURE_STIBP))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_STIBP);\n\tif (boot_cpu_has(X86_FEATURE_SPEC_CTRL_SSBD))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_SSBD);\n\tif (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_SSB_NO);\n\t/*\n\t * The preference is to use SPEC CTRL MSR instead of the\n\t * VIRT_SPEC MSR.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_LS_CFG_SSBD) &&\n\t    !boot_cpu_has(X86_FEATURE_AMD_SSBD))\n\t\tkvm_cpu_cap_set(X86_FEATURE_VIRT_SSBD);\n\n\t/*\n\t * Hide all SVM features by default, SVM will set the cap bits for\n\t * features it emulates and/or exposes for L1.\n\t */\n\tkvm_cpu_cap_mask(CPUID_8000_000A_EDX, 0);\n\n\tkvm_cpu_cap_mask(CPUID_C000_0001_EDX,\n\t\tF(XSTORE) | F(XSTORE_EN) | F(XCRYPT) | F(XCRYPT_EN) |\n\t\tF(ACE2) | F(ACE2_EN) | F(PHE) | F(PHE_EN) |\n\t\tF(PMM) | F(PMM_EN)\n\t);\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [
      "#define F feature_bit"
    ],
    "globals_used": [
      "u32 kvm_cpu_caps[NCAPINTS]"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_cpu_cap_mask",
          "args": [
            "CPUID_C000_0001_EDX",
            "F(XSTORE) | F(XSTORE_EN) | F(XCRYPT) | F(XCRYPT_EN) |\n\t\tF(ACE2) | F(ACE2_EN) | F(PHE) | F(PHE_EN) |\n\t\tF(PMM) | F(PMM_EN)"
          ],
          "line": 420
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_cpu_cap_mask",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "261-273",
          "snippet": "static __always_inline void kvm_cpu_cap_mask(enum cpuid_leafs leaf, u32 mask)\n{\n\tconst struct cpuid_reg cpuid = x86_feature_cpuid(leaf * 32);\n\tstruct kvm_cpuid_entry2 entry;\n\n\treverse_cpuid_check(leaf);\n\tkvm_cpu_caps[leaf] &= mask;\n\n\tcpuid_count(cpuid.function, cpuid.index,\n\t\t    &entry.eax, &entry.ebx, &entry.ecx, &entry.edx);\n\n\tkvm_cpu_caps[leaf] &= *__cpuid_entry_get_reg(&entry, cpuid.reg);\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "u32 kvm_cpu_caps[NCAPINTS]"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nu32 kvm_cpu_caps[NCAPINTS];\n\nstatic __always_inline void kvm_cpu_cap_mask(enum cpuid_leafs leaf, u32 mask)\n{\n\tconst struct cpuid_reg cpuid = x86_feature_cpuid(leaf * 32);\n\tstruct kvm_cpuid_entry2 entry;\n\n\treverse_cpuid_check(leaf);\n\tkvm_cpu_caps[leaf] &= mask;\n\n\tcpuid_count(cpuid.function, cpuid.index,\n\t\t    &entry.eax, &entry.ebx, &entry.ecx, &entry.edx);\n\n\tkvm_cpu_caps[leaf] &= *__cpuid_entry_get_reg(&entry, cpuid.reg);\n}"
        }
      },
      {
        "call_info": {
          "callee": "F",
          "args": [
            "PMM_EN"
          ],
          "line": 423
        },
        "resolved": true,
        "details": {
          "function_name": "FNAME",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/paging_tmpl.h",
          "lines": "883-893",
          "snippet": "static gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}",
          "includes": [],
          "macros_used": [
            "#define pt_element_t u64",
            "#define pt_element_t u32",
            "#define pt_element_t u64"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#define pt_element_t u64\n#define pt_element_t u32\n#define pt_element_t u64\n\nstatic gpa_t FNAME(get_level1_sp_gpa)(struct kvm_mmu_page *sp)\n{\n\tint offset = 0;\n\n\tWARN_ON(sp->role.level != PT_PAGE_TABLE_LEVEL);\n\n\tif (PTTYPE == 32)\n\t\toffset = sp->role.quadrant << PT64_LEVEL_BITS;\n\n\treturn gfn_to_gpa(sp->gfn) + offset * sizeof(pt_element_t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_cpu_cap_set",
          "args": [
            "X86_FEATURE_VIRT_SSBD"
          ],
          "line": 412
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_cpu_cap_set",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "279-285",
          "snippet": "static __always_inline void kvm_cpu_cap_set(unsigned int x86_feature)\n{\n\tunsigned int x86_leaf = x86_feature / 32;\n\n\treverse_cpuid_check(x86_leaf);\n\tkvm_cpu_caps[x86_leaf] |= __feature_bit(x86_feature);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline void kvm_cpu_cap_set(unsigned int x86_feature)\n{\n\tunsigned int x86_leaf = x86_feature / 32;\n\n\treverse_cpuid_check(x86_leaf);\n\tkvm_cpu_caps[x86_leaf] |= __feature_bit(x86_feature);\n}"
        }
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_AMD_SSBD"
          ],
          "line": 411
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_LS_CFG_SSBD"
          ],
          "line": 410
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has_bug",
          "args": [
            "X86_BUG_SPEC_STORE_BYPASS"
          ],
          "line": 404
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_SPEC_CTRL_SSBD"
          ],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_STIBP"
          ],
          "line": 400
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_IBRS"
          ],
          "line": 398
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_IBPB"
          ],
          "line": 396
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_X86_64"
          ],
          "line": 382
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_AMD_SSBD"
          ],
          "line": 352
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_STIBP"
          ],
          "line": 350
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_IBRS"
          ],
          "line": 348
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_IBPB"
          ],
          "line": 348
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpuid_ecx",
          "args": [
            "7"
          ],
          "line": 335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "&kvm_cpu_caps",
            "&boot_cpu_data.x86_capability",
            "sizeof(kvm_cpu_caps)"
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "sizeof(kvm_cpu_caps) >\n\t\t     sizeof(boot_cpu_data.x86_capability)"
          ],
          "line": 286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_efer_nx",
          "args": [],
          "line": 277
        },
        "resolved": true,
        "details": {
          "function_name": "is_efer_nx",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "135-138",
          "snippet": "static int is_efer_nx(void)\n{\n\treturn host_efer & EFER_NX;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic int is_efer_nx(void)\n{\n\treturn host_efer & EFER_NX;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\n#define F feature_bit\n\nu32 kvm_cpu_caps[NCAPINTS];\n\nvoid kvm_set_cpu_caps(void)\n{\n\tunsigned int f_nx = is_efer_nx() ? F(NX) : 0;\n#ifdef CONFIG_X86_64\n\tunsigned int f_gbpages = F(GBPAGES);\n\tunsigned int f_lm = F(LM);\n#else\n\tunsigned int f_gbpages = 0;\n\tunsigned int f_lm = 0;\n#endif\n\n\tBUILD_BUG_ON(sizeof(kvm_cpu_caps) >\n\t\t     sizeof(boot_cpu_data.x86_capability));\n\n\tmemcpy(&kvm_cpu_caps, &boot_cpu_data.x86_capability,\n\t       sizeof(kvm_cpu_caps));\n\n\tkvm_cpu_cap_mask(CPUID_1_ECX,\n\t\t/*\n\t\t * NOTE: MONITOR (and MWAIT) are emulated as NOP, but *not*\n\t\t * advertised to guests via CPUID!\n\t\t */\n\t\tF(XMM3) | F(PCLMULQDQ) | 0 /* DTES64, MONITOR */ |\n\t\t0 /* DS-CPL, VMX, SMX, EST */ |\n\t\t0 /* TM2 */ | F(SSSE3) | 0 /* CNXT-ID */ | 0 /* Reserved */ |\n\t\tF(FMA) | F(CX16) | 0 /* xTPR Update, PDCM */ |\n\t\tF(PCID) | 0 /* Reserved, DCA */ | F(XMM4_1) |\n\t\tF(XMM4_2) | F(X2APIC) | F(MOVBE) | F(POPCNT) |\n\t\t0 /* Reserved*/ | F(AES) | F(XSAVE) | 0 /* OSXSAVE */ | F(AVX) |\n\t\tF(F16C) | F(RDRAND)\n\t);\n\t/* KVM emulates x2apic in software irrespective of host support. */\n\tkvm_cpu_cap_set(X86_FEATURE_X2APIC);\n\n\tkvm_cpu_cap_mask(CPUID_1_EDX,\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SEP) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* PSN */ | F(CLFLUSH) |\n\t\t0 /* Reserved, DS, ACPI */ | F(MMX) |\n\t\tF(FXSR) | F(XMM) | F(XMM2) | F(SELFSNOOP) |\n\t\t0 /* HTT, TM, Reserved, PBE */\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_7_0_EBX,\n\t\tF(FSGSBASE) | F(BMI1) | F(HLE) | F(AVX2) | F(SMEP) |\n\t\tF(BMI2) | F(ERMS) | 0 /*INVPCID*/ | F(RTM) | 0 /*MPX*/ | F(RDSEED) |\n\t\tF(ADX) | F(SMAP) | F(AVX512IFMA) | F(AVX512F) | F(AVX512PF) |\n\t\tF(AVX512ER) | F(AVX512CD) | F(CLFLUSHOPT) | F(CLWB) | F(AVX512DQ) |\n\t\tF(SHA_NI) | F(AVX512BW) | F(AVX512VL) | 0 /*INTEL_PT*/\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_7_ECX,\n\t\tF(AVX512VBMI) | F(LA57) | 0 /*PKU*/ | 0 /*OSPKE*/ | F(RDPID) |\n\t\tF(AVX512_VPOPCNTDQ) | F(UMIP) | F(AVX512_VBMI2) | F(GFNI) |\n\t\tF(VAES) | F(VPCLMULQDQ) | F(AVX512_VNNI) | F(AVX512_BITALG) |\n\t\tF(CLDEMOTE) | F(MOVDIRI) | F(MOVDIR64B) | 0 /*WAITPKG*/\n\t);\n\t/* Set LA57 based on hardware capability. */\n\tif (cpuid_ecx(7) & F(LA57))\n\t\tkvm_cpu_cap_set(X86_FEATURE_LA57);\n\n\tkvm_cpu_cap_mask(CPUID_7_EDX,\n\t\tF(AVX512_4VNNIW) | F(AVX512_4FMAPS) | F(SPEC_CTRL) |\n\t\tF(SPEC_CTRL_SSBD) | F(ARCH_CAPABILITIES) | F(INTEL_STIBP) |\n\t\tF(MD_CLEAR) | F(AVX512_VP2INTERSECT) | F(FSRM)\n\t);\n\n\t/* TSC_ADJUST and ARCH_CAPABILITIES are emulated in software. */\n\tkvm_cpu_cap_set(X86_FEATURE_TSC_ADJUST);\n\tkvm_cpu_cap_set(X86_FEATURE_ARCH_CAPABILITIES);\n\n\tif (boot_cpu_has(X86_FEATURE_IBPB) && boot_cpu_has(X86_FEATURE_IBRS))\n\t\tkvm_cpu_cap_set(X86_FEATURE_SPEC_CTRL);\n\tif (boot_cpu_has(X86_FEATURE_STIBP))\n\t\tkvm_cpu_cap_set(X86_FEATURE_INTEL_STIBP);\n\tif (boot_cpu_has(X86_FEATURE_AMD_SSBD))\n\t\tkvm_cpu_cap_set(X86_FEATURE_SPEC_CTRL_SSBD);\n\n\tkvm_cpu_cap_mask(CPUID_7_1_EAX,\n\t\tF(AVX512_BF16)\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_D_1_EAX,\n\t\tF(XSAVEOPT) | F(XSAVEC) | F(XGETBV1) | F(XSAVES)\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_8000_0001_ECX,\n\t\tF(LAHF_LM) | F(CMP_LEGACY) | 0 /*SVM*/ | 0 /* ExtApicSpace */ |\n\t\tF(CR8_LEGACY) | F(ABM) | F(SSE4A) | F(MISALIGNSSE) |\n\t\tF(3DNOWPREFETCH) | F(OSVW) | 0 /* IBS */ | F(XOP) |\n\t\t0 /* SKINIT, WDT, LWP */ | F(FMA4) | F(TBM) |\n\t\tF(TOPOEXT) | F(PERFCTR_CORE)\n\t);\n\n\tkvm_cpu_cap_mask(CPUID_8000_0001_EDX,\n\t\tF(FPU) | F(VME) | F(DE) | F(PSE) |\n\t\tF(TSC) | F(MSR) | F(PAE) | F(MCE) |\n\t\tF(CX8) | F(APIC) | 0 /* Reserved */ | F(SYSCALL) |\n\t\tF(MTRR) | F(PGE) | F(MCA) | F(CMOV) |\n\t\tF(PAT) | F(PSE36) | 0 /* Reserved */ |\n\t\tf_nx | 0 /* Reserved */ | F(MMXEXT) | F(MMX) |\n\t\tF(FXSR) | F(FXSR_OPT) | f_gbpages | F(RDTSCP) |\n\t\t0 /* Reserved */ | f_lm | F(3DNOWEXT) | F(3DNOW)\n\t);\n\n\tif (!tdp_enabled && IS_ENABLED(CONFIG_X86_64))\n\t\tkvm_cpu_cap_set(X86_FEATURE_GBPAGES);\n\n\tkvm_cpu_cap_mask(CPUID_8000_0008_EBX,\n\t\tF(CLZERO) | F(XSAVEERPTR) |\n\t\tF(WBNOINVD) | F(AMD_IBPB) | F(AMD_IBRS) | F(AMD_SSBD) | F(VIRT_SSBD) |\n\t\tF(AMD_SSB_NO) | F(AMD_STIBP) | F(AMD_STIBP_ALWAYS_ON)\n\t);\n\n\t/*\n\t * AMD has separate bits for each SPEC_CTRL bit.\n\t * arch/x86/kernel/cpu/bugs.c is kind enough to\n\t * record that in cpufeatures so use them.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_IBPB))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_IBPB);\n\tif (boot_cpu_has(X86_FEATURE_IBRS))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_IBRS);\n\tif (boot_cpu_has(X86_FEATURE_STIBP))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_STIBP);\n\tif (boot_cpu_has(X86_FEATURE_SPEC_CTRL_SSBD))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_SSBD);\n\tif (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))\n\t\tkvm_cpu_cap_set(X86_FEATURE_AMD_SSB_NO);\n\t/*\n\t * The preference is to use SPEC CTRL MSR instead of the\n\t * VIRT_SPEC MSR.\n\t */\n\tif (boot_cpu_has(X86_FEATURE_LS_CFG_SSBD) &&\n\t    !boot_cpu_has(X86_FEATURE_AMD_SSBD))\n\t\tkvm_cpu_cap_set(X86_FEATURE_VIRT_SSBD);\n\n\t/*\n\t * Hide all SVM features by default, SVM will set the cap bits for\n\t * features it emulates and/or exposes for L1.\n\t */\n\tkvm_cpu_cap_mask(CPUID_8000_000A_EDX, 0);\n\n\tkvm_cpu_cap_mask(CPUID_C000_0001_EDX,\n\t\tF(XSTORE) | F(XSTORE_EN) | F(XCRYPT) | F(XCRYPT_EN) |\n\t\tF(ACE2) | F(ACE2_EN) | F(PHE) | F(PHE_EN) |\n\t\tF(PMM) | F(PMM_EN)\n\t);\n}"
  },
  {
    "function_name": "kvm_cpu_cap_mask",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "261-273",
    "snippet": "static __always_inline void kvm_cpu_cap_mask(enum cpuid_leafs leaf, u32 mask)\n{\n\tconst struct cpuid_reg cpuid = x86_feature_cpuid(leaf * 32);\n\tstruct kvm_cpuid_entry2 entry;\n\n\treverse_cpuid_check(leaf);\n\tkvm_cpu_caps[leaf] &= mask;\n\n\tcpuid_count(cpuid.function, cpuid.index,\n\t\t    &entry.eax, &entry.ebx, &entry.ecx, &entry.edx);\n\n\tkvm_cpu_caps[leaf] &= *__cpuid_entry_get_reg(&entry, cpuid.reg);\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "u32 kvm_cpu_caps[NCAPINTS]"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cpuid_entry_get_reg",
          "args": [
            "&entry",
            "cpuid.reg"
          ],
          "line": 272
        },
        "resolved": true,
        "details": {
          "function_name": "__cpuid_entry_get_reg",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "101-117",
          "snippet": "static __always_inline u32 *__cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t\t  u32 reg)\n{\n\tswitch (reg) {\n\tcase CPUID_EAX:\n\t\treturn &entry->eax;\n\tcase CPUID_EBX:\n\t\treturn &entry->ebx;\n\tcase CPUID_ECX:\n\t\treturn &entry->ecx;\n\tcase CPUID_EDX:\n\t\treturn &entry->edx;\n\tdefault:\n\t\tBUILD_BUG();\n\t\treturn NULL;\n\t}\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline u32 *__cpuid_entry_get_reg(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t\t  u32 reg)\n{\n\tswitch (reg) {\n\tcase CPUID_EAX:\n\t\treturn &entry->eax;\n\tcase CPUID_EBX:\n\t\treturn &entry->ebx;\n\tcase CPUID_ECX:\n\t\treturn &entry->ecx;\n\tcase CPUID_EDX:\n\t\treturn &entry->edx;\n\tdefault:\n\t\tBUILD_BUG();\n\t\treturn NULL;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_count",
          "args": [
            "cpuid.function",
            "cpuid.index",
            "&entry.eax",
            "&entry.ebx",
            "&entry.ecx",
            "&entry.edx"
          ],
          "line": 269
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "reverse_cpuid_check",
          "args": [
            "leaf"
          ],
          "line": 266
        },
        "resolved": true,
        "details": {
          "function_name": "reverse_cpuid_check",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "69-77",
          "snippet": "static __always_inline void reverse_cpuid_check(unsigned int x86_leaf)\n{\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_1);\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_2);\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_3);\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_4);\n\tBUILD_BUG_ON(x86_leaf >= ARRAY_SIZE(reverse_cpuid));\n\tBUILD_BUG_ON(reverse_cpuid[x86_leaf].function == 0);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline void reverse_cpuid_check(unsigned int x86_leaf)\n{\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_1);\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_2);\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_3);\n\tBUILD_BUG_ON(x86_leaf == CPUID_LNX_4);\n\tBUILD_BUG_ON(x86_leaf >= ARRAY_SIZE(reverse_cpuid));\n\tBUILD_BUG_ON(reverse_cpuid[x86_leaf].function == 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "x86_feature_cpuid",
          "args": [
            "leaf * 32"
          ],
          "line": 263
        },
        "resolved": true,
        "details": {
          "function_name": "x86_feature_cpuid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "93-99",
          "snippet": "cpuid_reg x86_feature_cpuid(unsigned int x86_feature)\n{\n\tunsigned int x86_leaf = x86_feature / 32;\n\n\treverse_cpuid_check(x86_leaf);\n\treturn reverse_cpuid[x86_leaf];\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\ncpuid_reg x86_feature_cpuid(unsigned int x86_feature)\n{\n\tunsigned int x86_leaf = x86_feature / 32;\n\n\treverse_cpuid_check(x86_leaf);\n\treturn reverse_cpuid[x86_leaf];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nu32 kvm_cpu_caps[NCAPINTS];\n\nstatic __always_inline void kvm_cpu_cap_mask(enum cpuid_leafs leaf, u32 mask)\n{\n\tconst struct cpuid_reg cpuid = x86_feature_cpuid(leaf * 32);\n\tstruct kvm_cpuid_entry2 entry;\n\n\treverse_cpuid_check(leaf);\n\tkvm_cpu_caps[leaf] &= mask;\n\n\tcpuid_count(cpuid.function, cpuid.index,\n\t\t    &entry.eax, &entry.ebx, &entry.ecx, &entry.edx);\n\n\tkvm_cpu_caps[leaf] &= *__cpuid_entry_get_reg(&entry, cpuid.reg);\n}"
  },
  {
    "function_name": "kvm_vcpu_ioctl_get_cpuid2",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "241-259",
    "snippet": "int kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,\n\t\t\t      struct kvm_cpuid2 *cpuid,\n\t\t\t      struct kvm_cpuid_entry2 __user *entries)\n{\n\tint r;\n\n\tr = -E2BIG;\n\tif (cpuid->nent < vcpu->arch.cpuid_nent)\n\t\tgoto out;\n\tr = -EFAULT;\n\tif (copy_to_user(entries, &vcpu->arch.cpuid_entries,\n\t\t\t vcpu->arch.cpuid_nent * sizeof(struct kvm_cpuid_entry2)))\n\t\tgoto out;\n\treturn 0;\n\nout:\n\tcpuid->nent = vcpu->arch.cpuid_nent;\n\treturn r;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "copy_to_user",
          "args": [
            "entries",
            "&vcpu->arch.cpuid_entries",
            "vcpu->arch.cpuid_nent * sizeof(struct kvm_cpuid_entry2)"
          ],
          "line": 251
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_vcpu_ioctl_get_cpuid2(struct kvm_vcpu *vcpu,\n\t\t\t      struct kvm_cpuid2 *cpuid,\n\t\t\t      struct kvm_cpuid_entry2 __user *entries)\n{\n\tint r;\n\n\tr = -E2BIG;\n\tif (cpuid->nent < vcpu->arch.cpuid_nent)\n\t\tgoto out;\n\tr = -EFAULT;\n\tif (copy_to_user(entries, &vcpu->arch.cpuid_entries,\n\t\t\t vcpu->arch.cpuid_nent * sizeof(struct kvm_cpuid_entry2)))\n\t\tgoto out;\n\treturn 0;\n\nout:\n\tcpuid->nent = vcpu->arch.cpuid_nent;\n\treturn r;\n}"
  },
  {
    "function_name": "kvm_vcpu_ioctl_set_cpuid2",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "220-239",
    "snippet": "int kvm_vcpu_ioctl_set_cpuid2(struct kvm_vcpu *vcpu,\n\t\t\t      struct kvm_cpuid2 *cpuid,\n\t\t\t      struct kvm_cpuid_entry2 __user *entries)\n{\n\tint r;\n\n\tr = -E2BIG;\n\tif (cpuid->nent > KVM_MAX_CPUID_ENTRIES)\n\t\tgoto out;\n\tr = -EFAULT;\n\tif (copy_from_user(&vcpu->arch.cpuid_entries, entries,\n\t\t\t   cpuid->nent * sizeof(struct kvm_cpuid_entry2)))\n\t\tgoto out;\n\tvcpu->arch.cpuid_nent = cpuid->nent;\n\tkvm_apic_set_version(vcpu);\n\tkvm_x86_ops.cpuid_update(vcpu);\n\tr = kvm_update_cpuid(vcpu);\nout:\n\treturn r;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_update_cpuid",
          "args": [
            "vcpu"
          ],
          "line": 236
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_update_cpuid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "57-133",
          "snippet": "int kvm_update_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 1, 0);\n\tif (!best)\n\t\treturn 0;\n\n\t/* Update OSXSAVE bit */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE) && best->function == 0x1)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSXSAVE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_OSXSAVE));\n\n\tcpuid_entry_change(best, X86_FEATURE_APIC,\n\t\t\t   vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);\n\n\tif (apic) {\n\t\tif (cpuid_entry_has(best, X86_FEATURE_TSC_DEADLINE_TIMER))\n\t\t\tapic->lapic_timer.timer_mode_mask = 3 << 17;\n\t\telse\n\t\t\tapic->lapic_timer.timer_mode_mask = 1 << 17;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 7, 0);\n\tif (best && boot_cpu_has(X86_FEATURE_PKU) && best->function == 0x7)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSPKE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_PKE));\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 0);\n\tif (!best) {\n\t\tvcpu->arch.guest_supported_xcr0 = 0;\n\t\tvcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\t} else {\n\t\tvcpu->arch.guest_supported_xcr0 =\n\t\t\t(best->eax | ((u64)best->edx << 32)) & supported_xcr0;\n\t\tvcpu->arch.guest_xstate_size = best->ebx =\n\t\t\txstate_required_size(vcpu->arch.xcr0, false);\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 1);\n\tif (best && (cpuid_entry_has(best, X86_FEATURE_XSAVES) ||\n\t\t     cpuid_entry_has(best, X86_FEATURE_XSAVEC)))\n\t\tbest->ebx = xstate_required_size(vcpu->arch.xcr0, true);\n\n\t/*\n\t * The existing code assumes virtual address is 48-bit or 57-bit in the\n\t * canonical address checks; exit if it is ever changed.\n\t */\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best) {\n\t\tint vaddr_bits = (best->eax & 0xff00) >> 8;\n\n\t\tif (vaddr_bits != 48 && vaddr_bits != 57 && vaddr_bits != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, KVM_CPUID_FEATURES, 0);\n\tif (kvm_hlt_in_guest(vcpu->kvm) && best &&\n\t\t(best->eax & (1 << KVM_FEATURE_PV_UNHALT)))\n\t\tbest->eax &= ~(1 << KVM_FEATURE_PV_UNHALT);\n\n\tif (!kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT)) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\t\tif (best)\n\t\t\tcpuid_entry_change(best, X86_FEATURE_MWAIT,\n\t\t\t\t\t   vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT);\n\t}\n\n\t/* Update physical-address width */\n\tvcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);\n\tkvm_mmu_reset_context(vcpu);\n\n\tkvm_pmu_refresh(vcpu);\n\treturn 0;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_update_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 1, 0);\n\tif (!best)\n\t\treturn 0;\n\n\t/* Update OSXSAVE bit */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE) && best->function == 0x1)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSXSAVE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_OSXSAVE));\n\n\tcpuid_entry_change(best, X86_FEATURE_APIC,\n\t\t\t   vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);\n\n\tif (apic) {\n\t\tif (cpuid_entry_has(best, X86_FEATURE_TSC_DEADLINE_TIMER))\n\t\t\tapic->lapic_timer.timer_mode_mask = 3 << 17;\n\t\telse\n\t\t\tapic->lapic_timer.timer_mode_mask = 1 << 17;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 7, 0);\n\tif (best && boot_cpu_has(X86_FEATURE_PKU) && best->function == 0x7)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSPKE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_PKE));\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 0);\n\tif (!best) {\n\t\tvcpu->arch.guest_supported_xcr0 = 0;\n\t\tvcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\t} else {\n\t\tvcpu->arch.guest_supported_xcr0 =\n\t\t\t(best->eax | ((u64)best->edx << 32)) & supported_xcr0;\n\t\tvcpu->arch.guest_xstate_size = best->ebx =\n\t\t\txstate_required_size(vcpu->arch.xcr0, false);\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 1);\n\tif (best && (cpuid_entry_has(best, X86_FEATURE_XSAVES) ||\n\t\t     cpuid_entry_has(best, X86_FEATURE_XSAVEC)))\n\t\tbest->ebx = xstate_required_size(vcpu->arch.xcr0, true);\n\n\t/*\n\t * The existing code assumes virtual address is 48-bit or 57-bit in the\n\t * canonical address checks; exit if it is ever changed.\n\t */\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best) {\n\t\tint vaddr_bits = (best->eax & 0xff00) >> 8;\n\n\t\tif (vaddr_bits != 48 && vaddr_bits != 57 && vaddr_bits != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, KVM_CPUID_FEATURES, 0);\n\tif (kvm_hlt_in_guest(vcpu->kvm) && best &&\n\t\t(best->eax & (1 << KVM_FEATURE_PV_UNHALT)))\n\t\tbest->eax &= ~(1 << KVM_FEATURE_PV_UNHALT);\n\n\tif (!kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT)) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\t\tif (best)\n\t\t\tcpuid_entry_change(best, X86_FEATURE_MWAIT,\n\t\t\t\t\t   vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT);\n\t}\n\n\t/* Update physical-address width */\n\tvcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);\n\tkvm_mmu_reset_context(vcpu);\n\n\tkvm_pmu_refresh(vcpu);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops.cpuid_update",
          "args": [
            "vcpu"
          ],
          "line": 235
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_apic_set_version",
          "args": [
            "vcpu"
          ],
          "line": 234
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_apic_set_version",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/lapic.c",
          "lines": "337-358",
          "snippet": "void kvm_apic_set_version(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\tstruct kvm_cpuid_entry2 *feat;\n\tu32 v = APIC_VERSION;\n\n\tif (!lapic_in_kernel(vcpu))\n\t\treturn;\n\n\t/*\n\t * KVM emulates 82093AA datasheet (with in-kernel IOAPIC implementation)\n\t * which doesn't have EOI register; Some buggy OSes (e.g. Windows with\n\t * Hyper-V role) disable EOI broadcast in lapic not checking for IOAPIC\n\t * version first and level-triggered interrupts never get EOIed in\n\t * IOAPIC.\n\t */\n\tfeat = kvm_find_cpuid_entry(apic->vcpu, 0x1, 0);\n\tif (feat && (feat->ecx & (1 << (X86_FEATURE_X2APIC & 31))) &&\n\t    !ioapic_in_kernel(vcpu->kvm))\n\t\tv |= APIC_LVR_DIRECTED_EOI;\n\tkvm_lapic_set_reg(apic, APIC_LVR, v);\n}",
          "includes": [
            "#include \"hyperv.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"trace.h\"",
            "#include \"irq.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/atomic.h>",
            "#include <asm/delay.h>",
            "#include <asm/apicdef.h>",
            "#include <asm/current.h>",
            "#include <asm/page.h>",
            "#include <asm/msr.h>",
            "#include <asm/processor.h>",
            "#include <linux/slab.h>",
            "#include <linux/math64.h>",
            "#include <linux/export.h>",
            "#include <linux/io.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/smp.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/kvm.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define APIC_VERSION\t\t\t(0x14UL | ((KVM_APIC_LVT_NUM - 1) << 16))"
          ],
          "globals_used": [
            "static void cancel_hv_timer(struct kvm_lapic *apic);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"hyperv.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"trace.h\"\n#include \"irq.h\"\n#include \"kvm_cache_regs.h\"\n#include <linux/jump_label.h>\n#include <linux/atomic.h>\n#include <asm/delay.h>\n#include <asm/apicdef.h>\n#include <asm/current.h>\n#include <asm/page.h>\n#include <asm/msr.h>\n#include <asm/processor.h>\n#include <linux/slab.h>\n#include <linux/math64.h>\n#include <linux/export.h>\n#include <linux/io.h>\n#include <linux/hrtimer.h>\n#include <linux/smp.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/kvm.h>\n#include <linux/kvm_host.h>\n\n#define APIC_VERSION\t\t\t(0x14UL | ((KVM_APIC_LVT_NUM - 1) << 16))\n\nstatic void cancel_hv_timer(struct kvm_lapic *apic);\n\nvoid kvm_apic_set_version(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\tstruct kvm_cpuid_entry2 *feat;\n\tu32 v = APIC_VERSION;\n\n\tif (!lapic_in_kernel(vcpu))\n\t\treturn;\n\n\t/*\n\t * KVM emulates 82093AA datasheet (with in-kernel IOAPIC implementation)\n\t * which doesn't have EOI register; Some buggy OSes (e.g. Windows with\n\t * Hyper-V role) disable EOI broadcast in lapic not checking for IOAPIC\n\t * version first and level-triggered interrupts never get EOIed in\n\t * IOAPIC.\n\t */\n\tfeat = kvm_find_cpuid_entry(apic->vcpu, 0x1, 0);\n\tif (feat && (feat->ecx & (1 << (X86_FEATURE_X2APIC & 31))) &&\n\t    !ioapic_in_kernel(vcpu->kvm))\n\t\tv |= APIC_LVR_DIRECTED_EOI;\n\tkvm_lapic_set_reg(apic, APIC_LVR, v);\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "&vcpu->arch.cpuid_entries",
            "entries",
            "cpuid->nent * sizeof(struct kvm_cpuid_entry2)"
          ],
          "line": 230
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_vcpu_ioctl_set_cpuid2(struct kvm_vcpu *vcpu,\n\t\t\t      struct kvm_cpuid2 *cpuid,\n\t\t\t      struct kvm_cpuid_entry2 __user *entries)\n{\n\tint r;\n\n\tr = -E2BIG;\n\tif (cpuid->nent > KVM_MAX_CPUID_ENTRIES)\n\t\tgoto out;\n\tr = -EFAULT;\n\tif (copy_from_user(&vcpu->arch.cpuid_entries, entries,\n\t\t\t   cpuid->nent * sizeof(struct kvm_cpuid_entry2)))\n\t\tgoto out;\n\tvcpu->arch.cpuid_nent = cpuid->nent;\n\tkvm_apic_set_version(vcpu);\n\tkvm_x86_ops.cpuid_update(vcpu);\n\tr = kvm_update_cpuid(vcpu);\nout:\n\treturn r;\n}"
  },
  {
    "function_name": "kvm_vcpu_ioctl_set_cpuid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "175-218",
    "snippet": "int kvm_vcpu_ioctl_set_cpuid(struct kvm_vcpu *vcpu,\n\t\t\t     struct kvm_cpuid *cpuid,\n\t\t\t     struct kvm_cpuid_entry __user *entries)\n{\n\tint r, i;\n\tstruct kvm_cpuid_entry *cpuid_entries = NULL;\n\n\tr = -E2BIG;\n\tif (cpuid->nent > KVM_MAX_CPUID_ENTRIES)\n\t\tgoto out;\n\tr = -ENOMEM;\n\tif (cpuid->nent) {\n\t\tcpuid_entries =\n\t\t\tvmalloc(array_size(sizeof(struct kvm_cpuid_entry),\n\t\t\t\t\t   cpuid->nent));\n\t\tif (!cpuid_entries)\n\t\t\tgoto out;\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(cpuid_entries, entries,\n\t\t\t\t   cpuid->nent * sizeof(struct kvm_cpuid_entry)))\n\t\t\tgoto out;\n\t}\n\tfor (i = 0; i < cpuid->nent; i++) {\n\t\tvcpu->arch.cpuid_entries[i].function = cpuid_entries[i].function;\n\t\tvcpu->arch.cpuid_entries[i].eax = cpuid_entries[i].eax;\n\t\tvcpu->arch.cpuid_entries[i].ebx = cpuid_entries[i].ebx;\n\t\tvcpu->arch.cpuid_entries[i].ecx = cpuid_entries[i].ecx;\n\t\tvcpu->arch.cpuid_entries[i].edx = cpuid_entries[i].edx;\n\t\tvcpu->arch.cpuid_entries[i].index = 0;\n\t\tvcpu->arch.cpuid_entries[i].flags = 0;\n\t\tvcpu->arch.cpuid_entries[i].padding[0] = 0;\n\t\tvcpu->arch.cpuid_entries[i].padding[1] = 0;\n\t\tvcpu->arch.cpuid_entries[i].padding[2] = 0;\n\t}\n\tvcpu->arch.cpuid_nent = cpuid->nent;\n\tcpuid_fix_nx_cap(vcpu);\n\tkvm_apic_set_version(vcpu);\n\tkvm_x86_ops.cpuid_update(vcpu);\n\tr = kvm_update_cpuid(vcpu);\n\nout:\n\tvfree(cpuid_entries);\n\treturn r;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "vfree",
          "args": [
            "cpuid_entries"
          ],
          "line": 216
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_update_cpuid",
          "args": [
            "vcpu"
          ],
          "line": 213
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_update_cpuid",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "57-133",
          "snippet": "int kvm_update_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 1, 0);\n\tif (!best)\n\t\treturn 0;\n\n\t/* Update OSXSAVE bit */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE) && best->function == 0x1)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSXSAVE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_OSXSAVE));\n\n\tcpuid_entry_change(best, X86_FEATURE_APIC,\n\t\t\t   vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);\n\n\tif (apic) {\n\t\tif (cpuid_entry_has(best, X86_FEATURE_TSC_DEADLINE_TIMER))\n\t\t\tapic->lapic_timer.timer_mode_mask = 3 << 17;\n\t\telse\n\t\t\tapic->lapic_timer.timer_mode_mask = 1 << 17;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 7, 0);\n\tif (best && boot_cpu_has(X86_FEATURE_PKU) && best->function == 0x7)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSPKE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_PKE));\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 0);\n\tif (!best) {\n\t\tvcpu->arch.guest_supported_xcr0 = 0;\n\t\tvcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\t} else {\n\t\tvcpu->arch.guest_supported_xcr0 =\n\t\t\t(best->eax | ((u64)best->edx << 32)) & supported_xcr0;\n\t\tvcpu->arch.guest_xstate_size = best->ebx =\n\t\t\txstate_required_size(vcpu->arch.xcr0, false);\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 1);\n\tif (best && (cpuid_entry_has(best, X86_FEATURE_XSAVES) ||\n\t\t     cpuid_entry_has(best, X86_FEATURE_XSAVEC)))\n\t\tbest->ebx = xstate_required_size(vcpu->arch.xcr0, true);\n\n\t/*\n\t * The existing code assumes virtual address is 48-bit or 57-bit in the\n\t * canonical address checks; exit if it is ever changed.\n\t */\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best) {\n\t\tint vaddr_bits = (best->eax & 0xff00) >> 8;\n\n\t\tif (vaddr_bits != 48 && vaddr_bits != 57 && vaddr_bits != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, KVM_CPUID_FEATURES, 0);\n\tif (kvm_hlt_in_guest(vcpu->kvm) && best &&\n\t\t(best->eax & (1 << KVM_FEATURE_PV_UNHALT)))\n\t\tbest->eax &= ~(1 << KVM_FEATURE_PV_UNHALT);\n\n\tif (!kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT)) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\t\tif (best)\n\t\t\tcpuid_entry_change(best, X86_FEATURE_MWAIT,\n\t\t\t\t\t   vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT);\n\t}\n\n\t/* Update physical-address width */\n\tvcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);\n\tkvm_mmu_reset_context(vcpu);\n\n\tkvm_pmu_refresh(vcpu);\n\treturn 0;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_update_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 1, 0);\n\tif (!best)\n\t\treturn 0;\n\n\t/* Update OSXSAVE bit */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE) && best->function == 0x1)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSXSAVE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_OSXSAVE));\n\n\tcpuid_entry_change(best, X86_FEATURE_APIC,\n\t\t\t   vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);\n\n\tif (apic) {\n\t\tif (cpuid_entry_has(best, X86_FEATURE_TSC_DEADLINE_TIMER))\n\t\t\tapic->lapic_timer.timer_mode_mask = 3 << 17;\n\t\telse\n\t\t\tapic->lapic_timer.timer_mode_mask = 1 << 17;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 7, 0);\n\tif (best && boot_cpu_has(X86_FEATURE_PKU) && best->function == 0x7)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSPKE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_PKE));\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 0);\n\tif (!best) {\n\t\tvcpu->arch.guest_supported_xcr0 = 0;\n\t\tvcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\t} else {\n\t\tvcpu->arch.guest_supported_xcr0 =\n\t\t\t(best->eax | ((u64)best->edx << 32)) & supported_xcr0;\n\t\tvcpu->arch.guest_xstate_size = best->ebx =\n\t\t\txstate_required_size(vcpu->arch.xcr0, false);\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 1);\n\tif (best && (cpuid_entry_has(best, X86_FEATURE_XSAVES) ||\n\t\t     cpuid_entry_has(best, X86_FEATURE_XSAVEC)))\n\t\tbest->ebx = xstate_required_size(vcpu->arch.xcr0, true);\n\n\t/*\n\t * The existing code assumes virtual address is 48-bit or 57-bit in the\n\t * canonical address checks; exit if it is ever changed.\n\t */\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best) {\n\t\tint vaddr_bits = (best->eax & 0xff00) >> 8;\n\n\t\tif (vaddr_bits != 48 && vaddr_bits != 57 && vaddr_bits != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, KVM_CPUID_FEATURES, 0);\n\tif (kvm_hlt_in_guest(vcpu->kvm) && best &&\n\t\t(best->eax & (1 << KVM_FEATURE_PV_UNHALT)))\n\t\tbest->eax &= ~(1 << KVM_FEATURE_PV_UNHALT);\n\n\tif (!kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT)) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\t\tif (best)\n\t\t\tcpuid_entry_change(best, X86_FEATURE_MWAIT,\n\t\t\t\t\t   vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT);\n\t}\n\n\t/* Update physical-address width */\n\tvcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);\n\tkvm_mmu_reset_context(vcpu);\n\n\tkvm_pmu_refresh(vcpu);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_x86_ops.cpuid_update",
          "args": [
            "vcpu"
          ],
          "line": 212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvm_apic_set_version",
          "args": [
            "vcpu"
          ],
          "line": 211
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_apic_set_version",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/lapic.c",
          "lines": "337-358",
          "snippet": "void kvm_apic_set_version(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\tstruct kvm_cpuid_entry2 *feat;\n\tu32 v = APIC_VERSION;\n\n\tif (!lapic_in_kernel(vcpu))\n\t\treturn;\n\n\t/*\n\t * KVM emulates 82093AA datasheet (with in-kernel IOAPIC implementation)\n\t * which doesn't have EOI register; Some buggy OSes (e.g. Windows with\n\t * Hyper-V role) disable EOI broadcast in lapic not checking for IOAPIC\n\t * version first and level-triggered interrupts never get EOIed in\n\t * IOAPIC.\n\t */\n\tfeat = kvm_find_cpuid_entry(apic->vcpu, 0x1, 0);\n\tif (feat && (feat->ecx & (1 << (X86_FEATURE_X2APIC & 31))) &&\n\t    !ioapic_in_kernel(vcpu->kvm))\n\t\tv |= APIC_LVR_DIRECTED_EOI;\n\tkvm_lapic_set_reg(apic, APIC_LVR, v);\n}",
          "includes": [
            "#include \"hyperv.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include \"trace.h\"",
            "#include \"irq.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/atomic.h>",
            "#include <asm/delay.h>",
            "#include <asm/apicdef.h>",
            "#include <asm/current.h>",
            "#include <asm/page.h>",
            "#include <asm/msr.h>",
            "#include <asm/processor.h>",
            "#include <linux/slab.h>",
            "#include <linux/math64.h>",
            "#include <linux/export.h>",
            "#include <linux/io.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/smp.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/kvm.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define APIC_VERSION\t\t\t(0x14UL | ((KVM_APIC_LVT_NUM - 1) << 16))"
          ],
          "globals_used": [
            "static void cancel_hv_timer(struct kvm_lapic *apic);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"hyperv.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include \"trace.h\"\n#include \"irq.h\"\n#include \"kvm_cache_regs.h\"\n#include <linux/jump_label.h>\n#include <linux/atomic.h>\n#include <asm/delay.h>\n#include <asm/apicdef.h>\n#include <asm/current.h>\n#include <asm/page.h>\n#include <asm/msr.h>\n#include <asm/processor.h>\n#include <linux/slab.h>\n#include <linux/math64.h>\n#include <linux/export.h>\n#include <linux/io.h>\n#include <linux/hrtimer.h>\n#include <linux/smp.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/kvm.h>\n#include <linux/kvm_host.h>\n\n#define APIC_VERSION\t\t\t(0x14UL | ((KVM_APIC_LVT_NUM - 1) << 16))\n\nstatic void cancel_hv_timer(struct kvm_lapic *apic);\n\nvoid kvm_apic_set_version(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\tstruct kvm_cpuid_entry2 *feat;\n\tu32 v = APIC_VERSION;\n\n\tif (!lapic_in_kernel(vcpu))\n\t\treturn;\n\n\t/*\n\t * KVM emulates 82093AA datasheet (with in-kernel IOAPIC implementation)\n\t * which doesn't have EOI register; Some buggy OSes (e.g. Windows with\n\t * Hyper-V role) disable EOI broadcast in lapic not checking for IOAPIC\n\t * version first and level-triggered interrupts never get EOIed in\n\t * IOAPIC.\n\t */\n\tfeat = kvm_find_cpuid_entry(apic->vcpu, 0x1, 0);\n\tif (feat && (feat->ecx & (1 << (X86_FEATURE_X2APIC & 31))) &&\n\t    !ioapic_in_kernel(vcpu->kvm))\n\t\tv |= APIC_LVR_DIRECTED_EOI;\n\tkvm_lapic_set_reg(apic, APIC_LVR, v);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_fix_nx_cap",
          "args": [
            "vcpu"
          ],
          "line": 210
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_fix_nx_cap",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "140-157",
          "snippet": "static void cpuid_fix_nx_cap(struct kvm_vcpu *vcpu)\n{\n\tint i;\n\tstruct kvm_cpuid_entry2 *e, *entry;\n\n\tentry = NULL;\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\t\tif (e->function == 0x80000001) {\n\t\t\tentry = e;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (entry && cpuid_entry_has(entry, X86_FEATURE_NX) && !is_efer_nx()) {\n\t\tcpuid_entry_clear(entry, X86_FEATURE_NX);\n\t\tprintk(KERN_INFO \"kvm: guest NX capability removed\\n\");\n\t}\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic void cpuid_fix_nx_cap(struct kvm_vcpu *vcpu)\n{\n\tint i;\n\tstruct kvm_cpuid_entry2 *e, *entry;\n\n\tentry = NULL;\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\t\tif (e->function == 0x80000001) {\n\t\t\tentry = e;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (entry && cpuid_entry_has(entry, X86_FEATURE_NX) && !is_efer_nx()) {\n\t\tcpuid_entry_clear(entry, X86_FEATURE_NX);\n\t\tprintk(KERN_INFO \"kvm: guest NX capability removed\\n\");\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "cpuid_entries",
            "entries",
            "cpuid->nent * sizeof(struct kvm_cpuid_entry)"
          ],
          "line": 193
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "vmalloc",
          "args": [
            "array_size(sizeof(struct kvm_cpuid_entry),\n\t\t\t\t\t   cpuid->nent)"
          ],
          "line": 188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "array_size",
          "args": [
            "sizeof(struct kvm_cpuid_entry)",
            "cpuid->nent"
          ],
          "line": 188
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_vcpu_ioctl_set_cpuid(struct kvm_vcpu *vcpu,\n\t\t\t     struct kvm_cpuid *cpuid,\n\t\t\t     struct kvm_cpuid_entry __user *entries)\n{\n\tint r, i;\n\tstruct kvm_cpuid_entry *cpuid_entries = NULL;\n\n\tr = -E2BIG;\n\tif (cpuid->nent > KVM_MAX_CPUID_ENTRIES)\n\t\tgoto out;\n\tr = -ENOMEM;\n\tif (cpuid->nent) {\n\t\tcpuid_entries =\n\t\t\tvmalloc(array_size(sizeof(struct kvm_cpuid_entry),\n\t\t\t\t\t   cpuid->nent));\n\t\tif (!cpuid_entries)\n\t\t\tgoto out;\n\t\tr = -EFAULT;\n\t\tif (copy_from_user(cpuid_entries, entries,\n\t\t\t\t   cpuid->nent * sizeof(struct kvm_cpuid_entry)))\n\t\t\tgoto out;\n\t}\n\tfor (i = 0; i < cpuid->nent; i++) {\n\t\tvcpu->arch.cpuid_entries[i].function = cpuid_entries[i].function;\n\t\tvcpu->arch.cpuid_entries[i].eax = cpuid_entries[i].eax;\n\t\tvcpu->arch.cpuid_entries[i].ebx = cpuid_entries[i].ebx;\n\t\tvcpu->arch.cpuid_entries[i].ecx = cpuid_entries[i].ecx;\n\t\tvcpu->arch.cpuid_entries[i].edx = cpuid_entries[i].edx;\n\t\tvcpu->arch.cpuid_entries[i].index = 0;\n\t\tvcpu->arch.cpuid_entries[i].flags = 0;\n\t\tvcpu->arch.cpuid_entries[i].padding[0] = 0;\n\t\tvcpu->arch.cpuid_entries[i].padding[1] = 0;\n\t\tvcpu->arch.cpuid_entries[i].padding[2] = 0;\n\t}\n\tvcpu->arch.cpuid_nent = cpuid->nent;\n\tcpuid_fix_nx_cap(vcpu);\n\tkvm_apic_set_version(vcpu);\n\tkvm_x86_ops.cpuid_update(vcpu);\n\tr = kvm_update_cpuid(vcpu);\n\nout:\n\tvfree(cpuid_entries);\n\treturn r;\n}"
  },
  {
    "function_name": "cpuid_query_maxphyaddr",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "159-171",
    "snippet": "int cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000000, 0);\n\tif (!best || best->eax < 0x80000008)\n\t\tgoto not_found;\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best)\n\t\treturn best->eax & 0xff;\nnot_found:\n\treturn 36;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_find_cpuid_entry",
          "args": [
            "vcpu",
            "0x80000008",
            "0"
          ],
          "line": 166
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_find_cpuid_entry",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "903-917",
          "snippet": "struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstruct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000000, 0);\n\tif (!best || best->eax < 0x80000008)\n\t\tgoto not_found;\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best)\n\t\treturn best->eax & 0xff;\nnot_found:\n\treturn 36;\n}"
  },
  {
    "function_name": "cpuid_fix_nx_cap",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "140-157",
    "snippet": "static void cpuid_fix_nx_cap(struct kvm_vcpu *vcpu)\n{\n\tint i;\n\tstruct kvm_cpuid_entry2 *e, *entry;\n\n\tentry = NULL;\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\t\tif (e->function == 0x80000001) {\n\t\t\tentry = e;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (entry && cpuid_entry_has(entry, X86_FEATURE_NX) && !is_efer_nx()) {\n\t\tcpuid_entry_clear(entry, X86_FEATURE_NX);\n\t\tprintk(KERN_INFO \"kvm: guest NX capability removed\\n\");\n\t}\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printk",
          "args": [
            "KERN_INFO \"kvm: guest NX capability removed\\n\""
          ],
          "line": 155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpuid_entry_clear",
          "args": [
            "entry",
            "X86_FEATURE_NX"
          ],
          "line": 154
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_entry_clear",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "141-147",
          "snippet": "static __always_inline void cpuid_entry_clear(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t      unsigned int x86_feature)\n{\n\tu32 *reg = cpuid_entry_get_reg(entry, x86_feature);\n\n\t*reg &= ~__feature_bit(x86_feature);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline void cpuid_entry_clear(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t      unsigned int x86_feature)\n{\n\tu32 *reg = cpuid_entry_get_reg(entry, x86_feature);\n\n\t*reg &= ~__feature_bit(x86_feature);\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_efer_nx",
          "args": [],
          "line": 153
        },
        "resolved": true,
        "details": {
          "function_name": "is_efer_nx",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "135-138",
          "snippet": "static int is_efer_nx(void)\n{\n\treturn host_efer & EFER_NX;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic int is_efer_nx(void)\n{\n\treturn host_efer & EFER_NX;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_entry_has",
          "args": [
            "entry",
            "X86_FEATURE_NX"
          ],
          "line": 153
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_entry_has",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "135-139",
          "snippet": "static __always_inline bool cpuid_entry_has(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t    unsigned int x86_feature)\n{\n\treturn cpuid_entry_get(entry, x86_feature);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline bool cpuid_entry_has(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t    unsigned int x86_feature)\n{\n\treturn cpuid_entry_get(entry, x86_feature);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic void cpuid_fix_nx_cap(struct kvm_vcpu *vcpu)\n{\n\tint i;\n\tstruct kvm_cpuid_entry2 *e, *entry;\n\n\tentry = NULL;\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\t\tif (e->function == 0x80000001) {\n\t\t\tentry = e;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (entry && cpuid_entry_has(entry, X86_FEATURE_NX) && !is_efer_nx()) {\n\t\tcpuid_entry_clear(entry, X86_FEATURE_NX);\n\t\tprintk(KERN_INFO \"kvm: guest NX capability removed\\n\");\n\t}\n}"
  },
  {
    "function_name": "is_efer_nx",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "135-138",
    "snippet": "static int is_efer_nx(void)\n{\n\treturn host_efer & EFER_NX;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic int is_efer_nx(void)\n{\n\treturn host_efer & EFER_NX;\n}"
  },
  {
    "function_name": "kvm_update_cpuid",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "57-133",
    "snippet": "int kvm_update_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 1, 0);\n\tif (!best)\n\t\treturn 0;\n\n\t/* Update OSXSAVE bit */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE) && best->function == 0x1)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSXSAVE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_OSXSAVE));\n\n\tcpuid_entry_change(best, X86_FEATURE_APIC,\n\t\t\t   vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);\n\n\tif (apic) {\n\t\tif (cpuid_entry_has(best, X86_FEATURE_TSC_DEADLINE_TIMER))\n\t\t\tapic->lapic_timer.timer_mode_mask = 3 << 17;\n\t\telse\n\t\t\tapic->lapic_timer.timer_mode_mask = 1 << 17;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 7, 0);\n\tif (best && boot_cpu_has(X86_FEATURE_PKU) && best->function == 0x7)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSPKE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_PKE));\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 0);\n\tif (!best) {\n\t\tvcpu->arch.guest_supported_xcr0 = 0;\n\t\tvcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\t} else {\n\t\tvcpu->arch.guest_supported_xcr0 =\n\t\t\t(best->eax | ((u64)best->edx << 32)) & supported_xcr0;\n\t\tvcpu->arch.guest_xstate_size = best->ebx =\n\t\t\txstate_required_size(vcpu->arch.xcr0, false);\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 1);\n\tif (best && (cpuid_entry_has(best, X86_FEATURE_XSAVES) ||\n\t\t     cpuid_entry_has(best, X86_FEATURE_XSAVEC)))\n\t\tbest->ebx = xstate_required_size(vcpu->arch.xcr0, true);\n\n\t/*\n\t * The existing code assumes virtual address is 48-bit or 57-bit in the\n\t * canonical address checks; exit if it is ever changed.\n\t */\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best) {\n\t\tint vaddr_bits = (best->eax & 0xff00) >> 8;\n\n\t\tif (vaddr_bits != 48 && vaddr_bits != 57 && vaddr_bits != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, KVM_CPUID_FEATURES, 0);\n\tif (kvm_hlt_in_guest(vcpu->kvm) && best &&\n\t\t(best->eax & (1 << KVM_FEATURE_PV_UNHALT)))\n\t\tbest->eax &= ~(1 << KVM_FEATURE_PV_UNHALT);\n\n\tif (!kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT)) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\t\tif (best)\n\t\t\tcpuid_entry_change(best, X86_FEATURE_MWAIT,\n\t\t\t\t\t   vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT);\n\t}\n\n\t/* Update physical-address width */\n\tvcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);\n\tkvm_mmu_reset_context(vcpu);\n\n\tkvm_pmu_refresh(vcpu);\n\treturn 0;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvm_pmu_refresh",
          "args": [
            "vcpu"
          ],
          "line": 131
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_pmu_refresh",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/pmu.c",
          "lines": "415-418",
          "snippet": "void kvm_pmu_refresh(struct kvm_vcpu *vcpu)\n{\n\tkvm_x86_ops.pmu_ops->refresh(vcpu);\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include \"x86.h\"",
            "#include <asm/perf_event.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/kvm_host.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include \"x86.h\"\n#include <asm/perf_event.h>\n#include <linux/perf_event.h>\n#include <linux/kvm_host.h>\n#include <linux/types.h>\n\nvoid kvm_pmu_refresh(struct kvm_vcpu *vcpu)\n{\n\tkvm_x86_ops.pmu_ops->refresh(vcpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_mmu_reset_context",
          "args": [
            "vcpu"
          ],
          "line": 129
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_mmu_reset_context",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/mmu/mmu.c",
          "lines": "5167-5171",
          "snippet": "void kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}",
          "includes": [
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"paging_tmpl.h\"",
            "#include \"mmu_audit.c\"",
            "#include \"mmutrace.h\"",
            "#include <trace/events/kvm.h>",
            "#include \"trace.h\"",
            "#include <asm/kvm_page_track.h>",
            "#include <asm/vmx.h>",
            "#include <asm/io.h>",
            "#include <asm/e820/api.h>",
            "#include <asm/cmpxchg.h>",
            "#include <asm/memtype.h>",
            "#include <asm/page.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kern_levels.h>",
            "#include <linux/hash.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/srcu.h>",
            "#include <linux/compiler.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/highmem.h>",
            "#include <linux/mm.h>",
            "#include <linux/string.h>",
            "#include <linux/types.h>",
            "#include <linux/kvm_host.h>",
            "#include \"cpuid.h\"",
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include \"x86.h\"",
            "#include \"mmu.h\"",
            "#include \"irq.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"paging_tmpl.h\"\n#include \"mmu_audit.c\"\n#include \"mmutrace.h\"\n#include <trace/events/kvm.h>\n#include \"trace.h\"\n#include <asm/kvm_page_track.h>\n#include <asm/vmx.h>\n#include <asm/io.h>\n#include <asm/e820/api.h>\n#include <asm/cmpxchg.h>\n#include <asm/memtype.h>\n#include <asm/page.h>\n#include <linux/kthread.h>\n#include <linux/kern_levels.h>\n#include <linux/hash.h>\n#include <linux/uaccess.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/srcu.h>\n#include <linux/compiler.h>\n#include <linux/hugetlb.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/moduleparam.h>\n#include <linux/highmem.h>\n#include <linux/mm.h>\n#include <linux/string.h>\n#include <linux/types.h>\n#include <linux/kvm_host.h>\n#include \"cpuid.h\"\n#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include \"x86.h\"\n#include \"mmu.h\"\n#include \"irq.h\"\n\nstatic union kvm_mmu_page_role\nkvm_mmu_calc_root_page_role(struct kvm_vcpu *vcpu);\n\nvoid kvm_mmu_reset_context(struct kvm_vcpu *vcpu)\n{\n\tkvm_mmu_unload(vcpu);\n\tkvm_init_mmu(vcpu, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_query_maxphyaddr",
          "args": [
            "vcpu"
          ],
          "line": 128
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_query_maxphyaddr",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "159-171",
          "snippet": "int cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000000, 0);\n\tif (!best || best->eax < 0x80000008)\n\t\tgoto not_found;\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best)\n\t\treturn best->eax & 0xff;\nnot_found:\n\treturn 36;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint cpuid_query_maxphyaddr(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000000, 0);\n\tif (!best || best->eax < 0x80000008)\n\t\tgoto not_found;\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best)\n\t\treturn best->eax & 0xff;\nnot_found:\n\treturn 36;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_entry_change",
          "args": [
            "best",
            "X86_FEATURE_MWAIT",
            "vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT"
          ],
          "line": 122
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_entry_change",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "157-171",
          "snippet": "static __always_inline void cpuid_entry_change(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t       unsigned int x86_feature,\n\t\t\t\t\t       bool set)\n{\n\tu32 *reg = cpuid_entry_get_reg(entry, x86_feature);\n\n\t/*\n\t * Open coded instead of using cpuid_entry_{clear,set}() to coerce the\n\t * compiler into using CMOV instead of Jcc when possible.\n\t */\n\tif (set)\n\t\t*reg |= __feature_bit(x86_feature);\n\telse\n\t\t*reg &= ~__feature_bit(x86_feature);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline void cpuid_entry_change(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t       unsigned int x86_feature,\n\t\t\t\t\t       bool set)\n{\n\tu32 *reg = cpuid_entry_get_reg(entry, x86_feature);\n\n\t/*\n\t * Open coded instead of using cpuid_entry_{clear,set}() to coerce the\n\t * compiler into using CMOV instead of Jcc when possible.\n\t */\n\tif (set)\n\t\t*reg |= __feature_bit(x86_feature);\n\telse\n\t\t*reg &= ~__feature_bit(x86_feature);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_find_cpuid_entry",
          "args": [
            "vcpu",
            "0x1",
            "0"
          ],
          "line": 120
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_find_cpuid_entry",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "903-917",
          "snippet": "struct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstruct kvm_cpuid_entry2 *kvm_find_cpuid_entry(struct kvm_vcpu *vcpu,\n\t\t\t\t\t      u32 function, u32 index)\n{\n\tstruct kvm_cpuid_entry2 *e;\n\tint i;\n\n\tfor (i = 0; i < vcpu->arch.cpuid_nent; ++i) {\n\t\te = &vcpu->arch.cpuid_entries[i];\n\n\t\tif (e->function == function && (e->index == index ||\n\t\t    !(e->flags & KVM_CPUID_FLAG_SIGNIFCANT_INDEX)))\n\t\t\treturn e;\n\t}\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_check_has_quirk",
          "args": [
            "vcpu->kvm",
            "KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT"
          ],
          "line": 119
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_check_has_quirk",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "233-236",
          "snippet": "static inline bool kvm_check_has_quirk(struct kvm *kvm, u64 quirk)\n{\n\treturn !(kvm->arch.disabled_quirks & quirk);\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline bool kvm_check_has_quirk(struct kvm *kvm, u64 quirk)\n{\n\treturn !(kvm->arch.disabled_quirks & quirk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_hlt_in_guest",
          "args": [
            "vcpu->kvm"
          ],
          "line": 115
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_hlt_in_guest",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/x86.h",
          "lines": "316-319",
          "snippet": "static inline bool kvm_hlt_in_guest(struct kvm *kvm)\n{\n\treturn kvm->arch.hlt_in_guest;\n}",
          "includes": [
            "#include \"kvm_emulate.h\"",
            "#include \"kvm_cache_regs.h\"",
            "#include <asm/pvclock.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kvm_emulate.h\"\n#include \"kvm_cache_regs.h\"\n#include <asm/pvclock.h>\n#include <linux/kvm_host.h>\n\nstatic inline bool kvm_hlt_in_guest(struct kvm *kvm)\n{\n\treturn kvm->arch.hlt_in_guest;\n}"
        }
      },
      {
        "call_info": {
          "callee": "xstate_required_size",
          "args": [
            "vcpu->arch.xcr0",
            "true"
          ],
          "line": 100
        },
        "resolved": true,
        "details": {
          "function_name": "xstate_required_size",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
          "lines": "34-53",
          "snippet": "static u32 xstate_required_size(u64 xstate_bv, bool compacted)\n{\n\tint feature_bit = 0;\n\tu32 ret = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\n\txstate_bv &= XFEATURE_MASK_EXTEND;\n\twhile (xstate_bv) {\n\t\tif (xstate_bv & 0x1) {\n\t\t        u32 eax, ebx, ecx, edx, offset;\n\t\t        cpuid_count(0xD, feature_bit, &eax, &ebx, &ecx, &edx);\n\t\t\toffset = compacted ? ret : ebx;\n\t\t\tret = max(ret, offset + eax);\n\t\t}\n\n\t\txstate_bv >>= 1;\n\t\tfeature_bit++;\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pmu.h\"",
            "#include \"trace.h\"",
            "#include \"mmu.h\"",
            "#include \"lapic.h\"",
            "#include \"cpuid.h\"",
            "#include <asm/fpu/xstate.h>",
            "#include <asm/user.h>",
            "#include <asm/processor.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic u32 xstate_required_size(u64 xstate_bv, bool compacted)\n{\n\tint feature_bit = 0;\n\tu32 ret = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\n\txstate_bv &= XFEATURE_MASK_EXTEND;\n\twhile (xstate_bv) {\n\t\tif (xstate_bv & 0x1) {\n\t\t        u32 eax, ebx, ecx, edx, offset;\n\t\t        cpuid_count(0xD, feature_bit, &eax, &ebx, &ecx, &edx);\n\t\t\toffset = compacted ? ret : ebx;\n\t\t\tret = max(ret, offset + eax);\n\t\t}\n\n\t\txstate_bv >>= 1;\n\t\tfeature_bit++;\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpuid_entry_has",
          "args": [
            "best",
            "X86_FEATURE_XSAVEC"
          ],
          "line": 99
        },
        "resolved": true,
        "details": {
          "function_name": "cpuid_entry_has",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.h",
          "lines": "135-139",
          "snippet": "static __always_inline bool cpuid_entry_has(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t    unsigned int x86_feature)\n{\n\treturn cpuid_entry_get(entry, x86_feature);\n}",
          "includes": [
            "#include <asm/processor.h>",
            "#include <asm/cpu.h>",
            "#include \"x86.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/processor.h>\n#include <asm/cpu.h>\n#include \"x86.h\"\n\nstatic __always_inline bool cpuid_entry_has(struct kvm_cpuid_entry2 *entry,\n\t\t\t\t\t    unsigned int x86_feature)\n{\n\treturn cpuid_entry_get(entry, x86_feature);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvm_read_cr4_bits",
          "args": [
            "vcpu",
            "X86_CR4_PKE"
          ],
          "line": 84
        },
        "resolved": true,
        "details": {
          "function_name": "kvm_read_cr4_bits",
          "container": null,
          "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/kvm_cache_regs.h",
          "lines": "129-135",
          "snippet": "static inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}",
          "includes": [
            "#include <linux/kvm_host.h>"
          ],
          "macros_used": [
            "#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kvm_host.h>\n\n#define KVM_POSSIBLE_CR4_GUEST_BITS\t\t\t\t  \\\n\t(X86_CR4_PVI | X86_CR4_DE | X86_CR4_PCE | X86_CR4_OSFXSR  \\\n\t | X86_CR4_OSXMMEXCPT | X86_CR4_LA57 | X86_CR4_PGE)\n\nstatic inline ulong kvm_read_cr4_bits(struct kvm_vcpu *vcpu, ulong mask)\n{\n\tulong tmask = mask & KVM_POSSIBLE_CR4_GUEST_BITS;\n\tif (tmask & vcpu->arch.cr4_guest_owned_bits)\n\t\tkvm_x86_ops.decache_cr4_guest_bits(vcpu);\n\treturn vcpu->arch.cr4 & mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_PKU"
          ],
          "line": 82
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "boot_cpu_has",
          "args": [
            "X86_FEATURE_XSAVE"
          ],
          "line": 67
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nint kvm_update_cpuid(struct kvm_vcpu *vcpu)\n{\n\tstruct kvm_cpuid_entry2 *best;\n\tstruct kvm_lapic *apic = vcpu->arch.apic;\n\n\tbest = kvm_find_cpuid_entry(vcpu, 1, 0);\n\tif (!best)\n\t\treturn 0;\n\n\t/* Update OSXSAVE bit */\n\tif (boot_cpu_has(X86_FEATURE_XSAVE) && best->function == 0x1)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSXSAVE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_OSXSAVE));\n\n\tcpuid_entry_change(best, X86_FEATURE_APIC,\n\t\t\t   vcpu->arch.apic_base & MSR_IA32_APICBASE_ENABLE);\n\n\tif (apic) {\n\t\tif (cpuid_entry_has(best, X86_FEATURE_TSC_DEADLINE_TIMER))\n\t\t\tapic->lapic_timer.timer_mode_mask = 3 << 17;\n\t\telse\n\t\t\tapic->lapic_timer.timer_mode_mask = 1 << 17;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 7, 0);\n\tif (best && boot_cpu_has(X86_FEATURE_PKU) && best->function == 0x7)\n\t\tcpuid_entry_change(best, X86_FEATURE_OSPKE,\n\t\t\t\t   kvm_read_cr4_bits(vcpu, X86_CR4_PKE));\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 0);\n\tif (!best) {\n\t\tvcpu->arch.guest_supported_xcr0 = 0;\n\t\tvcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\t} else {\n\t\tvcpu->arch.guest_supported_xcr0 =\n\t\t\t(best->eax | ((u64)best->edx << 32)) & supported_xcr0;\n\t\tvcpu->arch.guest_xstate_size = best->ebx =\n\t\t\txstate_required_size(vcpu->arch.xcr0, false);\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, 0xD, 1);\n\tif (best && (cpuid_entry_has(best, X86_FEATURE_XSAVES) ||\n\t\t     cpuid_entry_has(best, X86_FEATURE_XSAVEC)))\n\t\tbest->ebx = xstate_required_size(vcpu->arch.xcr0, true);\n\n\t/*\n\t * The existing code assumes virtual address is 48-bit or 57-bit in the\n\t * canonical address checks; exit if it is ever changed.\n\t */\n\tbest = kvm_find_cpuid_entry(vcpu, 0x80000008, 0);\n\tif (best) {\n\t\tint vaddr_bits = (best->eax & 0xff00) >> 8;\n\n\t\tif (vaddr_bits != 48 && vaddr_bits != 57 && vaddr_bits != 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\tbest = kvm_find_cpuid_entry(vcpu, KVM_CPUID_FEATURES, 0);\n\tif (kvm_hlt_in_guest(vcpu->kvm) && best &&\n\t\t(best->eax & (1 << KVM_FEATURE_PV_UNHALT)))\n\t\tbest->eax &= ~(1 << KVM_FEATURE_PV_UNHALT);\n\n\tif (!kvm_check_has_quirk(vcpu->kvm, KVM_X86_QUIRK_MISC_ENABLE_NO_MWAIT)) {\n\t\tbest = kvm_find_cpuid_entry(vcpu, 0x1, 0);\n\t\tif (best)\n\t\t\tcpuid_entry_change(best, X86_FEATURE_MWAIT,\n\t\t\t\t\t   vcpu->arch.ia32_misc_enable_msr &\n\t\t\t\t\t   MSR_IA32_MISC_ENABLE_MWAIT);\n\t}\n\n\t/* Update physical-address width */\n\tvcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);\n\tkvm_mmu_reset_context(vcpu);\n\n\tkvm_pmu_refresh(vcpu);\n\treturn 0;\n}"
  },
  {
    "function_name": "xstate_required_size",
    "container": null,
    "file": "output_repos_c_ICV/CVE-2021-3656/repo/arch/x86/kvm/cpuid.c",
    "lines": "34-53",
    "snippet": "static u32 xstate_required_size(u64 xstate_bv, bool compacted)\n{\n\tint feature_bit = 0;\n\tu32 ret = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\n\txstate_bv &= XFEATURE_MASK_EXTEND;\n\twhile (xstate_bv) {\n\t\tif (xstate_bv & 0x1) {\n\t\t        u32 eax, ebx, ecx, edx, offset;\n\t\t        cpuid_count(0xD, feature_bit, &eax, &ebx, &ecx, &edx);\n\t\t\toffset = compacted ? ret : ebx;\n\t\t\tret = max(ret, offset + eax);\n\t\t}\n\n\t\txstate_bv >>= 1;\n\t\tfeature_bit++;\n\t}\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pmu.h\"",
      "#include \"trace.h\"",
      "#include \"mmu.h\"",
      "#include \"lapic.h\"",
      "#include \"cpuid.h\"",
      "#include <asm/fpu/xstate.h>",
      "#include <asm/user.h>",
      "#include <asm/processor.h>",
      "#include <linux/sched/stat.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/export.h>",
      "#include <linux/kvm_host.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "max",
          "args": [
            "ret",
            "offset + eax"
          ],
          "line": 45
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpuid_count",
          "args": [
            "0xD",
            "feature_bit",
            "&eax",
            "&ebx",
            "&ecx",
            "&edx"
          ],
          "line": 43
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pmu.h\"\n#include \"trace.h\"\n#include \"mmu.h\"\n#include \"lapic.h\"\n#include \"cpuid.h\"\n#include <asm/fpu/xstate.h>\n#include <asm/user.h>\n#include <asm/processor.h>\n#include <linux/sched/stat.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/kvm_host.h>\n\nstatic u32 xstate_required_size(u64 xstate_bv, bool compacted)\n{\n\tint feature_bit = 0;\n\tu32 ret = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;\n\n\txstate_bv &= XFEATURE_MASK_EXTEND;\n\twhile (xstate_bv) {\n\t\tif (xstate_bv & 0x1) {\n\t\t        u32 eax, ebx, ecx, edx, offset;\n\t\t        cpuid_count(0xD, feature_bit, &eax, &ebx, &ecx, &edx);\n\t\t\toffset = compacted ? ret : ebx;\n\t\t\tret = max(ret, offset + eax);\n\t\t}\n\n\t\txstate_bv >>= 1;\n\t\tfeature_bit++;\n\t}\n\n\treturn ret;\n}"
  }
]