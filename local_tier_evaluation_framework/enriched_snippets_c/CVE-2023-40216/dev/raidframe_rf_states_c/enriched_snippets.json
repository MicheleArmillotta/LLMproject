[
  {
    "function_name": "rf_State_Cleanup",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "571-657",
    "snippet": "int \nrf_State_Cleanup(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_DagHeader_t *dag_h;\n\tRF_Etimer_t timer;\n\tint i;\n\n\tdesc->state++;\n\n\ttimer = tracerec->timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.dag_retry_us = RF_ETIMER_VAL_US(timer);\n\n\t/* the RAID I/O is complete.  Clean up. */\n\ttracerec->specific.user.dag_retry_us = 0;\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_DAG) {\n\t\t/* copy dags into paramDAG */\n\t\t*(desc->paramDAG) = desc->dagArray[0].dags;\n\t\tdag_h = *(desc->paramDAG);\n\t\tfor (i = 1; i < desc->numStripes; i++) {\n\t\t\t/* concatenate dags from remaining stripes */\n\t\t\tRF_ASSERT(dag_h);\n\t\t\twhile (dag_h->next)\n\t\t\t\tdag_h = dag_h->next;\n\t\t\tdag_h->next = desc->dagArray[i].dags;\n\t\t}\n\t} else {\n\t\t/* free all dags */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t}\n\t}\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us = RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS)) {\n\t\t\t\tRF_ASSERT_VALID_LOCKREQ(&asm_p->lockReqDesc);\n\t\t\t\trf_ReleaseStripeLock(raidPtr->lockTable, \n\t\t\t\t\t\t     asm_p->stripeID,\n\t\t\t\t    &asm_p->lockReqDesc);\n\t\t\t}\n\t\t\tif (asm_p->flags & RF_ASM_FLAGS_RECON_BLOCKED) {\n\t\t\t\trf_UnblockRecon(raidPtr, asm_p);\n\t\t\t}\n\t\t}\n\t}\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_ASM)\n\t\t*(desc->paramASM) = asmh;\n\telse\n\t\trf_FreeAccessStripeMap(asmh);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_STOP(desc->timer);\n\tRF_ETIMER_EVAL(desc->timer);\n\n\ttimer = desc->tracerec.tot_timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\tdesc->tracerec.total_us = RF_ETIMER_VAL_US(timer);\n\n\trf_LogTraceRec(raidPtr, tracerec);\n\n\tdesc->flags |= RF_DAG_ACCESS_COMPLETE;\n\n\treturn RF_FALSE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_LogTraceRec",
          "args": [
            "raidPtr",
            "tracerec"
          ],
          "line": 652
        },
        "resolved": true,
        "details": {
          "function_name": "rf_LogTraceRec",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_acctrace.c",
          "lines": "104-156",
          "snippet": "void \nrf_LogTraceRec(raid, rec)\n\tRF_Raid_t *raid;\n\tRF_AccTraceEntry_t *rec;\n{\n\tRF_AccTotals_t *acc = &raid->acc_totals;\n#if 0\n\tRF_Etimer_t timer;\n\tint     i, n;\n#endif\n\n\tif (rf_stopCollectingTraces || ((rf_maxNumTraces >= 0) && (numTracesSoFar >= rf_maxNumTraces)))\n\t\treturn;\n\n\t/* update AccTotals for this device */\n\tif (!raid->keep_acc_totals)\n\t\treturn;\n\tacc->num_log_ents++;\n\tif (rec->reconacc) {\n\t\tacc->recon_start_to_fetch_us += rec->specific.recon.recon_start_to_fetch_us;\n\t\tacc->recon_fetch_to_return_us += rec->specific.recon.recon_fetch_to_return_us;\n\t\tacc->recon_return_to_submit_us += rec->specific.recon.recon_return_to_submit_us;\n\t\tacc->recon_num_phys_ios += rec->num_phys_ios;\n\t\tacc->recon_phys_io_us += rec->phys_io_us;\n\t\tacc->recon_diskwait_us += rec->diskwait_us;\n\t\tacc->recon_reccount++;\n\t} else {\n\t\tRF_HIST_ADD(acc->tot_hist, rec->total_us);\n\t\tRF_HIST_ADD(acc->dw_hist, rec->diskwait_us);\n\t\t/* count of physical ios which are too big.  often due to\n\t\t * thermal recalibration */\n\t\t/* if bigvals > 0, you should probably ignore this data set */\n\t\tif (rec->diskwait_us > 100000)\n\t\t\tacc->bigvals++;\n\t\tacc->total_us += rec->total_us;\n\t\tacc->suspend_ovhd_us += rec->specific.user.suspend_ovhd_us;\n\t\tacc->map_us += rec->specific.user.map_us;\n\t\tacc->lock_us += rec->specific.user.lock_us;\n\t\tacc->dag_create_us += rec->specific.user.dag_create_us;\n\t\tacc->dag_retry_us += rec->specific.user.dag_retry_us;\n\t\tacc->exec_us += rec->specific.user.exec_us;\n\t\tacc->cleanup_us += rec->specific.user.cleanup_us;\n\t\tacc->exec_engine_us += rec->specific.user.exec_engine_us;\n\t\tacc->xor_us += rec->xor_us;\n\t\tacc->q_us += rec->q_us;\n\t\tacc->plog_us += rec->plog_us;\n\t\tacc->diskqueue_us += rec->diskqueue_us;\n\t\tacc->diskwait_us += rec->diskwait_us;\n\t\tacc->num_phys_ios += rec->num_phys_ios;\n\t\tacc->phys_io_us = rec->phys_io_us;\n\t\tacc->user_reccount++;\n\t}\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_hist.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include <sys/types.h>",
            "#include <sys/stat.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static long numTracesSoFar;",
            "int     rf_stopCollectingTraces;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_hist.h\"\n#include \"rf_etimer.h\"\n#include \"rf_raid.h\"\n#include \"rf_general.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_types.h\"\n#include \"rf_threadstuff.h\"\n#include <sys/types.h>\n#include <sys/stat.h>\n\nstatic long numTracesSoFar;\nint     rf_stopCollectingTraces;\n\nvoid \nrf_LogTraceRec(raid, rec)\n\tRF_Raid_t *raid;\n\tRF_AccTraceEntry_t *rec;\n{\n\tRF_AccTotals_t *acc = &raid->acc_totals;\n#if 0\n\tRF_Etimer_t timer;\n\tint     i, n;\n#endif\n\n\tif (rf_stopCollectingTraces || ((rf_maxNumTraces >= 0) && (numTracesSoFar >= rf_maxNumTraces)))\n\t\treturn;\n\n\t/* update AccTotals for this device */\n\tif (!raid->keep_acc_totals)\n\t\treturn;\n\tacc->num_log_ents++;\n\tif (rec->reconacc) {\n\t\tacc->recon_start_to_fetch_us += rec->specific.recon.recon_start_to_fetch_us;\n\t\tacc->recon_fetch_to_return_us += rec->specific.recon.recon_fetch_to_return_us;\n\t\tacc->recon_return_to_submit_us += rec->specific.recon.recon_return_to_submit_us;\n\t\tacc->recon_num_phys_ios += rec->num_phys_ios;\n\t\tacc->recon_phys_io_us += rec->phys_io_us;\n\t\tacc->recon_diskwait_us += rec->diskwait_us;\n\t\tacc->recon_reccount++;\n\t} else {\n\t\tRF_HIST_ADD(acc->tot_hist, rec->total_us);\n\t\tRF_HIST_ADD(acc->dw_hist, rec->diskwait_us);\n\t\t/* count of physical ios which are too big.  often due to\n\t\t * thermal recalibration */\n\t\t/* if bigvals > 0, you should probably ignore this data set */\n\t\tif (rec->diskwait_us > 100000)\n\t\t\tacc->bigvals++;\n\t\tacc->total_us += rec->total_us;\n\t\tacc->suspend_ovhd_us += rec->specific.user.suspend_ovhd_us;\n\t\tacc->map_us += rec->specific.user.map_us;\n\t\tacc->lock_us += rec->specific.user.lock_us;\n\t\tacc->dag_create_us += rec->specific.user.dag_create_us;\n\t\tacc->dag_retry_us += rec->specific.user.dag_retry_us;\n\t\tacc->exec_us += rec->specific.user.exec_us;\n\t\tacc->cleanup_us += rec->specific.user.cleanup_us;\n\t\tacc->exec_engine_us += rec->specific.user.exec_engine_us;\n\t\tacc->xor_us += rec->xor_us;\n\t\tacc->q_us += rec->q_us;\n\t\tacc->plog_us += rec->plog_us;\n\t\tacc->diskqueue_us += rec->diskqueue_us;\n\t\tacc->diskwait_us += rec->diskwait_us;\n\t\tacc->num_phys_ios += rec->num_phys_ios;\n\t\tacc->phys_io_us = rec->phys_io_us;\n\t\tacc->user_reccount++;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 650
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 649
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 648
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "desc->timer"
          ],
          "line": 645
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "desc->timer"
          ],
          "line": 644
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 642
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 641
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 640
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_FreeAccessStripeMap",
          "args": [
            "asmh"
          ],
          "line": 639
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeAccessStripeMap",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_map.c",
          "lines": "537-598",
          "snippet": "void \nrf_FreeAccessStripeMap(hdr)\n\tRF_AccessStripeMapHeader_t *hdr;\n{\n\tRF_AccessStripeMap_t *p, *pt = NULL;\n\tRF_PhysDiskAddr_t *pdp, *trailer, *pdaList = NULL, *pdaEnd = NULL;\n\tint     count = 0, t, asm_count = 0;\n\n\tfor (p = hdr->stripeMap; p; p = p->next) {\n\n\t\t/* link the 3 pda lists into the accumulating pda list */\n\n\t\tif (!pdaList)\n\t\t\tpdaList = p->qInfo;\n\t\telse\n\t\t\tpdaEnd->next = p->qInfo;\n\t\tfor (trailer = NULL, pdp = p->qInfo; pdp;) {\n\t\t\ttrailer = pdp;\n\t\t\tpdp = pdp->next;\n\t\t\tcount++;\n\t\t}\n\t\tif (trailer)\n\t\t\tpdaEnd = trailer;\n\n\t\tif (!pdaList)\n\t\t\tpdaList = p->parityInfo;\n\t\telse\n\t\t\tpdaEnd->next = p->parityInfo;\n\t\tfor (trailer = NULL, pdp = p->parityInfo; pdp;) {\n\t\t\ttrailer = pdp;\n\t\t\tpdp = pdp->next;\n\t\t\tcount++;\n\t\t}\n\t\tif (trailer)\n\t\t\tpdaEnd = trailer;\n\n\t\tif (!pdaList)\n\t\t\tpdaList = p->physInfo;\n\t\telse\n\t\t\tpdaEnd->next = p->physInfo;\n\t\tfor (trailer = NULL, pdp = p->physInfo; pdp;) {\n\t\t\ttrailer = pdp;\n\t\t\tpdp = pdp->next;\n\t\t\tcount++;\n\t\t}\n\t\tif (trailer)\n\t\t\tpdaEnd = trailer;\n\n\t\tpt = p;\n\t\tasm_count++;\n\t}\n\n\t/* debug only */\n\tfor (t = 0, pdp = pdaList; pdp; pdp = pdp->next)\n\t\tt++;\n\tRF_ASSERT(t == count);\n\n\tif (pdaList)\n\t\trf_FreePDAList(pdaList, pdaEnd, count);\n\trf_FreeASMList(hdr->stripeMap, pt, asm_count);\n\trf_FreeAccessStripeMapHeader(hdr);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_FreePDAList(RF_PhysDiskAddr_t * start, RF_PhysDiskAddr_t * end, int count);",
            "static void \nrf_FreeASMList(RF_AccessStripeMap_t * start, RF_AccessStripeMap_t * end,\n    int count);",
            "RF_PhysDiskAddr_t *\nrf_DuplicatePDA(pda)\n\tRF_PhysDiskAddr_t *pda;",
            "RF_PhysDiskAddr_t *\nrf_AllocPDAList(count)\n\tint     count;",
            "RF_AccessStripeMap_t *\nrf_AllocASMList(count)\n\tint     count;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic void rf_FreePDAList(RF_PhysDiskAddr_t * start, RF_PhysDiskAddr_t * end, int count);\nstatic void \nrf_FreeASMList(RF_AccessStripeMap_t * start, RF_AccessStripeMap_t * end,\n    int count);\nRF_PhysDiskAddr_t *\nrf_DuplicatePDA(pda)\n\tRF_PhysDiskAddr_t *pda;\nRF_PhysDiskAddr_t *\nrf_AllocPDAList(count)\n\tint     count;\nRF_AccessStripeMap_t *\nrf_AllocASMList(count)\n\tint     count;\n\nvoid \nrf_FreeAccessStripeMap(hdr)\n\tRF_AccessStripeMapHeader_t *hdr;\n{\n\tRF_AccessStripeMap_t *p, *pt = NULL;\n\tRF_PhysDiskAddr_t *pdp, *trailer, *pdaList = NULL, *pdaEnd = NULL;\n\tint     count = 0, t, asm_count = 0;\n\n\tfor (p = hdr->stripeMap; p; p = p->next) {\n\n\t\t/* link the 3 pda lists into the accumulating pda list */\n\n\t\tif (!pdaList)\n\t\t\tpdaList = p->qInfo;\n\t\telse\n\t\t\tpdaEnd->next = p->qInfo;\n\t\tfor (trailer = NULL, pdp = p->qInfo; pdp;) {\n\t\t\ttrailer = pdp;\n\t\t\tpdp = pdp->next;\n\t\t\tcount++;\n\t\t}\n\t\tif (trailer)\n\t\t\tpdaEnd = trailer;\n\n\t\tif (!pdaList)\n\t\t\tpdaList = p->parityInfo;\n\t\telse\n\t\t\tpdaEnd->next = p->parityInfo;\n\t\tfor (trailer = NULL, pdp = p->parityInfo; pdp;) {\n\t\t\ttrailer = pdp;\n\t\t\tpdp = pdp->next;\n\t\t\tcount++;\n\t\t}\n\t\tif (trailer)\n\t\t\tpdaEnd = trailer;\n\n\t\tif (!pdaList)\n\t\t\tpdaList = p->physInfo;\n\t\telse\n\t\t\tpdaEnd->next = p->physInfo;\n\t\tfor (trailer = NULL, pdp = p->physInfo; pdp;) {\n\t\t\ttrailer = pdp;\n\t\t\tpdp = pdp->next;\n\t\t\tcount++;\n\t\t}\n\t\tif (trailer)\n\t\t\tpdaEnd = trailer;\n\n\t\tpt = p;\n\t\tasm_count++;\n\t}\n\n\t/* debug only */\n\tfor (t = 0, pdp = pdaList; pdp; pdp = pdp->next)\n\t\tt++;\n\tRF_ASSERT(t == count);\n\n\tif (pdaList)\n\t\trf_FreePDAList(pdaList, pdaEnd, count);\n\trf_FreeASMList(hdr->stripeMap, pt, asm_count);\n\trf_FreeAccessStripeMapHeader(hdr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 635
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 633
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 632
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 631
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_UnblockRecon",
          "args": [
            "raidPtr",
            "asm_p"
          ],
          "line": 627
        },
        "resolved": true,
        "details": {
          "function_name": "rf_UnblockRecon",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_reconstruct.c",
          "lines": "1590-1646",
          "snippet": "int \nrf_UnblockRecon(raidPtr, asmap)\n\tRF_Raid_t *raidPtr;\n\tRF_AccessStripeMap_t *asmap;\n{\n\tRF_RowCol_t row = asmap->origRow;\n\tRF_StripeNum_t stripeID = asmap->stripeID;\n\tRF_ReconParityStripeStatus_t *pssPtr;\n\tRF_ReconUnitNum_t which_ru;\n\tRF_StripeNum_t psid;\n\tint     created = 0;\n\tRF_CallbackDesc_t *cb;\n\n\tpsid = rf_MapStripeIDToParityStripeID(&raidPtr->Layout, stripeID, &which_ru);\n\tRF_LOCK_PSS_MUTEX(raidPtr, row, psid);\n\tpssPtr = rf_LookupRUStatus(raidPtr, raidPtr->reconControl[row]->pssTable, psid, which_ru, RF_PSS_NONE, &created);\n\n\t/* When recon is forced, the pss desc can get deleted before we get\n\t * back to unblock recon. But, this can _only_ happen when recon is\n\t * forced. It would be good to put some kind of sanity check here, but\n\t * how to decide if recon was just forced or not? */\n\tif (!pssPtr) {\n\t\t/* printf(\"Warning: no pss descriptor upon unblock on psid %ld\n\t\t * RU %d\\n\",psid,which_ru); */\n\t\tif (rf_reconDebug || rf_pssDebug)\n\t\t\tprintf(\"Warning: no pss descriptor upon unblock on psid %ld RU %d\\n\", (long) psid, which_ru);\n\t\tgoto out;\n\t}\n\tpssPtr->blockCount--;\n\tDprintf3(\"raid%d: unblocking recon on psid %ld: blockcount is %d\\n\",\n\t\t raidPtr->raidid, psid, pssPtr->blockCount);\n\tif (pssPtr->blockCount == 0) {\t/* if recon blockage has been released */\n\n\t\t/* unblock recon before calling CauseReconEvent in case\n\t\t * CauseReconEvent causes us to try to issue a new read before\n\t\t * returning here. */\n\t\tpssPtr->flags &= ~RF_PSS_RECON_BLOCKED;\n\n\n\t\twhile (pssPtr->blockWaitList) {\t\n\t\t\t/* spin through the block-wait list and\n\t\t\t   release all the waiters */\n\t\t\tcb = pssPtr->blockWaitList;\n\t\t\tpssPtr->blockWaitList = cb->next;\n\t\t\tcb->next = NULL;\n\t\t\trf_CauseReconEvent(raidPtr, cb->row, cb->col, NULL, RF_REVENT_BLOCKCLEAR);\n\t\t\trf_FreeCallbackDesc(cb);\n\t\t}\n\t\tif (!(pssPtr->flags & RF_PSS_UNDER_RECON)) {\n\t\t\t/* if no recon was requested while recon was blocked */\n\t\t\trf_PSStatusDelete(raidPtr, raidPtr->reconControl[row]->pssTable, pssPtr);\n\t\t}\n\t}\nout:\n\tRF_UNLOCK_PSS_MUTEX(raidPtr, row, psid);\n\treturn (0);\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_reconbuffer.h\"",
            "#include \"rf_revent.h\"",
            "#include \"rf_reconutil.h\"",
            "#include \"rf_raid.h\"",
            "#include <sys/vnode.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/proc.h>",
            "#include <sys/systm.h>",
            "#include <sys/param.h>",
            "#include <sys/types.h>",
            "#include <sys/errno.h>",
            "#include <sys/buf.h>",
            "#include <sys/time.h>",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "int rf_CheckHeadSeparation(RF_Raid_t *, RF_PerDiskReconCtrl_t *, RF_RowCol_t, RF_RowCol_t, RF_HeadSepLimit_t, RF_ReconUnitNum_t);",
            "RF_RaidReconDesc_t *\nrf_AllocRaidReconDesc(raidPtr, row, col, spareDiskPtr, numDisksDone, srow, scol)\n\tRF_Raid_t *raidPtr;",
            "RF_RowCol_t row;",
            "RF_RowCol_t col;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_driver.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_etimer.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_reconbuffer.h\"\n#include \"rf_revent.h\"\n#include \"rf_reconutil.h\"\n#include \"rf_raid.h\"\n#include <sys/vnode.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/proc.h>\n#include <sys/systm.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <sys/errno.h>\n#include <sys/buf.h>\n#include <sys/time.h>\n#include \"rf_types.h\"\n\nint rf_CheckHeadSeparation(RF_Raid_t *, RF_PerDiskReconCtrl_t *, RF_RowCol_t, RF_RowCol_t, RF_HeadSepLimit_t, RF_ReconUnitNum_t);\nRF_RaidReconDesc_t *\nrf_AllocRaidReconDesc(raidPtr, row, col, spareDiskPtr, numDisksDone, srow, scol)\n\tRF_Raid_t *raidPtr;\nRF_RowCol_t row;\nRF_RowCol_t col;\n\nint \nrf_UnblockRecon(raidPtr, asmap)\n\tRF_Raid_t *raidPtr;\n\tRF_AccessStripeMap_t *asmap;\n{\n\tRF_RowCol_t row = asmap->origRow;\n\tRF_StripeNum_t stripeID = asmap->stripeID;\n\tRF_ReconParityStripeStatus_t *pssPtr;\n\tRF_ReconUnitNum_t which_ru;\n\tRF_StripeNum_t psid;\n\tint     created = 0;\n\tRF_CallbackDesc_t *cb;\n\n\tpsid = rf_MapStripeIDToParityStripeID(&raidPtr->Layout, stripeID, &which_ru);\n\tRF_LOCK_PSS_MUTEX(raidPtr, row, psid);\n\tpssPtr = rf_LookupRUStatus(raidPtr, raidPtr->reconControl[row]->pssTable, psid, which_ru, RF_PSS_NONE, &created);\n\n\t/* When recon is forced, the pss desc can get deleted before we get\n\t * back to unblock recon. But, this can _only_ happen when recon is\n\t * forced. It would be good to put some kind of sanity check here, but\n\t * how to decide if recon was just forced or not? */\n\tif (!pssPtr) {\n\t\t/* printf(\"Warning: no pss descriptor upon unblock on psid %ld\n\t\t * RU %d\\n\",psid,which_ru); */\n\t\tif (rf_reconDebug || rf_pssDebug)\n\t\t\tprintf(\"Warning: no pss descriptor upon unblock on psid %ld RU %d\\n\", (long) psid, which_ru);\n\t\tgoto out;\n\t}\n\tpssPtr->blockCount--;\n\tDprintf3(\"raid%d: unblocking recon on psid %ld: blockcount is %d\\n\",\n\t\t raidPtr->raidid, psid, pssPtr->blockCount);\n\tif (pssPtr->blockCount == 0) {\t/* if recon blockage has been released */\n\n\t\t/* unblock recon before calling CauseReconEvent in case\n\t\t * CauseReconEvent causes us to try to issue a new read before\n\t\t * returning here. */\n\t\tpssPtr->flags &= ~RF_PSS_RECON_BLOCKED;\n\n\n\t\twhile (pssPtr->blockWaitList) {\t\n\t\t\t/* spin through the block-wait list and\n\t\t\t   release all the waiters */\n\t\t\tcb = pssPtr->blockWaitList;\n\t\t\tpssPtr->blockWaitList = cb->next;\n\t\t\tcb->next = NULL;\n\t\t\trf_CauseReconEvent(raidPtr, cb->row, cb->col, NULL, RF_REVENT_BLOCKCLEAR);\n\t\t\trf_FreeCallbackDesc(cb);\n\t\t}\n\t\tif (!(pssPtr->flags & RF_PSS_UNDER_RECON)) {\n\t\t\t/* if no recon was requested while recon was blocked */\n\t\t\trf_PSStatusDelete(raidPtr, raidPtr->reconControl[row]->pssTable, pssPtr);\n\t\t}\n\t}\nout:\n\tRF_UNLOCK_PSS_MUTEX(raidPtr, row, psid);\n\treturn (0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_ReleaseStripeLock",
          "args": [
            "raidPtr->lockTable",
            "asm_p->stripeID",
            "&asm_p->lockReqDesc"
          ],
          "line": 622
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ReleaseStripeLock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_stripelocks.c",
          "lines": "332-563",
          "snippet": "void \nrf_ReleaseStripeLock(\n    RF_LockTableEntry_t * lockTable,\n    RF_StripeNum_t stripeID,\n    RF_LockReqDesc_t * lockReqDesc)\n{\n\tRF_StripeLockDesc_t *lockDesc, *ld_t;\n\tRF_LockReqDesc_t *lr, *lr_t, *callbacklist, *t;\n\tRF_IoType_t type = lockReqDesc->type;\n\tint     tid = 0, hashval = HASH_STRIPEID(stripeID);\n\tint     release_it, consider_it;\n\tRF_LockReqDesc_t *candidate, *candidate_t, *predecessor;\n\n\tRF_ASSERT(RF_IO_IS_R_OR_W(type));\n\n\tif (rf_stripeLockDebug) {\n\t\tif (stripeID == -1)\n\t\t\tDprintf1(\"[%d] Lock release supressed (stripeID == -1)\\n\", tid);\n\t\telse {\n\t\t\tDprintf8(\"[%d] Releasing stripe lock on stripe ID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2, lockTable);\n\t\t\tFLUSH;\n\t\t}\n\t}\n\tif (stripeID == -1)\n\t\treturn;\n\n\tRF_LOCK_MUTEX(lockTable[hashval].mutex);\n\n\t/* find the stripe lock descriptor */\n\tfor (ld_t = NULL, lockDesc = lockTable[hashval].descList; lockDesc; ld_t = lockDesc, lockDesc = lockDesc->next) {\n\t\tif (lockDesc->stripeID == stripeID)\n\t\t\tbreak;\n\t}\n\tRF_ASSERT(lockDesc);\t/* major error to release a lock that doesn't\n\t\t\t\t * exist */\n\n\t/* find the stripe lock request descriptor & delete it from the list */\n\tfor (lr_t = NULL, lr = lockDesc->granted; lr; lr_t = lr, lr = lr->next)\n\t\tif (lr == lockReqDesc)\n\t\t\tbreak;\n\n\tRF_ASSERT(lr && (lr == lockReqDesc));\t/* major error to release a\n\t\t\t\t\t\t * lock that hasn't been\n\t\t\t\t\t\t * granted */\n\tif (lr_t)\n\t\tlr_t->next = lr->next;\n\telse {\n\t\tRF_ASSERT(lr == lockDesc->granted);\n\t\tlockDesc->granted = lr->next;\n\t}\n\tlr->next = NULL;\n\n\tif (lockReqDesc->type == RF_IO_TYPE_WRITE)\n\t\tlockDesc->nWriters--;\n\n\t/* search through the waiters list to see if anyone needs to be woken\n\t * up. for each such descriptor in the wait list, we check it against\n\t * everything granted and against everything _in front_ of it in the\n\t * waiters queue.  If it conflicts with none of these, we release it.\n\t * \n\t * DON'T TOUCH THE TEMPLINK POINTER OF ANYTHING IN THE GRANTED LIST HERE.\n\t * This will roach the case where the callback tries to acquire a new\n\t * lock in the same stripe.  There are some asserts to try and detect\n\t * this.\n\t * \n\t * We apply 2 performance optimizations: (1) if releasing this lock\n\t * results in no more writers to this stripe, we just release\n\t * everybody waiting, since we place no restrictions on the number of\n\t * concurrent reads. (2) we consider as candidates for wakeup only\n\t * those waiters that have a range overlap with either the descriptor\n\t * being woken up or with something in the callbacklist (i.e.\n\t * something we've just now woken up). This allows us to avoid the\n\t * long evaluation for some descriptors. */\n\n\tcallbacklist = NULL;\n\tif (lockDesc->nWriters == 0) {\t/* performance tweak (1) */\n\t\twhile (lockDesc->waitersH) {\n\n\t\t\tlr = lockDesc->waitersH;\t/* delete from waiters\n\t\t\t\t\t\t\t * list */\n\t\t\tlockDesc->waitersH = lr->next;\n\n\t\t\tRF_ASSERT(lr->type == RF_IO_TYPE_READ);\n\n\t\t\tlr->next = lockDesc->granted;\t/* add to granted list */\n\t\t\tlockDesc->granted = lr;\n\n\t\t\tRF_ASSERT(!lr->templink);\n\t\t\tlr->templink = callbacklist;\t/* put on callback list\n\t\t\t\t\t\t\t * so that we'll invoke\n\t\t\t\t\t\t\t * callback below */\n\t\t\tcallbacklist = lr;\n\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\tDprintf8(\"[%d] No writers: granting lock stripe ID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t    tid, stripeID, lr->type, lr->start, lr->stop, lr->start2, lr->stop2, (unsigned long) lockTable);\n\t\t\t\tFLUSH;\n\t\t\t}\n\t\t}\n\t\tlockDesc->waitersT = NULL;\t/* we've purged the whole\n\t\t\t\t\t\t * waiters list */\n\n\t} else\n\t\tfor (candidate_t = NULL, candidate = lockDesc->waitersH; candidate;) {\n\n\t\t\t/* performance tweak (2) */\n\t\t\tconsider_it = 0;\n\t\t\tif (RANGE_OVERLAP(lockReqDesc, candidate))\n\t\t\t\tconsider_it = 1;\n\t\t\telse\n\t\t\t\tfor (t = callbacklist; t; t = t->templink)\n\t\t\t\t\tif (RANGE_OVERLAP(t, candidate)) {\n\t\t\t\t\t\tconsider_it = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\tif (!consider_it) {\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf8(\"[%d] No overlap: rejecting candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t\tcandidate_t = candidate;\n\t\t\t\tcandidate = candidate->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* we have a candidate for release.  check to make\n\t\t\t * sure it is not blocked by any granted locks */\n\t\t\trelease_it = 1;\n\t\t\tfor (predecessor = lockDesc->granted; predecessor; predecessor = predecessor->next) {\n\t\t\t\tif (STRIPELOCK_CONFLICT(candidate, predecessor)) {\n\t\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\t\tDprintf8(\"[%d] Conflicts with granted lock: rejecting candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\t\tFLUSH;\n\t\t\t\t\t}\n\t\t\t\t\trelease_it = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* now check to see if the candidate is blocked by any\n\t\t\t * waiters that occur before it it the wait queue */\n\t\t\tif (release_it)\n\t\t\t\tfor (predecessor = lockDesc->waitersH; predecessor != candidate; predecessor = predecessor->next) {\n\t\t\t\t\tif (STRIPELOCK_CONFLICT(candidate, predecessor)) {\n\t\t\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\t\t\tDprintf8(\"[%d] Conflicts with waiting lock: rejecting candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\t\t\tFLUSH;\n\t\t\t\t\t\t}\n\t\t\t\t\t\trelease_it = 0;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t/* release it if indicated */\n\t\t\tif (release_it) {\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf8(\"[%d] Granting lock to candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t\tif (candidate_t) {\n\t\t\t\t\tcandidate_t->next = candidate->next;\n\t\t\t\t\tif (lockDesc->waitersT == candidate)\n\t\t\t\t\t\tlockDesc->waitersT = candidate_t;\t/* cannot be waitersH\n\t\t\t\t\t\t\t\t\t\t\t * since candidate_t is\n\t\t\t\t\t\t\t\t\t\t\t * not NULL */\n\t\t\t\t} else {\n\t\t\t\t\tRF_ASSERT(candidate == lockDesc->waitersH);\n\t\t\t\t\tlockDesc->waitersH = lockDesc->waitersH->next;\n\t\t\t\t\tif (!lockDesc->waitersH)\n\t\t\t\t\t\tlockDesc->waitersT = NULL;\n\t\t\t\t}\n\t\t\t\tcandidate->next = lockDesc->granted;\t/* move it to the\n\t\t\t\t\t\t\t\t\t * granted list */\n\t\t\t\tlockDesc->granted = candidate;\n\n\t\t\t\tRF_ASSERT(!candidate->templink);\n\t\t\t\tcandidate->templink = callbacklist;\t/* put it on the list of\n\t\t\t\t\t\t\t\t\t * things to be called\n\t\t\t\t\t\t\t\t\t * after we release the\n\t\t\t\t\t\t\t\t\t * mutex */\n\t\t\t\tcallbacklist = candidate;\n\n\t\t\t\tif (!candidate_t)\n\t\t\t\t\tcandidate = lockDesc->waitersH;\n\t\t\t\telse\n\t\t\t\t\tcandidate = candidate_t->next;\t/* continue with the\n\t\t\t\t\t\t\t\t\t * rest of the list */\n\t\t\t} else {\n\t\t\t\tcandidate_t = candidate;\n\t\t\t\tcandidate = candidate->next;\t/* continue with the\n\t\t\t\t\t\t\t\t * rest of the list */\n\t\t\t}\n\t\t}\n\n\t/* delete the descriptor if no one is waiting or active */\n\tif (!lockDesc->granted && !lockDesc->waitersH) {\n\t\tRF_ASSERT(lockDesc->nWriters == 0);\n\t\tif (rf_stripeLockDebug) {\n\t\t\tDprintf3(\"[%d] Last lock released (table 0x%lx): deleting desc for stripeID %ld\\n\", tid, (unsigned long) lockTable, stripeID);\n\t\t\tFLUSH;\n\t\t}\n\t\tif (ld_t)\n\t\t\tld_t->next = lockDesc->next;\n\t\telse {\n\t\t\tRF_ASSERT(lockDesc == lockTable[hashval].descList);\n\t\t\tlockTable[hashval].descList = lockDesc->next;\n\t\t}\n\t\tFreeStripeLockDesc(lockDesc);\n\t\tlockDesc = NULL;/* only for the ASSERT below */\n\t}\n\tRF_UNLOCK_MUTEX(lockTable[hashval].mutex);\n\n\t/* now that we've unlocked the mutex, invoke the callback on all the\n\t * descriptors in the list */\n\tRF_ASSERT(!((callbacklist) && (!lockDesc)));\t/* if we deleted the\n\t\t\t\t\t\t\t * descriptor, we should\n\t\t\t\t\t\t\t * have no callbacks to\n\t\t\t\t\t\t\t * do */\n\tfor (candidate = callbacklist; candidate;) {\n\t\tt = candidate;\n\t\tcandidate = candidate->templink;\n\t\tt->templink = NULL;\n\t\t(t->cbFunc) (t->cbArg);\n\t}\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_stripelocks.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define FLUSH"
          ],
          "globals_used": [
            "static void AddToWaitersQueue(RF_LockTableEntry_t * lockTable, RF_StripeLockDesc_t * lockDesc, RF_LockReqDesc_t * lockReqDesc);",
            "static RF_StripeLockDesc_t *AllocStripeLockDesc(RF_StripeNum_t stripeID);",
            "static void PrintLockedStripes(RF_LockTableEntry_t * lockTable);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_driver.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_stripelocks.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n\n#define FLUSH\n\nstatic void AddToWaitersQueue(RF_LockTableEntry_t * lockTable, RF_StripeLockDesc_t * lockDesc, RF_LockReqDesc_t * lockReqDesc);\nstatic RF_StripeLockDesc_t *AllocStripeLockDesc(RF_StripeNum_t stripeID);\nstatic void PrintLockedStripes(RF_LockTableEntry_t * lockTable);\n\nvoid \nrf_ReleaseStripeLock(\n    RF_LockTableEntry_t * lockTable,\n    RF_StripeNum_t stripeID,\n    RF_LockReqDesc_t * lockReqDesc)\n{\n\tRF_StripeLockDesc_t *lockDesc, *ld_t;\n\tRF_LockReqDesc_t *lr, *lr_t, *callbacklist, *t;\n\tRF_IoType_t type = lockReqDesc->type;\n\tint     tid = 0, hashval = HASH_STRIPEID(stripeID);\n\tint     release_it, consider_it;\n\tRF_LockReqDesc_t *candidate, *candidate_t, *predecessor;\n\n\tRF_ASSERT(RF_IO_IS_R_OR_W(type));\n\n\tif (rf_stripeLockDebug) {\n\t\tif (stripeID == -1)\n\t\t\tDprintf1(\"[%d] Lock release supressed (stripeID == -1)\\n\", tid);\n\t\telse {\n\t\t\tDprintf8(\"[%d] Releasing stripe lock on stripe ID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2, lockTable);\n\t\t\tFLUSH;\n\t\t}\n\t}\n\tif (stripeID == -1)\n\t\treturn;\n\n\tRF_LOCK_MUTEX(lockTable[hashval].mutex);\n\n\t/* find the stripe lock descriptor */\n\tfor (ld_t = NULL, lockDesc = lockTable[hashval].descList; lockDesc; ld_t = lockDesc, lockDesc = lockDesc->next) {\n\t\tif (lockDesc->stripeID == stripeID)\n\t\t\tbreak;\n\t}\n\tRF_ASSERT(lockDesc);\t/* major error to release a lock that doesn't\n\t\t\t\t * exist */\n\n\t/* find the stripe lock request descriptor & delete it from the list */\n\tfor (lr_t = NULL, lr = lockDesc->granted; lr; lr_t = lr, lr = lr->next)\n\t\tif (lr == lockReqDesc)\n\t\t\tbreak;\n\n\tRF_ASSERT(lr && (lr == lockReqDesc));\t/* major error to release a\n\t\t\t\t\t\t * lock that hasn't been\n\t\t\t\t\t\t * granted */\n\tif (lr_t)\n\t\tlr_t->next = lr->next;\n\telse {\n\t\tRF_ASSERT(lr == lockDesc->granted);\n\t\tlockDesc->granted = lr->next;\n\t}\n\tlr->next = NULL;\n\n\tif (lockReqDesc->type == RF_IO_TYPE_WRITE)\n\t\tlockDesc->nWriters--;\n\n\t/* search through the waiters list to see if anyone needs to be woken\n\t * up. for each such descriptor in the wait list, we check it against\n\t * everything granted and against everything _in front_ of it in the\n\t * waiters queue.  If it conflicts with none of these, we release it.\n\t * \n\t * DON'T TOUCH THE TEMPLINK POINTER OF ANYTHING IN THE GRANTED LIST HERE.\n\t * This will roach the case where the callback tries to acquire a new\n\t * lock in the same stripe.  There are some asserts to try and detect\n\t * this.\n\t * \n\t * We apply 2 performance optimizations: (1) if releasing this lock\n\t * results in no more writers to this stripe, we just release\n\t * everybody waiting, since we place no restrictions on the number of\n\t * concurrent reads. (2) we consider as candidates for wakeup only\n\t * those waiters that have a range overlap with either the descriptor\n\t * being woken up or with something in the callbacklist (i.e.\n\t * something we've just now woken up). This allows us to avoid the\n\t * long evaluation for some descriptors. */\n\n\tcallbacklist = NULL;\n\tif (lockDesc->nWriters == 0) {\t/* performance tweak (1) */\n\t\twhile (lockDesc->waitersH) {\n\n\t\t\tlr = lockDesc->waitersH;\t/* delete from waiters\n\t\t\t\t\t\t\t * list */\n\t\t\tlockDesc->waitersH = lr->next;\n\n\t\t\tRF_ASSERT(lr->type == RF_IO_TYPE_READ);\n\n\t\t\tlr->next = lockDesc->granted;\t/* add to granted list */\n\t\t\tlockDesc->granted = lr;\n\n\t\t\tRF_ASSERT(!lr->templink);\n\t\t\tlr->templink = callbacklist;\t/* put on callback list\n\t\t\t\t\t\t\t * so that we'll invoke\n\t\t\t\t\t\t\t * callback below */\n\t\t\tcallbacklist = lr;\n\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\tDprintf8(\"[%d] No writers: granting lock stripe ID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t    tid, stripeID, lr->type, lr->start, lr->stop, lr->start2, lr->stop2, (unsigned long) lockTable);\n\t\t\t\tFLUSH;\n\t\t\t}\n\t\t}\n\t\tlockDesc->waitersT = NULL;\t/* we've purged the whole\n\t\t\t\t\t\t * waiters list */\n\n\t} else\n\t\tfor (candidate_t = NULL, candidate = lockDesc->waitersH; candidate;) {\n\n\t\t\t/* performance tweak (2) */\n\t\t\tconsider_it = 0;\n\t\t\tif (RANGE_OVERLAP(lockReqDesc, candidate))\n\t\t\t\tconsider_it = 1;\n\t\t\telse\n\t\t\t\tfor (t = callbacklist; t; t = t->templink)\n\t\t\t\t\tif (RANGE_OVERLAP(t, candidate)) {\n\t\t\t\t\t\tconsider_it = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\tif (!consider_it) {\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf8(\"[%d] No overlap: rejecting candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t\tcandidate_t = candidate;\n\t\t\t\tcandidate = candidate->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* we have a candidate for release.  check to make\n\t\t\t * sure it is not blocked by any granted locks */\n\t\t\trelease_it = 1;\n\t\t\tfor (predecessor = lockDesc->granted; predecessor; predecessor = predecessor->next) {\n\t\t\t\tif (STRIPELOCK_CONFLICT(candidate, predecessor)) {\n\t\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\t\tDprintf8(\"[%d] Conflicts with granted lock: rejecting candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\t\tFLUSH;\n\t\t\t\t\t}\n\t\t\t\t\trelease_it = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t/* now check to see if the candidate is blocked by any\n\t\t\t * waiters that occur before it it the wait queue */\n\t\t\tif (release_it)\n\t\t\t\tfor (predecessor = lockDesc->waitersH; predecessor != candidate; predecessor = predecessor->next) {\n\t\t\t\t\tif (STRIPELOCK_CONFLICT(candidate, predecessor)) {\n\t\t\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\t\t\tDprintf8(\"[%d] Conflicts with waiting lock: rejecting candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\t\t\tFLUSH;\n\t\t\t\t\t\t}\n\t\t\t\t\t\trelease_it = 0;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t/* release it if indicated */\n\t\t\tif (release_it) {\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf8(\"[%d] Granting lock to candidate stripeID %ld, type %c range %ld-%ld %ld-%ld table 0x%lx\\n\",\n\t\t\t\t\t    tid, stripeID, candidate->type, candidate->start, candidate->stop, candidate->start2, candidate->stop2,\n\t\t\t\t\t    (unsigned long) lockTable);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t\tif (candidate_t) {\n\t\t\t\t\tcandidate_t->next = candidate->next;\n\t\t\t\t\tif (lockDesc->waitersT == candidate)\n\t\t\t\t\t\tlockDesc->waitersT = candidate_t;\t/* cannot be waitersH\n\t\t\t\t\t\t\t\t\t\t\t * since candidate_t is\n\t\t\t\t\t\t\t\t\t\t\t * not NULL */\n\t\t\t\t} else {\n\t\t\t\t\tRF_ASSERT(candidate == lockDesc->waitersH);\n\t\t\t\t\tlockDesc->waitersH = lockDesc->waitersH->next;\n\t\t\t\t\tif (!lockDesc->waitersH)\n\t\t\t\t\t\tlockDesc->waitersT = NULL;\n\t\t\t\t}\n\t\t\t\tcandidate->next = lockDesc->granted;\t/* move it to the\n\t\t\t\t\t\t\t\t\t * granted list */\n\t\t\t\tlockDesc->granted = candidate;\n\n\t\t\t\tRF_ASSERT(!candidate->templink);\n\t\t\t\tcandidate->templink = callbacklist;\t/* put it on the list of\n\t\t\t\t\t\t\t\t\t * things to be called\n\t\t\t\t\t\t\t\t\t * after we release the\n\t\t\t\t\t\t\t\t\t * mutex */\n\t\t\t\tcallbacklist = candidate;\n\n\t\t\t\tif (!candidate_t)\n\t\t\t\t\tcandidate = lockDesc->waitersH;\n\t\t\t\telse\n\t\t\t\t\tcandidate = candidate_t->next;\t/* continue with the\n\t\t\t\t\t\t\t\t\t * rest of the list */\n\t\t\t} else {\n\t\t\t\tcandidate_t = candidate;\n\t\t\t\tcandidate = candidate->next;\t/* continue with the\n\t\t\t\t\t\t\t\t * rest of the list */\n\t\t\t}\n\t\t}\n\n\t/* delete the descriptor if no one is waiting or active */\n\tif (!lockDesc->granted && !lockDesc->waitersH) {\n\t\tRF_ASSERT(lockDesc->nWriters == 0);\n\t\tif (rf_stripeLockDebug) {\n\t\t\tDprintf3(\"[%d] Last lock released (table 0x%lx): deleting desc for stripeID %ld\\n\", tid, (unsigned long) lockTable, stripeID);\n\t\t\tFLUSH;\n\t\t}\n\t\tif (ld_t)\n\t\t\tld_t->next = lockDesc->next;\n\t\telse {\n\t\t\tRF_ASSERT(lockDesc == lockTable[hashval].descList);\n\t\t\tlockTable[hashval].descList = lockDesc->next;\n\t\t}\n\t\tFreeStripeLockDesc(lockDesc);\n\t\tlockDesc = NULL;/* only for the ASSERT below */\n\t}\n\tRF_UNLOCK_MUTEX(lockTable[hashval].mutex);\n\n\t/* now that we've unlocked the mutex, invoke the callback on all the\n\t * descriptors in the list */\n\tRF_ASSERT(!((callbacklist) && (!lockDesc)));\t/* if we deleted the\n\t\t\t\t\t\t\t * descriptor, we should\n\t\t\t\t\t\t\t * have no callbacks to\n\t\t\t\t\t\t\t * do */\n\tfor (candidate = callbacklist; candidate;) {\n\t\tt = candidate;\n\t\tcandidate = candidate->templink;\n\t\tt->templink = NULL;\n\t\t(t->cbFunc) (t->cbArg);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT_VALID_LOCKREQ",
          "args": [
            "&asm_p->lockReqDesc"
          ],
          "line": 621
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 615
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 613
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 612
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_FreeDAG",
          "args": [
            "desc->dagArray[i].dags"
          ],
          "line": 607
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeDAGHeader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_dagutils.c",
          "lines": "257-261",
          "snippet": "void \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_PrintDAG(RF_DagHeader_t *);",
            "static void rf_ValidateVisitedBits(RF_DagHeader_t *);",
            "static RF_FreeList_t *rf_dagh_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_map.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void rf_PrintDAG(RF_DagHeader_t *);\nstatic void rf_ValidateVisitedBits(RF_DagHeader_t *);\nstatic RF_FreeList_t *rf_dagh_freelist;\n\nvoid \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "dag_h"
          ],
          "line": 599
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 592
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 587
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 586
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 585
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Cleanup(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_DagHeader_t *dag_h;\n\tRF_Etimer_t timer;\n\tint i;\n\n\tdesc->state++;\n\n\ttimer = tracerec->timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.dag_retry_us = RF_ETIMER_VAL_US(timer);\n\n\t/* the RAID I/O is complete.  Clean up. */\n\ttracerec->specific.user.dag_retry_us = 0;\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_DAG) {\n\t\t/* copy dags into paramDAG */\n\t\t*(desc->paramDAG) = desc->dagArray[0].dags;\n\t\tdag_h = *(desc->paramDAG);\n\t\tfor (i = 1; i < desc->numStripes; i++) {\n\t\t\t/* concatenate dags from remaining stripes */\n\t\t\tRF_ASSERT(dag_h);\n\t\t\twhile (dag_h->next)\n\t\t\t\tdag_h = dag_h->next;\n\t\t\tdag_h->next = desc->dagArray[i].dags;\n\t\t}\n\t} else {\n\t\t/* free all dags */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t}\n\t}\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us = RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS)) {\n\t\t\t\tRF_ASSERT_VALID_LOCKREQ(&asm_p->lockReqDesc);\n\t\t\t\trf_ReleaseStripeLock(raidPtr->lockTable, \n\t\t\t\t\t\t     asm_p->stripeID,\n\t\t\t\t    &asm_p->lockReqDesc);\n\t\t\t}\n\t\t\tif (asm_p->flags & RF_ASM_FLAGS_RECON_BLOCKED) {\n\t\t\t\trf_UnblockRecon(raidPtr, asm_p);\n\t\t\t}\n\t\t}\n\t}\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_ASM)\n\t\t*(desc->paramASM) = asmh;\n\telse\n\t\trf_FreeAccessStripeMap(asmh);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_STOP(desc->timer);\n\tRF_ETIMER_EVAL(desc->timer);\n\n\ttimer = desc->tracerec.tot_timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\tdesc->tracerec.total_us = RF_ETIMER_VAL_US(timer);\n\n\trf_LogTraceRec(raidPtr, tracerec);\n\n\tdesc->flags |= RF_DAG_ACCESS_COMPLETE;\n\n\treturn RF_FALSE;\n}"
  },
  {
    "function_name": "rf_State_ProcessDAG",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "513-569",
    "snippet": "int \nrf_State_ProcessDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_DagHeader_t *dag_h;\n\tint     i, j, done = RF_TRUE;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\tRF_Etimer_t timer;\n\n\t/* check to see if this is the last dag */\n\tfor (i = 0; i < desc->numStripes; i++)\n\t\tif (dagArray[i].numDags != dagArray[i].numDagsDone)\n\t\t\tdone = RF_FALSE;\n\n\tif (done) {\n\t\tif (desc->status) {\n\t\t\t/* a dag failed, retry */\n\t\t\tRF_ETIMER_START(timer);\n\t\t\t/* free all dags */\n\t\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t\t}\n\t\t\trf_MarkFailuresInASMList(raidPtr, asmh);\n\t\t\t/* back up to rf_State_CreateDAG */\n\t\t\tdesc->state = desc->state - 2;\n\t\t\treturn RF_FALSE;\n\t\t} else {\n\t\t\t/* move on to rf_State_Cleanup */\n\t\t\tdesc->state++;\n\t\t}\n\t\treturn RF_FALSE;\n\t} else {\n\t\t/* more dags to execute */\n\t\t/* see if any are ready to be fired.  if so, fire them */\n\t\t/* don't fire the initial dag in a list, it's fired in\n\t\t * rf_State_ExecuteDAG */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tif ((dagArray[i].numDagsDone < dagArray[i].numDags)\n\t\t\t    && (dagArray[i].numDagsDone == dagArray[i].numDagsFired)\n\t\t\t    && (dagArray[i].numDagsFired > 0)) {\n\t\t\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t\t\t/* fire next dag in this stripe */\n\t\t\t\t/* first, skip to next dag awaiting execution */\n\t\t\t\tdag_h = dagArray[i].dags;\n\t\t\t\tfor (j = 0; j < dagArray[i].numDagsDone; j++)\n\t\t\t\t\tdag_h = dag_h->next;\n\t\t\t\tdagArray[i].numDagsFired++;\n\t\t\t\t/* XXX and again we pass a different function\n\t\t\t\t * pointer.. GO */\n\t\t\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess,\n\t\t\t\t    &dagArray[i]);\n\t\t\t}\n\t\t}\n\t\treturn RF_TRUE;\n\t}\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_DispatchDAG",
          "args": [
            "dag_h",
            "(void (*) (void *)) rf_ContinueDagAccess",
            "&dagArray[i]"
          ],
          "line": 563
        },
        "resolved": true,
        "details": {
          "function_name": "rf_DispatchDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_engine.c",
          "lines": "668-695",
          "snippet": "int \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_raid.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_dag.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_raid.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_engine.h\"\n#include \"rf_dag.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n\nint \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "dagArray[i].tracerec.timer"
          ],
          "line": 554
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MarkFailuresInASMList",
          "args": [
            "raidPtr",
            "asmh"
          ],
          "line": 536
        },
        "resolved": true,
        "details": {
          "function_name": "rf_MarkFailuresInASMList",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_map.c",
          "lines": "256-291",
          "snippet": "void \nrf_MarkFailuresInASMList(raidPtr, asm_h)\n\tRF_Raid_t *raidPtr;\n\tRF_AccessStripeMapHeader_t *asm_h;\n{\n\tRF_RaidDisk_t **disks = raidPtr->Disks;\n\tRF_AccessStripeMap_t *asmap;\n\tRF_PhysDiskAddr_t *pda;\n\n\tfor (asmap = asm_h->stripeMap; asmap; asmap = asmap->next) {\n\t\tasmap->numDataFailed = asmap->numParityFailed = asmap->numQFailed = 0;\n\t\tasmap->numFailedPDAs = 0;\n\t\tbzero((char *) asmap->failedPDAs,\n\t\t    RF_MAX_FAILED_PDA * sizeof(RF_PhysDiskAddr_t *));\n\t\tfor (pda = asmap->physInfo; pda; pda = pda->next) {\n\t\t\tif (RF_DEAD_DISK(disks[pda->row][pda->col].status)) {\n\t\t\t\tprintf(\"DEAD DISK BOGUSLY DETECTED!!\\n\");\n\t\t\t\tasmap->numDataFailed++;\n\t\t\t\tasmap->failedPDAs[asmap->numFailedPDAs] = pda;\n\t\t\t\tasmap->numFailedPDAs++;\n\t\t\t}\n\t\t}\n\t\tpda = asmap->parityInfo;\n\t\tif (pda && RF_DEAD_DISK(disks[pda->row][pda->col].status)) {\n\t\t\tasmap->numParityFailed++;\n\t\t\tasmap->failedPDAs[asmap->numFailedPDAs] = pda;\n\t\t\tasmap->numFailedPDAs++;\n\t\t}\n\t\tpda = asmap->qInfo;\n\t\tif (pda && RF_DEAD_DISK(disks[pda->row][pda->col].status)) {\n\t\t\tasmap->numQFailed++;\n\t\t\tasmap->failedPDAs[asmap->numFailedPDAs] = pda;\n\t\t\tasmap->numFailedPDAs++;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "RF_AccessStripeMapHeader_t *\nrf_MapAccess(raidPtr, raidAddress, numBlocks, buffer, remap)\n\tRF_Raid_t *raidPtr;",
            "RF_AccessStripeMap_t *\nrf_DuplicateASM(asmap)\n\tRF_AccessStripeMap_t *asmap;",
            "RF_PhysDiskAddr_t *\nrf_DuplicatePDA(pda)\n\tRF_PhysDiskAddr_t *pda;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nRF_AccessStripeMapHeader_t *\nrf_MapAccess(raidPtr, raidAddress, numBlocks, buffer, remap)\n\tRF_Raid_t *raidPtr;\nRF_AccessStripeMap_t *\nrf_DuplicateASM(asmap)\n\tRF_AccessStripeMap_t *asmap;\nRF_PhysDiskAddr_t *\nrf_DuplicatePDA(pda)\n\tRF_PhysDiskAddr_t *pda;\n\nvoid \nrf_MarkFailuresInASMList(raidPtr, asm_h)\n\tRF_Raid_t *raidPtr;\n\tRF_AccessStripeMapHeader_t *asm_h;\n{\n\tRF_RaidDisk_t **disks = raidPtr->Disks;\n\tRF_AccessStripeMap_t *asmap;\n\tRF_PhysDiskAddr_t *pda;\n\n\tfor (asmap = asm_h->stripeMap; asmap; asmap = asmap->next) {\n\t\tasmap->numDataFailed = asmap->numParityFailed = asmap->numQFailed = 0;\n\t\tasmap->numFailedPDAs = 0;\n\t\tbzero((char *) asmap->failedPDAs,\n\t\t    RF_MAX_FAILED_PDA * sizeof(RF_PhysDiskAddr_t *));\n\t\tfor (pda = asmap->physInfo; pda; pda = pda->next) {\n\t\t\tif (RF_DEAD_DISK(disks[pda->row][pda->col].status)) {\n\t\t\t\tprintf(\"DEAD DISK BOGUSLY DETECTED!!\\n\");\n\t\t\t\tasmap->numDataFailed++;\n\t\t\t\tasmap->failedPDAs[asmap->numFailedPDAs] = pda;\n\t\t\t\tasmap->numFailedPDAs++;\n\t\t\t}\n\t\t}\n\t\tpda = asmap->parityInfo;\n\t\tif (pda && RF_DEAD_DISK(disks[pda->row][pda->col].status)) {\n\t\t\tasmap->numParityFailed++;\n\t\t\tasmap->failedPDAs[asmap->numFailedPDAs] = pda;\n\t\t\tasmap->numFailedPDAs++;\n\t\t}\n\t\tpda = asmap->qInfo;\n\t\tif (pda && RF_DEAD_DISK(disks[pda->row][pda->col].status)) {\n\t\t\tasmap->numQFailed++;\n\t\t\tasmap->failedPDAs[asmap->numFailedPDAs] = pda;\n\t\t\tasmap->numFailedPDAs++;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreeDAG",
          "args": [
            "desc->dagArray[i].dags"
          ],
          "line": 534
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeDAGHeader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_dagutils.c",
          "lines": "257-261",
          "snippet": "void \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_PrintDAG(RF_DagHeader_t *);",
            "static void rf_ValidateVisitedBits(RF_DagHeader_t *);",
            "static RF_FreeList_t *rf_dagh_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_map.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void rf_PrintDAG(RF_DagHeader_t *);\nstatic void rf_ValidateVisitedBits(RF_DagHeader_t *);\nstatic RF_FreeList_t *rf_dagh_freelist;\n\nvoid \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 531
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_ProcessDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_DagHeader_t *dag_h;\n\tint     i, j, done = RF_TRUE;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\tRF_Etimer_t timer;\n\n\t/* check to see if this is the last dag */\n\tfor (i = 0; i < desc->numStripes; i++)\n\t\tif (dagArray[i].numDags != dagArray[i].numDagsDone)\n\t\t\tdone = RF_FALSE;\n\n\tif (done) {\n\t\tif (desc->status) {\n\t\t\t/* a dag failed, retry */\n\t\t\tRF_ETIMER_START(timer);\n\t\t\t/* free all dags */\n\t\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t\t}\n\t\t\trf_MarkFailuresInASMList(raidPtr, asmh);\n\t\t\t/* back up to rf_State_CreateDAG */\n\t\t\tdesc->state = desc->state - 2;\n\t\t\treturn RF_FALSE;\n\t\t} else {\n\t\t\t/* move on to rf_State_Cleanup */\n\t\t\tdesc->state++;\n\t\t}\n\t\treturn RF_FALSE;\n\t} else {\n\t\t/* more dags to execute */\n\t\t/* see if any are ready to be fired.  if so, fire them */\n\t\t/* don't fire the initial dag in a list, it's fired in\n\t\t * rf_State_ExecuteDAG */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tif ((dagArray[i].numDagsDone < dagArray[i].numDags)\n\t\t\t    && (dagArray[i].numDagsDone == dagArray[i].numDagsFired)\n\t\t\t    && (dagArray[i].numDagsFired > 0)) {\n\t\t\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t\t\t/* fire next dag in this stripe */\n\t\t\t\t/* first, skip to next dag awaiting execution */\n\t\t\t\tdag_h = dagArray[i].dags;\n\t\t\t\tfor (j = 0; j < dagArray[i].numDagsDone; j++)\n\t\t\t\t\tdag_h = dag_h->next;\n\t\t\t\tdagArray[i].numDagsFired++;\n\t\t\t\t/* XXX and again we pass a different function\n\t\t\t\t * pointer.. GO */\n\t\t\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess,\n\t\t\t\t    &dagArray[i]);\n\t\t\t}\n\t\t}\n\t\treturn RF_TRUE;\n\t}\n}"
  },
  {
    "function_name": "rf_State_ExecuteDAG",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "474-505",
    "snippet": "int \nrf_State_ExecuteDAG(RF_RaidAccessDesc_t * desc)\n{\n\tint     i;\n\tRF_DagHeader_t *dag_h;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\n\t/* next state is always rf_State_ProcessDAG important to do this\n\t * before firing the first dag (it may finish before we leave this\n\t * routine) */\n\tdesc->state++;\n\n\t/* sweep dag array, a stripe at a time, firing the first dag in each\n\t * stripe */\n\tfor (i = 0; i < desc->numStripes; i++) {\n\t\tRF_ASSERT(dagArray[i].numDags > 0);\n\t\tRF_ASSERT(dagArray[i].numDagsDone == 0);\n\t\tRF_ASSERT(dagArray[i].numDagsFired == 0);\n\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t/* fire first dag in this stripe */\n\t\tdag_h = dagArray[i].dags;\n\t\tRF_ASSERT(dag_h);\n\t\tdagArray[i].numDagsFired++;\n\t\t/* XXX Yet another case where we pass in a conflicting\n\t\t * function pointer :-(  XXX  GO */\n\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess, &dagArray[i]);\n\t}\n\n\t/* the DAG will always call the callback, even if there was no\n\t * blocking, so we are always suspended in this state */\n\treturn RF_TRUE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_DispatchDAG",
          "args": [
            "dag_h",
            "(void (*) (void *)) rf_ContinueDagAccess",
            "&dagArray[i]"
          ],
          "line": 499
        },
        "resolved": true,
        "details": {
          "function_name": "rf_DispatchDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_engine.c",
          "lines": "668-695",
          "snippet": "int \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_raid.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_dag.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_raid.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_engine.h\"\n#include \"rf_dag.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n\nint \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "dag_h"
          ],
          "line": 495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "dagArray[i].tracerec.timer"
          ],
          "line": 492
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "dagArray[i].numDagsFired == 0"
          ],
          "line": 491
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "dagArray[i].numDagsDone == 0"
          ],
          "line": 490
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "dagArray[i].numDags > 0"
          ],
          "line": 489
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_ExecuteDAG(RF_RaidAccessDesc_t * desc)\n{\n\tint     i;\n\tRF_DagHeader_t *dag_h;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\n\t/* next state is always rf_State_ProcessDAG important to do this\n\t * before firing the first dag (it may finish before we leave this\n\t * routine) */\n\tdesc->state++;\n\n\t/* sweep dag array, a stripe at a time, firing the first dag in each\n\t * stripe */\n\tfor (i = 0; i < desc->numStripes; i++) {\n\t\tRF_ASSERT(dagArray[i].numDags > 0);\n\t\tRF_ASSERT(dagArray[i].numDagsDone == 0);\n\t\tRF_ASSERT(dagArray[i].numDagsFired == 0);\n\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t/* fire first dag in this stripe */\n\t\tdag_h = dagArray[i].dags;\n\t\tRF_ASSERT(dag_h);\n\t\tdagArray[i].numDagsFired++;\n\t\t/* XXX Yet another case where we pass in a conflicting\n\t\t * function pointer :-(  XXX  GO */\n\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess, &dagArray[i]);\n\t}\n\n\t/* the DAG will always call the callback, even if there was no\n\t * blocking, so we are always suspended in this state */\n\treturn RF_TRUE;\n}"
  },
  {
    "function_name": "rf_State_CreateDAG",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "421-464",
    "snippet": "int \nrf_State_CreateDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tRF_DagHeader_t *dag_h;\n\tint     i, selectStatus;\n\n\t/* generate a dag for the access, and fire it off.  When the dag\n\t * completes, we'll get re-invoked in the next state. */\n\tRF_ETIMER_START(timer);\n\t/* SelectAlgorithm returns one or more dags */\n\tselectStatus = rf_SelectAlgorithm(desc, desc->flags | RF_DAG_SUPPRESS_LOCKS);\n\tif (rf_printDAGsDebug)\n\t\tfor (i = 0; i < desc->numStripes; i++)\n\t\t\trf_PrintDAGList(desc->dagArray[i].dags);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\t/* update time to create all dags */\n\ttracerec->specific.user.dag_create_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->status = 0;\t/* good status */\n\n\tif (selectStatus) {\n\t\t/* failed to create a dag */\n\t\t/* this happens when there are too many faults or incomplete\n\t\t * dag libraries */\n\t\tprintf(\"[Failed to create a DAG\\n]\");\n\t\tRF_PANIC();\n\t} else {\n\t\t/* bind dags to desc */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tdag_h = desc->dagArray[i].dags;\n\t\t\twhile (dag_h) {\n\t\t\t\tdag_h->bp = (struct buf *) desc->bp;\n\t\t\t\tdag_h->tracerec = tracerec;\n\t\t\t\tdag_h = dag_h->next;\n\t\t\t}\n\t\t}\n\t\tdesc->flags |= RF_DAG_DISPATCH_RETURNED;\n\t\tdesc->state++;\t/* next state should be rf_State_ExecuteDAG */\n\t}\n\treturn RF_FALSE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_PANIC",
          "args": [],
          "line": 449
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[Failed to create a DAG\\n]\""
          ],
          "line": 448
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 440
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 438
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 437
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_PrintDAGList",
          "args": [
            "desc->dagArray[i].dags"
          ],
          "line": 436
        },
        "resolved": true,
        "details": {
          "function_name": "rf_PrintDAGList",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_dagutils.c",
          "lines": "509-519",
          "snippet": "void \nrf_PrintDAGList(RF_DagHeader_t * dag_h)\n{\n\tint     i = 0;\n\n\tfor (; dag_h; dag_h = dag_h->next) {\n\t\trf_AssignNodeNums(dag_h);\n\t\tprintf(\"\\n\\nDAG %d IN LIST:\\n\", i++);\n\t\trf_PrintDAG(dag_h);\n\t}\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_PrintDAG(RF_DagHeader_t *);",
            "static void rf_ValidateVisitedBits(RF_DagHeader_t *);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_map.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void rf_PrintDAG(RF_DagHeader_t *);\nstatic void rf_ValidateVisitedBits(RF_DagHeader_t *);\n\nvoid \nrf_PrintDAGList(RF_DagHeader_t * dag_h)\n{\n\tint     i = 0;\n\n\tfor (; dag_h; dag_h = dag_h->next) {\n\t\trf_AssignNodeNums(dag_h);\n\t\tprintf(\"\\n\\nDAG %d IN LIST:\\n\", i++);\n\t\trf_PrintDAG(dag_h);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_SelectAlgorithm",
          "args": [
            "desc",
            "desc->flags | RF_DAG_SUPPRESS_LOCKS"
          ],
          "line": 433
        },
        "resolved": true,
        "details": {
          "function_name": "rf_SelectAlgorithm",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_aselect.c",
          "lines": "205-495",
          "snippet": "int \nrf_SelectAlgorithm(desc, flags)\n\tRF_RaidAccessDesc_t *desc;\n\tRF_RaidAccessFlags_t flags;\n{\n\tRF_AccessStripeMapHeader_t *asm_h = desc->asmap;\n\tRF_IoType_t type = desc->type;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tvoid   *bp = desc->bp;\n\n\tRF_AccessStripeMap_t *asmap = asm_h->stripeMap;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_DagHeader_t *dag_h = NULL, *tempdag_h, *lastdag_h;\n\tint     i, j, k;\n\tRF_VoidFuncPtr *stripeFuncs, normalStripeFuncs[MAXNSTRIPES];\n\tRF_AccessStripeMap_t *asm_up, *asm_bp;\n\tRF_AccessStripeMapHeader_t ***asmh_u, *endASMList;\n\tRF_AccessStripeMapHeader_t ***asmh_b;\n\tRF_VoidFuncPtr **stripeUnitFuncs, uFunc;\n\tRF_VoidFuncPtr **blockFuncs, bFunc;\n\tint     numStripesBailed = 0, cantCreateDAGs = RF_FALSE;\n\tint     numStripeUnitsBailed = 0;\n\tint     stripeNum, numUnitDags = 0, stripeUnitNum, numBlockDags = 0;\n\tRF_StripeNum_t numStripeUnits;\n\tRF_SectorNum_t numBlocks;\n\tRF_RaidAddr_t address;\n\tint     length;\n\tRF_PhysDiskAddr_t *physPtr;\n\tcaddr_t buffer;\n\n\tlastdag_h = NULL;\n\tasmh_u = asmh_b = NULL;\n\tstripeUnitFuncs = NULL;\n\tblockFuncs = NULL;\n\n\t/* get an array of dag-function creation pointers, try to avoid\n\t * calling malloc */\n\tif (asm_h->numStripes <= MAXNSTRIPES)\n\t\tstripeFuncs = normalStripeFuncs;\n\telse\n\t\tRF_Calloc(stripeFuncs, asm_h->numStripes, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr *));\n\n\t/* walk through the asm list once collecting information */\n\t/* attempt to find a single creation function for each stripe */\n\tdesc->numStripes = 0;\n\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++) {\n\t\tdesc->numStripes++;\n\t\t(raidPtr->Layout.map->SelectionFunc) (raidPtr, type, asm_p, &stripeFuncs[i]);\n\t\t/* check to see if we found a creation func for this stripe */\n\t\tif (stripeFuncs[i] == (RF_VoidFuncPtr) NULL) {\n\t\t\t/* could not find creation function for entire stripe\n\t\t\t * so, let's see if we can find one for each stripe\n\t\t\t * unit in the stripe */\n\n\t\t\tif (numStripesBailed == 0) {\n\t\t\t\t/* one stripe map header for each stripe we\n\t\t\t\t * bail on */\n\t\t\t\tRF_Malloc(asmh_u, sizeof(RF_AccessStripeMapHeader_t **) * asm_h->numStripes, (RF_AccessStripeMapHeader_t ***));\n\t\t\t\t/* create an array of ptrs to arrays of\n\t\t\t\t * stripeFuncs */\n\t\t\t\tRF_Calloc(stripeUnitFuncs, asm_h->numStripes, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr **));\n\t\t\t}\n\t\t\t/* create an array of creation funcs (called\n\t\t\t * stripeFuncs) for this stripe */\n\t\t\tnumStripeUnits = asm_p->numStripeUnitsAccessed;\n\t\t\tRF_Calloc(stripeUnitFuncs[numStripesBailed], numStripeUnits, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr *));\n\t\t\tRF_Malloc(asmh_u[numStripesBailed], numStripeUnits * sizeof(RF_AccessStripeMapHeader_t *), (RF_AccessStripeMapHeader_t **));\n\n\t\t\t/* lookup array of stripeUnitFuncs for this stripe */\n\t\t\tfor (j = 0, physPtr = asm_p->physInfo; physPtr; physPtr = physPtr->next, j++) {\n\t\t\t\t/* remap for series of single stripe-unit\n\t\t\t\t * accesses */\n\t\t\t\taddress = physPtr->raidAddress;\n\t\t\t\tlength = physPtr->numSector;\n\t\t\t\tbuffer = physPtr->bufPtr;\n\n\t\t\t\tasmh_u[numStripesBailed][j] = rf_MapAccess(raidPtr, address, length, buffer, RF_DONT_REMAP);\n\t\t\t\tasm_up = asmh_u[numStripesBailed][j]->stripeMap;\n\n\t\t\t\t/* get the creation func for this stripe unit */\n\t\t\t\t(raidPtr->Layout.map->SelectionFunc) (raidPtr, type, asm_up, &(stripeUnitFuncs[numStripesBailed][j]));\n\n\t\t\t\t/* check to see if we found a creation func\n\t\t\t\t * for this stripe unit */\n\t\t\t\tif (stripeUnitFuncs[numStripesBailed][j] == (RF_VoidFuncPtr) NULL) {\n\t\t\t\t\t/* could not find creation function\n\t\t\t\t\t * for stripe unit so, let's see if we\n\t\t\t\t\t * can find one for each block in the\n\t\t\t\t\t * stripe unit */\n\t\t\t\t\tif (numStripeUnitsBailed == 0) {\n\t\t\t\t\t\t/* one stripe map header for\n\t\t\t\t\t\t * each stripe unit we bail on */\n\t\t\t\t\t\tRF_Malloc(asmh_b, sizeof(RF_AccessStripeMapHeader_t **) * asm_h->numStripes * raidPtr->Layout.numDataCol, (RF_AccessStripeMapHeader_t ***));\n\t\t\t\t\t\t/* create an array of ptrs to\n\t\t\t\t\t\t * arrays of blockFuncs */\n\t\t\t\t\t\tRF_Calloc(blockFuncs, asm_h->numStripes * raidPtr->Layout.numDataCol, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr **));\n\t\t\t\t\t}\n\t\t\t\t\t/* create an array of creation funcs\n\t\t\t\t\t * (called blockFuncs) for this stripe\n\t\t\t\t\t * unit */\n\t\t\t\t\tnumBlocks = physPtr->numSector;\n\t\t\t\t\tnumBlockDags += numBlocks;\n\t\t\t\t\tRF_Calloc(blockFuncs[numStripeUnitsBailed], numBlocks, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr *));\n\t\t\t\t\tRF_Malloc(asmh_b[numStripeUnitsBailed], numBlocks * sizeof(RF_AccessStripeMapHeader_t *), (RF_AccessStripeMapHeader_t **));\n\n\t\t\t\t\t/* lookup array of blockFuncs for this\n\t\t\t\t\t * stripe unit */\n\t\t\t\t\tfor (k = 0; k < numBlocks; k++) {\n\t\t\t\t\t\t/* remap for series of single\n\t\t\t\t\t\t * stripe-unit accesses */\n\t\t\t\t\t\taddress = physPtr->raidAddress + k;\n\t\t\t\t\t\tlength = 1;\n\t\t\t\t\t\tbuffer = physPtr->bufPtr + (k * (1 << raidPtr->logBytesPerSector));\n\n\t\t\t\t\t\tasmh_b[numStripeUnitsBailed][k] = rf_MapAccess(raidPtr, address, length, buffer, RF_DONT_REMAP);\n\t\t\t\t\t\tasm_bp = asmh_b[numStripeUnitsBailed][k]->stripeMap;\n\n\t\t\t\t\t\t/* get the creation func for\n\t\t\t\t\t\t * this stripe unit */\n\t\t\t\t\t\t(raidPtr->Layout.map->SelectionFunc) (raidPtr, type, asm_bp, &(blockFuncs[numStripeUnitsBailed][k]));\n\n\t\t\t\t\t\t/* check to see if we found a\n\t\t\t\t\t\t * creation func for this\n\t\t\t\t\t\t * stripe unit */\n\t\t\t\t\t\tif (blockFuncs[numStripeUnitsBailed][k] == NULL)\n\t\t\t\t\t\t\tcantCreateDAGs = RF_TRUE;\n\t\t\t\t\t}\n\t\t\t\t\tnumStripeUnitsBailed++;\n\t\t\t\t} else {\n\t\t\t\t\tnumUnitDags++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tRF_ASSERT(j == numStripeUnits);\n\t\t\tnumStripesBailed++;\n\t\t}\n\t}\n\n\tif (cantCreateDAGs) {\n\t\t/* free memory and punt */\n\t\tif (asm_h->numStripes > MAXNSTRIPES)\n\t\t\tRF_Free(stripeFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\tif (numStripesBailed > 0) {\n\t\t\tstripeNum = 0;\n\t\t\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++)\n\t\t\t\tif (stripeFuncs[i] == NULL) {\n\t\t\t\t\tnumStripeUnits = asm_p->numStripeUnitsAccessed;\n\t\t\t\t\tfor (j = 0; j < numStripeUnits; j++)\n\t\t\t\t\t\trf_FreeAccessStripeMap(asmh_u[stripeNum][j]);\n\t\t\t\t\tRF_Free(asmh_u[stripeNum], numStripeUnits * sizeof(RF_AccessStripeMapHeader_t *));\n\t\t\t\t\tRF_Free(stripeUnitFuncs[stripeNum], numStripeUnits * sizeof(RF_VoidFuncPtr));\n\t\t\t\t\tstripeNum++;\n\t\t\t\t}\n\t\t\tRF_ASSERT(stripeNum == numStripesBailed);\n\t\t\tRF_Free(stripeUnitFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\t\tRF_Free(asmh_u, asm_h->numStripes * sizeof(RF_AccessStripeMapHeader_t **));\n\t\t}\n\t\treturn (1);\n\t} else {\n\t\t/* begin dag creation */\n\t\tstripeNum = 0;\n\t\tstripeUnitNum = 0;\n\n\t\t/* create an array of dagLists and fill them in */\n\t\tRF_CallocAndAdd(desc->dagArray, desc->numStripes, sizeof(RF_DagList_t), (RF_DagList_t *), desc->cleanupList);\n\n\t\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++) {\n\t\t\t/* grab dag header for this stripe */\n\t\t\tdag_h = NULL;\n\t\t\tdesc->dagArray[i].desc = desc;\n\n\t\t\tif (stripeFuncs[i] == (RF_VoidFuncPtr) NULL) {\n\t\t\t\t/* use bailout functions for this stripe */\n\t\t\t\tfor (j = 0, physPtr = asm_p->physInfo; physPtr; physPtr = physPtr->next, j++) {\n\t\t\t\t\tuFunc = stripeUnitFuncs[stripeNum][j];\n\t\t\t\t\tif (uFunc == (RF_VoidFuncPtr) NULL) {\n\t\t\t\t\t\t/* use bailout functions for\n\t\t\t\t\t\t * this stripe unit */\n\t\t\t\t\t\tfor (k = 0; k < physPtr->numSector; k++) {\n\t\t\t\t\t\t\t/* create a dag for\n\t\t\t\t\t\t\t * this block */\n\t\t\t\t\t\t\tInitHdrNode(&tempdag_h, raidPtr, rf_useMemChunks);\n\t\t\t\t\t\t\tdesc->dagArray[i].numDags++;\n\t\t\t\t\t\t\tif (dag_h == NULL) {\n\t\t\t\t\t\t\t\tdag_h = tempdag_h;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tlastdag_h->next = tempdag_h;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlastdag_h = tempdag_h;\n\n\t\t\t\t\t\t\tbFunc = blockFuncs[stripeUnitNum][k];\n\t\t\t\t\t\t\tRF_ASSERT(bFunc);\n\t\t\t\t\t\t\tasm_bp = asmh_b[stripeUnitNum][k]->stripeMap;\n\t\t\t\t\t\t\t(*bFunc) (raidPtr, asm_bp, tempdag_h, bp, flags, tempdag_h->allocList);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tstripeUnitNum++;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* create a dag for this unit */\n\t\t\t\t\t\tInitHdrNode(&tempdag_h, raidPtr, rf_useMemChunks);\n\t\t\t\t\t\tdesc->dagArray[i].numDags++;\n\t\t\t\t\t\tif (dag_h == NULL) {\n\t\t\t\t\t\t\tdag_h = tempdag_h;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlastdag_h->next = tempdag_h;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlastdag_h = tempdag_h;\n\n\t\t\t\t\t\tasm_up = asmh_u[stripeNum][j]->stripeMap;\n\t\t\t\t\t\t(*uFunc) (raidPtr, asm_up, tempdag_h, bp, flags, tempdag_h->allocList);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tRF_ASSERT(j == asm_p->numStripeUnitsAccessed);\n\t\t\t\t/* merge linked bailout dag to existing dag\n\t\t\t\t * collection */\n\t\t\t\tstripeNum++;\n\t\t\t} else {\n\t\t\t\t/* Create a dag for this parity stripe */\n\t\t\t\tInitHdrNode(&tempdag_h, raidPtr, rf_useMemChunks);\n\t\t\t\tdesc->dagArray[i].numDags++;\n\t\t\t\tif (dag_h == NULL) {\n\t\t\t\t\tdag_h = tempdag_h;\n\t\t\t\t} else {\n\t\t\t\t\tlastdag_h->next = tempdag_h;\n\t\t\t\t}\n\t\t\t\tlastdag_h = tempdag_h;\n\n\t\t\t\t(stripeFuncs[i]) (raidPtr, asm_p, tempdag_h, bp, flags, tempdag_h->allocList);\n\t\t\t}\n\t\t\tdesc->dagArray[i].dags = dag_h;\n\t\t}\n\t\tRF_ASSERT(i == desc->numStripes);\n\n\t\t/* free memory */\n\t\tif (asm_h->numStripes > MAXNSTRIPES)\n\t\t\tRF_Free(stripeFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\tif ((numStripesBailed > 0) || (numStripeUnitsBailed > 0)) {\n\t\t\tstripeNum = 0;\n\t\t\tstripeUnitNum = 0;\n\t\t\tif (dag_h->asmList) {\n\t\t\t\tendASMList = dag_h->asmList;\n\t\t\t\twhile (endASMList->next)\n\t\t\t\t\tendASMList = endASMList->next;\n\t\t\t} else\n\t\t\t\tendASMList = NULL;\n\t\t\t/* walk through io, stripe by stripe */\n\t\t\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++)\n\t\t\t\tif (stripeFuncs[i] == NULL) {\n\t\t\t\t\tnumStripeUnits = asm_p->numStripeUnitsAccessed;\n\t\t\t\t\t/* walk through stripe, stripe unit by\n\t\t\t\t\t * stripe unit */\n\t\t\t\t\tfor (j = 0, physPtr = asm_p->physInfo; physPtr; physPtr = physPtr->next, j++) {\n\t\t\t\t\t\tif (stripeUnitFuncs[stripeNum][j] == NULL) {\n\t\t\t\t\t\t\tnumBlocks = physPtr->numSector;\n\t\t\t\t\t\t\t/* walk through stripe\n\t\t\t\t\t\t\t * unit, block by\n\t\t\t\t\t\t\t * block */\n\t\t\t\t\t\t\tfor (k = 0; k < numBlocks; k++)\n\t\t\t\t\t\t\t\tif (dag_h->asmList == NULL) {\n\t\t\t\t\t\t\t\t\tdag_h->asmList = asmh_b[stripeUnitNum][k];\n\t\t\t\t\t\t\t\t\tendASMList = dag_h->asmList;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tendASMList->next = asmh_b[stripeUnitNum][k];\n\t\t\t\t\t\t\t\t\tendASMList = endASMList->next;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tRF_Free(asmh_b[stripeUnitNum], numBlocks * sizeof(RF_AccessStripeMapHeader_t *));\n\t\t\t\t\t\t\tRF_Free(blockFuncs[stripeUnitNum], numBlocks * sizeof(RF_VoidFuncPtr));\n\t\t\t\t\t\t\tstripeUnitNum++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (dag_h->asmList == NULL) {\n\t\t\t\t\t\t\tdag_h->asmList = asmh_u[stripeNum][j];\n\t\t\t\t\t\t\tendASMList = dag_h->asmList;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tendASMList->next = asmh_u[stripeNum][j];\n\t\t\t\t\t\t\tendASMList = endASMList->next;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tRF_Free(asmh_u[stripeNum], numStripeUnits * sizeof(RF_AccessStripeMapHeader_t *));\n\t\t\t\t\tRF_Free(stripeUnitFuncs[stripeNum], numStripeUnits * sizeof(RF_VoidFuncPtr));\n\t\t\t\t\tstripeNum++;\n\t\t\t\t}\n\t\t\tRF_ASSERT(stripeNum == numStripesBailed);\n\t\t\tRF_Free(stripeUnitFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\t\tRF_Free(asmh_u, asm_h->numStripes * sizeof(RF_AccessStripeMapHeader_t **));\n\t\t\tif (numStripeUnitsBailed > 0) {\n\t\t\t\tRF_ASSERT(stripeUnitNum == numStripeUnitsBailed);\n\t\t\t\tRF_Free(blockFuncs, raidPtr->Layout.numDataCol * asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\t\t\tRF_Free(asmh_b, raidPtr->Layout.numDataCol * asm_h->numStripes * sizeof(RF_AccessStripeMapHeader_t **));\n\t\t\t}\n\t\t}\n\t\treturn (0);\n\t}\n}",
          "includes": [
            "#include \"rf_map.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [
            "#define MAXNSTRIPES 50"
          ],
          "globals_used": [
            "static int InitHdrNode(RF_DagHeader_t **, RF_Raid_t *, int);",
            "int     rf_SelectAlgorithm(RF_RaidAccessDesc_t *, RF_RaidAccessFlags_t);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_map.h\"\n#include \"rf_desc.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\n#define MAXNSTRIPES 50\n\nstatic int InitHdrNode(RF_DagHeader_t **, RF_Raid_t *, int);\nint     rf_SelectAlgorithm(RF_RaidAccessDesc_t *, RF_RaidAccessFlags_t);\n\nint \nrf_SelectAlgorithm(desc, flags)\n\tRF_RaidAccessDesc_t *desc;\n\tRF_RaidAccessFlags_t flags;\n{\n\tRF_AccessStripeMapHeader_t *asm_h = desc->asmap;\n\tRF_IoType_t type = desc->type;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tvoid   *bp = desc->bp;\n\n\tRF_AccessStripeMap_t *asmap = asm_h->stripeMap;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_DagHeader_t *dag_h = NULL, *tempdag_h, *lastdag_h;\n\tint     i, j, k;\n\tRF_VoidFuncPtr *stripeFuncs, normalStripeFuncs[MAXNSTRIPES];\n\tRF_AccessStripeMap_t *asm_up, *asm_bp;\n\tRF_AccessStripeMapHeader_t ***asmh_u, *endASMList;\n\tRF_AccessStripeMapHeader_t ***asmh_b;\n\tRF_VoidFuncPtr **stripeUnitFuncs, uFunc;\n\tRF_VoidFuncPtr **blockFuncs, bFunc;\n\tint     numStripesBailed = 0, cantCreateDAGs = RF_FALSE;\n\tint     numStripeUnitsBailed = 0;\n\tint     stripeNum, numUnitDags = 0, stripeUnitNum, numBlockDags = 0;\n\tRF_StripeNum_t numStripeUnits;\n\tRF_SectorNum_t numBlocks;\n\tRF_RaidAddr_t address;\n\tint     length;\n\tRF_PhysDiskAddr_t *physPtr;\n\tcaddr_t buffer;\n\n\tlastdag_h = NULL;\n\tasmh_u = asmh_b = NULL;\n\tstripeUnitFuncs = NULL;\n\tblockFuncs = NULL;\n\n\t/* get an array of dag-function creation pointers, try to avoid\n\t * calling malloc */\n\tif (asm_h->numStripes <= MAXNSTRIPES)\n\t\tstripeFuncs = normalStripeFuncs;\n\telse\n\t\tRF_Calloc(stripeFuncs, asm_h->numStripes, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr *));\n\n\t/* walk through the asm list once collecting information */\n\t/* attempt to find a single creation function for each stripe */\n\tdesc->numStripes = 0;\n\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++) {\n\t\tdesc->numStripes++;\n\t\t(raidPtr->Layout.map->SelectionFunc) (raidPtr, type, asm_p, &stripeFuncs[i]);\n\t\t/* check to see if we found a creation func for this stripe */\n\t\tif (stripeFuncs[i] == (RF_VoidFuncPtr) NULL) {\n\t\t\t/* could not find creation function for entire stripe\n\t\t\t * so, let's see if we can find one for each stripe\n\t\t\t * unit in the stripe */\n\n\t\t\tif (numStripesBailed == 0) {\n\t\t\t\t/* one stripe map header for each stripe we\n\t\t\t\t * bail on */\n\t\t\t\tRF_Malloc(asmh_u, sizeof(RF_AccessStripeMapHeader_t **) * asm_h->numStripes, (RF_AccessStripeMapHeader_t ***));\n\t\t\t\t/* create an array of ptrs to arrays of\n\t\t\t\t * stripeFuncs */\n\t\t\t\tRF_Calloc(stripeUnitFuncs, asm_h->numStripes, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr **));\n\t\t\t}\n\t\t\t/* create an array of creation funcs (called\n\t\t\t * stripeFuncs) for this stripe */\n\t\t\tnumStripeUnits = asm_p->numStripeUnitsAccessed;\n\t\t\tRF_Calloc(stripeUnitFuncs[numStripesBailed], numStripeUnits, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr *));\n\t\t\tRF_Malloc(asmh_u[numStripesBailed], numStripeUnits * sizeof(RF_AccessStripeMapHeader_t *), (RF_AccessStripeMapHeader_t **));\n\n\t\t\t/* lookup array of stripeUnitFuncs for this stripe */\n\t\t\tfor (j = 0, physPtr = asm_p->physInfo; physPtr; physPtr = physPtr->next, j++) {\n\t\t\t\t/* remap for series of single stripe-unit\n\t\t\t\t * accesses */\n\t\t\t\taddress = physPtr->raidAddress;\n\t\t\t\tlength = physPtr->numSector;\n\t\t\t\tbuffer = physPtr->bufPtr;\n\n\t\t\t\tasmh_u[numStripesBailed][j] = rf_MapAccess(raidPtr, address, length, buffer, RF_DONT_REMAP);\n\t\t\t\tasm_up = asmh_u[numStripesBailed][j]->stripeMap;\n\n\t\t\t\t/* get the creation func for this stripe unit */\n\t\t\t\t(raidPtr->Layout.map->SelectionFunc) (raidPtr, type, asm_up, &(stripeUnitFuncs[numStripesBailed][j]));\n\n\t\t\t\t/* check to see if we found a creation func\n\t\t\t\t * for this stripe unit */\n\t\t\t\tif (stripeUnitFuncs[numStripesBailed][j] == (RF_VoidFuncPtr) NULL) {\n\t\t\t\t\t/* could not find creation function\n\t\t\t\t\t * for stripe unit so, let's see if we\n\t\t\t\t\t * can find one for each block in the\n\t\t\t\t\t * stripe unit */\n\t\t\t\t\tif (numStripeUnitsBailed == 0) {\n\t\t\t\t\t\t/* one stripe map header for\n\t\t\t\t\t\t * each stripe unit we bail on */\n\t\t\t\t\t\tRF_Malloc(asmh_b, sizeof(RF_AccessStripeMapHeader_t **) * asm_h->numStripes * raidPtr->Layout.numDataCol, (RF_AccessStripeMapHeader_t ***));\n\t\t\t\t\t\t/* create an array of ptrs to\n\t\t\t\t\t\t * arrays of blockFuncs */\n\t\t\t\t\t\tRF_Calloc(blockFuncs, asm_h->numStripes * raidPtr->Layout.numDataCol, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr **));\n\t\t\t\t\t}\n\t\t\t\t\t/* create an array of creation funcs\n\t\t\t\t\t * (called blockFuncs) for this stripe\n\t\t\t\t\t * unit */\n\t\t\t\t\tnumBlocks = physPtr->numSector;\n\t\t\t\t\tnumBlockDags += numBlocks;\n\t\t\t\t\tRF_Calloc(blockFuncs[numStripeUnitsBailed], numBlocks, sizeof(RF_VoidFuncPtr), (RF_VoidFuncPtr *));\n\t\t\t\t\tRF_Malloc(asmh_b[numStripeUnitsBailed], numBlocks * sizeof(RF_AccessStripeMapHeader_t *), (RF_AccessStripeMapHeader_t **));\n\n\t\t\t\t\t/* lookup array of blockFuncs for this\n\t\t\t\t\t * stripe unit */\n\t\t\t\t\tfor (k = 0; k < numBlocks; k++) {\n\t\t\t\t\t\t/* remap for series of single\n\t\t\t\t\t\t * stripe-unit accesses */\n\t\t\t\t\t\taddress = physPtr->raidAddress + k;\n\t\t\t\t\t\tlength = 1;\n\t\t\t\t\t\tbuffer = physPtr->bufPtr + (k * (1 << raidPtr->logBytesPerSector));\n\n\t\t\t\t\t\tasmh_b[numStripeUnitsBailed][k] = rf_MapAccess(raidPtr, address, length, buffer, RF_DONT_REMAP);\n\t\t\t\t\t\tasm_bp = asmh_b[numStripeUnitsBailed][k]->stripeMap;\n\n\t\t\t\t\t\t/* get the creation func for\n\t\t\t\t\t\t * this stripe unit */\n\t\t\t\t\t\t(raidPtr->Layout.map->SelectionFunc) (raidPtr, type, asm_bp, &(blockFuncs[numStripeUnitsBailed][k]));\n\n\t\t\t\t\t\t/* check to see if we found a\n\t\t\t\t\t\t * creation func for this\n\t\t\t\t\t\t * stripe unit */\n\t\t\t\t\t\tif (blockFuncs[numStripeUnitsBailed][k] == NULL)\n\t\t\t\t\t\t\tcantCreateDAGs = RF_TRUE;\n\t\t\t\t\t}\n\t\t\t\t\tnumStripeUnitsBailed++;\n\t\t\t\t} else {\n\t\t\t\t\tnumUnitDags++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tRF_ASSERT(j == numStripeUnits);\n\t\t\tnumStripesBailed++;\n\t\t}\n\t}\n\n\tif (cantCreateDAGs) {\n\t\t/* free memory and punt */\n\t\tif (asm_h->numStripes > MAXNSTRIPES)\n\t\t\tRF_Free(stripeFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\tif (numStripesBailed > 0) {\n\t\t\tstripeNum = 0;\n\t\t\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++)\n\t\t\t\tif (stripeFuncs[i] == NULL) {\n\t\t\t\t\tnumStripeUnits = asm_p->numStripeUnitsAccessed;\n\t\t\t\t\tfor (j = 0; j < numStripeUnits; j++)\n\t\t\t\t\t\trf_FreeAccessStripeMap(asmh_u[stripeNum][j]);\n\t\t\t\t\tRF_Free(asmh_u[stripeNum], numStripeUnits * sizeof(RF_AccessStripeMapHeader_t *));\n\t\t\t\t\tRF_Free(stripeUnitFuncs[stripeNum], numStripeUnits * sizeof(RF_VoidFuncPtr));\n\t\t\t\t\tstripeNum++;\n\t\t\t\t}\n\t\t\tRF_ASSERT(stripeNum == numStripesBailed);\n\t\t\tRF_Free(stripeUnitFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\t\tRF_Free(asmh_u, asm_h->numStripes * sizeof(RF_AccessStripeMapHeader_t **));\n\t\t}\n\t\treturn (1);\n\t} else {\n\t\t/* begin dag creation */\n\t\tstripeNum = 0;\n\t\tstripeUnitNum = 0;\n\n\t\t/* create an array of dagLists and fill them in */\n\t\tRF_CallocAndAdd(desc->dagArray, desc->numStripes, sizeof(RF_DagList_t), (RF_DagList_t *), desc->cleanupList);\n\n\t\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++) {\n\t\t\t/* grab dag header for this stripe */\n\t\t\tdag_h = NULL;\n\t\t\tdesc->dagArray[i].desc = desc;\n\n\t\t\tif (stripeFuncs[i] == (RF_VoidFuncPtr) NULL) {\n\t\t\t\t/* use bailout functions for this stripe */\n\t\t\t\tfor (j = 0, physPtr = asm_p->physInfo; physPtr; physPtr = physPtr->next, j++) {\n\t\t\t\t\tuFunc = stripeUnitFuncs[stripeNum][j];\n\t\t\t\t\tif (uFunc == (RF_VoidFuncPtr) NULL) {\n\t\t\t\t\t\t/* use bailout functions for\n\t\t\t\t\t\t * this stripe unit */\n\t\t\t\t\t\tfor (k = 0; k < physPtr->numSector; k++) {\n\t\t\t\t\t\t\t/* create a dag for\n\t\t\t\t\t\t\t * this block */\n\t\t\t\t\t\t\tInitHdrNode(&tempdag_h, raidPtr, rf_useMemChunks);\n\t\t\t\t\t\t\tdesc->dagArray[i].numDags++;\n\t\t\t\t\t\t\tif (dag_h == NULL) {\n\t\t\t\t\t\t\t\tdag_h = tempdag_h;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tlastdag_h->next = tempdag_h;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tlastdag_h = tempdag_h;\n\n\t\t\t\t\t\t\tbFunc = blockFuncs[stripeUnitNum][k];\n\t\t\t\t\t\t\tRF_ASSERT(bFunc);\n\t\t\t\t\t\t\tasm_bp = asmh_b[stripeUnitNum][k]->stripeMap;\n\t\t\t\t\t\t\t(*bFunc) (raidPtr, asm_bp, tempdag_h, bp, flags, tempdag_h->allocList);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tstripeUnitNum++;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* create a dag for this unit */\n\t\t\t\t\t\tInitHdrNode(&tempdag_h, raidPtr, rf_useMemChunks);\n\t\t\t\t\t\tdesc->dagArray[i].numDags++;\n\t\t\t\t\t\tif (dag_h == NULL) {\n\t\t\t\t\t\t\tdag_h = tempdag_h;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlastdag_h->next = tempdag_h;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlastdag_h = tempdag_h;\n\n\t\t\t\t\t\tasm_up = asmh_u[stripeNum][j]->stripeMap;\n\t\t\t\t\t\t(*uFunc) (raidPtr, asm_up, tempdag_h, bp, flags, tempdag_h->allocList);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tRF_ASSERT(j == asm_p->numStripeUnitsAccessed);\n\t\t\t\t/* merge linked bailout dag to existing dag\n\t\t\t\t * collection */\n\t\t\t\tstripeNum++;\n\t\t\t} else {\n\t\t\t\t/* Create a dag for this parity stripe */\n\t\t\t\tInitHdrNode(&tempdag_h, raidPtr, rf_useMemChunks);\n\t\t\t\tdesc->dagArray[i].numDags++;\n\t\t\t\tif (dag_h == NULL) {\n\t\t\t\t\tdag_h = tempdag_h;\n\t\t\t\t} else {\n\t\t\t\t\tlastdag_h->next = tempdag_h;\n\t\t\t\t}\n\t\t\t\tlastdag_h = tempdag_h;\n\n\t\t\t\t(stripeFuncs[i]) (raidPtr, asm_p, tempdag_h, bp, flags, tempdag_h->allocList);\n\t\t\t}\n\t\t\tdesc->dagArray[i].dags = dag_h;\n\t\t}\n\t\tRF_ASSERT(i == desc->numStripes);\n\n\t\t/* free memory */\n\t\tif (asm_h->numStripes > MAXNSTRIPES)\n\t\t\tRF_Free(stripeFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\tif ((numStripesBailed > 0) || (numStripeUnitsBailed > 0)) {\n\t\t\tstripeNum = 0;\n\t\t\tstripeUnitNum = 0;\n\t\t\tif (dag_h->asmList) {\n\t\t\t\tendASMList = dag_h->asmList;\n\t\t\t\twhile (endASMList->next)\n\t\t\t\t\tendASMList = endASMList->next;\n\t\t\t} else\n\t\t\t\tendASMList = NULL;\n\t\t\t/* walk through io, stripe by stripe */\n\t\t\tfor (i = 0, asm_p = asmap; asm_p; asm_p = asm_p->next, i++)\n\t\t\t\tif (stripeFuncs[i] == NULL) {\n\t\t\t\t\tnumStripeUnits = asm_p->numStripeUnitsAccessed;\n\t\t\t\t\t/* walk through stripe, stripe unit by\n\t\t\t\t\t * stripe unit */\n\t\t\t\t\tfor (j = 0, physPtr = asm_p->physInfo; physPtr; physPtr = physPtr->next, j++) {\n\t\t\t\t\t\tif (stripeUnitFuncs[stripeNum][j] == NULL) {\n\t\t\t\t\t\t\tnumBlocks = physPtr->numSector;\n\t\t\t\t\t\t\t/* walk through stripe\n\t\t\t\t\t\t\t * unit, block by\n\t\t\t\t\t\t\t * block */\n\t\t\t\t\t\t\tfor (k = 0; k < numBlocks; k++)\n\t\t\t\t\t\t\t\tif (dag_h->asmList == NULL) {\n\t\t\t\t\t\t\t\t\tdag_h->asmList = asmh_b[stripeUnitNum][k];\n\t\t\t\t\t\t\t\t\tendASMList = dag_h->asmList;\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tendASMList->next = asmh_b[stripeUnitNum][k];\n\t\t\t\t\t\t\t\t\tendASMList = endASMList->next;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tRF_Free(asmh_b[stripeUnitNum], numBlocks * sizeof(RF_AccessStripeMapHeader_t *));\n\t\t\t\t\t\t\tRF_Free(blockFuncs[stripeUnitNum], numBlocks * sizeof(RF_VoidFuncPtr));\n\t\t\t\t\t\t\tstripeUnitNum++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (dag_h->asmList == NULL) {\n\t\t\t\t\t\t\tdag_h->asmList = asmh_u[stripeNum][j];\n\t\t\t\t\t\t\tendASMList = dag_h->asmList;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tendASMList->next = asmh_u[stripeNum][j];\n\t\t\t\t\t\t\tendASMList = endASMList->next;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tRF_Free(asmh_u[stripeNum], numStripeUnits * sizeof(RF_AccessStripeMapHeader_t *));\n\t\t\t\t\tRF_Free(stripeUnitFuncs[stripeNum], numStripeUnits * sizeof(RF_VoidFuncPtr));\n\t\t\t\t\tstripeNum++;\n\t\t\t\t}\n\t\t\tRF_ASSERT(stripeNum == numStripesBailed);\n\t\t\tRF_Free(stripeUnitFuncs, asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\t\tRF_Free(asmh_u, asm_h->numStripes * sizeof(RF_AccessStripeMapHeader_t **));\n\t\t\tif (numStripeUnitsBailed > 0) {\n\t\t\t\tRF_ASSERT(stripeUnitNum == numStripeUnitsBailed);\n\t\t\t\tRF_Free(blockFuncs, raidPtr->Layout.numDataCol * asm_h->numStripes * sizeof(RF_VoidFuncPtr));\n\t\t\t\tRF_Free(asmh_b, raidPtr->Layout.numDataCol * asm_h->numStripes * sizeof(RF_AccessStripeMapHeader_t **));\n\t\t\t}\n\t\t}\n\t\treturn (0);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 431
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_CreateDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tRF_DagHeader_t *dag_h;\n\tint     i, selectStatus;\n\n\t/* generate a dag for the access, and fire it off.  When the dag\n\t * completes, we'll get re-invoked in the next state. */\n\tRF_ETIMER_START(timer);\n\t/* SelectAlgorithm returns one or more dags */\n\tselectStatus = rf_SelectAlgorithm(desc, desc->flags | RF_DAG_SUPPRESS_LOCKS);\n\tif (rf_printDAGsDebug)\n\t\tfor (i = 0; i < desc->numStripes; i++)\n\t\t\trf_PrintDAGList(desc->dagArray[i].dags);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\t/* update time to create all dags */\n\ttracerec->specific.user.dag_create_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->status = 0;\t/* good status */\n\n\tif (selectStatus) {\n\t\t/* failed to create a dag */\n\t\t/* this happens when there are too many faults or incomplete\n\t\t * dag libraries */\n\t\tprintf(\"[Failed to create a DAG\\n]\");\n\t\tRF_PANIC();\n\t} else {\n\t\t/* bind dags to desc */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tdag_h = desc->dagArray[i].dags;\n\t\t\twhile (dag_h) {\n\t\t\t\tdag_h->bp = (struct buf *) desc->bp;\n\t\t\t\tdag_h->tracerec = tracerec;\n\t\t\t\tdag_h = dag_h->next;\n\t\t\t}\n\t\t}\n\t\tdesc->flags |= RF_DAG_DISPATCH_RETURNED;\n\t\tdesc->state++;\t/* next state should be rf_State_ExecuteDAG */\n\t}\n\treturn RF_FALSE;\n}"
  },
  {
    "function_name": "rf_State_Lock",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "321-399",
    "snippet": "int \nrf_State_Lock(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tRF_StripeNum_t lastStripeID = -1;\n\n\t\t/* acquire each lock that we don't already hold */\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tRF_ASSERT(RF_IO_IS_R_OR_W(desc->type));\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS) &&\n\t\t\t    !(asm_p->flags & RF_ASM_FLAGS_LOCK_TRIED)) {\n\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_LOCK_TRIED;\n\t\t\t\tRF_ASSERT(asm_p->stripeID > lastStripeID);\t/* locks must be\n\t\t\t\t\t\t\t\t\t\t * acquired\n\t\t\t\t\t\t\t\t\t\t * hierarchically */\n\t\t\t\tlastStripeID = asm_p->stripeID;\n\t\t\t\t/* XXX the cast to (void (*)(RF_CBParam_t))\n\t\t\t\t * below is bogus!  GO */\n\t\t\t\tRF_INIT_LOCK_REQ_DESC(asm_p->lockReqDesc, desc->type,\n\t\t\t\t    (void (*) (struct buf *)) rf_ContinueRaidAccess, desc, asm_p,\n\t\t\t\t    raidPtr->Layout.dataSectorsPerStripe);\n\t\t\t\tif (rf_AcquireStripeLock(raidPtr->lockTable, asm_p->stripeID,\n\t\t\t\t\t&asm_p->lockReqDesc)) {\n\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (desc->type == RF_IO_TYPE_WRITE &&\n\t\t\t    raidPtr->status[asm_p->physInfo->row] == rf_rs_reconstructing) {\n\t\t\t\tif (!(asm_p->flags & RF_ASM_FLAGS_FORCE_TRIED)) {\n\t\t\t\t\tint     val;\n\n\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_FORCE_TRIED;\n\t\t\t\t\t/* XXX the cast below is quite\n\t\t\t\t\t * bogus!!! XXX  GO */\n\t\t\t\t\tval = rf_ForceOrBlockRecon(raidPtr, asm_p,\n\t\t\t\t\t    (void (*) (RF_Raid_t *, void *)) rf_ContinueRaidAccess, desc);\n\t\t\t\t\tif (val == 0) {\n\t\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_RECON_BLOCKED;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\t\tprintf(\"raid%d: skipping force/block because already done, psid %ld\\n\",\n\t\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\tprintf(\"raid%d: skipping force/block because not write or not under recon, psid %ld\\n\",\n\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tRF_ETIMER_STOP(timer);\n\t\tRF_ETIMER_EVAL(timer);\n\t\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\t\tif (suspended)\n\t\t\treturn (RF_TRUE);\n\t}\n\tdesc->state++;\n\treturn (RF_FALSE);\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 392
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 391
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 390
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"raid%d: skipping force/block because not write or not under recon, psid %ld\\n\"",
            "desc->raidPtr->raidid",
            "(long) asm_p->stripeID"
          ],
          "line": 383
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_ForceOrBlockRecon",
          "args": [
            "raidPtr",
            "asm_p",
            "(void (*) (RF_Raid_t *, void *)) rf_ContinueRaidAccess",
            "desc"
          ],
          "line": 366
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ForceOrBlockRecon",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_reconstruct.c",
          "lines": "1459-1569",
          "snippet": "int \nrf_ForceOrBlockRecon(raidPtr, asmap, cbFunc, cbArg)\n\tRF_Raid_t *raidPtr;\n\tRF_AccessStripeMap_t *asmap;\n\tvoid    (*cbFunc) (RF_Raid_t *, void *);\n\tvoid   *cbArg;\n{\n\tRF_RowCol_t row = asmap->physInfo->row;\t/* which row of the array\n\t\t\t\t\t\t * we're working on */\n\tRF_StripeNum_t stripeID = asmap->stripeID;\t/* the stripe ID we're\n\t\t\t\t\t\t\t * forcing recon on */\n\tRF_SectorCount_t sectorsPerRU = raidPtr->Layout.sectorsPerStripeUnit * raidPtr->Layout.SUsPerRU;\t/* num sects in one RU */\n\tRF_ReconParityStripeStatus_t *pssPtr;\t/* a pointer to the parity\n\t\t\t\t\t\t * stripe status structure */\n\tRF_StripeNum_t psid;\t/* parity stripe id */\n\tRF_SectorNum_t offset, fd_offset;\t/* disk offset, failed-disk\n\t\t\t\t\t\t * offset */\n\tRF_RowCol_t *diskids;\n\tRF_RowCol_t stripe;\n\tRF_ReconUnitNum_t which_ru;\t/* RU within parity stripe */\n\tRF_RowCol_t fcol, diskno, i;\n\tRF_ReconBuffer_t *new_rbuf;\t/* ptr to newly allocated rbufs */\n\tRF_DiskQueueData_t *req;/* disk I/O req to be enqueued */\n\tRF_CallbackDesc_t *cb;\n\tint     created = 0, nPromoted;\n\n\tpsid = rf_MapStripeIDToParityStripeID(&raidPtr->Layout, stripeID, &which_ru);\n\n\tRF_LOCK_PSS_MUTEX(raidPtr, row, psid);\n\n\tpssPtr = rf_LookupRUStatus(raidPtr, raidPtr->reconControl[row]->pssTable, psid, which_ru, RF_PSS_CREATE | RF_PSS_RECON_BLOCKED, &created);\n\n\t/* if recon is not ongoing on this PS, just return */\n\tif (!(pssPtr->flags & RF_PSS_UNDER_RECON)) {\n\t\tRF_UNLOCK_PSS_MUTEX(raidPtr, row, psid);\n\t\treturn (0);\n\t}\n\t/* otherwise, we have to wait for reconstruction to complete on this\n\t * RU. */\n\t/* In order to avoid waiting for a potentially large number of\n\t * low-priority accesses to complete, we force a normal-priority (i.e.\n\t * not low-priority) reconstruction on this RU. */\n\tif (!(pssPtr->flags & RF_PSS_FORCED_ON_WRITE) && !(pssPtr->flags & RF_PSS_FORCED_ON_READ)) {\n\t\tDDprintf1(\"Forcing recon on psid %ld\\n\", psid);\n\t\tpssPtr->flags |= RF_PSS_FORCED_ON_WRITE;\t/* mark this RU as under\n\t\t\t\t\t\t\t\t * forced recon */\n\t\tpssPtr->flags &= ~RF_PSS_RECON_BLOCKED;\t/* clear the blockage\n\t\t\t\t\t\t\t * that we just set */\n\t\tfcol = raidPtr->reconControl[row]->fcol;\n\n\t\t/* get a listing of the disks comprising the indicated stripe */\n\t\t(raidPtr->Layout.map->IdentifyStripe) (raidPtr, asmap->raidAddress, &diskids, &stripe);\n\t\tRF_ASSERT(row == stripe);\n\n\t\t/* For previously issued reads, elevate them to normal\n\t\t * priority.  If the I/O has already completed, it won't be\n\t\t * found in the queue, and hence this will be a no-op. For\n\t\t * unissued reads, allocate buffers and issue new reads.  The\n\t\t * fact that we've set the FORCED bit means that the regular\n\t\t * recon procs will not re-issue these reqs */\n\t\tfor (i = 0; i < raidPtr->Layout.numDataCol + raidPtr->Layout.numParityCol; i++)\n\t\t\tif ((diskno = diskids[i]) != fcol) {\n\t\t\t\tif (pssPtr->issued[diskno]) {\n\t\t\t\t\tnPromoted = rf_DiskIOPromote(&raidPtr->Queues[row][diskno], psid, which_ru);\n\t\t\t\t\tif (rf_reconDebug && nPromoted)\n\t\t\t\t\t\tprintf(\"raid%d: promoted read from row %d col %d\\n\", raidPtr->raidid, row, diskno);\n\t\t\t\t} else {\n\t\t\t\t\tnew_rbuf = rf_MakeReconBuffer(raidPtr, row, diskno, RF_RBUF_TYPE_FORCED);\t/* create new buf */\n\t\t\t\t\trf_ComputePSDiskOffsets(raidPtr, psid, row, diskno, &offset, &fd_offset,\n\t\t\t\t\t    &new_rbuf->spRow, &new_rbuf->spCol, &new_rbuf->spOffset);\t/* find offsets & spare\n\t\t\t\t\t\t\t\t\t\t\t\t\t * location */\n\t\t\t\t\tnew_rbuf->parityStripeID = psid;\t/* fill in the buffer */\n\t\t\t\t\tnew_rbuf->which_ru = which_ru;\n\t\t\t\t\tnew_rbuf->failedDiskSectorOffset = fd_offset;\n\t\t\t\t\tnew_rbuf->priority = RF_IO_NORMAL_PRIORITY;\n\n\t\t\t\t\t/* use NULL b_proc b/c all addrs\n\t\t\t\t\t * should be in kernel space */\n\t\t\t\t\treq = rf_CreateDiskQueueData(RF_IO_TYPE_READ, offset + which_ru * sectorsPerRU, sectorsPerRU, new_rbuf->buffer,\n\t\t\t\t\t    psid, which_ru, (int (*) (void *, int)) rf_ForceReconReadDoneProc, (void *) new_rbuf, NULL,\n\t\t\t\t\t    NULL, (void *) raidPtr, 0, NULL);\n\n\t\t\t\t\tRF_ASSERT(req);\t/* XXX -- fix this --\n\t\t\t\t\t\t\t * XXX */\n\n\t\t\t\t\tnew_rbuf->arg = req;\n\t\t\t\t\trf_DiskIOEnqueue(&raidPtr->Queues[row][diskno], req, RF_IO_NORMAL_PRIORITY);\t/* enqueue the I/O */\n\t\t\t\t\tDprintf3(\"raid%d: Issued new read req on row %d col %d\\n\", raidPtr->raidid, row, diskno);\n\t\t\t\t}\n\t\t\t}\n\t\t/* if the write is sitting in the disk queue, elevate its\n\t\t * priority */\n\t\tif (rf_DiskIOPromote(&raidPtr->Queues[row][fcol], psid, which_ru))\n\t\t\tprintf(\"raid%d: promoted write to row %d col %d\\n\", \n\t\t\t       raidPtr->raidid, row, fcol);\n\t}\n\t/* install a callback descriptor to be invoked when recon completes on\n\t * this parity stripe. */\n\tcb = rf_AllocCallbackDesc();\n\t/* XXX the following is bogus.. These functions don't really match!!\n\t * GO */\n\tcb->callbackFunc = (void (*) (RF_CBParam_t)) cbFunc;\n\tcb->callbackArg.p = (void *) cbArg;\n\tcb->next = pssPtr->procWaitList;\n\tpssPtr->procWaitList = cb;\n\tDDprintf2(\"raid%d: Waiting for forced recon on psid %ld\\n\", \n\t\t  raidPtr->raidid, psid);\n\n\tRF_UNLOCK_PSS_MUTEX(raidPtr, row, psid);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_reconbuffer.h\"",
            "#include \"rf_revent.h\"",
            "#include \"rf_reconutil.h\"",
            "#include \"rf_raid.h\"",
            "#include <sys/vnode.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/proc.h>",
            "#include <sys/systm.h>",
            "#include <sys/param.h>",
            "#include <sys/types.h>",
            "#include <sys/errno.h>",
            "#include <sys/buf.h>",
            "#include <sys/time.h>",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "int rf_ComputePSDiskOffsets",
            "int rf_CheckHeadSeparation(RF_Raid_t *, RF_PerDiskReconCtrl_t *, RF_RowCol_t, RF_RowCol_t, RF_HeadSepLimit_t, RF_ReconUnitNum_t);",
            "void rf_ForceReconReadDoneProc",
            "RF_RaidReconDesc_t *\nrf_AllocRaidReconDesc(raidPtr, row, col, spareDiskPtr, numDisksDone, srow, scol)\n\tRF_Raid_t *raidPtr;",
            "RF_RowCol_t row;",
            "RF_RowCol_t col;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_driver.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_etimer.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_reconbuffer.h\"\n#include \"rf_revent.h\"\n#include \"rf_reconutil.h\"\n#include \"rf_raid.h\"\n#include <sys/vnode.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/proc.h>\n#include <sys/systm.h>\n#include <sys/param.h>\n#include <sys/types.h>\n#include <sys/errno.h>\n#include <sys/buf.h>\n#include <sys/time.h>\n#include \"rf_types.h\"\n\nint rf_ComputePSDiskOffsets;\nint rf_CheckHeadSeparation(RF_Raid_t *, RF_PerDiskReconCtrl_t *, RF_RowCol_t, RF_RowCol_t, RF_HeadSepLimit_t, RF_ReconUnitNum_t);\nvoid rf_ForceReconReadDoneProc;\nRF_RaidReconDesc_t *\nrf_AllocRaidReconDesc(raidPtr, row, col, spareDiskPtr, numDisksDone, srow, scol)\n\tRF_Raid_t *raidPtr;\nRF_RowCol_t row;\nRF_RowCol_t col;\n\nint \nrf_ForceOrBlockRecon(raidPtr, asmap, cbFunc, cbArg)\n\tRF_Raid_t *raidPtr;\n\tRF_AccessStripeMap_t *asmap;\n\tvoid    (*cbFunc) (RF_Raid_t *, void *);\n\tvoid   *cbArg;\n{\n\tRF_RowCol_t row = asmap->physInfo->row;\t/* which row of the array\n\t\t\t\t\t\t * we're working on */\n\tRF_StripeNum_t stripeID = asmap->stripeID;\t/* the stripe ID we're\n\t\t\t\t\t\t\t * forcing recon on */\n\tRF_SectorCount_t sectorsPerRU = raidPtr->Layout.sectorsPerStripeUnit * raidPtr->Layout.SUsPerRU;\t/* num sects in one RU */\n\tRF_ReconParityStripeStatus_t *pssPtr;\t/* a pointer to the parity\n\t\t\t\t\t\t * stripe status structure */\n\tRF_StripeNum_t psid;\t/* parity stripe id */\n\tRF_SectorNum_t offset, fd_offset;\t/* disk offset, failed-disk\n\t\t\t\t\t\t * offset */\n\tRF_RowCol_t *diskids;\n\tRF_RowCol_t stripe;\n\tRF_ReconUnitNum_t which_ru;\t/* RU within parity stripe */\n\tRF_RowCol_t fcol, diskno, i;\n\tRF_ReconBuffer_t *new_rbuf;\t/* ptr to newly allocated rbufs */\n\tRF_DiskQueueData_t *req;/* disk I/O req to be enqueued */\n\tRF_CallbackDesc_t *cb;\n\tint     created = 0, nPromoted;\n\n\tpsid = rf_MapStripeIDToParityStripeID(&raidPtr->Layout, stripeID, &which_ru);\n\n\tRF_LOCK_PSS_MUTEX(raidPtr, row, psid);\n\n\tpssPtr = rf_LookupRUStatus(raidPtr, raidPtr->reconControl[row]->pssTable, psid, which_ru, RF_PSS_CREATE | RF_PSS_RECON_BLOCKED, &created);\n\n\t/* if recon is not ongoing on this PS, just return */\n\tif (!(pssPtr->flags & RF_PSS_UNDER_RECON)) {\n\t\tRF_UNLOCK_PSS_MUTEX(raidPtr, row, psid);\n\t\treturn (0);\n\t}\n\t/* otherwise, we have to wait for reconstruction to complete on this\n\t * RU. */\n\t/* In order to avoid waiting for a potentially large number of\n\t * low-priority accesses to complete, we force a normal-priority (i.e.\n\t * not low-priority) reconstruction on this RU. */\n\tif (!(pssPtr->flags & RF_PSS_FORCED_ON_WRITE) && !(pssPtr->flags & RF_PSS_FORCED_ON_READ)) {\n\t\tDDprintf1(\"Forcing recon on psid %ld\\n\", psid);\n\t\tpssPtr->flags |= RF_PSS_FORCED_ON_WRITE;\t/* mark this RU as under\n\t\t\t\t\t\t\t\t * forced recon */\n\t\tpssPtr->flags &= ~RF_PSS_RECON_BLOCKED;\t/* clear the blockage\n\t\t\t\t\t\t\t * that we just set */\n\t\tfcol = raidPtr->reconControl[row]->fcol;\n\n\t\t/* get a listing of the disks comprising the indicated stripe */\n\t\t(raidPtr->Layout.map->IdentifyStripe) (raidPtr, asmap->raidAddress, &diskids, &stripe);\n\t\tRF_ASSERT(row == stripe);\n\n\t\t/* For previously issued reads, elevate them to normal\n\t\t * priority.  If the I/O has already completed, it won't be\n\t\t * found in the queue, and hence this will be a no-op. For\n\t\t * unissued reads, allocate buffers and issue new reads.  The\n\t\t * fact that we've set the FORCED bit means that the regular\n\t\t * recon procs will not re-issue these reqs */\n\t\tfor (i = 0; i < raidPtr->Layout.numDataCol + raidPtr->Layout.numParityCol; i++)\n\t\t\tif ((diskno = diskids[i]) != fcol) {\n\t\t\t\tif (pssPtr->issued[diskno]) {\n\t\t\t\t\tnPromoted = rf_DiskIOPromote(&raidPtr->Queues[row][diskno], psid, which_ru);\n\t\t\t\t\tif (rf_reconDebug && nPromoted)\n\t\t\t\t\t\tprintf(\"raid%d: promoted read from row %d col %d\\n\", raidPtr->raidid, row, diskno);\n\t\t\t\t} else {\n\t\t\t\t\tnew_rbuf = rf_MakeReconBuffer(raidPtr, row, diskno, RF_RBUF_TYPE_FORCED);\t/* create new buf */\n\t\t\t\t\trf_ComputePSDiskOffsets(raidPtr, psid, row, diskno, &offset, &fd_offset,\n\t\t\t\t\t    &new_rbuf->spRow, &new_rbuf->spCol, &new_rbuf->spOffset);\t/* find offsets & spare\n\t\t\t\t\t\t\t\t\t\t\t\t\t * location */\n\t\t\t\t\tnew_rbuf->parityStripeID = psid;\t/* fill in the buffer */\n\t\t\t\t\tnew_rbuf->which_ru = which_ru;\n\t\t\t\t\tnew_rbuf->failedDiskSectorOffset = fd_offset;\n\t\t\t\t\tnew_rbuf->priority = RF_IO_NORMAL_PRIORITY;\n\n\t\t\t\t\t/* use NULL b_proc b/c all addrs\n\t\t\t\t\t * should be in kernel space */\n\t\t\t\t\treq = rf_CreateDiskQueueData(RF_IO_TYPE_READ, offset + which_ru * sectorsPerRU, sectorsPerRU, new_rbuf->buffer,\n\t\t\t\t\t    psid, which_ru, (int (*) (void *, int)) rf_ForceReconReadDoneProc, (void *) new_rbuf, NULL,\n\t\t\t\t\t    NULL, (void *) raidPtr, 0, NULL);\n\n\t\t\t\t\tRF_ASSERT(req);\t/* XXX -- fix this --\n\t\t\t\t\t\t\t * XXX */\n\n\t\t\t\t\tnew_rbuf->arg = req;\n\t\t\t\t\trf_DiskIOEnqueue(&raidPtr->Queues[row][diskno], req, RF_IO_NORMAL_PRIORITY);\t/* enqueue the I/O */\n\t\t\t\t\tDprintf3(\"raid%d: Issued new read req on row %d col %d\\n\", raidPtr->raidid, row, diskno);\n\t\t\t\t}\n\t\t\t}\n\t\t/* if the write is sitting in the disk queue, elevate its\n\t\t * priority */\n\t\tif (rf_DiskIOPromote(&raidPtr->Queues[row][fcol], psid, which_ru))\n\t\t\tprintf(\"raid%d: promoted write to row %d col %d\\n\", \n\t\t\t       raidPtr->raidid, row, fcol);\n\t}\n\t/* install a callback descriptor to be invoked when recon completes on\n\t * this parity stripe. */\n\tcb = rf_AllocCallbackDesc();\n\t/* XXX the following is bogus.. These functions don't really match!!\n\t * GO */\n\tcb->callbackFunc = (void (*) (RF_CBParam_t)) cbFunc;\n\tcb->callbackArg.p = (void *) cbArg;\n\tcb->next = pssPtr->procWaitList;\n\tpssPtr->procWaitList = cb;\n\tDDprintf2(\"raid%d: Waiting for forced recon on psid %ld\\n\", \n\t\t  raidPtr->raidid, psid);\n\n\tRF_UNLOCK_PSS_MUTEX(raidPtr, row, psid);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_AcquireStripeLock",
          "args": [
            "raidPtr->lockTable",
            "asm_p->stripeID",
            "&asm_p->lockReqDesc"
          ],
          "line": 352
        },
        "resolved": true,
        "details": {
          "function_name": "rf_AcquireStripeLock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_stripelocks.c",
          "lines": "225-330",
          "snippet": "int \nrf_AcquireStripeLock(\n    RF_LockTableEntry_t * lockTable,\n    RF_StripeNum_t stripeID,\n    RF_LockReqDesc_t * lockReqDesc)\n{\n\tRF_StripeLockDesc_t *lockDesc;\n\tRF_LockReqDesc_t *p;\n\tint     tid = 0, hashval = HASH_STRIPEID(stripeID);\n\tint     retcode = 0;\n\n\tRF_ASSERT(RF_IO_IS_R_OR_W(lockReqDesc->type));\n\n\tif (rf_stripeLockDebug) {\n\t\tif (stripeID == -1)\n\t\t\tDprintf1(\"[%d] Lock acquisition supressed (stripeID == -1)\\n\", tid);\n\t\telse {\n\t\t\tDprintf8(\"[%d] Trying to acquire stripe lock table 0x%lx SID %ld type %c range %ld-%ld, range2 %ld-%ld hashval %d\\n\",\n\t\t\t    tid, (unsigned long) lockTable, stripeID, lockReqDesc->type, lockReqDesc->start,\n\t\t\t    lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\tDprintf3(\"[%d] lock %ld hashval %d\\n\", tid, stripeID, hashval);\n\t\t\tFLUSH;\n\t\t}\n\t}\n\tif (stripeID == -1)\n\t\treturn (0);\n\tlockReqDesc->next = NULL;\t/* just to be sure */\n\n\tRF_LOCK_MUTEX(lockTable[hashval].mutex);\n\tfor (lockDesc = lockTable[hashval].descList; lockDesc; lockDesc = lockDesc->next) {\n\t\tif (lockDesc->stripeID == stripeID)\n\t\t\tbreak;\n\t}\n\n\tif (!lockDesc) {\t/* no entry in table => no one reading or\n\t\t\t\t * writing */\n\t\tlockDesc = AllocStripeLockDesc(stripeID);\n\t\tlockDesc->next = lockTable[hashval].descList;\n\t\tlockTable[hashval].descList = lockDesc;\n\t\tif (lockReqDesc->type == RF_IO_TYPE_WRITE)\n\t\t\tlockDesc->nWriters++;\n\t\tlockDesc->granted = lockReqDesc;\n\t\tif (rf_stripeLockDebug) {\n\t\t\tDprintf7(\"[%d] no one waiting: lock %ld %c %ld-%ld %ld-%ld granted\\n\",\n\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\tFLUSH;\n\t\t}\n\t} else {\n\n\t\tif (lockReqDesc->type == RF_IO_TYPE_WRITE)\n\t\t\tlockDesc->nWriters++;\n\n\t\tif (lockDesc->nWriters == 0) {\t/* no need to search any lists\n\t\t\t\t\t\t * if there are no writers\n\t\t\t\t\t\t * anywhere */\n\t\t\tlockReqDesc->next = lockDesc->granted;\n\t\t\tlockDesc->granted = lockReqDesc;\n\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\tDprintf7(\"[%d] no writers: lock %ld %c %ld-%ld %ld-%ld granted\\n\",\n\t\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\t\tFLUSH;\n\t\t\t}\n\t\t} else {\n\n\t\t\t/* search the granted & waiting lists for a conflict.\n\t\t\t * stop searching as soon as we find one */\n\t\t\tretcode = 0;\n\t\t\tfor (p = lockDesc->granted; p; p = p->next)\n\t\t\t\tif (STRIPELOCK_CONFLICT(lockReqDesc, p)) {\n\t\t\t\t\tretcode = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tif (!retcode)\n\t\t\t\tfor (p = lockDesc->waitersH; p; p = p->next)\n\t\t\t\t\tif (STRIPELOCK_CONFLICT(lockReqDesc, p)) {\n\t\t\t\t\t\tretcode = 2;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\tif (!retcode) {\n\t\t\t\tlockReqDesc->next = lockDesc->granted;\t/* no conflicts found =>\n\t\t\t\t\t\t\t\t\t * grant lock */\n\t\t\t\tlockDesc->granted = lockReqDesc;\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf7(\"[%d] no conflicts: lock %ld %c %ld-%ld %ld-%ld granted\\n\",\n\t\t\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop,\n\t\t\t\t\t    lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf6(\"[%d] conflict: lock %ld %c %ld-%ld hashval=%d not granted\\n\",\n\t\t\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop,\n\t\t\t\t\t    hashval);\n\t\t\t\t\tDprintf3(\"[%d] lock %ld retcode=%d\\n\", tid, stripeID, retcode);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t\tAddToWaitersQueue(lockTable, lockDesc, lockReqDesc);\t/* conflict => the\n\t\t\t\t\t\t\t\t\t\t\t * current access must\n\t\t\t\t\t\t\t\t\t\t\t * wait */\n\t\t\t}\n\t\t}\n\t}\n\n\tRF_UNLOCK_MUTEX(lockTable[hashval].mutex);\n\treturn (retcode);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_stripelocks.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define FLUSH"
          ],
          "globals_used": [
            "static void AddToWaitersQueue(RF_LockTableEntry_t * lockTable, RF_StripeLockDesc_t * lockDesc, RF_LockReqDesc_t * lockReqDesc);",
            "static RF_StripeLockDesc_t *AllocStripeLockDesc(RF_StripeNum_t stripeID);",
            "static void FreeStripeLockDesc(RF_StripeLockDesc_t * p);",
            "static void PrintLockedStripes(RF_LockTableEntry_t * lockTable);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_driver.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_stripelocks.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n\n#define FLUSH\n\nstatic void AddToWaitersQueue(RF_LockTableEntry_t * lockTable, RF_StripeLockDesc_t * lockDesc, RF_LockReqDesc_t * lockReqDesc);\nstatic RF_StripeLockDesc_t *AllocStripeLockDesc(RF_StripeNum_t stripeID);\nstatic void FreeStripeLockDesc(RF_StripeLockDesc_t * p);\nstatic void PrintLockedStripes(RF_LockTableEntry_t * lockTable);\n\nint \nrf_AcquireStripeLock(\n    RF_LockTableEntry_t * lockTable,\n    RF_StripeNum_t stripeID,\n    RF_LockReqDesc_t * lockReqDesc)\n{\n\tRF_StripeLockDesc_t *lockDesc;\n\tRF_LockReqDesc_t *p;\n\tint     tid = 0, hashval = HASH_STRIPEID(stripeID);\n\tint     retcode = 0;\n\n\tRF_ASSERT(RF_IO_IS_R_OR_W(lockReqDesc->type));\n\n\tif (rf_stripeLockDebug) {\n\t\tif (stripeID == -1)\n\t\t\tDprintf1(\"[%d] Lock acquisition supressed (stripeID == -1)\\n\", tid);\n\t\telse {\n\t\t\tDprintf8(\"[%d] Trying to acquire stripe lock table 0x%lx SID %ld type %c range %ld-%ld, range2 %ld-%ld hashval %d\\n\",\n\t\t\t    tid, (unsigned long) lockTable, stripeID, lockReqDesc->type, lockReqDesc->start,\n\t\t\t    lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\tDprintf3(\"[%d] lock %ld hashval %d\\n\", tid, stripeID, hashval);\n\t\t\tFLUSH;\n\t\t}\n\t}\n\tif (stripeID == -1)\n\t\treturn (0);\n\tlockReqDesc->next = NULL;\t/* just to be sure */\n\n\tRF_LOCK_MUTEX(lockTable[hashval].mutex);\n\tfor (lockDesc = lockTable[hashval].descList; lockDesc; lockDesc = lockDesc->next) {\n\t\tif (lockDesc->stripeID == stripeID)\n\t\t\tbreak;\n\t}\n\n\tif (!lockDesc) {\t/* no entry in table => no one reading or\n\t\t\t\t * writing */\n\t\tlockDesc = AllocStripeLockDesc(stripeID);\n\t\tlockDesc->next = lockTable[hashval].descList;\n\t\tlockTable[hashval].descList = lockDesc;\n\t\tif (lockReqDesc->type == RF_IO_TYPE_WRITE)\n\t\t\tlockDesc->nWriters++;\n\t\tlockDesc->granted = lockReqDesc;\n\t\tif (rf_stripeLockDebug) {\n\t\t\tDprintf7(\"[%d] no one waiting: lock %ld %c %ld-%ld %ld-%ld granted\\n\",\n\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\tFLUSH;\n\t\t}\n\t} else {\n\n\t\tif (lockReqDesc->type == RF_IO_TYPE_WRITE)\n\t\t\tlockDesc->nWriters++;\n\n\t\tif (lockDesc->nWriters == 0) {\t/* no need to search any lists\n\t\t\t\t\t\t * if there are no writers\n\t\t\t\t\t\t * anywhere */\n\t\t\tlockReqDesc->next = lockDesc->granted;\n\t\t\tlockDesc->granted = lockReqDesc;\n\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\tDprintf7(\"[%d] no writers: lock %ld %c %ld-%ld %ld-%ld granted\\n\",\n\t\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop, lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\t\tFLUSH;\n\t\t\t}\n\t\t} else {\n\n\t\t\t/* search the granted & waiting lists for a conflict.\n\t\t\t * stop searching as soon as we find one */\n\t\t\tretcode = 0;\n\t\t\tfor (p = lockDesc->granted; p; p = p->next)\n\t\t\t\tif (STRIPELOCK_CONFLICT(lockReqDesc, p)) {\n\t\t\t\t\tretcode = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\tif (!retcode)\n\t\t\t\tfor (p = lockDesc->waitersH; p; p = p->next)\n\t\t\t\t\tif (STRIPELOCK_CONFLICT(lockReqDesc, p)) {\n\t\t\t\t\t\tretcode = 2;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\tif (!retcode) {\n\t\t\t\tlockReqDesc->next = lockDesc->granted;\t/* no conflicts found =>\n\t\t\t\t\t\t\t\t\t * grant lock */\n\t\t\t\tlockDesc->granted = lockReqDesc;\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf7(\"[%d] no conflicts: lock %ld %c %ld-%ld %ld-%ld granted\\n\",\n\t\t\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop,\n\t\t\t\t\t    lockReqDesc->start2, lockReqDesc->stop2);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rf_stripeLockDebug) {\n\t\t\t\t\tDprintf6(\"[%d] conflict: lock %ld %c %ld-%ld hashval=%d not granted\\n\",\n\t\t\t\t\t    tid, stripeID, lockReqDesc->type, lockReqDesc->start, lockReqDesc->stop,\n\t\t\t\t\t    hashval);\n\t\t\t\t\tDprintf3(\"[%d] lock %ld retcode=%d\\n\", tid, stripeID, retcode);\n\t\t\t\t\tFLUSH;\n\t\t\t\t}\n\t\t\t\tAddToWaitersQueue(lockTable, lockDesc, lockReqDesc);\t/* conflict => the\n\t\t\t\t\t\t\t\t\t\t\t * current access must\n\t\t\t\t\t\t\t\t\t\t\t * wait */\n\t\t\t}\n\t\t}\n\t}\n\n\tRF_UNLOCK_MUTEX(lockTable[hashval].mutex);\n\treturn (retcode);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_INIT_LOCK_REQ_DESC",
          "args": [
            "asm_p->lockReqDesc",
            "desc->type",
            "(void (*) (struct buf *)) rf_ContinueRaidAccess",
            "desc",
            "asm_p",
            "raidPtr->Layout.dataSectorsPerStripe"
          ],
          "line": 349
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "asm_p->stripeID > lastStripeID"
          ],
          "line": 343
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "RF_IO_IS_R_OR_W(desc->type)"
          ],
          "line": 337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_IO_IS_R_OR_W",
          "args": [
            "desc->type"
          ],
          "line": 337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 331
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Lock(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tRF_StripeNum_t lastStripeID = -1;\n\n\t\t/* acquire each lock that we don't already hold */\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tRF_ASSERT(RF_IO_IS_R_OR_W(desc->type));\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS) &&\n\t\t\t    !(asm_p->flags & RF_ASM_FLAGS_LOCK_TRIED)) {\n\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_LOCK_TRIED;\n\t\t\t\tRF_ASSERT(asm_p->stripeID > lastStripeID);\t/* locks must be\n\t\t\t\t\t\t\t\t\t\t * acquired\n\t\t\t\t\t\t\t\t\t\t * hierarchically */\n\t\t\t\tlastStripeID = asm_p->stripeID;\n\t\t\t\t/* XXX the cast to (void (*)(RF_CBParam_t))\n\t\t\t\t * below is bogus!  GO */\n\t\t\t\tRF_INIT_LOCK_REQ_DESC(asm_p->lockReqDesc, desc->type,\n\t\t\t\t    (void (*) (struct buf *)) rf_ContinueRaidAccess, desc, asm_p,\n\t\t\t\t    raidPtr->Layout.dataSectorsPerStripe);\n\t\t\t\tif (rf_AcquireStripeLock(raidPtr->lockTable, asm_p->stripeID,\n\t\t\t\t\t&asm_p->lockReqDesc)) {\n\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (desc->type == RF_IO_TYPE_WRITE &&\n\t\t\t    raidPtr->status[asm_p->physInfo->row] == rf_rs_reconstructing) {\n\t\t\t\tif (!(asm_p->flags & RF_ASM_FLAGS_FORCE_TRIED)) {\n\t\t\t\t\tint     val;\n\n\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_FORCE_TRIED;\n\t\t\t\t\t/* XXX the cast below is quite\n\t\t\t\t\t * bogus!!! XXX  GO */\n\t\t\t\t\tval = rf_ForceOrBlockRecon(raidPtr, asm_p,\n\t\t\t\t\t    (void (*) (RF_Raid_t *, void *)) rf_ContinueRaidAccess, desc);\n\t\t\t\t\tif (val == 0) {\n\t\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_RECON_BLOCKED;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\t\tprintf(\"raid%d: skipping force/block because already done, psid %ld\\n\",\n\t\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\tprintf(\"raid%d: skipping force/block because not write or not under recon, psid %ld\\n\",\n\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tRF_ETIMER_STOP(timer);\n\t\tRF_ETIMER_EVAL(timer);\n\t\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\t\tif (suspended)\n\t\t\treturn (RF_TRUE);\n\t}\n\tdesc->state++;\n\treturn (RF_FALSE);\n}"
  },
  {
    "function_name": "rf_State_Map",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "300-319",
    "snippet": "int \nrf_State_Map(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\n\tRF_ETIMER_START(timer);\n\n\tif (!(desc->asmap = rf_MapAccess(raidPtr, desc->raidAddress, desc->numBlocks,\n\t\t    desc->bufPtr, RF_DONT_REMAP)))\n\t\tRF_PANIC();\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.map_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 315
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 314
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 313
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_PANIC",
          "args": [],
          "line": 311
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MapAccess",
          "args": [
            "raidPtr",
            "desc->raidAddress",
            "desc->numBlocks",
            "desc->bufPtr",
            "RF_DONT_REMAP"
          ],
          "line": 309
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 307
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Map(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\n\tRF_ETIMER_START(timer);\n\n\tif (!(desc->asmap = rf_MapAccess(raidPtr, desc->raidAddress, desc->numBlocks,\n\t\t    desc->bufPtr, RF_DONT_REMAP)))\n\t\tRF_PANIC();\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.map_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}"
  },
  {
    "function_name": "rf_State_Quiesce",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "261-298",
    "snippet": "int \nrf_State_Quiesce(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_ETIMER_START(timer);\n\tRF_ETIMER_START(desc->timer);\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\tif (raidPtr->accesses_suspended) {\n\t\tRF_CallbackDesc_t *cb;\n\t\tcb = rf_AllocCallbackDesc();\n\t\t/* XXX the following cast is quite bogus...\n\t\t * rf_ContinueRaidAccess takes a (RF_RaidAccessDesc_t *) as an\n\t\t * argument..  GO */\n\t\tcb->callbackFunc = (void (*) (RF_CBParam_t)) rf_ContinueRaidAccess;\n\t\tcb->callbackArg.p = (void *) desc;\n\t\tcb->next = raidPtr->quiesce_wait_list;\n\t\traidPtr->quiesce_wait_list = cb;\n\t\tsuspended = RF_TRUE;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.suspend_ovhd_us += RF_ETIMER_VAL_US(timer);\n\n\tif (suspended && rf_quiesceDebug)\n\t\tprintf(\"Stalling access due to quiescence lock\\n\");\n\n\tdesc->state++;\n\treturn suspended;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"Stalling access due to quiescence lock\\n\""
          ],
          "line": 294
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 291
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 290
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->access_suspend_mutex"
          ],
          "line": 287
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_AllocCallbackDesc",
          "args": [],
          "line": 277
        },
        "resolved": true,
        "details": {
          "function_name": "rf_AllocCallbackDesc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_callback.c",
          "lines": "80-87",
          "snippet": "RF_CallbackDesc_t *\nrf_AllocCallbackDesc()\n{\n\tRF_CallbackDesc_t *p;\n\n\tRF_FREELIST_GET(rf_callback_freelist, p, next, (RF_CallbackDesc_t *));\n\treturn (p);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_callback.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_callback_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_callback.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_callback_freelist;\n\nRF_CallbackDesc_t *\nrf_AllocCallbackDesc()\n{\n\tRF_CallbackDesc_t *p;\n\n\tRF_FREELIST_GET(rf_callback_freelist, p, next, (RF_CallbackDesc_t *));\n\treturn (p);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->access_suspend_mutex"
          ],
          "line": 274
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "desc->timer"
          ],
          "line": 272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "timer"
          ],
          "line": 271
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Quiesce(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_ETIMER_START(timer);\n\tRF_ETIMER_START(desc->timer);\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\tif (raidPtr->accesses_suspended) {\n\t\tRF_CallbackDesc_t *cb;\n\t\tcb = rf_AllocCallbackDesc();\n\t\t/* XXX the following cast is quite bogus...\n\t\t * rf_ContinueRaidAccess takes a (RF_RaidAccessDesc_t *) as an\n\t\t * argument..  GO */\n\t\tcb->callbackFunc = (void (*) (RF_CBParam_t)) rf_ContinueRaidAccess;\n\t\tcb->callbackArg.p = (void *) desc;\n\t\tcb->next = raidPtr->quiesce_wait_list;\n\t\traidPtr->quiesce_wait_list = cb;\n\t\tsuspended = RF_TRUE;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.suspend_ovhd_us += RF_ETIMER_VAL_US(timer);\n\n\tif (suspended && rf_quiesceDebug)\n\t\tprintf(\"Stalling access due to quiescence lock\\n\");\n\n\tdesc->state++;\n\treturn suspended;\n}"
  },
  {
    "function_name": "rf_State_DecrAccessCount",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "242-259",
    "snippet": "int \nrf_State_DecrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight--;\n\tif (raidPtr->accesses_suspended && raidPtr->accs_in_flight == 0) {\n\t\trf_SignalQuiescenceLock(raidPtr, raidPtr->reconDesc);\n\t}\n\trf_UpdateUserStats(raidPtr, RF_ETIMER_VAL_US(desc->timer), desc->numBlocks);\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->access_suspend_mutex"
          ],
          "line": 255
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_UpdateUserStats",
          "args": [
            "raidPtr",
            "RF_ETIMER_VAL_US(desc->timer)",
            "desc->numBlocks"
          ],
          "line": 254
        },
        "resolved": true,
        "details": {
          "function_name": "rf_UpdateUserStats",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_driver.c",
          "lines": "964-973",
          "snippet": "void \nrf_UpdateUserStats(raidPtr, rt, numsect)\n\tRF_Raid_t *raidPtr;\n\tint     rt;\t\t/* resp time in us */\n\tint     numsect;\t/* number of sectors for this access */\n{\n\traidPtr->userstats.sum_io_us += rt;\n\traidPtr->userstats.num_ios++;\n\traidPtr->userstats.num_sect_moved += numsect;\n}",
          "includes": [
            "#include <sys/buf.h>",
            "#include \"rf_kintf.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_options.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_copyback.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_nwayxor.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_memchunk.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_callback.h\"",
            "#include \"rf_revent.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_decluster.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_configure.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/vnode.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/systm.h>",
            "#include <sys/param.h>",
            "#include <sys/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void rf_UnconfigureVnodes( RF_Raid_t * );"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/buf.h>\n#include \"rf_kintf.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_options.h\"\n#include \"rf_driver.h\"\n#include \"rf_copyback.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_nwayxor.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_memchunk.h\"\n#include \"rf_engine.h\"\n#include \"rf_callback.h\"\n#include \"rf_revent.h\"\n#include \"rf_map.h\"\n#include \"rf_decluster.h\"\n#include \"rf_freelist.h\"\n#include \"rf_states.h\"\n#include \"rf_desc.h\"\n#include \"rf_general.h\"\n#include \"rf_configure.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_etimer.h\"\n#include \"rf_utils.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_aselect.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/vnode.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/systm.h>\n#include <sys/param.h>\n#include <sys/types.h>\n\nvoid rf_UnconfigureVnodes( RF_Raid_t * );\n\nvoid \nrf_UpdateUserStats(raidPtr, rt, numsect)\n\tRF_Raid_t *raidPtr;\n\tint     rt;\t\t/* resp time in us */\n\tint     numsect;\t/* number of sectors for this access */\n{\n\traidPtr->userstats.sum_io_us += rt;\n\traidPtr->userstats.num_ios++;\n\traidPtr->userstats.num_sect_moved += numsect;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "desc->timer"
          ],
          "line": 254
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_SignalQuiescenceLock",
          "args": [
            "raidPtr",
            "raidPtr->reconDesc"
          ],
          "line": 252
        },
        "resolved": true,
        "details": {
          "function_name": "rf_SignalQuiescenceLock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_driver.c",
          "lines": "769-783",
          "snippet": "void \nrf_SignalQuiescenceLock(raidPtr, reconDesc)\n\tRF_Raid_t *raidPtr;\n\tRF_RaidReconDesc_t *reconDesc;\n{\n\tif (rf_quiesceDebug) {\n\t\tprintf(\"raid%d: Signalling quiescence lock\\n\", \n\t\t       raidPtr->raidid);\n\t}\n\traidPtr->access_suspend_release = 1;\n\n\tif (raidPtr->waiting_for_quiescence) {\n\t\tSIGNAL_QUIESCENT_COND(raidPtr);\n\t}\n}",
          "includes": [
            "#include <sys/buf.h>",
            "#include \"rf_kintf.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_options.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_copyback.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_nwayxor.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_memchunk.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_callback.h\"",
            "#include \"rf_revent.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_decluster.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_configure.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/vnode.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/systm.h>",
            "#include <sys/param.h>",
            "#include <sys/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void rf_UnconfigureVnodes( RF_Raid_t * );"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/buf.h>\n#include \"rf_kintf.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_options.h\"\n#include \"rf_driver.h\"\n#include \"rf_copyback.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_nwayxor.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_memchunk.h\"\n#include \"rf_engine.h\"\n#include \"rf_callback.h\"\n#include \"rf_revent.h\"\n#include \"rf_map.h\"\n#include \"rf_decluster.h\"\n#include \"rf_freelist.h\"\n#include \"rf_states.h\"\n#include \"rf_desc.h\"\n#include \"rf_general.h\"\n#include \"rf_configure.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_etimer.h\"\n#include \"rf_utils.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_aselect.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/vnode.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/systm.h>\n#include <sys/param.h>\n#include <sys/types.h>\n\nvoid rf_UnconfigureVnodes( RF_Raid_t * );\n\nvoid \nrf_SignalQuiescenceLock(raidPtr, reconDesc)\n\tRF_Raid_t *raidPtr;\n\tRF_RaidReconDesc_t *reconDesc;\n{\n\tif (rf_quiesceDebug) {\n\t\tprintf(\"raid%d: Signalling quiescence lock\\n\", \n\t\t       raidPtr->raidid);\n\t}\n\traidPtr->access_suspend_release = 1;\n\n\tif (raidPtr->waiting_for_quiescence) {\n\t\tSIGNAL_QUIESCENT_COND(raidPtr);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->access_suspend_mutex"
          ],
          "line": 249
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_DecrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight--;\n\tif (raidPtr->accesses_suspended && raidPtr->accs_in_flight == 0) {\n\t\trf_SignalQuiescenceLock(raidPtr, raidPtr->reconDesc);\n\t}\n\trf_UpdateUserStats(raidPtr, RF_ETIMER_VAL_US(desc->timer), desc->numBlocks);\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}"
  },
  {
    "function_name": "rf_State_IncrAccessCount",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "226-240",
    "snippet": "int \nrf_State_IncrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\t/* Bummer. We have to do this to be 100% safe w.r.t. the increment\n\t * below */\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight++;\t/* used to detect quiescence */\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->access_suspend_mutex"
          ],
          "line": 236
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->access_suspend_mutex"
          ],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_IncrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\t/* Bummer. We have to do this to be 100% safe w.r.t. the increment\n\t * below */\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight++;\t/* used to detect quiescence */\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}"
  },
  {
    "function_name": "rf_State_LastState",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "192-224",
    "snippet": "int \nrf_State_LastState(RF_RaidAccessDesc_t * desc)\n{\n\tvoid    (*callbackFunc) (RF_CBParam_t) = desc->callbackFunc;\n\tRF_CBParam_t callbackArg;\n\n\tcallbackArg.p = desc->callbackArg;\n\n\t/*\n         * If this is not an async request, wake up the caller\n         */\n\tif (desc->async_flag == 0)\n\t\twakeup(desc->bp);\n\n\t/* \n\t * Wakeup any requests waiting to go.\n\t */\n\n\tRF_LOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\t((RF_Raid_t *) desc->raidPtr)->openings++;\n\tRF_UNLOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\n\t/* wake up any pending IO */\n\traidstart(((RF_Raid_t *) desc->raidPtr));\n\n\t/* printf(\"Calling biodone on 0x%x\\n\",desc->bp); */\n\tbiodone(desc->bp);\t/* access came through ioctl */\n\tif (callbackFunc)\n\t\tcallbackFunc(callbackArg);\n\trf_FreeRaidAccDesc(desc);\n\n\treturn RF_FALSE;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_FreeRaidAccDesc",
          "args": [
            "desc"
          ],
          "line": 221
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeRaidAccDesc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_driver.c",
          "lines": "633-647",
          "snippet": "void \nrf_FreeRaidAccDesc(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\n\tRF_ASSERT(desc);\n\n\trf_FreeAllocList(desc->cleanupList);\n\tRF_FREELIST_FREE_CLEAN_NOUNLOCK(rf_rad_freelist, desc, next, clean_rad);\n\traidPtr->nAccOutstanding--;\n\tif (raidPtr->waitShutdown) {\n\t\tRF_SIGNAL_COND(raidPtr->outstandingCond);\n\t}\n\tRF_FREELIST_DO_UNLOCK(rf_rad_freelist);\n}",
          "includes": [
            "#include <sys/buf.h>",
            "#include \"rf_kintf.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_options.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_copyback.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_nwayxor.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_memchunk.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_callback.h\"",
            "#include \"rf_revent.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_decluster.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_configure.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/vnode.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/systm.h>",
            "#include <sys/param.h>",
            "#include <sys/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_rad_freelist;",
            "static int init_rad(RF_RaidAccessDesc_t *);",
            "static void clean_rad(RF_RaidAccessDesc_t *);",
            "void rf_UnconfigureVnodes( RF_Raid_t * );"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/buf.h>\n#include \"rf_kintf.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_options.h\"\n#include \"rf_driver.h\"\n#include \"rf_copyback.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_nwayxor.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_memchunk.h\"\n#include \"rf_engine.h\"\n#include \"rf_callback.h\"\n#include \"rf_revent.h\"\n#include \"rf_map.h\"\n#include \"rf_decluster.h\"\n#include \"rf_freelist.h\"\n#include \"rf_states.h\"\n#include \"rf_desc.h\"\n#include \"rf_general.h\"\n#include \"rf_configure.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_etimer.h\"\n#include \"rf_utils.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_aselect.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/vnode.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/systm.h>\n#include <sys/param.h>\n#include <sys/types.h>\n\nstatic RF_FreeList_t *rf_rad_freelist;\nstatic int init_rad(RF_RaidAccessDesc_t *);\nstatic void clean_rad(RF_RaidAccessDesc_t *);\nvoid rf_UnconfigureVnodes( RF_Raid_t * );\n\nvoid \nrf_FreeRaidAccDesc(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\n\tRF_ASSERT(desc);\n\n\trf_FreeAllocList(desc->cleanupList);\n\tRF_FREELIST_FREE_CLEAN_NOUNLOCK(rf_rad_freelist, desc, next, clean_rad);\n\traidPtr->nAccOutstanding--;\n\tif (raidPtr->waitShutdown) {\n\t\tRF_SIGNAL_COND(raidPtr->outstandingCond);\n\t}\n\tRF_FREELIST_DO_UNLOCK(rf_rad_freelist);\n}"
        }
      },
      {
        "call_info": {
          "callee": "callbackFunc",
          "args": [
            "callbackArg"
          ],
          "line": 220
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "biodone",
          "args": [
            "desc->bp"
          ],
          "line": 218
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raidstart",
          "args": [
            "((RF_Raid_t *) desc->raidPtr)"
          ],
          "line": 215
        },
        "resolved": true,
        "details": {
          "function_name": "raidstart",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_netbsdkintf.c",
          "lines": "1350-1469",
          "snippet": "void\nraidstart(raidPtr)\n\tRF_Raid_t *raidPtr;\n{\n\tRF_SectorCount_t num_blocks, pb, sum;\n\tRF_RaidAddr_t raid_addr;\n\tint     retcode;\n\tstruct partition *pp;\n\tdaddr_t blocknum;\n\tint     unit;\n\tstruct raid_softc *rs;\n\tint     do_async;\n\tstruct buf *bp;\n\tstruct buf *dp;\n\n\tunit = raidPtr->raidid;\n\trs = &raid_softc[unit];\n\n\t/* Check to see if we're at the limit... */\n\tRF_LOCK_MUTEX(raidPtr->mutex);\n\twhile (raidPtr->openings > 0) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->mutex);\n\n\t\t/* get the next item, if any, from the queue */\n\t\tdp = &rs->buf_queue;\n\t\tbp = dp->b_actf;\n\t\tif (bp == NULL) {\n\t\t\t/* nothing more to do */\n\t\t\treturn;\n\t\t}\n\n\t\t/* update structures */\n\t\tdp = bp->b_actf;\n\t\tif (dp != NULL) {\n\t\t\tdp->b_actb = bp->b_actb;\n\t\t} else {\n\t\t\trs->buf_queue.b_actb = bp->b_actb;\n\t\t}\n\t\t*bp->b_actb = dp;\n\n\t/* Ok, for the bp we have here, bp->b_blkno is relative to the\n\t\t * partition.. Need to make it absolute to the underlying \n\t\t * device.. */\n\n\tblocknum = bp->b_blkno;\n\tif (DISKPART(bp->b_dev) != RAW_PART) {\n\t\tpp = &rs->sc_dkdev.dk_label->d_partitions[DISKPART(bp->b_dev)];\n\t\tblocknum += pp->p_offset;\n\t}\n\n\t\tdb1_printf((\"Blocks: %d, %d\\n\", (int) bp->b_blkno, \n\t\t\t    (int) blocknum));\n\n\tdb1_printf((\"bp->b_bcount = %d\\n\", (int) bp->b_bcount));\n\tdb1_printf((\"bp->b_resid = %d\\n\", (int) bp->b_resid));\n\n\t\t/* *THIS* is where we adjust what block we're going to... \n\t\t * but DO NOT TOUCH bp->b_blkno!!! */\n\traid_addr = blocknum;\n\n\tnum_blocks = bp->b_bcount >> raidPtr->logBytesPerSector;\n\tpb = (bp->b_bcount & raidPtr->sectorMask) ? 1 : 0;\n\tsum = raid_addr + num_blocks + pb;\n\tif (1 || rf_debugKernelAccess) {\n\t\tdb1_printf((\"raid_addr=%d sum=%d num_blocks=%d(+%d) (%d)\\n\",\n\t\t\t(int) raid_addr, (int) sum, (int) num_blocks,\n\t\t\t(int) pb, (int) bp->b_resid));\n\t}\n\tif ((sum > raidPtr->totalSectors) || (sum < raid_addr)\n\t    || (sum < num_blocks) || (sum < pb)) {\n\t\tbp->b_error = ENOSPC;\n\t\tbp->b_flags |= B_ERROR;\n\t\tbp->b_resid = bp->b_bcount;\n\t\tbiodone(bp);\n\t\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\t\t\tcontinue;\n\t}\n\t/*\n\t * XXX rf_DoAccess() should do this, not just DoAccessKernel()\n\t */\n\n\tif (bp->b_bcount & raidPtr->sectorMask) {\n\t\tbp->b_error = EINVAL;\n\t\tbp->b_flags |= B_ERROR;\n\t\tbp->b_resid = bp->b_bcount;\n\t\tbiodone(bp);\n\t\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\t\t\tcontinue;\n\t\t\t\n\t}\n\tdb1_printf((\"Calling DoAccess..\\n\"));\n\n\n\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\traidPtr->openings--;\n\tRF_UNLOCK_MUTEX(raidPtr->mutex);\n\n\t/*\n\t * Everything is async.\n\t */\n\tdo_async = 1;\n\t\t\n\t\t/* don't ever condition on bp->b_flags & B_WRITE.  \n\t\t * always condition on B_READ instead */\n\n\t\t/* XXX we're still at splbio() here... do we *really* \n\t\t   need to be? */\n\n\t\t\n\tretcode = rf_DoAccess(raidPtr, (bp->b_flags & B_READ) ?\n\t    RF_IO_TYPE_READ : RF_IO_TYPE_WRITE,\n\t    do_async, raid_addr, num_blocks,\n\t\t\t\t      bp->b_un.b_addr, bp, NULL, NULL, \n\t\t\t\t      RF_DAG_NONBLOCKING_IO, NULL, NULL, NULL);\n\n\n\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->mutex);\n}",
          "includes": [
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_options.h\"",
            "#include \"rf_kintf.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_acctrace.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_dagflags.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_copyback.h\"",
            "#include \"rf_raidframe.h\"",
            "#include \"rf_raid.h\"",
            "#include \"raid.h\"",
            "#include <sys/user.h>",
            "#include <sys/buf.h>",
            "#include <sys/lock.h>",
            "#include <sys/conf.h>",
            "#include <sys/disklabel.h>",
            "#include <machine/types.h>",
            "#include <sys/types.h>",
            "#include <sys/param.h>",
            "#include <sys/vnode.h>",
            "#include <sys/namei.h>",
            "#include <sys/systm.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/stat.h>",
            "#include <sys/device.h>",
            "#include <sys/disk.h>",
            "#include <sys/queue.h>",
            "#include <sys/pool.h>",
            "#include <sys/param.h>",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void KernelWakeupFunc(struct buf * bp);",
            "struct raid_softc *raid_softc;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_threadstuff.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_driver.h\"\n#include \"rf_options.h\"\n#include \"rf_kintf.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_acctrace.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_dagflags.h\"\n#include \"rf_dag.h\"\n#include \"rf_copyback.h\"\n#include \"rf_raidframe.h\"\n#include \"rf_raid.h\"\n#include \"raid.h\"\n#include <sys/user.h>\n#include <sys/buf.h>\n#include <sys/lock.h>\n#include <sys/conf.h>\n#include <sys/disklabel.h>\n#include <machine/types.h>\n#include <sys/types.h>\n#include <sys/param.h>\n#include <sys/vnode.h>\n#include <sys/namei.h>\n#include <sys/systm.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/stat.h>\n#include <sys/device.h>\n#include <sys/disk.h>\n#include <sys/queue.h>\n#include <sys/pool.h>\n#include <sys/param.h>\n#include <sys/errno.h>\n\nstatic void KernelWakeupFunc(struct buf * bp);\nstruct raid_softc *raid_softc;\n\nvoid\nraidstart(raidPtr)\n\tRF_Raid_t *raidPtr;\n{\n\tRF_SectorCount_t num_blocks, pb, sum;\n\tRF_RaidAddr_t raid_addr;\n\tint     retcode;\n\tstruct partition *pp;\n\tdaddr_t blocknum;\n\tint     unit;\n\tstruct raid_softc *rs;\n\tint     do_async;\n\tstruct buf *bp;\n\tstruct buf *dp;\n\n\tunit = raidPtr->raidid;\n\trs = &raid_softc[unit];\n\n\t/* Check to see if we're at the limit... */\n\tRF_LOCK_MUTEX(raidPtr->mutex);\n\twhile (raidPtr->openings > 0) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->mutex);\n\n\t\t/* get the next item, if any, from the queue */\n\t\tdp = &rs->buf_queue;\n\t\tbp = dp->b_actf;\n\t\tif (bp == NULL) {\n\t\t\t/* nothing more to do */\n\t\t\treturn;\n\t\t}\n\n\t\t/* update structures */\n\t\tdp = bp->b_actf;\n\t\tif (dp != NULL) {\n\t\t\tdp->b_actb = bp->b_actb;\n\t\t} else {\n\t\t\trs->buf_queue.b_actb = bp->b_actb;\n\t\t}\n\t\t*bp->b_actb = dp;\n\n\t/* Ok, for the bp we have here, bp->b_blkno is relative to the\n\t\t * partition.. Need to make it absolute to the underlying \n\t\t * device.. */\n\n\tblocknum = bp->b_blkno;\n\tif (DISKPART(bp->b_dev) != RAW_PART) {\n\t\tpp = &rs->sc_dkdev.dk_label->d_partitions[DISKPART(bp->b_dev)];\n\t\tblocknum += pp->p_offset;\n\t}\n\n\t\tdb1_printf((\"Blocks: %d, %d\\n\", (int) bp->b_blkno, \n\t\t\t    (int) blocknum));\n\n\tdb1_printf((\"bp->b_bcount = %d\\n\", (int) bp->b_bcount));\n\tdb1_printf((\"bp->b_resid = %d\\n\", (int) bp->b_resid));\n\n\t\t/* *THIS* is where we adjust what block we're going to... \n\t\t * but DO NOT TOUCH bp->b_blkno!!! */\n\traid_addr = blocknum;\n\n\tnum_blocks = bp->b_bcount >> raidPtr->logBytesPerSector;\n\tpb = (bp->b_bcount & raidPtr->sectorMask) ? 1 : 0;\n\tsum = raid_addr + num_blocks + pb;\n\tif (1 || rf_debugKernelAccess) {\n\t\tdb1_printf((\"raid_addr=%d sum=%d num_blocks=%d(+%d) (%d)\\n\",\n\t\t\t(int) raid_addr, (int) sum, (int) num_blocks,\n\t\t\t(int) pb, (int) bp->b_resid));\n\t}\n\tif ((sum > raidPtr->totalSectors) || (sum < raid_addr)\n\t    || (sum < num_blocks) || (sum < pb)) {\n\t\tbp->b_error = ENOSPC;\n\t\tbp->b_flags |= B_ERROR;\n\t\tbp->b_resid = bp->b_bcount;\n\t\tbiodone(bp);\n\t\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\t\t\tcontinue;\n\t}\n\t/*\n\t * XXX rf_DoAccess() should do this, not just DoAccessKernel()\n\t */\n\n\tif (bp->b_bcount & raidPtr->sectorMask) {\n\t\tbp->b_error = EINVAL;\n\t\tbp->b_flags |= B_ERROR;\n\t\tbp->b_resid = bp->b_bcount;\n\t\tbiodone(bp);\n\t\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\t\t\tcontinue;\n\t\t\t\n\t}\n\tdb1_printf((\"Calling DoAccess..\\n\"));\n\n\n\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\traidPtr->openings--;\n\tRF_UNLOCK_MUTEX(raidPtr->mutex);\n\n\t/*\n\t * Everything is async.\n\t */\n\tdo_async = 1;\n\t\t\n\t\t/* don't ever condition on bp->b_flags & B_WRITE.  \n\t\t * always condition on B_READ instead */\n\n\t\t/* XXX we're still at splbio() here... do we *really* \n\t\t   need to be? */\n\n\t\t\n\tretcode = rf_DoAccess(raidPtr, (bp->b_flags & B_READ) ?\n\t    RF_IO_TYPE_READ : RF_IO_TYPE_WRITE,\n\t    do_async, raid_addr, num_blocks,\n\t\t\t\t      bp->b_un.b_addr, bp, NULL, NULL, \n\t\t\t\t      RF_DAG_NONBLOCKING_IO, NULL, NULL, NULL);\n\n\n\t\tRF_LOCK_MUTEX(raidPtr->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "((RF_Raid_t *) desc->raidPtr)->mutex"
          ],
          "line": 212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "((RF_Raid_t *) desc->raidPtr)->mutex"
          ],
          "line": 210
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wakeup",
          "args": [
            "desc->bp"
          ],
          "line": 204
        },
        "resolved": true,
        "details": {
          "function_name": "audio_wakeup",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/audio.c",
          "lines": "765-774",
          "snippet": "static __inline void\naudio_wakeup(chan)\n\tint *chan;\n{\n\tDPRINTFN(3, (\"audio_wakeup: chan=%p, *chan=%d\\n\", chan, *chan));\n\tif (*chan) {\n\t\twakeup(chan);\n\t\t*chan = 0;\n\t}\n}",
          "includes": [
            "#include <machine/endian.h>",
            "#include <vm/vm_prot.h>",
            "#include <vm/vm.h>",
            "#include <dev/rndvar.h>",
            "#include <dev/audiovar.h>",
            "#include <dev/audio_if.h>",
            "#include <sys/device.h>",
            "#include <sys/audioio.h>",
            "#include <sys/conf.h>",
            "#include <sys/signalvar.h>",
            "#include <sys/kernel.h>",
            "#include <sys/syslog.h>",
            "#include <sys/systm.h>",
            "#include <sys/proc.h>",
            "#include <sys/malloc.h>",
            "#include <sys/poll.h>",
            "#include <sys/select.h>",
            "#include <sys/vnode.h>",
            "#include <sys/fcntl.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/param.h>",
            "#include \"audio.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <machine/endian.h>\n#include <vm/vm_prot.h>\n#include <vm/vm.h>\n#include <dev/rndvar.h>\n#include <dev/audiovar.h>\n#include <dev/audio_if.h>\n#include <sys/device.h>\n#include <sys/audioio.h>\n#include <sys/conf.h>\n#include <sys/signalvar.h>\n#include <sys/kernel.h>\n#include <sys/syslog.h>\n#include <sys/systm.h>\n#include <sys/proc.h>\n#include <sys/malloc.h>\n#include <sys/poll.h>\n#include <sys/select.h>\n#include <sys/vnode.h>\n#include <sys/fcntl.h>\n#include <sys/ioctl.h>\n#include <sys/param.h>\n#include \"audio.h\"\n\nstatic __inline void\naudio_wakeup(chan)\n\tint *chan;\n{\n\tDPRINTFN(3, (\"audio_wakeup: chan=%p, *chan=%d\\n\", chan, *chan));\n\tif (*chan) {\n\t\twakeup(chan);\n\t\t*chan = 0;\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_LastState(RF_RaidAccessDesc_t * desc)\n{\n\tvoid    (*callbackFunc) (RF_CBParam_t) = desc->callbackFunc;\n\tRF_CBParam_t callbackArg;\n\n\tcallbackArg.p = desc->callbackArg;\n\n\t/*\n         * If this is not an async request, wake up the caller\n         */\n\tif (desc->async_flag == 0)\n\t\twakeup(desc->bp);\n\n\t/* \n\t * Wakeup any requests waiting to go.\n\t */\n\n\tRF_LOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\t((RF_Raid_t *) desc->raidPtr)->openings++;\n\tRF_UNLOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\n\t/* wake up any pending IO */\n\traidstart(((RF_Raid_t *) desc->raidPtr));\n\n\t/* printf(\"Calling biodone on 0x%x\\n\",desc->bp); */\n\tbiodone(desc->bp);\t/* access came through ioctl */\n\tif (callbackFunc)\n\t\tcallbackFunc(callbackArg);\n\trf_FreeRaidAccDesc(desc);\n\n\treturn RF_FALSE;\n}"
  },
  {
    "function_name": "rf_ContinueDagAccess",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "150-190",
    "snippet": "void \nrf_ContinueDagAccess(RF_DagList_t * dagList)\n{\n\tRF_AccTraceEntry_t *tracerec = &(dagList->desc->tracerec);\n\tRF_RaidAccessDesc_t *desc;\n\tRF_DagHeader_t *dag_h;\n\tRF_Etimer_t timer;\n\tint     i;\n\n\tdesc = dagList->desc;\n\n\ttimer = tracerec->timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.exec_us = RF_ETIMER_VAL_US(timer);\n\tRF_ETIMER_START(tracerec->timer);\n\n\t/* skip to dag which just finished */\n\tdag_h = dagList->dags;\n\tfor (i = 0; i < dagList->numDagsDone; i++) {\n\t\tdag_h = dag_h->next;\n\t}\n\n\t/* check to see if retry is required */\n\tif (dag_h->status == rf_rollBackward) {\n\t\t/* when a dag fails, mark desc status as bad and allow all\n\t\t * other dags in the desc to execute to completion.  then,\n\t\t * free all dags and start over */\n\t\tdesc->status = 1;\t/* bad status */\n\t\t{\n\t\t\tprintf(\"raid%d: DAG failure: %c addr 0x%lx (%ld) nblk 0x%x (%d) buf 0x%lx\\n\",\n\t\t\t       desc->raidPtr->raidid, desc->type, \n\t\t\t       (long) desc->raidAddress,\n\t\t\t    (long) desc->raidAddress, (int) desc->numBlocks,\n\t\t\t       (int) desc->numBlocks, \n\t\t\t       (unsigned long) (desc->bufPtr));\n\t\t}\n\t}\n\tdagList->numDagsDone++;\n\trf_ContinueRaidAccess(desc);\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_ContinueRaidAccess",
          "args": [
            "desc"
          ],
          "line": 189
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ContinueRaidAccess",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "87-147",
          "snippet": "void \nrf_ContinueRaidAccess(RF_RaidAccessDesc_t * desc)\n{\n\tint     suspended = RF_FALSE;\n\tint     current_state_index = desc->state;\n\tRF_AccessState_t current_state = desc->states[current_state_index];\n\tint     unit = desc->raidPtr->raidid;\n\n\tdo {\n\n\t\tcurrent_state_index = desc->state;\n\t\tcurrent_state = desc->states[current_state_index];\n\n\t\tswitch (current_state) {\n\n\t\tcase rf_QuiesceState:\n\t\t\tsuspended = rf_State_Quiesce(desc);\n\t\t\tbreak;\n\t\tcase rf_IncrAccessesCountState:\n\t\t\tsuspended = rf_State_IncrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_MapState:\n\t\t\tsuspended = rf_State_Map(desc);\n\t\t\tbreak;\n\t\tcase rf_LockState:\n\t\t\tsuspended = rf_State_Lock(desc);\n\t\t\tbreak;\n\t\tcase rf_CreateDAGState:\n\t\t\tsuspended = rf_State_CreateDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ExecuteDAGState:\n\t\t\tsuspended = rf_State_ExecuteDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ProcessDAGState:\n\t\t\tsuspended = rf_State_ProcessDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_CleanupState:\n\t\t\tsuspended = rf_State_Cleanup(desc);\n\t\t\tbreak;\n\t\tcase rf_DecrAccessesCountState:\n\t\t\tsuspended = rf_State_DecrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_LastState:\n\t\t\tsuspended = rf_State_LastState(desc);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* after this point, we cannot dereference desc since desc may\n\t\t * have been freed. desc is only freed in LastState, so if we\n\t\t * renter this function or loop back up, desc should be valid. */\n\n\t\tif (rf_printStatesDebug) {\n\t\t\tprintf(\"raid%d: State: %-24s StateIndex: %3i desc: 0x%ld %s\\n\",\n\t\t\t       unit, StateName(current_state), \n\t\t\t       current_state_index, (long) desc,\n\t\t\t    suspended ? \"callback scheduled\" : \"looping\");\n\t\t}\n\t} while (!suspended && current_state != rf_LastState);\n\n\treturn;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nvoid \nrf_ContinueRaidAccess(RF_RaidAccessDesc_t * desc)\n{\n\tint     suspended = RF_FALSE;\n\tint     current_state_index = desc->state;\n\tRF_AccessState_t current_state = desc->states[current_state_index];\n\tint     unit = desc->raidPtr->raidid;\n\n\tdo {\n\n\t\tcurrent_state_index = desc->state;\n\t\tcurrent_state = desc->states[current_state_index];\n\n\t\tswitch (current_state) {\n\n\t\tcase rf_QuiesceState:\n\t\t\tsuspended = rf_State_Quiesce(desc);\n\t\t\tbreak;\n\t\tcase rf_IncrAccessesCountState:\n\t\t\tsuspended = rf_State_IncrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_MapState:\n\t\t\tsuspended = rf_State_Map(desc);\n\t\t\tbreak;\n\t\tcase rf_LockState:\n\t\t\tsuspended = rf_State_Lock(desc);\n\t\t\tbreak;\n\t\tcase rf_CreateDAGState:\n\t\t\tsuspended = rf_State_CreateDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ExecuteDAGState:\n\t\t\tsuspended = rf_State_ExecuteDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ProcessDAGState:\n\t\t\tsuspended = rf_State_ProcessDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_CleanupState:\n\t\t\tsuspended = rf_State_Cleanup(desc);\n\t\t\tbreak;\n\t\tcase rf_DecrAccessesCountState:\n\t\t\tsuspended = rf_State_DecrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_LastState:\n\t\t\tsuspended = rf_State_LastState(desc);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* after this point, we cannot dereference desc since desc may\n\t\t * have been freed. desc is only freed in LastState, so if we\n\t\t * renter this function or loop back up, desc should be valid. */\n\n\t\tif (rf_printStatesDebug) {\n\t\t\tprintf(\"raid%d: State: %-24s StateIndex: %3i desc: 0x%ld %s\\n\",\n\t\t\t       unit, StateName(current_state), \n\t\t\t       current_state_index, (long) desc,\n\t\t\t    suspended ? \"callback scheduled\" : \"looping\");\n\t\t}\n\t} while (!suspended && current_state != rf_LastState);\n\n\treturn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"raid%d: DAG failure: %c addr 0x%lx (%ld) nblk 0x%x (%d) buf 0x%lx\\n\"",
            "desc->raidPtr->raidid",
            "desc->type",
            "(long) desc->raidAddress",
            "(long) desc->raidAddress",
            "(int) desc->numBlocks",
            "(int) desc->numBlocks",
            "(unsigned long) (desc->bufPtr)"
          ],
          "line": 180
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_START",
          "args": [
            "tracerec->timer"
          ],
          "line": 165
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 164
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 163
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 162
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nvoid \nrf_ContinueDagAccess(RF_DagList_t * dagList)\n{\n\tRF_AccTraceEntry_t *tracerec = &(dagList->desc->tracerec);\n\tRF_RaidAccessDesc_t *desc;\n\tRF_DagHeader_t *dag_h;\n\tRF_Etimer_t timer;\n\tint     i;\n\n\tdesc = dagList->desc;\n\n\ttimer = tracerec->timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.exec_us = RF_ETIMER_VAL_US(timer);\n\tRF_ETIMER_START(tracerec->timer);\n\n\t/* skip to dag which just finished */\n\tdag_h = dagList->dags;\n\tfor (i = 0; i < dagList->numDagsDone; i++) {\n\t\tdag_h = dag_h->next;\n\t}\n\n\t/* check to see if retry is required */\n\tif (dag_h->status == rf_rollBackward) {\n\t\t/* when a dag fails, mark desc status as bad and allow all\n\t\t * other dags in the desc to execute to completion.  then,\n\t\t * free all dags and start over */\n\t\tdesc->status = 1;\t/* bad status */\n\t\t{\n\t\t\tprintf(\"raid%d: DAG failure: %c addr 0x%lx (%ld) nblk 0x%x (%d) buf 0x%lx\\n\",\n\t\t\t       desc->raidPtr->raidid, desc->type, \n\t\t\t       (long) desc->raidAddress,\n\t\t\t    (long) desc->raidAddress, (int) desc->numBlocks,\n\t\t\t       (int) desc->numBlocks, \n\t\t\t       (unsigned long) (desc->bufPtr));\n\t\t}\n\t}\n\tdagList->numDagsDone++;\n\trf_ContinueRaidAccess(desc);\n}"
  },
  {
    "function_name": "rf_ContinueRaidAccess",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "87-147",
    "snippet": "void \nrf_ContinueRaidAccess(RF_RaidAccessDesc_t * desc)\n{\n\tint     suspended = RF_FALSE;\n\tint     current_state_index = desc->state;\n\tRF_AccessState_t current_state = desc->states[current_state_index];\n\tint     unit = desc->raidPtr->raidid;\n\n\tdo {\n\n\t\tcurrent_state_index = desc->state;\n\t\tcurrent_state = desc->states[current_state_index];\n\n\t\tswitch (current_state) {\n\n\t\tcase rf_QuiesceState:\n\t\t\tsuspended = rf_State_Quiesce(desc);\n\t\t\tbreak;\n\t\tcase rf_IncrAccessesCountState:\n\t\t\tsuspended = rf_State_IncrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_MapState:\n\t\t\tsuspended = rf_State_Map(desc);\n\t\t\tbreak;\n\t\tcase rf_LockState:\n\t\t\tsuspended = rf_State_Lock(desc);\n\t\t\tbreak;\n\t\tcase rf_CreateDAGState:\n\t\t\tsuspended = rf_State_CreateDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ExecuteDAGState:\n\t\t\tsuspended = rf_State_ExecuteDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ProcessDAGState:\n\t\t\tsuspended = rf_State_ProcessDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_CleanupState:\n\t\t\tsuspended = rf_State_Cleanup(desc);\n\t\t\tbreak;\n\t\tcase rf_DecrAccessesCountState:\n\t\t\tsuspended = rf_State_DecrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_LastState:\n\t\t\tsuspended = rf_State_LastState(desc);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* after this point, we cannot dereference desc since desc may\n\t\t * have been freed. desc is only freed in LastState, so if we\n\t\t * renter this function or loop back up, desc should be valid. */\n\n\t\tif (rf_printStatesDebug) {\n\t\t\tprintf(\"raid%d: State: %-24s StateIndex: %3i desc: 0x%ld %s\\n\",\n\t\t\t       unit, StateName(current_state), \n\t\t\t       current_state_index, (long) desc,\n\t\t\t    suspended ? \"callback scheduled\" : \"looping\");\n\t\t}\n\t} while (!suspended && current_state != rf_LastState);\n\n\treturn;\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"raid%d: State: %-24s StateIndex: %3i desc: 0x%ld %s\\n\"",
            "unit",
            "StateName(current_state)",
            "current_state_index",
            "(long) desc",
            "suspended ? \"callback scheduled\" : \"looping\""
          ],
          "line": 139
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "StateName",
          "args": [
            "current_state"
          ],
          "line": 140
        },
        "resolved": true,
        "details": {
          "function_name": "StateName",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "59-85",
          "snippet": "static char *\nStateName(RF_AccessState_t state)\n{\n\tswitch (state) {\n\t\tcase rf_QuiesceState:return \"QuiesceState\";\n\tcase rf_MapState:\n\t\treturn \"MapState\";\n\tcase rf_LockState:\n\t\treturn \"LockState\";\n\tcase rf_CreateDAGState:\n\t\treturn \"CreateDAGState\";\n\tcase rf_ExecuteDAGState:\n\t\treturn \"ExecuteDAGState\";\n\tcase rf_ProcessDAGState:\n\t\treturn \"ProcessDAGState\";\n\tcase rf_CleanupState:\n\t\treturn \"CleanupState\";\n\tcase rf_LastState:\n\t\treturn \"LastState\";\n\tcase rf_IncrAccessesCountState:\n\t\treturn \"IncrAccessesCountState\";\n\tcase rf_DecrAccessesCountState:\n\t\treturn \"DecrAccessesCountState\";\n\tdefault:\n\t\treturn \"!!! UnnamedState !!!\";\n\t}\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nstatic char *\nStateName(RF_AccessState_t state)\n{\n\tswitch (state) {\n\t\tcase rf_QuiesceState:return \"QuiesceState\";\n\tcase rf_MapState:\n\t\treturn \"MapState\";\n\tcase rf_LockState:\n\t\treturn \"LockState\";\n\tcase rf_CreateDAGState:\n\t\treturn \"CreateDAGState\";\n\tcase rf_ExecuteDAGState:\n\t\treturn \"ExecuteDAGState\";\n\tcase rf_ProcessDAGState:\n\t\treturn \"ProcessDAGState\";\n\tcase rf_CleanupState:\n\t\treturn \"CleanupState\";\n\tcase rf_LastState:\n\t\treturn \"LastState\";\n\tcase rf_IncrAccessesCountState:\n\t\treturn \"IncrAccessesCountState\";\n\tcase rf_DecrAccessesCountState:\n\t\treturn \"DecrAccessesCountState\";\n\tdefault:\n\t\treturn \"!!! UnnamedState !!!\";\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_LastState",
          "args": [
            "desc"
          ],
          "line": 130
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_LastState",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "192-224",
          "snippet": "int \nrf_State_LastState(RF_RaidAccessDesc_t * desc)\n{\n\tvoid    (*callbackFunc) (RF_CBParam_t) = desc->callbackFunc;\n\tRF_CBParam_t callbackArg;\n\n\tcallbackArg.p = desc->callbackArg;\n\n\t/*\n         * If this is not an async request, wake up the caller\n         */\n\tif (desc->async_flag == 0)\n\t\twakeup(desc->bp);\n\n\t/* \n\t * Wakeup any requests waiting to go.\n\t */\n\n\tRF_LOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\t((RF_Raid_t *) desc->raidPtr)->openings++;\n\tRF_UNLOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\n\t/* wake up any pending IO */\n\traidstart(((RF_Raid_t *) desc->raidPtr));\n\n\t/* printf(\"Calling biodone on 0x%x\\n\",desc->bp); */\n\tbiodone(desc->bp);\t/* access came through ioctl */\n\tif (callbackFunc)\n\t\tcallbackFunc(callbackArg);\n\trf_FreeRaidAccDesc(desc);\n\n\treturn RF_FALSE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_LastState(RF_RaidAccessDesc_t * desc)\n{\n\tvoid    (*callbackFunc) (RF_CBParam_t) = desc->callbackFunc;\n\tRF_CBParam_t callbackArg;\n\n\tcallbackArg.p = desc->callbackArg;\n\n\t/*\n         * If this is not an async request, wake up the caller\n         */\n\tif (desc->async_flag == 0)\n\t\twakeup(desc->bp);\n\n\t/* \n\t * Wakeup any requests waiting to go.\n\t */\n\n\tRF_LOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\t((RF_Raid_t *) desc->raidPtr)->openings++;\n\tRF_UNLOCK_MUTEX(((RF_Raid_t *) desc->raidPtr)->mutex);\n\n\t/* wake up any pending IO */\n\traidstart(((RF_Raid_t *) desc->raidPtr));\n\n\t/* printf(\"Calling biodone on 0x%x\\n\",desc->bp); */\n\tbiodone(desc->bp);\t/* access came through ioctl */\n\tif (callbackFunc)\n\t\tcallbackFunc(callbackArg);\n\trf_FreeRaidAccDesc(desc);\n\n\treturn RF_FALSE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_DecrAccessCount",
          "args": [
            "desc"
          ],
          "line": 127
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_DecrAccessCount",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "242-259",
          "snippet": "int \nrf_State_DecrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight--;\n\tif (raidPtr->accesses_suspended && raidPtr->accs_in_flight == 0) {\n\t\trf_SignalQuiescenceLock(raidPtr, raidPtr->reconDesc);\n\t}\n\trf_UpdateUserStats(raidPtr, RF_ETIMER_VAL_US(desc->timer), desc->numBlocks);\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_DecrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight--;\n\tif (raidPtr->accesses_suspended && raidPtr->accs_in_flight == 0) {\n\t\trf_SignalQuiescenceLock(raidPtr, raidPtr->reconDesc);\n\t}\n\trf_UpdateUserStats(raidPtr, RF_ETIMER_VAL_US(desc->timer), desc->numBlocks);\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_Cleanup",
          "args": [
            "desc"
          ],
          "line": 124
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_Cleanup",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "571-657",
          "snippet": "int \nrf_State_Cleanup(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_DagHeader_t *dag_h;\n\tRF_Etimer_t timer;\n\tint i;\n\n\tdesc->state++;\n\n\ttimer = tracerec->timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.dag_retry_us = RF_ETIMER_VAL_US(timer);\n\n\t/* the RAID I/O is complete.  Clean up. */\n\ttracerec->specific.user.dag_retry_us = 0;\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_DAG) {\n\t\t/* copy dags into paramDAG */\n\t\t*(desc->paramDAG) = desc->dagArray[0].dags;\n\t\tdag_h = *(desc->paramDAG);\n\t\tfor (i = 1; i < desc->numStripes; i++) {\n\t\t\t/* concatenate dags from remaining stripes */\n\t\t\tRF_ASSERT(dag_h);\n\t\t\twhile (dag_h->next)\n\t\t\t\tdag_h = dag_h->next;\n\t\t\tdag_h->next = desc->dagArray[i].dags;\n\t\t}\n\t} else {\n\t\t/* free all dags */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t}\n\t}\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us = RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS)) {\n\t\t\t\tRF_ASSERT_VALID_LOCKREQ(&asm_p->lockReqDesc);\n\t\t\t\trf_ReleaseStripeLock(raidPtr->lockTable, \n\t\t\t\t\t\t     asm_p->stripeID,\n\t\t\t\t    &asm_p->lockReqDesc);\n\t\t\t}\n\t\t\tif (asm_p->flags & RF_ASM_FLAGS_RECON_BLOCKED) {\n\t\t\t\trf_UnblockRecon(raidPtr, asm_p);\n\t\t\t}\n\t\t}\n\t}\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_ASM)\n\t\t*(desc->paramASM) = asmh;\n\telse\n\t\trf_FreeAccessStripeMap(asmh);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_STOP(desc->timer);\n\tRF_ETIMER_EVAL(desc->timer);\n\n\ttimer = desc->tracerec.tot_timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\tdesc->tracerec.total_us = RF_ETIMER_VAL_US(timer);\n\n\trf_LogTraceRec(raidPtr, tracerec);\n\n\tdesc->flags |= RF_DAG_ACCESS_COMPLETE;\n\n\treturn RF_FALSE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Cleanup(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_DagHeader_t *dag_h;\n\tRF_Etimer_t timer;\n\tint i;\n\n\tdesc->state++;\n\n\ttimer = tracerec->timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.dag_retry_us = RF_ETIMER_VAL_US(timer);\n\n\t/* the RAID I/O is complete.  Clean up. */\n\ttracerec->specific.user.dag_retry_us = 0;\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_DAG) {\n\t\t/* copy dags into paramDAG */\n\t\t*(desc->paramDAG) = desc->dagArray[0].dags;\n\t\tdag_h = *(desc->paramDAG);\n\t\tfor (i = 1; i < desc->numStripes; i++) {\n\t\t\t/* concatenate dags from remaining stripes */\n\t\t\tRF_ASSERT(dag_h);\n\t\t\twhile (dag_h->next)\n\t\t\t\tdag_h = dag_h->next;\n\t\t\tdag_h->next = desc->dagArray[i].dags;\n\t\t}\n\t} else {\n\t\t/* free all dags */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t}\n\t}\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us = RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS)) {\n\t\t\t\tRF_ASSERT_VALID_LOCKREQ(&asm_p->lockReqDesc);\n\t\t\t\trf_ReleaseStripeLock(raidPtr->lockTable, \n\t\t\t\t\t\t     asm_p->stripeID,\n\t\t\t\t    &asm_p->lockReqDesc);\n\t\t\t}\n\t\t\tif (asm_p->flags & RF_ASM_FLAGS_RECON_BLOCKED) {\n\t\t\t\trf_UnblockRecon(raidPtr, asm_p);\n\t\t\t}\n\t\t}\n\t}\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_START(timer);\n\tif (desc->flags & RF_DAG_RETURN_ASM)\n\t\t*(desc->paramASM) = asmh;\n\telse\n\t\trf_FreeAccessStripeMap(asmh);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.cleanup_us += RF_ETIMER_VAL_US(timer);\n\n\tRF_ETIMER_STOP(desc->timer);\n\tRF_ETIMER_EVAL(desc->timer);\n\n\ttimer = desc->tracerec.tot_timer;\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\tdesc->tracerec.total_us = RF_ETIMER_VAL_US(timer);\n\n\trf_LogTraceRec(raidPtr, tracerec);\n\n\tdesc->flags |= RF_DAG_ACCESS_COMPLETE;\n\n\treturn RF_FALSE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_ProcessDAG",
          "args": [
            "desc"
          ],
          "line": 121
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_ProcessDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "513-569",
          "snippet": "int \nrf_State_ProcessDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_DagHeader_t *dag_h;\n\tint     i, j, done = RF_TRUE;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\tRF_Etimer_t timer;\n\n\t/* check to see if this is the last dag */\n\tfor (i = 0; i < desc->numStripes; i++)\n\t\tif (dagArray[i].numDags != dagArray[i].numDagsDone)\n\t\t\tdone = RF_FALSE;\n\n\tif (done) {\n\t\tif (desc->status) {\n\t\t\t/* a dag failed, retry */\n\t\t\tRF_ETIMER_START(timer);\n\t\t\t/* free all dags */\n\t\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t\t}\n\t\t\trf_MarkFailuresInASMList(raidPtr, asmh);\n\t\t\t/* back up to rf_State_CreateDAG */\n\t\t\tdesc->state = desc->state - 2;\n\t\t\treturn RF_FALSE;\n\t\t} else {\n\t\t\t/* move on to rf_State_Cleanup */\n\t\t\tdesc->state++;\n\t\t}\n\t\treturn RF_FALSE;\n\t} else {\n\t\t/* more dags to execute */\n\t\t/* see if any are ready to be fired.  if so, fire them */\n\t\t/* don't fire the initial dag in a list, it's fired in\n\t\t * rf_State_ExecuteDAG */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tif ((dagArray[i].numDagsDone < dagArray[i].numDags)\n\t\t\t    && (dagArray[i].numDagsDone == dagArray[i].numDagsFired)\n\t\t\t    && (dagArray[i].numDagsFired > 0)) {\n\t\t\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t\t\t/* fire next dag in this stripe */\n\t\t\t\t/* first, skip to next dag awaiting execution */\n\t\t\t\tdag_h = dagArray[i].dags;\n\t\t\t\tfor (j = 0; j < dagArray[i].numDagsDone; j++)\n\t\t\t\t\tdag_h = dag_h->next;\n\t\t\t\tdagArray[i].numDagsFired++;\n\t\t\t\t/* XXX and again we pass a different function\n\t\t\t\t * pointer.. GO */\n\t\t\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess,\n\t\t\t\t    &dagArray[i]);\n\t\t\t}\n\t\t}\n\t\treturn RF_TRUE;\n\t}\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_ProcessDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_DagHeader_t *dag_h;\n\tint     i, j, done = RF_TRUE;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\tRF_Etimer_t timer;\n\n\t/* check to see if this is the last dag */\n\tfor (i = 0; i < desc->numStripes; i++)\n\t\tif (dagArray[i].numDags != dagArray[i].numDagsDone)\n\t\t\tdone = RF_FALSE;\n\n\tif (done) {\n\t\tif (desc->status) {\n\t\t\t/* a dag failed, retry */\n\t\t\tRF_ETIMER_START(timer);\n\t\t\t/* free all dags */\n\t\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\t\trf_FreeDAG(desc->dagArray[i].dags);\n\t\t\t}\n\t\t\trf_MarkFailuresInASMList(raidPtr, asmh);\n\t\t\t/* back up to rf_State_CreateDAG */\n\t\t\tdesc->state = desc->state - 2;\n\t\t\treturn RF_FALSE;\n\t\t} else {\n\t\t\t/* move on to rf_State_Cleanup */\n\t\t\tdesc->state++;\n\t\t}\n\t\treturn RF_FALSE;\n\t} else {\n\t\t/* more dags to execute */\n\t\t/* see if any are ready to be fired.  if so, fire them */\n\t\t/* don't fire the initial dag in a list, it's fired in\n\t\t * rf_State_ExecuteDAG */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tif ((dagArray[i].numDagsDone < dagArray[i].numDags)\n\t\t\t    && (dagArray[i].numDagsDone == dagArray[i].numDagsFired)\n\t\t\t    && (dagArray[i].numDagsFired > 0)) {\n\t\t\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t\t\t/* fire next dag in this stripe */\n\t\t\t\t/* first, skip to next dag awaiting execution */\n\t\t\t\tdag_h = dagArray[i].dags;\n\t\t\t\tfor (j = 0; j < dagArray[i].numDagsDone; j++)\n\t\t\t\t\tdag_h = dag_h->next;\n\t\t\t\tdagArray[i].numDagsFired++;\n\t\t\t\t/* XXX and again we pass a different function\n\t\t\t\t * pointer.. GO */\n\t\t\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess,\n\t\t\t\t    &dagArray[i]);\n\t\t\t}\n\t\t}\n\t\treturn RF_TRUE;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_ExecuteDAG",
          "args": [
            "desc"
          ],
          "line": 118
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_ExecuteDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "474-505",
          "snippet": "int \nrf_State_ExecuteDAG(RF_RaidAccessDesc_t * desc)\n{\n\tint     i;\n\tRF_DagHeader_t *dag_h;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\n\t/* next state is always rf_State_ProcessDAG important to do this\n\t * before firing the first dag (it may finish before we leave this\n\t * routine) */\n\tdesc->state++;\n\n\t/* sweep dag array, a stripe at a time, firing the first dag in each\n\t * stripe */\n\tfor (i = 0; i < desc->numStripes; i++) {\n\t\tRF_ASSERT(dagArray[i].numDags > 0);\n\t\tRF_ASSERT(dagArray[i].numDagsDone == 0);\n\t\tRF_ASSERT(dagArray[i].numDagsFired == 0);\n\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t/* fire first dag in this stripe */\n\t\tdag_h = dagArray[i].dags;\n\t\tRF_ASSERT(dag_h);\n\t\tdagArray[i].numDagsFired++;\n\t\t/* XXX Yet another case where we pass in a conflicting\n\t\t * function pointer :-(  XXX  GO */\n\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess, &dagArray[i]);\n\t}\n\n\t/* the DAG will always call the callback, even if there was no\n\t * blocking, so we are always suspended in this state */\n\treturn RF_TRUE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_ExecuteDAG(RF_RaidAccessDesc_t * desc)\n{\n\tint     i;\n\tRF_DagHeader_t *dag_h;\n\tRF_DagList_t *dagArray = desc->dagArray;\n\n\t/* next state is always rf_State_ProcessDAG important to do this\n\t * before firing the first dag (it may finish before we leave this\n\t * routine) */\n\tdesc->state++;\n\n\t/* sweep dag array, a stripe at a time, firing the first dag in each\n\t * stripe */\n\tfor (i = 0; i < desc->numStripes; i++) {\n\t\tRF_ASSERT(dagArray[i].numDags > 0);\n\t\tRF_ASSERT(dagArray[i].numDagsDone == 0);\n\t\tRF_ASSERT(dagArray[i].numDagsFired == 0);\n\t\tRF_ETIMER_START(dagArray[i].tracerec.timer);\n\t\t/* fire first dag in this stripe */\n\t\tdag_h = dagArray[i].dags;\n\t\tRF_ASSERT(dag_h);\n\t\tdagArray[i].numDagsFired++;\n\t\t/* XXX Yet another case where we pass in a conflicting\n\t\t * function pointer :-(  XXX  GO */\n\t\trf_DispatchDAG(dag_h, (void (*) (void *)) rf_ContinueDagAccess, &dagArray[i]);\n\t}\n\n\t/* the DAG will always call the callback, even if there was no\n\t * blocking, so we are always suspended in this state */\n\treturn RF_TRUE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_CreateDAG",
          "args": [
            "desc"
          ],
          "line": 115
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_CreateDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "421-464",
          "snippet": "int \nrf_State_CreateDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tRF_DagHeader_t *dag_h;\n\tint     i, selectStatus;\n\n\t/* generate a dag for the access, and fire it off.  When the dag\n\t * completes, we'll get re-invoked in the next state. */\n\tRF_ETIMER_START(timer);\n\t/* SelectAlgorithm returns one or more dags */\n\tselectStatus = rf_SelectAlgorithm(desc, desc->flags | RF_DAG_SUPPRESS_LOCKS);\n\tif (rf_printDAGsDebug)\n\t\tfor (i = 0; i < desc->numStripes; i++)\n\t\t\trf_PrintDAGList(desc->dagArray[i].dags);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\t/* update time to create all dags */\n\ttracerec->specific.user.dag_create_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->status = 0;\t/* good status */\n\n\tif (selectStatus) {\n\t\t/* failed to create a dag */\n\t\t/* this happens when there are too many faults or incomplete\n\t\t * dag libraries */\n\t\tprintf(\"[Failed to create a DAG\\n]\");\n\t\tRF_PANIC();\n\t} else {\n\t\t/* bind dags to desc */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tdag_h = desc->dagArray[i].dags;\n\t\t\twhile (dag_h) {\n\t\t\t\tdag_h->bp = (struct buf *) desc->bp;\n\t\t\t\tdag_h->tracerec = tracerec;\n\t\t\t\tdag_h = dag_h->next;\n\t\t\t}\n\t\t}\n\t\tdesc->flags |= RF_DAG_DISPATCH_RETURNED;\n\t\tdesc->state++;\t/* next state should be rf_State_ExecuteDAG */\n\t}\n\treturn RF_FALSE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_CreateDAG(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tRF_DagHeader_t *dag_h;\n\tint     i, selectStatus;\n\n\t/* generate a dag for the access, and fire it off.  When the dag\n\t * completes, we'll get re-invoked in the next state. */\n\tRF_ETIMER_START(timer);\n\t/* SelectAlgorithm returns one or more dags */\n\tselectStatus = rf_SelectAlgorithm(desc, desc->flags | RF_DAG_SUPPRESS_LOCKS);\n\tif (rf_printDAGsDebug)\n\t\tfor (i = 0; i < desc->numStripes; i++)\n\t\t\trf_PrintDAGList(desc->dagArray[i].dags);\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\t/* update time to create all dags */\n\ttracerec->specific.user.dag_create_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->status = 0;\t/* good status */\n\n\tif (selectStatus) {\n\t\t/* failed to create a dag */\n\t\t/* this happens when there are too many faults or incomplete\n\t\t * dag libraries */\n\t\tprintf(\"[Failed to create a DAG\\n]\");\n\t\tRF_PANIC();\n\t} else {\n\t\t/* bind dags to desc */\n\t\tfor (i = 0; i < desc->numStripes; i++) {\n\t\t\tdag_h = desc->dagArray[i].dags;\n\t\t\twhile (dag_h) {\n\t\t\t\tdag_h->bp = (struct buf *) desc->bp;\n\t\t\t\tdag_h->tracerec = tracerec;\n\t\t\t\tdag_h = dag_h->next;\n\t\t\t}\n\t\t}\n\t\tdesc->flags |= RF_DAG_DISPATCH_RETURNED;\n\t\tdesc->state++;\t/* next state should be rf_State_ExecuteDAG */\n\t}\n\treturn RF_FALSE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_Lock",
          "args": [
            "desc"
          ],
          "line": 112
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_Lock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "321-399",
          "snippet": "int \nrf_State_Lock(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tRF_StripeNum_t lastStripeID = -1;\n\n\t\t/* acquire each lock that we don't already hold */\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tRF_ASSERT(RF_IO_IS_R_OR_W(desc->type));\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS) &&\n\t\t\t    !(asm_p->flags & RF_ASM_FLAGS_LOCK_TRIED)) {\n\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_LOCK_TRIED;\n\t\t\t\tRF_ASSERT(asm_p->stripeID > lastStripeID);\t/* locks must be\n\t\t\t\t\t\t\t\t\t\t * acquired\n\t\t\t\t\t\t\t\t\t\t * hierarchically */\n\t\t\t\tlastStripeID = asm_p->stripeID;\n\t\t\t\t/* XXX the cast to (void (*)(RF_CBParam_t))\n\t\t\t\t * below is bogus!  GO */\n\t\t\t\tRF_INIT_LOCK_REQ_DESC(asm_p->lockReqDesc, desc->type,\n\t\t\t\t    (void (*) (struct buf *)) rf_ContinueRaidAccess, desc, asm_p,\n\t\t\t\t    raidPtr->Layout.dataSectorsPerStripe);\n\t\t\t\tif (rf_AcquireStripeLock(raidPtr->lockTable, asm_p->stripeID,\n\t\t\t\t\t&asm_p->lockReqDesc)) {\n\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (desc->type == RF_IO_TYPE_WRITE &&\n\t\t\t    raidPtr->status[asm_p->physInfo->row] == rf_rs_reconstructing) {\n\t\t\t\tif (!(asm_p->flags & RF_ASM_FLAGS_FORCE_TRIED)) {\n\t\t\t\t\tint     val;\n\n\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_FORCE_TRIED;\n\t\t\t\t\t/* XXX the cast below is quite\n\t\t\t\t\t * bogus!!! XXX  GO */\n\t\t\t\t\tval = rf_ForceOrBlockRecon(raidPtr, asm_p,\n\t\t\t\t\t    (void (*) (RF_Raid_t *, void *)) rf_ContinueRaidAccess, desc);\n\t\t\t\t\tif (val == 0) {\n\t\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_RECON_BLOCKED;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\t\tprintf(\"raid%d: skipping force/block because already done, psid %ld\\n\",\n\t\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\tprintf(\"raid%d: skipping force/block because not write or not under recon, psid %ld\\n\",\n\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tRF_ETIMER_STOP(timer);\n\t\tRF_ETIMER_EVAL(timer);\n\t\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\t\tif (suspended)\n\t\t\treturn (RF_TRUE);\n\t}\n\tdesc->state++;\n\treturn (RF_FALSE);\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Lock(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccessStripeMapHeader_t *asmh = desc->asmap;\n\tRF_AccessStripeMap_t *asm_p;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\n\tRF_ETIMER_START(timer);\n\tif (!(raidPtr->Layout.map->flags & RF_NO_STRIPE_LOCKS)) {\n\t\tRF_StripeNum_t lastStripeID = -1;\n\n\t\t/* acquire each lock that we don't already hold */\n\t\tfor (asm_p = asmh->stripeMap; asm_p; asm_p = asm_p->next) {\n\t\t\tRF_ASSERT(RF_IO_IS_R_OR_W(desc->type));\n\t\t\tif (!rf_suppressLocksAndLargeWrites &&\n\t\t\t    asm_p->parityInfo &&\n\t\t\t    !(desc->flags & RF_DAG_SUPPRESS_LOCKS) &&\n\t\t\t    !(asm_p->flags & RF_ASM_FLAGS_LOCK_TRIED)) {\n\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_LOCK_TRIED;\n\t\t\t\tRF_ASSERT(asm_p->stripeID > lastStripeID);\t/* locks must be\n\t\t\t\t\t\t\t\t\t\t * acquired\n\t\t\t\t\t\t\t\t\t\t * hierarchically */\n\t\t\t\tlastStripeID = asm_p->stripeID;\n\t\t\t\t/* XXX the cast to (void (*)(RF_CBParam_t))\n\t\t\t\t * below is bogus!  GO */\n\t\t\t\tRF_INIT_LOCK_REQ_DESC(asm_p->lockReqDesc, desc->type,\n\t\t\t\t    (void (*) (struct buf *)) rf_ContinueRaidAccess, desc, asm_p,\n\t\t\t\t    raidPtr->Layout.dataSectorsPerStripe);\n\t\t\t\tif (rf_AcquireStripeLock(raidPtr->lockTable, asm_p->stripeID,\n\t\t\t\t\t&asm_p->lockReqDesc)) {\n\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (desc->type == RF_IO_TYPE_WRITE &&\n\t\t\t    raidPtr->status[asm_p->physInfo->row] == rf_rs_reconstructing) {\n\t\t\t\tif (!(asm_p->flags & RF_ASM_FLAGS_FORCE_TRIED)) {\n\t\t\t\t\tint     val;\n\n\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_FORCE_TRIED;\n\t\t\t\t\t/* XXX the cast below is quite\n\t\t\t\t\t * bogus!!! XXX  GO */\n\t\t\t\t\tval = rf_ForceOrBlockRecon(raidPtr, asm_p,\n\t\t\t\t\t    (void (*) (RF_Raid_t *, void *)) rf_ContinueRaidAccess, desc);\n\t\t\t\t\tif (val == 0) {\n\t\t\t\t\t\tasm_p->flags |= RF_ASM_FLAGS_RECON_BLOCKED;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsuspended = RF_TRUE;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\t\tprintf(\"raid%d: skipping force/block because already done, psid %ld\\n\",\n\t\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (rf_pssDebug) {\n\t\t\t\t\tprintf(\"raid%d: skipping force/block because not write or not under recon, psid %ld\\n\",\n\t\t\t\t\t       desc->raidPtr->raidid, \n\t\t\t\t\t       (long) asm_p->stripeID);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tRF_ETIMER_STOP(timer);\n\t\tRF_ETIMER_EVAL(timer);\n\t\ttracerec->specific.user.lock_us += RF_ETIMER_VAL_US(timer);\n\n\t\tif (suspended)\n\t\t\treturn (RF_TRUE);\n\t}\n\tdesc->state++;\n\treturn (RF_FALSE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_Map",
          "args": [
            "desc"
          ],
          "line": 109
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_Map",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "300-319",
          "snippet": "int \nrf_State_Map(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\n\tRF_ETIMER_START(timer);\n\n\tif (!(desc->asmap = rf_MapAccess(raidPtr, desc->raidAddress, desc->numBlocks,\n\t\t    desc->bufPtr, RF_DONT_REMAP)))\n\t\tRF_PANIC();\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.map_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Map(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr = desc->raidPtr;\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\n\tRF_ETIMER_START(timer);\n\n\tif (!(desc->asmap = rf_MapAccess(raidPtr, desc->raidAddress, desc->numBlocks,\n\t\t    desc->bufPtr, RF_DONT_REMAP)))\n\t\tRF_PANIC();\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.map_us = RF_ETIMER_VAL_US(timer);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_IncrAccessCount",
          "args": [
            "desc"
          ],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_IncrAccessCount",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "226-240",
          "snippet": "int \nrf_State_IncrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\t/* Bummer. We have to do this to be 100% safe w.r.t. the increment\n\t * below */\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight++;\t/* used to detect quiescence */\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_IncrAccessCount(RF_RaidAccessDesc_t * desc)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\t/* Bummer. We have to do this to be 100% safe w.r.t. the increment\n\t * below */\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\traidPtr->accs_in_flight++;\t/* used to detect quiescence */\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tdesc->state++;\n\treturn RF_FALSE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_State_Quiesce",
          "args": [
            "desc"
          ],
          "line": 103
        },
        "resolved": true,
        "details": {
          "function_name": "rf_State_Quiesce",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
          "lines": "261-298",
          "snippet": "int \nrf_State_Quiesce(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_ETIMER_START(timer);\n\tRF_ETIMER_START(desc->timer);\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\tif (raidPtr->accesses_suspended) {\n\t\tRF_CallbackDesc_t *cb;\n\t\tcb = rf_AllocCallbackDesc();\n\t\t/* XXX the following cast is quite bogus...\n\t\t * rf_ContinueRaidAccess takes a (RF_RaidAccessDesc_t *) as an\n\t\t * argument..  GO */\n\t\tcb->callbackFunc = (void (*) (RF_CBParam_t)) rf_ContinueRaidAccess;\n\t\tcb->callbackArg.p = (void *) desc;\n\t\tcb->next = raidPtr->quiesce_wait_list;\n\t\traidPtr->quiesce_wait_list = cb;\n\t\tsuspended = RF_TRUE;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.suspend_ovhd_us += RF_ETIMER_VAL_US(timer);\n\n\tif (suspended && rf_quiesceDebug)\n\t\tprintf(\"Stalling access due to quiescence lock\\n\");\n\n\tdesc->state++;\n\treturn suspended;\n}",
          "includes": [
            "#include \"rf_kintf.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_driver.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_states.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_aselect.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_archs.h\"",
            "#include <sys/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nint \nrf_State_Quiesce(RF_RaidAccessDesc_t * desc)\n{\n\tRF_AccTraceEntry_t *tracerec = &desc->tracerec;\n\tRF_Etimer_t timer;\n\tint     suspended = RF_FALSE;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = desc->raidPtr;\n\n\tRF_ETIMER_START(timer);\n\tRF_ETIMER_START(desc->timer);\n\n\tRF_LOCK_MUTEX(raidPtr->access_suspend_mutex);\n\tif (raidPtr->accesses_suspended) {\n\t\tRF_CallbackDesc_t *cb;\n\t\tcb = rf_AllocCallbackDesc();\n\t\t/* XXX the following cast is quite bogus...\n\t\t * rf_ContinueRaidAccess takes a (RF_RaidAccessDesc_t *) as an\n\t\t * argument..  GO */\n\t\tcb->callbackFunc = (void (*) (RF_CBParam_t)) rf_ContinueRaidAccess;\n\t\tcb->callbackArg.p = (void *) desc;\n\t\tcb->next = raidPtr->quiesce_wait_list;\n\t\traidPtr->quiesce_wait_list = cb;\n\t\tsuspended = RF_TRUE;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->access_suspend_mutex);\n\n\tRF_ETIMER_STOP(timer);\n\tRF_ETIMER_EVAL(timer);\n\ttracerec->specific.user.suspend_ovhd_us += RF_ETIMER_VAL_US(timer);\n\n\tif (suspended && rf_quiesceDebug)\n\t\tprintf(\"Stalling access due to quiescence lock\\n\");\n\n\tdesc->state++;\n\treturn suspended;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nvoid \nrf_ContinueRaidAccess(RF_RaidAccessDesc_t * desc)\n{\n\tint     suspended = RF_FALSE;\n\tint     current_state_index = desc->state;\n\tRF_AccessState_t current_state = desc->states[current_state_index];\n\tint     unit = desc->raidPtr->raidid;\n\n\tdo {\n\n\t\tcurrent_state_index = desc->state;\n\t\tcurrent_state = desc->states[current_state_index];\n\n\t\tswitch (current_state) {\n\n\t\tcase rf_QuiesceState:\n\t\t\tsuspended = rf_State_Quiesce(desc);\n\t\t\tbreak;\n\t\tcase rf_IncrAccessesCountState:\n\t\t\tsuspended = rf_State_IncrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_MapState:\n\t\t\tsuspended = rf_State_Map(desc);\n\t\t\tbreak;\n\t\tcase rf_LockState:\n\t\t\tsuspended = rf_State_Lock(desc);\n\t\t\tbreak;\n\t\tcase rf_CreateDAGState:\n\t\t\tsuspended = rf_State_CreateDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ExecuteDAGState:\n\t\t\tsuspended = rf_State_ExecuteDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_ProcessDAGState:\n\t\t\tsuspended = rf_State_ProcessDAG(desc);\n\t\t\tbreak;\n\t\tcase rf_CleanupState:\n\t\t\tsuspended = rf_State_Cleanup(desc);\n\t\t\tbreak;\n\t\tcase rf_DecrAccessesCountState:\n\t\t\tsuspended = rf_State_DecrAccessCount(desc);\n\t\t\tbreak;\n\t\tcase rf_LastState:\n\t\t\tsuspended = rf_State_LastState(desc);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* after this point, we cannot dereference desc since desc may\n\t\t * have been freed. desc is only freed in LastState, so if we\n\t\t * renter this function or loop back up, desc should be valid. */\n\n\t\tif (rf_printStatesDebug) {\n\t\t\tprintf(\"raid%d: State: %-24s StateIndex: %3i desc: 0x%ld %s\\n\",\n\t\t\t       unit, StateName(current_state), \n\t\t\t       current_state_index, (long) desc,\n\t\t\t    suspended ? \"callback scheduled\" : \"looping\");\n\t\t}\n\t} while (!suspended && current_state != rf_LastState);\n\n\treturn;\n}"
  },
  {
    "function_name": "StateName",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_states.c",
    "lines": "59-85",
    "snippet": "static char *\nStateName(RF_AccessState_t state)\n{\n\tswitch (state) {\n\t\tcase rf_QuiesceState:return \"QuiesceState\";\n\tcase rf_MapState:\n\t\treturn \"MapState\";\n\tcase rf_LockState:\n\t\treturn \"LockState\";\n\tcase rf_CreateDAGState:\n\t\treturn \"CreateDAGState\";\n\tcase rf_ExecuteDAGState:\n\t\treturn \"ExecuteDAGState\";\n\tcase rf_ProcessDAGState:\n\t\treturn \"ProcessDAGState\";\n\tcase rf_CleanupState:\n\t\treturn \"CleanupState\";\n\tcase rf_LastState:\n\t\treturn \"LastState\";\n\tcase rf_IncrAccessesCountState:\n\t\treturn \"IncrAccessesCountState\";\n\tcase rf_DecrAccessesCountState:\n\t\treturn \"DecrAccessesCountState\";\n\tdefault:\n\t\treturn \"!!! UnnamedState !!!\";\n\t}\n}",
    "includes": [
      "#include \"rf_kintf.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_driver.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_states.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_aselect.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_archs.h\"",
      "#include <sys/errno.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rf_kintf.h\"\n#include \"rf_etimer.h\"\n#include \"rf_map.h\"\n#include \"rf_engine.h\"\n#include \"rf_driver.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_states.h\"\n#include \"rf_general.h\"\n#include \"rf_aselect.h\"\n#include \"rf_desc.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_archs.h\"\n#include <sys/errno.h>\n\nstatic char *\nStateName(RF_AccessState_t state)\n{\n\tswitch (state) {\n\t\tcase rf_QuiesceState:return \"QuiesceState\";\n\tcase rf_MapState:\n\t\treturn \"MapState\";\n\tcase rf_LockState:\n\t\treturn \"LockState\";\n\tcase rf_CreateDAGState:\n\t\treturn \"CreateDAGState\";\n\tcase rf_ExecuteDAGState:\n\t\treturn \"ExecuteDAGState\";\n\tcase rf_ProcessDAGState:\n\t\treturn \"ProcessDAGState\";\n\tcase rf_CleanupState:\n\t\treturn \"CleanupState\";\n\tcase rf_LastState:\n\t\treturn \"LastState\";\n\tcase rf_IncrAccessesCountState:\n\t\treturn \"IncrAccessesCountState\";\n\tcase rf_DecrAccessesCountState:\n\t\treturn \"DecrAccessesCountState\";\n\tdefault:\n\t\treturn \"!!! UnnamedState !!!\";\n\t}\n}"
  }
]