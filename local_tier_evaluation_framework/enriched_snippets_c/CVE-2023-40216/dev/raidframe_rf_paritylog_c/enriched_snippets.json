[
  {
    "function_name": "rf_EnableParityLogging",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "856-868",
    "snippet": "void \nrf_EnableParityLogging(RF_Raid_t * raidPtr)\n{\n\tint     regionID;\n\n\tfor (regionID = 0; regionID < rf_numParityRegions; regionID++) {\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\traidPtr->regionInfo[regionID].loggingEnabled = RF_TRUE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[parity logging enabled]\\n\");\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[parity logging enabled]\\n\""
          ],
          "line": 867
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 864
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 862
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_EnableParityLogging(RF_Raid_t * raidPtr)\n{\n\tint     regionID;\n\n\tfor (regionID = 0; regionID < rf_numParityRegions; regionID++) {\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\traidPtr->regionInfo[regionID].loggingEnabled = RF_TRUE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[parity logging enabled]\\n\");\n}"
  },
  {
    "function_name": "rf_ParityLogAppend",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "660-853",
    "snippet": "int \nrf_ParityLogAppend(\n    RF_ParityLogData_t * logData,\n    int finish,\n    RF_ParityLog_t ** incomingLog,\n    int clearReintFlag)\n{\n\tint     regionID, logItem, itemDone;\n\tRF_ParityLogData_t *item;\n\tint     punt, done = RF_FALSE;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\tRF_Etimer_t timer;\n\tint     (*wakeFunc) (RF_DagNode_t * node, int status);\n\tvoid   *wakeArg;\n\n\t/* Add parity to the appropriate log, one sector at a time. This\n\t * routine is called is called by dag functions ParityLogUpdateFunc\n\t * and ParityLogOverwriteFunc and therefore MUST BE NONBLOCKING.\n\t * \n\t * Parity to be logged is contained in a linked-list (logData).  When\n\t * this routine returns, every sector in the list will be in one of\n\t * three places: 1) entered into the parity log 2) queued, waiting on\n\t * reintegration 3) queued, waiting on a core log\n\t * \n\t * Blocked work is passed to the ParityLoggingDiskManager for completion.\n\t * Later, as conditions which required the block are removed, the work\n\t * reenters this routine with the \"finish\" parameter set to \"RF_TRUE.\"\n\t * \n\t * NON-BLOCKING */\n\n\traidPtr = logData->common->raidPtr;\n\t/* lock the region for the first item in logData */\n\tRF_ASSERT(logData != NULL);\n\tregionID = logData->regionID;\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\n\tif (clearReintFlag) {\n\t\t/* Enable flushing for this region.  Holding both locks\n\t\t * provides a synchronization barrier with DumpParityLogToDisk */\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE);\n\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t}\n\t/* process each item in logData */\n\twhile (logData) {\n\t\t/* remove an item from logData */\n\t\titem = logData;\n\t\tlogData = logData->next;\n\t\titem->next = NULL;\n\t\titem->prev = NULL;\n\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[appending parity log data, region %d, raidAddress %d, numSector %d]\\n\", item->regionID, (int) item->diskAddress.raidAddress, (int) item->diskAddress.numSector);\n\n\t\t/* see if we moved to a new region */\n\t\tif (regionID != item->regionID) {\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tregionID = item->regionID;\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\t\t}\n\t\tpunt = RF_FALSE;/* Set to RF_TRUE if work is blocked.  This\n\t\t\t\t * can happen in one of two ways: 1) no core\n\t\t\t\t * log (AcquireParityLog) 2) waiting on\n\t\t\t\t * reintegration (DumpParityLogToDisk) If punt\n\t\t\t\t * is RF_TRUE, the dataItem was queued, so\n\t\t\t\t * skip to next item. */\n\n\t\t/* process item, one sector at a time, until all sectors\n\t\t * processed or we punt */\n\t\tif (item->diskAddress.numSector > 0)\n\t\t\tdone = RF_FALSE;\n\t\telse\n\t\t\tRF_ASSERT(0);\n\t\twhile (!punt && !done) {\n\t\t\t/* verify that a core log exists for this region */\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog) {\n\t\t\t\t/* Attempt to acquire a parity log. If\n\t\t\t\t * acquisition fails, queue remaining work in\n\t\t\t\t * data item and move to nextItem. */\n\t\t\t\tif (incomingLog) {\n\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t} else\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t} else\n\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t/* Note: AcquireParityLog either returns a log\n\t\t\t\t * or enqueues currentItem */\n\t\t\t}\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\tpunt = RF_TRUE;\t/* failed to find a core log */\n\t\t\telse {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* verify that the log has room for new\n\t\t\t\t * entries */\n\t\t\t\t/* if log is full, dump it to disk and grab a\n\t\t\t\t * new log */\n\t\t\t\tif (raidPtr->regionInfo[regionID].coreLog->numRecords == raidPtr->numSectorsPerLog) {\n\t\t\t\t\t/* log is full, dump it to disk */\n\t\t\t\t\tif (DumpParityLogToDisk(finish, item))\n\t\t\t\t\t\tpunt = RF_TRUE;\t/* dump unsuccessful,\n\t\t\t\t\t\t\t\t * blocked on\n\t\t\t\t\t\t\t\t * reintegration */\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* dump was successful */\n\t\t\t\t\t  if (incomingLog) {\n\t\t\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t\t\t} else\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t/* if a core log is not\n\t\t\t\t\t\t * available, must queue work\n\t\t\t\t\t\t * and return */\n\t\t\t\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\t\t\t\tpunt = RF_TRUE;\t/* blocked on log\n\t\t\t\t\t\t\t\t\t * availability */\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* if we didn't punt on this item, attempt to add a\n\t\t\t * sector to the core log */\n\t\t\tif (!punt) {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* at this point, we have a core log with\n\t\t\t\t * enough room for a sector */\n\t\t\t\t/* copy a sector into the log */\n\t\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\t\tRF_ASSERT(log->numRecords < raidPtr->numSectorsPerLog);\n\t\t\t\tlogItem = log->numRecords++;\n\t\t\t\tlog->records[logItem].parityAddr = item->diskAddress;\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr);\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity);\n\t\t\t\tlog->records[logItem].parityAddr.numSector = 1;\n\t\t\t\tlog->records[logItem].operation = item->common->operation;\n\t\t\t\tbcopy((item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector))), log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector)), (1 << item->common->raidPtr->logBytesPerSector));\n\t\t\t\titem->diskAddress.numSector--;\n\t\t\t\titem->diskAddress.startSector++;\n\t\t\t\tif (item->diskAddress.numSector == 0)\n\t\t\t\t\tdone = RF_TRUE;\n\t\t\t}\n\t\t}\n\n\t\tif (!punt) {\n\t\t\t/* Processed this item completely, decrement count of\n\t\t\t * items to be processed. */\n\t\t\tRF_ASSERT(item->diskAddress.numSector == 0);\n\t\t\tRF_LOCK_MUTEX(item->common->mutex);\n\t\t\titem->common->cnt--;\n\t\t\tif (item->common->cnt == 0)\n\t\t\t\titemDone = RF_TRUE;\n\t\t\telse\n\t\t\t\titemDone = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(item->common->mutex);\n\t\t\tif (itemDone) {\n\t\t\t\t/* Finished processing all log data for this\n\t\t\t\t * IO Return structs to free list and invoke\n\t\t\t\t * wakeup function. */\n\t\t\t\ttimer = item->common->startTime;\t/* grab initial value of\n\t\t\t\t\t\t\t\t\t * timer */\n\t\t\t\tRF_ETIMER_STOP(timer);\n\t\t\t\tRF_ETIMER_EVAL(timer);\n\t\t\t\titem->common->tracerec->plog_us += RF_ETIMER_VAL_US(timer);\n\t\t\t\tif (rf_parityLogDebug)\n\t\t\t\t\tprintf(\"[waking process for region %d]\\n\", item->regionID);\n\t\t\t\twakeFunc = item->common->wakeFunc;\n\t\t\t\twakeArg = item->common->wakeArg;\n\t\t\t\tFreeParityLogCommonData(item->common);\n\t\t\t\tFreeParityLogData(item);\n\t\t\t\t(wakeFunc) (wakeArg, 0);\n\t\t\t} else\n\t\t\t\tFreeParityLogData(item);\n\t\t}\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[exiting ParityLogAppend]\\n\");\n\treturn (0);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[exiting ParityLogAppend]\\n\""
          ],
          "line": 851
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 849
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FreeParityLogData",
          "args": [
            "item"
          ],
          "line": 846
        },
        "resolved": true,
        "details": {
          "function_name": "FreeParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "128-147",
          "snippet": "static void \nFreeParityLogData(RF_ParityLogData_t * data)\n{\n\tRF_ParityLogData_t *nextItem;\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a linked list of structs for holding parity log information\n\t * (data) into the free list (parityLogDiskQueue.freeList).\n\t * NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\twhile (data) {\n\t\tnextItem = data->next;\n\t\tdata->next = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = data;\n\t\tdata = nextItem;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFreeParityLogData(RF_ParityLogData_t * data)\n{\n\tRF_ParityLogData_t *nextItem;\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a linked list of structs for holding parity log information\n\t * (data) into the free list (parityLogDiskQueue.freeList).\n\t * NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\twhile (data) {\n\t\tnextItem = data->next;\n\t\tdata->next = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = data;\n\t\tdata = nextItem;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "",
          "args": [
            "wakeArg",
            "0"
          ],
          "line": 844
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FreeParityLogCommonData",
          "args": [
            "item->common"
          ],
          "line": 842
        },
        "resolved": true,
        "details": {
          "function_name": "FreeParityLogCommonData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "88-102",
          "snippet": "static void \nFreeParityLogCommonData(RF_CommonLogData_t * common)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a single struct for holding parity log information (data)\n\t * into the free list (rf_parityLogDiskQueue.freeCommonList).\n\t * NON-BLOCKING */\n\n\traidPtr = common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tcommon->next = raidPtr->parityLogDiskQueue.freeCommonList;\n\traidPtr->parityLogDiskQueue.freeCommonList = common;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFreeParityLogCommonData(RF_CommonLogData_t * common)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a single struct for holding parity log information (data)\n\t * into the free list (rf_parityLogDiskQueue.freeCommonList).\n\t * NON-BLOCKING */\n\n\traidPtr = common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tcommon->next = raidPtr->parityLogDiskQueue.freeCommonList;\n\traidPtr->parityLogDiskQueue.freeCommonList = common;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_VAL_US",
          "args": [
            "timer"
          ],
          "line": 837
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_EVAL",
          "args": [
            "timer"
          ],
          "line": 836
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ETIMER_STOP",
          "args": [
            "timer"
          ],
          "line": 835
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "item->common->mutex"
          ],
          "line": 828
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "item->common->mutex"
          ],
          "line": 822
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "item->diskAddress.numSector == 0"
          ],
          "line": 821
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bcopy",
          "args": [
            "(item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector)))",
            "log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector))",
            "(1 << item->common->raidPtr->logBytesPerSector)"
          ],
          "line": 810
        },
        "resolved": true,
        "details": {
          "function_name": "tr_bcopy",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/ic/tropic.c",
          "lines": "1618-1663",
          "snippet": "void \ntr_bcopy(sc, dest, len)\nstruct tr_softc *sc;\t/* pointer to softc struct for this adapter */\nu_char *dest;\t\t/* destination address */\nint len;\t\t/* number of bytes to copy */\n{\n\tstruct rbcb *rbc = &sc->rbc;\t/* pointer to rec buf ctl blk */\n\n\t/* While amount of data needed >= amount in current receive buffer. */\n\twhile (len >= rbc->data_len) {\n\t\t/* Copy all data from receive buffer to destination. */\n\n\t\tbus_space_read_region_1(sc->sc_memt, sc->sc_sramh,\n\t\t    rbc->rbuf_datap, dest, (bus_size_t)rbc->data_len);\n\t\tlen -= rbc->data_len;\t/* update length left to transfer */\n\t\tdest += rbc->data_len;\t/* update destination address */\n\n\t\t/* Make next receive buffer current receive buffer. */\n\t\trbc->rbufp = rbc->rbufp_next;\n\t\tif (rbc->rbufp != 0) { /* More receive buffers? */\n\n\t\t\t/* Calculate pointer to next receive buffer. */\n\t\t\trbc->rbufp_next = RB_INW(sc, rbc->rbufp, RB_NEXTBUF);\n\t\t\tif (rbc->rbufp_next != 0)\n\t\t\t\trbc->rbufp_next -= RB_NEXTBUF;\n\n\t\t\t/* Get pointer to data in current receive buffer. */\n\t\t\trbc->rbuf_datap = rbc->rbufp + RB_DATA;\n\n\t\t\t/* Get length of data in current receive buffer. */\n\t\t\trbc->data_len = RB_INW(sc, rbc->rbufp, RB_BUFLEN);\n\t\t}\n\t\telse {\n\t\t\tif (len != 0)\t/* len should equal zero. */\n\t\t\t\tprintf(\"tr_bcopy: residual data not copied\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Amount of data needed is < amount in current receive buffer. */\n\n\tbus_space_read_region_1(sc->sc_memt, sc->sc_sramh,\n\t    rbc->rbuf_datap, dest, (bus_size_t)len);\n\trbc->data_len -= len;\t/* Update count of data in receive buffer. */\n\trbc->rbuf_datap += len;\t/* Update pointer to receive buffer data. */\n}",
          "includes": [
            "#include <dev/ic/tropicvar.h>",
            "#include <dev/ic/tropicreg.h>",
            "#include <machine/bus.h>",
            "#include <machine/cpu.h>",
            "#include <net/bpfdesc.h>",
            "#include <net/bpf.h>",
            "#include <netns/ns_if.h>",
            "#include <netns/ns.h>",
            "#include <net/if_token.h>",
            "#include <netinet/in_var.h>",
            "#include <netinet/ip.h>",
            "#include <netinet/if_ether.h>",
            "#include <netinet/in_systm.h>",
            "#include <netinet/in.h>",
            "#include <net/route.h>",
            "#include <net/netisr.h>",
            "#include <net/if_media.h>",
            "#include <net/if_llc.h>",
            "#include <net/if.h>",
            "#include <sys/device.h>",
            "#include <sys/errno.h>",
            "#include <sys/ioctl.h>",
            "#include <sys/syslog.h>",
            "#include <sys/socket.h>",
            "#include <sys/buf.h>",
            "#include <sys/mbuf.h>",
            "#include <sys/proc.h>",
            "#include <sys/kernel.h>",
            "#include <sys/systm.h>",
            "#include <sys/param.h>",
            "#include \"bpfilter.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "void\ttr_bcopy",
            "struct mbuf *\ntr_get(sc, totlen, ifp)\nstruct tr_softc *sc;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <dev/ic/tropicvar.h>\n#include <dev/ic/tropicreg.h>\n#include <machine/bus.h>\n#include <machine/cpu.h>\n#include <net/bpfdesc.h>\n#include <net/bpf.h>\n#include <netns/ns_if.h>\n#include <netns/ns.h>\n#include <net/if_token.h>\n#include <netinet/in_var.h>\n#include <netinet/ip.h>\n#include <netinet/if_ether.h>\n#include <netinet/in_systm.h>\n#include <netinet/in.h>\n#include <net/route.h>\n#include <net/netisr.h>\n#include <net/if_media.h>\n#include <net/if_llc.h>\n#include <net/if.h>\n#include <sys/device.h>\n#include <sys/errno.h>\n#include <sys/ioctl.h>\n#include <sys/syslog.h>\n#include <sys/socket.h>\n#include <sys/buf.h>\n#include <sys/mbuf.h>\n#include <sys/proc.h>\n#include <sys/kernel.h>\n#include <sys/systm.h>\n#include <sys/param.h>\n#include \"bpfilter.h\"\n\nvoid\ttr_bcopy;\nstruct mbuf *\ntr_get(sc, totlen, ifp)\nstruct tr_softc *sc;\n\nvoid \ntr_bcopy(sc, dest, len)\nstruct tr_softc *sc;\t/* pointer to softc struct for this adapter */\nu_char *dest;\t\t/* destination address */\nint len;\t\t/* number of bytes to copy */\n{\n\tstruct rbcb *rbc = &sc->rbc;\t/* pointer to rec buf ctl blk */\n\n\t/* While amount of data needed >= amount in current receive buffer. */\n\twhile (len >= rbc->data_len) {\n\t\t/* Copy all data from receive buffer to destination. */\n\n\t\tbus_space_read_region_1(sc->sc_memt, sc->sc_sramh,\n\t\t    rbc->rbuf_datap, dest, (bus_size_t)rbc->data_len);\n\t\tlen -= rbc->data_len;\t/* update length left to transfer */\n\t\tdest += rbc->data_len;\t/* update destination address */\n\n\t\t/* Make next receive buffer current receive buffer. */\n\t\trbc->rbufp = rbc->rbufp_next;\n\t\tif (rbc->rbufp != 0) { /* More receive buffers? */\n\n\t\t\t/* Calculate pointer to next receive buffer. */\n\t\t\trbc->rbufp_next = RB_INW(sc, rbc->rbufp, RB_NEXTBUF);\n\t\t\tif (rbc->rbufp_next != 0)\n\t\t\t\trbc->rbufp_next -= RB_NEXTBUF;\n\n\t\t\t/* Get pointer to data in current receive buffer. */\n\t\t\trbc->rbuf_datap = rbc->rbufp + RB_DATA;\n\n\t\t\t/* Get length of data in current receive buffer. */\n\t\t\trbc->data_len = RB_INW(sc, rbc->rbufp, RB_BUFLEN);\n\t\t}\n\t\telse {\n\t\t\tif (len != 0)\t/* len should equal zero. */\n\t\t\t\tprintf(\"tr_bcopy: residual data not copied\\n\");\n\t\t\treturn;\n\t\t}\n\t}\n\n\t/* Amount of data needed is < amount in current receive buffer. */\n\n\tbus_space_read_region_1(sc->sc_memt, sc->sc_sramh,\n\t    rbc->rbuf_datap, dest, (bus_size_t)len);\n\trbc->data_len -= len;\t/* Update count of data in receive buffer. */\n\trbc->rbuf_datap += len;\t/* Update pointer to receive buffer data. */\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity"
          ],
          "line": 807
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr"
          ],
          "line": 806
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->numRecords < raidPtr->numSectorsPerLog"
          ],
          "line": 803
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->regionInfo[regionID].coreLog->next == NULL"
          ],
          "line": 798
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "AcquireParityLog",
          "args": [
            "item",
            "finish"
          ],
          "line": 785
        },
        "resolved": true,
        "details": {
          "function_name": "AcquireParityLog",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "431-465",
          "snippet": "static RF_ParityLog_t *\nAcquireParityLog(\n    RF_ParityLogData_t * logData,\n    int finish)\n{\n\tRF_ParityLog_t *log = NULL;\n\tRF_Raid_t *raidPtr;\n\n\t/* Grab a log buffer from the pool and return it. If no buffers are\n\t * available, return NULL. NON-BLOCKING */\n\traidPtr = logData->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tif (raidPtr->parityLogPool.parityLogs) {\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = raidPtr->parityLogPool.parityLogs->next;\n\t\tlog->regionID = logData->regionID;\n\t\tlog->numRecords = 0;\n\t\tlog->next = NULL;\n\t\traidPtr->logsInUse++;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t} else {\n\t\t/* no logs available, so place ourselves on the queue of work\n\t\t * waiting on log buffers this is done while\n\t\t * parityLogPool.mutex is held, to ensure synchronization with\n\t\t * ReleaseParityLogs. */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[blocked on log, region %d, finish %d]\\n\", logData->regionID, finish);\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\treturn (log);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLog_t *\nAcquireParityLog(\n    RF_ParityLogData_t * logData,\n    int finish)\n{\n\tRF_ParityLog_t *log = NULL;\n\tRF_Raid_t *raidPtr;\n\n\t/* Grab a log buffer from the pool and return it. If no buffers are\n\t * available, return NULL. NON-BLOCKING */\n\traidPtr = logData->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tif (raidPtr->parityLogPool.parityLogs) {\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = raidPtr->parityLogPool.parityLogs->next;\n\t\tlog->regionID = logData->regionID;\n\t\tlog->numRecords = 0;\n\t\tlog->next = NULL;\n\t\traidPtr->logsInUse++;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t} else {\n\t\t/* no logs available, so place ourselves on the queue of work\n\t\t * waiting on log buffers this is done while\n\t\t * parityLogPool.mutex is held, to ensure synchronization with\n\t\t * ReleaseParityLogs. */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[blocked on log, region %d, finish %d]\\n\", logData->regionID, finish);\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\treturn (log);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*incomingLog)->next == NULL"
          ],
          "line": 778
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DumpParityLogToDisk",
          "args": [
            "finish",
            "item"
          ],
          "line": 770
        },
        "resolved": true,
        "details": {
          "function_name": "DumpParityLogToDisk",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "589-658",
          "snippet": "static int \nDumpParityLogToDisk(\n    int finish,\n    RF_ParityLogData_t * logData)\n{\n\tint     i, diskCount, regionID = logData->regionID;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = logData->common->raidPtr;\n\n\t/* Move a core log to disk.  If the log disk is full, initiate\n\t * reintegration.\n\t * \n\t * Return (0) if we can enqueue the dump immediately, otherwise return\n\t * (1) to indicate we are blocked on reintegration and control of the\n\t * thread should be relinquished.\n\t * \n\t * Caller must hold regionInfo[regionID].mutex\n\t * \n\t * NON-BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[dumping parity log to disk, region %d]\\n\", regionID);\n\tlog = raidPtr->regionInfo[regionID].coreLog;\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\n\t/* if reintegration is in progress, must queue work */\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tif (raidPtr->regionInfo[regionID].reintInProgress) {\n\t\t/* Can not proceed since this region is currently being\n\t\t * reintegrated. We can not block, so queue remaining work and\n\t\t * return */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[region %d waiting on reintegration]\\n\", regionID);\n\t\t/* XXX not sure about the use of finish - shouldn't this\n\t\t * always be \"Enqueue\"? */\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\treturn (1);\t/* relenquish control of this thread */\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].coreLog = NULL;\n\tif ((raidPtr->regionInfo[regionID].diskCount) < raidPtr->regionInfo[regionID].capacity)\n\t\t/* IMPORTANT!! this loop bound assumes region disk holds an\n\t\t * integral number of core logs */\n\t{\n\t\t/* update disk map for this region */\n\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\tfor (i = 0; i < raidPtr->numSectorsPerLog; i++) {\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].operation = log->records[i].operation;\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].parityAddr = log->records[i].parityAddr;\n\t\t}\n\t\tlog->diskOffset = diskCount;\n\t\traidPtr->regionInfo[regionID].diskCount += raidPtr->numSectorsPerLog;\n\t\tFlushLog(raidPtr, log);\n\t} else {\n\t\t/* no room for log on disk, send it to disk manager and\n\t\t * request reintegration */\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].diskCount == raidPtr->regionInfo[regionID].capacity);\n\t\tReintLog(raidPtr, regionID, log);\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished dumping parity log to disk, region %d]\\n\", regionID);\n\treturn (0);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic int \nDumpParityLogToDisk(\n    int finish,\n    RF_ParityLogData_t * logData)\n{\n\tint     i, diskCount, regionID = logData->regionID;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = logData->common->raidPtr;\n\n\t/* Move a core log to disk.  If the log disk is full, initiate\n\t * reintegration.\n\t * \n\t * Return (0) if we can enqueue the dump immediately, otherwise return\n\t * (1) to indicate we are blocked on reintegration and control of the\n\t * thread should be relinquished.\n\t * \n\t * Caller must hold regionInfo[regionID].mutex\n\t * \n\t * NON-BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[dumping parity log to disk, region %d]\\n\", regionID);\n\tlog = raidPtr->regionInfo[regionID].coreLog;\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\n\t/* if reintegration is in progress, must queue work */\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tif (raidPtr->regionInfo[regionID].reintInProgress) {\n\t\t/* Can not proceed since this region is currently being\n\t\t * reintegrated. We can not block, so queue remaining work and\n\t\t * return */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[region %d waiting on reintegration]\\n\", regionID);\n\t\t/* XXX not sure about the use of finish - shouldn't this\n\t\t * always be \"Enqueue\"? */\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\treturn (1);\t/* relenquish control of this thread */\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].coreLog = NULL;\n\tif ((raidPtr->regionInfo[regionID].diskCount) < raidPtr->regionInfo[regionID].capacity)\n\t\t/* IMPORTANT!! this loop bound assumes region disk holds an\n\t\t * integral number of core logs */\n\t{\n\t\t/* update disk map for this region */\n\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\tfor (i = 0; i < raidPtr->numSectorsPerLog; i++) {\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].operation = log->records[i].operation;\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].parityAddr = log->records[i].parityAddr;\n\t\t}\n\t\tlog->diskOffset = diskCount;\n\t\traidPtr->regionInfo[regionID].diskCount += raidPtr->numSectorsPerLog;\n\t\tFlushLog(raidPtr, log);\n\t} else {\n\t\t/* no room for log on disk, send it to disk manager and\n\t\t * request reintegration */\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].diskCount == raidPtr->regionInfo[regionID].capacity);\n\t\tReintLog(raidPtr, regionID, log);\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished dumping parity log to disk, region %d]\\n\", regionID);\n\treturn (0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->regionInfo[regionID].coreLog->next == NULL"
          ],
          "line": 763
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*incomingLog)->next == NULL"
          ],
          "line": 749
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "0"
          ],
          "line": 740
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->regionInfo[regionID].loggingEnabled"
          ],
          "line": 726
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 725
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 723
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 708
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 706
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE"
          ],
          "line": 703
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 702
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 701
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->regionInfo[regionID].loggingEnabled"
          ],
          "line": 696
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 695
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "logData != NULL"
          ],
          "line": 693
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nint \nrf_ParityLogAppend(\n    RF_ParityLogData_t * logData,\n    int finish,\n    RF_ParityLog_t ** incomingLog,\n    int clearReintFlag)\n{\n\tint     regionID, logItem, itemDone;\n\tRF_ParityLogData_t *item;\n\tint     punt, done = RF_FALSE;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\tRF_Etimer_t timer;\n\tint     (*wakeFunc) (RF_DagNode_t * node, int status);\n\tvoid   *wakeArg;\n\n\t/* Add parity to the appropriate log, one sector at a time. This\n\t * routine is called is called by dag functions ParityLogUpdateFunc\n\t * and ParityLogOverwriteFunc and therefore MUST BE NONBLOCKING.\n\t * \n\t * Parity to be logged is contained in a linked-list (logData).  When\n\t * this routine returns, every sector in the list will be in one of\n\t * three places: 1) entered into the parity log 2) queued, waiting on\n\t * reintegration 3) queued, waiting on a core log\n\t * \n\t * Blocked work is passed to the ParityLoggingDiskManager for completion.\n\t * Later, as conditions which required the block are removed, the work\n\t * reenters this routine with the \"finish\" parameter set to \"RF_TRUE.\"\n\t * \n\t * NON-BLOCKING */\n\n\traidPtr = logData->common->raidPtr;\n\t/* lock the region for the first item in logData */\n\tRF_ASSERT(logData != NULL);\n\tregionID = logData->regionID;\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\n\tif (clearReintFlag) {\n\t\t/* Enable flushing for this region.  Holding both locks\n\t\t * provides a synchronization barrier with DumpParityLogToDisk */\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE);\n\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t}\n\t/* process each item in logData */\n\twhile (logData) {\n\t\t/* remove an item from logData */\n\t\titem = logData;\n\t\tlogData = logData->next;\n\t\titem->next = NULL;\n\t\titem->prev = NULL;\n\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[appending parity log data, region %d, raidAddress %d, numSector %d]\\n\", item->regionID, (int) item->diskAddress.raidAddress, (int) item->diskAddress.numSector);\n\n\t\t/* see if we moved to a new region */\n\t\tif (regionID != item->regionID) {\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tregionID = item->regionID;\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\t\t}\n\t\tpunt = RF_FALSE;/* Set to RF_TRUE if work is blocked.  This\n\t\t\t\t * can happen in one of two ways: 1) no core\n\t\t\t\t * log (AcquireParityLog) 2) waiting on\n\t\t\t\t * reintegration (DumpParityLogToDisk) If punt\n\t\t\t\t * is RF_TRUE, the dataItem was queued, so\n\t\t\t\t * skip to next item. */\n\n\t\t/* process item, one sector at a time, until all sectors\n\t\t * processed or we punt */\n\t\tif (item->diskAddress.numSector > 0)\n\t\t\tdone = RF_FALSE;\n\t\telse\n\t\t\tRF_ASSERT(0);\n\t\twhile (!punt && !done) {\n\t\t\t/* verify that a core log exists for this region */\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog) {\n\t\t\t\t/* Attempt to acquire a parity log. If\n\t\t\t\t * acquisition fails, queue remaining work in\n\t\t\t\t * data item and move to nextItem. */\n\t\t\t\tif (incomingLog) {\n\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t} else\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t} else\n\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t/* Note: AcquireParityLog either returns a log\n\t\t\t\t * or enqueues currentItem */\n\t\t\t}\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\tpunt = RF_TRUE;\t/* failed to find a core log */\n\t\t\telse {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* verify that the log has room for new\n\t\t\t\t * entries */\n\t\t\t\t/* if log is full, dump it to disk and grab a\n\t\t\t\t * new log */\n\t\t\t\tif (raidPtr->regionInfo[regionID].coreLog->numRecords == raidPtr->numSectorsPerLog) {\n\t\t\t\t\t/* log is full, dump it to disk */\n\t\t\t\t\tif (DumpParityLogToDisk(finish, item))\n\t\t\t\t\t\tpunt = RF_TRUE;\t/* dump unsuccessful,\n\t\t\t\t\t\t\t\t * blocked on\n\t\t\t\t\t\t\t\t * reintegration */\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* dump was successful */\n\t\t\t\t\t  if (incomingLog) {\n\t\t\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t\t\t} else\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t/* if a core log is not\n\t\t\t\t\t\t * available, must queue work\n\t\t\t\t\t\t * and return */\n\t\t\t\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\t\t\t\tpunt = RF_TRUE;\t/* blocked on log\n\t\t\t\t\t\t\t\t\t * availability */\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* if we didn't punt on this item, attempt to add a\n\t\t\t * sector to the core log */\n\t\t\tif (!punt) {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* at this point, we have a core log with\n\t\t\t\t * enough room for a sector */\n\t\t\t\t/* copy a sector into the log */\n\t\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\t\tRF_ASSERT(log->numRecords < raidPtr->numSectorsPerLog);\n\t\t\t\tlogItem = log->numRecords++;\n\t\t\t\tlog->records[logItem].parityAddr = item->diskAddress;\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr);\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity);\n\t\t\t\tlog->records[logItem].parityAddr.numSector = 1;\n\t\t\t\tlog->records[logItem].operation = item->common->operation;\n\t\t\t\tbcopy((item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector))), log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector)), (1 << item->common->raidPtr->logBytesPerSector));\n\t\t\t\titem->diskAddress.numSector--;\n\t\t\t\titem->diskAddress.startSector++;\n\t\t\t\tif (item->diskAddress.numSector == 0)\n\t\t\t\t\tdone = RF_TRUE;\n\t\t\t}\n\t\t}\n\n\t\tif (!punt) {\n\t\t\t/* Processed this item completely, decrement count of\n\t\t\t * items to be processed. */\n\t\t\tRF_ASSERT(item->diskAddress.numSector == 0);\n\t\t\tRF_LOCK_MUTEX(item->common->mutex);\n\t\t\titem->common->cnt--;\n\t\t\tif (item->common->cnt == 0)\n\t\t\t\titemDone = RF_TRUE;\n\t\t\telse\n\t\t\t\titemDone = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(item->common->mutex);\n\t\t\tif (itemDone) {\n\t\t\t\t/* Finished processing all log data for this\n\t\t\t\t * IO Return structs to free list and invoke\n\t\t\t\t * wakeup function. */\n\t\t\t\ttimer = item->common->startTime;\t/* grab initial value of\n\t\t\t\t\t\t\t\t\t * timer */\n\t\t\t\tRF_ETIMER_STOP(timer);\n\t\t\t\tRF_ETIMER_EVAL(timer);\n\t\t\t\titem->common->tracerec->plog_us += RF_ETIMER_VAL_US(timer);\n\t\t\t\tif (rf_parityLogDebug)\n\t\t\t\t\tprintf(\"[waking process for region %d]\\n\", item->regionID);\n\t\t\t\twakeFunc = item->common->wakeFunc;\n\t\t\t\twakeArg = item->common->wakeArg;\n\t\t\t\tFreeParityLogCommonData(item->common);\n\t\t\t\tFreeParityLogData(item);\n\t\t\t\t(wakeFunc) (wakeArg, 0);\n\t\t\t} else\n\t\t\t\tFreeParityLogData(item);\n\t\t}\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[exiting ParityLogAppend]\\n\");\n\treturn (0);\n}"
  },
  {
    "function_name": "DumpParityLogToDisk",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "589-658",
    "snippet": "static int \nDumpParityLogToDisk(\n    int finish,\n    RF_ParityLogData_t * logData)\n{\n\tint     i, diskCount, regionID = logData->regionID;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = logData->common->raidPtr;\n\n\t/* Move a core log to disk.  If the log disk is full, initiate\n\t * reintegration.\n\t * \n\t * Return (0) if we can enqueue the dump immediately, otherwise return\n\t * (1) to indicate we are blocked on reintegration and control of the\n\t * thread should be relinquished.\n\t * \n\t * Caller must hold regionInfo[regionID].mutex\n\t * \n\t * NON-BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[dumping parity log to disk, region %d]\\n\", regionID);\n\tlog = raidPtr->regionInfo[regionID].coreLog;\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\n\t/* if reintegration is in progress, must queue work */\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tif (raidPtr->regionInfo[regionID].reintInProgress) {\n\t\t/* Can not proceed since this region is currently being\n\t\t * reintegrated. We can not block, so queue remaining work and\n\t\t * return */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[region %d waiting on reintegration]\\n\", regionID);\n\t\t/* XXX not sure about the use of finish - shouldn't this\n\t\t * always be \"Enqueue\"? */\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\treturn (1);\t/* relenquish control of this thread */\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].coreLog = NULL;\n\tif ((raidPtr->regionInfo[regionID].diskCount) < raidPtr->regionInfo[regionID].capacity)\n\t\t/* IMPORTANT!! this loop bound assumes region disk holds an\n\t\t * integral number of core logs */\n\t{\n\t\t/* update disk map for this region */\n\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\tfor (i = 0; i < raidPtr->numSectorsPerLog; i++) {\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].operation = log->records[i].operation;\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].parityAddr = log->records[i].parityAddr;\n\t\t}\n\t\tlog->diskOffset = diskCount;\n\t\traidPtr->regionInfo[regionID].diskCount += raidPtr->numSectorsPerLog;\n\t\tFlushLog(raidPtr, log);\n\t} else {\n\t\t/* no room for log on disk, send it to disk manager and\n\t\t * request reintegration */\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].diskCount == raidPtr->regionInfo[regionID].capacity);\n\t\tReintLog(raidPtr, regionID, log);\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished dumping parity log to disk, region %d]\\n\", regionID);\n\treturn (0);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[finished dumping parity log to disk, region %d]\\n\"",
            "regionID"
          ],
          "line": 656
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "ReintLog",
          "args": [
            "raidPtr",
            "regionID",
            "log"
          ],
          "line": 653
        },
        "resolved": true,
        "details": {
          "function_name": "ReintLog",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "541-567",
          "snippet": "static void \nReintLog(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLog_t * log)\n{\n\tRF_ASSERT(log);\n\n\t/* Insert an in-core parity log (log) into the disk queue of\n\t * reintegration work.  Set the flag (reintInProgress) for the\n\t * specified region (regionID) to indicate that reintegration is in\n\t * progress for this region. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].reintInProgress = RF_TRUE;\t/* cleared when reint\n\t\t\t\t\t\t\t\t\t * complete */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requesting reintegration of region %d]\\n\", log->regionID);\n\t/* move record to reintegration queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.reintQueue;\n\traidPtr->parityLogDiskQueue.reintQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintLog(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLog_t * log)\n{\n\tRF_ASSERT(log);\n\n\t/* Insert an in-core parity log (log) into the disk queue of\n\t * reintegration work.  Set the flag (reintInProgress) for the\n\t * specified region (regionID) to indicate that reintegration is in\n\t * progress for this region. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].reintInProgress = RF_TRUE;\t/* cleared when reint\n\t\t\t\t\t\t\t\t\t * complete */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requesting reintegration of region %d]\\n\", log->regionID);\n\t/* move record to reintegration queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.reintQueue;\n\traidPtr->parityLogDiskQueue.reintQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->regionInfo[regionID].diskCount == raidPtr->regionInfo[regionID].capacity"
          ],
          "line": 652
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "FlushLog",
          "args": [
            "raidPtr",
            "log"
          ],
          "line": 648
        },
        "resolved": true,
        "details": {
          "function_name": "FlushLog",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "569-587",
          "snippet": "static void \nFlushLog(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * log)\n{\n\t/* insert a core log (log) into a list of logs\n\t * (parityLogDiskQueue.flushQueue) waiting to be written to disk.\n\t * NON-BLOCKING */\n\n\tRF_ASSERT(log);\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\t/* move log to flush queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.flushQueue;\n\traidPtr->parityLogDiskQueue.flushQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFlushLog(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * log)\n{\n\t/* insert a core log (log) into a list of logs\n\t * (parityLogDiskQueue.flushQueue) waiting to be written to disk.\n\t * NON-BLOCKING */\n\n\tRF_ASSERT(log);\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\t/* move log to flush queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.flushQueue;\n\traidPtr->parityLogDiskQueue.flushQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 634
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 631
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EnqueueParityLogData",
          "args": [
            "logData",
            "&raidPtr->parityLogDiskQueue.reintBlockHead",
            "&raidPtr->parityLogDiskQueue.reintBlockTail"
          ],
          "line": 630
        },
        "resolved": true,
        "details": {
          "function_name": "EnqueueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "150-184",
          "snippet": "static void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RequeueParityLogData",
          "args": [
            "logData",
            "&raidPtr->parityLogDiskQueue.reintBlockHead",
            "&raidPtr->parityLogDiskQueue.reintBlockTail"
          ],
          "line": 628
        },
        "resolved": true,
        "details": {
          "function_name": "RequeueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "228-260",
          "snippet": "static void \nRequeueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the tail of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_ASSERT(data);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*tail) {\n\t\t/* append to tail of list */\n\t\tdata->prev = *tail;\n\t\tdata->next = NULL;\n\t\t(*tail)->next = data;\n\t\t*tail = data;\n\t} else {\n\t\t/* inserting into an empty list */\n\t\t*head = data;\n\t\t*tail = data;\n\t\t(*head)->prev = NULL;\n\t\t(*tail)->next = NULL;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nRequeueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the tail of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_ASSERT(data);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*tail) {\n\t\t/* append to tail of list */\n\t\tdata->prev = *tail;\n\t\tdata->next = NULL;\n\t\t(*tail)->next = data;\n\t\t*tail = data;\n\t} else {\n\t\t/* inserting into an empty list */\n\t\t*head = data;\n\t\t*tail = data;\n\t\t(*head)->prev = NULL;\n\t\t(*tail)->next = NULL;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 618
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->next == NULL"
          ],
          "line": 615
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->numRecords == raidPtr->numSectorsPerLog"
          ],
          "line": 614
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic int \nDumpParityLogToDisk(\n    int finish,\n    RF_ParityLogData_t * logData)\n{\n\tint     i, diskCount, regionID = logData->regionID;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = logData->common->raidPtr;\n\n\t/* Move a core log to disk.  If the log disk is full, initiate\n\t * reintegration.\n\t * \n\t * Return (0) if we can enqueue the dump immediately, otherwise return\n\t * (1) to indicate we are blocked on reintegration and control of the\n\t * thread should be relinquished.\n\t * \n\t * Caller must hold regionInfo[regionID].mutex\n\t * \n\t * NON-BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[dumping parity log to disk, region %d]\\n\", regionID);\n\tlog = raidPtr->regionInfo[regionID].coreLog;\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\n\t/* if reintegration is in progress, must queue work */\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tif (raidPtr->regionInfo[regionID].reintInProgress) {\n\t\t/* Can not proceed since this region is currently being\n\t\t * reintegrated. We can not block, so queue remaining work and\n\t\t * return */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[region %d waiting on reintegration]\\n\", regionID);\n\t\t/* XXX not sure about the use of finish - shouldn't this\n\t\t * always be \"Enqueue\"? */\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail);\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\treturn (1);\t/* relenquish control of this thread */\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].coreLog = NULL;\n\tif ((raidPtr->regionInfo[regionID].diskCount) < raidPtr->regionInfo[regionID].capacity)\n\t\t/* IMPORTANT!! this loop bound assumes region disk holds an\n\t\t * integral number of core logs */\n\t{\n\t\t/* update disk map for this region */\n\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\tfor (i = 0; i < raidPtr->numSectorsPerLog; i++) {\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].operation = log->records[i].operation;\n\t\t\traidPtr->regionInfo[regionID].diskMap[i + diskCount].parityAddr = log->records[i].parityAddr;\n\t\t}\n\t\tlog->diskOffset = diskCount;\n\t\traidPtr->regionInfo[regionID].diskCount += raidPtr->numSectorsPerLog;\n\t\tFlushLog(raidPtr, log);\n\t} else {\n\t\t/* no room for log on disk, send it to disk manager and\n\t\t * request reintegration */\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].diskCount == raidPtr->regionInfo[regionID].capacity);\n\t\tReintLog(raidPtr, regionID, log);\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished dumping parity log to disk, region %d]\\n\", regionID);\n\treturn (0);\n}"
  },
  {
    "function_name": "FlushLog",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "569-587",
    "snippet": "static void \nFlushLog(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * log)\n{\n\t/* insert a core log (log) into a list of logs\n\t * (parityLogDiskQueue.flushQueue) waiting to be written to disk.\n\t * NON-BLOCKING */\n\n\tRF_ASSERT(log);\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\t/* move log to flush queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.flushQueue;\n\traidPtr->parityLogDiskQueue.flushQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_SIGNAL_COND",
          "args": [
            "raidPtr->parityLogDiskQueue.cond"
          ],
          "line": 586
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 585
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 582
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->next == NULL"
          ],
          "line": 580
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log->numRecords == raidPtr->numSectorsPerLog"
          ],
          "line": 579
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log"
          ],
          "line": 578
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFlushLog(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * log)\n{\n\t/* insert a core log (log) into a list of logs\n\t * (parityLogDiskQueue.flushQueue) waiting to be written to disk.\n\t * NON-BLOCKING */\n\n\tRF_ASSERT(log);\n\tRF_ASSERT(log->numRecords == raidPtr->numSectorsPerLog);\n\tRF_ASSERT(log->next == NULL);\n\t/* move log to flush queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.flushQueue;\n\traidPtr->parityLogDiskQueue.flushQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}"
  },
  {
    "function_name": "ReintLog",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "541-567",
    "snippet": "static void \nReintLog(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLog_t * log)\n{\n\tRF_ASSERT(log);\n\n\t/* Insert an in-core parity log (log) into the disk queue of\n\t * reintegration work.  Set the flag (reintInProgress) for the\n\t * specified region (regionID) to indicate that reintegration is in\n\t * progress for this region. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].reintInProgress = RF_TRUE;\t/* cleared when reint\n\t\t\t\t\t\t\t\t\t * complete */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requesting reintegration of region %d]\\n\", log->regionID);\n\t/* move record to reintegration queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.reintQueue;\n\traidPtr->parityLogDiskQueue.reintQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_SIGNAL_COND",
          "args": [
            "raidPtr->parityLogDiskQueue.cond"
          ],
          "line": 566
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 565
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 564
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 561
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[requesting reintegration of region %d]\\n\"",
            "log->regionID"
          ],
          "line": 559
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 554
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "log"
          ],
          "line": 547
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintLog(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLog_t * log)\n{\n\tRF_ASSERT(log);\n\n\t/* Insert an in-core parity log (log) into the disk queue of\n\t * reintegration work.  Set the flag (reintInProgress) for the\n\t * specified region (regionID) to indicate that reintegration is in\n\t * progress for this region. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\traidPtr->regionInfo[regionID].reintInProgress = RF_TRUE;\t/* cleared when reint\n\t\t\t\t\t\t\t\t\t * complete */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requesting reintegration of region %d]\\n\", log->regionID);\n\t/* move record to reintegration queue */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlog->next = raidPtr->parityLogDiskQueue.reintQueue;\n\traidPtr->parityLogDiskQueue.reintQueue = log;\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n}"
  },
  {
    "function_name": "rf_ReleaseParityLogs",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "467-539",
    "snippet": "void \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogPool.mutex"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "cnt + raidPtr->logsInUse == raidPtr->numParityLogs"
          ],
          "line": 535
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs"
          ],
          "line": 525
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs"
          ],
          "line": 521
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DequeueMatchingLogData",
          "args": [
            "raidPtr",
            "&raidPtr->parityLogDiskQueue.logBlockHead",
            "&raidPtr->parityLogDiskQueue.logBlockTail"
          ],
          "line": 511
        },
        "resolved": true,
        "details": {
          "function_name": "DequeueMatchingLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "402-428",
          "snippet": "static RF_ParityLogData_t *\nDequeueMatchingLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_ParityLogData_t *logDataList, *logData;\n\tint     regionID;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail).  Then remove all matching (identical\n\t * regionIDs) logData and return as a linked list.\n\t * \n\t * NON-BLOCKING */\n\n\tlogDataList = DequeueParityLogData(raidPtr, head, tail, RF_TRUE);\n\tif (logDataList) {\n\t\tregionID = logDataList->regionID;\n\t\tlogData = logDataList;\n\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\twhile (logData->next) {\n\t\t\tlogData = logData->next;\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\t}\n\t}\n\treturn (logDataList);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLogData_t *\nDequeueMatchingLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_ParityLogData_t *logDataList, *logData;\n\tint     regionID;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail).  Then remove all matching (identical\n\t * regionIDs) logData and return as a linked list.\n\t * \n\t * NON-BLOCKING */\n\n\tlogDataList = DequeueParityLogData(raidPtr, head, tail, RF_TRUE);\n\tif (logDataList) {\n\t\tregionID = logDataList->regionID;\n\t\tlogData = logDataList;\n\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\twhile (logData->next) {\n\t\t\tlogData = logData->next;\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\t}\n\t}\n\treturn (logDataList);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 509
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogPool.mutex"
          ],
          "line": 508
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[finishing up buf-blocked log data, region %d]\\n\"",
            "logDataList->regionID"
          ],
          "line": 499
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_ParityLogAppend",
          "args": [
            "logDataList",
            "RF_TRUE",
            "&log",
            "RF_FALSE"
          ],
          "line": 497
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ParityLogAppend",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "660-853",
          "snippet": "int \nrf_ParityLogAppend(\n    RF_ParityLogData_t * logData,\n    int finish,\n    RF_ParityLog_t ** incomingLog,\n    int clearReintFlag)\n{\n\tint     regionID, logItem, itemDone;\n\tRF_ParityLogData_t *item;\n\tint     punt, done = RF_FALSE;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\tRF_Etimer_t timer;\n\tint     (*wakeFunc) (RF_DagNode_t * node, int status);\n\tvoid   *wakeArg;\n\n\t/* Add parity to the appropriate log, one sector at a time. This\n\t * routine is called is called by dag functions ParityLogUpdateFunc\n\t * and ParityLogOverwriteFunc and therefore MUST BE NONBLOCKING.\n\t * \n\t * Parity to be logged is contained in a linked-list (logData).  When\n\t * this routine returns, every sector in the list will be in one of\n\t * three places: 1) entered into the parity log 2) queued, waiting on\n\t * reintegration 3) queued, waiting on a core log\n\t * \n\t * Blocked work is passed to the ParityLoggingDiskManager for completion.\n\t * Later, as conditions which required the block are removed, the work\n\t * reenters this routine with the \"finish\" parameter set to \"RF_TRUE.\"\n\t * \n\t * NON-BLOCKING */\n\n\traidPtr = logData->common->raidPtr;\n\t/* lock the region for the first item in logData */\n\tRF_ASSERT(logData != NULL);\n\tregionID = logData->regionID;\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\n\tif (clearReintFlag) {\n\t\t/* Enable flushing for this region.  Holding both locks\n\t\t * provides a synchronization barrier with DumpParityLogToDisk */\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE);\n\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t}\n\t/* process each item in logData */\n\twhile (logData) {\n\t\t/* remove an item from logData */\n\t\titem = logData;\n\t\tlogData = logData->next;\n\t\titem->next = NULL;\n\t\titem->prev = NULL;\n\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[appending parity log data, region %d, raidAddress %d, numSector %d]\\n\", item->regionID, (int) item->diskAddress.raidAddress, (int) item->diskAddress.numSector);\n\n\t\t/* see if we moved to a new region */\n\t\tif (regionID != item->regionID) {\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tregionID = item->regionID;\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\t\t}\n\t\tpunt = RF_FALSE;/* Set to RF_TRUE if work is blocked.  This\n\t\t\t\t * can happen in one of two ways: 1) no core\n\t\t\t\t * log (AcquireParityLog) 2) waiting on\n\t\t\t\t * reintegration (DumpParityLogToDisk) If punt\n\t\t\t\t * is RF_TRUE, the dataItem was queued, so\n\t\t\t\t * skip to next item. */\n\n\t\t/* process item, one sector at a time, until all sectors\n\t\t * processed or we punt */\n\t\tif (item->diskAddress.numSector > 0)\n\t\t\tdone = RF_FALSE;\n\t\telse\n\t\t\tRF_ASSERT(0);\n\t\twhile (!punt && !done) {\n\t\t\t/* verify that a core log exists for this region */\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog) {\n\t\t\t\t/* Attempt to acquire a parity log. If\n\t\t\t\t * acquisition fails, queue remaining work in\n\t\t\t\t * data item and move to nextItem. */\n\t\t\t\tif (incomingLog) {\n\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t} else\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t} else\n\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t/* Note: AcquireParityLog either returns a log\n\t\t\t\t * or enqueues currentItem */\n\t\t\t}\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\tpunt = RF_TRUE;\t/* failed to find a core log */\n\t\t\telse {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* verify that the log has room for new\n\t\t\t\t * entries */\n\t\t\t\t/* if log is full, dump it to disk and grab a\n\t\t\t\t * new log */\n\t\t\t\tif (raidPtr->regionInfo[regionID].coreLog->numRecords == raidPtr->numSectorsPerLog) {\n\t\t\t\t\t/* log is full, dump it to disk */\n\t\t\t\t\tif (DumpParityLogToDisk(finish, item))\n\t\t\t\t\t\tpunt = RF_TRUE;\t/* dump unsuccessful,\n\t\t\t\t\t\t\t\t * blocked on\n\t\t\t\t\t\t\t\t * reintegration */\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* dump was successful */\n\t\t\t\t\t  if (incomingLog) {\n\t\t\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t\t\t} else\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t/* if a core log is not\n\t\t\t\t\t\t * available, must queue work\n\t\t\t\t\t\t * and return */\n\t\t\t\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\t\t\t\tpunt = RF_TRUE;\t/* blocked on log\n\t\t\t\t\t\t\t\t\t * availability */\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* if we didn't punt on this item, attempt to add a\n\t\t\t * sector to the core log */\n\t\t\tif (!punt) {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* at this point, we have a core log with\n\t\t\t\t * enough room for a sector */\n\t\t\t\t/* copy a sector into the log */\n\t\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\t\tRF_ASSERT(log->numRecords < raidPtr->numSectorsPerLog);\n\t\t\t\tlogItem = log->numRecords++;\n\t\t\t\tlog->records[logItem].parityAddr = item->diskAddress;\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr);\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity);\n\t\t\t\tlog->records[logItem].parityAddr.numSector = 1;\n\t\t\t\tlog->records[logItem].operation = item->common->operation;\n\t\t\t\tbcopy((item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector))), log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector)), (1 << item->common->raidPtr->logBytesPerSector));\n\t\t\t\titem->diskAddress.numSector--;\n\t\t\t\titem->diskAddress.startSector++;\n\t\t\t\tif (item->diskAddress.numSector == 0)\n\t\t\t\t\tdone = RF_TRUE;\n\t\t\t}\n\t\t}\n\n\t\tif (!punt) {\n\t\t\t/* Processed this item completely, decrement count of\n\t\t\t * items to be processed. */\n\t\t\tRF_ASSERT(item->diskAddress.numSector == 0);\n\t\t\tRF_LOCK_MUTEX(item->common->mutex);\n\t\t\titem->common->cnt--;\n\t\t\tif (item->common->cnt == 0)\n\t\t\t\titemDone = RF_TRUE;\n\t\t\telse\n\t\t\t\titemDone = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(item->common->mutex);\n\t\t\tif (itemDone) {\n\t\t\t\t/* Finished processing all log data for this\n\t\t\t\t * IO Return structs to free list and invoke\n\t\t\t\t * wakeup function. */\n\t\t\t\ttimer = item->common->startTime;\t/* grab initial value of\n\t\t\t\t\t\t\t\t\t * timer */\n\t\t\t\tRF_ETIMER_STOP(timer);\n\t\t\t\tRF_ETIMER_EVAL(timer);\n\t\t\t\titem->common->tracerec->plog_us += RF_ETIMER_VAL_US(timer);\n\t\t\t\tif (rf_parityLogDebug)\n\t\t\t\t\tprintf(\"[waking process for region %d]\\n\", item->regionID);\n\t\t\t\twakeFunc = item->common->wakeFunc;\n\t\t\t\twakeArg = item->common->wakeArg;\n\t\t\t\tFreeParityLogCommonData(item->common);\n\t\t\t\tFreeParityLogData(item);\n\t\t\t\t(wakeFunc) (wakeArg, 0);\n\t\t\t} else\n\t\t\t\tFreeParityLogData(item);\n\t\t}\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[exiting ParityLogAppend]\\n\");\n\treturn (0);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nint \nrf_ParityLogAppend(\n    RF_ParityLogData_t * logData,\n    int finish,\n    RF_ParityLog_t ** incomingLog,\n    int clearReintFlag)\n{\n\tint     regionID, logItem, itemDone;\n\tRF_ParityLogData_t *item;\n\tint     punt, done = RF_FALSE;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\tRF_Etimer_t timer;\n\tint     (*wakeFunc) (RF_DagNode_t * node, int status);\n\tvoid   *wakeArg;\n\n\t/* Add parity to the appropriate log, one sector at a time. This\n\t * routine is called is called by dag functions ParityLogUpdateFunc\n\t * and ParityLogOverwriteFunc and therefore MUST BE NONBLOCKING.\n\t * \n\t * Parity to be logged is contained in a linked-list (logData).  When\n\t * this routine returns, every sector in the list will be in one of\n\t * three places: 1) entered into the parity log 2) queued, waiting on\n\t * reintegration 3) queued, waiting on a core log\n\t * \n\t * Blocked work is passed to the ParityLoggingDiskManager for completion.\n\t * Later, as conditions which required the block are removed, the work\n\t * reenters this routine with the \"finish\" parameter set to \"RF_TRUE.\"\n\t * \n\t * NON-BLOCKING */\n\n\traidPtr = logData->common->raidPtr;\n\t/* lock the region for the first item in logData */\n\tRF_ASSERT(logData != NULL);\n\tregionID = logData->regionID;\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\n\tif (clearReintFlag) {\n\t\t/* Enable flushing for this region.  Holding both locks\n\t\t * provides a synchronization barrier with DumpParityLogToDisk */\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE);\n\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t}\n\t/* process each item in logData */\n\twhile (logData) {\n\t\t/* remove an item from logData */\n\t\titem = logData;\n\t\tlogData = logData->next;\n\t\titem->next = NULL;\n\t\titem->prev = NULL;\n\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[appending parity log data, region %d, raidAddress %d, numSector %d]\\n\", item->regionID, (int) item->diskAddress.raidAddress, (int) item->diskAddress.numSector);\n\n\t\t/* see if we moved to a new region */\n\t\tif (regionID != item->regionID) {\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tregionID = item->regionID;\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\t\t}\n\t\tpunt = RF_FALSE;/* Set to RF_TRUE if work is blocked.  This\n\t\t\t\t * can happen in one of two ways: 1) no core\n\t\t\t\t * log (AcquireParityLog) 2) waiting on\n\t\t\t\t * reintegration (DumpParityLogToDisk) If punt\n\t\t\t\t * is RF_TRUE, the dataItem was queued, so\n\t\t\t\t * skip to next item. */\n\n\t\t/* process item, one sector at a time, until all sectors\n\t\t * processed or we punt */\n\t\tif (item->diskAddress.numSector > 0)\n\t\t\tdone = RF_FALSE;\n\t\telse\n\t\t\tRF_ASSERT(0);\n\t\twhile (!punt && !done) {\n\t\t\t/* verify that a core log exists for this region */\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog) {\n\t\t\t\t/* Attempt to acquire a parity log. If\n\t\t\t\t * acquisition fails, queue remaining work in\n\t\t\t\t * data item and move to nextItem. */\n\t\t\t\tif (incomingLog) {\n\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t} else\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t} else\n\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t/* Note: AcquireParityLog either returns a log\n\t\t\t\t * or enqueues currentItem */\n\t\t\t}\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\tpunt = RF_TRUE;\t/* failed to find a core log */\n\t\t\telse {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* verify that the log has room for new\n\t\t\t\t * entries */\n\t\t\t\t/* if log is full, dump it to disk and grab a\n\t\t\t\t * new log */\n\t\t\t\tif (raidPtr->regionInfo[regionID].coreLog->numRecords == raidPtr->numSectorsPerLog) {\n\t\t\t\t\t/* log is full, dump it to disk */\n\t\t\t\t\tif (DumpParityLogToDisk(finish, item))\n\t\t\t\t\t\tpunt = RF_TRUE;\t/* dump unsuccessful,\n\t\t\t\t\t\t\t\t * blocked on\n\t\t\t\t\t\t\t\t * reintegration */\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* dump was successful */\n\t\t\t\t\t  if (incomingLog) {\n\t\t\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t\t\t} else\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t/* if a core log is not\n\t\t\t\t\t\t * available, must queue work\n\t\t\t\t\t\t * and return */\n\t\t\t\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\t\t\t\tpunt = RF_TRUE;\t/* blocked on log\n\t\t\t\t\t\t\t\t\t * availability */\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* if we didn't punt on this item, attempt to add a\n\t\t\t * sector to the core log */\n\t\t\tif (!punt) {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* at this point, we have a core log with\n\t\t\t\t * enough room for a sector */\n\t\t\t\t/* copy a sector into the log */\n\t\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\t\tRF_ASSERT(log->numRecords < raidPtr->numSectorsPerLog);\n\t\t\t\tlogItem = log->numRecords++;\n\t\t\t\tlog->records[logItem].parityAddr = item->diskAddress;\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr);\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity);\n\t\t\t\tlog->records[logItem].parityAddr.numSector = 1;\n\t\t\t\tlog->records[logItem].operation = item->common->operation;\n\t\t\t\tbcopy((item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector))), log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector)), (1 << item->common->raidPtr->logBytesPerSector));\n\t\t\t\titem->diskAddress.numSector--;\n\t\t\t\titem->diskAddress.startSector++;\n\t\t\t\tif (item->diskAddress.numSector == 0)\n\t\t\t\t\tdone = RF_TRUE;\n\t\t\t}\n\t\t}\n\n\t\tif (!punt) {\n\t\t\t/* Processed this item completely, decrement count of\n\t\t\t * items to be processed. */\n\t\t\tRF_ASSERT(item->diskAddress.numSector == 0);\n\t\t\tRF_LOCK_MUTEX(item->common->mutex);\n\t\t\titem->common->cnt--;\n\t\t\tif (item->common->cnt == 0)\n\t\t\t\titemDone = RF_TRUE;\n\t\t\telse\n\t\t\t\titemDone = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(item->common->mutex);\n\t\t\tif (itemDone) {\n\t\t\t\t/* Finished processing all log data for this\n\t\t\t\t * IO Return structs to free list and invoke\n\t\t\t\t * wakeup function. */\n\t\t\t\ttimer = item->common->startTime;\t/* grab initial value of\n\t\t\t\t\t\t\t\t\t * timer */\n\t\t\t\tRF_ETIMER_STOP(timer);\n\t\t\t\tRF_ETIMER_EVAL(timer);\n\t\t\t\titem->common->tracerec->plog_us += RF_ETIMER_VAL_US(timer);\n\t\t\t\tif (rf_parityLogDebug)\n\t\t\t\t\tprintf(\"[waking process for region %d]\\n\", item->regionID);\n\t\t\t\twakeFunc = item->common->wakeFunc;\n\t\t\t\twakeArg = item->common->wakeArg;\n\t\t\t\tFreeParityLogCommonData(item->common);\n\t\t\t\tFreeParityLogData(item);\n\t\t\t\t(wakeFunc) (wakeArg, 0);\n\t\t\t} else\n\t\t\t\tFreeParityLogData(item);\n\t\t}\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[exiting ParityLogAppend]\\n\");\n\treturn (0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 496
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogPool.mutex"
          ],
          "line": 495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 487
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogPool.mutex"
          ],
          "line": 486
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "firstLog"
          ],
          "line": 481
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
  },
  {
    "function_name": "AcquireParityLog",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "431-465",
    "snippet": "static RF_ParityLog_t *\nAcquireParityLog(\n    RF_ParityLogData_t * logData,\n    int finish)\n{\n\tRF_ParityLog_t *log = NULL;\n\tRF_Raid_t *raidPtr;\n\n\t/* Grab a log buffer from the pool and return it. If no buffers are\n\t * available, return NULL. NON-BLOCKING */\n\traidPtr = logData->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tif (raidPtr->parityLogPool.parityLogs) {\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = raidPtr->parityLogPool.parityLogs->next;\n\t\tlog->regionID = logData->regionID;\n\t\tlog->numRecords = 0;\n\t\tlog->next = NULL;\n\t\traidPtr->logsInUse++;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t} else {\n\t\t/* no logs available, so place ourselves on the queue of work\n\t\t * waiting on log buffers this is done while\n\t\t * parityLogPool.mutex is held, to ensure synchronization with\n\t\t * ReleaseParityLogs. */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[blocked on log, region %d, finish %d]\\n\", logData->regionID, finish);\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\treturn (log);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogPool.mutex"
          ],
          "line": 463
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "EnqueueParityLogData",
          "args": [
            "logData",
            "&raidPtr->parityLogDiskQueue.logBlockHead",
            "&raidPtr->parityLogDiskQueue.logBlockTail"
          ],
          "line": 461
        },
        "resolved": true,
        "details": {
          "function_name": "EnqueueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "150-184",
          "snippet": "static void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RequeueParityLogData",
          "args": [
            "logData",
            "&raidPtr->parityLogDiskQueue.logBlockHead",
            "&raidPtr->parityLogDiskQueue.logBlockTail"
          ],
          "line": 459
        },
        "resolved": true,
        "details": {
          "function_name": "RequeueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "228-260",
          "snippet": "static void \nRequeueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the tail of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_ASSERT(data);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*tail) {\n\t\t/* append to tail of list */\n\t\tdata->prev = *tail;\n\t\tdata->next = NULL;\n\t\t(*tail)->next = data;\n\t\t*tail = data;\n\t} else {\n\t\t/* inserting into an empty list */\n\t\t*head = data;\n\t\t*tail = data;\n\t\t(*head)->prev = NULL;\n\t\t(*tail)->next = NULL;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nRequeueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the tail of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_ASSERT(data);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*tail) {\n\t\t/* append to tail of list */\n\t\tdata->prev = *tail;\n\t\tdata->next = NULL;\n\t\t(*tail)->next = data;\n\t\t*tail = data;\n\t} else {\n\t\t/* inserting into an empty list */\n\t\t*head = data;\n\t\t*tail = data;\n\t\t(*head)->prev = NULL;\n\t\t(*tail)->next = NULL;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[blocked on log, region %d, finish %d]\\n\"",
            "logData->regionID",
            "finish"
          ],
          "line": 457
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs"
          ],
          "line": 450
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogPool.mutex"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLog_t *\nAcquireParityLog(\n    RF_ParityLogData_t * logData,\n    int finish)\n{\n\tRF_ParityLog_t *log = NULL;\n\tRF_Raid_t *raidPtr;\n\n\t/* Grab a log buffer from the pool and return it. If no buffers are\n\t * available, return NULL. NON-BLOCKING */\n\traidPtr = logData->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tif (raidPtr->parityLogPool.parityLogs) {\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = raidPtr->parityLogPool.parityLogs->next;\n\t\tlog->regionID = logData->regionID;\n\t\tlog->numRecords = 0;\n\t\tlog->next = NULL;\n\t\traidPtr->logsInUse++;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t} else {\n\t\t/* no logs available, so place ourselves on the queue of work\n\t\t * waiting on log buffers this is done while\n\t\t * parityLogPool.mutex is held, to ensure synchronization with\n\t\t * ReleaseParityLogs. */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[blocked on log, region %d, finish %d]\\n\", logData->regionID, finish);\n\t\tif (finish)\n\t\t\tRequeueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t\telse\n\t\t\tEnqueueParityLogData(logData, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\treturn (log);\n}"
  },
  {
    "function_name": "DequeueMatchingLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "402-428",
    "snippet": "static RF_ParityLogData_t *\nDequeueMatchingLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_ParityLogData_t *logDataList, *logData;\n\tint     regionID;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail).  Then remove all matching (identical\n\t * regionIDs) logData and return as a linked list.\n\t * \n\t * NON-BLOCKING */\n\n\tlogDataList = DequeueParityLogData(raidPtr, head, tail, RF_TRUE);\n\tif (logDataList) {\n\t\tregionID = logDataList->regionID;\n\t\tlogData = logDataList;\n\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\twhile (logData->next) {\n\t\t\tlogData = logData->next;\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\t}\n\t}\n\treturn (logDataList);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_SearchAndDequeueParityLogData",
          "args": [
            "raidPtr",
            "regionID",
            "head",
            "tail",
            "RF_TRUE"
          ],
          "line": 424
        },
        "resolved": true,
        "details": {
          "function_name": "rf_SearchAndDequeueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "338-400",
          "snippet": "RF_ParityLogData_t *\nrf_SearchAndDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *w;\n\n\t/* Remove and return an in-core parity log from a specified region\n\t * (regionID). If a matching log is not found, return NULL.\n\t * \n\t * NON-BLOCKING. */\n\n\t/* walk backward through a list, looking for an entry with a matching\n\t * region ID */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tw = (*tail);\n\twhile (w) {\n\t\tif (w->regionID == regionID) {\n\t\t\t/* remove an element from the list */\n\t\t\tif (w == *tail) {\n\t\t\t\tif (*head == *tail) {\n\t\t\t\t\t/* removing only element in the list */\n\t\t\t\t\t*head = NULL;\n\t\t\t\t\t*tail = NULL;\n\t\t\t\t} else {\n\t\t\t\t\t/* removing last item in the list */\n\t\t\t\t\t*tail = (*tail)->prev;\n\t\t\t\t\t(*tail)->next = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (w == *head) {\n\t\t\t\t\t/* removing first item in the list */\n\t\t\t\t\t*head = (*head)->next;\n\t\t\t\t\t(*head)->prev = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t} else {\n\t\t\t\t\t/* removing an item from the middle of\n\t\t\t\t\t * the list */\n\t\t\t\t\tw->prev->next = w->next;\n\t\t\t\t\tw->next->prev = w->prev;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tw->prev = NULL;\n\t\t\tw->next = NULL;\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", w->regionID, (int) w->diskAddress.raidAddress, (int) w->diskAddress.numSector);\n\t\t\treturn (w);\n\t\t} else\n\t\t\tw = w->prev;\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (NULL);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nRF_ParityLogData_t *\nrf_SearchAndDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *w;\n\n\t/* Remove and return an in-core parity log from a specified region\n\t * (regionID). If a matching log is not found, return NULL.\n\t * \n\t * NON-BLOCKING. */\n\n\t/* walk backward through a list, looking for an entry with a matching\n\t * region ID */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tw = (*tail);\n\twhile (w) {\n\t\tif (w->regionID == regionID) {\n\t\t\t/* remove an element from the list */\n\t\t\tif (w == *tail) {\n\t\t\t\tif (*head == *tail) {\n\t\t\t\t\t/* removing only element in the list */\n\t\t\t\t\t*head = NULL;\n\t\t\t\t\t*tail = NULL;\n\t\t\t\t} else {\n\t\t\t\t\t/* removing last item in the list */\n\t\t\t\t\t*tail = (*tail)->prev;\n\t\t\t\t\t(*tail)->next = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (w == *head) {\n\t\t\t\t\t/* removing first item in the list */\n\t\t\t\t\t*head = (*head)->next;\n\t\t\t\t\t(*head)->prev = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t} else {\n\t\t\t\t\t/* removing an item from the middle of\n\t\t\t\t\t * the list */\n\t\t\t\t\tw->prev->next = w->next;\n\t\t\t\t\tw->next->prev = w->prev;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tw->prev = NULL;\n\t\t\tw->next = NULL;\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", w->regionID, (int) w->diskAddress.raidAddress, (int) w->diskAddress.numSector);\n\t\t\treturn (w);\n\t\t} else\n\t\t\tw = w->prev;\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "DequeueParityLogData",
          "args": [
            "raidPtr",
            "head",
            "tail",
            "RF_TRUE"
          ],
          "line": 417
        },
        "resolved": true,
        "details": {
          "function_name": "DequeueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "186-225",
          "snippet": "static RF_ParityLogData_t *\nDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *data;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail). NON-BLOCKING */\n\n\t/* remove from tail, preserving FIFO order */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tdata = *tail;\n\tif (data) {\n\t\tif (*head == *tail) {\n\t\t\t/* removing last item from queue */\n\t\t\t*head = NULL;\n\t\t\t*tail = NULL;\n\t\t} else {\n\t\t\t*tail = (*tail)->prev;\n\t\t\t(*tail)->next = NULL;\n\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t}\n\t\tdata->next = NULL;\n\t\tdata->prev = NULL;\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\t}\n\tif (*head) {\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (data);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLogData_t *\nDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *data;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail). NON-BLOCKING */\n\n\t/* remove from tail, preserving FIFO order */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tdata = *tail;\n\tif (data) {\n\t\tif (*head == *tail) {\n\t\t\t/* removing last item from queue */\n\t\t\t*head = NULL;\n\t\t\t*tail = NULL;\n\t\t} else {\n\t\t\t*tail = (*tail)->prev;\n\t\t\t(*tail)->next = NULL;\n\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t}\n\t\tdata->next = NULL;\n\t\tdata->prev = NULL;\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\t}\n\tif (*head) {\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (data);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLogData_t *\nDequeueMatchingLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_ParityLogData_t *logDataList, *logData;\n\tint     regionID;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail).  Then remove all matching (identical\n\t * regionIDs) logData and return as a linked list.\n\t * \n\t * NON-BLOCKING */\n\n\tlogDataList = DequeueParityLogData(raidPtr, head, tail, RF_TRUE);\n\tif (logDataList) {\n\t\tregionID = logDataList->regionID;\n\t\tlogData = logDataList;\n\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\twhile (logData->next) {\n\t\t\tlogData = logData->next;\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, head, tail, RF_TRUE);\n\t\t}\n\t}\n\treturn (logDataList);\n}"
  },
  {
    "function_name": "rf_SearchAndDequeueParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "338-400",
    "snippet": "RF_ParityLogData_t *\nrf_SearchAndDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *w;\n\n\t/* Remove and return an in-core parity log from a specified region\n\t * (regionID). If a matching log is not found, return NULL.\n\t * \n\t * NON-BLOCKING. */\n\n\t/* walk backward through a list, looking for an entry with a matching\n\t * region ID */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tw = (*tail);\n\twhile (w) {\n\t\tif (w->regionID == regionID) {\n\t\t\t/* remove an element from the list */\n\t\t\tif (w == *tail) {\n\t\t\t\tif (*head == *tail) {\n\t\t\t\t\t/* removing only element in the list */\n\t\t\t\t\t*head = NULL;\n\t\t\t\t\t*tail = NULL;\n\t\t\t\t} else {\n\t\t\t\t\t/* removing last item in the list */\n\t\t\t\t\t*tail = (*tail)->prev;\n\t\t\t\t\t(*tail)->next = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (w == *head) {\n\t\t\t\t\t/* removing first item in the list */\n\t\t\t\t\t*head = (*head)->next;\n\t\t\t\t\t(*head)->prev = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t} else {\n\t\t\t\t\t/* removing an item from the middle of\n\t\t\t\t\t * the list */\n\t\t\t\t\tw->prev->next = w->next;\n\t\t\t\t\tw->next->prev = w->prev;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tw->prev = NULL;\n\t\t\tw->next = NULL;\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", w->regionID, (int) w->diskAddress.raidAddress, (int) w->diskAddress.numSector);\n\t\t\treturn (w);\n\t\t} else\n\t\t\tw = w->prev;\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (NULL);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 398
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\"",
            "w->regionID",
            "(int) w->diskAddress.raidAddress",
            "(int) w->diskAddress.numSector"
          ],
          "line": 392
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 386
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 385
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 379
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 378
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 371
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 356
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nRF_ParityLogData_t *\nrf_SearchAndDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *w;\n\n\t/* Remove and return an in-core parity log from a specified region\n\t * (regionID). If a matching log is not found, return NULL.\n\t * \n\t * NON-BLOCKING. */\n\n\t/* walk backward through a list, looking for an entry with a matching\n\t * region ID */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tw = (*tail);\n\twhile (w) {\n\t\tif (w->regionID == regionID) {\n\t\t\t/* remove an element from the list */\n\t\t\tif (w == *tail) {\n\t\t\t\tif (*head == *tail) {\n\t\t\t\t\t/* removing only element in the list */\n\t\t\t\t\t*head = NULL;\n\t\t\t\t\t*tail = NULL;\n\t\t\t\t} else {\n\t\t\t\t\t/* removing last item in the list */\n\t\t\t\t\t*tail = (*tail)->prev;\n\t\t\t\t\t(*tail)->next = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (w == *head) {\n\t\t\t\t\t/* removing first item in the list */\n\t\t\t\t\t*head = (*head)->next;\n\t\t\t\t\t(*head)->prev = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t} else {\n\t\t\t\t\t/* removing an item from the middle of\n\t\t\t\t\t * the list */\n\t\t\t\t\tw->prev->next = w->next;\n\t\t\t\t\tw->next->prev = w->prev;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tw->prev = NULL;\n\t\t\tw->next = NULL;\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", w->regionID, (int) w->diskAddress.raidAddress, (int) w->diskAddress.numSector);\n\t\t\treturn (w);\n\t\t} else\n\t\t\tw = w->prev;\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (NULL);\n}"
  },
  {
    "function_name": "rf_CreateParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "262-335",
    "snippet": "RF_ParityLogData_t *\nrf_CreateParityLogData(\n    RF_ParityRecordType_t operation,\n    RF_PhysDiskAddr_t * pda,\n    caddr_t bufPtr,\n    RF_Raid_t * raidPtr,\n    int (*wakeFunc) (RF_DagNode_t * node, int status),\n    void *wakeArg,\n    RF_AccTraceEntry_t * tracerec,\n    RF_Etimer_t startTime)\n{\n\tRF_ParityLogData_t *data, *resultHead = NULL, *resultTail = NULL;\n\tRF_CommonLogData_t *common;\n\tRF_PhysDiskAddr_t *diskAddress;\n\tint     boundary, offset = 0;\n\n\t/* Return an initialized struct of info to be logged. Build one item\n\t * per physical disk address, one item per region.\n\t * \n\t * NON-BLOCKING */\n\n\tdiskAddress = pda;\n\tcommon = AllocParityLogCommonData(raidPtr);\n\tRF_ASSERT(common);\n\n\tcommon->operation = operation;\n\tcommon->bufPtr = bufPtr;\n\tcommon->raidPtr = raidPtr;\n\tcommon->wakeFunc = wakeFunc;\n\tcommon->wakeArg = wakeArg;\n\tcommon->tracerec = tracerec;\n\tcommon->startTime = startTime;\n\tcommon->cnt = 0;\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[entering CreateParityLogData]\\n\");\n\twhile (diskAddress) {\n\t\tcommon->cnt++;\n\t\tdata = AllocParityLogData(raidPtr);\n\t\tRF_ASSERT(data);\n\t\tdata->common = common;\n\t\tdata->next = NULL;\n\t\tdata->prev = NULL;\n\t\tdata->regionID = rf_MapRegionIDParityLogging(raidPtr, diskAddress->startSector);\n\t\tif (data->regionID == rf_MapRegionIDParityLogging(raidPtr, diskAddress->startSector + diskAddress->numSector - 1)) {\n\t\t\t/* disk address does not cross a region boundary */\n\t\t\tdata->diskAddress = *diskAddress;\n\t\t\tdata->bufOffset = offset;\n\t\t\toffset = offset + diskAddress->numSector;\n\t\t\tEnqueueParityLogData(data, &resultHead, &resultTail);\n\t\t\t/* adjust disk address */\n\t\t\tdiskAddress = diskAddress->next;\n\t\t} else {\n\t\t\t/* disk address crosses a region boundary */\n\t\t\t/* find address where region is crossed */\n\t\t\tboundary = 0;\n\t\t\twhile (data->regionID == rf_MapRegionIDParityLogging(raidPtr, diskAddress->startSector + boundary))\n\t\t\t\tboundary++;\n\n\t\t\t/* enter data before the boundary */\n\t\t\tdata->diskAddress = *diskAddress;\n\t\t\tdata->diskAddress.numSector = boundary;\n\t\t\tdata->bufOffset = offset;\n\t\t\toffset += boundary;\n\t\t\tEnqueueParityLogData(data, &resultHead, &resultTail);\n\t\t\t/* adjust disk address */\n\t\t\tdiskAddress->startSector += boundary;\n\t\t\tdiskAddress->numSector -= boundary;\n\t\t}\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[leaving CreateParityLogData]\\n\");\n\treturn (resultHead);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[leaving CreateParityLogData]\\n\""
          ],
          "line": 333
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "EnqueueParityLogData",
          "args": [
            "data",
            "&resultHead",
            "&resultTail"
          ],
          "line": 326
        },
        "resolved": true,
        "details": {
          "function_name": "EnqueueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "150-184",
          "snippet": "static void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_MapRegionIDParityLogging",
          "args": [
            "raidPtr",
            "diskAddress->startSector + boundary"
          ],
          "line": 318
        },
        "resolved": true,
        "details": {
          "function_name": "rf_MapRegionIDParityLogging",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogging.c",
          "lines": "780-798",
          "snippet": "RF_RegionId_t \nrf_MapRegionIDParityLogging(\n    RF_Raid_t * raidPtr,\n    RF_SectorNum_t address)\n{\n\tRF_RegionId_t regionID;\n\n/*  regionID = address / (raidPtr->regionParityRange * raidPtr->Layout.numDataCol); */\n\tregionID = address / raidPtr->regionParityRange;\n\tif (regionID == rf_numParityRegions) {\n\t\t/* last region may be larger than other regions */\n\t\tregionID--;\n\t}\n\tRF_ASSERT(address >= raidPtr->regionInfo[regionID].parityStartAddr);\n\tRF_ASSERT(address < raidPtr->regionInfo[regionID].parityStartAddr + \n\t\t  raidPtr->regionInfo[regionID].numSectorsParity);\n\tRF_ASSERT(regionID < rf_numParityRegions);\n\treturn (regionID);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_parityloggingdags.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_dagdegwr.h\"",
            "#include \"rf_dagdegrd.h\"",
            "#include \"rf_dagffwr.h\"",
            "#include \"rf_dagffrd.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_parityloggingdags.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_dagdegwr.h\"\n#include \"rf_dagdegrd.h\"\n#include \"rf_dagffwr.h\"\n#include \"rf_dagffrd.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nRF_RegionId_t \nrf_MapRegionIDParityLogging(\n    RF_Raid_t * raidPtr,\n    RF_SectorNum_t address)\n{\n\tRF_RegionId_t regionID;\n\n/*  regionID = address / (raidPtr->regionParityRange * raidPtr->Layout.numDataCol); */\n\tregionID = address / raidPtr->regionParityRange;\n\tif (regionID == rf_numParityRegions) {\n\t\t/* last region may be larger than other regions */\n\t\tregionID--;\n\t}\n\tRF_ASSERT(address >= raidPtr->regionInfo[regionID].parityStartAddr);\n\tRF_ASSERT(address < raidPtr->regionInfo[regionID].parityStartAddr + \n\t\t  raidPtr->regionInfo[regionID].numSectorsParity);\n\tRF_ASSERT(regionID < rf_numParityRegions);\n\treturn (regionID);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "data"
          ],
          "line": 301
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "AllocParityLogData",
          "args": [
            "raidPtr"
          ],
          "line": 300
        },
        "resolved": true,
        "details": {
          "function_name": "AllocParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "104-125",
          "snippet": "static RF_ParityLogData_t *\nAllocParityLogData(RF_Raid_t * raidPtr)\n{\n\tRF_ParityLogData_t *data = NULL;\n\n\t/* Return a struct for holding parity log information from the free\n\t * list (rf_parityLogDiskQueue.freeList).  If the free list is empty,\n\t * call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeDataList) {\n\t\tdata = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = raidPtr->parityLogDiskQueue.freeDataList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(data, sizeof(RF_ParityLogData_t), (RF_ParityLogData_t *));\n\t}\n\tdata->next = NULL;\n\tdata->prev = NULL;\n\treturn (data);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLogData_t *\nAllocParityLogData(RF_Raid_t * raidPtr)\n{\n\tRF_ParityLogData_t *data = NULL;\n\n\t/* Return a struct for holding parity log information from the free\n\t * list (rf_parityLogDiskQueue.freeList).  If the free list is empty,\n\t * call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeDataList) {\n\t\tdata = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = raidPtr->parityLogDiskQueue.freeDataList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(data, sizeof(RF_ParityLogData_t), (RF_ParityLogData_t *));\n\t}\n\tdata->next = NULL;\n\tdata->prev = NULL;\n\treturn (data);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "common"
          ],
          "line": 285
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "AllocParityLogCommonData",
          "args": [
            "raidPtr"
          ],
          "line": 284
        },
        "resolved": true,
        "details": {
          "function_name": "AllocParityLogCommonData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "58-86",
          "snippet": "static RF_CommonLogData_t *\nAllocParityLogCommonData(RF_Raid_t * raidPtr)\n{\n\tRF_CommonLogData_t *common = NULL;\n\tint     rc;\n\n\t/* Return a struct for holding common parity log information from the\n\t * free list (rf_parityLogDiskQueue.freeCommonList).  If the free list\n\t * is empty, call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeCommonList) {\n\t\tcommon = raidPtr->parityLogDiskQueue.freeCommonList;\n\t\traidPtr->parityLogDiskQueue.freeCommonList = raidPtr->parityLogDiskQueue.freeCommonList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(common, sizeof(RF_CommonLogData_t), (RF_CommonLogData_t *));\n\t\trc = rf_mutex_init(&common->mutex);\n\t\tif (rc) {\n\t\t\tRF_ERRORMSG3(\"Unable to init mutex file %s line %d rc=%d\\n\", __FILE__,\n\t\t\t    __LINE__, rc);\n\t\t\tRF_Free(common, sizeof(RF_CommonLogData_t));\n\t\t\tcommon = NULL;\n\t\t}\n\t}\n\tcommon->next = NULL;\n\treturn (common);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_CommonLogData_t *\nAllocParityLogCommonData(RF_Raid_t * raidPtr)\n{\n\tRF_CommonLogData_t *common = NULL;\n\tint     rc;\n\n\t/* Return a struct for holding common parity log information from the\n\t * free list (rf_parityLogDiskQueue.freeCommonList).  If the free list\n\t * is empty, call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeCommonList) {\n\t\tcommon = raidPtr->parityLogDiskQueue.freeCommonList;\n\t\traidPtr->parityLogDiskQueue.freeCommonList = raidPtr->parityLogDiskQueue.freeCommonList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(common, sizeof(RF_CommonLogData_t), (RF_CommonLogData_t *));\n\t\trc = rf_mutex_init(&common->mutex);\n\t\tif (rc) {\n\t\t\tRF_ERRORMSG3(\"Unable to init mutex file %s line %d rc=%d\\n\", __FILE__,\n\t\t\t    __LINE__, rc);\n\t\t\tRF_Free(common, sizeof(RF_CommonLogData_t));\n\t\t\tcommon = NULL;\n\t\t}\n\t}\n\tcommon->next = NULL;\n\treturn (common);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nRF_ParityLogData_t *\nrf_CreateParityLogData(\n    RF_ParityRecordType_t operation,\n    RF_PhysDiskAddr_t * pda,\n    caddr_t bufPtr,\n    RF_Raid_t * raidPtr,\n    int (*wakeFunc) (RF_DagNode_t * node, int status),\n    void *wakeArg,\n    RF_AccTraceEntry_t * tracerec,\n    RF_Etimer_t startTime)\n{\n\tRF_ParityLogData_t *data, *resultHead = NULL, *resultTail = NULL;\n\tRF_CommonLogData_t *common;\n\tRF_PhysDiskAddr_t *diskAddress;\n\tint     boundary, offset = 0;\n\n\t/* Return an initialized struct of info to be logged. Build one item\n\t * per physical disk address, one item per region.\n\t * \n\t * NON-BLOCKING */\n\n\tdiskAddress = pda;\n\tcommon = AllocParityLogCommonData(raidPtr);\n\tRF_ASSERT(common);\n\n\tcommon->operation = operation;\n\tcommon->bufPtr = bufPtr;\n\tcommon->raidPtr = raidPtr;\n\tcommon->wakeFunc = wakeFunc;\n\tcommon->wakeArg = wakeArg;\n\tcommon->tracerec = tracerec;\n\tcommon->startTime = startTime;\n\tcommon->cnt = 0;\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[entering CreateParityLogData]\\n\");\n\twhile (diskAddress) {\n\t\tcommon->cnt++;\n\t\tdata = AllocParityLogData(raidPtr);\n\t\tRF_ASSERT(data);\n\t\tdata->common = common;\n\t\tdata->next = NULL;\n\t\tdata->prev = NULL;\n\t\tdata->regionID = rf_MapRegionIDParityLogging(raidPtr, diskAddress->startSector);\n\t\tif (data->regionID == rf_MapRegionIDParityLogging(raidPtr, diskAddress->startSector + diskAddress->numSector - 1)) {\n\t\t\t/* disk address does not cross a region boundary */\n\t\t\tdata->diskAddress = *diskAddress;\n\t\t\tdata->bufOffset = offset;\n\t\t\toffset = offset + diskAddress->numSector;\n\t\t\tEnqueueParityLogData(data, &resultHead, &resultTail);\n\t\t\t/* adjust disk address */\n\t\t\tdiskAddress = diskAddress->next;\n\t\t} else {\n\t\t\t/* disk address crosses a region boundary */\n\t\t\t/* find address where region is crossed */\n\t\t\tboundary = 0;\n\t\t\twhile (data->regionID == rf_MapRegionIDParityLogging(raidPtr, diskAddress->startSector + boundary))\n\t\t\t\tboundary++;\n\n\t\t\t/* enter data before the boundary */\n\t\t\tdata->diskAddress = *diskAddress;\n\t\t\tdata->diskAddress.numSector = boundary;\n\t\t\tdata->bufOffset = offset;\n\t\t\toffset += boundary;\n\t\t\tEnqueueParityLogData(data, &resultHead, &resultTail);\n\t\t\t/* adjust disk address */\n\t\t\tdiskAddress->startSector += boundary;\n\t\t\tdiskAddress->numSector -= boundary;\n\t\t}\n\t}\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[leaving CreateParityLogData]\\n\");\n\treturn (resultHead);\n}"
  },
  {
    "function_name": "RequeueParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "228-260",
    "snippet": "static void \nRequeueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the tail of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_ASSERT(data);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*tail) {\n\t\t/* append to tail of list */\n\t\tdata->prev = *tail;\n\t\tdata->next = NULL;\n\t\t(*tail)->next = data;\n\t\t*tail = data;\n\t} else {\n\t\t/* inserting into an empty list */\n\t\t*head = data;\n\t\t*tail = data;\n\t\t(*head)->prev = NULL;\n\t\t(*tail)->next = NULL;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 258
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 257
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 243
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\"",
            "data->regionID",
            "(int) data->diskAddress.raidAddress",
            "(int) data->diskAddress.numSector"
          ],
          "line": 242
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "data"
          ],
          "line": 240
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nRequeueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the tail of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_ASSERT(data);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[requeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*tail) {\n\t\t/* append to tail of list */\n\t\tdata->prev = *tail;\n\t\tdata->next = NULL;\n\t\t(*tail)->next = data;\n\t\t*tail = data;\n\t} else {\n\t\t/* inserting into an empty list */\n\t\t*head = data;\n\t\t*tail = data;\n\t\t(*head)->prev = NULL;\n\t\t(*tail)->next = NULL;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
  },
  {
    "function_name": "DequeueParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "186-225",
    "snippet": "static RF_ParityLogData_t *\nDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *data;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail). NON-BLOCKING */\n\n\t/* remove from tail, preserving FIFO order */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tdata = *tail;\n\tif (data) {\n\t\tif (*head == *tail) {\n\t\t\t/* removing last item from queue */\n\t\t\t*head = NULL;\n\t\t\t*tail = NULL;\n\t\t} else {\n\t\t\t*tail = (*tail)->prev;\n\t\t\t(*tail)->next = NULL;\n\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t}\n\t\tdata->next = NULL;\n\t\tdata->prev = NULL;\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\t}\n\tif (*head) {\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (data);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 223
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 220
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 219
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\"",
            "data->regionID",
            "(int) data->diskAddress.raidAddress",
            "(int) data->diskAddress.numSector"
          ],
          "line": 216
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 211
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 210
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLogData_t *\nDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *data;\n\n\t/* Remove and return an in-core parity log from the tail of a disk\n\t * queue (*head, *tail). NON-BLOCKING */\n\n\t/* remove from tail, preserving FIFO order */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tdata = *tail;\n\tif (data) {\n\t\tif (*head == *tail) {\n\t\t\t/* removing last item from queue */\n\t\t\t*head = NULL;\n\t\t\t*tail = NULL;\n\t\t} else {\n\t\t\t*tail = (*tail)->prev;\n\t\t\t(*tail)->next = NULL;\n\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t}\n\t\tdata->next = NULL;\n\t\tdata->prev = NULL;\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\t}\n\tif (*head) {\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (data);\n}"
  },
  {
    "function_name": "EnqueueParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "150-184",
    "snippet": "static void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 183
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 181
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "*tail == NULL"
          ],
          "line": 177
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "*head == NULL"
          ],
          "line": 176
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*tail)->next == NULL"
          ],
          "line": 170
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "(*head)->prev == NULL"
          ],
          "line": 169
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 166
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "data->next == NULL"
          ],
          "line": 165
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "data->prev == NULL"
          ],
          "line": 164
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\"",
            "data->regionID",
            "(int) data->diskAddress.raidAddress",
            "(int) data->diskAddress.numSector"
          ],
          "line": 163
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nEnqueueParityLogData(\n    RF_ParityLogData_t * data,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert an in-core parity log (*data) into the head of a disk queue\n\t * (*head, *tail). NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[enqueueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", data->regionID, (int) data->diskAddress.raidAddress, (int) data->diskAddress.numSector);\n\tRF_ASSERT(data->prev == NULL);\n\tRF_ASSERT(data->next == NULL);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (*head) {\n\t\t/* insert into head of queue */\n\t\tRF_ASSERT((*head)->prev == NULL);\n\t\tRF_ASSERT((*tail)->next == NULL);\n\t\tdata->next = *head;\n\t\t(*head)->prev = data;\n\t\t*head = data;\n\t} else {\n\t\t/* insert into empty list */\n\t\tRF_ASSERT(*head == NULL);\n\t\tRF_ASSERT(*tail == NULL);\n\t\t*head = data;\n\t\t*tail = data;\n\t}\n\tRF_ASSERT((*head)->prev == NULL);\n\tRF_ASSERT((*tail)->next == NULL);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
  },
  {
    "function_name": "FreeParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "128-147",
    "snippet": "static void \nFreeParityLogData(RF_ParityLogData_t * data)\n{\n\tRF_ParityLogData_t *nextItem;\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a linked list of structs for holding parity log information\n\t * (data) into the free list (parityLogDiskQueue.freeList).\n\t * NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\twhile (data) {\n\t\tnextItem = data->next;\n\t\tdata->next = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = data;\n\t\tdata = nextItem;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 146
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 139
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFreeParityLogData(RF_ParityLogData_t * data)\n{\n\tRF_ParityLogData_t *nextItem;\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a linked list of structs for holding parity log information\n\t * (data) into the free list (parityLogDiskQueue.freeList).\n\t * NON-BLOCKING */\n\n\traidPtr = data->common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\twhile (data) {\n\t\tnextItem = data->next;\n\t\tdata->next = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = data;\n\t\tdata = nextItem;\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
  },
  {
    "function_name": "AllocParityLogData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "104-125",
    "snippet": "static RF_ParityLogData_t *\nAllocParityLogData(RF_Raid_t * raidPtr)\n{\n\tRF_ParityLogData_t *data = NULL;\n\n\t/* Return a struct for holding parity log information from the free\n\t * list (rf_parityLogDiskQueue.freeList).  If the free list is empty,\n\t * call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeDataList) {\n\t\tdata = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = raidPtr->parityLogDiskQueue.freeDataList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(data, sizeof(RF_ParityLogData_t), (RF_ParityLogData_t *));\n\t}\n\tdata->next = NULL;\n\tdata->prev = NULL;\n\treturn (data);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_Malloc",
          "args": [
            "data",
            "sizeof(RF_ParityLogData_t)",
            "(RF_ParityLogData_t *)"
          ],
          "line": 120
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 119
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 117
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 113
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_ParityLogData_t *\nAllocParityLogData(RF_Raid_t * raidPtr)\n{\n\tRF_ParityLogData_t *data = NULL;\n\n\t/* Return a struct for holding parity log information from the free\n\t * list (rf_parityLogDiskQueue.freeList).  If the free list is empty,\n\t * call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeDataList) {\n\t\tdata = raidPtr->parityLogDiskQueue.freeDataList;\n\t\traidPtr->parityLogDiskQueue.freeDataList = raidPtr->parityLogDiskQueue.freeDataList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(data, sizeof(RF_ParityLogData_t), (RF_ParityLogData_t *));\n\t}\n\tdata->next = NULL;\n\tdata->prev = NULL;\n\treturn (data);\n}"
  },
  {
    "function_name": "FreeParityLogCommonData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "88-102",
    "snippet": "static void \nFreeParityLogCommonData(RF_CommonLogData_t * common)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a single struct for holding parity log information (data)\n\t * into the free list (rf_parityLogDiskQueue.freeCommonList).\n\t * NON-BLOCKING */\n\n\traidPtr = common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tcommon->next = raidPtr->parityLogDiskQueue.freeCommonList;\n\traidPtr->parityLogDiskQueue.freeCommonList = common;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 98
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFreeParityLogCommonData(RF_CommonLogData_t * common)\n{\n\tRF_Raid_t *raidPtr;\n\n\t/* Insert a single struct for holding parity log information (data)\n\t * into the free list (rf_parityLogDiskQueue.freeCommonList).\n\t * NON-BLOCKING */\n\n\traidPtr = common->raidPtr;\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tcommon->next = raidPtr->parityLogDiskQueue.freeCommonList;\n\traidPtr->parityLogDiskQueue.freeCommonList = common;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
  },
  {
    "function_name": "AllocParityLogCommonData",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
    "lines": "58-86",
    "snippet": "static RF_CommonLogData_t *\nAllocParityLogCommonData(RF_Raid_t * raidPtr)\n{\n\tRF_CommonLogData_t *common = NULL;\n\tint     rc;\n\n\t/* Return a struct for holding common parity log information from the\n\t * free list (rf_parityLogDiskQueue.freeCommonList).  If the free list\n\t * is empty, call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeCommonList) {\n\t\tcommon = raidPtr->parityLogDiskQueue.freeCommonList;\n\t\traidPtr->parityLogDiskQueue.freeCommonList = raidPtr->parityLogDiskQueue.freeCommonList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(common, sizeof(RF_CommonLogData_t), (RF_CommonLogData_t *));\n\t\trc = rf_mutex_init(&common->mutex);\n\t\tif (rc) {\n\t\t\tRF_ERRORMSG3(\"Unable to init mutex file %s line %d rc=%d\\n\", __FILE__,\n\t\t\t    __LINE__, rc);\n\t\t\tRF_Free(common, sizeof(RF_CommonLogData_t));\n\t\t\tcommon = NULL;\n\t\t}\n\t}\n\tcommon->next = NULL;\n\treturn (common);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_Free",
          "args": [
            "common",
            "sizeof(RF_CommonLogData_t)"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ERRORMSG3",
          "args": [
            "\"Unable to init mutex file %s line %d rc=%d\\n\"",
            "__FILE__",
            "__LINE__",
            "rc"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_mutex_init",
          "args": [
            "&common->mutex"
          ],
          "line": 76
        },
        "resolved": true,
        "details": {
          "function_name": "rf_mutex_init",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_threadstuff.c",
          "lines": "173-186",
          "snippet": "int \nrf_mutex_init(m)\ndecl_simple_lock_data(, *m)\n{\n\tsimple_lock_init(m);\n\treturn (0);\n}\n\nint \nrf_mutex_destroy(m)\ndecl_simple_lock_data(, *m)\n{\n\treturn (0);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_general.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nint \nrf_mutex_init(m)\ndecl_simple_lock_data(, *m)\n{\n\tsimple_lock_init(m);\n\treturn (0);\n}\n\nint \nrf_mutex_destroy(m)\ndecl_simple_lock_data(, *m)\n{\n\treturn (0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_Malloc",
          "args": [
            "common",
            "sizeof(RF_CommonLogData_t)",
            "(RF_CommonLogData_t *)"
          ],
          "line": 75
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 74
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 72
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 68
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic RF_CommonLogData_t *\nAllocParityLogCommonData(RF_Raid_t * raidPtr)\n{\n\tRF_CommonLogData_t *common = NULL;\n\tint     rc;\n\n\t/* Return a struct for holding common parity log information from the\n\t * free list (rf_parityLogDiskQueue.freeCommonList).  If the free list\n\t * is empty, call RF_Malloc to create a new structure. NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tif (raidPtr->parityLogDiskQueue.freeCommonList) {\n\t\tcommon = raidPtr->parityLogDiskQueue.freeCommonList;\n\t\traidPtr->parityLogDiskQueue.freeCommonList = raidPtr->parityLogDiskQueue.freeCommonList->next;\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t} else {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_Malloc(common, sizeof(RF_CommonLogData_t), (RF_CommonLogData_t *));\n\t\trc = rf_mutex_init(&common->mutex);\n\t\tif (rc) {\n\t\t\tRF_ERRORMSG3(\"Unable to init mutex file %s line %d rc=%d\\n\", __FILE__,\n\t\t\t    __LINE__, rc);\n\t\t\tRF_Free(common, sizeof(RF_CommonLogData_t));\n\t\t\tcommon = NULL;\n\t\t}\n\t}\n\tcommon->next = NULL;\n\treturn (common);\n}"
  }
]