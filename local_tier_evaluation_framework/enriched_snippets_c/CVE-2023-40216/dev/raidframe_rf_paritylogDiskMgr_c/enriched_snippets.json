[
  {
    "function_name": "rf_ParityLoggingDiskManager",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "551-650",
    "snippet": "int \nrf_ParityLoggingDiskManager(RF_Raid_t * raidPtr)\n{\n\tRF_ParityLog_t *reintQueue, *flushQueue;\n\tint     workNeeded, done = RF_FALSE;\n\n\t/* Main program for parity logging disk thread.  This routine waits\n\t * for work to appear in either the flush or reintegration queues and\n\t * is responsible for flushing core logs to the log disk as well as\n\t * reintegrating parity regions.\n\t * \n\t * BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t/*\n         * Inform our creator that we're running. Don't bother doing the\n         * mutex lock/unlock dance- we locked above, and we'll unlock\n         * below with nothing to do, yet.\n         */\n\traidPtr->parityLogDiskQueue.threadState |= RF_PLOG_RUNNING;\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n\n\t/* empty the work queues */\n\tflushQueue = raidPtr->parityLogDiskQueue.flushQueue;\n\traidPtr->parityLogDiskQueue.flushQueue = NULL;\n\treintQueue = raidPtr->parityLogDiskQueue.reintQueue;\n\traidPtr->parityLogDiskQueue.reintQueue = NULL;\n\tworkNeeded = (flushQueue || reintQueue);\n\n\twhile (!done) {\n\t\twhile (workNeeded) {\n\t\t\t/* First, flush all logs in the flush queue, freeing\n\t\t\t * buffers Second, reintegrate all regions which are\n\t\t\t * reported as full. Third, append queued log data\n\t\t\t * until blocked.\n\t\t\t * \n\t\t\t * Note: Incoming appends (ParityLogAppend) can block on\n\t\t\t * either 1. empty buffer pool 2. region under\n\t\t\t * reintegration To preserve a global FIFO ordering of\n\t\t\t * appends, buffers are not released to the world\n\t\t\t * until those appends blocked on buffers are removed\n\t\t\t * from the append queue.  Similarly, regions which\n\t\t\t * are reintegrated are not opened for general use\n\t\t\t * until the append queue has been emptied. */\n\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t\t\t/* empty flushQueue, using free'd log buffers to\n\t\t\t * process bufTail */\n\t\t\tif (flushQueue)\n\t\t\t\tFlushLogsToDisk(raidPtr, flushQueue);\n\n\t\t\t/* empty reintQueue, flushing from reintTail as we go */\n\t\t\tif (reintQueue)\n\t\t\t\tReintegrateLogs(raidPtr, reintQueue);\n\n\t\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\tflushQueue = raidPtr->parityLogDiskQueue.flushQueue;\n\t\t\traidPtr->parityLogDiskQueue.flushQueue = NULL;\n\t\t\treintQueue = raidPtr->parityLogDiskQueue.reintQueue;\n\t\t\traidPtr->parityLogDiskQueue.reintQueue = NULL;\n\t\t\tworkNeeded = (flushQueue || reintQueue);\n\t\t}\n\t\t/* no work is needed at this point */\n\t\tif (raidPtr->parityLogDiskQueue.threadState & RF_PLOG_TERMINATE) {\n\t\t\t/* shutdown parity logging 1. disable parity logging\n\t\t\t * in all regions 2. reintegrate all regions */\n\t\t\tdone = RF_TRUE;\t/* thread disabled, no work needed */\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\trf_ShutdownLogging(raidPtr);\n\t\t}\n\t\tif (!done) {\n\t\t\t/* thread enabled, no work needed, so sleep */\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[parity logging disk manager sleeping]\\n\");\n\t\t\tRF_WAIT_COND(raidPtr->parityLogDiskQueue.cond, raidPtr->parityLogDiskQueue.mutex);\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[parity logging disk manager just woke up]\\n\");\n\t\t\tflushQueue = raidPtr->parityLogDiskQueue.flushQueue;\n\t\t\traidPtr->parityLogDiskQueue.flushQueue = NULL;\n\t\t\treintQueue = raidPtr->parityLogDiskQueue.reintQueue;\n\t\t\traidPtr->parityLogDiskQueue.reintQueue = NULL;\n\t\t\tworkNeeded = (flushQueue || reintQueue);\n\t\t}\n\t}\n\t/*\n         * Announce that we're done.\n         */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\traidPtr->parityLogDiskQueue.threadState |= RF_PLOG_SHUTDOWN;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n\n\t/*\n         * In the Net- & OpenBSD kernel, the thread must exit; returning would\n         * cause the proc trampoline to attempt to return to userspace.\n         */\n\tkthread_exit(0);\t/* does not return */\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kthread_exit",
          "args": [
            "0"
          ],
          "line": 649
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_SIGNAL_COND",
          "args": [
            "raidPtr->parityLogDiskQueue.cond"
          ],
          "line": 643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 642
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 640
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[parity logging disk manager just woke up]\\n\""
          ],
          "line": 629
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_WAIT_COND",
          "args": [
            "raidPtr->parityLogDiskQueue.cond",
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 627
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_ShutdownLogging",
          "args": [
            "raidPtr"
          ],
          "line": 621
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ShutdownLogging",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "516-549",
          "snippet": "int \nrf_ShutdownLogging(RF_Raid_t * raidPtr)\n{\n\t/* shutdown parity logging 1) disable parity logging in all regions 2)\n\t * reintegrate all regions */\n\n\tRF_SectorCount_t diskCount;\n\tRF_RegionId_t regionID;\n\tRF_ParityLog_t *log;\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[shutting down parity logging]\\n\");\n\t/* Since parity log maps are volatile, we must reintegrate all\n\t * regions. */\n\tif (rf_forceParityLogReint) {\n\t\tfor (regionID = 0; regionID < rf_numParityRegions; regionID++) {\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\traidPtr->regionInfo[regionID].loggingEnabled = RF_FALSE;\n\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\traidPtr->regionInfo[regionID].coreLog = NULL;\n\t\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tif (diskCount > 0 || log != NULL)\n\t\t\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\t\tif (log != NULL)\n\t\t\t\trf_ReleaseParityLogs(raidPtr, log);\n\t\t}\n\t}\n\tif (rf_parityLogDebug) {\n\t\tprintf(\"[parity logging disabled]\\n\");\n\t\tprintf(\"[should be done!]\\n\");\n\t}\n\treturn (0);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nint \nrf_ShutdownLogging(RF_Raid_t * raidPtr)\n{\n\t/* shutdown parity logging 1) disable parity logging in all regions 2)\n\t * reintegrate all regions */\n\n\tRF_SectorCount_t diskCount;\n\tRF_RegionId_t regionID;\n\tRF_ParityLog_t *log;\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[shutting down parity logging]\\n\");\n\t/* Since parity log maps are volatile, we must reintegrate all\n\t * regions. */\n\tif (rf_forceParityLogReint) {\n\t\tfor (regionID = 0; regionID < rf_numParityRegions; regionID++) {\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\traidPtr->regionInfo[regionID].loggingEnabled = RF_FALSE;\n\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\traidPtr->regionInfo[regionID].coreLog = NULL;\n\t\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tif (diskCount > 0 || log != NULL)\n\t\t\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\t\tif (log != NULL)\n\t\t\t\trf_ReleaseParityLogs(raidPtr, log);\n\t\t}\n\t}\n\tif (rf_parityLogDebug) {\n\t\tprintf(\"[parity logging disabled]\\n\");\n\t\tprintf(\"[should be done!]\\n\");\n\t}\n\treturn (0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 620
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 608
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ReintegrateLogs",
          "args": [
            "raidPtr",
            "reintQueue"
          ],
          "line": 606
        },
        "resolved": true,
        "details": {
          "function_name": "ReintegrateLogs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "458-514",
          "snippet": "static void \nReintegrateLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\tRF_ParityLog_t *log, *freeLogList = NULL;\n\tRF_ParityLogData_t *logData, *logDataList;\n\tRF_RegionId_t regionID;\n\n\tRF_ASSERT(logList);\n\twhile (logList) {\n\t\tlog = logList;\n\t\tlogList = logList->next;\n\t\tlog->next = NULL;\n\t\tregionID = log->regionID;\n\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\tlog->numRecords = 0;\n\n\t\t/* remove all items which are blocked on reintegration of this\n\t\t * region */\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tlogData = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\tlogDataList = logData;\n\t\twhile (logData) {\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\t\tlogData = logData->next;\n\t\t}\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t\t/* process blocked log data and clear reintInProgress flag for\n\t\t * this region */\n\t\tif (logDataList)\n\t\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_TRUE);\n\t\telse {\n\t\t\t/* Enable flushing for this region.  Holding both\n\t\t\t * locks provides a synchronization barrier with\n\t\t\t * DumpParityLogToDisk */\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t}\n\t\t/* if log wasn't used, attach it to the list of logs to be\n\t\t * returned */\n\t\tif (log) {\n\t\t\tlog->next = freeLogList;\n\t\t\tfreeLogList = log;\n\t\t}\n\t}\n\tif (freeLogList)\n\t\trf_ReleaseParityLogs(raidPtr, freeLogList);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintegrateLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\tRF_ParityLog_t *log, *freeLogList = NULL;\n\tRF_ParityLogData_t *logData, *logDataList;\n\tRF_RegionId_t regionID;\n\n\tRF_ASSERT(logList);\n\twhile (logList) {\n\t\tlog = logList;\n\t\tlogList = logList->next;\n\t\tlog->next = NULL;\n\t\tregionID = log->regionID;\n\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\tlog->numRecords = 0;\n\n\t\t/* remove all items which are blocked on reintegration of this\n\t\t * region */\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tlogData = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\tlogDataList = logData;\n\t\twhile (logData) {\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\t\tlogData = logData->next;\n\t\t}\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t\t/* process blocked log data and clear reintInProgress flag for\n\t\t * this region */\n\t\tif (logDataList)\n\t\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_TRUE);\n\t\telse {\n\t\t\t/* Enable flushing for this region.  Holding both\n\t\t\t * locks provides a synchronization barrier with\n\t\t\t * DumpParityLogToDisk */\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t}\n\t\t/* if log wasn't used, attach it to the list of logs to be\n\t\t * returned */\n\t\tif (log) {\n\t\t\tlog->next = freeLogList;\n\t\t\tfreeLogList = log;\n\t\t}\n\t}\n\tif (freeLogList)\n\t\trf_ReleaseParityLogs(raidPtr, freeLogList);\n}"
        }
      },
      {
        "call_info": {
          "callee": "FlushLogsToDisk",
          "args": [
            "raidPtr",
            "flushQueue"
          ],
          "line": 602
        },
        "resolved": true,
        "details": {
          "function_name": "FlushLogsToDisk",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "295-347",
          "snippet": "static void \nFlushLogsToDisk(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\t/* Flush a linked list of core logs to the log disk. Logs contain the\n\t * disk location where they should be written.  Logs were written in\n\t * FIFO order and that order must be preserved.\n\t * \n\t * Recommended optimizations: 1) allow multiple flushes to occur\n\t * simultaneously 2) coalesce contiguous flush operations\n\t * \n\t * BLOCKING */\n\n\tRF_ParityLog_t *log;\n\tRF_RegionId_t regionID;\n\tRF_MCPair_t *fwr_mcpair;\n\tRF_DagHeader_t *fwr_dag_h;\n\tRF_AllocListElem_t *fwr_alloclist;\n\tRF_PhysDiskAddr_t *fwr_pda;\n\n\tfwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(fwr_mcpair->mutex);\n\n\tRF_ASSERT(logList);\n\tlog = logList;\n\twhile (log) {\n\t\tregionID = log->regionID;\n\n\t\t/* create and launch a DAG to write the core log */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating write of core log for region %d]\\n\", regionID);\n\t\tfwr_mcpair->flag = RF_FALSE;\n\t\tWriteCoreLog(log, fwr_mcpair, raidPtr, &fwr_dag_h, &fwr_alloclist, &fwr_pda);\n\n\t\t/* wait for the DAG to complete */\n\t\twhile (!fwr_mcpair->flag)\n\t\t\tRF_WAIT_COND(fwr_mcpair->cond, fwr_mcpair->mutex);\n\t\tif (fwr_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG1(\"Unable to write core log to disk (region %d)\\n\", regionID);\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* RF_Free(fwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(fwr_pda);\n\t\trf_FreeDAG(fwr_dag_h);\n\t\trf_FreeAllocList(fwr_alloclist);\n\n\t\tlog = log->next;\n\t}\n\tRF_UNLOCK_MUTEX(fwr_mcpair->mutex);\n\trf_FreeMCPair(fwr_mcpair);\n\trf_ReleaseParityLogs(raidPtr, logList);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFlushLogsToDisk(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\t/* Flush a linked list of core logs to the log disk. Logs contain the\n\t * disk location where they should be written.  Logs were written in\n\t * FIFO order and that order must be preserved.\n\t * \n\t * Recommended optimizations: 1) allow multiple flushes to occur\n\t * simultaneously 2) coalesce contiguous flush operations\n\t * \n\t * BLOCKING */\n\n\tRF_ParityLog_t *log;\n\tRF_RegionId_t regionID;\n\tRF_MCPair_t *fwr_mcpair;\n\tRF_DagHeader_t *fwr_dag_h;\n\tRF_AllocListElem_t *fwr_alloclist;\n\tRF_PhysDiskAddr_t *fwr_pda;\n\n\tfwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(fwr_mcpair->mutex);\n\n\tRF_ASSERT(logList);\n\tlog = logList;\n\twhile (log) {\n\t\tregionID = log->regionID;\n\n\t\t/* create and launch a DAG to write the core log */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating write of core log for region %d]\\n\", regionID);\n\t\tfwr_mcpair->flag = RF_FALSE;\n\t\tWriteCoreLog(log, fwr_mcpair, raidPtr, &fwr_dag_h, &fwr_alloclist, &fwr_pda);\n\n\t\t/* wait for the DAG to complete */\n\t\twhile (!fwr_mcpair->flag)\n\t\t\tRF_WAIT_COND(fwr_mcpair->cond, fwr_mcpair->mutex);\n\t\tif (fwr_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG1(\"Unable to write core log to disk (region %d)\\n\", regionID);\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* RF_Free(fwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(fwr_pda);\n\t\trf_FreeDAG(fwr_dag_h);\n\t\trf_FreeAllocList(fwr_alloclist);\n\n\t\tlog = log->next;\n\t}\n\tRF_UNLOCK_MUTEX(fwr_mcpair->mutex);\n\trf_FreeMCPair(fwr_mcpair);\n\trf_ReleaseParityLogs(raidPtr, logList);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 597
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_SIGNAL_COND",
          "args": [
            "raidPtr->parityLogDiskQueue.cond"
          ],
          "line": 572
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 564
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nint \nrf_ParityLoggingDiskManager(RF_Raid_t * raidPtr)\n{\n\tRF_ParityLog_t *reintQueue, *flushQueue;\n\tint     workNeeded, done = RF_FALSE;\n\n\t/* Main program for parity logging disk thread.  This routine waits\n\t * for work to appear in either the flush or reintegration queues and\n\t * is responsible for flushing core logs to the log disk as well as\n\t * reintegrating parity regions.\n\t * \n\t * BLOCKING */\n\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t/*\n         * Inform our creator that we're running. Don't bother doing the\n         * mutex lock/unlock dance- we locked above, and we'll unlock\n         * below with nothing to do, yet.\n         */\n\traidPtr->parityLogDiskQueue.threadState |= RF_PLOG_RUNNING;\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n\n\t/* empty the work queues */\n\tflushQueue = raidPtr->parityLogDiskQueue.flushQueue;\n\traidPtr->parityLogDiskQueue.flushQueue = NULL;\n\treintQueue = raidPtr->parityLogDiskQueue.reintQueue;\n\traidPtr->parityLogDiskQueue.reintQueue = NULL;\n\tworkNeeded = (flushQueue || reintQueue);\n\n\twhile (!done) {\n\t\twhile (workNeeded) {\n\t\t\t/* First, flush all logs in the flush queue, freeing\n\t\t\t * buffers Second, reintegrate all regions which are\n\t\t\t * reported as full. Third, append queued log data\n\t\t\t * until blocked.\n\t\t\t * \n\t\t\t * Note: Incoming appends (ParityLogAppend) can block on\n\t\t\t * either 1. empty buffer pool 2. region under\n\t\t\t * reintegration To preserve a global FIFO ordering of\n\t\t\t * appends, buffers are not released to the world\n\t\t\t * until those appends blocked on buffers are removed\n\t\t\t * from the append queue.  Similarly, regions which\n\t\t\t * are reintegrated are not opened for general use\n\t\t\t * until the append queue has been emptied. */\n\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t\t\t/* empty flushQueue, using free'd log buffers to\n\t\t\t * process bufTail */\n\t\t\tif (flushQueue)\n\t\t\t\tFlushLogsToDisk(raidPtr, flushQueue);\n\n\t\t\t/* empty reintQueue, flushing from reintTail as we go */\n\t\t\tif (reintQueue)\n\t\t\t\tReintegrateLogs(raidPtr, reintQueue);\n\n\t\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\tflushQueue = raidPtr->parityLogDiskQueue.flushQueue;\n\t\t\traidPtr->parityLogDiskQueue.flushQueue = NULL;\n\t\t\treintQueue = raidPtr->parityLogDiskQueue.reintQueue;\n\t\t\traidPtr->parityLogDiskQueue.reintQueue = NULL;\n\t\t\tworkNeeded = (flushQueue || reintQueue);\n\t\t}\n\t\t/* no work is needed at this point */\n\t\tif (raidPtr->parityLogDiskQueue.threadState & RF_PLOG_TERMINATE) {\n\t\t\t/* shutdown parity logging 1. disable parity logging\n\t\t\t * in all regions 2. reintegrate all regions */\n\t\t\tdone = RF_TRUE;\t/* thread disabled, no work needed */\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\trf_ShutdownLogging(raidPtr);\n\t\t}\n\t\tif (!done) {\n\t\t\t/* thread enabled, no work needed, so sleep */\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[parity logging disk manager sleeping]\\n\");\n\t\t\tRF_WAIT_COND(raidPtr->parityLogDiskQueue.cond, raidPtr->parityLogDiskQueue.mutex);\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[parity logging disk manager just woke up]\\n\");\n\t\t\tflushQueue = raidPtr->parityLogDiskQueue.flushQueue;\n\t\t\traidPtr->parityLogDiskQueue.flushQueue = NULL;\n\t\t\treintQueue = raidPtr->parityLogDiskQueue.reintQueue;\n\t\t\traidPtr->parityLogDiskQueue.reintQueue = NULL;\n\t\t\tworkNeeded = (flushQueue || reintQueue);\n\t\t}\n\t}\n\t/*\n         * Announce that we're done.\n         */\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\traidPtr->parityLogDiskQueue.threadState |= RF_PLOG_SHUTDOWN;\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tRF_SIGNAL_COND(raidPtr->parityLogDiskQueue.cond);\n\n\t/*\n         * In the Net- & OpenBSD kernel, the thread must exit; returning would\n         * cause the proc trampoline to attempt to return to userspace.\n         */\n\tkthread_exit(0);\t/* does not return */\n}"
  },
  {
    "function_name": "rf_ShutdownLogging",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "516-549",
    "snippet": "int \nrf_ShutdownLogging(RF_Raid_t * raidPtr)\n{\n\t/* shutdown parity logging 1) disable parity logging in all regions 2)\n\t * reintegrate all regions */\n\n\tRF_SectorCount_t diskCount;\n\tRF_RegionId_t regionID;\n\tRF_ParityLog_t *log;\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[shutting down parity logging]\\n\");\n\t/* Since parity log maps are volatile, we must reintegrate all\n\t * regions. */\n\tif (rf_forceParityLogReint) {\n\t\tfor (regionID = 0; regionID < rf_numParityRegions; regionID++) {\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\traidPtr->regionInfo[regionID].loggingEnabled = RF_FALSE;\n\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\traidPtr->regionInfo[regionID].coreLog = NULL;\n\t\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tif (diskCount > 0 || log != NULL)\n\t\t\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\t\tif (log != NULL)\n\t\t\t\trf_ReleaseParityLogs(raidPtr, log);\n\t\t}\n\t}\n\tif (rf_parityLogDebug) {\n\t\tprintf(\"[parity logging disabled]\\n\");\n\t\tprintf(\"[should be done!]\\n\");\n\t}\n\treturn (0);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[should be done!]\\n\""
          ],
          "line": 546
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_ReleaseParityLogs",
          "args": [
            "raidPtr",
            "log"
          ],
          "line": 541
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ReleaseParityLogs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "467-539",
          "snippet": "void \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ReintegrateRegion",
          "args": [
            "raidPtr",
            "regionID",
            "log"
          ],
          "line": 539
        },
        "resolved": true,
        "details": {
          "function_name": "ReintegrateRegion",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "349-454",
          "snippet": "static void \nReintegrateRegion(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_ParityLog_t * coreLog)\n{\n\tRF_MCPair_t *rrd_mcpair = NULL, *prd_mcpair, *pwr_mcpair;\n\tRF_DagHeader_t *rrd_dag_h, *prd_dag_h, *pwr_dag_h;\n\tRF_AllocListElem_t *rrd_alloclist, *prd_alloclist, *pwr_alloclist;\n\tRF_PhysDiskAddr_t *rrd_pda, *prd_pda, *pwr_pda;\n\tcaddr_t parityBuffer, regionBuffer = NULL;\n\n\t/* Reintegrate a region (regionID). 1. acquire region and parity\n\t * buffers 2. read log from disk 3. read parity from disk 4. apply log\n\t * to parity 5. apply core log to parity 6. write new parity to disk\n\t * \n\t * BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reintegrating region %d]\\n\", regionID);\n\n\t/* initiate read of region parity */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating read of parity for region %d]\\n\", regionID);\n\tparityBuffer = AcquireReintBuffer(&raidPtr->parityBufferPool);\n\tprd_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(prd_mcpair->mutex);\n\tprd_mcpair->flag = RF_FALSE;\n\tReadRegionParity(regionID, prd_mcpair, parityBuffer, raidPtr, &prd_dag_h, &prd_alloclist, &prd_pda);\n\n\t/* if region log nonempty, initiate read */\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating read of disk log for region %d]\\n\", regionID);\n\t\tregionBuffer = AcquireReintBuffer(&raidPtr->regionBufferPool);\n\t\trrd_mcpair = rf_AllocMCPair();\n\t\tRF_LOCK_MUTEX(rrd_mcpair->mutex);\n\t\trrd_mcpair->flag = RF_FALSE;\n\t\tReadRegionLog(regionID, rrd_mcpair, regionBuffer, raidPtr, &rrd_dag_h, &rrd_alloclist, &rrd_pda);\n\t}\n\t/* wait on read of region parity to complete */\n\twhile (!prd_mcpair->flag) {\n\t\tRF_WAIT_COND(prd_mcpair->cond, prd_mcpair->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(prd_mcpair->mutex);\n\tif (prd_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to read parity from disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* apply core log to parity */\n\t/* if (coreLog) ApplyLogsToParity(coreLog, parityBuffer); */\n\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\t/* wait on read of region log to complete */\n\t\twhile (!rrd_mcpair->flag)\n\t\t\tRF_WAIT_COND(rrd_mcpair->cond, rrd_mcpair->mutex);\n\t\tRF_UNLOCK_MUTEX(rrd_mcpair->mutex);\n\t\tif (rrd_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG(\"Unable to read region log from disk\\n\");\n\t\t\t/* add code to fail the log disk */\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* apply region log to parity */\n\t\t/* ApplyRegionToParity(regionID, regionBuffer, parityBuffer); */\n\t\t/* release resources associated with region log */\n\t\t/* RF_Free(rrd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(rrd_pda);\n\t\trf_FreeDAG(rrd_dag_h);\n\t\trf_FreeAllocList(rrd_alloclist);\n\t\trf_FreeMCPair(rrd_mcpair);\n\t\tReleaseReintBuffer(&raidPtr->regionBufferPool, regionBuffer);\n\t}\n\t/* write reintegrated parity to disk */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating write of parity for region %d]\\n\", regionID);\n\tpwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(pwr_mcpair->mutex);\n\tpwr_mcpair->flag = RF_FALSE;\n\tWriteRegionParity(regionID, pwr_mcpair, parityBuffer, raidPtr, &pwr_dag_h, &pwr_alloclist, &pwr_pda);\n\twhile (!pwr_mcpair->flag)\n\t\tRF_WAIT_COND(pwr_mcpair->cond, pwr_mcpair->mutex);\n\tRF_UNLOCK_MUTEX(pwr_mcpair->mutex);\n\tif (pwr_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to write parity to disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* release resources associated with read of old parity */\n\t/* RF_Free(prd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(prd_pda);\n\trf_FreeDAG(prd_dag_h);\n\trf_FreeAllocList(prd_alloclist);\n\trf_FreeMCPair(prd_mcpair);\n\n\t/* release resources associated with write of new parity */\n\tReleaseReintBuffer(&raidPtr->parityBufferPool, parityBuffer);\n\t/* RF_Free(pwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(pwr_pda);\n\trf_FreeDAG(pwr_dag_h);\n\trf_FreeAllocList(pwr_alloclist);\n\trf_FreeMCPair(pwr_mcpair);\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished reintegrating region %d]\\n\", regionID);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintegrateRegion(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_ParityLog_t * coreLog)\n{\n\tRF_MCPair_t *rrd_mcpair = NULL, *prd_mcpair, *pwr_mcpair;\n\tRF_DagHeader_t *rrd_dag_h, *prd_dag_h, *pwr_dag_h;\n\tRF_AllocListElem_t *rrd_alloclist, *prd_alloclist, *pwr_alloclist;\n\tRF_PhysDiskAddr_t *rrd_pda, *prd_pda, *pwr_pda;\n\tcaddr_t parityBuffer, regionBuffer = NULL;\n\n\t/* Reintegrate a region (regionID). 1. acquire region and parity\n\t * buffers 2. read log from disk 3. read parity from disk 4. apply log\n\t * to parity 5. apply core log to parity 6. write new parity to disk\n\t * \n\t * BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reintegrating region %d]\\n\", regionID);\n\n\t/* initiate read of region parity */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating read of parity for region %d]\\n\", regionID);\n\tparityBuffer = AcquireReintBuffer(&raidPtr->parityBufferPool);\n\tprd_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(prd_mcpair->mutex);\n\tprd_mcpair->flag = RF_FALSE;\n\tReadRegionParity(regionID, prd_mcpair, parityBuffer, raidPtr, &prd_dag_h, &prd_alloclist, &prd_pda);\n\n\t/* if region log nonempty, initiate read */\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating read of disk log for region %d]\\n\", regionID);\n\t\tregionBuffer = AcquireReintBuffer(&raidPtr->regionBufferPool);\n\t\trrd_mcpair = rf_AllocMCPair();\n\t\tRF_LOCK_MUTEX(rrd_mcpair->mutex);\n\t\trrd_mcpair->flag = RF_FALSE;\n\t\tReadRegionLog(regionID, rrd_mcpair, regionBuffer, raidPtr, &rrd_dag_h, &rrd_alloclist, &rrd_pda);\n\t}\n\t/* wait on read of region parity to complete */\n\twhile (!prd_mcpair->flag) {\n\t\tRF_WAIT_COND(prd_mcpair->cond, prd_mcpair->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(prd_mcpair->mutex);\n\tif (prd_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to read parity from disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* apply core log to parity */\n\t/* if (coreLog) ApplyLogsToParity(coreLog, parityBuffer); */\n\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\t/* wait on read of region log to complete */\n\t\twhile (!rrd_mcpair->flag)\n\t\t\tRF_WAIT_COND(rrd_mcpair->cond, rrd_mcpair->mutex);\n\t\tRF_UNLOCK_MUTEX(rrd_mcpair->mutex);\n\t\tif (rrd_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG(\"Unable to read region log from disk\\n\");\n\t\t\t/* add code to fail the log disk */\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* apply region log to parity */\n\t\t/* ApplyRegionToParity(regionID, regionBuffer, parityBuffer); */\n\t\t/* release resources associated with region log */\n\t\t/* RF_Free(rrd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(rrd_pda);\n\t\trf_FreeDAG(rrd_dag_h);\n\t\trf_FreeAllocList(rrd_alloclist);\n\t\trf_FreeMCPair(rrd_mcpair);\n\t\tReleaseReintBuffer(&raidPtr->regionBufferPool, regionBuffer);\n\t}\n\t/* write reintegrated parity to disk */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating write of parity for region %d]\\n\", regionID);\n\tpwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(pwr_mcpair->mutex);\n\tpwr_mcpair->flag = RF_FALSE;\n\tWriteRegionParity(regionID, pwr_mcpair, parityBuffer, raidPtr, &pwr_dag_h, &pwr_alloclist, &pwr_pda);\n\twhile (!pwr_mcpair->flag)\n\t\tRF_WAIT_COND(pwr_mcpair->cond, pwr_mcpair->mutex);\n\tRF_UNLOCK_MUTEX(pwr_mcpair->mutex);\n\tif (pwr_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to write parity to disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* release resources associated with read of old parity */\n\t/* RF_Free(prd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(prd_pda);\n\trf_FreeDAG(prd_dag_h);\n\trf_FreeAllocList(prd_alloclist);\n\trf_FreeMCPair(prd_mcpair);\n\n\t/* release resources associated with write of new parity */\n\tReleaseReintBuffer(&raidPtr->parityBufferPool, parityBuffer);\n\t/* RF_Free(pwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(pwr_pda);\n\trf_FreeDAG(pwr_dag_h);\n\trf_FreeAllocList(pwr_alloclist);\n\trf_FreeMCPair(pwr_mcpair);\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished reintegrating region %d]\\n\", regionID);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 532
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nint \nrf_ShutdownLogging(RF_Raid_t * raidPtr)\n{\n\t/* shutdown parity logging 1) disable parity logging in all regions 2)\n\t * reintegrate all regions */\n\n\tRF_SectorCount_t diskCount;\n\tRF_RegionId_t regionID;\n\tRF_ParityLog_t *log;\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[shutting down parity logging]\\n\");\n\t/* Since parity log maps are volatile, we must reintegrate all\n\t * regions. */\n\tif (rf_forceParityLogReint) {\n\t\tfor (regionID = 0; regionID < rf_numParityRegions; regionID++) {\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\traidPtr->regionInfo[regionID].loggingEnabled = RF_FALSE;\n\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\traidPtr->regionInfo[regionID].coreLog = NULL;\n\t\t\tdiskCount = raidPtr->regionInfo[regionID].diskCount;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tif (diskCount > 0 || log != NULL)\n\t\t\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\t\tif (log != NULL)\n\t\t\t\trf_ReleaseParityLogs(raidPtr, log);\n\t\t}\n\t}\n\tif (rf_parityLogDebug) {\n\t\tprintf(\"[parity logging disabled]\\n\");\n\t\tprintf(\"[should be done!]\\n\");\n\t}\n\treturn (0);\n}"
  },
  {
    "function_name": "ReintegrateLogs",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "458-514",
    "snippet": "static void \nReintegrateLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\tRF_ParityLog_t *log, *freeLogList = NULL;\n\tRF_ParityLogData_t *logData, *logDataList;\n\tRF_RegionId_t regionID;\n\n\tRF_ASSERT(logList);\n\twhile (logList) {\n\t\tlog = logList;\n\t\tlogList = logList->next;\n\t\tlog->next = NULL;\n\t\tregionID = log->regionID;\n\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\tlog->numRecords = 0;\n\n\t\t/* remove all items which are blocked on reintegration of this\n\t\t * region */\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tlogData = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\tlogDataList = logData;\n\t\twhile (logData) {\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\t\tlogData = logData->next;\n\t\t}\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t\t/* process blocked log data and clear reintInProgress flag for\n\t\t * this region */\n\t\tif (logDataList)\n\t\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_TRUE);\n\t\telse {\n\t\t\t/* Enable flushing for this region.  Holding both\n\t\t\t * locks provides a synchronization barrier with\n\t\t\t * DumpParityLogToDisk */\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t}\n\t\t/* if log wasn't used, attach it to the list of logs to be\n\t\t * returned */\n\t\tif (log) {\n\t\t\tlog->next = freeLogList;\n\t\t\tfreeLogList = log;\n\t\t}\n\t}\n\tif (freeLogList)\n\t\trf_ReleaseParityLogs(raidPtr, freeLogList);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_ReleaseParityLogs",
          "args": [
            "raidPtr",
            "freeLogList"
          ],
          "line": 513
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ReleaseParityLogs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "467-539",
          "snippet": "void \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 501
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 500
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 497
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].reintMutex"
          ],
          "line": 496
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->regionInfo[regionID].mutex"
          ],
          "line": 495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_ParityLogAppend",
          "args": [
            "logDataList",
            "RF_TRUE",
            "&log",
            "RF_TRUE"
          ],
          "line": 490
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ParityLogAppend",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "660-853",
          "snippet": "int \nrf_ParityLogAppend(\n    RF_ParityLogData_t * logData,\n    int finish,\n    RF_ParityLog_t ** incomingLog,\n    int clearReintFlag)\n{\n\tint     regionID, logItem, itemDone;\n\tRF_ParityLogData_t *item;\n\tint     punt, done = RF_FALSE;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\tRF_Etimer_t timer;\n\tint     (*wakeFunc) (RF_DagNode_t * node, int status);\n\tvoid   *wakeArg;\n\n\t/* Add parity to the appropriate log, one sector at a time. This\n\t * routine is called is called by dag functions ParityLogUpdateFunc\n\t * and ParityLogOverwriteFunc and therefore MUST BE NONBLOCKING.\n\t * \n\t * Parity to be logged is contained in a linked-list (logData).  When\n\t * this routine returns, every sector in the list will be in one of\n\t * three places: 1) entered into the parity log 2) queued, waiting on\n\t * reintegration 3) queued, waiting on a core log\n\t * \n\t * Blocked work is passed to the ParityLoggingDiskManager for completion.\n\t * Later, as conditions which required the block are removed, the work\n\t * reenters this routine with the \"finish\" parameter set to \"RF_TRUE.\"\n\t * \n\t * NON-BLOCKING */\n\n\traidPtr = logData->common->raidPtr;\n\t/* lock the region for the first item in logData */\n\tRF_ASSERT(logData != NULL);\n\tregionID = logData->regionID;\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\n\tif (clearReintFlag) {\n\t\t/* Enable flushing for this region.  Holding both locks\n\t\t * provides a synchronization barrier with DumpParityLogToDisk */\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE);\n\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t}\n\t/* process each item in logData */\n\twhile (logData) {\n\t\t/* remove an item from logData */\n\t\titem = logData;\n\t\tlogData = logData->next;\n\t\titem->next = NULL;\n\t\titem->prev = NULL;\n\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[appending parity log data, region %d, raidAddress %d, numSector %d]\\n\", item->regionID, (int) item->diskAddress.raidAddress, (int) item->diskAddress.numSector);\n\n\t\t/* see if we moved to a new region */\n\t\tif (regionID != item->regionID) {\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tregionID = item->regionID;\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\t\t}\n\t\tpunt = RF_FALSE;/* Set to RF_TRUE if work is blocked.  This\n\t\t\t\t * can happen in one of two ways: 1) no core\n\t\t\t\t * log (AcquireParityLog) 2) waiting on\n\t\t\t\t * reintegration (DumpParityLogToDisk) If punt\n\t\t\t\t * is RF_TRUE, the dataItem was queued, so\n\t\t\t\t * skip to next item. */\n\n\t\t/* process item, one sector at a time, until all sectors\n\t\t * processed or we punt */\n\t\tif (item->diskAddress.numSector > 0)\n\t\t\tdone = RF_FALSE;\n\t\telse\n\t\t\tRF_ASSERT(0);\n\t\twhile (!punt && !done) {\n\t\t\t/* verify that a core log exists for this region */\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog) {\n\t\t\t\t/* Attempt to acquire a parity log. If\n\t\t\t\t * acquisition fails, queue remaining work in\n\t\t\t\t * data item and move to nextItem. */\n\t\t\t\tif (incomingLog) {\n\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t} else\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t} else\n\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t/* Note: AcquireParityLog either returns a log\n\t\t\t\t * or enqueues currentItem */\n\t\t\t}\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\tpunt = RF_TRUE;\t/* failed to find a core log */\n\t\t\telse {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* verify that the log has room for new\n\t\t\t\t * entries */\n\t\t\t\t/* if log is full, dump it to disk and grab a\n\t\t\t\t * new log */\n\t\t\t\tif (raidPtr->regionInfo[regionID].coreLog->numRecords == raidPtr->numSectorsPerLog) {\n\t\t\t\t\t/* log is full, dump it to disk */\n\t\t\t\t\tif (DumpParityLogToDisk(finish, item))\n\t\t\t\t\t\tpunt = RF_TRUE;\t/* dump unsuccessful,\n\t\t\t\t\t\t\t\t * blocked on\n\t\t\t\t\t\t\t\t * reintegration */\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* dump was successful */\n\t\t\t\t\t  if (incomingLog) {\n\t\t\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t\t\t} else\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t/* if a core log is not\n\t\t\t\t\t\t * available, must queue work\n\t\t\t\t\t\t * and return */\n\t\t\t\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\t\t\t\tpunt = RF_TRUE;\t/* blocked on log\n\t\t\t\t\t\t\t\t\t * availability */\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* if we didn't punt on this item, attempt to add a\n\t\t\t * sector to the core log */\n\t\t\tif (!punt) {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* at this point, we have a core log with\n\t\t\t\t * enough room for a sector */\n\t\t\t\t/* copy a sector into the log */\n\t\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\t\tRF_ASSERT(log->numRecords < raidPtr->numSectorsPerLog);\n\t\t\t\tlogItem = log->numRecords++;\n\t\t\t\tlog->records[logItem].parityAddr = item->diskAddress;\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr);\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity);\n\t\t\t\tlog->records[logItem].parityAddr.numSector = 1;\n\t\t\t\tlog->records[logItem].operation = item->common->operation;\n\t\t\t\tbcopy((item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector))), log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector)), (1 << item->common->raidPtr->logBytesPerSector));\n\t\t\t\titem->diskAddress.numSector--;\n\t\t\t\titem->diskAddress.startSector++;\n\t\t\t\tif (item->diskAddress.numSector == 0)\n\t\t\t\t\tdone = RF_TRUE;\n\t\t\t}\n\t\t}\n\n\t\tif (!punt) {\n\t\t\t/* Processed this item completely, decrement count of\n\t\t\t * items to be processed. */\n\t\t\tRF_ASSERT(item->diskAddress.numSector == 0);\n\t\t\tRF_LOCK_MUTEX(item->common->mutex);\n\t\t\titem->common->cnt--;\n\t\t\tif (item->common->cnt == 0)\n\t\t\t\titemDone = RF_TRUE;\n\t\t\telse\n\t\t\t\titemDone = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(item->common->mutex);\n\t\t\tif (itemDone) {\n\t\t\t\t/* Finished processing all log data for this\n\t\t\t\t * IO Return structs to free list and invoke\n\t\t\t\t * wakeup function. */\n\t\t\t\ttimer = item->common->startTime;\t/* grab initial value of\n\t\t\t\t\t\t\t\t\t * timer */\n\t\t\t\tRF_ETIMER_STOP(timer);\n\t\t\t\tRF_ETIMER_EVAL(timer);\n\t\t\t\titem->common->tracerec->plog_us += RF_ETIMER_VAL_US(timer);\n\t\t\t\tif (rf_parityLogDebug)\n\t\t\t\t\tprintf(\"[waking process for region %d]\\n\", item->regionID);\n\t\t\t\twakeFunc = item->common->wakeFunc;\n\t\t\t\twakeArg = item->common->wakeArg;\n\t\t\t\tFreeParityLogCommonData(item->common);\n\t\t\t\tFreeParityLogData(item);\n\t\t\t\t(wakeFunc) (wakeArg, 0);\n\t\t\t} else\n\t\t\t\tFreeParityLogData(item);\n\t\t}\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[exiting ParityLogAppend]\\n\");\n\treturn (0);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nint \nrf_ParityLogAppend(\n    RF_ParityLogData_t * logData,\n    int finish,\n    RF_ParityLog_t ** incomingLog,\n    int clearReintFlag)\n{\n\tint     regionID, logItem, itemDone;\n\tRF_ParityLogData_t *item;\n\tint     punt, done = RF_FALSE;\n\tRF_ParityLog_t *log;\n\tRF_Raid_t *raidPtr;\n\tRF_Etimer_t timer;\n\tint     (*wakeFunc) (RF_DagNode_t * node, int status);\n\tvoid   *wakeArg;\n\n\t/* Add parity to the appropriate log, one sector at a time. This\n\t * routine is called is called by dag functions ParityLogUpdateFunc\n\t * and ParityLogOverwriteFunc and therefore MUST BE NONBLOCKING.\n\t * \n\t * Parity to be logged is contained in a linked-list (logData).  When\n\t * this routine returns, every sector in the list will be in one of\n\t * three places: 1) entered into the parity log 2) queued, waiting on\n\t * reintegration 3) queued, waiting on a core log\n\t * \n\t * Blocked work is passed to the ParityLoggingDiskManager for completion.\n\t * Later, as conditions which required the block are removed, the work\n\t * reenters this routine with the \"finish\" parameter set to \"RF_TRUE.\"\n\t * \n\t * NON-BLOCKING */\n\n\traidPtr = logData->common->raidPtr;\n\t/* lock the region for the first item in logData */\n\tRF_ASSERT(logData != NULL);\n\tregionID = logData->regionID;\n\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\n\tif (clearReintFlag) {\n\t\t/* Enable flushing for this region.  Holding both locks\n\t\t * provides a synchronization barrier with DumpParityLogToDisk */\n\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tRF_ASSERT(raidPtr->regionInfo[regionID].reintInProgress == RF_TRUE);\n\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t}\n\t/* process each item in logData */\n\twhile (logData) {\n\t\t/* remove an item from logData */\n\t\titem = logData;\n\t\tlogData = logData->next;\n\t\titem->next = NULL;\n\t\titem->prev = NULL;\n\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[appending parity log data, region %d, raidAddress %d, numSector %d]\\n\", item->regionID, (int) item->diskAddress.raidAddress, (int) item->diskAddress.numSector);\n\n\t\t/* see if we moved to a new region */\n\t\tif (regionID != item->regionID) {\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tregionID = item->regionID;\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].loggingEnabled);\n\t\t}\n\t\tpunt = RF_FALSE;/* Set to RF_TRUE if work is blocked.  This\n\t\t\t\t * can happen in one of two ways: 1) no core\n\t\t\t\t * log (AcquireParityLog) 2) waiting on\n\t\t\t\t * reintegration (DumpParityLogToDisk) If punt\n\t\t\t\t * is RF_TRUE, the dataItem was queued, so\n\t\t\t\t * skip to next item. */\n\n\t\t/* process item, one sector at a time, until all sectors\n\t\t * processed or we punt */\n\t\tif (item->diskAddress.numSector > 0)\n\t\t\tdone = RF_FALSE;\n\t\telse\n\t\t\tRF_ASSERT(0);\n\t\twhile (!punt && !done) {\n\t\t\t/* verify that a core log exists for this region */\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog) {\n\t\t\t\t/* Attempt to acquire a parity log. If\n\t\t\t\t * acquisition fails, queue remaining work in\n\t\t\t\t * data item and move to nextItem. */\n\t\t\t\tif (incomingLog) {\n\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t} else\n\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t} else\n\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t/* Note: AcquireParityLog either returns a log\n\t\t\t\t * or enqueues currentItem */\n\t\t\t}\n\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\tpunt = RF_TRUE;\t/* failed to find a core log */\n\t\t\telse {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* verify that the log has room for new\n\t\t\t\t * entries */\n\t\t\t\t/* if log is full, dump it to disk and grab a\n\t\t\t\t * new log */\n\t\t\t\tif (raidPtr->regionInfo[regionID].coreLog->numRecords == raidPtr->numSectorsPerLog) {\n\t\t\t\t\t/* log is full, dump it to disk */\n\t\t\t\t\tif (DumpParityLogToDisk(finish, item))\n\t\t\t\t\t\tpunt = RF_TRUE;\t/* dump unsuccessful,\n\t\t\t\t\t\t\t\t * blocked on\n\t\t\t\t\t\t\t\t * reintegration */\n\t\t\t\t\telse {\n\t\t\t\t\t\t/* dump was successful */\n\t\t\t\t\t  if (incomingLog) {\n\t\t\t\t\t\t\tif (*incomingLog) {\n\t\t\t\t\t\t\t\tRF_ASSERT((*incomingLog)->next == NULL);\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = *incomingLog;\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog->regionID = regionID;\n\t\t\t\t\t\t\t\t*incomingLog = NULL;\n\t\t\t\t\t\t\t} else\n\t\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\traidPtr->regionInfo[regionID].coreLog = AcquireParityLog(item, finish);\n\t\t\t\t\t\t/* if a core log is not\n\t\t\t\t\t\t * available, must queue work\n\t\t\t\t\t\t * and return */\n\t\t\t\t\t\tif (!raidPtr->regionInfo[regionID].coreLog)\n\t\t\t\t\t\t\tpunt = RF_TRUE;\t/* blocked on log\n\t\t\t\t\t\t\t\t\t * availability */\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t/* if we didn't punt on this item, attempt to add a\n\t\t\t * sector to the core log */\n\t\t\tif (!punt) {\n\t\t\t\tRF_ASSERT(raidPtr->regionInfo[regionID].coreLog->next == NULL);\n\t\t\t\t/* at this point, we have a core log with\n\t\t\t\t * enough room for a sector */\n\t\t\t\t/* copy a sector into the log */\n\t\t\t\tlog = raidPtr->regionInfo[regionID].coreLog;\n\t\t\t\tRF_ASSERT(log->numRecords < raidPtr->numSectorsPerLog);\n\t\t\t\tlogItem = log->numRecords++;\n\t\t\t\tlog->records[logItem].parityAddr = item->diskAddress;\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector >= raidPtr->regionInfo[regionID].parityStartAddr);\n\t\t\t\tRF_ASSERT(log->records[logItem].parityAddr.startSector < raidPtr->regionInfo[regionID].parityStartAddr + raidPtr->regionInfo[regionID].numSectorsParity);\n\t\t\t\tlog->records[logItem].parityAddr.numSector = 1;\n\t\t\t\tlog->records[logItem].operation = item->common->operation;\n\t\t\t\tbcopy((item->common->bufPtr + (item->bufOffset++ * (1 << item->common->raidPtr->logBytesPerSector))), log->bufPtr + (logItem * (1 << item->common->raidPtr->logBytesPerSector)), (1 << item->common->raidPtr->logBytesPerSector));\n\t\t\t\titem->diskAddress.numSector--;\n\t\t\t\titem->diskAddress.startSector++;\n\t\t\t\tif (item->diskAddress.numSector == 0)\n\t\t\t\t\tdone = RF_TRUE;\n\t\t\t}\n\t\t}\n\n\t\tif (!punt) {\n\t\t\t/* Processed this item completely, decrement count of\n\t\t\t * items to be processed. */\n\t\t\tRF_ASSERT(item->diskAddress.numSector == 0);\n\t\t\tRF_LOCK_MUTEX(item->common->mutex);\n\t\t\titem->common->cnt--;\n\t\t\tif (item->common->cnt == 0)\n\t\t\t\titemDone = RF_TRUE;\n\t\t\telse\n\t\t\t\titemDone = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(item->common->mutex);\n\t\t\tif (itemDone) {\n\t\t\t\t/* Finished processing all log data for this\n\t\t\t\t * IO Return structs to free list and invoke\n\t\t\t\t * wakeup function. */\n\t\t\t\ttimer = item->common->startTime;\t/* grab initial value of\n\t\t\t\t\t\t\t\t\t * timer */\n\t\t\t\tRF_ETIMER_STOP(timer);\n\t\t\t\tRF_ETIMER_EVAL(timer);\n\t\t\t\titem->common->tracerec->plog_us += RF_ETIMER_VAL_US(timer);\n\t\t\t\tif (rf_parityLogDebug)\n\t\t\t\t\tprintf(\"[waking process for region %d]\\n\", item->regionID);\n\t\t\t\twakeFunc = item->common->wakeFunc;\n\t\t\t\twakeArg = item->common->wakeArg;\n\t\t\t\tFreeParityLogCommonData(item->common);\n\t\t\t\tFreeParityLogData(item);\n\t\t\t\t(wakeFunc) (wakeArg, 0);\n\t\t\t} else\n\t\t\t\tFreeParityLogData(item);\n\t\t}\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[exiting ParityLogAppend]\\n\");\n\treturn (0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 485
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_SearchAndDequeueParityLogData",
          "args": [
            "raidPtr",
            "regionID",
            "&raidPtr->parityLogDiskQueue.reintBlockHead",
            "&raidPtr->parityLogDiskQueue.reintBlockTail",
            "RF_TRUE"
          ],
          "line": 482
        },
        "resolved": true,
        "details": {
          "function_name": "rf_SearchAndDequeueParityLogData",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "338-400",
          "snippet": "RF_ParityLogData_t *\nrf_SearchAndDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *w;\n\n\t/* Remove and return an in-core parity log from a specified region\n\t * (regionID). If a matching log is not found, return NULL.\n\t * \n\t * NON-BLOCKING. */\n\n\t/* walk backward through a list, looking for an entry with a matching\n\t * region ID */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tw = (*tail);\n\twhile (w) {\n\t\tif (w->regionID == regionID) {\n\t\t\t/* remove an element from the list */\n\t\t\tif (w == *tail) {\n\t\t\t\tif (*head == *tail) {\n\t\t\t\t\t/* removing only element in the list */\n\t\t\t\t\t*head = NULL;\n\t\t\t\t\t*tail = NULL;\n\t\t\t\t} else {\n\t\t\t\t\t/* removing last item in the list */\n\t\t\t\t\t*tail = (*tail)->prev;\n\t\t\t\t\t(*tail)->next = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (w == *head) {\n\t\t\t\t\t/* removing first item in the list */\n\t\t\t\t\t*head = (*head)->next;\n\t\t\t\t\t(*head)->prev = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t} else {\n\t\t\t\t\t/* removing an item from the middle of\n\t\t\t\t\t * the list */\n\t\t\t\t\tw->prev->next = w->next;\n\t\t\t\t\tw->next->prev = w->prev;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tw->prev = NULL;\n\t\t\tw->next = NULL;\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", w->regionID, (int) w->diskAddress.raidAddress, (int) w->diskAddress.numSector);\n\t\t\treturn (w);\n\t\t} else\n\t\t\tw = w->prev;\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (NULL);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nRF_ParityLogData_t *\nrf_SearchAndDequeueParityLogData(\n    RF_Raid_t * raidPtr,\n    int regionID,\n    RF_ParityLogData_t ** head,\n    RF_ParityLogData_t ** tail,\n    int ignoreLocks)\n{\n\tRF_ParityLogData_t *w;\n\n\t/* Remove and return an in-core parity log from a specified region\n\t * (regionID). If a matching log is not found, return NULL.\n\t * \n\t * NON-BLOCKING. */\n\n\t/* walk backward through a list, looking for an entry with a matching\n\t * region ID */\n\tif (!ignoreLocks)\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tw = (*tail);\n\twhile (w) {\n\t\tif (w->regionID == regionID) {\n\t\t\t/* remove an element from the list */\n\t\t\tif (w == *tail) {\n\t\t\t\tif (*head == *tail) {\n\t\t\t\t\t/* removing only element in the list */\n\t\t\t\t\t*head = NULL;\n\t\t\t\t\t*tail = NULL;\n\t\t\t\t} else {\n\t\t\t\t\t/* removing last item in the list */\n\t\t\t\t\t*tail = (*tail)->prev;\n\t\t\t\t\t(*tail)->next = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (w == *head) {\n\t\t\t\t\t/* removing first item in the list */\n\t\t\t\t\t*head = (*head)->next;\n\t\t\t\t\t(*head)->prev = NULL;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t} else {\n\t\t\t\t\t/* removing an item from the middle of\n\t\t\t\t\t * the list */\n\t\t\t\t\tw->prev->next = w->next;\n\t\t\t\t\tw->next->prev = w->prev;\n\t\t\t\t\tRF_ASSERT((*head)->prev == NULL);\n\t\t\t\t\tRF_ASSERT((*tail)->next == NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tw->prev = NULL;\n\t\t\tw->next = NULL;\n\t\t\tif (rf_parityLogDebug)\n\t\t\t\tprintf(\"[dequeueing parity log data, region %d, raidAddress %d, numSector %d]\\n\", w->regionID, (int) w->diskAddress.raidAddress, (int) w->diskAddress.numSector);\n\t\t\treturn (w);\n\t\t} else\n\t\t\tw = w->prev;\n\t}\n\tif (!ignoreLocks)\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\treturn (NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "raidPtr->parityLogDiskQueue.mutex"
          ],
          "line": 478
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ReintegrateRegion",
          "args": [
            "raidPtr",
            "regionID",
            "log"
          ],
          "line": 473
        },
        "resolved": true,
        "details": {
          "function_name": "ReintegrateRegion",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "349-454",
          "snippet": "static void \nReintegrateRegion(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_ParityLog_t * coreLog)\n{\n\tRF_MCPair_t *rrd_mcpair = NULL, *prd_mcpair, *pwr_mcpair;\n\tRF_DagHeader_t *rrd_dag_h, *prd_dag_h, *pwr_dag_h;\n\tRF_AllocListElem_t *rrd_alloclist, *prd_alloclist, *pwr_alloclist;\n\tRF_PhysDiskAddr_t *rrd_pda, *prd_pda, *pwr_pda;\n\tcaddr_t parityBuffer, regionBuffer = NULL;\n\n\t/* Reintegrate a region (regionID). 1. acquire region and parity\n\t * buffers 2. read log from disk 3. read parity from disk 4. apply log\n\t * to parity 5. apply core log to parity 6. write new parity to disk\n\t * \n\t * BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reintegrating region %d]\\n\", regionID);\n\n\t/* initiate read of region parity */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating read of parity for region %d]\\n\", regionID);\n\tparityBuffer = AcquireReintBuffer(&raidPtr->parityBufferPool);\n\tprd_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(prd_mcpair->mutex);\n\tprd_mcpair->flag = RF_FALSE;\n\tReadRegionParity(regionID, prd_mcpair, parityBuffer, raidPtr, &prd_dag_h, &prd_alloclist, &prd_pda);\n\n\t/* if region log nonempty, initiate read */\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating read of disk log for region %d]\\n\", regionID);\n\t\tregionBuffer = AcquireReintBuffer(&raidPtr->regionBufferPool);\n\t\trrd_mcpair = rf_AllocMCPair();\n\t\tRF_LOCK_MUTEX(rrd_mcpair->mutex);\n\t\trrd_mcpair->flag = RF_FALSE;\n\t\tReadRegionLog(regionID, rrd_mcpair, regionBuffer, raidPtr, &rrd_dag_h, &rrd_alloclist, &rrd_pda);\n\t}\n\t/* wait on read of region parity to complete */\n\twhile (!prd_mcpair->flag) {\n\t\tRF_WAIT_COND(prd_mcpair->cond, prd_mcpair->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(prd_mcpair->mutex);\n\tif (prd_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to read parity from disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* apply core log to parity */\n\t/* if (coreLog) ApplyLogsToParity(coreLog, parityBuffer); */\n\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\t/* wait on read of region log to complete */\n\t\twhile (!rrd_mcpair->flag)\n\t\t\tRF_WAIT_COND(rrd_mcpair->cond, rrd_mcpair->mutex);\n\t\tRF_UNLOCK_MUTEX(rrd_mcpair->mutex);\n\t\tif (rrd_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG(\"Unable to read region log from disk\\n\");\n\t\t\t/* add code to fail the log disk */\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* apply region log to parity */\n\t\t/* ApplyRegionToParity(regionID, regionBuffer, parityBuffer); */\n\t\t/* release resources associated with region log */\n\t\t/* RF_Free(rrd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(rrd_pda);\n\t\trf_FreeDAG(rrd_dag_h);\n\t\trf_FreeAllocList(rrd_alloclist);\n\t\trf_FreeMCPair(rrd_mcpair);\n\t\tReleaseReintBuffer(&raidPtr->regionBufferPool, regionBuffer);\n\t}\n\t/* write reintegrated parity to disk */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating write of parity for region %d]\\n\", regionID);\n\tpwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(pwr_mcpair->mutex);\n\tpwr_mcpair->flag = RF_FALSE;\n\tWriteRegionParity(regionID, pwr_mcpair, parityBuffer, raidPtr, &pwr_dag_h, &pwr_alloclist, &pwr_pda);\n\twhile (!pwr_mcpair->flag)\n\t\tRF_WAIT_COND(pwr_mcpair->cond, pwr_mcpair->mutex);\n\tRF_UNLOCK_MUTEX(pwr_mcpair->mutex);\n\tif (pwr_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to write parity to disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* release resources associated with read of old parity */\n\t/* RF_Free(prd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(prd_pda);\n\trf_FreeDAG(prd_dag_h);\n\trf_FreeAllocList(prd_alloclist);\n\trf_FreeMCPair(prd_mcpair);\n\n\t/* release resources associated with write of new parity */\n\tReleaseReintBuffer(&raidPtr->parityBufferPool, parityBuffer);\n\t/* RF_Free(pwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(pwr_pda);\n\trf_FreeDAG(pwr_dag_h);\n\trf_FreeAllocList(pwr_alloclist);\n\trf_FreeMCPair(pwr_mcpair);\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished reintegrating region %d]\\n\", regionID);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintegrateRegion(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_ParityLog_t * coreLog)\n{\n\tRF_MCPair_t *rrd_mcpair = NULL, *prd_mcpair, *pwr_mcpair;\n\tRF_DagHeader_t *rrd_dag_h, *prd_dag_h, *pwr_dag_h;\n\tRF_AllocListElem_t *rrd_alloclist, *prd_alloclist, *pwr_alloclist;\n\tRF_PhysDiskAddr_t *rrd_pda, *prd_pda, *pwr_pda;\n\tcaddr_t parityBuffer, regionBuffer = NULL;\n\n\t/* Reintegrate a region (regionID). 1. acquire region and parity\n\t * buffers 2. read log from disk 3. read parity from disk 4. apply log\n\t * to parity 5. apply core log to parity 6. write new parity to disk\n\t * \n\t * BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reintegrating region %d]\\n\", regionID);\n\n\t/* initiate read of region parity */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating read of parity for region %d]\\n\", regionID);\n\tparityBuffer = AcquireReintBuffer(&raidPtr->parityBufferPool);\n\tprd_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(prd_mcpair->mutex);\n\tprd_mcpair->flag = RF_FALSE;\n\tReadRegionParity(regionID, prd_mcpair, parityBuffer, raidPtr, &prd_dag_h, &prd_alloclist, &prd_pda);\n\n\t/* if region log nonempty, initiate read */\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating read of disk log for region %d]\\n\", regionID);\n\t\tregionBuffer = AcquireReintBuffer(&raidPtr->regionBufferPool);\n\t\trrd_mcpair = rf_AllocMCPair();\n\t\tRF_LOCK_MUTEX(rrd_mcpair->mutex);\n\t\trrd_mcpair->flag = RF_FALSE;\n\t\tReadRegionLog(regionID, rrd_mcpair, regionBuffer, raidPtr, &rrd_dag_h, &rrd_alloclist, &rrd_pda);\n\t}\n\t/* wait on read of region parity to complete */\n\twhile (!prd_mcpair->flag) {\n\t\tRF_WAIT_COND(prd_mcpair->cond, prd_mcpair->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(prd_mcpair->mutex);\n\tif (prd_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to read parity from disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* apply core log to parity */\n\t/* if (coreLog) ApplyLogsToParity(coreLog, parityBuffer); */\n\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\t/* wait on read of region log to complete */\n\t\twhile (!rrd_mcpair->flag)\n\t\t\tRF_WAIT_COND(rrd_mcpair->cond, rrd_mcpair->mutex);\n\t\tRF_UNLOCK_MUTEX(rrd_mcpair->mutex);\n\t\tif (rrd_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG(\"Unable to read region log from disk\\n\");\n\t\t\t/* add code to fail the log disk */\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* apply region log to parity */\n\t\t/* ApplyRegionToParity(regionID, regionBuffer, parityBuffer); */\n\t\t/* release resources associated with region log */\n\t\t/* RF_Free(rrd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(rrd_pda);\n\t\trf_FreeDAG(rrd_dag_h);\n\t\trf_FreeAllocList(rrd_alloclist);\n\t\trf_FreeMCPair(rrd_mcpair);\n\t\tReleaseReintBuffer(&raidPtr->regionBufferPool, regionBuffer);\n\t}\n\t/* write reintegrated parity to disk */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating write of parity for region %d]\\n\", regionID);\n\tpwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(pwr_mcpair->mutex);\n\tpwr_mcpair->flag = RF_FALSE;\n\tWriteRegionParity(regionID, pwr_mcpair, parityBuffer, raidPtr, &pwr_dag_h, &pwr_alloclist, &pwr_pda);\n\twhile (!pwr_mcpair->flag)\n\t\tRF_WAIT_COND(pwr_mcpair->cond, pwr_mcpair->mutex);\n\tRF_UNLOCK_MUTEX(pwr_mcpair->mutex);\n\tif (pwr_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to write parity to disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* release resources associated with read of old parity */\n\t/* RF_Free(prd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(prd_pda);\n\trf_FreeDAG(prd_dag_h);\n\trf_FreeAllocList(prd_alloclist);\n\trf_FreeMCPair(prd_mcpair);\n\n\t/* release resources associated with write of new parity */\n\tReleaseReintBuffer(&raidPtr->parityBufferPool, parityBuffer);\n\t/* RF_Free(pwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(pwr_pda);\n\trf_FreeDAG(pwr_dag_h);\n\trf_FreeAllocList(pwr_alloclist);\n\trf_FreeMCPair(pwr_mcpair);\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished reintegrating region %d]\\n\", regionID);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "logList"
          ],
          "line": 467
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintegrateLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\tRF_ParityLog_t *log, *freeLogList = NULL;\n\tRF_ParityLogData_t *logData, *logDataList;\n\tRF_RegionId_t regionID;\n\n\tRF_ASSERT(logList);\n\twhile (logList) {\n\t\tlog = logList;\n\t\tlogList = logList->next;\n\t\tlog->next = NULL;\n\t\tregionID = log->regionID;\n\t\tReintegrateRegion(raidPtr, regionID, log);\n\t\tlog->numRecords = 0;\n\n\t\t/* remove all items which are blocked on reintegration of this\n\t\t * region */\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tlogData = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\tlogDataList = logData;\n\t\twhile (logData) {\n\t\t\tlogData->next = rf_SearchAndDequeueParityLogData(raidPtr, regionID, &raidPtr->parityLogDiskQueue.reintBlockHead, &raidPtr->parityLogDiskQueue.reintBlockTail, RF_TRUE);\n\t\t\tlogData = logData->next;\n\t\t}\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\n\t\t/* process blocked log data and clear reintInProgress flag for\n\t\t * this region */\n\t\tif (logDataList)\n\t\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_TRUE);\n\t\telse {\n\t\t\t/* Enable flushing for this region.  Holding both\n\t\t\t * locks provides a synchronization barrier with\n\t\t\t * DumpParityLogToDisk */\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\n\t\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t\traidPtr->regionInfo[regionID].diskCount = 0;\n\t\t\traidPtr->regionInfo[regionID].reintInProgress = RF_FALSE;\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].mutex);\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->regionInfo[regionID].reintMutex);\t/* flushing is now\n\t\t\t\t\t\t\t\t\t\t\t * enabled */\n\t\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\t}\n\t\t/* if log wasn't used, attach it to the list of logs to be\n\t\t * returned */\n\t\tif (log) {\n\t\t\tlog->next = freeLogList;\n\t\t\tfreeLogList = log;\n\t\t}\n\t}\n\tif (freeLogList)\n\t\trf_ReleaseParityLogs(raidPtr, freeLogList);\n}"
  },
  {
    "function_name": "ReintegrateRegion",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "349-454",
    "snippet": "static void \nReintegrateRegion(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_ParityLog_t * coreLog)\n{\n\tRF_MCPair_t *rrd_mcpair = NULL, *prd_mcpair, *pwr_mcpair;\n\tRF_DagHeader_t *rrd_dag_h, *prd_dag_h, *pwr_dag_h;\n\tRF_AllocListElem_t *rrd_alloclist, *prd_alloclist, *pwr_alloclist;\n\tRF_PhysDiskAddr_t *rrd_pda, *prd_pda, *pwr_pda;\n\tcaddr_t parityBuffer, regionBuffer = NULL;\n\n\t/* Reintegrate a region (regionID). 1. acquire region and parity\n\t * buffers 2. read log from disk 3. read parity from disk 4. apply log\n\t * to parity 5. apply core log to parity 6. write new parity to disk\n\t * \n\t * BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reintegrating region %d]\\n\", regionID);\n\n\t/* initiate read of region parity */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating read of parity for region %d]\\n\", regionID);\n\tparityBuffer = AcquireReintBuffer(&raidPtr->parityBufferPool);\n\tprd_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(prd_mcpair->mutex);\n\tprd_mcpair->flag = RF_FALSE;\n\tReadRegionParity(regionID, prd_mcpair, parityBuffer, raidPtr, &prd_dag_h, &prd_alloclist, &prd_pda);\n\n\t/* if region log nonempty, initiate read */\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating read of disk log for region %d]\\n\", regionID);\n\t\tregionBuffer = AcquireReintBuffer(&raidPtr->regionBufferPool);\n\t\trrd_mcpair = rf_AllocMCPair();\n\t\tRF_LOCK_MUTEX(rrd_mcpair->mutex);\n\t\trrd_mcpair->flag = RF_FALSE;\n\t\tReadRegionLog(regionID, rrd_mcpair, regionBuffer, raidPtr, &rrd_dag_h, &rrd_alloclist, &rrd_pda);\n\t}\n\t/* wait on read of region parity to complete */\n\twhile (!prd_mcpair->flag) {\n\t\tRF_WAIT_COND(prd_mcpair->cond, prd_mcpair->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(prd_mcpair->mutex);\n\tif (prd_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to read parity from disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* apply core log to parity */\n\t/* if (coreLog) ApplyLogsToParity(coreLog, parityBuffer); */\n\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\t/* wait on read of region log to complete */\n\t\twhile (!rrd_mcpair->flag)\n\t\t\tRF_WAIT_COND(rrd_mcpair->cond, rrd_mcpair->mutex);\n\t\tRF_UNLOCK_MUTEX(rrd_mcpair->mutex);\n\t\tif (rrd_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG(\"Unable to read region log from disk\\n\");\n\t\t\t/* add code to fail the log disk */\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* apply region log to parity */\n\t\t/* ApplyRegionToParity(regionID, regionBuffer, parityBuffer); */\n\t\t/* release resources associated with region log */\n\t\t/* RF_Free(rrd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(rrd_pda);\n\t\trf_FreeDAG(rrd_dag_h);\n\t\trf_FreeAllocList(rrd_alloclist);\n\t\trf_FreeMCPair(rrd_mcpair);\n\t\tReleaseReintBuffer(&raidPtr->regionBufferPool, regionBuffer);\n\t}\n\t/* write reintegrated parity to disk */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating write of parity for region %d]\\n\", regionID);\n\tpwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(pwr_mcpair->mutex);\n\tpwr_mcpair->flag = RF_FALSE;\n\tWriteRegionParity(regionID, pwr_mcpair, parityBuffer, raidPtr, &pwr_dag_h, &pwr_alloclist, &pwr_pda);\n\twhile (!pwr_mcpair->flag)\n\t\tRF_WAIT_COND(pwr_mcpair->cond, pwr_mcpair->mutex);\n\tRF_UNLOCK_MUTEX(pwr_mcpair->mutex);\n\tif (pwr_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to write parity to disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* release resources associated with read of old parity */\n\t/* RF_Free(prd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(prd_pda);\n\trf_FreeDAG(prd_dag_h);\n\trf_FreeAllocList(prd_alloclist);\n\trf_FreeMCPair(prd_mcpair);\n\n\t/* release resources associated with write of new parity */\n\tReleaseReintBuffer(&raidPtr->parityBufferPool, parityBuffer);\n\t/* RF_Free(pwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(pwr_pda);\n\trf_FreeDAG(pwr_dag_h);\n\trf_FreeAllocList(pwr_alloclist);\n\trf_FreeMCPair(pwr_mcpair);\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished reintegrating region %d]\\n\", regionID);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[finished reintegrating region %d]\\n\"",
            "regionID"
          ],
          "line": 453
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreeMCPair",
          "args": [
            "pwr_mcpair"
          ],
          "line": 450
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeMCPair",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_mcpair.c",
          "lines": "125-130",
          "snippet": "void \nrf_FreeMCPair(t)\n\tRF_MCPair_t *t;\n{\n\tRF_FREELIST_FREE_CLEAN(rf_mcpair_freelist, t, next, clean_mcpair);\n}",
          "includes": [
            "#include <sys/proc.h>",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_mcpair_freelist;",
            "static int init_mcpair(RF_MCPair_t *);",
            "static void clean_mcpair(RF_MCPair_t *);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/proc.h>\n#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_mcpair_freelist;\nstatic int init_mcpair(RF_MCPair_t *);\nstatic void clean_mcpair(RF_MCPair_t *);\n\nvoid \nrf_FreeMCPair(t)\n\tRF_MCPair_t *t;\n{\n\tRF_FREELIST_FREE_CLEAN(rf_mcpair_freelist, t, next, clean_mcpair);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreeAllocList",
          "args": [
            "pwr_alloclist"
          ],
          "line": 449
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeAllocList",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_alloclist.c",
          "lines": "139-164",
          "snippet": "void \nrf_FreeAllocList(l)\n\tRF_AllocListElem_t *l;\n{\n\tint     i;\n\tRF_AllocListElem_t *temp, *p;\n\n\tfor (p = l; p; p = p->next) {\n\t\tRF_ASSERT(p->numPointers >= 0 && p->numPointers <= RF_POINTERS_PER_ALLOC_LIST_ELEMENT);\n\t\tfor (i = 0; i < p->numPointers; i++) {\n\t\t\tRF_ASSERT(p->pointers[i]);\n\t\t\tRF_Free(p->pointers[i], p->sizes[i]);\n\t\t}\n\t}\n\twhile (l) {\n\t\ttemp = l;\n\t\tl = l->next;\n\t\tif (al_free_list_count > RF_AL_FREELIST_MAX) {\n\t\t\tDO_FREE(temp, sizeof(*temp));\n\t\t} else {\n\t\t\ttemp->next = al_free_list;\n\t\t\tal_free_list = temp;\n\t\t\tal_free_list_count++;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define RF_AL_FREELIST_MAX 256"
          ],
          "globals_used": [
            "static RF_AllocListElem_t *al_free_list = NULL;",
            "static int al_free_list_count;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define RF_AL_FREELIST_MAX 256\n\nstatic RF_AllocListElem_t *al_free_list = NULL;\nstatic int al_free_list_count;\n\nvoid \nrf_FreeAllocList(l)\n\tRF_AllocListElem_t *l;\n{\n\tint     i;\n\tRF_AllocListElem_t *temp, *p;\n\n\tfor (p = l; p; p = p->next) {\n\t\tRF_ASSERT(p->numPointers >= 0 && p->numPointers <= RF_POINTERS_PER_ALLOC_LIST_ELEMENT);\n\t\tfor (i = 0; i < p->numPointers; i++) {\n\t\t\tRF_ASSERT(p->pointers[i]);\n\t\t\tRF_Free(p->pointers[i], p->sizes[i]);\n\t\t}\n\t}\n\twhile (l) {\n\t\ttemp = l;\n\t\tl = l->next;\n\t\tif (al_free_list_count > RF_AL_FREELIST_MAX) {\n\t\t\tDO_FREE(temp, sizeof(*temp));\n\t\t} else {\n\t\t\ttemp->next = al_free_list;\n\t\t\tal_free_list = temp;\n\t\t\tal_free_list_count++;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreeDAG",
          "args": [
            "pwr_dag_h"
          ],
          "line": 448
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeDAGHeader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_dagutils.c",
          "lines": "257-261",
          "snippet": "void \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_PrintDAG(RF_DagHeader_t *);",
            "static void rf_ValidateVisitedBits(RF_DagHeader_t *);",
            "static RF_FreeList_t *rf_dagh_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_map.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void rf_PrintDAG(RF_DagHeader_t *);\nstatic void rf_ValidateVisitedBits(RF_DagHeader_t *);\nstatic RF_FreeList_t *rf_dagh_freelist;\n\nvoid \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreePhysDiskAddr",
          "args": [
            "pwr_pda"
          ],
          "line": 447
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreePhysDiskAddr",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_map.c",
          "lines": "481-486",
          "snippet": "void \nrf_FreePhysDiskAddr(p)\n\tRF_PhysDiskAddr_t *p;\n{\n\tRF_FREELIST_FREE(rf_pda_freelist, p, next);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_pda_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_pda_freelist;\n\nvoid \nrf_FreePhysDiskAddr(p)\n\tRF_PhysDiskAddr_t *p;\n{\n\tRF_FREELIST_FREE(rf_pda_freelist, p, next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ReleaseReintBuffer",
          "args": [
            "&raidPtr->parityBufferPool",
            "parityBuffer"
          ],
          "line": 445
        },
        "resolved": true,
        "details": {
          "function_name": "ReleaseReintBuffer",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "84-101",
          "snippet": "static void \nReleaseReintBuffer(\n    RF_RegionBufferQueue_t * pool,\n    caddr_t bufPtr)\n{\n\t/* Insert a region buffer (bufPtr) into the free list (pool).\n\t * NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tpool->availableBuffers++;\n\tpool->buffers[pool->emptyBuffersIndex] = bufPtr;\n\tpool->emptyBuffersIndex++;\n\tif (pool->emptyBuffersIndex == pool->totalBuffers)\n\t\tpool->emptyBuffersIndex = 0;\n\tRF_ASSERT(pool->availableBuffers <= pool->totalBuffers);\n\tRF_UNLOCK_MUTEX(pool->mutex);\n\tRF_SIGNAL_COND(pool->cond);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReleaseReintBuffer(\n    RF_RegionBufferQueue_t * pool,\n    caddr_t bufPtr)\n{\n\t/* Insert a region buffer (bufPtr) into the free list (pool).\n\t * NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tpool->availableBuffers++;\n\tpool->buffers[pool->emptyBuffersIndex] = bufPtr;\n\tpool->emptyBuffersIndex++;\n\tif (pool->emptyBuffersIndex == pool->totalBuffers)\n\t\tpool->emptyBuffersIndex = 0;\n\tRF_ASSERT(pool->availableBuffers <= pool->totalBuffers);\n\tRF_UNLOCK_MUTEX(pool->mutex);\n\tRF_SIGNAL_COND(pool->cond);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "0"
          ],
          "line": 435
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ERRORMSG",
          "args": [
            "\"Unable to write parity to disk\\n\""
          ],
          "line": 433
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "pwr_mcpair->mutex"
          ],
          "line": 431
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_WAIT_COND",
          "args": [
            "pwr_mcpair->cond",
            "pwr_mcpair->mutex"
          ],
          "line": 430
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WriteRegionParity",
          "args": [
            "regionID",
            "pwr_mcpair",
            "parityBuffer",
            "raidPtr",
            "&pwr_dag_h",
            "&pwr_alloclist",
            "&pwr_pda"
          ],
          "line": 428
        },
        "resolved": true,
        "details": {
          "function_name": "WriteRegionParity",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "252-293",
          "snippet": "static void \nWriteRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * pwr_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** pwr_dag_h,\n    RF_AllocListElem_t ** pwr_alloclist,\n    RF_PhysDiskAddr_t ** pwr_pda)\n{\n\t/* Initiate the write of region parity to disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *pwr_wrNode;\n\n\t/* create DAG to write region log from disk */\n\trf_MakeAllocList(*pwr_alloclist);\n\t*pwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, parityBuffer, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wrp\", *pwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*pwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*pwr_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*pwr_pda)->row), &((*pwr_pda)->col), &((*pwr_pda)->startSector), &((*pwr_pda)->numSector));\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*pwr_dag_h)->tracerec = &tracerec;\n\tpwr_wrNode = (*pwr_dag_h)->succedents[0]->succedents[0];\n\tpwr_wrNode->params[0].p = *pwr_pda;\n/*  pwr_wrNode->params[1] = parityBuffer; */\n\tpwr_wrNode->params[2].v = 0;\n\tpwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write region parity to disk */\n\trf_DispatchDAG(*pwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) pwr_mcpair);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nWriteRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * pwr_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** pwr_dag_h,\n    RF_AllocListElem_t ** pwr_alloclist,\n    RF_PhysDiskAddr_t ** pwr_pda)\n{\n\t/* Initiate the write of region parity to disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *pwr_wrNode;\n\n\t/* create DAG to write region log from disk */\n\trf_MakeAllocList(*pwr_alloclist);\n\t*pwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, parityBuffer, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wrp\", *pwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*pwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*pwr_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*pwr_pda)->row), &((*pwr_pda)->col), &((*pwr_pda)->startSector), &((*pwr_pda)->numSector));\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*pwr_dag_h)->tracerec = &tracerec;\n\tpwr_wrNode = (*pwr_dag_h)->succedents[0]->succedents[0];\n\tpwr_wrNode->params[0].p = *pwr_pda;\n/*  pwr_wrNode->params[1] = parityBuffer; */\n\tpwr_wrNode->params[2].v = 0;\n\tpwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write region parity to disk */\n\trf_DispatchDAG(*pwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) pwr_mcpair);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "pwr_mcpair->mutex"
          ],
          "line": 426
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_AllocMCPair",
          "args": [],
          "line": 425
        },
        "resolved": true,
        "details": {
          "function_name": "rf_AllocMCPair",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_mcpair.c",
          "lines": "112-123",
          "snippet": "RF_MCPair_t *\nrf_AllocMCPair()\n{\n\tRF_MCPair_t *t;\n\n\tRF_FREELIST_GET_INIT(rf_mcpair_freelist, t, next, (RF_MCPair_t *), init_mcpair);\n\tif (t) {\n\t\tt->flag = 0;\n\t\tt->next = NULL;\n\t}\n\treturn (t);\n}",
          "includes": [
            "#include <sys/proc.h>",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_mcpair_freelist;",
            "static int init_mcpair(RF_MCPair_t *);",
            "static void clean_mcpair(RF_MCPair_t *);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/proc.h>\n#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_mcpair_freelist;\nstatic int init_mcpair(RF_MCPair_t *);\nstatic void clean_mcpair(RF_MCPair_t *);\n\nRF_MCPair_t *\nrf_AllocMCPair()\n{\n\tRF_MCPair_t *t;\n\n\tRF_FREELIST_GET_INIT(rf_mcpair_freelist, t, next, (RF_MCPair_t *), init_mcpair);\n\tif (t) {\n\t\tt->flag = 0;\n\t\tt->next = NULL;\n\t}\n\treturn (t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "0"
          ],
          "line": 410
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ERRORMSG",
          "args": [
            "\"Unable to read region log from disk\\n\""
          ],
          "line": 408
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "rrd_mcpair->mutex"
          ],
          "line": 406
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_WAIT_COND",
          "args": [
            "rrd_mcpair->cond",
            "rrd_mcpair->mutex"
          ],
          "line": 405
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "0"
          ],
          "line": 397
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ERRORMSG",
          "args": [
            "\"Unable to read parity from disk\\n\""
          ],
          "line": 395
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "prd_mcpair->mutex"
          ],
          "line": 393
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_WAIT_COND",
          "args": [
            "prd_mcpair->cond",
            "prd_mcpair->mutex"
          ],
          "line": 391
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ReadRegionLog",
          "args": [
            "regionID",
            "rrd_mcpair",
            "regionBuffer",
            "raidPtr",
            "&rrd_dag_h",
            "&rrd_alloclist",
            "&rrd_pda"
          ],
          "line": 387
        },
        "resolved": true,
        "details": {
          "function_name": "ReadRegionLog",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "105-151",
          "snippet": "static void \nReadRegionLog(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * rrd_mcpair,\n    caddr_t regionBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** rrd_dag_h,\n    RF_AllocListElem_t ** rrd_alloclist,\n    RF_PhysDiskAddr_t ** rrd_pda)\n{\n\t/* Initiate the read a region log from disk.  Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *rrd_rdNode;\n\n\t/* create DAG to read region log from disk */\n\trf_MakeAllocList(*rrd_alloclist);\n\t*rrd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, regionBuffer, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrl\", *rrd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the core log */\n\t/* RF_Malloc(*rrd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*rrd_pda = rf_AllocPDAList(1);\n\trf_MapLogParityLogging(raidPtr, regionID, 0, &((*rrd_pda)->row), &((*rrd_pda)->col), &((*rrd_pda)->startSector));\n\t(*rrd_pda)->numSector = raidPtr->regionInfo[regionID].capacity;\n\n\tif ((*rrd_pda)->next) {\n\t\t(*rrd_pda)->next = NULL;\n\t\tprintf(\"set rrd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*rrd_dag_h)->tracerec = &tracerec;\n\trrd_rdNode = (*rrd_dag_h)->succedents[0]->succedents[0];\n\trrd_rdNode->params[0].p = *rrd_pda;\n/*  rrd_rdNode->params[1] = regionBuffer; */\n\trrd_rdNode->params[2].v = 0;\n\trrd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch region log read dag */\n\trf_DispatchDAG(*rrd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) rrd_mcpair);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReadRegionLog(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * rrd_mcpair,\n    caddr_t regionBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** rrd_dag_h,\n    RF_AllocListElem_t ** rrd_alloclist,\n    RF_PhysDiskAddr_t ** rrd_pda)\n{\n\t/* Initiate the read a region log from disk.  Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *rrd_rdNode;\n\n\t/* create DAG to read region log from disk */\n\trf_MakeAllocList(*rrd_alloclist);\n\t*rrd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, regionBuffer, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrl\", *rrd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the core log */\n\t/* RF_Malloc(*rrd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*rrd_pda = rf_AllocPDAList(1);\n\trf_MapLogParityLogging(raidPtr, regionID, 0, &((*rrd_pda)->row), &((*rrd_pda)->col), &((*rrd_pda)->startSector));\n\t(*rrd_pda)->numSector = raidPtr->regionInfo[regionID].capacity;\n\n\tif ((*rrd_pda)->next) {\n\t\t(*rrd_pda)->next = NULL;\n\t\tprintf(\"set rrd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*rrd_dag_h)->tracerec = &tracerec;\n\trrd_rdNode = (*rrd_dag_h)->succedents[0]->succedents[0];\n\trrd_rdNode->params[0].p = *rrd_pda;\n/*  rrd_rdNode->params[1] = regionBuffer; */\n\trrd_rdNode->params[2].v = 0;\n\trrd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch region log read dag */\n\trf_DispatchDAG(*rrd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) rrd_mcpair);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "rrd_mcpair->mutex"
          ],
          "line": 385
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "AcquireReintBuffer",
          "args": [
            "&raidPtr->regionBufferPool"
          ],
          "line": 383
        },
        "resolved": true,
        "details": {
          "function_name": "AcquireReintBuffer",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "59-82",
          "snippet": "static caddr_t \nAcquireReintBuffer(pool)\n\tRF_RegionBufferQueue_t *pool;\n{\n\tcaddr_t bufPtr = NULL;\n\n\t/* Return a region buffer from the free list (pool). If the free list\n\t * is empty, WAIT. BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tif (pool->availableBuffers > 0) {\n\t\tbufPtr = pool->buffers[pool->availBuffersIndex];\n\t\tpool->availableBuffers--;\n\t\tpool->availBuffersIndex++;\n\t\tif (pool->availBuffersIndex == pool->totalBuffers)\n\t\t\tpool->availBuffersIndex = 0;\n\t\tRF_UNLOCK_MUTEX(pool->mutex);\n\t} else {\n\t\tRF_PANIC();\t/* should never happen in currect config,\n\t\t\t\t * single reint */\n\t\tRF_WAIT_COND(pool->cond, pool->mutex);\n\t}\n\treturn (bufPtr);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic caddr_t \nAcquireReintBuffer(pool)\n\tRF_RegionBufferQueue_t *pool;\n{\n\tcaddr_t bufPtr = NULL;\n\n\t/* Return a region buffer from the free list (pool). If the free list\n\t * is empty, WAIT. BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tif (pool->availableBuffers > 0) {\n\t\tbufPtr = pool->buffers[pool->availBuffersIndex];\n\t\tpool->availableBuffers--;\n\t\tpool->availBuffersIndex++;\n\t\tif (pool->availBuffersIndex == pool->totalBuffers)\n\t\t\tpool->availBuffersIndex = 0;\n\t\tRF_UNLOCK_MUTEX(pool->mutex);\n\t} else {\n\t\tRF_PANIC();\t/* should never happen in currect config,\n\t\t\t\t * single reint */\n\t\tRF_WAIT_COND(pool->cond, pool->mutex);\n\t}\n\treturn (bufPtr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ReadRegionParity",
          "args": [
            "regionID",
            "prd_mcpair",
            "parityBuffer",
            "raidPtr",
            "&prd_dag_h",
            "&prd_alloclist",
            "&prd_pda"
          ],
          "line": 377
        },
        "resolved": true,
        "details": {
          "function_name": "ReadRegionParity",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "202-250",
          "snippet": "static void \nReadRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * prd_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** prd_dag_h,\n    RF_AllocListElem_t ** prd_alloclist,\n    RF_PhysDiskAddr_t ** prd_pda)\n{\n\t/* Initiate the read region parity from disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *prd_rdNode;\n\n\t/* create DAG to read region parity from disk */\n\trf_MakeAllocList(*prd_alloclist);\n\t*prd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, NULL, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrp\", *prd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*prd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*prd_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*prd_pda)->row), &((*prd_pda)->col), &((*prd_pda)->startSector), &((*prd_pda)->numSector));\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reading %d sectors of parity from region %d]\\n\",\n\t\t    (int) (*prd_pda)->numSector, regionID);\n\tif ((*prd_pda)->next) {\n\t\t(*prd_pda)->next = NULL;\n\t\tprintf(\"set prd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*prd_dag_h)->tracerec = &tracerec;\n\tprd_rdNode = (*prd_dag_h)->succedents[0]->succedents[0];\n\tprd_rdNode->params[0].p = *prd_pda;\n\tprd_rdNode->params[1].p = parityBuffer;\n\tprd_rdNode->params[2].v = 0;\n\tprd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\tif (rf_validateDAGDebug)\n\t\trf_ValidateDAG(*prd_dag_h);\n\t/* launch region parity read dag */\n\trf_DispatchDAG(*prd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) prd_mcpair);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReadRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * prd_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** prd_dag_h,\n    RF_AllocListElem_t ** prd_alloclist,\n    RF_PhysDiskAddr_t ** prd_pda)\n{\n\t/* Initiate the read region parity from disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *prd_rdNode;\n\n\t/* create DAG to read region parity from disk */\n\trf_MakeAllocList(*prd_alloclist);\n\t*prd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, NULL, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrp\", *prd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*prd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*prd_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*prd_pda)->row), &((*prd_pda)->col), &((*prd_pda)->startSector), &((*prd_pda)->numSector));\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reading %d sectors of parity from region %d]\\n\",\n\t\t    (int) (*prd_pda)->numSector, regionID);\n\tif ((*prd_pda)->next) {\n\t\t(*prd_pda)->next = NULL;\n\t\tprintf(\"set prd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*prd_dag_h)->tracerec = &tracerec;\n\tprd_rdNode = (*prd_dag_h)->succedents[0]->succedents[0];\n\tprd_rdNode->params[0].p = *prd_pda;\n\tprd_rdNode->params[1].p = parityBuffer;\n\tprd_rdNode->params[2].v = 0;\n\tprd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\tif (rf_validateDAGDebug)\n\t\trf_ValidateDAG(*prd_dag_h);\n\t/* launch region parity read dag */\n\trf_DispatchDAG(*prd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) prd_mcpair);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "prd_mcpair->mutex"
          ],
          "line": 375
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReintegrateRegion(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_ParityLog_t * coreLog)\n{\n\tRF_MCPair_t *rrd_mcpair = NULL, *prd_mcpair, *pwr_mcpair;\n\tRF_DagHeader_t *rrd_dag_h, *prd_dag_h, *pwr_dag_h;\n\tRF_AllocListElem_t *rrd_alloclist, *prd_alloclist, *pwr_alloclist;\n\tRF_PhysDiskAddr_t *rrd_pda, *prd_pda, *pwr_pda;\n\tcaddr_t parityBuffer, regionBuffer = NULL;\n\n\t/* Reintegrate a region (regionID). 1. acquire region and parity\n\t * buffers 2. read log from disk 3. read parity from disk 4. apply log\n\t * to parity 5. apply core log to parity 6. write new parity to disk\n\t * \n\t * BLOCKING */\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reintegrating region %d]\\n\", regionID);\n\n\t/* initiate read of region parity */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating read of parity for region %d]\\n\", regionID);\n\tparityBuffer = AcquireReintBuffer(&raidPtr->parityBufferPool);\n\tprd_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(prd_mcpair->mutex);\n\tprd_mcpair->flag = RF_FALSE;\n\tReadRegionParity(regionID, prd_mcpair, parityBuffer, raidPtr, &prd_dag_h, &prd_alloclist, &prd_pda);\n\n\t/* if region log nonempty, initiate read */\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating read of disk log for region %d]\\n\", regionID);\n\t\tregionBuffer = AcquireReintBuffer(&raidPtr->regionBufferPool);\n\t\trrd_mcpair = rf_AllocMCPair();\n\t\tRF_LOCK_MUTEX(rrd_mcpair->mutex);\n\t\trrd_mcpair->flag = RF_FALSE;\n\t\tReadRegionLog(regionID, rrd_mcpair, regionBuffer, raidPtr, &rrd_dag_h, &rrd_alloclist, &rrd_pda);\n\t}\n\t/* wait on read of region parity to complete */\n\twhile (!prd_mcpair->flag) {\n\t\tRF_WAIT_COND(prd_mcpair->cond, prd_mcpair->mutex);\n\t}\n\tRF_UNLOCK_MUTEX(prd_mcpair->mutex);\n\tif (prd_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to read parity from disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* apply core log to parity */\n\t/* if (coreLog) ApplyLogsToParity(coreLog, parityBuffer); */\n\n\tif (raidPtr->regionInfo[regionID].diskCount > 0) {\n\t\t/* wait on read of region log to complete */\n\t\twhile (!rrd_mcpair->flag)\n\t\t\tRF_WAIT_COND(rrd_mcpair->cond, rrd_mcpair->mutex);\n\t\tRF_UNLOCK_MUTEX(rrd_mcpair->mutex);\n\t\tif (rrd_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG(\"Unable to read region log from disk\\n\");\n\t\t\t/* add code to fail the log disk */\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* apply region log to parity */\n\t\t/* ApplyRegionToParity(regionID, regionBuffer, parityBuffer); */\n\t\t/* release resources associated with region log */\n\t\t/* RF_Free(rrd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(rrd_pda);\n\t\trf_FreeDAG(rrd_dag_h);\n\t\trf_FreeAllocList(rrd_alloclist);\n\t\trf_FreeMCPair(rrd_mcpair);\n\t\tReleaseReintBuffer(&raidPtr->regionBufferPool, regionBuffer);\n\t}\n\t/* write reintegrated parity to disk */\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[initiating write of parity for region %d]\\n\", regionID);\n\tpwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(pwr_mcpair->mutex);\n\tpwr_mcpair->flag = RF_FALSE;\n\tWriteRegionParity(regionID, pwr_mcpair, parityBuffer, raidPtr, &pwr_dag_h, &pwr_alloclist, &pwr_pda);\n\twhile (!pwr_mcpair->flag)\n\t\tRF_WAIT_COND(pwr_mcpair->cond, pwr_mcpair->mutex);\n\tRF_UNLOCK_MUTEX(pwr_mcpair->mutex);\n\tif (pwr_dag_h->status != rf_enable) {\n\t\tRF_ERRORMSG(\"Unable to write parity to disk\\n\");\n\t\t/* add code to fail the parity disk */\n\t\tRF_ASSERT(0);\n\t}\n\t/* release resources associated with read of old parity */\n\t/* RF_Free(prd_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(prd_pda);\n\trf_FreeDAG(prd_dag_h);\n\trf_FreeAllocList(prd_alloclist);\n\trf_FreeMCPair(prd_mcpair);\n\n\t/* release resources associated with write of new parity */\n\tReleaseReintBuffer(&raidPtr->parityBufferPool, parityBuffer);\n\t/* RF_Free(pwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\trf_FreePhysDiskAddr(pwr_pda);\n\trf_FreeDAG(pwr_dag_h);\n\trf_FreeAllocList(pwr_alloclist);\n\trf_FreeMCPair(pwr_mcpair);\n\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[finished reintegrating region %d]\\n\", regionID);\n}"
  },
  {
    "function_name": "FlushLogsToDisk",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "295-347",
    "snippet": "static void \nFlushLogsToDisk(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\t/* Flush a linked list of core logs to the log disk. Logs contain the\n\t * disk location where they should be written.  Logs were written in\n\t * FIFO order and that order must be preserved.\n\t * \n\t * Recommended optimizations: 1) allow multiple flushes to occur\n\t * simultaneously 2) coalesce contiguous flush operations\n\t * \n\t * BLOCKING */\n\n\tRF_ParityLog_t *log;\n\tRF_RegionId_t regionID;\n\tRF_MCPair_t *fwr_mcpair;\n\tRF_DagHeader_t *fwr_dag_h;\n\tRF_AllocListElem_t *fwr_alloclist;\n\tRF_PhysDiskAddr_t *fwr_pda;\n\n\tfwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(fwr_mcpair->mutex);\n\n\tRF_ASSERT(logList);\n\tlog = logList;\n\twhile (log) {\n\t\tregionID = log->regionID;\n\n\t\t/* create and launch a DAG to write the core log */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating write of core log for region %d]\\n\", regionID);\n\t\tfwr_mcpair->flag = RF_FALSE;\n\t\tWriteCoreLog(log, fwr_mcpair, raidPtr, &fwr_dag_h, &fwr_alloclist, &fwr_pda);\n\n\t\t/* wait for the DAG to complete */\n\t\twhile (!fwr_mcpair->flag)\n\t\t\tRF_WAIT_COND(fwr_mcpair->cond, fwr_mcpair->mutex);\n\t\tif (fwr_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG1(\"Unable to write core log to disk (region %d)\\n\", regionID);\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* RF_Free(fwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(fwr_pda);\n\t\trf_FreeDAG(fwr_dag_h);\n\t\trf_FreeAllocList(fwr_alloclist);\n\n\t\tlog = log->next;\n\t}\n\tRF_UNLOCK_MUTEX(fwr_mcpair->mutex);\n\trf_FreeMCPair(fwr_mcpair);\n\trf_ReleaseParityLogs(raidPtr, logList);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_ReleaseParityLogs",
          "args": [
            "raidPtr",
            "logList"
          ],
          "line": 346
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ReleaseParityLogs",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylog.c",
          "lines": "467-539",
          "snippet": "void \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_etimer.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_ReleaseParityLogs(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * firstLog)\n{\n\tRF_ParityLogData_t *logDataList;\n\tRF_ParityLog_t *log, *lastLog;\n\tint     cnt;\n\n\t/* Insert a linked list of parity logs (firstLog) to the free list\n\t * (parityLogPool.parityLogPool)\n\t * \n\t * NON-BLOCKING. */\n\n\tRF_ASSERT(firstLog);\n\n\t/* Before returning logs to global free list, service all requests\n\t * which are blocked on logs.  Holding mutexes for parityLogPool and\n\t * parityLogDiskQueue forces synchronization with AcquireParityLog(). */\n\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\tlog = firstLog;\n\tif (firstLog)\n\t\tfirstLog = firstLog->next;\n\tlog->numRecords = 0;\n\tlog->next = NULL;\n\twhile (logDataList && log) {\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\trf_ParityLogAppend(logDataList, RF_TRUE, &log, RF_FALSE);\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[finishing up buf-blocked log data, region %d]\\n\", logDataList->regionID);\n\t\tif (log == NULL) {\n\t\t\tlog = firstLog;\n\t\t\tif (firstLog) {\n\t\t\t\tfirstLog = firstLog->next;\n\t\t\t\tlog->numRecords = 0;\n\t\t\t\tlog->next = NULL;\n\t\t\t}\n\t\t}\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\t\tRF_LOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n\t\tif (log)\n\t\t\tlogDataList = DequeueMatchingLogData(raidPtr, &raidPtr->parityLogDiskQueue.logBlockHead, &raidPtr->parityLogDiskQueue.logBlockTail);\n\t}\n\t/* return remaining logs to pool */\n\tif (log) {\n\t\tlog->next = firstLog;\n\t\tfirstLog = log;\n\t}\n\tif (firstLog) {\n\t\tlastLog = firstLog;\n\t\traidPtr->logsInUse--;\n\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\twhile (lastLog->next) {\n\t\t\tlastLog = lastLog->next;\n\t\t\traidPtr->logsInUse--;\n\t\t\tRF_ASSERT(raidPtr->logsInUse >= 0 && raidPtr->logsInUse <= raidPtr->numParityLogs);\n\t\t}\n\t\tlastLog->next = raidPtr->parityLogPool.parityLogs;\n\t\traidPtr->parityLogPool.parityLogs = firstLog;\n\t\tcnt = 0;\n\t\tlog = raidPtr->parityLogPool.parityLogs;\n\t\twhile (log) {\n\t\t\tcnt++;\n\t\t\tlog = log->next;\n\t\t}\n\t\tRF_ASSERT(cnt + raidPtr->logsInUse == raidPtr->numParityLogs);\n\t}\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogPool.mutex);\n\tRF_UNLOCK_MUTEX(raidPtr->parityLogDiskQueue.mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreeMCPair",
          "args": [
            "fwr_mcpair"
          ],
          "line": 345
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeMCPair",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_mcpair.c",
          "lines": "125-130",
          "snippet": "void \nrf_FreeMCPair(t)\n\tRF_MCPair_t *t;\n{\n\tRF_FREELIST_FREE_CLEAN(rf_mcpair_freelist, t, next, clean_mcpair);\n}",
          "includes": [
            "#include <sys/proc.h>",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_mcpair_freelist;",
            "static int init_mcpair(RF_MCPair_t *);",
            "static void clean_mcpair(RF_MCPair_t *);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/proc.h>\n#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_mcpair_freelist;\nstatic int init_mcpair(RF_MCPair_t *);\nstatic void clean_mcpair(RF_MCPair_t *);\n\nvoid \nrf_FreeMCPair(t)\n\tRF_MCPair_t *t;\n{\n\tRF_FREELIST_FREE_CLEAN(rf_mcpair_freelist, t, next, clean_mcpair);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "fwr_mcpair->mutex"
          ],
          "line": 344
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_FreeAllocList",
          "args": [
            "fwr_alloclist"
          ],
          "line": 340
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeAllocList",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_alloclist.c",
          "lines": "139-164",
          "snippet": "void \nrf_FreeAllocList(l)\n\tRF_AllocListElem_t *l;\n{\n\tint     i;\n\tRF_AllocListElem_t *temp, *p;\n\n\tfor (p = l; p; p = p->next) {\n\t\tRF_ASSERT(p->numPointers >= 0 && p->numPointers <= RF_POINTERS_PER_ALLOC_LIST_ELEMENT);\n\t\tfor (i = 0; i < p->numPointers; i++) {\n\t\t\tRF_ASSERT(p->pointers[i]);\n\t\t\tRF_Free(p->pointers[i], p->sizes[i]);\n\t\t}\n\t}\n\twhile (l) {\n\t\ttemp = l;\n\t\tl = l->next;\n\t\tif (al_free_list_count > RF_AL_FREELIST_MAX) {\n\t\t\tDO_FREE(temp, sizeof(*temp));\n\t\t} else {\n\t\t\ttemp->next = al_free_list;\n\t\t\tal_free_list = temp;\n\t\t\tal_free_list_count++;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_alloclist.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define RF_AL_FREELIST_MAX 256"
          ],
          "globals_used": [
            "static RF_AllocListElem_t *al_free_list = NULL;",
            "static int al_free_list_count;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_alloclist.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define RF_AL_FREELIST_MAX 256\n\nstatic RF_AllocListElem_t *al_free_list = NULL;\nstatic int al_free_list_count;\n\nvoid \nrf_FreeAllocList(l)\n\tRF_AllocListElem_t *l;\n{\n\tint     i;\n\tRF_AllocListElem_t *temp, *p;\n\n\tfor (p = l; p; p = p->next) {\n\t\tRF_ASSERT(p->numPointers >= 0 && p->numPointers <= RF_POINTERS_PER_ALLOC_LIST_ELEMENT);\n\t\tfor (i = 0; i < p->numPointers; i++) {\n\t\t\tRF_ASSERT(p->pointers[i]);\n\t\t\tRF_Free(p->pointers[i], p->sizes[i]);\n\t\t}\n\t}\n\twhile (l) {\n\t\ttemp = l;\n\t\tl = l->next;\n\t\tif (al_free_list_count > RF_AL_FREELIST_MAX) {\n\t\t\tDO_FREE(temp, sizeof(*temp));\n\t\t} else {\n\t\t\ttemp->next = al_free_list;\n\t\t\tal_free_list = temp;\n\t\t\tal_free_list_count++;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreeDAG",
          "args": [
            "fwr_dag_h"
          ],
          "line": 339
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreeDAGHeader",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_dagutils.c",
          "lines": "257-261",
          "snippet": "void \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_PrintDAG(RF_DagHeader_t *);",
            "static void rf_ValidateVisitedBits(RF_DagHeader_t *);",
            "static RF_FreeList_t *rf_dagh_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_map.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void rf_PrintDAG(RF_DagHeader_t *);\nstatic void rf_ValidateVisitedBits(RF_DagHeader_t *);\nstatic RF_FreeList_t *rf_dagh_freelist;\n\nvoid \nrf_FreeDAGHeader(RF_DagHeader_t * dh)\n{\n\tRF_FREELIST_FREE(rf_dagh_freelist, dh, next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_FreePhysDiskAddr",
          "args": [
            "fwr_pda"
          ],
          "line": 338
        },
        "resolved": true,
        "details": {
          "function_name": "rf_FreePhysDiskAddr",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_map.c",
          "lines": "481-486",
          "snippet": "void \nrf_FreePhysDiskAddr(p)\n\tRF_PhysDiskAddr_t *p;\n{\n\tRF_FREELIST_FREE(rf_pda_freelist, p, next);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_pda_freelist;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_pda_freelist;\n\nvoid \nrf_FreePhysDiskAddr(p)\n\tRF_PhysDiskAddr_t *p;\n{\n\tRF_FREELIST_FREE(rf_pda_freelist, p, next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "0"
          ],
          "line": 335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ERRORMSG1",
          "args": [
            "\"Unable to write core log to disk (region %d)\\n\"",
            "regionID"
          ],
          "line": 334
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_WAIT_COND",
          "args": [
            "fwr_mcpair->cond",
            "fwr_mcpair->mutex"
          ],
          "line": 332
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WriteCoreLog",
          "args": [
            "log",
            "fwr_mcpair",
            "raidPtr",
            "&fwr_dag_h",
            "&fwr_alloclist",
            "&fwr_pda"
          ],
          "line": 328
        },
        "resolved": true,
        "details": {
          "function_name": "WriteCoreLog",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
          "lines": "155-199",
          "snippet": "static void \nWriteCoreLog(\n    RF_ParityLog_t * log,\n    RF_MCPair_t * fwr_mcpair,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** fwr_dag_h,\n    RF_AllocListElem_t ** fwr_alloclist,\n    RF_PhysDiskAddr_t ** fwr_pda)\n{\n\tRF_RegionId_t regionID = log->regionID;\n\tRF_AccTraceEntry_t tracerec;\n\tRF_SectorNum_t regionOffset;\n\tRF_DagNode_t *fwr_wrNode;\n\n\t/* Initiate the write of a core log to a region log disk. Once\n\t * initiated, return to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\t/* create DAG to write a core log to a region log disk */\n\trf_MakeAllocList(*fwr_alloclist);\n\t*fwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, log->bufPtr, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wcl\", *fwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the region log */\n\t/* RF_Malloc(*fwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*fwr_pda = rf_AllocPDAList(1);\n\tregionOffset = log->diskOffset;\n\trf_MapLogParityLogging(raidPtr, regionID, regionOffset, &((*fwr_pda)->row), &((*fwr_pda)->col), &((*fwr_pda)->startSector));\n\t(*fwr_pda)->numSector = raidPtr->numSectorsPerLog;\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*fwr_dag_h)->tracerec = &tracerec;\n\tfwr_wrNode = (*fwr_dag_h)->succedents[0]->succedents[0];\n\tfwr_wrNode->params[0].p = *fwr_pda;\n/*  fwr_wrNode->params[1] = log->bufPtr; */\n\tfwr_wrNode->params[2].v = 0;\n\tfwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write the core log to disk */\n\trf_DispatchDAG(*fwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) fwr_mcpair);\n}",
          "includes": [
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_parityscan.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_diskqueue.h\"",
            "#include \"rf_layout.h\"",
            "#include \"rf_desc.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nWriteCoreLog(\n    RF_ParityLog_t * log,\n    RF_MCPair_t * fwr_mcpair,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** fwr_dag_h,\n    RF_AllocListElem_t ** fwr_alloclist,\n    RF_PhysDiskAddr_t ** fwr_pda)\n{\n\tRF_RegionId_t regionID = log->regionID;\n\tRF_AccTraceEntry_t tracerec;\n\tRF_SectorNum_t regionOffset;\n\tRF_DagNode_t *fwr_wrNode;\n\n\t/* Initiate the write of a core log to a region log disk. Once\n\t * initiated, return to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\t/* create DAG to write a core log to a region log disk */\n\trf_MakeAllocList(*fwr_alloclist);\n\t*fwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, log->bufPtr, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wcl\", *fwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the region log */\n\t/* RF_Malloc(*fwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*fwr_pda = rf_AllocPDAList(1);\n\tregionOffset = log->diskOffset;\n\trf_MapLogParityLogging(raidPtr, regionID, regionOffset, &((*fwr_pda)->row), &((*fwr_pda)->col), &((*fwr_pda)->startSector));\n\t(*fwr_pda)->numSector = raidPtr->numSectorsPerLog;\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*fwr_dag_h)->tracerec = &tracerec;\n\tfwr_wrNode = (*fwr_dag_h)->succedents[0]->succedents[0];\n\tfwr_wrNode->params[0].p = *fwr_pda;\n/*  fwr_wrNode->params[1] = log->bufPtr; */\n\tfwr_wrNode->params[2].v = 0;\n\tfwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write the core log to disk */\n\trf_DispatchDAG(*fwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) fwr_mcpair);\n}"
        }
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"[initiating write of core log for region %d]\\n\"",
            "regionID"
          ],
          "line": 326
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "logList"
          ],
          "line": 319
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "fwr_mcpair->mutex"
          ],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_AllocMCPair",
          "args": [],
          "line": 316
        },
        "resolved": true,
        "details": {
          "function_name": "rf_AllocMCPair",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_mcpair.c",
          "lines": "112-123",
          "snippet": "RF_MCPair_t *\nrf_AllocMCPair()\n{\n\tRF_MCPair_t *t;\n\n\tRF_FREELIST_GET_INIT(rf_mcpair_freelist, t, next, (RF_MCPair_t *), init_mcpair);\n\tif (t) {\n\t\tt->flag = 0;\n\t\tt->next = NULL;\n\t}\n\treturn (t);\n}",
          "includes": [
            "#include <sys/proc.h>",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_debugMem.h\"",
            "#include \"rf_mcpair.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static RF_FreeList_t *rf_mcpair_freelist;",
            "static int init_mcpair(RF_MCPair_t *);",
            "static void clean_mcpair(RF_MCPair_t *);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/proc.h>\n#include \"rf_shutdown.h\"\n#include \"rf_freelist.h\"\n#include \"rf_debugMem.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\nstatic RF_FreeList_t *rf_mcpair_freelist;\nstatic int init_mcpair(RF_MCPair_t *);\nstatic void clean_mcpair(RF_MCPair_t *);\n\nRF_MCPair_t *\nrf_AllocMCPair()\n{\n\tRF_MCPair_t *t;\n\n\tRF_FREELIST_GET_INIT(rf_mcpair_freelist, t, next, (RF_MCPair_t *), init_mcpair);\n\tif (t) {\n\t\tt->flag = 0;\n\t\tt->next = NULL;\n\t}\n\treturn (t);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nFlushLogsToDisk(\n    RF_Raid_t * raidPtr,\n    RF_ParityLog_t * logList)\n{\n\t/* Flush a linked list of core logs to the log disk. Logs contain the\n\t * disk location where they should be written.  Logs were written in\n\t * FIFO order and that order must be preserved.\n\t * \n\t * Recommended optimizations: 1) allow multiple flushes to occur\n\t * simultaneously 2) coalesce contiguous flush operations\n\t * \n\t * BLOCKING */\n\n\tRF_ParityLog_t *log;\n\tRF_RegionId_t regionID;\n\tRF_MCPair_t *fwr_mcpair;\n\tRF_DagHeader_t *fwr_dag_h;\n\tRF_AllocListElem_t *fwr_alloclist;\n\tRF_PhysDiskAddr_t *fwr_pda;\n\n\tfwr_mcpair = rf_AllocMCPair();\n\tRF_LOCK_MUTEX(fwr_mcpair->mutex);\n\n\tRF_ASSERT(logList);\n\tlog = logList;\n\twhile (log) {\n\t\tregionID = log->regionID;\n\n\t\t/* create and launch a DAG to write the core log */\n\t\tif (rf_parityLogDebug)\n\t\t\tprintf(\"[initiating write of core log for region %d]\\n\", regionID);\n\t\tfwr_mcpair->flag = RF_FALSE;\n\t\tWriteCoreLog(log, fwr_mcpair, raidPtr, &fwr_dag_h, &fwr_alloclist, &fwr_pda);\n\n\t\t/* wait for the DAG to complete */\n\t\twhile (!fwr_mcpair->flag)\n\t\t\tRF_WAIT_COND(fwr_mcpair->cond, fwr_mcpair->mutex);\n\t\tif (fwr_dag_h->status != rf_enable) {\n\t\t\tRF_ERRORMSG1(\"Unable to write core log to disk (region %d)\\n\", regionID);\n\t\t\tRF_ASSERT(0);\n\t\t}\n\t\t/* RF_Free(fwr_pda, sizeof(RF_PhysDiskAddr_t)); */\n\t\trf_FreePhysDiskAddr(fwr_pda);\n\t\trf_FreeDAG(fwr_dag_h);\n\t\trf_FreeAllocList(fwr_alloclist);\n\n\t\tlog = log->next;\n\t}\n\tRF_UNLOCK_MUTEX(fwr_mcpair->mutex);\n\trf_FreeMCPair(fwr_mcpair);\n\trf_ReleaseParityLogs(raidPtr, logList);\n}"
  },
  {
    "function_name": "WriteRegionParity",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "252-293",
    "snippet": "static void \nWriteRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * pwr_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** pwr_dag_h,\n    RF_AllocListElem_t ** pwr_alloclist,\n    RF_PhysDiskAddr_t ** pwr_pda)\n{\n\t/* Initiate the write of region parity to disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *pwr_wrNode;\n\n\t/* create DAG to write region log from disk */\n\trf_MakeAllocList(*pwr_alloclist);\n\t*pwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, parityBuffer, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wrp\", *pwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*pwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*pwr_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*pwr_pda)->row), &((*pwr_pda)->col), &((*pwr_pda)->startSector), &((*pwr_pda)->numSector));\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*pwr_dag_h)->tracerec = &tracerec;\n\tpwr_wrNode = (*pwr_dag_h)->succedents[0]->succedents[0];\n\tpwr_wrNode->params[0].p = *pwr_pda;\n/*  pwr_wrNode->params[1] = parityBuffer; */\n\tpwr_wrNode->params[2].v = 0;\n\tpwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write region parity to disk */\n\trf_DispatchDAG(*pwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) pwr_mcpair);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_DispatchDAG",
          "args": [
            "*pwr_dag_h",
            "(void (*) (void *)) rf_MCPairWakeupFunc",
            "(void *) pwr_mcpair"
          ],
          "line": 291
        },
        "resolved": true,
        "details": {
          "function_name": "rf_DispatchDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_engine.c",
          "lines": "668-695",
          "snippet": "int \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_raid.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_dag.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_raid.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_engine.h\"\n#include \"rf_dag.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n\nint \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_CREATE_PARAM3",
          "args": [
            "RF_IO_NORMAL_PRIORITY",
            "0",
            "0",
            "0"
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bzero",
          "args": [
            "(char *) &tracerec",
            "sizeof(tracerec)"
          ],
          "line": 282
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MapRegionParity",
          "args": [
            "raidPtr",
            "regionID",
            "&((*pwr_pda)->row)",
            "&((*pwr_pda)->col)",
            "&((*pwr_pda)->startSector)",
            "&((*pwr_pda)->numSector)"
          ],
          "line": 279
        },
        "resolved": true,
        "details": {
          "function_name": "rf_MapRegionParity",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogging.c",
          "lines": "865-878",
          "snippet": "void \nrf_MapRegionParity(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector,\n    RF_SectorCount_t * numSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 2;\n\t*startSector = raidPtr->regionInfo[regionID].parityStartAddr;\n\t*numSector = raidPtr->regionInfo[regionID].numSectorsParity;\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_parityloggingdags.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_dagdegwr.h\"",
            "#include \"rf_dagdegrd.h\"",
            "#include \"rf_dagffwr.h\"",
            "#include \"rf_dagffrd.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_parityloggingdags.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_dagdegwr.h\"\n#include \"rf_dagdegrd.h\"\n#include \"rf_dagffwr.h\"\n#include \"rf_dagffrd.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_MapRegionParity(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector,\n    RF_SectorCount_t * numSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 2;\n\t*startSector = raidPtr->regionInfo[regionID].parityStartAddr;\n\t*numSector = raidPtr->regionInfo[regionID].numSectorsParity;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_AllocPDAList",
          "args": [
            "1"
          ],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeSimpleDAG",
          "args": [
            "raidPtr",
            "1",
            "0",
            "parityBuffer",
            "rf_DiskWriteFunc",
            "rf_DiskWriteUndoFunc",
            "\"Wrp\"",
            "*pwr_alloclist",
            "RF_DAG_FLAGS_NONE",
            "RF_IO_NORMAL_PRIORITY"
          ],
          "line": 272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeAllocList",
          "args": [
            "*pwr_alloclist"
          ],
          "line": 271
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nWriteRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * pwr_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** pwr_dag_h,\n    RF_AllocListElem_t ** pwr_alloclist,\n    RF_PhysDiskAddr_t ** pwr_pda)\n{\n\t/* Initiate the write of region parity to disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *pwr_wrNode;\n\n\t/* create DAG to write region log from disk */\n\trf_MakeAllocList(*pwr_alloclist);\n\t*pwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, parityBuffer, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wrp\", *pwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*pwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*pwr_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*pwr_pda)->row), &((*pwr_pda)->col), &((*pwr_pda)->startSector), &((*pwr_pda)->numSector));\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*pwr_dag_h)->tracerec = &tracerec;\n\tpwr_wrNode = (*pwr_dag_h)->succedents[0]->succedents[0];\n\tpwr_wrNode->params[0].p = *pwr_pda;\n/*  pwr_wrNode->params[1] = parityBuffer; */\n\tpwr_wrNode->params[2].v = 0;\n\tpwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write region parity to disk */\n\trf_DispatchDAG(*pwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) pwr_mcpair);\n}"
  },
  {
    "function_name": "ReadRegionParity",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "202-250",
    "snippet": "static void \nReadRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * prd_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** prd_dag_h,\n    RF_AllocListElem_t ** prd_alloclist,\n    RF_PhysDiskAddr_t ** prd_pda)\n{\n\t/* Initiate the read region parity from disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *prd_rdNode;\n\n\t/* create DAG to read region parity from disk */\n\trf_MakeAllocList(*prd_alloclist);\n\t*prd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, NULL, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrp\", *prd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*prd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*prd_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*prd_pda)->row), &((*prd_pda)->col), &((*prd_pda)->startSector), &((*prd_pda)->numSector));\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reading %d sectors of parity from region %d]\\n\",\n\t\t    (int) (*prd_pda)->numSector, regionID);\n\tif ((*prd_pda)->next) {\n\t\t(*prd_pda)->next = NULL;\n\t\tprintf(\"set prd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*prd_dag_h)->tracerec = &tracerec;\n\tprd_rdNode = (*prd_dag_h)->succedents[0]->succedents[0];\n\tprd_rdNode->params[0].p = *prd_pda;\n\tprd_rdNode->params[1].p = parityBuffer;\n\tprd_rdNode->params[2].v = 0;\n\tprd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\tif (rf_validateDAGDebug)\n\t\trf_ValidateDAG(*prd_dag_h);\n\t/* launch region parity read dag */\n\trf_DispatchDAG(*prd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) prd_mcpair);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_DispatchDAG",
          "args": [
            "*prd_dag_h",
            "(void (*) (void *)) rf_MCPairWakeupFunc",
            "(void *) prd_mcpair"
          ],
          "line": 248
        },
        "resolved": true,
        "details": {
          "function_name": "rf_DispatchDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_engine.c",
          "lines": "668-695",
          "snippet": "int \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_raid.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_dag.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_raid.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_engine.h\"\n#include \"rf_dag.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n\nint \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_ValidateDAG",
          "args": [
            "*prd_dag_h"
          ],
          "line": 246
        },
        "resolved": true,
        "details": {
          "function_name": "rf_ValidateDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_dagutils.c",
          "lines": "635-733",
          "snippet": "int \nrf_ValidateDAG(dag_h)\n\tRF_DagHeader_t *dag_h;\n{\n\tint     i, nodecount;\n\tint    *scount, *acount;/* per-node successor and antecedent counts */\n\tRF_DagNode_t **nodes;\t/* array of ptrs to nodes in dag */\n\tint     retcode = 0;\n\tint     unvisited;\n\tint     commitNodeCount = 0;\n\n\tif (rf_validateVisitedDebug)\n\t\trf_ValidateVisitedBits(dag_h);\n\n\tif (dag_h->numNodesCompleted != 0) {\n\t\tprintf(\"INVALID DAG: num nodes completed is %d, should be 0\\n\", dag_h->numNodesCompleted);\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tif (dag_h->status != rf_enable) {\n\t\tprintf(\"INVALID DAG: not enabled\\n\");\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tif (dag_h->numCommits != 0) {\n\t\tprintf(\"INVALID DAG: numCommits != 0 (%d)\\n\", dag_h->numCommits);\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tif (dag_h->numSuccedents != 1) {\n\t\t/* currently, all dags must have only one succedent */\n\t\tprintf(\"INVALID DAG: numSuccedents !1 (%d)\\n\", dag_h->numSuccedents);\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tnodecount = rf_AssignNodeNums(dag_h);\n\n\tunvisited = dag_h->succedents[0]->visited;\n\n\tRF_Calloc(scount, nodecount, sizeof(int), (int *));\n\tRF_Calloc(acount, nodecount, sizeof(int), (int *));\n\tRF_Calloc(nodes, nodecount, sizeof(RF_DagNode_t *), (RF_DagNode_t **));\n\tfor (i = 0; i < dag_h->numSuccedents; i++) {\n\t\tif ((dag_h->succedents[i]->visited == unvisited)\n\t\t    && rf_ValidateBranch(dag_h->succedents[i], scount,\n\t\t\tacount, nodes, unvisited)) {\n\t\t\tretcode = 1;\n\t\t}\n\t}\n\t/* start at 1 to skip the header node */\n\tfor (i = 1; i < nodecount; i++) {\n\t\tif (nodes[i]->commitNode)\n\t\t\tcommitNodeCount++;\n\t\tif (nodes[i]->doFunc == NULL) {\n\t\t\tprintf(\"INVALID DAG: node %s has an undefined doFunc\\n\", nodes[i]->name);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t\tif (nodes[i]->undoFunc == NULL) {\n\t\t\tprintf(\"INVALID DAG: node %s has an undefined doFunc\\n\", nodes[i]->name);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t\tif (nodes[i]->numAntecedents != scount[nodes[i]->nodeNum]) {\n\t\t\tprintf(\"INVALID DAG: node %s has %d antecedents but appears as a succedent %d times\\n\",\n\t\t\t    nodes[i]->name, nodes[i]->numAntecedents, scount[nodes[i]->nodeNum]);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t\tif (nodes[i]->numSuccedents != acount[nodes[i]->nodeNum]) {\n\t\t\tprintf(\"INVALID DAG: node %s has %d succedents but appears as an antecedent %d times\\n\",\n\t\t\t    nodes[i]->name, nodes[i]->numSuccedents, acount[nodes[i]->nodeNum]);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t}\n\n\tif (dag_h->numCommitNodes != commitNodeCount) {\n\t\tprintf(\"INVALID DAG: incorrect commit node count.  hdr->numCommitNodes (%d) found (%d) commit nodes in graph\\n\",\n\t\t    dag_h->numCommitNodes, commitNodeCount);\n\t\tretcode = 1;\n\t\tgoto validate_dag_out;\n\t}\nvalidate_dag_out:\n\tRF_Free(scount, nodecount * sizeof(int));\n\tRF_Free(acount, nodecount * sizeof(int));\n\tRF_Free(nodes, nodecount * sizeof(RF_DagNode_t *));\n\tif (retcode)\n\t\trf_PrintDAGList(dag_h);\n\n\tif (rf_validateVisitedDebug)\n\t\trf_ValidateVisitedBits(dag_h);\n\n\treturn (retcode);\n\nvalidate_dag_bad:\n\trf_PrintDAGList(dag_h);\n\treturn (retcode);\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_freelist.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void rf_RecurPrintDAG(RF_DagNode_t *, int, int);",
            "static void rf_PrintDAG(RF_DagHeader_t *);",
            "static int \nrf_ValidateBranch(RF_DagNode_t *, int *, int *,\n    RF_DagNode_t **, int);",
            "static void rf_ValidateBranchVisitedBits(RF_DagNode_t *, int, int);",
            "static void rf_ValidateVisitedBits(RF_DagHeader_t *);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_map.h\"\n#include \"rf_freelist.h\"\n#include \"rf_general.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void rf_RecurPrintDAG(RF_DagNode_t *, int, int);\nstatic void rf_PrintDAG(RF_DagHeader_t *);\nstatic int \nrf_ValidateBranch(RF_DagNode_t *, int *, int *,\n    RF_DagNode_t **, int);\nstatic void rf_ValidateBranchVisitedBits(RF_DagNode_t *, int, int);\nstatic void rf_ValidateVisitedBits(RF_DagHeader_t *);\n\nint \nrf_ValidateDAG(dag_h)\n\tRF_DagHeader_t *dag_h;\n{\n\tint     i, nodecount;\n\tint    *scount, *acount;/* per-node successor and antecedent counts */\n\tRF_DagNode_t **nodes;\t/* array of ptrs to nodes in dag */\n\tint     retcode = 0;\n\tint     unvisited;\n\tint     commitNodeCount = 0;\n\n\tif (rf_validateVisitedDebug)\n\t\trf_ValidateVisitedBits(dag_h);\n\n\tif (dag_h->numNodesCompleted != 0) {\n\t\tprintf(\"INVALID DAG: num nodes completed is %d, should be 0\\n\", dag_h->numNodesCompleted);\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tif (dag_h->status != rf_enable) {\n\t\tprintf(\"INVALID DAG: not enabled\\n\");\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tif (dag_h->numCommits != 0) {\n\t\tprintf(\"INVALID DAG: numCommits != 0 (%d)\\n\", dag_h->numCommits);\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tif (dag_h->numSuccedents != 1) {\n\t\t/* currently, all dags must have only one succedent */\n\t\tprintf(\"INVALID DAG: numSuccedents !1 (%d)\\n\", dag_h->numSuccedents);\n\t\tretcode = 1;\n\t\tgoto validate_dag_bad;\n\t}\n\tnodecount = rf_AssignNodeNums(dag_h);\n\n\tunvisited = dag_h->succedents[0]->visited;\n\n\tRF_Calloc(scount, nodecount, sizeof(int), (int *));\n\tRF_Calloc(acount, nodecount, sizeof(int), (int *));\n\tRF_Calloc(nodes, nodecount, sizeof(RF_DagNode_t *), (RF_DagNode_t **));\n\tfor (i = 0; i < dag_h->numSuccedents; i++) {\n\t\tif ((dag_h->succedents[i]->visited == unvisited)\n\t\t    && rf_ValidateBranch(dag_h->succedents[i], scount,\n\t\t\tacount, nodes, unvisited)) {\n\t\t\tretcode = 1;\n\t\t}\n\t}\n\t/* start at 1 to skip the header node */\n\tfor (i = 1; i < nodecount; i++) {\n\t\tif (nodes[i]->commitNode)\n\t\t\tcommitNodeCount++;\n\t\tif (nodes[i]->doFunc == NULL) {\n\t\t\tprintf(\"INVALID DAG: node %s has an undefined doFunc\\n\", nodes[i]->name);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t\tif (nodes[i]->undoFunc == NULL) {\n\t\t\tprintf(\"INVALID DAG: node %s has an undefined doFunc\\n\", nodes[i]->name);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t\tif (nodes[i]->numAntecedents != scount[nodes[i]->nodeNum]) {\n\t\t\tprintf(\"INVALID DAG: node %s has %d antecedents but appears as a succedent %d times\\n\",\n\t\t\t    nodes[i]->name, nodes[i]->numAntecedents, scount[nodes[i]->nodeNum]);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t\tif (nodes[i]->numSuccedents != acount[nodes[i]->nodeNum]) {\n\t\t\tprintf(\"INVALID DAG: node %s has %d succedents but appears as an antecedent %d times\\n\",\n\t\t\t    nodes[i]->name, nodes[i]->numSuccedents, acount[nodes[i]->nodeNum]);\n\t\t\tretcode = 1;\n\t\t\tgoto validate_dag_out;\n\t\t}\n\t}\n\n\tif (dag_h->numCommitNodes != commitNodeCount) {\n\t\tprintf(\"INVALID DAG: incorrect commit node count.  hdr->numCommitNodes (%d) found (%d) commit nodes in graph\\n\",\n\t\t    dag_h->numCommitNodes, commitNodeCount);\n\t\tretcode = 1;\n\t\tgoto validate_dag_out;\n\t}\nvalidate_dag_out:\n\tRF_Free(scount, nodecount * sizeof(int));\n\tRF_Free(acount, nodecount * sizeof(int));\n\tRF_Free(nodes, nodecount * sizeof(RF_DagNode_t *));\n\tif (retcode)\n\t\trf_PrintDAGList(dag_h);\n\n\tif (rf_validateVisitedDebug)\n\t\trf_ValidateVisitedBits(dag_h);\n\n\treturn (retcode);\n\nvalidate_dag_bad:\n\trf_PrintDAGList(dag_h);\n\treturn (retcode);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_CREATE_PARAM3",
          "args": [
            "RF_IO_NORMAL_PRIORITY",
            "0",
            "0",
            "0"
          ],
          "line": 244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bzero",
          "args": [
            "(char *) &tracerec",
            "sizeof(tracerec)"
          ],
          "line": 238
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"set prd_pda->next to NULL\\n\""
          ],
          "line": 235
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_MapRegionParity",
          "args": [
            "raidPtr",
            "regionID",
            "&((*prd_pda)->row)",
            "&((*prd_pda)->col)",
            "&((*prd_pda)->startSector)",
            "&((*prd_pda)->numSector)"
          ],
          "line": 229
        },
        "resolved": true,
        "details": {
          "function_name": "rf_MapRegionParity",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogging.c",
          "lines": "865-878",
          "snippet": "void \nrf_MapRegionParity(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector,\n    RF_SectorCount_t * numSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 2;\n\t*startSector = raidPtr->regionInfo[regionID].parityStartAddr;\n\t*numSector = raidPtr->regionInfo[regionID].numSectorsParity;\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_parityloggingdags.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_dagdegwr.h\"",
            "#include \"rf_dagdegrd.h\"",
            "#include \"rf_dagffwr.h\"",
            "#include \"rf_dagffrd.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_parityloggingdags.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_dagdegwr.h\"\n#include \"rf_dagdegrd.h\"\n#include \"rf_dagffwr.h\"\n#include \"rf_dagffrd.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_MapRegionParity(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector,\n    RF_SectorCount_t * numSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 2;\n\t*startSector = raidPtr->regionInfo[regionID].parityStartAddr;\n\t*numSector = raidPtr->regionInfo[regionID].numSectorsParity;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_AllocPDAList",
          "args": [
            "1"
          ],
          "line": 228
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeSimpleDAG",
          "args": [
            "raidPtr",
            "1",
            "0",
            "NULL",
            "rf_DiskReadFunc",
            "rf_DiskReadUndoFunc",
            "\"Rrp\"",
            "*prd_alloclist",
            "RF_DAG_FLAGS_NONE",
            "RF_IO_NORMAL_PRIORITY"
          ],
          "line": 222
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeAllocList",
          "args": [
            "*prd_alloclist"
          ],
          "line": 221
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReadRegionParity(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * prd_mcpair,\n    caddr_t parityBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** prd_dag_h,\n    RF_AllocListElem_t ** prd_alloclist,\n    RF_PhysDiskAddr_t ** prd_pda)\n{\n\t/* Initiate the read region parity from disk. Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *prd_rdNode;\n\n\t/* create DAG to read region parity from disk */\n\trf_MakeAllocList(*prd_alloclist);\n\t*prd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, NULL, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrp\", *prd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for region parity */\n\t/* RF_Malloc(*prd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*prd_pda = rf_AllocPDAList(1);\n\trf_MapRegionParity(raidPtr, regionID, &((*prd_pda)->row), &((*prd_pda)->col), &((*prd_pda)->startSector), &((*prd_pda)->numSector));\n\tif (rf_parityLogDebug)\n\t\tprintf(\"[reading %d sectors of parity from region %d]\\n\",\n\t\t    (int) (*prd_pda)->numSector, regionID);\n\tif ((*prd_pda)->next) {\n\t\t(*prd_pda)->next = NULL;\n\t\tprintf(\"set prd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*prd_dag_h)->tracerec = &tracerec;\n\tprd_rdNode = (*prd_dag_h)->succedents[0]->succedents[0];\n\tprd_rdNode->params[0].p = *prd_pda;\n\tprd_rdNode->params[1].p = parityBuffer;\n\tprd_rdNode->params[2].v = 0;\n\tprd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\tif (rf_validateDAGDebug)\n\t\trf_ValidateDAG(*prd_dag_h);\n\t/* launch region parity read dag */\n\trf_DispatchDAG(*prd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) prd_mcpair);\n}"
  },
  {
    "function_name": "WriteCoreLog",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "155-199",
    "snippet": "static void \nWriteCoreLog(\n    RF_ParityLog_t * log,\n    RF_MCPair_t * fwr_mcpair,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** fwr_dag_h,\n    RF_AllocListElem_t ** fwr_alloclist,\n    RF_PhysDiskAddr_t ** fwr_pda)\n{\n\tRF_RegionId_t regionID = log->regionID;\n\tRF_AccTraceEntry_t tracerec;\n\tRF_SectorNum_t regionOffset;\n\tRF_DagNode_t *fwr_wrNode;\n\n\t/* Initiate the write of a core log to a region log disk. Once\n\t * initiated, return to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\t/* create DAG to write a core log to a region log disk */\n\trf_MakeAllocList(*fwr_alloclist);\n\t*fwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, log->bufPtr, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wcl\", *fwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the region log */\n\t/* RF_Malloc(*fwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*fwr_pda = rf_AllocPDAList(1);\n\tregionOffset = log->diskOffset;\n\trf_MapLogParityLogging(raidPtr, regionID, regionOffset, &((*fwr_pda)->row), &((*fwr_pda)->col), &((*fwr_pda)->startSector));\n\t(*fwr_pda)->numSector = raidPtr->numSectorsPerLog;\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*fwr_dag_h)->tracerec = &tracerec;\n\tfwr_wrNode = (*fwr_dag_h)->succedents[0]->succedents[0];\n\tfwr_wrNode->params[0].p = *fwr_pda;\n/*  fwr_wrNode->params[1] = log->bufPtr; */\n\tfwr_wrNode->params[2].v = 0;\n\tfwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write the core log to disk */\n\trf_DispatchDAG(*fwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) fwr_mcpair);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_DispatchDAG",
          "args": [
            "*fwr_dag_h",
            "(void (*) (void *)) rf_MCPairWakeupFunc",
            "(void *) fwr_mcpair"
          ],
          "line": 197
        },
        "resolved": true,
        "details": {
          "function_name": "rf_DispatchDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_engine.c",
          "lines": "668-695",
          "snippet": "int \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_raid.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_dag.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_raid.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_engine.h\"\n#include \"rf_dag.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n\nint \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_CREATE_PARAM3",
          "args": [
            "RF_IO_NORMAL_PRIORITY",
            "0",
            "0",
            "0"
          ],
          "line": 194
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bzero",
          "args": [
            "(char *) &tracerec",
            "sizeof(tracerec)"
          ],
          "line": 188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MapLogParityLogging",
          "args": [
            "raidPtr",
            "regionID",
            "regionOffset",
            "&((*fwr_pda)->row)",
            "&((*fwr_pda)->col)",
            "&((*fwr_pda)->startSector)"
          ],
          "line": 184
        },
        "resolved": true,
        "details": {
          "function_name": "rf_MapLogParityLogging",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogging.c",
          "lines": "848-860",
          "snippet": "void \nrf_MapLogParityLogging(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_SectorNum_t regionOffset,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 1;\n\t*startSector = raidPtr->regionInfo[regionID].regionStartAddr + regionOffset;\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_parityloggingdags.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_dagdegwr.h\"",
            "#include \"rf_dagdegrd.h\"",
            "#include \"rf_dagffwr.h\"",
            "#include \"rf_dagffrd.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_parityloggingdags.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_dagdegwr.h\"\n#include \"rf_dagdegrd.h\"\n#include \"rf_dagffwr.h\"\n#include \"rf_dagffrd.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_MapLogParityLogging(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_SectorNum_t regionOffset,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 1;\n\t*startSector = raidPtr->regionInfo[regionID].regionStartAddr + regionOffset;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_AllocPDAList",
          "args": [
            "1"
          ],
          "line": 182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeSimpleDAG",
          "args": [
            "raidPtr",
            "1",
            "0",
            "log->bufPtr",
            "rf_DiskWriteFunc",
            "rf_DiskWriteUndoFunc",
            "\"Wcl\"",
            "*fwr_alloclist",
            "RF_DAG_FLAGS_NONE",
            "RF_IO_NORMAL_PRIORITY"
          ],
          "line": 176
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeAllocList",
          "args": [
            "*fwr_alloclist"
          ],
          "line": 175
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nWriteCoreLog(\n    RF_ParityLog_t * log,\n    RF_MCPair_t * fwr_mcpair,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** fwr_dag_h,\n    RF_AllocListElem_t ** fwr_alloclist,\n    RF_PhysDiskAddr_t ** fwr_pda)\n{\n\tRF_RegionId_t regionID = log->regionID;\n\tRF_AccTraceEntry_t tracerec;\n\tRF_SectorNum_t regionOffset;\n\tRF_DagNode_t *fwr_wrNode;\n\n\t/* Initiate the write of a core log to a region log disk. Once\n\t * initiated, return to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\t/* create DAG to write a core log to a region log disk */\n\trf_MakeAllocList(*fwr_alloclist);\n\t*fwr_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, log->bufPtr, rf_DiskWriteFunc, rf_DiskWriteUndoFunc,\n\t    \"Wcl\", *fwr_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the region log */\n\t/* RF_Malloc(*fwr_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*fwr_pda = rf_AllocPDAList(1);\n\tregionOffset = log->diskOffset;\n\trf_MapLogParityLogging(raidPtr, regionID, regionOffset, &((*fwr_pda)->row), &((*fwr_pda)->col), &((*fwr_pda)->startSector));\n\t(*fwr_pda)->numSector = raidPtr->numSectorsPerLog;\n\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*fwr_dag_h)->tracerec = &tracerec;\n\tfwr_wrNode = (*fwr_dag_h)->succedents[0]->succedents[0];\n\tfwr_wrNode->params[0].p = *fwr_pda;\n/*  fwr_wrNode->params[1] = log->bufPtr; */\n\tfwr_wrNode->params[2].v = 0;\n\tfwr_wrNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch the dag to write the core log to disk */\n\trf_DispatchDAG(*fwr_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) fwr_mcpair);\n}"
  },
  {
    "function_name": "ReadRegionLog",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "105-151",
    "snippet": "static void \nReadRegionLog(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * rrd_mcpair,\n    caddr_t regionBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** rrd_dag_h,\n    RF_AllocListElem_t ** rrd_alloclist,\n    RF_PhysDiskAddr_t ** rrd_pda)\n{\n\t/* Initiate the read a region log from disk.  Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *rrd_rdNode;\n\n\t/* create DAG to read region log from disk */\n\trf_MakeAllocList(*rrd_alloclist);\n\t*rrd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, regionBuffer, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrl\", *rrd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the core log */\n\t/* RF_Malloc(*rrd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*rrd_pda = rf_AllocPDAList(1);\n\trf_MapLogParityLogging(raidPtr, regionID, 0, &((*rrd_pda)->row), &((*rrd_pda)->col), &((*rrd_pda)->startSector));\n\t(*rrd_pda)->numSector = raidPtr->regionInfo[regionID].capacity;\n\n\tif ((*rrd_pda)->next) {\n\t\t(*rrd_pda)->next = NULL;\n\t\tprintf(\"set rrd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*rrd_dag_h)->tracerec = &tracerec;\n\trrd_rdNode = (*rrd_dag_h)->succedents[0]->succedents[0];\n\trrd_rdNode->params[0].p = *rrd_pda;\n/*  rrd_rdNode->params[1] = regionBuffer; */\n\trrd_rdNode->params[2].v = 0;\n\trrd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch region log read dag */\n\trf_DispatchDAG(*rrd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) rrd_mcpair);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rf_DispatchDAG",
          "args": [
            "*rrd_dag_h",
            "(void (*) (void *)) rf_MCPairWakeupFunc",
            "(void *) rrd_mcpair"
          ],
          "line": 149
        },
        "resolved": true,
        "details": {
          "function_name": "rf_DispatchDAG",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_engine.c",
          "lines": "668-695",
          "snippet": "int \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}",
          "includes": [
            "#include \"rf_raid.h\"",
            "#include \"rf_shutdown.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_etimer.h\"",
            "#include \"rf_engine.h\"",
            "#include \"rf_dag.h\"",
            "#include <sys/errno.h>",
            "#include \"rf_threadstuff.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_raid.h\"\n#include \"rf_shutdown.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_general.h\"\n#include \"rf_etimer.h\"\n#include \"rf_engine.h\"\n#include \"rf_dag.h\"\n#include <sys/errno.h>\n#include \"rf_threadstuff.h\"\n\nint \nrf_DispatchDAG(\n    RF_DagHeader_t * dag,\n    void (*cbFunc) (void *),\n    void *cbArg)\n{\n\tRF_Raid_t *raidPtr;\n\n\traidPtr = dag->raidPtr;\n\tif (dag->tracerec) {\n\t\tRF_ETIMER_START(dag->tracerec->timer);\n\t}\n\tif (rf_engineDebug || rf_validateDAGDebug) {\n\t\tif (rf_ValidateDAG(dag))\n\t\t\tRF_PANIC();\n\t}\n\tif (rf_engineDebug) {\n\t\tprintf(\"raid%d: Entering DispatchDAG\\n\", raidPtr->raidid);\n\t}\n\traidPtr->dags_in_flight++;\t/* debug only:  blow off proper\n\t\t\t\t\t * locking */\n\tdag->cbFunc = cbFunc;\n\tdag->cbArg = cbArg;\n\tdag->numNodesCompleted = 0;\n\tdag->status = rf_enable;\n\tFireNodeArray(dag->numSuccedents, dag->succedents);\n\treturn (1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RF_CREATE_PARAM3",
          "args": [
            "RF_IO_NORMAL_PRIORITY",
            "0",
            "0",
            "0"
          ],
          "line": 146
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bzero",
          "args": [
            "(char *) &tracerec",
            "sizeof(tracerec)"
          ],
          "line": 140
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "printf",
          "args": [
            "\"set rrd_pda->next to NULL\\n\""
          ],
          "line": 137
        },
        "resolved": true,
        "details": {
          "function_name": "rf_debug_printf",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_debugprint.c",
          "lines": "82-108",
          "snippet": "void \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}",
          "includes": [
            "#include <sys/param.h>",
            "#include \"rf_options.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_debugprint.h\"",
            "#include \"rf_threadstuff.h\"",
            "#include \"rf_types.h\""
          ],
          "macros_used": [
            "#define BUFMASK  (BUFSIZE-1)"
          ],
          "globals_used": [
            "static struct RF_Entry_s rf_debugprint_buf[BUFSIZE];",
            "static int rf_debugprint_index = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <sys/param.h>\n#include \"rf_options.h\"\n#include \"rf_general.h\"\n#include \"rf_debugprint.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n\n#define BUFMASK  (BUFSIZE-1)\n\nstatic struct RF_Entry_s rf_debugprint_buf[BUFSIZE];\nstatic int rf_debugprint_index = 0;\n\nvoid \nrf_debug_printf(s, a1, a2, a3, a4, a5, a6, a7, a8)\n\tchar   *s;\n\tvoid   *a1, *a2, *a3, *a4, *a5, *a6, *a7, *a8;\n{\n\tint     idx;\n\n\tif (rf_debugPrintUseBuffer) {\n\n\t\tRF_LOCK_MUTEX(rf_debug_print_mutex);\n\t\tidx = rf_debugprint_index;\n\t\trf_debugprint_index = (rf_debugprint_index + 1) & BUFMASK;\n\t\tRF_UNLOCK_MUTEX(rf_debug_print_mutex);\n\n\t\trf_debugprint_buf[idx].cstring = s;\n\t\trf_debugprint_buf[idx].a1 = a1;\n\t\trf_debugprint_buf[idx].a2 = a2;\n\t\trf_debugprint_buf[idx].a3 = a3;\n\t\trf_debugprint_buf[idx].a4 = a4;\n\t\trf_debugprint_buf[idx].a5 = a5;\n\t\trf_debugprint_buf[idx].a6 = a6;\n\t\trf_debugprint_buf[idx].a7 = a7;\n\t\trf_debugprint_buf[idx].a8 = a8;\n\t} else {\n\t\tprintf(s, a1, a2, a3, a4, a5, a6, a7, a8);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_MapLogParityLogging",
          "args": [
            "raidPtr",
            "regionID",
            "0",
            "&((*rrd_pda)->row)",
            "&((*rrd_pda)->col)",
            "&((*rrd_pda)->startSector)"
          ],
          "line": 132
        },
        "resolved": true,
        "details": {
          "function_name": "rf_MapLogParityLogging",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogging.c",
          "lines": "848-860",
          "snippet": "void \nrf_MapLogParityLogging(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_SectorNum_t regionOffset,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 1;\n\t*startSector = raidPtr->regionInfo[regionID].regionStartAddr + regionOffset;\n}",
          "includes": [
            "#include \"rf_shutdown.h\"",
            "#include \"rf_utils.h\"",
            "#include \"rf_map.h\"",
            "#include \"rf_general.h\"",
            "#include \"rf_parityloggingdags.h\"",
            "#include \"rf_paritylogging.h\"",
            "#include \"rf_paritylogDiskMgr.h\"",
            "#include \"rf_paritylog.h\"",
            "#include \"rf_dagdegwr.h\"",
            "#include \"rf_dagdegrd.h\"",
            "#include \"rf_dagffwr.h\"",
            "#include \"rf_dagffrd.h\"",
            "#include \"rf_dagfuncs.h\"",
            "#include \"rf_dagutils.h\"",
            "#include \"rf_dag.h\"",
            "#include \"rf_raid.h\"",
            "#include \"rf_types.h\"",
            "#include \"rf_archs.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rf_shutdown.h\"\n#include \"rf_utils.h\"\n#include \"rf_map.h\"\n#include \"rf_general.h\"\n#include \"rf_parityloggingdags.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_dagdegwr.h\"\n#include \"rf_dagdegrd.h\"\n#include \"rf_dagffwr.h\"\n#include \"rf_dagffrd.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nvoid \nrf_MapLogParityLogging(\n    RF_Raid_t * raidPtr,\n    RF_RegionId_t regionID,\n    RF_SectorNum_t regionOffset,\n    RF_RowCol_t * row,\n    RF_RowCol_t * col,\n    RF_SectorNum_t * startSector)\n{\n\t*row = 0;\n\t*col = raidPtr->numCol - 1;\n\t*startSector = raidPtr->regionInfo[regionID].regionStartAddr + regionOffset;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rf_AllocPDAList",
          "args": [
            "1"
          ],
          "line": 131
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeSimpleDAG",
          "args": [
            "raidPtr",
            "1",
            "0",
            "regionBuffer",
            "rf_DiskReadFunc",
            "rf_DiskReadUndoFunc",
            "\"Rrl\"",
            "*rrd_alloclist",
            "RF_DAG_FLAGS_NONE",
            "RF_IO_NORMAL_PRIORITY"
          ],
          "line": 125
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rf_MakeAllocList",
          "args": [
            "*rrd_alloclist"
          ],
          "line": 124
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReadRegionLog(\n    RF_RegionId_t regionID,\n    RF_MCPair_t * rrd_mcpair,\n    caddr_t regionBuffer,\n    RF_Raid_t * raidPtr,\n    RF_DagHeader_t ** rrd_dag_h,\n    RF_AllocListElem_t ** rrd_alloclist,\n    RF_PhysDiskAddr_t ** rrd_pda)\n{\n\t/* Initiate the read a region log from disk.  Once initiated, return\n\t * to the calling routine.\n\t * \n\t * NON-BLOCKING */\n\n\tRF_AccTraceEntry_t tracerec;\n\tRF_DagNode_t *rrd_rdNode;\n\n\t/* create DAG to read region log from disk */\n\trf_MakeAllocList(*rrd_alloclist);\n\t*rrd_dag_h = rf_MakeSimpleDAG(raidPtr, 1, 0, regionBuffer, rf_DiskReadFunc, rf_DiskReadUndoFunc,\n\t    \"Rrl\", *rrd_alloclist, RF_DAG_FLAGS_NONE, RF_IO_NORMAL_PRIORITY);\n\n\t/* create and initialize PDA for the core log */\n\t/* RF_Malloc(*rrd_pda, sizeof(RF_PhysDiskAddr_t), (RF_PhysDiskAddr_t\n\t * *)); */\n\t*rrd_pda = rf_AllocPDAList(1);\n\trf_MapLogParityLogging(raidPtr, regionID, 0, &((*rrd_pda)->row), &((*rrd_pda)->col), &((*rrd_pda)->startSector));\n\t(*rrd_pda)->numSector = raidPtr->regionInfo[regionID].capacity;\n\n\tif ((*rrd_pda)->next) {\n\t\t(*rrd_pda)->next = NULL;\n\t\tprintf(\"set rrd_pda->next to NULL\\n\");\n\t}\n\t/* initialize DAG parameters */\n\tbzero((char *) &tracerec, sizeof(tracerec));\n\t(*rrd_dag_h)->tracerec = &tracerec;\n\trrd_rdNode = (*rrd_dag_h)->succedents[0]->succedents[0];\n\trrd_rdNode->params[0].p = *rrd_pda;\n/*  rrd_rdNode->params[1] = regionBuffer; */\n\trrd_rdNode->params[2].v = 0;\n\trrd_rdNode->params[3].v = RF_CREATE_PARAM3(RF_IO_NORMAL_PRIORITY, 0, 0, 0);\n\n\t/* launch region log read dag */\n\trf_DispatchDAG(*rrd_dag_h, (void (*) (void *)) rf_MCPairWakeupFunc,\n\t    (void *) rrd_mcpair);\n}"
  },
  {
    "function_name": "ReleaseReintBuffer",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "84-101",
    "snippet": "static void \nReleaseReintBuffer(\n    RF_RegionBufferQueue_t * pool,\n    caddr_t bufPtr)\n{\n\t/* Insert a region buffer (bufPtr) into the free list (pool).\n\t * NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tpool->availableBuffers++;\n\tpool->buffers[pool->emptyBuffersIndex] = bufPtr;\n\tpool->emptyBuffersIndex++;\n\tif (pool->emptyBuffersIndex == pool->totalBuffers)\n\t\tpool->emptyBuffersIndex = 0;\n\tRF_ASSERT(pool->availableBuffers <= pool->totalBuffers);\n\tRF_UNLOCK_MUTEX(pool->mutex);\n\tRF_SIGNAL_COND(pool->cond);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_SIGNAL_COND",
          "args": [
            "pool->cond"
          ],
          "line": 100
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "pool->mutex"
          ],
          "line": 99
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_ASSERT",
          "args": [
            "pool->availableBuffers <= pool->totalBuffers"
          ],
          "line": 98
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "pool->mutex"
          ],
          "line": 92
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic void \nReleaseReintBuffer(\n    RF_RegionBufferQueue_t * pool,\n    caddr_t bufPtr)\n{\n\t/* Insert a region buffer (bufPtr) into the free list (pool).\n\t * NON-BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tpool->availableBuffers++;\n\tpool->buffers[pool->emptyBuffersIndex] = bufPtr;\n\tpool->emptyBuffersIndex++;\n\tif (pool->emptyBuffersIndex == pool->totalBuffers)\n\t\tpool->emptyBuffersIndex = 0;\n\tRF_ASSERT(pool->availableBuffers <= pool->totalBuffers);\n\tRF_UNLOCK_MUTEX(pool->mutex);\n\tRF_SIGNAL_COND(pool->cond);\n}"
  },
  {
    "function_name": "AcquireReintBuffer",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c_ICV/CVE-2023-40216/repo/sys/dev/raidframe/rf_paritylogDiskMgr.c",
    "lines": "59-82",
    "snippet": "static caddr_t \nAcquireReintBuffer(pool)\n\tRF_RegionBufferQueue_t *pool;\n{\n\tcaddr_t bufPtr = NULL;\n\n\t/* Return a region buffer from the free list (pool). If the free list\n\t * is empty, WAIT. BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tif (pool->availableBuffers > 0) {\n\t\tbufPtr = pool->buffers[pool->availBuffersIndex];\n\t\tpool->availableBuffers--;\n\t\tpool->availBuffersIndex++;\n\t\tif (pool->availBuffersIndex == pool->totalBuffers)\n\t\t\tpool->availBuffersIndex = 0;\n\t\tRF_UNLOCK_MUTEX(pool->mutex);\n\t} else {\n\t\tRF_PANIC();\t/* should never happen in currect config,\n\t\t\t\t * single reint */\n\t\tRF_WAIT_COND(pool->cond, pool->mutex);\n\t}\n\treturn (bufPtr);\n}",
    "includes": [
      "#include \"rf_paritylogDiskMgr.h\"",
      "#include \"rf_parityscan.h\"",
      "#include \"rf_map.h\"",
      "#include \"rf_dagutils.h\"",
      "#include \"rf_engine.h\"",
      "#include \"rf_paritylogging.h\"",
      "#include \"rf_etimer.h\"",
      "#include \"rf_general.h\"",
      "#include \"rf_paritylog.h\"",
      "#include \"rf_diskqueue.h\"",
      "#include \"rf_layout.h\"",
      "#include \"rf_desc.h\"",
      "#include \"rf_dagfuncs.h\"",
      "#include \"rf_dag.h\"",
      "#include \"rf_raid.h\"",
      "#include \"rf_mcpair.h\"",
      "#include \"rf_threadstuff.h\"",
      "#include \"rf_types.h\"",
      "#include \"rf_archs.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "RF_WAIT_COND",
          "args": [
            "pool->cond",
            "pool->mutex"
          ],
          "line": 79
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_PANIC",
          "args": [],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_UNLOCK_MUTEX",
          "args": [
            "pool->mutex"
          ],
          "line": 75
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RF_LOCK_MUTEX",
          "args": [
            "pool->mutex"
          ],
          "line": 68
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rf_paritylogDiskMgr.h\"\n#include \"rf_parityscan.h\"\n#include \"rf_map.h\"\n#include \"rf_dagutils.h\"\n#include \"rf_engine.h\"\n#include \"rf_paritylogging.h\"\n#include \"rf_etimer.h\"\n#include \"rf_general.h\"\n#include \"rf_paritylog.h\"\n#include \"rf_diskqueue.h\"\n#include \"rf_layout.h\"\n#include \"rf_desc.h\"\n#include \"rf_dagfuncs.h\"\n#include \"rf_dag.h\"\n#include \"rf_raid.h\"\n#include \"rf_mcpair.h\"\n#include \"rf_threadstuff.h\"\n#include \"rf_types.h\"\n#include \"rf_archs.h\"\n\nstatic caddr_t \nAcquireReintBuffer(pool)\n\tRF_RegionBufferQueue_t *pool;\n{\n\tcaddr_t bufPtr = NULL;\n\n\t/* Return a region buffer from the free list (pool). If the free list\n\t * is empty, WAIT. BLOCKING */\n\n\tRF_LOCK_MUTEX(pool->mutex);\n\tif (pool->availableBuffers > 0) {\n\t\tbufPtr = pool->buffers[pool->availBuffersIndex];\n\t\tpool->availableBuffers--;\n\t\tpool->availBuffersIndex++;\n\t\tif (pool->availBuffersIndex == pool->totalBuffers)\n\t\t\tpool->availBuffersIndex = 0;\n\t\tRF_UNLOCK_MUTEX(pool->mutex);\n\t} else {\n\t\tRF_PANIC();\t/* should never happen in currect config,\n\t\t\t\t * single reint */\n\t\tRF_WAIT_COND(pool->cond, pool->mutex);\n\t}\n\treturn (bufPtr);\n}"
  }
]