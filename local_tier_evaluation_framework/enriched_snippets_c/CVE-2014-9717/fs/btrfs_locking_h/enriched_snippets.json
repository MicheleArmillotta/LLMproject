[
  {
    "function_name": "btrfs_clear_lock_blocking",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.h",
    "lines": "58-61",
    "snippet": "static inline void btrfs_clear_lock_blocking(struct extent_buffer *eb)\n{\n\tbtrfs_clear_lock_blocking_rw(eb, BTRFS_WRITE_LOCK_BLOCKING);\n}",
    "includes": [],
    "macros_used": [
      "#define BTRFS_WRITE_LOCK_BLOCKING 3"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "btrfs_clear_lock_blocking_rw",
          "args": [
            "eb",
            "BTRFS_WRITE_LOCK_BLOCKING"
          ],
          "line": 60
        },
        "resolved": true,
        "details": {
          "function_name": "btrfs_clear_lock_blocking_rw",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.c",
          "lines": "66-94",
          "snippet": "void btrfs_clear_lock_blocking_rw(struct extent_buffer *eb, int rw)\n{\n\t/*\n\t * no lock is required.  The lock owner may change if\n\t * we have a read lock, but it won't change to or away\n\t * from us.  If we have the write lock, we are the owner\n\t * and it'll never change.\n\t */\n\tif (eb->lock_nested && current->pid == eb->lock_owner)\n\t\treturn;\n\n\tif (rw == BTRFS_WRITE_LOCK_BLOCKING) {\n\t\tBUG_ON(atomic_read(&eb->blocking_writers) != 1);\n\t\twrite_lock(&eb->lock);\n\t\tWARN_ON(atomic_read(&eb->spinning_writers));\n\t\tatomic_inc(&eb->spinning_writers);\n\t\tif (atomic_dec_and_test(&eb->blocking_writers) &&\n\t\t    waitqueue_active(&eb->write_lock_wq))\n\t\t\twake_up(&eb->write_lock_wq);\n\t} else if (rw == BTRFS_READ_LOCK_BLOCKING) {\n\t\tBUG_ON(atomic_read(&eb->blocking_readers) == 0);\n\t\tread_lock(&eb->lock);\n\t\tatomic_inc(&eb->spinning_readers);\n\t\tif (atomic_dec_and_test(&eb->blocking_readers) &&\n\t\t    waitqueue_active(&eb->read_lock_wq))\n\t\t\twake_up(&eb->read_lock_wq);\n\t}\n\treturn;\n}",
          "includes": [
            "#include \"locking.h\"",
            "#include \"extent_io.h\"",
            "#include \"ctree.h\"",
            "#include <asm/bug.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void btrfs_assert_tree_read_locked(struct extent_buffer *eb);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"locking.h\"\n#include \"extent_io.h\"\n#include \"ctree.h\"\n#include <asm/bug.h>\n#include <linux/page-flags.h>\n#include <linux/spinlock.h>\n#include <linux/pagemap.h>\n#include <linux/sched.h>\n\nstatic void btrfs_assert_tree_read_locked(struct extent_buffer *eb);\n\nvoid btrfs_clear_lock_blocking_rw(struct extent_buffer *eb, int rw)\n{\n\t/*\n\t * no lock is required.  The lock owner may change if\n\t * we have a read lock, but it won't change to or away\n\t * from us.  If we have the write lock, we are the owner\n\t * and it'll never change.\n\t */\n\tif (eb->lock_nested && current->pid == eb->lock_owner)\n\t\treturn;\n\n\tif (rw == BTRFS_WRITE_LOCK_BLOCKING) {\n\t\tBUG_ON(atomic_read(&eb->blocking_writers) != 1);\n\t\twrite_lock(&eb->lock);\n\t\tWARN_ON(atomic_read(&eb->spinning_writers));\n\t\tatomic_inc(&eb->spinning_writers);\n\t\tif (atomic_dec_and_test(&eb->blocking_writers) &&\n\t\t    waitqueue_active(&eb->write_lock_wq))\n\t\t\twake_up(&eb->write_lock_wq);\n\t} else if (rw == BTRFS_READ_LOCK_BLOCKING) {\n\t\tBUG_ON(atomic_read(&eb->blocking_readers) == 0);\n\t\tread_lock(&eb->lock);\n\t\tatomic_inc(&eb->spinning_readers);\n\t\tif (atomic_dec_and_test(&eb->blocking_readers) &&\n\t\t    waitqueue_active(&eb->read_lock_wq))\n\t\t\twake_up(&eb->read_lock_wq);\n\t}\n\treturn;\n}"
        }
      }
    ],
    "contextual_snippet": "#define BTRFS_WRITE_LOCK_BLOCKING 3\n\nstatic inline void btrfs_clear_lock_blocking(struct extent_buffer *eb)\n{\n\tbtrfs_clear_lock_blocking_rw(eb, BTRFS_WRITE_LOCK_BLOCKING);\n}"
  },
  {
    "function_name": "btrfs_set_lock_blocking",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.h",
    "lines": "53-56",
    "snippet": "static inline void btrfs_set_lock_blocking(struct extent_buffer *eb)\n{\n\tbtrfs_set_lock_blocking_rw(eb, BTRFS_WRITE_LOCK);\n}",
    "includes": [],
    "macros_used": [
      "#define BTRFS_WRITE_LOCK 1"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "btrfs_set_lock_blocking_rw",
          "args": [
            "eb",
            "BTRFS_WRITE_LOCK"
          ],
          "line": 55
        },
        "resolved": true,
        "details": {
          "function_name": "btrfs_set_lock_blocking_rw",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.c",
          "lines": "34-60",
          "snippet": "void btrfs_set_lock_blocking_rw(struct extent_buffer *eb, int rw)\n{\n\t/*\n\t * no lock is required.  The lock owner may change if\n\t * we have a read lock, but it won't change to or away\n\t * from us.  If we have the write lock, we are the owner\n\t * and it'll never change.\n\t */\n\tif (eb->lock_nested && current->pid == eb->lock_owner)\n\t\treturn;\n\tif (rw == BTRFS_WRITE_LOCK) {\n\t\tif (atomic_read(&eb->blocking_writers) == 0) {\n\t\t\tWARN_ON(atomic_read(&eb->spinning_writers) != 1);\n\t\t\tatomic_dec(&eb->spinning_writers);\n\t\t\tbtrfs_assert_tree_locked(eb);\n\t\t\tatomic_inc(&eb->blocking_writers);\n\t\t\twrite_unlock(&eb->lock);\n\t\t}\n\t} else if (rw == BTRFS_READ_LOCK) {\n\t\tbtrfs_assert_tree_read_locked(eb);\n\t\tatomic_inc(&eb->blocking_readers);\n\t\tWARN_ON(atomic_read(&eb->spinning_readers) == 0);\n\t\tatomic_dec(&eb->spinning_readers);\n\t\tread_unlock(&eb->lock);\n\t}\n\treturn;\n}",
          "includes": [
            "#include \"locking.h\"",
            "#include \"extent_io.h\"",
            "#include \"ctree.h\"",
            "#include <asm/bug.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void btrfs_assert_tree_read_locked(struct extent_buffer *eb);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"locking.h\"\n#include \"extent_io.h\"\n#include \"ctree.h\"\n#include <asm/bug.h>\n#include <linux/page-flags.h>\n#include <linux/spinlock.h>\n#include <linux/pagemap.h>\n#include <linux/sched.h>\n\nstatic void btrfs_assert_tree_read_locked(struct extent_buffer *eb);\n\nvoid btrfs_set_lock_blocking_rw(struct extent_buffer *eb, int rw)\n{\n\t/*\n\t * no lock is required.  The lock owner may change if\n\t * we have a read lock, but it won't change to or away\n\t * from us.  If we have the write lock, we are the owner\n\t * and it'll never change.\n\t */\n\tif (eb->lock_nested && current->pid == eb->lock_owner)\n\t\treturn;\n\tif (rw == BTRFS_WRITE_LOCK) {\n\t\tif (atomic_read(&eb->blocking_writers) == 0) {\n\t\t\tWARN_ON(atomic_read(&eb->spinning_writers) != 1);\n\t\t\tatomic_dec(&eb->spinning_writers);\n\t\t\tbtrfs_assert_tree_locked(eb);\n\t\t\tatomic_inc(&eb->blocking_writers);\n\t\t\twrite_unlock(&eb->lock);\n\t\t}\n\t} else if (rw == BTRFS_READ_LOCK) {\n\t\tbtrfs_assert_tree_read_locked(eb);\n\t\tatomic_inc(&eb->blocking_readers);\n\t\tWARN_ON(atomic_read(&eb->spinning_readers) == 0);\n\t\tatomic_dec(&eb->spinning_readers);\n\t\tread_unlock(&eb->lock);\n\t}\n\treturn;\n}"
        }
      }
    ],
    "contextual_snippet": "#define BTRFS_WRITE_LOCK 1\n\nstatic inline void btrfs_set_lock_blocking(struct extent_buffer *eb)\n{\n\tbtrfs_set_lock_blocking_rw(eb, BTRFS_WRITE_LOCK);\n}"
  },
  {
    "function_name": "btrfs_tree_unlock_rw",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.h",
    "lines": "41-51",
    "snippet": "static inline void btrfs_tree_unlock_rw(struct extent_buffer *eb, int rw)\n{\n\tif (rw == BTRFS_WRITE_LOCK || rw == BTRFS_WRITE_LOCK_BLOCKING)\n\t\tbtrfs_tree_unlock(eb);\n\telse if (rw == BTRFS_READ_LOCK_BLOCKING)\n\t\tbtrfs_tree_read_unlock_blocking(eb);\n\telse if (rw == BTRFS_READ_LOCK)\n\t\tbtrfs_tree_read_unlock(eb);\n\telse\n\t\tBUG();\n}",
    "includes": [],
    "macros_used": [
      "#define BTRFS_READ_LOCK_BLOCKING 4",
      "#define BTRFS_WRITE_LOCK_BLOCKING 3",
      "#define BTRFS_READ_LOCK 2",
      "#define BTRFS_WRITE_LOCK 1"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 50
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "btrfs_tree_read_unlock",
          "args": [
            "eb"
          ],
          "line": 48
        },
        "resolved": true,
        "details": {
          "function_name": "btrfs_tree_read_unlock_blocking",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.c",
          "lines": "218-236",
          "snippet": "void btrfs_tree_read_unlock_blocking(struct extent_buffer *eb)\n{\n\t/*\n\t * if we're nested, we have the write lock.  No new locking\n\t * is needed as long as we are the lock owner.\n\t * The write unlock will do a barrier for us, and the lock_nested\n\t * field only matters to the lock owner.\n\t */\n\tif (eb->lock_nested && current->pid == eb->lock_owner) {\n\t\teb->lock_nested = 0;\n\t\treturn;\n\t}\n\tbtrfs_assert_tree_read_locked(eb);\n\tWARN_ON(atomic_read(&eb->blocking_readers) == 0);\n\tif (atomic_dec_and_test(&eb->blocking_readers) &&\n\t    waitqueue_active(&eb->read_lock_wq))\n\t\twake_up(&eb->read_lock_wq);\n\tatomic_dec(&eb->read_locks);\n}",
          "includes": [
            "#include \"locking.h\"",
            "#include \"extent_io.h\"",
            "#include \"ctree.h\"",
            "#include <asm/bug.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void btrfs_assert_tree_read_locked(struct extent_buffer *eb);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"locking.h\"\n#include \"extent_io.h\"\n#include \"ctree.h\"\n#include <asm/bug.h>\n#include <linux/page-flags.h>\n#include <linux/spinlock.h>\n#include <linux/pagemap.h>\n#include <linux/sched.h>\n\nstatic void btrfs_assert_tree_read_locked(struct extent_buffer *eb);\n\nvoid btrfs_tree_read_unlock_blocking(struct extent_buffer *eb)\n{\n\t/*\n\t * if we're nested, we have the write lock.  No new locking\n\t * is needed as long as we are the lock owner.\n\t * The write unlock will do a barrier for us, and the lock_nested\n\t * field only matters to the lock owner.\n\t */\n\tif (eb->lock_nested && current->pid == eb->lock_owner) {\n\t\teb->lock_nested = 0;\n\t\treturn;\n\t}\n\tbtrfs_assert_tree_read_locked(eb);\n\tWARN_ON(atomic_read(&eb->blocking_readers) == 0);\n\tif (atomic_dec_and_test(&eb->blocking_readers) &&\n\t    waitqueue_active(&eb->read_lock_wq))\n\t\twake_up(&eb->read_lock_wq);\n\tatomic_dec(&eb->read_locks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "btrfs_tree_unlock",
          "args": [
            "eb"
          ],
          "line": 44
        },
        "resolved": true,
        "details": {
          "function_name": "btrfs_tree_unlock",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/btrfs/locking.c",
          "lines": "269-290",
          "snippet": "void btrfs_tree_unlock(struct extent_buffer *eb)\n{\n\tint blockers = atomic_read(&eb->blocking_writers);\n\n\tBUG_ON(blockers > 1);\n\n\tbtrfs_assert_tree_locked(eb);\n\teb->lock_owner = 0;\n\tatomic_dec(&eb->write_locks);\n\n\tif (blockers) {\n\t\tWARN_ON(atomic_read(&eb->spinning_writers));\n\t\tatomic_dec(&eb->blocking_writers);\n\t\tsmp_mb();\n\t\tif (waitqueue_active(&eb->write_lock_wq))\n\t\t\twake_up(&eb->write_lock_wq);\n\t} else {\n\t\tWARN_ON(atomic_read(&eb->spinning_writers) != 1);\n\t\tatomic_dec(&eb->spinning_writers);\n\t\twrite_unlock(&eb->lock);\n\t}\n}",
          "includes": [
            "#include \"locking.h\"",
            "#include \"extent_io.h\"",
            "#include \"ctree.h\"",
            "#include <asm/bug.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void btrfs_assert_tree_read_locked(struct extent_buffer *eb);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"locking.h\"\n#include \"extent_io.h\"\n#include \"ctree.h\"\n#include <asm/bug.h>\n#include <linux/page-flags.h>\n#include <linux/spinlock.h>\n#include <linux/pagemap.h>\n#include <linux/sched.h>\n\nstatic void btrfs_assert_tree_read_locked(struct extent_buffer *eb);\n\nvoid btrfs_tree_unlock(struct extent_buffer *eb)\n{\n\tint blockers = atomic_read(&eb->blocking_writers);\n\n\tBUG_ON(blockers > 1);\n\n\tbtrfs_assert_tree_locked(eb);\n\teb->lock_owner = 0;\n\tatomic_dec(&eb->write_locks);\n\n\tif (blockers) {\n\t\tWARN_ON(atomic_read(&eb->spinning_writers));\n\t\tatomic_dec(&eb->blocking_writers);\n\t\tsmp_mb();\n\t\tif (waitqueue_active(&eb->write_lock_wq))\n\t\t\twake_up(&eb->write_lock_wq);\n\t} else {\n\t\tWARN_ON(atomic_read(&eb->spinning_writers) != 1);\n\t\tatomic_dec(&eb->spinning_writers);\n\t\twrite_unlock(&eb->lock);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#define BTRFS_READ_LOCK_BLOCKING 4\n#define BTRFS_WRITE_LOCK_BLOCKING 3\n#define BTRFS_READ_LOCK 2\n#define BTRFS_WRITE_LOCK 1\n\nstatic inline void btrfs_tree_unlock_rw(struct extent_buffer *eb, int rw)\n{\n\tif (rw == BTRFS_WRITE_LOCK || rw == BTRFS_WRITE_LOCK_BLOCKING)\n\t\tbtrfs_tree_unlock(eb);\n\telse if (rw == BTRFS_READ_LOCK_BLOCKING)\n\t\tbtrfs_tree_read_unlock_blocking(eb);\n\telse if (rw == BTRFS_READ_LOCK)\n\t\tbtrfs_tree_read_unlock(eb);\n\telse\n\t\tBUG();\n}"
  }
]