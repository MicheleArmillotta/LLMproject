[
  {
    "function_name": "xfs_trans_read_buf",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/xfs/xfs_trans.h",
    "lines": "186-200",
    "snippet": "static inline int\nxfs_trans_read_buf(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\txfs_daddr_t\t\tblkno,\n\tint\t\t\tnumblks,\n\txfs_buf_flags_t\t\tflags,\n\tstruct xfs_buf\t\t**bpp,\n\tconst struct xfs_buf_ops *ops)\n{\n\tDEFINE_SINGLE_BUF_MAP(map, blkno, numblks);\n\treturn xfs_trans_read_buf_map(mp, tp, target, &map, 1,\n\t\t\t\t      flags, bpp, ops);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "xfs_trans_read_buf_map",
          "args": [
            "mp",
            "tp",
            "target",
            "&map",
            "1",
            "flags",
            "bpp",
            "ops"
          ],
          "line": 198
        },
        "resolved": true,
        "details": {
          "function_name": "xfs_trans_read_buf_map",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/xfs/xfs_trans_buf.c",
          "lines": "240-337",
          "snippet": "int\nxfs_trans_read_buf_map(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\tstruct xfs_buf_map\t*map,\n\tint\t\t\tnmaps,\n\txfs_buf_flags_t\t\tflags,\n\tstruct xfs_buf\t\t**bpp,\n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf\t\t*bp = NULL;\n\tstruct xfs_buf_log_item\t*bip;\n\tint\t\t\terror;\n\n\t*bpp = NULL;\n\t/*\n\t * If we find the buffer in the cache with this transaction\n\t * pointer in its b_fsprivate2 field, then we know we already\n\t * have it locked.  If it is already read in we just increment\n\t * the lock recursion count and return the buffer to the caller.\n\t * If the buffer is not yet read in, then we read it in, increment\n\t * the lock recursion count, and return it to the caller.\n\t */\n\tif (tp)\n\t\tbp = xfs_trans_buf_item_match(tp, target, map, nmaps);\n\tif (bp) {\n\t\tASSERT(xfs_buf_islocked(bp));\n\t\tASSERT(bp->b_transp == tp);\n\t\tASSERT(bp->b_fspriv != NULL);\n\t\tASSERT(!bp->b_error);\n\t\tASSERT(bp->b_flags & XBF_DONE);\n\n\t\t/*\n\t\t * We never locked this buf ourselves, so we shouldn't\n\t\t * brelse it either. Just get out.\n\t\t */\n\t\tif (XFS_FORCED_SHUTDOWN(mp)) {\n\t\t\ttrace_xfs_trans_read_buf_shut(bp, _RET_IP_);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tbip = bp->b_fspriv;\n\t\tbip->bli_recur++;\n\n\t\tASSERT(atomic_read(&bip->bli_refcount) > 0);\n\t\ttrace_xfs_trans_read_buf_recur(bip);\n\t\t*bpp = bp;\n\t\treturn 0;\n\t}\n\n\tbp = xfs_buf_read_map(target, map, nmaps, flags, ops);\n\tif (!bp) {\n\t\tif (!(flags & XBF_TRYLOCK))\n\t\t\treturn -ENOMEM;\n\t\treturn tp ? 0 : -EAGAIN;\n\t}\n\n\t/*\n\t * If we've had a read error, then the contents of the buffer are\n\t * invalid and should not be used. To ensure that a followup read tries\n\t * to pull the buffer from disk again, we clear the XBF_DONE flag and\n\t * mark the buffer stale. This ensures that anyone who has a current\n\t * reference to the buffer will interpret it's contents correctly and\n\t * future cache lookups will also treat it as an empty, uninitialised\n\t * buffer.\n\t */\n\tif (bp->b_error) {\n\t\terror = bp->b_error;\n\t\tif (!XFS_FORCED_SHUTDOWN(mp))\n\t\t\txfs_buf_ioerror_alert(bp, __func__);\n\t\tbp->b_flags &= ~XBF_DONE;\n\t\txfs_buf_stale(bp);\n\n\t\tif (tp && (tp->t_flags & XFS_TRANS_DIRTY))\n\t\t\txfs_force_shutdown(tp->t_mountp, SHUTDOWN_META_IO_ERROR);\n\t\txfs_buf_relse(bp);\n\n\t\t/* bad CRC means corrupted metadata */\n\t\tif (error == -EFSBADCRC)\n\t\t\terror = -EFSCORRUPTED;\n\t\treturn error;\n\t}\n\n\tif (XFS_FORCED_SHUTDOWN(mp)) {\n\t\txfs_buf_relse(bp);\n\t\ttrace_xfs_trans_read_buf_shut(bp, _RET_IP_);\n\t\treturn -EIO;\n\t}\n\n\tif (tp) {\n\t\t_xfs_trans_bjoin(tp, bp, 1);\n\t\ttrace_xfs_trans_read_buf(bp->b_fspriv);\n\t}\n\t*bpp = bp;\n\treturn 0;\n\n}",
          "includes": [
            "#include \"xfs_trace.h\"",
            "#include \"xfs_error.h\"",
            "#include \"xfs_trans_priv.h\"",
            "#include \"xfs_buf_item.h\"",
            "#include \"xfs_trans.h\"",
            "#include \"xfs_inode.h\"",
            "#include \"xfs_mount.h\"",
            "#include \"xfs_trans_resv.h\"",
            "#include \"xfs_log_format.h\"",
            "#include \"xfs_format.h\"",
            "#include \"xfs_shared.h\"",
            "#include \"xfs_fs.h\"",
            "#include \"xfs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "STATIC struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"xfs_trace.h\"\n#include \"xfs_error.h\"\n#include \"xfs_trans_priv.h\"\n#include \"xfs_buf_item.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_inode.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_format.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_fs.h\"\n#include \"xfs.h\"\n\nSTATIC struct;\n\nint\nxfs_trans_read_buf_map(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\tstruct xfs_buf_map\t*map,\n\tint\t\t\tnmaps,\n\txfs_buf_flags_t\t\tflags,\n\tstruct xfs_buf\t\t**bpp,\n\tconst struct xfs_buf_ops *ops)\n{\n\tstruct xfs_buf\t\t*bp = NULL;\n\tstruct xfs_buf_log_item\t*bip;\n\tint\t\t\terror;\n\n\t*bpp = NULL;\n\t/*\n\t * If we find the buffer in the cache with this transaction\n\t * pointer in its b_fsprivate2 field, then we know we already\n\t * have it locked.  If it is already read in we just increment\n\t * the lock recursion count and return the buffer to the caller.\n\t * If the buffer is not yet read in, then we read it in, increment\n\t * the lock recursion count, and return it to the caller.\n\t */\n\tif (tp)\n\t\tbp = xfs_trans_buf_item_match(tp, target, map, nmaps);\n\tif (bp) {\n\t\tASSERT(xfs_buf_islocked(bp));\n\t\tASSERT(bp->b_transp == tp);\n\t\tASSERT(bp->b_fspriv != NULL);\n\t\tASSERT(!bp->b_error);\n\t\tASSERT(bp->b_flags & XBF_DONE);\n\n\t\t/*\n\t\t * We never locked this buf ourselves, so we shouldn't\n\t\t * brelse it either. Just get out.\n\t\t */\n\t\tif (XFS_FORCED_SHUTDOWN(mp)) {\n\t\t\ttrace_xfs_trans_read_buf_shut(bp, _RET_IP_);\n\t\t\treturn -EIO;\n\t\t}\n\n\t\tbip = bp->b_fspriv;\n\t\tbip->bli_recur++;\n\n\t\tASSERT(atomic_read(&bip->bli_refcount) > 0);\n\t\ttrace_xfs_trans_read_buf_recur(bip);\n\t\t*bpp = bp;\n\t\treturn 0;\n\t}\n\n\tbp = xfs_buf_read_map(target, map, nmaps, flags, ops);\n\tif (!bp) {\n\t\tif (!(flags & XBF_TRYLOCK))\n\t\t\treturn -ENOMEM;\n\t\treturn tp ? 0 : -EAGAIN;\n\t}\n\n\t/*\n\t * If we've had a read error, then the contents of the buffer are\n\t * invalid and should not be used. To ensure that a followup read tries\n\t * to pull the buffer from disk again, we clear the XBF_DONE flag and\n\t * mark the buffer stale. This ensures that anyone who has a current\n\t * reference to the buffer will interpret it's contents correctly and\n\t * future cache lookups will also treat it as an empty, uninitialised\n\t * buffer.\n\t */\n\tif (bp->b_error) {\n\t\terror = bp->b_error;\n\t\tif (!XFS_FORCED_SHUTDOWN(mp))\n\t\t\txfs_buf_ioerror_alert(bp, __func__);\n\t\tbp->b_flags &= ~XBF_DONE;\n\t\txfs_buf_stale(bp);\n\n\t\tif (tp && (tp->t_flags & XFS_TRANS_DIRTY))\n\t\t\txfs_force_shutdown(tp->t_mountp, SHUTDOWN_META_IO_ERROR);\n\t\txfs_buf_relse(bp);\n\n\t\t/* bad CRC means corrupted metadata */\n\t\tif (error == -EFSBADCRC)\n\t\t\terror = -EFSCORRUPTED;\n\t\treturn error;\n\t}\n\n\tif (XFS_FORCED_SHUTDOWN(mp)) {\n\t\txfs_buf_relse(bp);\n\t\ttrace_xfs_trans_read_buf_shut(bp, _RET_IP_);\n\t\treturn -EIO;\n\t}\n\n\tif (tp) {\n\t\t_xfs_trans_bjoin(tp, bp, 1);\n\t\ttrace_xfs_trans_read_buf(bp->b_fspriv);\n\t}\n\t*bpp = bp;\n\treturn 0;\n\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEFINE_SINGLE_BUF_MAP",
          "args": [
            "map",
            "blkno",
            "numblks"
          ],
          "line": 197
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline int\nxfs_trans_read_buf(\n\tstruct xfs_mount\t*mp,\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\txfs_daddr_t\t\tblkno,\n\tint\t\t\tnumblks,\n\txfs_buf_flags_t\t\tflags,\n\tstruct xfs_buf\t\t**bpp,\n\tconst struct xfs_buf_ops *ops)\n{\n\tDEFINE_SINGLE_BUF_MAP(map, blkno, numblks);\n\treturn xfs_trans_read_buf_map(mp, tp, target, &map, 1,\n\t\t\t\t      flags, bpp, ops);\n}"
  },
  {
    "function_name": "xfs_trans_get_buf",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/xfs/xfs_trans.h",
    "lines": "166-176",
    "snippet": "static inline struct xfs_buf *\nxfs_trans_get_buf(\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\txfs_daddr_t\t\tblkno,\n\tint\t\t\tnumblks,\n\tuint\t\t\tflags)\n{\n\tDEFINE_SINGLE_BUF_MAP(map, blkno, numblks);\n\treturn xfs_trans_get_buf_map(tp, target, &map, 1, flags);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "xfs_trans_get_buf_map",
          "args": [
            "tp",
            "target",
            "&map",
            "1",
            "flags"
          ],
          "line": 175
        },
        "resolved": true,
        "details": {
          "function_name": "xfs_trans_get_buf_map",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2014-9717/repo/fs/xfs/xfs_trans_buf.c",
          "lines": "133-180",
          "snippet": "struct xfs_buf *\nxfs_trans_get_buf_map(\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\tstruct xfs_buf_map\t*map,\n\tint\t\t\tnmaps,\n\txfs_buf_flags_t\t\tflags)\n{\n\txfs_buf_t\t\t*bp;\n\txfs_buf_log_item_t\t*bip;\n\n\tif (!tp)\n\t\treturn xfs_buf_get_map(target, map, nmaps, flags);\n\n\t/*\n\t * If we find the buffer in the cache with this transaction\n\t * pointer in its b_fsprivate2 field, then we know we already\n\t * have it locked.  In this case we just increment the lock\n\t * recursion count and return the buffer to the caller.\n\t */\n\tbp = xfs_trans_buf_item_match(tp, target, map, nmaps);\n\tif (bp != NULL) {\n\t\tASSERT(xfs_buf_islocked(bp));\n\t\tif (XFS_FORCED_SHUTDOWN(tp->t_mountp)) {\n\t\t\txfs_buf_stale(bp);\n\t\t\tXFS_BUF_DONE(bp);\n\t\t}\n\n\t\tASSERT(bp->b_transp == tp);\n\t\tbip = bp->b_fspriv;\n\t\tASSERT(bip != NULL);\n\t\tASSERT(atomic_read(&bip->bli_refcount) > 0);\n\t\tbip->bli_recur++;\n\t\ttrace_xfs_trans_get_buf_recur(bip);\n\t\treturn bp;\n\t}\n\n\tbp = xfs_buf_get_map(target, map, nmaps, flags);\n\tif (bp == NULL) {\n\t\treturn NULL;\n\t}\n\n\tASSERT(!bp->b_error);\n\n\t_xfs_trans_bjoin(tp, bp, 1);\n\ttrace_xfs_trans_get_buf(bp->b_fspriv);\n\treturn bp;\n}",
          "includes": [
            "#include \"xfs_trace.h\"",
            "#include \"xfs_error.h\"",
            "#include \"xfs_trans_priv.h\"",
            "#include \"xfs_buf_item.h\"",
            "#include \"xfs_trans.h\"",
            "#include \"xfs_inode.h\"",
            "#include \"xfs_mount.h\"",
            "#include \"xfs_trans_resv.h\"",
            "#include \"xfs_log_format.h\"",
            "#include \"xfs_format.h\"",
            "#include \"xfs_shared.h\"",
            "#include \"xfs_fs.h\"",
            "#include \"xfs.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "STATIC struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"xfs_trace.h\"\n#include \"xfs_error.h\"\n#include \"xfs_trans_priv.h\"\n#include \"xfs_buf_item.h\"\n#include \"xfs_trans.h\"\n#include \"xfs_inode.h\"\n#include \"xfs_mount.h\"\n#include \"xfs_trans_resv.h\"\n#include \"xfs_log_format.h\"\n#include \"xfs_format.h\"\n#include \"xfs_shared.h\"\n#include \"xfs_fs.h\"\n#include \"xfs.h\"\n\nSTATIC struct;\n\nstruct xfs_buf *\nxfs_trans_get_buf_map(\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\tstruct xfs_buf_map\t*map,\n\tint\t\t\tnmaps,\n\txfs_buf_flags_t\t\tflags)\n{\n\txfs_buf_t\t\t*bp;\n\txfs_buf_log_item_t\t*bip;\n\n\tif (!tp)\n\t\treturn xfs_buf_get_map(target, map, nmaps, flags);\n\n\t/*\n\t * If we find the buffer in the cache with this transaction\n\t * pointer in its b_fsprivate2 field, then we know we already\n\t * have it locked.  In this case we just increment the lock\n\t * recursion count and return the buffer to the caller.\n\t */\n\tbp = xfs_trans_buf_item_match(tp, target, map, nmaps);\n\tif (bp != NULL) {\n\t\tASSERT(xfs_buf_islocked(bp));\n\t\tif (XFS_FORCED_SHUTDOWN(tp->t_mountp)) {\n\t\t\txfs_buf_stale(bp);\n\t\t\tXFS_BUF_DONE(bp);\n\t\t}\n\n\t\tASSERT(bp->b_transp == tp);\n\t\tbip = bp->b_fspriv;\n\t\tASSERT(bip != NULL);\n\t\tASSERT(atomic_read(&bip->bli_refcount) > 0);\n\t\tbip->bli_recur++;\n\t\ttrace_xfs_trans_get_buf_recur(bip);\n\t\treturn bp;\n\t}\n\n\tbp = xfs_buf_get_map(target, map, nmaps, flags);\n\tif (bp == NULL) {\n\t\treturn NULL;\n\t}\n\n\tASSERT(!bp->b_error);\n\n\t_xfs_trans_bjoin(tp, bp, 1);\n\ttrace_xfs_trans_get_buf(bp->b_fspriv);\n\treturn bp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEFINE_SINGLE_BUF_MAP",
          "args": [
            "map",
            "blkno",
            "numblks"
          ],
          "line": 174
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline struct xfs_buf *\nxfs_trans_get_buf(\n\tstruct xfs_trans\t*tp,\n\tstruct xfs_buftarg\t*target,\n\txfs_daddr_t\t\tblkno,\n\tint\t\t\tnumblks,\n\tuint\t\t\tflags)\n{\n\tDEFINE_SINGLE_BUF_MAP(map, blkno, numblks);\n\treturn xfs_trans_get_buf_map(tp, target, &map, 1, flags);\n}"
  }
]