[
  {
    "function_name": "htab_of_map_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2409-2413",
    "snippet": "static void htab_of_map_free(struct bpf_map *map)\n{\n\tbpf_map_meta_free(map->inner_map_meta);\n\tfd_htab_map_free(map);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "fd_htab_map_free",
          "args": [
            "map"
          ],
          "line": 2412
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "2302-2321",
          "snippet": "static void fd_htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_node *n;\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\tvoid *ptr = fd_htab_map_get_ptr(map, l);\n\n\t\t\tmap->ops->map_fd_put_ptr(ptr);\n\t\t}\n\t}\n\n\thtab_map_free(map);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void fd_htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_node *n;\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\tvoid *ptr = fd_htab_map_get_ptr(map, l);\n\n\t\t\tmap->ops->map_fd_put_ptr(ptr);\n\t\t}\n\t}\n\n\thtab_map_free(map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_meta_free",
          "args": [
            "map->inner_map_meta"
          ],
          "line": 2411
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_meta_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/map_in_map.c",
          "lines": "72-76",
          "snippet": "void bpf_map_meta_free(struct bpf_map *map_meta)\n{\n\tbtf_put(map_meta->btf);\n\tkfree(map_meta);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n\nvoid bpf_map_meta_free(struct bpf_map *map_meta)\n{\n\tbtf_put(map_meta->btf);\n\tkfree(map_meta);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_of_map_free(struct bpf_map *map)\n{\n\tbpf_map_meta_free(map->inner_map_meta);\n\tfd_htab_map_free(map);\n}"
  },
  {
    "function_name": "htab_of_map_gen_lookup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2391-2407",
    "snippet": "static int htab_of_map_gen_lookup(struct bpf_map *map,\n\t\t\t\t  struct bpf_insn *insn_buf)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\tconst int ret = BPF_REG_0;\n\n\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);\n\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 2);\n\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,\n\t\t\t\toffsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8));\n\t*insn++ = BPF_LDX_MEM(BPF_DW, ret, ret, 0);\n\n\treturn insn - insn_buf;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_DW",
            "ret",
            "ret",
            "0"
          ],
          "line": 2404
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_ALU64_IMM",
          "args": [
            "BPF_ADD",
            "ret",
            "offsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8)"
          ],
          "line": 2401
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 2403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_JMP_IMM",
          "args": [
            "BPF_JEQ",
            "ret",
            "0",
            "2"
          ],
          "line": 2400
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_EMIT_CALL",
          "args": [
            "__htab_map_lookup_elem"
          ],
          "line": 2399
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL)"
          ],
          "line": 2397
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__same_type",
          "args": [
            "&__htab_map_lookup_elem",
            "(void *(*)(struct bpf_map *map, void *key))NULL"
          ],
          "line": 2397
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_of_map_gen_lookup(struct bpf_map *map,\n\t\t\t\t  struct bpf_insn *insn_buf)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\tconst int ret = BPF_REG_0;\n\n\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);\n\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 2);\n\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,\n\t\t\t\toffsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8));\n\t*insn++ = BPF_LDX_MEM(BPF_DW, ret, ret, 0);\n\n\treturn insn - insn_buf;\n}"
  },
  {
    "function_name": "htab_of_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2381-2389",
    "snippet": "static void *htab_of_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_map **inner_map  = htab_map_lookup_elem(map, key);\n\n\tif (!inner_map)\n\t\treturn NULL;\n\n\treturn READ_ONCE(*inner_map);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "*inner_map"
          ],
          "line": 2388
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 2383
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "643-651",
          "snippet": "static void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_of_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_map **inner_map  = htab_map_lookup_elem(map, key);\n\n\tif (!inner_map)\n\t\treturn NULL;\n\n\treturn READ_ONCE(*inner_map);\n}"
  },
  {
    "function_name": "htab_of_map_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2362-2379",
    "snippet": "static struct bpf_map *htab_of_map_alloc(union bpf_attr *attr)\n{\n\tstruct bpf_map *map, *inner_map_meta;\n\n\tinner_map_meta = bpf_map_meta_alloc(attr->inner_map_fd);\n\tif (IS_ERR(inner_map_meta))\n\t\treturn inner_map_meta;\n\n\tmap = htab_map_alloc(attr);\n\tif (IS_ERR(map)) {\n\t\tbpf_map_meta_free(inner_map_meta);\n\t\treturn map;\n\t}\n\n\tmap->inner_map_meta = inner_map_meta;\n\n\treturn map;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_map_meta_free",
          "args": [
            "inner_map_meta"
          ],
          "line": 2372
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_meta_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/map_in_map.c",
          "lines": "72-76",
          "snippet": "void bpf_map_meta_free(struct bpf_map *map_meta)\n{\n\tbtf_put(map_meta->btf);\n\tkfree(map_meta);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n\nvoid bpf_map_meta_free(struct bpf_map *map_meta)\n{\n\tbtf_put(map_meta->btf);\n\tkfree(map_meta);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "map"
          ],
          "line": 2371
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_map_alloc",
          "args": [
            "attr"
          ],
          "line": 2370
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_alloc_check",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "2295-2300",
          "snippet": "static int fd_htab_map_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn htab_map_alloc_check(attr);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int fd_htab_map_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn htab_map_alloc_check(attr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "inner_map_meta"
          ],
          "line": 2367
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_meta_alloc",
          "args": [
            "attr->inner_map_fd"
          ],
          "line": 2366
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_meta_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/map_in_map.c",
          "lines": "10-70",
          "snippet": "struct bpf_map *bpf_map_meta_alloc(int inner_map_ufd)\n{\n\tstruct bpf_map *inner_map, *inner_map_meta;\n\tu32 inner_map_meta_size;\n\tstruct fd f;\n\n\tf = fdget(inner_map_ufd);\n\tinner_map = __bpf_map_get(f);\n\tif (IS_ERR(inner_map))\n\t\treturn inner_map;\n\n\t/* Does not support >1 level map-in-map */\n\tif (inner_map->inner_map_meta) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!inner_map->ops->map_meta_equal) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-ENOTSUPP);\n\t}\n\n\tif (map_value_has_spin_lock(inner_map)) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-ENOTSUPP);\n\t}\n\n\tinner_map_meta_size = sizeof(*inner_map_meta);\n\t/* In some cases verifier needs to access beyond just base map. */\n\tif (inner_map->ops == &array_map_ops)\n\t\tinner_map_meta_size = sizeof(struct bpf_array);\n\n\tinner_map_meta = kzalloc(inner_map_meta_size, GFP_USER);\n\tif (!inner_map_meta) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tinner_map_meta->map_type = inner_map->map_type;\n\tinner_map_meta->key_size = inner_map->key_size;\n\tinner_map_meta->value_size = inner_map->value_size;\n\tinner_map_meta->map_flags = inner_map->map_flags;\n\tinner_map_meta->max_entries = inner_map->max_entries;\n\tinner_map_meta->spin_lock_off = inner_map->spin_lock_off;\n\tinner_map_meta->timer_off = inner_map->timer_off;\n\tif (inner_map->btf) {\n\t\tbtf_get(inner_map->btf);\n\t\tinner_map_meta->btf = inner_map->btf;\n\t}\n\n\t/* Misc members not needed in bpf_map_meta_equal() check. */\n\tinner_map_meta->ops = inner_map->ops;\n\tif (inner_map->ops == &array_map_ops) {\n\t\tinner_map_meta->bypass_spec_v1 = inner_map->bypass_spec_v1;\n\t\tcontainer_of(inner_map_meta, struct bpf_array, map)->index_mask =\n\t\t     container_of(inner_map, struct bpf_array, map)->index_mask;\n\t}\n\n\tfdput(f);\n\treturn inner_map_meta;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n\nstruct bpf_map *bpf_map_meta_alloc(int inner_map_ufd)\n{\n\tstruct bpf_map *inner_map, *inner_map_meta;\n\tu32 inner_map_meta_size;\n\tstruct fd f;\n\n\tf = fdget(inner_map_ufd);\n\tinner_map = __bpf_map_get(f);\n\tif (IS_ERR(inner_map))\n\t\treturn inner_map;\n\n\t/* Does not support >1 level map-in-map */\n\tif (inner_map->inner_map_meta) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-EINVAL);\n\t}\n\n\tif (!inner_map->ops->map_meta_equal) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-ENOTSUPP);\n\t}\n\n\tif (map_value_has_spin_lock(inner_map)) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-ENOTSUPP);\n\t}\n\n\tinner_map_meta_size = sizeof(*inner_map_meta);\n\t/* In some cases verifier needs to access beyond just base map. */\n\tif (inner_map->ops == &array_map_ops)\n\t\tinner_map_meta_size = sizeof(struct bpf_array);\n\n\tinner_map_meta = kzalloc(inner_map_meta_size, GFP_USER);\n\tif (!inner_map_meta) {\n\t\tfdput(f);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\n\tinner_map_meta->map_type = inner_map->map_type;\n\tinner_map_meta->key_size = inner_map->key_size;\n\tinner_map_meta->value_size = inner_map->value_size;\n\tinner_map_meta->map_flags = inner_map->map_flags;\n\tinner_map_meta->max_entries = inner_map->max_entries;\n\tinner_map_meta->spin_lock_off = inner_map->spin_lock_off;\n\tinner_map_meta->timer_off = inner_map->timer_off;\n\tif (inner_map->btf) {\n\t\tbtf_get(inner_map->btf);\n\t\tinner_map_meta->btf = inner_map->btf;\n\t}\n\n\t/* Misc members not needed in bpf_map_meta_equal() check. */\n\tinner_map_meta->ops = inner_map->ops;\n\tif (inner_map->ops == &array_map_ops) {\n\t\tinner_map_meta->bypass_spec_v1 = inner_map->bypass_spec_v1;\n\t\tcontainer_of(inner_map_meta, struct bpf_array, map)->index_mask =\n\t\t     container_of(inner_map, struct bpf_array, map)->index_mask;\n\t}\n\n\tfdput(f);\n\treturn inner_map_meta;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct bpf_map *htab_of_map_alloc(union bpf_attr *attr)\n{\n\tstruct bpf_map *map, *inner_map_meta;\n\n\tinner_map_meta = bpf_map_meta_alloc(attr->inner_map_fd);\n\tif (IS_ERR(inner_map_meta))\n\t\treturn inner_map_meta;\n\n\tmap = htab_map_alloc(attr);\n\tif (IS_ERR(map)) {\n\t\tbpf_map_meta_free(inner_map_meta);\n\t\treturn map;\n\t}\n\n\tmap->inner_map_meta = inner_map_meta;\n\n\treturn map;\n}"
  },
  {
    "function_name": "bpf_fd_htab_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2344-2360",
    "snippet": "int bpf_fd_htab_map_update_elem(struct bpf_map *map, struct file *map_file,\n\t\t\t\tvoid *key, void *value, u64 map_flags)\n{\n\tvoid *ptr;\n\tint ret;\n\tu32 ufd = *(u32 *)value;\n\n\tptr = map->ops->map_fd_get_ptr(map, map_file, ufd);\n\tif (IS_ERR(ptr))\n\t\treturn PTR_ERR(ptr);\n\n\tret = htab_map_update_elem(map, key, &ptr, map_flags);\n\tif (ret)\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "map->ops->map_fd_put_ptr",
          "args": [
            "ptr"
          ],
          "line": 2357
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_map_update_elem",
          "args": [
            "map",
            "key",
            "&ptr",
            "map_flags"
          ],
          "line": 2355
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_update_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1019-1113",
          "snippet": "static int htab_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\tu64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely((map_flags & ~BPF_F_LOCK) > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tif (unlikely(map_flags & BPF_F_LOCK)) {\n\t\tif (unlikely(!map_value_has_spin_lock(map)))\n\t\t\treturn -EINVAL;\n\t\t/* find an element without taking the bucket lock */\n\t\tl_old = lookup_nulls_elem_raw(head, hash, key, key_size,\n\t\t\t\t\t      htab->n_buckets);\n\t\tret = check_flags(htab, l_old, map_flags);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (l_old) {\n\t\t\t/* grab the element lock and update value in place */\n\t\t\tcopy_map_value_locked(map,\n\t\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t\t      value, false);\n\t\t\treturn 0;\n\t\t}\n\t\t/* fall through, grab the bucket lock and lookup again.\n\t\t * 99.9% chance that the element won't be found,\n\t\t * but second lookup under lock has to be done.\n\t\t */\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (unlikely(l_old && (map_flags & BPF_F_LOCK))) {\n\t\t/* first lookup without the bucket lock didn't find the element,\n\t\t * but second lookup with the bucket lock found it.\n\t\t * This case is highly unlikely, but has to be dealt with:\n\t\t * grab the element lock in addition to the bucket lock\n\t\t * and update element in place\n\t\t */\n\t\tcopy_map_value_locked(map,\n\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t      value, false);\n\t\tret = 0;\n\t\tgoto err;\n\t}\n\n\tl_new = alloc_htab_elem(htab, key, value, key_size, hash, false, false,\n\t\t\t\tl_old);\n\tif (IS_ERR(l_new)) {\n\t\t/* all pre-allocated elements are in use or memory exhausted */\n\t\tret = PTR_ERR(l_new);\n\t\tgoto err;\n\t}\n\n\t/* add new element to the head of the list, so that\n\t * concurrent search will find it before old elem\n\t */\n\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\tif (l_old) {\n\t\thlist_nulls_del_rcu(&l_old->hash_node);\n\t\tif (!htab_is_prealloc(htab))\n\t\t\tfree_htab_elem(htab, l_old);\n\t\telse\n\t\t\tcheck_and_free_timer(htab, l_old);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\tu64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely((map_flags & ~BPF_F_LOCK) > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tif (unlikely(map_flags & BPF_F_LOCK)) {\n\t\tif (unlikely(!map_value_has_spin_lock(map)))\n\t\t\treturn -EINVAL;\n\t\t/* find an element without taking the bucket lock */\n\t\tl_old = lookup_nulls_elem_raw(head, hash, key, key_size,\n\t\t\t\t\t      htab->n_buckets);\n\t\tret = check_flags(htab, l_old, map_flags);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (l_old) {\n\t\t\t/* grab the element lock and update value in place */\n\t\t\tcopy_map_value_locked(map,\n\t\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t\t      value, false);\n\t\t\treturn 0;\n\t\t}\n\t\t/* fall through, grab the bucket lock and lookup again.\n\t\t * 99.9% chance that the element won't be found,\n\t\t * but second lookup under lock has to be done.\n\t\t */\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (unlikely(l_old && (map_flags & BPF_F_LOCK))) {\n\t\t/* first lookup without the bucket lock didn't find the element,\n\t\t * but second lookup with the bucket lock found it.\n\t\t * This case is highly unlikely, but has to be dealt with:\n\t\t * grab the element lock in addition to the bucket lock\n\t\t * and update element in place\n\t\t */\n\t\tcopy_map_value_locked(map,\n\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t      value, false);\n\t\tret = 0;\n\t\tgoto err;\n\t}\n\n\tl_new = alloc_htab_elem(htab, key, value, key_size, hash, false, false,\n\t\t\t\tl_old);\n\tif (IS_ERR(l_new)) {\n\t\t/* all pre-allocated elements are in use or memory exhausted */\n\t\tret = PTR_ERR(l_new);\n\t\tgoto err;\n\t}\n\n\t/* add new element to the head of the list, so that\n\t * concurrent search will find it before old elem\n\t */\n\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\tif (l_old) {\n\t\thlist_nulls_del_rcu(&l_old->hash_node);\n\t\tif (!htab_is_prealloc(htab))\n\t\t\tfree_htab_elem(htab, l_old);\n\t\telse\n\t\t\tcheck_and_free_timer(htab, l_old);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "ptr"
          ],
          "line": 2353
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "ptr"
          ],
          "line": 2352
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map->ops->map_fd_get_ptr",
          "args": [
            "map",
            "map_file",
            "ufd"
          ],
          "line": 2351
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nint bpf_fd_htab_map_update_elem(struct bpf_map *map, struct file *map_file,\n\t\t\t\tvoid *key, void *value, u64 map_flags)\n{\n\tvoid *ptr;\n\tint ret;\n\tu32 ufd = *(u32 *)value;\n\n\tptr = map->ops->map_fd_get_ptr(map, map_file, ufd);\n\tif (IS_ERR(ptr))\n\t\treturn PTR_ERR(ptr);\n\n\tret = htab_map_update_elem(map, key, &ptr, map_flags);\n\tif (ret)\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_fd_htab_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2324-2341",
    "snippet": "int bpf_fd_htab_map_lookup_elem(struct bpf_map *map, void *key, u32 *value)\n{\n\tvoid **ptr;\n\tint ret = 0;\n\n\tif (!map->ops->map_fd_sys_lookup_elem)\n\t\treturn -ENOTSUPP;\n\n\trcu_read_lock();\n\tptr = htab_map_lookup_elem(map, key);\n\tif (ptr)\n\t\t*value = map->ops->map_fd_sys_lookup_elem(READ_ONCE(*ptr));\n\telse\n\t\tret = -ENOENT;\n\trcu_read_unlock();\n\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2338
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "map->ops->map_fd_sys_lookup_elem",
          "args": [
            "READ_ONCE(*ptr)"
          ],
          "line": 2335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "*ptr"
          ],
          "line": 2335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 2333
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "643-651",
          "snippet": "static void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2332
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nint bpf_fd_htab_map_lookup_elem(struct bpf_map *map, void *key, u32 *value)\n{\n\tvoid **ptr;\n\tint ret = 0;\n\n\tif (!map->ops->map_fd_sys_lookup_elem)\n\t\treturn -ENOTSUPP;\n\n\trcu_read_lock();\n\tptr = htab_map_lookup_elem(map, key);\n\tif (ptr)\n\t\t*value = map->ops->map_fd_sys_lookup_elem(READ_ONCE(*ptr));\n\telse\n\t\tret = -ENOENT;\n\trcu_read_unlock();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "fd_htab_map_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2302-2321",
    "snippet": "static void fd_htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_node *n;\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\tvoid *ptr = fd_htab_map_get_ptr(map, l);\n\n\t\t\tmap->ops->map_fd_put_ptr(ptr);\n\t\t}\n\t}\n\n\thtab_map_free(map);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_map_free",
          "args": [
            "map"
          ],
          "line": 2320
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "2302-2321",
          "snippet": "static void fd_htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_node *n;\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\tvoid *ptr = fd_htab_map_get_ptr(map, l);\n\n\t\t\tmap->ops->map_fd_put_ptr(ptr);\n\t\t}\n\t}\n\n\thtab_map_free(map);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "map->ops->map_fd_put_ptr",
          "args": [
            "ptr"
          ],
          "line": 2316
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fd_htab_map_get_ptr",
          "args": [
            "map",
            "l"
          ],
          "line": 2314
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "221-224",
          "snippet": "static void *fd_htab_map_get_ptr(const struct bpf_map *map, struct htab_elem *l)\n{\n\treturn *(void **)(l->key + roundup(map->key_size, 8));\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *fd_htab_map_get_ptr(const struct bpf_map *map, struct htab_elem *l)\n{\n\treturn *(void **)(l->key + roundup(map->key_size, 8));\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_safe",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 2313
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "select_bucket",
          "args": [
            "htab",
            "i"
          ],
          "line": 2311
        },
        "resolved": true,
        "details": {
          "function_name": "select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "576-579",
          "snippet": "static inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 2304
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void fd_htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_node *n;\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\tvoid *ptr = fd_htab_map_get_ptr(map, l);\n\n\t\t\tmap->ops->map_fd_put_ptr(ptr);\n\t\t}\n\t}\n\n\thtab_map_free(map);\n}"
  },
  {
    "function_name": "fd_htab_map_alloc_check",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2295-2300",
    "snippet": "static int fd_htab_map_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn htab_map_alloc_check(attr);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_map_alloc_check",
          "args": [
            "attr"
          ],
          "line": 2299
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_alloc_check",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "2295-2300",
          "snippet": "static int fd_htab_map_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn htab_map_alloc_check(attr);\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int fd_htab_map_alloc_check(union bpf_attr *attr)\n{\n\tif (attr->value_size != sizeof(u32))\n\t\treturn -EINVAL;\n\treturn htab_map_alloc_check(attr);\n}"
  },
  {
    "function_name": "htab_percpu_map_seq_show_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2226-2253",
    "snippet": "static void htab_percpu_map_seq_show_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t  struct seq_file *m)\n{\n\tstruct htab_elem *l;\n\tvoid __percpu *pptr;\n\tint cpu;\n\n\trcu_read_lock();\n\n\tl = __htab_map_lookup_elem(map, key);\n\tif (!l) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);\n\tseq_puts(m, \": {\\n\");\n\tpptr = htab_elem_get_ptr(l, map->key_size);\n\tfor_each_possible_cpu(cpu) {\n\t\tseq_printf(m, \"\\tcpu%d: \", cpu);\n\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,\n\t\t\t\t  per_cpu_ptr(pptr, cpu), m);\n\t\tseq_puts(m, \"\\n\");\n\t}\n\tseq_puts(m, \"}\\n\");\n\n\trcu_read_unlock();\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2252
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_puts",
          "args": [
            "m",
            "\"}\\n\""
          ],
          "line": 2250
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "205-220",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      },
      {
        "call_info": {
          "callee": "btf_type_seq_show",
          "args": [
            "map->btf",
            "map->btf_value_type_id",
            "per_cpu_ptr(pptr, cpu)",
            "m"
          ],
          "line": 2246
        },
        "resolved": true,
        "details": {
          "function_name": "btf_type_seq_show",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/btf.c",
          "lines": "5958-5964",
          "snippet": "void btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t       struct seq_file *m)\n{\n\t(void) btf_type_seq_show_flags(btf, type_id, obj, m,\n\t\t\t\t       BTF_SHOW_NONAME | BTF_SHOW_COMPACT |\n\t\t\t\t       BTF_SHOW_ZERO | BTF_SHOW_UNSAFE);\n}",
          "includes": [
            "#include <linux/bpf_types.h>",
            "#include \"../tools/lib/bpf/relo_core.h\"",
            "#include <net/sock.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/kobject.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/skmsg.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/sort.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/file.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/slab.h>",
            "#include <linux/errno.h>",
            "#include <linux/ctype.h>",
            "#include <linux/compiler.h>",
            "#include <linux/seq_file.h>",
            "#include <uapi/linux/types.h>",
            "#include <uapi/linux/bpf_perf_event.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_types.h>\n#include \"../tools/lib/bpf/relo_core.h\"\n#include <net/sock.h>\n#include <linux/sysfs.h>\n#include <linux/kobject.h>\n#include <linux/bsearch.h>\n#include <linux/perf_event.h>\n#include <linux/skmsg.h>\n#include <linux/btf_ids.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/sort.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/uaccess.h>\n#include <linux/file.h>\n#include <linux/anon_inodes.h>\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/ctype.h>\n#include <linux/compiler.h>\n#include <linux/seq_file.h>\n#include <uapi/linux/types.h>\n#include <uapi/linux/bpf_perf_event.h>\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/btf.h>\n\nstatic int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);\n\nvoid btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t       struct seq_file *m)\n{\n\t(void) btf_type_seq_show_flags(btf, type_id, obj, m,\n\t\t\t\t       BTF_SHOW_NONAME | BTF_SHOW_COMPACT |\n\t\t\t\t       BTF_SHOW_ZERO | BTF_SHOW_UNSAFE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 2247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "seq_printf",
          "args": [
            "m",
            "\"\\tcpu%d: \"",
            "cpu"
          ],
          "line": 2245
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_printf",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "81-100",
          "snippet": "void trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "map->key_size"
          ],
          "line": 2243
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 2235
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "622-641",
          "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2233
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_percpu_map_seq_show_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t  struct seq_file *m)\n{\n\tstruct htab_elem *l;\n\tvoid __percpu *pptr;\n\tint cpu;\n\n\trcu_read_lock();\n\n\tl = __htab_map_lookup_elem(map, key);\n\tif (!l) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);\n\tseq_puts(m, \": {\\n\");\n\tpptr = htab_elem_get_ptr(l, map->key_size);\n\tfor_each_possible_cpu(cpu) {\n\t\tseq_printf(m, \"\\tcpu%d: \", cpu);\n\t\tbtf_type_seq_show(map->btf, map->btf_value_type_id,\n\t\t\t\t  per_cpu_ptr(pptr, cpu), m);\n\t\tseq_puts(m, \"\\n\");\n\t}\n\tseq_puts(m, \"}\\n\");\n\n\trcu_read_unlock();\n}"
  },
  {
    "function_name": "bpf_percpu_hash_update",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2208-2224",
    "snippet": "int bpf_percpu_hash_update(struct bpf_map *map, void *key, void *value,\n\t\t\t   u64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tint ret;\n\n\trcu_read_lock();\n\tif (htab_is_lru(htab))\n\t\tret = __htab_lru_percpu_map_update_elem(map, key, value,\n\t\t\t\t\t\t\tmap_flags, true);\n\telse\n\t\tret = __htab_percpu_map_update_elem(map, key, value, map_flags,\n\t\t\t\t\t\t    true);\n\trcu_read_unlock();\n\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2221
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_percpu_map_update_elem",
          "args": [
            "map",
            "key",
            "value",
            "map_flags",
            "true"
          ],
          "line": 2219
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_percpu_map_update_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1188-1241",
          "snippet": "static int __htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t void *value, u64 map_flags,\n\t\t\t\t\t bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tl_new = alloc_htab_elem(htab, key, value, key_size,\n\t\t\t\t\thash, true, onallcpus, NULL);\n\t\tif (IS_ERR(l_new)) {\n\t\t\tret = PTR_ERR(l_new);\n\t\t\tgoto err;\n\t\t}\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t void *value, u64 map_flags,\n\t\t\t\t\t bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tl_new = alloc_htab_elem(htab, key, value, key_size,\n\t\t\t\t\thash, true, onallcpus, NULL);\n\t\tif (IS_ERR(l_new)) {\n\t\t\tret = PTR_ERR(l_new);\n\t\t\tgoto err;\n\t\t}\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_lru_percpu_map_update_elem",
          "args": [
            "map",
            "key",
            "value",
            "map_flags",
            "true"
          ],
          "line": 2216
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_lru_percpu_map_update_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1243-1308",
          "snippet": "static int __htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags,\n\t\t\t\t\t     bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because LRU's elem alloc may need\n\t * to remove older elem from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tif (map_flags != BPF_EXIST) {\n\t\tl_new = prealloc_lru_pop(htab, key, hash);\n\t\tif (!l_new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_old->lru_node);\n\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tpcpu_init_value(htab, htab_elem_get_ptr(l_new, key_size),\n\t\t\t\tvalue, onallcpus);\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t\tl_new = NULL;\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l_new)\n\t\tbpf_lru_push_free(&htab->lru, &l_new->lru_node);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags,\n\t\t\t\t\t     bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because LRU's elem alloc may need\n\t * to remove older elem from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tif (map_flags != BPF_EXIST) {\n\t\tl_new = prealloc_lru_pop(htab, key, hash);\n\t\tif (!l_new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_old->lru_node);\n\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tpcpu_init_value(htab, htab_elem_get_ptr(l_new, key_size),\n\t\t\t\tvalue, onallcpus);\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t\tl_new = NULL;\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l_new)\n\t\tbpf_lru_push_free(&htab->lru, &l_new->lru_node);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_lru",
          "args": [
            "htab"
          ],
          "line": 2215
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_lru",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "198-202",
          "snippet": "static bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2214
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 2211
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nint bpf_percpu_hash_update(struct bpf_map *map, void *key, void *value,\n\t\t\t   u64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tint ret;\n\n\trcu_read_lock();\n\tif (htab_is_lru(htab))\n\t\tret = __htab_lru_percpu_map_update_elem(map, key, value,\n\t\t\t\t\t\t\tmap_flags, true);\n\telse\n\t\tret = __htab_percpu_map_update_elem(map, key, value, map_flags,\n\t\t\t\t\t\t    true);\n\trcu_read_unlock();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_percpu_hash_copy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2176-2206",
    "snippet": "int bpf_percpu_hash_copy(struct bpf_map *map, void *key, void *value)\n{\n\tstruct htab_elem *l;\n\tvoid __percpu *pptr;\n\tint ret = -ENOENT;\n\tint cpu, off = 0;\n\tu32 size;\n\n\t/* per_cpu areas are zero-filled and bpf programs can only\n\t * access 'value_size' of them, so copying rounded areas\n\t * will not leak any kernel data\n\t */\n\tsize = round_up(map->value_size, 8);\n\trcu_read_lock();\n\tl = __htab_map_lookup_elem(map, key);\n\tif (!l)\n\t\tgoto out;\n\t/* We do not mark LRU map element here in order to not mess up\n\t * eviction heuristics when user space does a map walk.\n\t */\n\tpptr = htab_elem_get_ptr(l, map->key_size);\n\tfor_each_possible_cpu(cpu) {\n\t\tbpf_long_memcpy(value + off,\n\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\toff += size;\n\t}\n\tret = 0;\nout:\n\trcu_read_unlock();\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2204
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_long_memcpy",
          "args": [
            "value + off",
            "per_cpu_ptr(pptr, cpu)",
            "size"
          ],
          "line": 2198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 2199
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "map->key_size"
          ],
          "line": 2196
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 2190
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "622-641",
          "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2189
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->value_size",
            "8"
          ],
          "line": 2188
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nint bpf_percpu_hash_copy(struct bpf_map *map, void *key, void *value)\n{\n\tstruct htab_elem *l;\n\tvoid __percpu *pptr;\n\tint ret = -ENOENT;\n\tint cpu, off = 0;\n\tu32 size;\n\n\t/* per_cpu areas are zero-filled and bpf programs can only\n\t * access 'value_size' of them, so copying rounded areas\n\t * will not leak any kernel data\n\t */\n\tsize = round_up(map->value_size, 8);\n\trcu_read_lock();\n\tl = __htab_map_lookup_elem(map, key);\n\tif (!l)\n\t\tgoto out;\n\t/* We do not mark LRU map element here in order to not mess up\n\t * eviction heuristics when user space does a map walk.\n\t */\n\tpptr = htab_elem_get_ptr(l, map->key_size);\n\tfor_each_possible_cpu(cpu) {\n\t\tbpf_long_memcpy(value + off,\n\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\toff += size;\n\t}\n\tret = 0;\nout:\n\trcu_read_unlock();\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_lru_percpu_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2164-2174",
    "snippet": "static void *htab_lru_percpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn this_cpu_ptr(htab_elem_get_ptr(l, map->key_size));\n\t}\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "htab_elem_get_ptr(l, map->key_size)"
          ],
          "line": 2170
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "map->key_size"
          ],
          "line": 2170
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_lru_node_set_ref",
          "args": [
            "&l->lru_node"
          ],
          "line": 2169
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_node_set_ref",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.h",
          "lines": "64-71",
          "snippet": "static inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}",
          "includes": [
            "#include <linux/spinlock_types.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/spinlock_types.h>\n#include <linux/list.h>\n\nstatic inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 2166
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "622-641",
          "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_lru_percpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn this_cpu_ptr(htab_elem_get_ptr(l, map->key_size));\n\t}\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "htab_percpu_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2154-2162",
    "snippet": "static void *htab_percpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn this_cpu_ptr(htab_elem_get_ptr(l, map->key_size));\n\telse\n\t\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "htab_elem_get_ptr(l, map->key_size)"
          ],
          "line": 2159
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "map->key_size"
          ],
          "line": 2159
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 2156
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "622-641",
          "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_percpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn this_cpu_ptr(htab_elem_get_ptr(l, map->key_size));\n\telse\n\t\treturn NULL;\n}"
  },
  {
    "function_name": "bpf_for_each_hash_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2052-2106",
    "snippet": "static int bpf_for_each_hash_elem(struct bpf_map *map, bpf_callback_t callback_fn,\n\t\t\t\t  void *callback_ctx, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tu32 roundup_key_size;\n\tint i, num_elems = 0;\n\tvoid __percpu *pptr;\n\tstruct bucket *b;\n\tvoid *key, *val;\n\tbool is_percpu;\n\tu64 ret = 0;\n\n\tif (flags != 0)\n\t\treturn -EINVAL;\n\n\tis_percpu = htab_is_percpu(htab);\n\n\troundup_key_size = round_up(map->key_size, 8);\n\t/* disable migration so percpu value prepared here will be the\n\t * same as the one seen by the bpf program with bpf_map_lookup_elem().\n\t */\n\tif (is_percpu)\n\t\tmigrate_disable();\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tkey = elem->key;\n\t\t\tif (is_percpu) {\n\t\t\t\t/* current cpu value for percpu map */\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tval = this_cpu_ptr(pptr);\n\t\t\t} else {\n\t\t\t\tval = elem->key + roundup_key_size;\n\t\t\t}\n\t\t\tnum_elems++;\n\t\t\tret = callback_fn((u64)(long)map, (u64)(long)key,\n\t\t\t\t\t  (u64)(long)val, (u64)(long)callback_ctx, 0);\n\t\t\t/* return value: 0 - continue, 1 - stop and return */\n\t\t\tif (ret) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock();\n\t}\nout:\n\tif (is_percpu)\n\t\tmigrate_enable();\n\treturn num_elems;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_enable",
          "args": [],
          "line": 2104
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2178-2206",
          "snippet": "void migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2100
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "callback_fn",
          "args": [
            "(u64)(long)map",
            "(u64)(long)key",
            "(u64)(long)val",
            "(u64)(long)callback_ctx",
            "0"
          ],
          "line": 2092
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "pptr"
          ],
          "line": 2087
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "elem",
            "map->key_size"
          ],
          "line": 2086
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_rcu",
          "args": [
            "elem",
            "n",
            "head",
            "hash_node"
          ],
          "line": 2082
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2080
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 2077
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 2072
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_is_percpu",
          "args": [
            "htab"
          ],
          "line": 2070
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "204-208",
          "snippet": "static bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 2055
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int bpf_for_each_hash_elem(struct bpf_map *map, bpf_callback_t callback_fn,\n\t\t\t\t  void *callback_ctx, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tu32 roundup_key_size;\n\tint i, num_elems = 0;\n\tvoid __percpu *pptr;\n\tstruct bucket *b;\n\tvoid *key, *val;\n\tbool is_percpu;\n\tu64 ret = 0;\n\n\tif (flags != 0)\n\t\treturn -EINVAL;\n\n\tis_percpu = htab_is_percpu(htab);\n\n\troundup_key_size = round_up(map->key_size, 8);\n\t/* disable migration so percpu value prepared here will be the\n\t * same as the one seen by the bpf program with bpf_map_lookup_elem().\n\t */\n\tif (is_percpu)\n\t\tmigrate_disable();\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tkey = elem->key;\n\t\t\tif (is_percpu) {\n\t\t\t\t/* current cpu value for percpu map */\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tval = this_cpu_ptr(pptr);\n\t\t\t} else {\n\t\t\t\tval = elem->key + roundup_key_size;\n\t\t\t}\n\t\t\tnum_elems++;\n\t\t\tret = callback_fn((u64)(long)map, (u64)(long)key,\n\t\t\t\t\t  (u64)(long)val, (u64)(long)callback_ctx, 0);\n\t\t\t/* return value: 0 - continue, 1 - stop and return */\n\t\t\tif (ret) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\trcu_read_unlock();\n\t}\nout:\n\tif (is_percpu)\n\t\tmigrate_enable();\n\treturn num_elems;\n}"
  },
  {
    "function_name": "bpf_iter_fini_hash_map",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2031-2036",
    "snippet": "static void bpf_iter_fini_hash_map(void *priv_data)\n{\n\tstruct bpf_iter_seq_hash_map_info *seq_info = priv_data;\n\n\tkfree(seq_info->percpu_value_buf);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "seq_info->percpu_value_buf"
          ],
          "line": 2035
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_iter_fini_hash_map(void *priv_data)\n{\n\tstruct bpf_iter_seq_hash_map_info *seq_info = priv_data;\n\n\tkfree(seq_info->percpu_value_buf);\n}"
  },
  {
    "function_name": "bpf_iter_init_hash_map",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2008-2029",
    "snippet": "static int bpf_iter_init_hash_map(void *priv_data,\n\t\t\t\t  struct bpf_iter_aux_info *aux)\n{\n\tstruct bpf_iter_seq_hash_map_info *seq_info = priv_data;\n\tstruct bpf_map *map = aux->map;\n\tvoid *value_buf;\n\tu32 buf_size;\n\n\tif (map->map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t    map->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH) {\n\t\tbuf_size = round_up(map->value_size, 8) * num_possible_cpus();\n\t\tvalue_buf = kmalloc(buf_size, GFP_USER | __GFP_NOWARN);\n\t\tif (!value_buf)\n\t\t\treturn -ENOMEM;\n\n\t\tseq_info->percpu_value_buf = value_buf;\n\t}\n\n\tseq_info->map = map;\n\tseq_info->htab = container_of(map, struct bpf_htab, map);\n\treturn 0;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 2027
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmalloc",
          "args": [
            "buf_size",
            "GFP_USER | __GFP_NOWARN"
          ],
          "line": 2019
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 2018
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->value_size",
            "8"
          ],
          "line": 2018
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int bpf_iter_init_hash_map(void *priv_data,\n\t\t\t\t  struct bpf_iter_aux_info *aux)\n{\n\tstruct bpf_iter_seq_hash_map_info *seq_info = priv_data;\n\tstruct bpf_map *map = aux->map;\n\tvoid *value_buf;\n\tu32 buf_size;\n\n\tif (map->map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t    map->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH) {\n\t\tbuf_size = round_up(map->value_size, 8) * num_possible_cpus();\n\t\tvalue_buf = kmalloc(buf_size, GFP_USER | __GFP_NOWARN);\n\t\tif (!value_buf)\n\t\t\treturn -ENOMEM;\n\n\t\tseq_info->percpu_value_buf = value_buf;\n\t}\n\n\tseq_info->map = map;\n\tseq_info->htab = container_of(map, struct bpf_htab, map);\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_hash_map_seq_stop",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "2000-2006",
    "snippet": "static void bpf_hash_map_seq_stop(struct seq_file *seq, void *v)\n{\n\tif (!v)\n\t\t(void)__bpf_hash_map_seq_show(seq, NULL);\n\telse\n\t\trcu_read_unlock();\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2005
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__bpf_hash_map_seq_show",
          "args": [
            "seq",
            "NULL"
          ],
          "line": 2003
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_hash_map_seq_show",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1956-1993",
          "snippet": "static int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tu32 roundup_key_size, roundup_value_size;\n\tstruct bpf_iter__bpf_map_elem ctx = {};\n\tstruct bpf_map *map = info->map;\n\tstruct bpf_iter_meta meta;\n\tint ret = 0, off = 0, cpu;\n\tstruct bpf_prog *prog;\n\tvoid __percpu *pptr;\n\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, elem == NULL);\n\tif (prog) {\n\t\tctx.meta = &meta;\n\t\tctx.map = info->map;\n\t\tif (elem) {\n\t\t\troundup_key_size = round_up(map->key_size, 8);\n\t\t\tctx.key = elem->key;\n\t\t\tif (!info->percpu_value_buf) {\n\t\t\t\tctx.value = elem->key + roundup_key_size;\n\t\t\t} else {\n\t\t\t\troundup_value_size = round_up(map->value_size, 8);\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tbpf_long_memcpy(info->percpu_value_buf + off,\n\t\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\t\troundup_value_size);\n\t\t\t\t\toff += roundup_value_size;\n\t\t\t\t}\n\t\t\t\tctx.value = info->percpu_value_buf;\n\t\t\t}\n\t\t}\n\t\tret = bpf_iter_run_prog(prog, &ctx);\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tu32 roundup_key_size, roundup_value_size;\n\tstruct bpf_iter__bpf_map_elem ctx = {};\n\tstruct bpf_map *map = info->map;\n\tstruct bpf_iter_meta meta;\n\tint ret = 0, off = 0, cpu;\n\tstruct bpf_prog *prog;\n\tvoid __percpu *pptr;\n\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, elem == NULL);\n\tif (prog) {\n\t\tctx.meta = &meta;\n\t\tctx.map = info->map;\n\t\tif (elem) {\n\t\t\troundup_key_size = round_up(map->key_size, 8);\n\t\t\tctx.key = elem->key;\n\t\t\tif (!info->percpu_value_buf) {\n\t\t\t\tctx.value = elem->key + roundup_key_size;\n\t\t\t} else {\n\t\t\t\troundup_value_size = round_up(map->value_size, 8);\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tbpf_long_memcpy(info->percpu_value_buf + off,\n\t\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\t\troundup_value_size);\n\t\t\t\t\toff += roundup_value_size;\n\t\t\t\t}\n\t\t\t\tctx.value = info->percpu_value_buf;\n\t\t\t}\n\t\t}\n\t\tret = bpf_iter_run_prog(prog, &ctx);\n\t}\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_hash_map_seq_stop(struct seq_file *seq, void *v)\n{\n\tif (!v)\n\t\t(void)__bpf_hash_map_seq_show(seq, NULL);\n\telse\n\t\trcu_read_unlock();\n}"
  },
  {
    "function_name": "bpf_hash_map_seq_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1995-1998",
    "snippet": "static int bpf_hash_map_seq_show(struct seq_file *seq, void *v)\n{\n\treturn __bpf_hash_map_seq_show(seq, v);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__bpf_hash_map_seq_show",
          "args": [
            "seq",
            "v"
          ],
          "line": 1997
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_hash_map_seq_show",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1956-1993",
          "snippet": "static int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tu32 roundup_key_size, roundup_value_size;\n\tstruct bpf_iter__bpf_map_elem ctx = {};\n\tstruct bpf_map *map = info->map;\n\tstruct bpf_iter_meta meta;\n\tint ret = 0, off = 0, cpu;\n\tstruct bpf_prog *prog;\n\tvoid __percpu *pptr;\n\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, elem == NULL);\n\tif (prog) {\n\t\tctx.meta = &meta;\n\t\tctx.map = info->map;\n\t\tif (elem) {\n\t\t\troundup_key_size = round_up(map->key_size, 8);\n\t\t\tctx.key = elem->key;\n\t\t\tif (!info->percpu_value_buf) {\n\t\t\t\tctx.value = elem->key + roundup_key_size;\n\t\t\t} else {\n\t\t\t\troundup_value_size = round_up(map->value_size, 8);\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tbpf_long_memcpy(info->percpu_value_buf + off,\n\t\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\t\troundup_value_size);\n\t\t\t\t\toff += roundup_value_size;\n\t\t\t\t}\n\t\t\t\tctx.value = info->percpu_value_buf;\n\t\t\t}\n\t\t}\n\t\tret = bpf_iter_run_prog(prog, &ctx);\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tu32 roundup_key_size, roundup_value_size;\n\tstruct bpf_iter__bpf_map_elem ctx = {};\n\tstruct bpf_map *map = info->map;\n\tstruct bpf_iter_meta meta;\n\tint ret = 0, off = 0, cpu;\n\tstruct bpf_prog *prog;\n\tvoid __percpu *pptr;\n\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, elem == NULL);\n\tif (prog) {\n\t\tctx.meta = &meta;\n\t\tctx.map = info->map;\n\t\tif (elem) {\n\t\t\troundup_key_size = round_up(map->key_size, 8);\n\t\t\tctx.key = elem->key;\n\t\t\tif (!info->percpu_value_buf) {\n\t\t\t\tctx.value = elem->key + roundup_key_size;\n\t\t\t} else {\n\t\t\t\troundup_value_size = round_up(map->value_size, 8);\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tbpf_long_memcpy(info->percpu_value_buf + off,\n\t\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\t\troundup_value_size);\n\t\t\t\t\toff += roundup_value_size;\n\t\t\t\t}\n\t\t\t\tctx.value = info->percpu_value_buf;\n\t\t\t}\n\t\t}\n\t\tret = bpf_iter_run_prog(prog, &ctx);\n\t}\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int bpf_hash_map_seq_show(struct seq_file *seq, void *v)\n{\n\treturn __bpf_hash_map_seq_show(seq, v);\n}"
  },
  {
    "function_name": "__bpf_hash_map_seq_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1956-1993",
    "snippet": "static int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tu32 roundup_key_size, roundup_value_size;\n\tstruct bpf_iter__bpf_map_elem ctx = {};\n\tstruct bpf_map *map = info->map;\n\tstruct bpf_iter_meta meta;\n\tint ret = 0, off = 0, cpu;\n\tstruct bpf_prog *prog;\n\tvoid __percpu *pptr;\n\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, elem == NULL);\n\tif (prog) {\n\t\tctx.meta = &meta;\n\t\tctx.map = info->map;\n\t\tif (elem) {\n\t\t\troundup_key_size = round_up(map->key_size, 8);\n\t\t\tctx.key = elem->key;\n\t\t\tif (!info->percpu_value_buf) {\n\t\t\t\tctx.value = elem->key + roundup_key_size;\n\t\t\t} else {\n\t\t\t\troundup_value_size = round_up(map->value_size, 8);\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tbpf_long_memcpy(info->percpu_value_buf + off,\n\t\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\t\troundup_value_size);\n\t\t\t\t\toff += roundup_value_size;\n\t\t\t\t}\n\t\t\t\tctx.value = info->percpu_value_buf;\n\t\t\t}\n\t\t}\n\t\tret = bpf_iter_run_prog(prog, &ctx);\n\t}\n\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_iter_run_prog",
          "args": [
            "prog",
            "&ctx"
          ],
          "line": 1989
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_iter_run_prog",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_iter.c",
          "lines": "683-700",
          "snippet": "int bpf_iter_run_prog(struct bpf_prog *prog, void *ctx)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tmigrate_disable();\n\tret = bpf_prog_run(prog, ctx);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\t/* bpf program can only return 0 or 1:\n\t *  0 : okay\n\t *  1 : retry the same object\n\t * The bpf_iter_run_prog() return value\n\t * will be seq_ops->show() return value.\n\t */\n\treturn ret == 0 ? 0 : -EAGAIN;\n}",
          "includes": [
            "#include <linux/bpf.h>",
            "#include <linux/filter.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf.h>\n#include <linux/filter.h>\n#include <linux/anon_inodes.h>\n#include <linux/fs.h>\n\nint bpf_iter_run_prog(struct bpf_prog *prog, void *ctx)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tmigrate_disable();\n\tret = bpf_prog_run(prog, ctx);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\t/* bpf program can only return 0 or 1:\n\t *  0 : okay\n\t *  1 : retry the same object\n\t * The bpf_iter_run_prog() return value\n\t * will be seq_ops->show() return value.\n\t */\n\treturn ret == 0 ? 0 : -EAGAIN;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_long_memcpy",
          "args": [
            "info->percpu_value_buf + off",
            "per_cpu_ptr(pptr, cpu)",
            "roundup_value_size"
          ],
          "line": 1981
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 1982
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "elem",
            "map->key_size"
          ],
          "line": 1979
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->value_size",
            "8"
          ],
          "line": 1978
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 1973
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_iter_get_info",
          "args": [
            "&meta",
            "elem == NULL"
          ],
          "line": 1968
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_iter_get_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_iter.c",
          "lines": "660-681",
          "snippet": "struct bpf_prog *bpf_iter_get_info(struct bpf_iter_meta *meta, bool in_stop)\n{\n\tstruct bpf_iter_priv_data *iter_priv;\n\tstruct seq_file *seq;\n\tvoid *seq_priv;\n\n\tseq = meta->seq;\n\tif (seq->file->f_op != &bpf_iter_fops)\n\t\treturn NULL;\n\n\tseq_priv = seq->private;\n\titer_priv = container_of(seq_priv, struct bpf_iter_priv_data,\n\t\t\t\t target_private);\n\n\tif (in_stop && iter_priv->done_stop)\n\t\treturn NULL;\n\n\tmeta->session_id = iter_priv->session_id;\n\tmeta->seq_num = iter_priv->seq_num;\n\n\treturn iter_priv->prog;\n}",
          "includes": [
            "#include <linux/bpf.h>",
            "#include <linux/filter.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static atomic64_t session_id;",
            "const struct file_operations bpf_iter_fops = {\n\t.open\t\t= iter_open,\n\t.llseek\t\t= no_llseek,\n\t.read\t\t= bpf_seq_read,\n\t.release\t= iter_release,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf.h>\n#include <linux/filter.h>\n#include <linux/anon_inodes.h>\n#include <linux/fs.h>\n\nstatic atomic64_t session_id;\nconst struct file_operations bpf_iter_fops = {\n\t.open\t\t= iter_open,\n\t.llseek\t\t= no_llseek,\n\t.read\t\t= bpf_seq_read,\n\t.release\t= iter_release,\n};\n\nstruct bpf_prog *bpf_iter_get_info(struct bpf_iter_meta *meta, bool in_stop)\n{\n\tstruct bpf_iter_priv_data *iter_priv;\n\tstruct seq_file *seq;\n\tvoid *seq_priv;\n\n\tseq = meta->seq;\n\tif (seq->file->f_op != &bpf_iter_fops)\n\t\treturn NULL;\n\n\tseq_priv = seq->private;\n\titer_priv = container_of(seq_priv, struct bpf_iter_priv_data,\n\t\t\t\t target_private);\n\n\tif (in_stop && iter_priv->done_stop)\n\t\treturn NULL;\n\n\tmeta->session_id = iter_priv->session_id;\n\tmeta->seq_num = iter_priv->seq_num;\n\n\treturn iter_priv->prog;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __bpf_hash_map_seq_show(struct seq_file *seq, struct htab_elem *elem)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tu32 roundup_key_size, roundup_value_size;\n\tstruct bpf_iter__bpf_map_elem ctx = {};\n\tstruct bpf_map *map = info->map;\n\tstruct bpf_iter_meta meta;\n\tint ret = 0, off = 0, cpu;\n\tstruct bpf_prog *prog;\n\tvoid __percpu *pptr;\n\n\tmeta.seq = seq;\n\tprog = bpf_iter_get_info(&meta, elem == NULL);\n\tif (prog) {\n\t\tctx.meta = &meta;\n\t\tctx.map = info->map;\n\t\tif (elem) {\n\t\t\troundup_key_size = round_up(map->key_size, 8);\n\t\t\tctx.key = elem->key;\n\t\t\tif (!info->percpu_value_buf) {\n\t\t\t\tctx.value = elem->key + roundup_key_size;\n\t\t\t} else {\n\t\t\t\troundup_value_size = round_up(map->value_size, 8);\n\t\t\t\tpptr = htab_elem_get_ptr(elem, map->key_size);\n\t\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\t\tbpf_long_memcpy(info->percpu_value_buf + off,\n\t\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\t\troundup_value_size);\n\t\t\t\t\toff += roundup_value_size;\n\t\t\t\t}\n\t\t\t\tctx.value = info->percpu_value_buf;\n\t\t\t}\n\t\t}\n\t\tret = bpf_iter_run_prog(prog, &ctx);\n\t}\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_hash_map_seq_next",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1947-1954",
    "snippet": "static void *bpf_hash_map_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\n\t++*pos;\n\t++info->skip_elems;\n\treturn bpf_hash_map_seq_find_next(info, v);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_hash_map_seq_find_next",
          "args": [
            "info",
            "v"
          ],
          "line": 1953
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_hash_map_seq_find_next",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1877-1931",
          "snippet": "static struct htab_elem *\nbpf_hash_map_seq_find_next(struct bpf_iter_seq_hash_map_info *info,\n\t\t\t   struct htab_elem *prev_elem)\n{\n\tconst struct bpf_htab *htab = info->htab;\n\tu32 skip_elems = info->skip_elems;\n\tu32 bucket_id = info->bucket_id;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tstruct bucket *b;\n\tu32 i, count;\n\n\tif (bucket_id >= htab->n_buckets)\n\t\treturn NULL;\n\n\t/* try to find next elem in the same bucket */\n\tif (prev_elem) {\n\t\t/* no update/deletion on this bucket, prev_elem should be still valid\n\t\t * and we won't skip elements.\n\t\t */\n\t\tn = rcu_dereference_raw(hlist_nulls_next_rcu(&prev_elem->hash_node));\n\t\telem = hlist_nulls_entry_safe(n, struct htab_elem, hash_node);\n\t\tif (elem)\n\t\t\treturn elem;\n\n\t\t/* not found, unlock and go to the next bucket */\n\t\tb = &htab->buckets[bucket_id++];\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tfor (i = bucket_id; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\n\t\tcount = 0;\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tif (count >= skip_elems) {\n\t\t\t\tinfo->bucket_id = i;\n\t\t\t\tinfo->skip_elems = count;\n\t\t\t\treturn elem;\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tinfo->bucket_id = i;\n\tinfo->skip_elems = 0;\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *\nbpf_hash_map_seq_find_next(struct bpf_iter_seq_hash_map_info *info,\n\t\t\t   struct htab_elem *prev_elem)\n{\n\tconst struct bpf_htab *htab = info->htab;\n\tu32 skip_elems = info->skip_elems;\n\tu32 bucket_id = info->bucket_id;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tstruct bucket *b;\n\tu32 i, count;\n\n\tif (bucket_id >= htab->n_buckets)\n\t\treturn NULL;\n\n\t/* try to find next elem in the same bucket */\n\tif (prev_elem) {\n\t\t/* no update/deletion on this bucket, prev_elem should be still valid\n\t\t * and we won't skip elements.\n\t\t */\n\t\tn = rcu_dereference_raw(hlist_nulls_next_rcu(&prev_elem->hash_node));\n\t\telem = hlist_nulls_entry_safe(n, struct htab_elem, hash_node);\n\t\tif (elem)\n\t\t\treturn elem;\n\n\t\t/* not found, unlock and go to the next bucket */\n\t\tb = &htab->buckets[bucket_id++];\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tfor (i = bucket_id; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\n\t\tcount = 0;\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tif (count >= skip_elems) {\n\t\t\t\tinfo->bucket_id = i;\n\t\t\t\tinfo->skip_elems = count;\n\t\t\t\treturn elem;\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tinfo->bucket_id = i;\n\tinfo->skip_elems = 0;\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *bpf_hash_map_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\n\t++*pos;\n\t++info->skip_elems;\n\treturn bpf_hash_map_seq_find_next(info, v);\n}"
  },
  {
    "function_name": "bpf_hash_map_seq_start",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1933-1945",
    "snippet": "static void *bpf_hash_map_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tstruct htab_elem *elem;\n\n\telem = bpf_hash_map_seq_find_next(info, NULL);\n\tif (!elem)\n\t\treturn NULL;\n\n\tif (*pos == 0)\n\t\t++*pos;\n\treturn elem;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_hash_map_seq_find_next",
          "args": [
            "info",
            "NULL"
          ],
          "line": 1938
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_hash_map_seq_find_next",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1877-1931",
          "snippet": "static struct htab_elem *\nbpf_hash_map_seq_find_next(struct bpf_iter_seq_hash_map_info *info,\n\t\t\t   struct htab_elem *prev_elem)\n{\n\tconst struct bpf_htab *htab = info->htab;\n\tu32 skip_elems = info->skip_elems;\n\tu32 bucket_id = info->bucket_id;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tstruct bucket *b;\n\tu32 i, count;\n\n\tif (bucket_id >= htab->n_buckets)\n\t\treturn NULL;\n\n\t/* try to find next elem in the same bucket */\n\tif (prev_elem) {\n\t\t/* no update/deletion on this bucket, prev_elem should be still valid\n\t\t * and we won't skip elements.\n\t\t */\n\t\tn = rcu_dereference_raw(hlist_nulls_next_rcu(&prev_elem->hash_node));\n\t\telem = hlist_nulls_entry_safe(n, struct htab_elem, hash_node);\n\t\tif (elem)\n\t\t\treturn elem;\n\n\t\t/* not found, unlock and go to the next bucket */\n\t\tb = &htab->buckets[bucket_id++];\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tfor (i = bucket_id; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\n\t\tcount = 0;\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tif (count >= skip_elems) {\n\t\t\t\tinfo->bucket_id = i;\n\t\t\t\tinfo->skip_elems = count;\n\t\t\t\treturn elem;\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tinfo->bucket_id = i;\n\tinfo->skip_elems = 0;\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *\nbpf_hash_map_seq_find_next(struct bpf_iter_seq_hash_map_info *info,\n\t\t\t   struct htab_elem *prev_elem)\n{\n\tconst struct bpf_htab *htab = info->htab;\n\tu32 skip_elems = info->skip_elems;\n\tu32 bucket_id = info->bucket_id;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tstruct bucket *b;\n\tu32 i, count;\n\n\tif (bucket_id >= htab->n_buckets)\n\t\treturn NULL;\n\n\t/* try to find next elem in the same bucket */\n\tif (prev_elem) {\n\t\t/* no update/deletion on this bucket, prev_elem should be still valid\n\t\t * and we won't skip elements.\n\t\t */\n\t\tn = rcu_dereference_raw(hlist_nulls_next_rcu(&prev_elem->hash_node));\n\t\telem = hlist_nulls_entry_safe(n, struct htab_elem, hash_node);\n\t\tif (elem)\n\t\t\treturn elem;\n\n\t\t/* not found, unlock and go to the next bucket */\n\t\tb = &htab->buckets[bucket_id++];\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tfor (i = bucket_id; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\n\t\tcount = 0;\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tif (count >= skip_elems) {\n\t\t\t\tinfo->bucket_id = i;\n\t\t\t\tinfo->skip_elems = count;\n\t\t\t\treturn elem;\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tinfo->bucket_id = i;\n\tinfo->skip_elems = 0;\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *bpf_hash_map_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tstruct bpf_iter_seq_hash_map_info *info = seq->private;\n\tstruct htab_elem *elem;\n\n\telem = bpf_hash_map_seq_find_next(info, NULL);\n\tif (!elem)\n\t\treturn NULL;\n\n\tif (*pos == 0)\n\t\t++*pos;\n\treturn elem;\n}"
  },
  {
    "function_name": "bpf_hash_map_seq_find_next",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1877-1931",
    "snippet": "static struct htab_elem *\nbpf_hash_map_seq_find_next(struct bpf_iter_seq_hash_map_info *info,\n\t\t\t   struct htab_elem *prev_elem)\n{\n\tconst struct bpf_htab *htab = info->htab;\n\tu32 skip_elems = info->skip_elems;\n\tu32 bucket_id = info->bucket_id;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tstruct bucket *b;\n\tu32 i, count;\n\n\tif (bucket_id >= htab->n_buckets)\n\t\treturn NULL;\n\n\t/* try to find next elem in the same bucket */\n\tif (prev_elem) {\n\t\t/* no update/deletion on this bucket, prev_elem should be still valid\n\t\t * and we won't skip elements.\n\t\t */\n\t\tn = rcu_dereference_raw(hlist_nulls_next_rcu(&prev_elem->hash_node));\n\t\telem = hlist_nulls_entry_safe(n, struct htab_elem, hash_node);\n\t\tif (elem)\n\t\t\treturn elem;\n\n\t\t/* not found, unlock and go to the next bucket */\n\t\tb = &htab->buckets[bucket_id++];\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tfor (i = bucket_id; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\n\t\tcount = 0;\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tif (count >= skip_elems) {\n\t\t\t\tinfo->bucket_id = i;\n\t\t\t\tinfo->skip_elems = count;\n\t\t\t\treturn elem;\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tinfo->bucket_id = i;\n\tinfo->skip_elems = 0;\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1924
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_rcu",
          "args": [
            "elem",
            "n",
            "head",
            "hash_node"
          ],
          "line": 1915
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1911
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_entry_safe",
          "args": [
            "n",
            "structhtab_elem",
            "hash_node"
          ],
          "line": 1899
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference_raw",
          "args": [
            "hlist_nulls_next_rcu(&prev_elem->hash_node)"
          ],
          "line": 1898
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_next_rcu",
          "args": [
            "&prev_elem->hash_node"
          ],
          "line": 1898
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *\nbpf_hash_map_seq_find_next(struct bpf_iter_seq_hash_map_info *info,\n\t\t\t   struct htab_elem *prev_elem)\n{\n\tconst struct bpf_htab *htab = info->htab;\n\tu32 skip_elems = info->skip_elems;\n\tu32 bucket_id = info->bucket_id;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *elem;\n\tstruct bucket *b;\n\tu32 i, count;\n\n\tif (bucket_id >= htab->n_buckets)\n\t\treturn NULL;\n\n\t/* try to find next elem in the same bucket */\n\tif (prev_elem) {\n\t\t/* no update/deletion on this bucket, prev_elem should be still valid\n\t\t * and we won't skip elements.\n\t\t */\n\t\tn = rcu_dereference_raw(hlist_nulls_next_rcu(&prev_elem->hash_node));\n\t\telem = hlist_nulls_entry_safe(n, struct htab_elem, hash_node);\n\t\tif (elem)\n\t\t\treturn elem;\n\n\t\t/* not found, unlock and go to the next bucket */\n\t\tb = &htab->buckets[bucket_id++];\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tfor (i = bucket_id; i < htab->n_buckets; i++) {\n\t\tb = &htab->buckets[i];\n\t\trcu_read_lock();\n\n\t\tcount = 0;\n\t\thead = &b->head;\n\t\thlist_nulls_for_each_entry_rcu(elem, n, head, hash_node) {\n\t\t\tif (count >= skip_elems) {\n\t\t\t\tinfo->bucket_id = i;\n\t\t\t\tinfo->skip_elems = count;\n\t\t\t\treturn elem;\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\trcu_read_unlock();\n\t\tskip_elems = 0;\n\t}\n\n\tinfo->bucket_id = i;\n\tinfo->skip_elems = 0;\n\treturn NULL;\n}"
  },
  {
    "function_name": "htab_lru_map_lookup_and_delete_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1860-1867",
    "snippet": "static int\nhtab_lru_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t     const union bpf_attr *attr,\n\t\t\t\t     union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  true, false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "true",
            "true",
            "false"
          ],
          "line": 1865
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_lru_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t     const union bpf_attr *attr,\n\t\t\t\t     union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  true, false);\n}"
  },
  {
    "function_name": "htab_lru_map_lookup_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1852-1858",
    "snippet": "static int\nhtab_lru_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,\n\t\t\t  union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  true, false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "false",
            "true",
            "false"
          ],
          "line": 1856
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_lru_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,\n\t\t\t  union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  true, false);\n}"
  },
  {
    "function_name": "htab_lru_percpu_map_lookup_and_delete_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1843-1850",
    "snippet": "static int\nhtab_lru_percpu_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t\t    const union bpf_attr *attr,\n\t\t\t\t\t    union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  true, true);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "true",
            "true",
            "true"
          ],
          "line": 1848
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_lru_percpu_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t\t    const union bpf_attr *attr,\n\t\t\t\t\t    union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  true, true);\n}"
  },
  {
    "function_name": "htab_lru_percpu_map_lookup_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1834-1841",
    "snippet": "static int\nhtab_lru_percpu_map_lookup_batch(struct bpf_map *map,\n\t\t\t\t const union bpf_attr *attr,\n\t\t\t\t union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  true, true);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "false",
            "true",
            "true"
          ],
          "line": 1839
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_lru_percpu_map_lookup_batch(struct bpf_map *map,\n\t\t\t\t const union bpf_attr *attr,\n\t\t\t\t union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  true, true);\n}"
  },
  {
    "function_name": "htab_map_lookup_and_delete_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1825-1832",
    "snippet": "static int\nhtab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t const union bpf_attr *attr,\n\t\t\t\t union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  false, false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "true",
            "false",
            "false"
          ],
          "line": 1830
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t const union bpf_attr *attr,\n\t\t\t\t union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  false, false);\n}"
  },
  {
    "function_name": "htab_map_lookup_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1817-1823",
    "snippet": "static int\nhtab_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,\n\t\t      union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  false, false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "false",
            "false",
            "false"
          ],
          "line": 1821
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,\n\t\t      union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  false, false);\n}"
  },
  {
    "function_name": "htab_percpu_map_lookup_and_delete_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1808-1815",
    "snippet": "static int\nhtab_percpu_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t\tconst union bpf_attr *attr,\n\t\t\t\t\tunion bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  false, true);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "true",
            "false",
            "true"
          ],
          "line": 1813
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_percpu_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t\tconst union bpf_attr *attr,\n\t\t\t\t\tunion bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, true,\n\t\t\t\t\t\t  false, true);\n}"
  },
  {
    "function_name": "htab_percpu_map_lookup_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1800-1806",
    "snippet": "static int\nhtab_percpu_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,\n\t\t\t     union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  false, true);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_batch",
          "args": [
            "map",
            "attr",
            "uattr",
            "false",
            "false",
            "true"
          ],
          "line": 1804
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_batch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1584-1798",
          "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\nhtab_percpu_map_lookup_batch(struct bpf_map *map, const union bpf_attr *attr,\n\t\t\t     union bpf_attr __user *uattr)\n{\n\treturn __htab_map_lookup_and_delete_batch(map, attr, uattr, false,\n\t\t\t\t\t\t  false, true);\n}"
  },
  {
    "function_name": "__htab_map_lookup_and_delete_batch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1584-1798",
    "snippet": "static int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "values"
          ],
          "line": 1796
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "keys"
          ],
          "line": 1795
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "put_user",
          "args": [
            "total",
            "&uattr->batch.count"
          ],
          "line": 1791
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_to_user",
          "args": [
            "ubatch",
            "&batch",
            "sizeof(batch)"
          ],
          "line": 1790
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_copy_to_user",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2043-2067",
          "snippet": "int bpf_prog_array_copy_to_user(struct bpf_prog_array *array,\n\t\t\t\t__u32 __user *prog_ids, u32 cnt)\n{\n\tunsigned long err = 0;\n\tbool nospc;\n\tu32 *ids;\n\n\t/* users of this function are doing:\n\t * cnt = bpf_prog_array_length();\n\t * if (cnt > 0)\n\t *     bpf_prog_array_copy_to_user(..., cnt);\n\t * so below kcalloc doesn't need extra cnt > 0 check.\n\t */\n\tids = kcalloc(cnt, sizeof(u32), GFP_USER | __GFP_NOWARN);\n\tif (!ids)\n\t\treturn -ENOMEM;\n\tnospc = bpf_prog_array_copy_core(array, ids, cnt);\n\terr = copy_to_user(prog_ids, ids, cnt * sizeof(u32));\n\tkfree(ids);\n\tif (err)\n\t\treturn -EFAULT;\n\tif (nospc)\n\t\treturn -ENOSPC;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nint bpf_prog_array_copy_to_user(struct bpf_prog_array *array,\n\t\t\t\t__u32 __user *prog_ids, u32 cnt)\n{\n\tunsigned long err = 0;\n\tbool nospc;\n\tu32 *ids;\n\n\t/* users of this function are doing:\n\t * cnt = bpf_prog_array_length();\n\t * if (cnt > 0)\n\t *     bpf_prog_array_copy_to_user(..., cnt);\n\t * so below kcalloc doesn't need extra cnt > 0 check.\n\t */\n\tids = kcalloc(cnt, sizeof(u32), GFP_USER | __GFP_NOWARN);\n\tif (!ids)\n\t\treturn -ENOMEM;\n\tnospc = bpf_prog_array_copy_core(array, ids, cnt);\n\terr = copy_to_user(prog_ids, ids, cnt * sizeof(u32));\n\tkfree(ids);\n\tif (err)\n\t\treturn -EFAULT;\n\tif (nospc)\n\t\treturn -ENOSPC;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "u64_to_user_ptr",
          "args": [
            "attr->batch.out_batch"
          ],
          "line": 1789
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_enable_instrumentation",
          "args": [],
          "line": 1767
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1766
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lru_push_free",
          "args": [
            "htab",
            "l"
          ],
          "line": 1754
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lru_push_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1115-1119",
          "snippet": "static void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "batch",
            "flags"
          ],
          "line": 1748
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_htab_elem",
          "args": [
            "htab",
            "l"
          ],
          "line": 1741
        },
        "resolved": true,
        "details": {
          "function_name": "free_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "855-867",
          "snippet": "static void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 1730
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_and_init_map_value",
          "args": [
            "map",
            "dst_val"
          ],
          "line": 1727
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_map_value",
          "args": [
            "map",
            "dst_val",
            "value"
          ],
          "line": 1726
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_map_value_locked",
          "args": [
            "map",
            "dst_val",
            "value",
            "true"
          ],
          "line": 1723
        },
        "resolved": true,
        "details": {
          "function_name": "copy_map_value_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "337-351",
          "snippet": "void copy_map_value_locked(struct bpf_map *map, void *dst, void *src,\n\t\t\t   bool lock_src)\n{\n\tstruct bpf_spin_lock *lock;\n\n\tif (lock_src)\n\t\tlock = src + map->spin_lock_off;\n\telse\n\t\tlock = dst + map->spin_lock_off;\n\tpreempt_disable();\n\t__bpf_spin_lock_irqsave(lock);\n\tcopy_map_value(map, dst, src);\n\t__bpf_spin_unlock_irqrestore(lock);\n\tpreempt_enable();\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid copy_map_value_locked(struct bpf_map *map, void *dst, void *src,\n\t\t\t   bool lock_src)\n{\n\tstruct bpf_spin_lock *lock;\n\n\tif (lock_src)\n\t\tlock = src + map->spin_lock_off;\n\telse\n\t\tlock = dst + map->spin_lock_off;\n\tpreempt_disable();\n\t__bpf_spin_lock_irqsave(lock);\n\tcopy_map_value(map, dst, src);\n\t__bpf_spin_unlock_irqrestore(lock);\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_long_memcpy",
          "args": [
            "dst_val + off",
            "per_cpu_ptr(pptr, cpu)",
            "size"
          ],
          "line": 1716
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 1717
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "map->key_size"
          ],
          "line": 1714
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "dst_key",
            "l->key",
            "key_size"
          ],
          "line": 1708
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_safe",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 1707
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "values"
          ],
          "line": 1699
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "keys"
          ],
          "line": 1698
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_enable_instrumentation",
          "args": [],
          "line": 1697
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_enable_instrumentation",
          "args": [],
          "line": 1686
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_rcu",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 1670
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "batch",
            "&flags"
          ],
          "line": 1664
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1656
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_disable_instrumentation",
          "args": [],
          "line": 1655
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvmalloc_array",
          "args": [
            "value_size",
            "bucket_size",
            "GFP_USER | __GFP_NOWARN"
          ],
          "line": 1648
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvmalloc_array",
          "args": [
            "key_size",
            "bucket_size",
            "GFP_USER | __GFP_NOWARN"
          ],
          "line": 1647
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 1636
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "value_size",
            "8"
          ],
          "line": 1634
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.key_size",
            "8"
          ],
          "line": 1632
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "&batch",
            "ubatch",
            "sizeof(batch)"
          ],
          "line": 1625
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "put_user",
          "args": [
            "0",
            "&uattr->batch.count"
          ],
          "line": 1621
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_value_has_spin_lock",
          "args": [
            "map"
          ],
          "line": 1610
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "u64_to_user_ptr",
          "args": [
            "attr->batch.in_batch"
          ],
          "line": 1596
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "u64_to_user_ptr",
          "args": [
            "attr->batch.keys"
          ],
          "line": 1595
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "u64_to_user_ptr",
          "args": [
            "attr->batch.values"
          ],
          "line": 1594
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1591
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int\n__htab_map_lookup_and_delete_batch(struct bpf_map *map,\n\t\t\t\t   const union bpf_attr *attr,\n\t\t\t\t   union bpf_attr __user *uattr,\n\t\t\t\t   bool do_delete, bool is_lru_map,\n\t\t\t\t   bool is_percpu)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tu32 bucket_cnt, total, key_size, value_size, roundup_key_size;\n\tvoid *keys = NULL, *values = NULL, *value, *dst_key, *dst_val;\n\tvoid __user *uvalues = u64_to_user_ptr(attr->batch.values);\n\tvoid __user *ukeys = u64_to_user_ptr(attr->batch.keys);\n\tvoid __user *ubatch = u64_to_user_ptr(attr->batch.in_batch);\n\tu32 batch, max_count, size, bucket_size;\n\tstruct htab_elem *node_to_free = NULL;\n\tu64 elem_map_flags, map_flags;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags = 0;\n\tbool locked = false;\n\tstruct htab_elem *l;\n\tstruct bucket *b;\n\tint ret = 0;\n\n\telem_map_flags = attr->batch.elem_flags;\n\tif ((elem_map_flags & ~BPF_F_LOCK) ||\n\t    ((elem_map_flags & BPF_F_LOCK) && !map_value_has_spin_lock(map)))\n\t\treturn -EINVAL;\n\n\tmap_flags = attr->batch.flags;\n\tif (map_flags)\n\t\treturn -EINVAL;\n\n\tmax_count = attr->batch.count;\n\tif (!max_count)\n\t\treturn 0;\n\n\tif (put_user(0, &uattr->batch.count))\n\t\treturn -EFAULT;\n\n\tbatch = 0;\n\tif (ubatch && copy_from_user(&batch, ubatch, sizeof(batch)))\n\t\treturn -EFAULT;\n\n\tif (batch >= htab->n_buckets)\n\t\treturn -ENOENT;\n\n\tkey_size = htab->map.key_size;\n\troundup_key_size = round_up(htab->map.key_size, 8);\n\tvalue_size = htab->map.value_size;\n\tsize = round_up(value_size, 8);\n\tif (is_percpu)\n\t\tvalue_size = size * num_possible_cpus();\n\ttotal = 0;\n\t/* while experimenting with hash tables with sizes ranging from 10 to\n\t * 1000, it was observed that a bucket can have upto 5 entries.\n\t */\n\tbucket_size = 5;\n\nalloc:\n\t/* We cannot do copy_from_user or copy_to_user inside\n\t * the rcu_read_lock. Allocate enough space here.\n\t */\n\tkeys = kvmalloc_array(key_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tvalues = kvmalloc_array(value_size, bucket_size, GFP_USER | __GFP_NOWARN);\n\tif (!keys || !values) {\n\t\tret = -ENOMEM;\n\t\tgoto after_loop;\n\t}\n\nagain:\n\tbpf_disable_instrumentation();\n\trcu_read_lock();\nagain_nocopy:\n\tdst_key = keys;\n\tdst_val = values;\n\tb = &htab->buckets[batch];\n\thead = &b->head;\n\t/* do not grab the lock unless need it (bucket_cnt > 0). */\n\tif (locked) {\n\t\tret = htab_lock_bucket(htab, b, batch, &flags);\n\t\tif (ret)\n\t\t\tgoto next_batch;\n\t}\n\n\tbucket_cnt = 0;\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tbucket_cnt++;\n\n\tif (bucket_cnt && !locked) {\n\t\tlocked = true;\n\t\tgoto again_nocopy;\n\t}\n\n\tif (bucket_cnt > (max_count - total)) {\n\t\tif (total == 0)\n\t\t\tret = -ENOSPC;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tgoto after_loop;\n\t}\n\n\tif (bucket_cnt > bucket_size) {\n\t\tbucket_size = bucket_cnt;\n\t\t/* Note that since bucket_cnt > 0 here, it is implicit\n\t\t * that the locked was grabbed, so release it.\n\t\t */\n\t\thtab_unlock_bucket(htab, b, batch, flags);\n\t\trcu_read_unlock();\n\t\tbpf_enable_instrumentation();\n\t\tkvfree(keys);\n\t\tkvfree(values);\n\t\tgoto alloc;\n\t}\n\n\t/* Next block is only safe to run if you have grabbed the lock */\n\tif (!locked)\n\t\tgoto next_batch;\n\n\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\tmemcpy(dst_key, l->key, key_size);\n\n\t\tif (is_percpu) {\n\t\t\tint off = 0, cpu;\n\t\t\tvoid __percpu *pptr;\n\n\t\t\tpptr = htab_elem_get_ptr(l, map->key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(dst_val + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu), size);\n\t\t\t\toff += size;\n\t\t\t}\n\t\t} else {\n\t\t\tvalue = l->key + roundup_key_size;\n\t\t\tif (elem_map_flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, dst_val, value,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, dst_val, value);\n\t\t\tcheck_and_init_map_value(map, dst_val);\n\t\t}\n\t\tif (do_delete) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\n\t\t\t/* bpf_lru_push_free() will acquire lru_lock, which\n\t\t\t * may cause deadlock. See comments in function\n\t\t\t * prealloc_lru_pop(). Let us do bpf_lru_push_free()\n\t\t\t * after releasing the bucket lock.\n\t\t\t */\n\t\t\tif (is_lru_map) {\n\t\t\t\tl->batch_flink = node_to_free;\n\t\t\t\tnode_to_free = l;\n\t\t\t} else {\n\t\t\t\tfree_htab_elem(htab, l);\n\t\t\t}\n\t\t}\n\t\tdst_key += key_size;\n\t\tdst_val += value_size;\n\t}\n\n\thtab_unlock_bucket(htab, b, batch, flags);\n\tlocked = false;\n\n\twhile (node_to_free) {\n\t\tl = node_to_free;\n\t\tnode_to_free = node_to_free->batch_flink;\n\t\thtab_lru_push_free(htab, l);\n\t}\n\nnext_batch:\n\t/* If we are not copying data, we can go to next bucket and avoid\n\t * unlocking the rcu.\n\t */\n\tif (!bucket_cnt && (batch + 1 < htab->n_buckets)) {\n\t\tbatch++;\n\t\tgoto again_nocopy;\n\t}\n\n\trcu_read_unlock();\n\tbpf_enable_instrumentation();\n\tif (bucket_cnt && (copy_to_user(ukeys + total * key_size, keys,\n\t    key_size * bucket_cnt) ||\n\t    copy_to_user(uvalues + total * value_size, values,\n\t    value_size * bucket_cnt))) {\n\t\tret = -EFAULT;\n\t\tgoto after_loop;\n\t}\n\n\ttotal += bucket_cnt;\n\tbatch++;\n\tif (batch >= htab->n_buckets) {\n\t\tret = -ENOENT;\n\t\tgoto after_loop;\n\t}\n\tgoto again;\n\nafter_loop:\n\tif (ret == -EFAULT)\n\t\tgoto out;\n\n\t/* copy # of entries and next batch */\n\tubatch = u64_to_user_ptr(attr->batch.out_batch);\n\tif (copy_to_user(ubatch, &batch, sizeof(batch)) ||\n\t    put_user(total, &uattr->batch.count))\n\t\tret = -EFAULT;\n\nout:\n\tkvfree(keys);\n\tkvfree(values);\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_lru_percpu_map_lookup_and_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1576-1582",
    "snippet": "static int htab_lru_percpu_map_lookup_and_delete_elem(struct bpf_map *map,\n\t\t\t\t\t\t      void *key, void *value,\n\t\t\t\t\t\t      u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, true, true,\n\t\t\t\t\t\t flags);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_elem",
          "args": [
            "map",
            "key",
            "value",
            "true",
            "true",
            "flags"
          ],
          "line": 1580
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1490-1552",
          "snippet": "static int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_lru_percpu_map_lookup_and_delete_elem(struct bpf_map *map,\n\t\t\t\t\t\t      void *key, void *value,\n\t\t\t\t\t\t      u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, true, true,\n\t\t\t\t\t\t flags);\n}"
  },
  {
    "function_name": "htab_lru_map_lookup_and_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1569-1574",
    "snippet": "static int htab_lru_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t       void *value, u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, true, false,\n\t\t\t\t\t\t flags);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_elem",
          "args": [
            "map",
            "key",
            "value",
            "true",
            "false",
            "flags"
          ],
          "line": 1572
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1490-1552",
          "snippet": "static int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_lru_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t       void *value, u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, true, false,\n\t\t\t\t\t\t flags);\n}"
  },
  {
    "function_name": "htab_percpu_map_lookup_and_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1561-1567",
    "snippet": "static int htab_percpu_map_lookup_and_delete_elem(struct bpf_map *map,\n\t\t\t\t\t\t  void *key, void *value,\n\t\t\t\t\t\t  u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, false, true,\n\t\t\t\t\t\t flags);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_elem",
          "args": [
            "map",
            "key",
            "value",
            "false",
            "true",
            "flags"
          ],
          "line": 1565
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1490-1552",
          "snippet": "static int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_percpu_map_lookup_and_delete_elem(struct bpf_map *map,\n\t\t\t\t\t\t  void *key, void *value,\n\t\t\t\t\t\t  u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, false, true,\n\t\t\t\t\t\t flags);\n}"
  },
  {
    "function_name": "htab_map_lookup_and_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1554-1559",
    "snippet": "static int htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t   void *value, u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, false, false,\n\t\t\t\t\t\t flags);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_map_lookup_and_delete_elem",
          "args": [
            "map",
            "key",
            "value",
            "false",
            "false",
            "flags"
          ],
          "line": 1557
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_and_delete_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1490-1552",
          "snippet": "static int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t   void *value, u64 flags)\n{\n\treturn __htab_map_lookup_and_delete_elem(map, key, value, false, false,\n\t\t\t\t\t\t flags);\n}"
  },
  {
    "function_name": "__htab_map_lookup_and_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1490-1552",
    "snippet": "static int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_lru_push_free",
          "args": [
            "htab",
            "l"
          ],
          "line": 1549
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lru_push_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1115-1119",
          "snippet": "static void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "bflags"
          ],
          "line": 1546
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_htab_elem",
          "args": [
            "htab",
            "l"
          ],
          "line": 1543
        },
        "resolved": true,
        "details": {
          "function_name": "free_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "855-867",
          "snippet": "static void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 1541
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_and_init_map_value",
          "args": [
            "map",
            "value"
          ],
          "line": 1538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_map_value",
          "args": [
            "map",
            "value",
            "l->key +\n\t\t\t\t\t       roundup_key_size"
          ],
          "line": 1536
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_map_value_locked",
          "args": [
            "map",
            "value",
            "l->key +\n\t\t\t\t\t\t      roundup_key_size",
            "true"
          ],
          "line": 1532
        },
        "resolved": true,
        "details": {
          "function_name": "copy_map_value_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "337-351",
          "snippet": "void copy_map_value_locked(struct bpf_map *map, void *dst, void *src,\n\t\t\t   bool lock_src)\n{\n\tstruct bpf_spin_lock *lock;\n\n\tif (lock_src)\n\t\tlock = src + map->spin_lock_off;\n\telse\n\t\tlock = dst + map->spin_lock_off;\n\tpreempt_disable();\n\t__bpf_spin_lock_irqsave(lock);\n\tcopy_map_value(map, dst, src);\n\t__bpf_spin_unlock_irqrestore(lock);\n\tpreempt_enable();\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid copy_map_value_locked(struct bpf_map *map, void *dst, void *src,\n\t\t\t   bool lock_src)\n{\n\tstruct bpf_spin_lock *lock;\n\n\tif (lock_src)\n\t\tlock = src + map->spin_lock_off;\n\telse\n\t\tlock = dst + map->spin_lock_off;\n\tpreempt_disable();\n\t__bpf_spin_lock_irqsave(lock);\n\tcopy_map_value(map, dst, src);\n\t__bpf_spin_unlock_irqrestore(lock);\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 1529
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_long_memcpy",
          "args": [
            "value + off",
            "per_cpu_ptr(pptr, cpu)",
            "roundup_value_size"
          ],
          "line": 1523
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 1524
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "key_size"
          ],
          "line": 1521
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->value_size",
            "8"
          ],
          "line": 1517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1512
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&bflags"
          ],
          "line": 1508
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1505
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1504
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1494
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_map_lookup_and_delete_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, bool is_lru_map,\n\t\t\t\t\t     bool is_percpu, u64 flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tunsigned long bflags;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\tstruct bucket *b;\n\tint ret;\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &bflags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\tif (!l) {\n\t\tret = -ENOENT;\n\t} else {\n\t\tif (is_percpu) {\n\t\t\tu32 roundup_value_size = round_up(map->value_size, 8);\n\t\t\tvoid __percpu *pptr;\n\t\t\tint off = 0, cpu;\n\n\t\t\tpptr = htab_elem_get_ptr(l, key_size);\n\t\t\tfor_each_possible_cpu(cpu) {\n\t\t\t\tbpf_long_memcpy(value + off,\n\t\t\t\t\t\tper_cpu_ptr(pptr, cpu),\n\t\t\t\t\t\troundup_value_size);\n\t\t\t\toff += roundup_value_size;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 roundup_key_size = round_up(map->key_size, 8);\n\n\t\t\tif (flags & BPF_F_LOCK)\n\t\t\t\tcopy_map_value_locked(map, value, l->key +\n\t\t\t\t\t\t      roundup_key_size,\n\t\t\t\t\t\t      true);\n\t\t\telse\n\t\t\t\tcopy_map_value(map, value, l->key +\n\t\t\t\t\t       roundup_key_size);\n\t\t\tcheck_and_init_map_value(map, value);\n\t\t}\n\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tif (!is_lru_map)\n\t\t\tfree_htab_elem(htab, l);\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, bflags);\n\n\tif (is_lru_map && l)\n\t\thtab_lru_push_free(htab, l);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_map_seq_show_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1469-1488",
    "snippet": "static void htab_map_seq_show_elem(struct bpf_map *map, void *key,\n\t\t\t\t   struct seq_file *m)\n{\n\tvoid *value;\n\n\trcu_read_lock();\n\n\tvalue = htab_map_lookup_elem(map, key);\n\tif (!value) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);\n\tseq_puts(m, \": \");\n\tbtf_type_seq_show(map->btf, map->btf_value_type_id, value, m);\n\tseq_puts(m, \"\\n\");\n\n\trcu_read_unlock();\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1487
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_puts",
          "args": [
            "m",
            "\"\\n\""
          ],
          "line": 1485
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "205-220",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      },
      {
        "call_info": {
          "callee": "btf_type_seq_show",
          "args": [
            "map->btf",
            "map->btf_value_type_id",
            "value",
            "m"
          ],
          "line": 1484
        },
        "resolved": true,
        "details": {
          "function_name": "btf_type_seq_show",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/btf.c",
          "lines": "5958-5964",
          "snippet": "void btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t       struct seq_file *m)\n{\n\t(void) btf_type_seq_show_flags(btf, type_id, obj, m,\n\t\t\t\t       BTF_SHOW_NONAME | BTF_SHOW_COMPACT |\n\t\t\t\t       BTF_SHOW_ZERO | BTF_SHOW_UNSAFE);\n}",
          "includes": [
            "#include <linux/bpf_types.h>",
            "#include \"../tools/lib/bpf/relo_core.h\"",
            "#include <net/sock.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/kobject.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/skmsg.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/sort.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/file.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/slab.h>",
            "#include <linux/errno.h>",
            "#include <linux/ctype.h>",
            "#include <linux/compiler.h>",
            "#include <linux/seq_file.h>",
            "#include <uapi/linux/types.h>",
            "#include <uapi/linux/bpf_perf_event.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_types.h>\n#include \"../tools/lib/bpf/relo_core.h\"\n#include <net/sock.h>\n#include <linux/sysfs.h>\n#include <linux/kobject.h>\n#include <linux/bsearch.h>\n#include <linux/perf_event.h>\n#include <linux/skmsg.h>\n#include <linux/btf_ids.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/sort.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/uaccess.h>\n#include <linux/file.h>\n#include <linux/anon_inodes.h>\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/ctype.h>\n#include <linux/compiler.h>\n#include <linux/seq_file.h>\n#include <uapi/linux/types.h>\n#include <uapi/linux/bpf_perf_event.h>\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/btf.h>\n\nstatic int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);\n\nvoid btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,\n\t\t       struct seq_file *m)\n{\n\t(void) btf_type_seq_show_flags(btf, type_id, obj, m,\n\t\t\t\t       BTF_SHOW_NONAME | BTF_SHOW_COMPACT |\n\t\t\t\t       BTF_SHOW_ZERO | BTF_SHOW_UNSAFE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 1476
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "643-651",
          "snippet": "static void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1474
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_map_seq_show_elem(struct bpf_map *map, void *key,\n\t\t\t\t   struct seq_file *m)\n{\n\tvoid *value;\n\n\trcu_read_lock();\n\n\tvalue = htab_map_lookup_elem(map, key);\n\tif (!value) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\n\tbtf_type_seq_show(map->btf, map->btf_key_type_id, key, m);\n\tseq_puts(m, \": \");\n\tbtf_type_seq_show(map->btf, map->btf_value_type_id, value, m);\n\tseq_puts(m, \"\\n\");\n\n\trcu_read_unlock();\n}"
  },
  {
    "function_name": "htab_map_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1442-1467",
    "snippet": "static void htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tint i;\n\n\t/* bpf_free_used_maps() or close(map_fd) will trigger this map_free callback.\n\t * bpf_free_used_maps() is called after bpf prog is no longer executing.\n\t * There is no need to synchronize_rcu() here to protect map elements.\n\t */\n\n\t/* some of free_htab_elem() callbacks for elements of this map may\n\t * not have executed. Wait for them.\n\t */\n\trcu_barrier();\n\tif (!htab_is_prealloc(htab))\n\t\tdelete_all_elements(htab);\n\telse\n\t\tprealloc_destroy(htab);\n\n\tfree_percpu(htab->extra_elems);\n\tbpf_map_area_free(htab->buckets);\n\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++)\n\t\tfree_percpu(htab->map_locked[i]);\n\tlockdep_unregister_key(&htab->lockdep_key);\n\tkfree(htab);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define HASHTAB_MAP_LOCK_COUNT 8"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "htab"
          ],
          "line": 1466
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_unregister_key",
          "args": [
            "&htab->lockdep_key"
          ],
          "line": 1465
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_unregister_key",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "6294-6328",
          "snippet": "void lockdep_unregister_key(struct lock_class_key *key)\n{\n\tstruct hlist_head *hash_head = keyhashentry(key);\n\tstruct lock_class_key *k;\n\tstruct pending_free *pf;\n\tunsigned long flags;\n\tbool found = false;\n\n\tmight_sleep();\n\n\tif (WARN_ON_ONCE(static_obj(key)))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tif (!graph_lock())\n\t\tgoto out_irq;\n\n\tpf = get_pending_free();\n\thlist_for_each_entry_rcu(k, hash_head, hash_entry) {\n\t\tif (k == key) {\n\t\t\thlist_del_rcu(&k->hash_entry);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tWARN_ON_ONCE(!found);\n\t__lockdep_free_key_range(pf, key, 1);\n\tcall_rcu_zapped(pf);\n\tgraph_unlock();\nout_irq:\n\traw_local_irq_restore(flags);\n\n\t/* Wait until is_dynamic_key() has finished accessing k->hash_entry. */\n\tsynchronize_rcu();\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct delayed_free {\n\tstruct rcu_head\t\trcu_head;\n\tint\t\t\tindex;\n\tint\t\t\tscheduled;\n\tstruct pending_free\tpf[2];\n} delayed_free;",
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic struct delayed_free {\n\tstruct rcu_head\t\trcu_head;\n\tint\t\t\tindex;\n\tint\t\t\tscheduled;\n\tstruct pending_free\tpf[2];\n} delayed_free;\nstatic noinstr struct;\n\nvoid lockdep_unregister_key(struct lock_class_key *key)\n{\n\tstruct hlist_head *hash_head = keyhashentry(key);\n\tstruct lock_class_key *k;\n\tstruct pending_free *pf;\n\tunsigned long flags;\n\tbool found = false;\n\n\tmight_sleep();\n\n\tif (WARN_ON_ONCE(static_obj(key)))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tif (!graph_lock())\n\t\tgoto out_irq;\n\n\tpf = get_pending_free();\n\thlist_for_each_entry_rcu(k, hash_head, hash_entry) {\n\t\tif (k == key) {\n\t\t\thlist_del_rcu(&k->hash_entry);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tWARN_ON_ONCE(!found);\n\t__lockdep_free_key_range(pf, key, 1);\n\tcall_rcu_zapped(pf);\n\tgraph_unlock();\nout_irq:\n\traw_local_irq_restore(flags);\n\n\t/* Wait until is_dynamic_key() has finished accessing k->hash_entry. */\n\tsynchronize_rcu();\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "htab->map_locked[i]"
          ],
          "line": 1464
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/arraymap.c",
          "lines": "21-29",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "htab->buckets"
          ],
          "line": 1462
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "prealloc_destroy",
          "args": [
            "htab"
          ],
          "line": 1459
        },
        "resolved": true,
        "details": {
          "function_name": "prealloc_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "365-373",
          "snippet": "static void prealloc_destroy(struct bpf_htab *htab)\n{\n\thtab_free_elems(htab);\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_destroy(&htab->lru);\n\telse\n\t\tpcpu_freelist_destroy(&htab->freelist);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void prealloc_destroy(struct bpf_htab *htab)\n{\n\thtab_free_elems(htab);\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_destroy(&htab->lru);\n\telse\n\t\tpcpu_freelist_destroy(&htab->freelist);\n}"
        }
      },
      {
        "call_info": {
          "callee": "delete_all_elements",
          "args": [
            "htab"
          ],
          "line": 1457
        },
        "resolved": true,
        "details": {
          "function_name": "delete_all_elements",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1396-1410",
          "snippet": "static void delete_all_elements(struct bpf_htab *htab)\n{\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\t\thtab_elem_free(htab, l);\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void delete_all_elements(struct bpf_htab *htab)\n{\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\t\thtab_elem_free(htab, l);\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 1456
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_barrier",
          "args": [],
          "line": 1455
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1569-1572",
          "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1444
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_COUNT 8\n\nstatic void htab_map_free(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tint i;\n\n\t/* bpf_free_used_maps() or close(map_fd) will trigger this map_free callback.\n\t * bpf_free_used_maps() is called after bpf prog is no longer executing.\n\t * There is no need to synchronize_rcu() here to protect map elements.\n\t */\n\n\t/* some of free_htab_elem() callbacks for elements of this map may\n\t * not have executed. Wait for them.\n\t */\n\trcu_barrier();\n\tif (!htab_is_prealloc(htab))\n\t\tdelete_all_elements(htab);\n\telse\n\t\tprealloc_destroy(htab);\n\n\tfree_percpu(htab->extra_elems);\n\tbpf_map_area_free(htab->buckets);\n\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++)\n\t\tfree_percpu(htab->map_locked[i]);\n\tlockdep_unregister_key(&htab->lockdep_key);\n\tkfree(htab);\n}"
  },
  {
    "function_name": "htab_map_free_timers",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1429-1439",
    "snippet": "static void htab_map_free_timers(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\n\tif (likely(!map_value_has_timer(&htab->map)))\n\t\treturn;\n\tif (!htab_is_prealloc(htab))\n\t\thtab_free_malloced_timers(htab);\n\telse\n\t\thtab_free_prealloced_timers(htab);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_free_prealloced_timers",
          "args": [
            "htab"
          ],
          "line": 1438
        },
        "resolved": true,
        "details": {
          "function_name": "htab_free_prealloced_timers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "236-255",
          "snippet": "static void htab_free_prealloced_timers(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint i;\n\n\tif (likely(!map_value_has_timer(&htab->map)))\n\t\treturn;\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tstruct htab_elem *elem;\n\n\t\telem = get_htab_elem(htab, i);\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_prealloced_timers(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint i;\n\n\tif (likely(!map_value_has_timer(&htab->map)))\n\t\treturn;\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tstruct htab_elem *elem;\n\n\t\telem = get_htab_elem(htab, i);\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_free_malloced_timers",
          "args": [
            "htab"
          ],
          "line": 1436
        },
        "resolved": true,
        "details": {
          "function_name": "htab_free_malloced_timers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1412-1427",
          "snippet": "static void htab_free_malloced_timers(struct bpf_htab *htab)\n{\n\tint i;\n\n\trcu_read_lock();\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry(l, n, head, hash_node)\n\t\t\tcheck_and_free_timer(htab, l);\n\t\tcond_resched_rcu();\n\t}\n\trcu_read_unlock();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_malloced_timers(struct bpf_htab *htab)\n{\n\tint i;\n\n\trcu_read_lock();\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry(l, n, head, hash_node)\n\t\t\tcheck_and_free_timer(htab, l);\n\t\tcond_resched_rcu();\n\t}\n\trcu_read_unlock();\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 1435
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!map_value_has_timer(&htab->map)"
          ],
          "line": 1433
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_value_has_timer",
          "args": [
            "&htab->map"
          ],
          "line": 1433
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1431
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_map_free_timers(struct bpf_map *map)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\n\tif (likely(!map_value_has_timer(&htab->map)))\n\t\treturn;\n\tif (!htab_is_prealloc(htab))\n\t\thtab_free_malloced_timers(htab);\n\telse\n\t\thtab_free_prealloced_timers(htab);\n}"
  },
  {
    "function_name": "htab_free_malloced_timers",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1412-1427",
    "snippet": "static void htab_free_malloced_timers(struct bpf_htab *htab)\n{\n\tint i;\n\n\trcu_read_lock();\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry(l, n, head, hash_node)\n\t\t\tcheck_and_free_timer(htab, l);\n\t\tcond_resched_rcu();\n\t}\n\trcu_read_unlock();\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1426
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cond_resched_rcu",
          "args": [],
          "line": 1424
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_and_free_timer",
          "args": [
            "htab",
            "l"
          ],
          "line": 1423
        },
        "resolved": true,
        "details": {
          "function_name": "check_and_free_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "728-734",
          "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 1422
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "select_bucket",
          "args": [
            "htab",
            "i"
          ],
          "line": 1418
        },
        "resolved": true,
        "details": {
          "function_name": "select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "576-579",
          "snippet": "static inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1416
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_malloced_timers(struct bpf_htab *htab)\n{\n\tint i;\n\n\trcu_read_lock();\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry(l, n, head, hash_node)\n\t\t\tcheck_and_free_timer(htab, l);\n\t\tcond_resched_rcu();\n\t}\n\trcu_read_unlock();\n}"
  },
  {
    "function_name": "delete_all_elements",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1396-1410",
    "snippet": "static void delete_all_elements(struct bpf_htab *htab)\n{\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\t\thtab_elem_free(htab, l);\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_elem_free",
          "args": [
            "htab",
            "l"
          ],
          "line": 1407
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "828-834",
          "snippet": "static void htab_elem_free(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tif (htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH)\n\t\tfree_percpu(htab_elem_get_ptr(l, htab->map.key_size));\n\tcheck_and_free_timer(htab, l);\n\tkfree(l);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_elem_free(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tif (htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH)\n\t\tfree_percpu(htab_elem_get_ptr(l, htab->map.key_size));\n\tcheck_and_free_timer(htab, l);\n\tkfree(l);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 1406
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_safe",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 1405
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "select_bucket",
          "args": [
            "htab",
            "i"
          ],
          "line": 1401
        },
        "resolved": true,
        "details": {
          "function_name": "select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "576-579",
          "snippet": "static inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void delete_all_elements(struct bpf_htab *htab)\n{\n\tint i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tstruct hlist_nulls_head *head = select_bucket(htab, i);\n\t\tstruct hlist_nulls_node *n;\n\t\tstruct htab_elem *l;\n\n\t\thlist_nulls_for_each_entry_safe(l, n, head, hash_node) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\t\thtab_elem_free(htab, l);\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "htab_lru_map_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1360-1394",
    "snippet": "static int htab_lru_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct bucket *b;\n\tstruct htab_elem *l;\n\tunsigned long flags;\n\tu32 hash, key_size;\n\tint ret;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\n\tif (l)\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\telse\n\t\tret = -ENOENT;\n\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l)\n\t\thtab_lru_push_free(htab, l);\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_lru_push_free",
          "args": [
            "htab",
            "l"
          ],
          "line": 1392
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lru_push_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1115-1119",
          "snippet": "static void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "flags"
          ],
          "line": 1390
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 1386
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1383
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&flags"
          ],
          "line": 1379
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1376
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1375
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 1370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 1371
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 1370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 1370
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1362
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_lru_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct bucket *b;\n\tstruct htab_elem *l;\n\tunsigned long flags;\n\tu32 hash, key_size;\n\tint ret;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\n\tif (l)\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\telse\n\t\tret = -ENOENT;\n\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l)\n\t\thtab_lru_push_free(htab, l);\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_map_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1324-1358",
    "snippet": "static int htab_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct bucket *b;\n\tstruct htab_elem *l;\n\tunsigned long flags;\n\tu32 hash, key_size;\n\tint ret;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\n\tif (l) {\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tfree_htab_elem(htab, l);\n\t} else {\n\t\tret = -ENOENT;\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "flags"
          ],
          "line": 1356
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_htab_elem",
          "args": [
            "htab",
            "l"
          ],
          "line": 1351
        },
        "resolved": true,
        "details": {
          "function_name": "free_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "855-867",
          "snippet": "static void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 1350
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1347
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&flags"
          ],
          "line": 1343
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1340
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1339
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 1334
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 1335
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 1334
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 1334
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1326
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct bucket *b;\n\tstruct htab_elem *l;\n\tunsigned long flags;\n\tu32 hash, key_size;\n\tint ret;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl = lookup_elem_raw(head, hash, key, key_size);\n\n\tif (l) {\n\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\tfree_htab_elem(htab, l);\n\t} else {\n\t\tret = -ENOENT;\n\t}\n\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_lru_percpu_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1316-1321",
    "snippet": "static int htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t   void *value, u64 map_flags)\n{\n\treturn __htab_lru_percpu_map_update_elem(map, key, value, map_flags,\n\t\t\t\t\t\t false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_lru_percpu_map_update_elem",
          "args": [
            "map",
            "key",
            "value",
            "map_flags",
            "false"
          ],
          "line": 1319
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_lru_percpu_map_update_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1243-1308",
          "snippet": "static int __htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags,\n\t\t\t\t\t     bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because LRU's elem alloc may need\n\t * to remove older elem from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tif (map_flags != BPF_EXIST) {\n\t\tl_new = prealloc_lru_pop(htab, key, hash);\n\t\tif (!l_new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_old->lru_node);\n\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tpcpu_init_value(htab, htab_elem_get_ptr(l_new, key_size),\n\t\t\t\tvalue, onallcpus);\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t\tl_new = NULL;\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l_new)\n\t\tbpf_lru_push_free(&htab->lru, &l_new->lru_node);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags,\n\t\t\t\t\t     bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because LRU's elem alloc may need\n\t * to remove older elem from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tif (map_flags != BPF_EXIST) {\n\t\tl_new = prealloc_lru_pop(htab, key, hash);\n\t\tif (!l_new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_old->lru_node);\n\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tpcpu_init_value(htab, htab_elem_get_ptr(l_new, key_size),\n\t\t\t\tvalue, onallcpus);\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t\tl_new = NULL;\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l_new)\n\t\tbpf_lru_push_free(&htab->lru, &l_new->lru_node);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t   void *value, u64 map_flags)\n{\n\treturn __htab_lru_percpu_map_update_elem(map, key, value, map_flags,\n\t\t\t\t\t\t false);\n}"
  },
  {
    "function_name": "htab_percpu_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1310-1314",
    "snippet": "static int htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value, u64 map_flags)\n{\n\treturn __htab_percpu_map_update_elem(map, key, value, map_flags, false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_percpu_map_update_elem",
          "args": [
            "map",
            "key",
            "value",
            "map_flags",
            "false"
          ],
          "line": 1313
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_percpu_map_update_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1188-1241",
          "snippet": "static int __htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t void *value, u64 map_flags,\n\t\t\t\t\t bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tl_new = alloc_htab_elem(htab, key, value, key_size,\n\t\t\t\t\thash, true, onallcpus, NULL);\n\t\tif (IS_ERR(l_new)) {\n\t\t\tret = PTR_ERR(l_new);\n\t\t\tgoto err;\n\t\t}\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t void *value, u64 map_flags,\n\t\t\t\t\t bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tl_new = alloc_htab_elem(htab, key, value, key_size,\n\t\t\t\t\thash, true, onallcpus, NULL);\n\t\tif (IS_ERR(l_new)) {\n\t\t\tret = PTR_ERR(l_new);\n\t\t\tgoto err;\n\t\t}\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t       void *value, u64 map_flags)\n{\n\treturn __htab_percpu_map_update_elem(map, key, value, map_flags, false);\n}"
  },
  {
    "function_name": "__htab_lru_percpu_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1243-1308",
    "snippet": "static int __htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags,\n\t\t\t\t\t     bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because LRU's elem alloc may need\n\t * to remove older elem from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tif (map_flags != BPF_EXIST) {\n\t\tl_new = prealloc_lru_pop(htab, key, hash);\n\t\tif (!l_new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_old->lru_node);\n\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tpcpu_init_value(htab, htab_elem_get_ptr(l_new, key_size),\n\t\t\t\tvalue, onallcpus);\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t\tl_new = NULL;\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l_new)\n\t\tbpf_lru_push_free(&htab->lru, &l_new->lru_node);\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_lru_push_free",
          "args": [
            "&htab->lru",
            "&l_new->lru_node"
          ],
          "line": 1306
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_push_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.c",
          "lines": "551-557",
          "snippet": "void bpf_lru_push_free(struct bpf_lru *lru, struct bpf_lru_node *node)\n{\n\tif (lru->percpu)\n\t\tbpf_percpu_lru_push_free(lru, node);\n\telse\n\t\tbpf_common_lru_push_free(lru, node);\n}",
          "includes": [
            "#include \"bpf_lru_list.h\"",
            "#include <linux/percpu.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/cpumask.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_lru_list.h\"\n#include <linux/percpu.h>\n#include <linux/spinlock.h>\n#include <linux/cpumask.h>\n\nvoid bpf_lru_push_free(struct bpf_lru *lru, struct bpf_lru_node *node)\n{\n\tif (lru->percpu)\n\t\tbpf_percpu_lru_push_free(lru, node);\n\telse\n\t\tbpf_common_lru_push_free(lru, node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "flags"
          ],
          "line": 1304
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_add_head_rcu",
          "args": [
            "&l_new->hash_node",
            "head"
          ],
          "line": 1299
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pcpu_init_value",
          "args": [
            "htab",
            "htab_elem_get_ptr(l_new, key_size)",
            "value",
            "onallcpus"
          ],
          "line": 1297
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_init_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "887-911",
          "snippet": "static void pcpu_init_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\t/* When using prealloc and not setting the initial value on all cpus,\n\t * zero-fill element values for other cpus (just as what happens when\n\t * not using prealloc). Otherwise, bpf program has no way to ensure\n\t * known initial values for cpus other than current one\n\t * (onallcpus=false always when coming from bpf prog).\n\t */\n\tif (htab_is_prealloc(htab) && !onallcpus) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint current_cpu = raw_smp_processor_id();\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tif (cpu == current_cpu)\n\t\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu), value,\n\t\t\t\t\t\tsize);\n\t\t\telse\n\t\t\t\tmemset(per_cpu_ptr(pptr, cpu), 0, size);\n\t\t}\n\t} else {\n\t\tpcpu_copy_value(htab, pptr, value, onallcpus);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_init_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\t/* When using prealloc and not setting the initial value on all cpus,\n\t * zero-fill element values for other cpus (just as what happens when\n\t * not using prealloc). Otherwise, bpf program has no way to ensure\n\t * known initial values for cpus other than current one\n\t * (onallcpus=false always when coming from bpf prog).\n\t */\n\tif (htab_is_prealloc(htab) && !onallcpus) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint current_cpu = raw_smp_processor_id();\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tif (cpu == current_cpu)\n\t\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu), value,\n\t\t\t\t\t\tsize);\n\t\t\telse\n\t\t\t\tmemset(per_cpu_ptr(pptr, cpu), 0, size);\n\t\t}\n\t} else {\n\t\tpcpu_copy_value(htab, pptr, value, onallcpus);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l_new",
            "key_size"
          ],
          "line": 1297
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_copy_value",
          "args": [
            "htab",
            "htab_elem_get_ptr(l_old, key_size)",
            "value",
            "onallcpus"
          ],
          "line": 1294
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_copy_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "869-885",
          "snippet": "static void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_lru_node_set_ref",
          "args": [
            "&l_old->lru_node"
          ],
          "line": 1291
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_node_set_ref",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.h",
          "lines": "64-71",
          "snippet": "static inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}",
          "includes": [
            "#include <linux/spinlock_types.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/spinlock_types.h>\n#include <linux/list.h>\n\nstatic inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_flags",
          "args": [
            "htab",
            "l_old",
            "map_flags"
          ],
          "line": 1286
        },
        "resolved": true,
        "details": {
          "function_name": "check_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1004-1016",
          "snippet": "static int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1284
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&flags"
          ],
          "line": 1280
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "prealloc_lru_pop",
          "args": [
            "htab",
            "key",
            "hash"
          ],
          "line": 1275
        },
        "resolved": true,
        "details": {
          "function_name": "prealloc_lru_pop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "287-304",
          "snippet": "static struct htab_elem *prealloc_lru_pop(struct bpf_htab *htab, void *key,\n\t\t\t\t\t  u32 hash)\n{\n\tstruct bpf_lru_node *node = bpf_lru_pop_free(&htab->lru, hash);\n\tstruct htab_elem *l;\n\n\tif (node) {\n\t\tu32 key_size = htab->map.key_size;\n\n\t\tl = container_of(node, struct htab_elem, lru_node);\n\t\tmemcpy(l->key, key, key_size);\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l->key + round_up(key_size, 8));\n\t\treturn l;\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);\n\nstatic struct htab_elem *prealloc_lru_pop(struct bpf_htab *htab, void *key,\n\t\t\t\t\t  u32 hash)\n{\n\tstruct bpf_lru_node *node = bpf_lru_pop_free(&htab->lru, hash);\n\tstruct htab_elem *l;\n\n\tif (node) {\n\t\tu32 key_size = htab->map.key_size;\n\n\t\tl = container_of(node, struct htab_elem, lru_node);\n\t\tmemcpy(l->key, key, key_size);\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l->key + round_up(key_size, 8));\n\t\treturn l;\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1266
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1264
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 1259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 1260
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 1259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 1259
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 1255
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1247
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_lru_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t     void *value, u64 map_flags,\n\t\t\t\t\t     bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because LRU's elem alloc may need\n\t * to remove older elem from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tif (map_flags != BPF_EXIST) {\n\t\tl_new = prealloc_lru_pop(htab, key, hash);\n\t\tif (!l_new)\n\t\t\treturn -ENOMEM;\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_old->lru_node);\n\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tpcpu_init_value(htab, htab_elem_get_ptr(l_new, key_size),\n\t\t\t\tvalue, onallcpus);\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t\tl_new = NULL;\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\tif (l_new)\n\t\tbpf_lru_push_free(&htab->lru, &l_new->lru_node);\n\treturn ret;\n}"
  },
  {
    "function_name": "__htab_percpu_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1188-1241",
    "snippet": "static int __htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t void *value, u64 map_flags,\n\t\t\t\t\t bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tl_new = alloc_htab_elem(htab, key, value, key_size,\n\t\t\t\t\thash, true, onallcpus, NULL);\n\t\tif (IS_ERR(l_new)) {\n\t\t\tret = PTR_ERR(l_new);\n\t\t\tgoto err;\n\t\t}\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "flags"
          ],
          "line": 1239
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_add_head_rcu",
          "args": [
            "&l_new->hash_node",
            "head"
          ],
          "line": 1235
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "l_new"
          ],
          "line": 1232
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "l_new"
          ],
          "line": 1231
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_htab_elem",
          "args": [
            "htab",
            "key",
            "value",
            "key_size",
            "hash",
            "true",
            "onallcpus",
            "NULL"
          ],
          "line": 1229
        },
        "resolved": true,
        "details": {
          "function_name": "alloc_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "919-1002",
          "snippet": "static struct htab_elem *alloc_htab_elem(struct bpf_htab *htab, void *key,\n\t\t\t\t\t void *value, u32 key_size, u32 hash,\n\t\t\t\t\t bool percpu, bool onallcpus,\n\t\t\t\t\t struct htab_elem *old_elem)\n{\n\tu32 size = htab->map.value_size;\n\tbool prealloc = htab_is_prealloc(htab);\n\tstruct htab_elem *l_new, **pl_new;\n\tvoid __percpu *pptr;\n\n\tif (prealloc) {\n\t\tif (old_elem) {\n\t\t\t/* if we're updating the existing element,\n\t\t\t * use per-cpu extra elems to avoid freelist_pop/push\n\t\t\t */\n\t\t\tpl_new = this_cpu_ptr(htab->extra_elems);\n\t\t\tl_new = *pl_new;\n\t\t\thtab_put_fd_value(htab, old_elem);\n\t\t\t*pl_new = old_elem;\n\t\t} else {\n\t\t\tstruct pcpu_freelist_node *l;\n\n\t\t\tl = __pcpu_freelist_pop(&htab->freelist);\n\t\t\tif (!l)\n\t\t\t\treturn ERR_PTR(-E2BIG);\n\t\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t}\n\t} else {\n\t\tif (atomic_inc_return(&htab->count) > htab->map.max_entries)\n\t\t\tif (!old_elem) {\n\t\t\t\t/* when map is full and update() is replacing\n\t\t\t\t * old element, it's ok to allocate, since\n\t\t\t\t * old element will be freed immediately.\n\t\t\t\t * Otherwise return an error\n\t\t\t\t */\n\t\t\t\tl_new = ERR_PTR(-E2BIG);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\tl_new = bpf_map_kmalloc_node(&htab->map, htab->elem_size,\n\t\t\t\t\t     GFP_ATOMIC | __GFP_NOWARN,\n\t\t\t\t\t     htab->map.numa_node);\n\t\tif (!l_new) {\n\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\tgoto dec_count;\n\t\t}\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l_new->key + round_up(key_size, 8));\n\t}\n\n\tmemcpy(l_new->key, key, key_size);\n\tif (percpu) {\n\t\tsize = round_up(size, 8);\n\t\tif (prealloc) {\n\t\t\tpptr = htab_elem_get_ptr(l_new, key_size);\n\t\t} else {\n\t\t\t/* alloc_percpu zero-fills */\n\t\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t\t    GFP_ATOMIC | __GFP_NOWARN);\n\t\t\tif (!pptr) {\n\t\t\t\tkfree(l_new);\n\t\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\t}\n\n\t\tpcpu_init_value(htab, pptr, value, onallcpus);\n\n\t\tif (!prealloc)\n\t\t\thtab_elem_set_ptr(l_new, key_size, pptr);\n\t} else if (fd_htab_map_needs_adjust(htab)) {\n\t\tsize = round_up(size, 8);\n\t\tmemcpy(l_new->key + round_up(key_size, 8), value, size);\n\t} else {\n\t\tcopy_map_value(&htab->map,\n\t\t\t       l_new->key + round_up(key_size, 8),\n\t\t\t       value);\n\t}\n\n\tl_new->hash = hash;\n\treturn l_new;\ndec_count:\n\tatomic_dec(&htab->count);\n\treturn l_new;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *alloc_htab_elem(struct bpf_htab *htab, void *key,\n\t\t\t\t\t void *value, u32 key_size, u32 hash,\n\t\t\t\t\t bool percpu, bool onallcpus,\n\t\t\t\t\t struct htab_elem *old_elem)\n{\n\tu32 size = htab->map.value_size;\n\tbool prealloc = htab_is_prealloc(htab);\n\tstruct htab_elem *l_new, **pl_new;\n\tvoid __percpu *pptr;\n\n\tif (prealloc) {\n\t\tif (old_elem) {\n\t\t\t/* if we're updating the existing element,\n\t\t\t * use per-cpu extra elems to avoid freelist_pop/push\n\t\t\t */\n\t\t\tpl_new = this_cpu_ptr(htab->extra_elems);\n\t\t\tl_new = *pl_new;\n\t\t\thtab_put_fd_value(htab, old_elem);\n\t\t\t*pl_new = old_elem;\n\t\t} else {\n\t\t\tstruct pcpu_freelist_node *l;\n\n\t\t\tl = __pcpu_freelist_pop(&htab->freelist);\n\t\t\tif (!l)\n\t\t\t\treturn ERR_PTR(-E2BIG);\n\t\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t}\n\t} else {\n\t\tif (atomic_inc_return(&htab->count) > htab->map.max_entries)\n\t\t\tif (!old_elem) {\n\t\t\t\t/* when map is full and update() is replacing\n\t\t\t\t * old element, it's ok to allocate, since\n\t\t\t\t * old element will be freed immediately.\n\t\t\t\t * Otherwise return an error\n\t\t\t\t */\n\t\t\t\tl_new = ERR_PTR(-E2BIG);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\tl_new = bpf_map_kmalloc_node(&htab->map, htab->elem_size,\n\t\t\t\t\t     GFP_ATOMIC | __GFP_NOWARN,\n\t\t\t\t\t     htab->map.numa_node);\n\t\tif (!l_new) {\n\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\tgoto dec_count;\n\t\t}\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l_new->key + round_up(key_size, 8));\n\t}\n\n\tmemcpy(l_new->key, key, key_size);\n\tif (percpu) {\n\t\tsize = round_up(size, 8);\n\t\tif (prealloc) {\n\t\t\tpptr = htab_elem_get_ptr(l_new, key_size);\n\t\t} else {\n\t\t\t/* alloc_percpu zero-fills */\n\t\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t\t    GFP_ATOMIC | __GFP_NOWARN);\n\t\t\tif (!pptr) {\n\t\t\t\tkfree(l_new);\n\t\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\t}\n\n\t\tpcpu_init_value(htab, pptr, value, onallcpus);\n\n\t\tif (!prealloc)\n\t\t\thtab_elem_set_ptr(l_new, key_size, pptr);\n\t} else if (fd_htab_map_needs_adjust(htab)) {\n\t\tsize = round_up(size, 8);\n\t\tmemcpy(l_new->key + round_up(key_size, 8), value, size);\n\t} else {\n\t\tcopy_map_value(&htab->map,\n\t\t\t       l_new->key + round_up(key_size, 8),\n\t\t\t       value);\n\t}\n\n\tl_new->hash = hash;\n\treturn l_new;\ndec_count:\n\tatomic_dec(&htab->count);\n\treturn l_new;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_copy_value",
          "args": [
            "htab",
            "htab_elem_get_ptr(l_old, key_size)",
            "value",
            "onallcpus"
          ],
          "line": 1226
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_copy_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "869-885",
          "snippet": "static void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l_old",
            "key_size"
          ],
          "line": 1226
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_flags",
          "args": [
            "htab",
            "l_old",
            "map_flags"
          ],
          "line": 1220
        },
        "resolved": true,
        "details": {
          "function_name": "check_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1004-1016",
          "snippet": "static int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1218
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&flags"
          ],
          "line": 1214
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1211
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1209
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 1204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 1205
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 1204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 1204
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 1200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1192
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int __htab_percpu_map_update_elem(struct bpf_map *map, void *key,\n\t\t\t\t\t void *value, u64 map_flags,\n\t\t\t\t\t bool onallcpus)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (l_old) {\n\t\t/* per-cpu hash map can update value in-place */\n\t\tpcpu_copy_value(htab, htab_elem_get_ptr(l_old, key_size),\n\t\t\t\tvalue, onallcpus);\n\t} else {\n\t\tl_new = alloc_htab_elem(htab, key, value, key_size,\n\t\t\t\t\thash, true, onallcpus, NULL);\n\t\tif (IS_ERR(l_new)) {\n\t\t\tret = PTR_ERR(l_new);\n\t\t\tgoto err;\n\t\t}\n\t\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_lru_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1121-1186",
    "snippet": "static int htab_lru_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\t    u64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new, *l_old = NULL;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because getting free nodes from LRU may need\n\t * to remove older elements from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tl_new = prealloc_lru_pop(htab, key, hash);\n\tif (!l_new)\n\t\treturn -ENOMEM;\n\tcopy_map_value(&htab->map,\n\t\t       l_new->key + round_up(map->key_size, 8), value);\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\t/* add new element to the head of the list, so that\n\t * concurrent search will find it before old elem\n\t */\n\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_new->lru_node);\n\t\thlist_nulls_del_rcu(&l_old->hash_node);\n\t}\n\tret = 0;\n\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\n\tif (ret)\n\t\thtab_lru_push_free(htab, l_new);\n\telse if (l_old)\n\t\thtab_lru_push_free(htab, l_old);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_lru_push_free",
          "args": [
            "htab",
            "l_old"
          ],
          "line": 1183
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lru_push_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1115-1119",
          "snippet": "static void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "flags"
          ],
          "line": 1178
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l_old->hash_node"
          ],
          "line": 1173
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_lru_node_set_ref",
          "args": [
            "&l_new->lru_node"
          ],
          "line": 1172
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_node_set_ref",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.h",
          "lines": "64-71",
          "snippet": "static inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}",
          "includes": [
            "#include <linux/spinlock_types.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/spinlock_types.h>\n#include <linux/list.h>\n\nstatic inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_add_head_rcu",
          "args": [
            "&l_new->hash_node",
            "head"
          ],
          "line": 1170
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_flags",
          "args": [
            "htab",
            "l_old",
            "map_flags"
          ],
          "line": 1163
        },
        "resolved": true,
        "details": {
          "function_name": "check_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1004-1016",
          "snippet": "static int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1161
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&flags"
          ],
          "line": 1157
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_map_value",
          "args": [
            "&htab->map",
            "l_new->key + round_up(map->key_size, 8)",
            "value"
          ],
          "line": 1154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 1155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "prealloc_lru_pop",
          "args": [
            "htab",
            "key",
            "hash"
          ],
          "line": 1151
        },
        "resolved": true,
        "details": {
          "function_name": "prealloc_lru_pop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "287-304",
          "snippet": "static struct htab_elem *prealloc_lru_pop(struct bpf_htab *htab, void *key,\n\t\t\t\t\t  u32 hash)\n{\n\tstruct bpf_lru_node *node = bpf_lru_pop_free(&htab->lru, hash);\n\tstruct htab_elem *l;\n\n\tif (node) {\n\t\tu32 key_size = htab->map.key_size;\n\n\t\tl = container_of(node, struct htab_elem, lru_node);\n\t\tmemcpy(l->key, key, key_size);\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l->key + round_up(key_size, 8));\n\t\treturn l;\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);\n\nstatic struct htab_elem *prealloc_lru_pop(struct bpf_htab *htab, void *key,\n\t\t\t\t\t  u32 hash)\n{\n\tstruct bpf_lru_node *node = bpf_lru_pop_free(&htab->lru, hash);\n\tstruct htab_elem *l;\n\n\tif (node) {\n\t\tu32 key_size = htab->map.key_size;\n\n\t\tl = container_of(node, struct htab_elem, lru_node);\n\t\tmemcpy(l->key, key, key_size);\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l->key + round_up(key_size, 8));\n\t\treturn l;\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1143
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1141
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 1136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 1137
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 1136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 1136
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 1132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1124
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_lru_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\t    u64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new, *l_old = NULL;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\t/* For LRU, we need to alloc before taking bucket's\n\t * spinlock because getting free nodes from LRU may need\n\t * to remove older elements from htab and this removal\n\t * operation will need a bucket lock.\n\t */\n\tl_new = prealloc_lru_pop(htab, key, hash);\n\tif (!l_new)\n\t\treturn -ENOMEM;\n\tcopy_map_value(&htab->map,\n\t\t       l_new->key + round_up(map->key_size, 8), value);\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\t/* add new element to the head of the list, so that\n\t * concurrent search will find it before old elem\n\t */\n\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\tif (l_old) {\n\t\tbpf_lru_node_set_ref(&l_new->lru_node);\n\t\thlist_nulls_del_rcu(&l_old->hash_node);\n\t}\n\tret = 0;\n\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\n\tif (ret)\n\t\thtab_lru_push_free(htab, l_new);\n\telse if (l_old)\n\t\thtab_lru_push_free(htab, l_old);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "htab_lru_push_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1115-1119",
    "snippet": "static void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_lru_push_free",
          "args": [
            "&htab->lru",
            "&elem->lru_node"
          ],
          "line": 1118
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_push_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.c",
          "lines": "551-557",
          "snippet": "void bpf_lru_push_free(struct bpf_lru *lru, struct bpf_lru_node *node)\n{\n\tif (lru->percpu)\n\t\tbpf_percpu_lru_push_free(lru, node);\n\telse\n\t\tbpf_common_lru_push_free(lru, node);\n}",
          "includes": [
            "#include \"bpf_lru_list.h\"",
            "#include <linux/percpu.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/cpumask.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_lru_list.h\"\n#include <linux/percpu.h>\n#include <linux/spinlock.h>\n#include <linux/cpumask.h>\n\nvoid bpf_lru_push_free(struct bpf_lru *lru, struct bpf_lru_node *node)\n{\n\tif (lru->percpu)\n\t\tbpf_percpu_lru_push_free(lru, node);\n\telse\n\t\tbpf_common_lru_push_free(lru, node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_and_free_timer",
          "args": [
            "htab",
            "elem"
          ],
          "line": 1117
        },
        "resolved": true,
        "details": {
          "function_name": "check_and_free_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "728-734",
          "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_lru_push_free(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tcheck_and_free_timer(htab, elem);\n\tbpf_lru_push_free(&htab->lru, &elem->lru_node);\n}"
  },
  {
    "function_name": "htab_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1019-1113",
    "snippet": "static int htab_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\tu64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely((map_flags & ~BPF_F_LOCK) > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tif (unlikely(map_flags & BPF_F_LOCK)) {\n\t\tif (unlikely(!map_value_has_spin_lock(map)))\n\t\t\treturn -EINVAL;\n\t\t/* find an element without taking the bucket lock */\n\t\tl_old = lookup_nulls_elem_raw(head, hash, key, key_size,\n\t\t\t\t\t      htab->n_buckets);\n\t\tret = check_flags(htab, l_old, map_flags);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (l_old) {\n\t\t\t/* grab the element lock and update value in place */\n\t\t\tcopy_map_value_locked(map,\n\t\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t\t      value, false);\n\t\t\treturn 0;\n\t\t}\n\t\t/* fall through, grab the bucket lock and lookup again.\n\t\t * 99.9% chance that the element won't be found,\n\t\t * but second lookup under lock has to be done.\n\t\t */\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (unlikely(l_old && (map_flags & BPF_F_LOCK))) {\n\t\t/* first lookup without the bucket lock didn't find the element,\n\t\t * but second lookup with the bucket lock found it.\n\t\t * This case is highly unlikely, but has to be dealt with:\n\t\t * grab the element lock in addition to the bucket lock\n\t\t * and update element in place\n\t\t */\n\t\tcopy_map_value_locked(map,\n\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t      value, false);\n\t\tret = 0;\n\t\tgoto err;\n\t}\n\n\tl_new = alloc_htab_elem(htab, key, value, key_size, hash, false, false,\n\t\t\t\tl_old);\n\tif (IS_ERR(l_new)) {\n\t\t/* all pre-allocated elements are in use or memory exhausted */\n\t\tret = PTR_ERR(l_new);\n\t\tgoto err;\n\t}\n\n\t/* add new element to the head of the list, so that\n\t * concurrent search will find it before old elem\n\t */\n\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\tif (l_old) {\n\t\thlist_nulls_del_rcu(&l_old->hash_node);\n\t\tif (!htab_is_prealloc(htab))\n\t\t\tfree_htab_elem(htab, l_old);\n\t\telse\n\t\t\tcheck_and_free_timer(htab, l_old);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "flags"
          ],
          "line": 1111
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_and_free_timer",
          "args": [
            "htab",
            "l_old"
          ],
          "line": 1107
        },
        "resolved": true,
        "details": {
          "function_name": "check_and_free_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "728-734",
          "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_htab_elem",
          "args": [
            "htab",
            "l_old"
          ],
          "line": 1105
        },
        "resolved": true,
        "details": {
          "function_name": "free_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "855-867",
          "snippet": "static void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 1104
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l_old->hash_node"
          ],
          "line": 1103
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_add_head_rcu",
          "args": [
            "&l_new->hash_node",
            "head"
          ],
          "line": 1101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "l_new"
          ],
          "line": 1094
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "l_new"
          ],
          "line": 1092
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_htab_elem",
          "args": [
            "htab",
            "key",
            "value",
            "key_size",
            "hash",
            "false",
            "false",
            "l_old"
          ],
          "line": 1090
        },
        "resolved": true,
        "details": {
          "function_name": "alloc_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "919-1002",
          "snippet": "static struct htab_elem *alloc_htab_elem(struct bpf_htab *htab, void *key,\n\t\t\t\t\t void *value, u32 key_size, u32 hash,\n\t\t\t\t\t bool percpu, bool onallcpus,\n\t\t\t\t\t struct htab_elem *old_elem)\n{\n\tu32 size = htab->map.value_size;\n\tbool prealloc = htab_is_prealloc(htab);\n\tstruct htab_elem *l_new, **pl_new;\n\tvoid __percpu *pptr;\n\n\tif (prealloc) {\n\t\tif (old_elem) {\n\t\t\t/* if we're updating the existing element,\n\t\t\t * use per-cpu extra elems to avoid freelist_pop/push\n\t\t\t */\n\t\t\tpl_new = this_cpu_ptr(htab->extra_elems);\n\t\t\tl_new = *pl_new;\n\t\t\thtab_put_fd_value(htab, old_elem);\n\t\t\t*pl_new = old_elem;\n\t\t} else {\n\t\t\tstruct pcpu_freelist_node *l;\n\n\t\t\tl = __pcpu_freelist_pop(&htab->freelist);\n\t\t\tif (!l)\n\t\t\t\treturn ERR_PTR(-E2BIG);\n\t\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t}\n\t} else {\n\t\tif (atomic_inc_return(&htab->count) > htab->map.max_entries)\n\t\t\tif (!old_elem) {\n\t\t\t\t/* when map is full and update() is replacing\n\t\t\t\t * old element, it's ok to allocate, since\n\t\t\t\t * old element will be freed immediately.\n\t\t\t\t * Otherwise return an error\n\t\t\t\t */\n\t\t\t\tl_new = ERR_PTR(-E2BIG);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\tl_new = bpf_map_kmalloc_node(&htab->map, htab->elem_size,\n\t\t\t\t\t     GFP_ATOMIC | __GFP_NOWARN,\n\t\t\t\t\t     htab->map.numa_node);\n\t\tif (!l_new) {\n\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\tgoto dec_count;\n\t\t}\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l_new->key + round_up(key_size, 8));\n\t}\n\n\tmemcpy(l_new->key, key, key_size);\n\tif (percpu) {\n\t\tsize = round_up(size, 8);\n\t\tif (prealloc) {\n\t\t\tpptr = htab_elem_get_ptr(l_new, key_size);\n\t\t} else {\n\t\t\t/* alloc_percpu zero-fills */\n\t\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t\t    GFP_ATOMIC | __GFP_NOWARN);\n\t\t\tif (!pptr) {\n\t\t\t\tkfree(l_new);\n\t\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\t}\n\n\t\tpcpu_init_value(htab, pptr, value, onallcpus);\n\n\t\tif (!prealloc)\n\t\t\thtab_elem_set_ptr(l_new, key_size, pptr);\n\t} else if (fd_htab_map_needs_adjust(htab)) {\n\t\tsize = round_up(size, 8);\n\t\tmemcpy(l_new->key + round_up(key_size, 8), value, size);\n\t} else {\n\t\tcopy_map_value(&htab->map,\n\t\t\t       l_new->key + round_up(key_size, 8),\n\t\t\t       value);\n\t}\n\n\tl_new->hash = hash;\n\treturn l_new;\ndec_count:\n\tatomic_dec(&htab->count);\n\treturn l_new;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *alloc_htab_elem(struct bpf_htab *htab, void *key,\n\t\t\t\t\t void *value, u32 key_size, u32 hash,\n\t\t\t\t\t bool percpu, bool onallcpus,\n\t\t\t\t\t struct htab_elem *old_elem)\n{\n\tu32 size = htab->map.value_size;\n\tbool prealloc = htab_is_prealloc(htab);\n\tstruct htab_elem *l_new, **pl_new;\n\tvoid __percpu *pptr;\n\n\tif (prealloc) {\n\t\tif (old_elem) {\n\t\t\t/* if we're updating the existing element,\n\t\t\t * use per-cpu extra elems to avoid freelist_pop/push\n\t\t\t */\n\t\t\tpl_new = this_cpu_ptr(htab->extra_elems);\n\t\t\tl_new = *pl_new;\n\t\t\thtab_put_fd_value(htab, old_elem);\n\t\t\t*pl_new = old_elem;\n\t\t} else {\n\t\t\tstruct pcpu_freelist_node *l;\n\n\t\t\tl = __pcpu_freelist_pop(&htab->freelist);\n\t\t\tif (!l)\n\t\t\t\treturn ERR_PTR(-E2BIG);\n\t\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t}\n\t} else {\n\t\tif (atomic_inc_return(&htab->count) > htab->map.max_entries)\n\t\t\tif (!old_elem) {\n\t\t\t\t/* when map is full and update() is replacing\n\t\t\t\t * old element, it's ok to allocate, since\n\t\t\t\t * old element will be freed immediately.\n\t\t\t\t * Otherwise return an error\n\t\t\t\t */\n\t\t\t\tl_new = ERR_PTR(-E2BIG);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\tl_new = bpf_map_kmalloc_node(&htab->map, htab->elem_size,\n\t\t\t\t\t     GFP_ATOMIC | __GFP_NOWARN,\n\t\t\t\t\t     htab->map.numa_node);\n\t\tif (!l_new) {\n\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\tgoto dec_count;\n\t\t}\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l_new->key + round_up(key_size, 8));\n\t}\n\n\tmemcpy(l_new->key, key, key_size);\n\tif (percpu) {\n\t\tsize = round_up(size, 8);\n\t\tif (prealloc) {\n\t\t\tpptr = htab_elem_get_ptr(l_new, key_size);\n\t\t} else {\n\t\t\t/* alloc_percpu zero-fills */\n\t\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t\t    GFP_ATOMIC | __GFP_NOWARN);\n\t\t\tif (!pptr) {\n\t\t\t\tkfree(l_new);\n\t\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\t}\n\n\t\tpcpu_init_value(htab, pptr, value, onallcpus);\n\n\t\tif (!prealloc)\n\t\t\thtab_elem_set_ptr(l_new, key_size, pptr);\n\t} else if (fd_htab_map_needs_adjust(htab)) {\n\t\tsize = round_up(size, 8);\n\t\tmemcpy(l_new->key + round_up(key_size, 8), value, size);\n\t} else {\n\t\tcopy_map_value(&htab->map,\n\t\t\t       l_new->key + round_up(key_size, 8),\n\t\t\t       value);\n\t}\n\n\tl_new->hash = hash;\n\treturn l_new;\ndec_count:\n\tatomic_dec(&htab->count);\n\treturn l_new;\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_map_value_locked",
          "args": [
            "map",
            "l_old->key + round_up(key_size, 8)",
            "value",
            "false"
          ],
          "line": 1083
        },
        "resolved": true,
        "details": {
          "function_name": "copy_map_value_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "337-351",
          "snippet": "void copy_map_value_locked(struct bpf_map *map, void *dst, void *src,\n\t\t\t   bool lock_src)\n{\n\tstruct bpf_spin_lock *lock;\n\n\tif (lock_src)\n\t\tlock = src + map->spin_lock_off;\n\telse\n\t\tlock = dst + map->spin_lock_off;\n\tpreempt_disable();\n\t__bpf_spin_lock_irqsave(lock);\n\tcopy_map_value(map, dst, src);\n\t__bpf_spin_unlock_irqrestore(lock);\n\tpreempt_enable();\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid copy_map_value_locked(struct bpf_map *map, void *dst, void *src,\n\t\t\t   bool lock_src)\n{\n\tstruct bpf_spin_lock *lock;\n\n\tif (lock_src)\n\t\tlock = src + map->spin_lock_off;\n\telse\n\t\tlock = dst + map->spin_lock_off;\n\tpreempt_disable();\n\t__bpf_spin_lock_irqsave(lock);\n\tcopy_map_value(map, dst, src);\n\t__bpf_spin_unlock_irqrestore(lock);\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "key_size",
            "8"
          ],
          "line": 1084
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "l_old && (map_flags & BPF_F_LOCK)"
          ],
          "line": 1076
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_flags",
          "args": [
            "htab",
            "l_old",
            "map_flags"
          ],
          "line": 1072
        },
        "resolved": true,
        "details": {
          "function_name": "check_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "1004-1016",
          "snippet": "static int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lookup_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size"
          ],
          "line": 1070
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "582-593",
          "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "hash",
            "&flags"
          ],
          "line": 1066
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "key_size",
            "8"
          ],
          "line": 1056
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lookup_nulls_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size",
            "htab->n_buckets"
          ],
          "line": 1048
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_nulls_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "599-615",
          "snippet": "static struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!map_value_has_spin_lock(map)"
          ],
          "line": 1045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_value_has_spin_lock",
          "args": [
            "map"
          ],
          "line": 1045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags & BPF_F_LOCK"
          ],
          "line": 1044
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 1041
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 1039
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 1034
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 1035
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 1034
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 1034
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "(map_flags & ~BPF_F_LOCK) > BPF_EXIST"
          ],
          "line": 1030
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 1022
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\tu64 map_flags)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct htab_elem *l_new = NULL, *l_old;\n\tstruct hlist_nulls_head *head;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tu32 key_size, hash;\n\tint ret;\n\n\tif (unlikely((map_flags & ~BPF_F_LOCK) > BPF_EXIST))\n\t\t/* unknown flags */\n\t\treturn -EINVAL;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\tb = __select_bucket(htab, hash);\n\thead = &b->head;\n\n\tif (unlikely(map_flags & BPF_F_LOCK)) {\n\t\tif (unlikely(!map_value_has_spin_lock(map)))\n\t\t\treturn -EINVAL;\n\t\t/* find an element without taking the bucket lock */\n\t\tl_old = lookup_nulls_elem_raw(head, hash, key, key_size,\n\t\t\t\t\t      htab->n_buckets);\n\t\tret = check_flags(htab, l_old, map_flags);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\tif (l_old) {\n\t\t\t/* grab the element lock and update value in place */\n\t\t\tcopy_map_value_locked(map,\n\t\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t\t      value, false);\n\t\t\treturn 0;\n\t\t}\n\t\t/* fall through, grab the bucket lock and lookup again.\n\t\t * 99.9% chance that the element won't be found,\n\t\t * but second lookup under lock has to be done.\n\t\t */\n\t}\n\n\tret = htab_lock_bucket(htab, b, hash, &flags);\n\tif (ret)\n\t\treturn ret;\n\n\tl_old = lookup_elem_raw(head, hash, key, key_size);\n\n\tret = check_flags(htab, l_old, map_flags);\n\tif (ret)\n\t\tgoto err;\n\n\tif (unlikely(l_old && (map_flags & BPF_F_LOCK))) {\n\t\t/* first lookup without the bucket lock didn't find the element,\n\t\t * but second lookup with the bucket lock found it.\n\t\t * This case is highly unlikely, but has to be dealt with:\n\t\t * grab the element lock in addition to the bucket lock\n\t\t * and update element in place\n\t\t */\n\t\tcopy_map_value_locked(map,\n\t\t\t\t      l_old->key + round_up(key_size, 8),\n\t\t\t\t      value, false);\n\t\tret = 0;\n\t\tgoto err;\n\t}\n\n\tl_new = alloc_htab_elem(htab, key, value, key_size, hash, false, false,\n\t\t\t\tl_old);\n\tif (IS_ERR(l_new)) {\n\t\t/* all pre-allocated elements are in use or memory exhausted */\n\t\tret = PTR_ERR(l_new);\n\t\tgoto err;\n\t}\n\n\t/* add new element to the head of the list, so that\n\t * concurrent search will find it before old elem\n\t */\n\thlist_nulls_add_head_rcu(&l_new->hash_node, head);\n\tif (l_old) {\n\t\thlist_nulls_del_rcu(&l_old->hash_node);\n\t\tif (!htab_is_prealloc(htab))\n\t\t\tfree_htab_elem(htab, l_old);\n\t\telse\n\t\t\tcheck_and_free_timer(htab, l_old);\n\t}\n\tret = 0;\nerr:\n\thtab_unlock_bucket(htab, b, hash, flags);\n\treturn ret;\n}"
  },
  {
    "function_name": "check_flags",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "1004-1016",
    "snippet": "static int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int check_flags(struct bpf_htab *htab, struct htab_elem *l_old,\n\t\t       u64 map_flags)\n{\n\tif (l_old && (map_flags & ~BPF_F_LOCK) == BPF_NOEXIST)\n\t\t/* elem already exists */\n\t\treturn -EEXIST;\n\n\tif (!l_old && (map_flags & ~BPF_F_LOCK) == BPF_EXIST)\n\t\t/* elem doesn't exist, cannot update it */\n\t\treturn -ENOENT;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "alloc_htab_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "919-1002",
    "snippet": "static struct htab_elem *alloc_htab_elem(struct bpf_htab *htab, void *key,\n\t\t\t\t\t void *value, u32 key_size, u32 hash,\n\t\t\t\t\t bool percpu, bool onallcpus,\n\t\t\t\t\t struct htab_elem *old_elem)\n{\n\tu32 size = htab->map.value_size;\n\tbool prealloc = htab_is_prealloc(htab);\n\tstruct htab_elem *l_new, **pl_new;\n\tvoid __percpu *pptr;\n\n\tif (prealloc) {\n\t\tif (old_elem) {\n\t\t\t/* if we're updating the existing element,\n\t\t\t * use per-cpu extra elems to avoid freelist_pop/push\n\t\t\t */\n\t\t\tpl_new = this_cpu_ptr(htab->extra_elems);\n\t\t\tl_new = *pl_new;\n\t\t\thtab_put_fd_value(htab, old_elem);\n\t\t\t*pl_new = old_elem;\n\t\t} else {\n\t\t\tstruct pcpu_freelist_node *l;\n\n\t\t\tl = __pcpu_freelist_pop(&htab->freelist);\n\t\t\tif (!l)\n\t\t\t\treturn ERR_PTR(-E2BIG);\n\t\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t}\n\t} else {\n\t\tif (atomic_inc_return(&htab->count) > htab->map.max_entries)\n\t\t\tif (!old_elem) {\n\t\t\t\t/* when map is full and update() is replacing\n\t\t\t\t * old element, it's ok to allocate, since\n\t\t\t\t * old element will be freed immediately.\n\t\t\t\t * Otherwise return an error\n\t\t\t\t */\n\t\t\t\tl_new = ERR_PTR(-E2BIG);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\tl_new = bpf_map_kmalloc_node(&htab->map, htab->elem_size,\n\t\t\t\t\t     GFP_ATOMIC | __GFP_NOWARN,\n\t\t\t\t\t     htab->map.numa_node);\n\t\tif (!l_new) {\n\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\tgoto dec_count;\n\t\t}\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l_new->key + round_up(key_size, 8));\n\t}\n\n\tmemcpy(l_new->key, key, key_size);\n\tif (percpu) {\n\t\tsize = round_up(size, 8);\n\t\tif (prealloc) {\n\t\t\tpptr = htab_elem_get_ptr(l_new, key_size);\n\t\t} else {\n\t\t\t/* alloc_percpu zero-fills */\n\t\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t\t    GFP_ATOMIC | __GFP_NOWARN);\n\t\t\tif (!pptr) {\n\t\t\t\tkfree(l_new);\n\t\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\t}\n\n\t\tpcpu_init_value(htab, pptr, value, onallcpus);\n\n\t\tif (!prealloc)\n\t\t\thtab_elem_set_ptr(l_new, key_size, pptr);\n\t} else if (fd_htab_map_needs_adjust(htab)) {\n\t\tsize = round_up(size, 8);\n\t\tmemcpy(l_new->key + round_up(key_size, 8), value, size);\n\t} else {\n\t\tcopy_map_value(&htab->map,\n\t\t\t       l_new->key + round_up(key_size, 8),\n\t\t\t       value);\n\t}\n\n\tl_new->hash = hash;\n\treturn l_new;\ndec_count:\n\tatomic_dec(&htab->count);\n\treturn l_new;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&htab->count"
          ],
          "line": 1000
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_map_value",
          "args": [
            "&htab->map",
            "l_new->key + round_up(key_size, 8)",
            "value"
          ],
          "line": 992
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "key_size",
            "8"
          ],
          "line": 993
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "l_new->key + round_up(key_size, 8)",
            "value",
            "size"
          ],
          "line": 990
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "key_size",
            "8"
          ],
          "line": 990
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "size",
            "8"
          ],
          "line": 989
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fd_htab_map_needs_adjust",
          "args": [
            "htab"
          ],
          "line": 988
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_needs_adjust",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "913-917",
          "snippet": "static bool fd_htab_map_needs_adjust(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_HASH_OF_MAPS &&\n\t       BITS_PER_LONG == 64;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool fd_htab_map_needs_adjust(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_HASH_OF_MAPS &&\n\t       BITS_PER_LONG == 64;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_set_ptr",
          "args": [
            "l_new",
            "key_size",
            "pptr"
          ],
          "line": 987
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_set_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "210-214",
          "snippet": "static inline void htab_elem_set_ptr(struct htab_elem *l, u32 key_size,\n\t\t\t\t     void __percpu *pptr)\n{\n\t*(void __percpu **)(l->key + key_size) = pptr;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void htab_elem_set_ptr(struct htab_elem *l, u32 key_size,\n\t\t\t\t     void __percpu *pptr)\n{\n\t*(void __percpu **)(l->key + key_size) = pptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_init_value",
          "args": [
            "htab",
            "pptr",
            "value",
            "onallcpus"
          ],
          "line": 984
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_init_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "887-911",
          "snippet": "static void pcpu_init_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\t/* When using prealloc and not setting the initial value on all cpus,\n\t * zero-fill element values for other cpus (just as what happens when\n\t * not using prealloc). Otherwise, bpf program has no way to ensure\n\t * known initial values for cpus other than current one\n\t * (onallcpus=false always when coming from bpf prog).\n\t */\n\tif (htab_is_prealloc(htab) && !onallcpus) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint current_cpu = raw_smp_processor_id();\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tif (cpu == current_cpu)\n\t\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu), value,\n\t\t\t\t\t\tsize);\n\t\t\telse\n\t\t\t\tmemset(per_cpu_ptr(pptr, cpu), 0, size);\n\t\t}\n\t} else {\n\t\tpcpu_copy_value(htab, pptr, value, onallcpus);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_init_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\t/* When using prealloc and not setting the initial value on all cpus,\n\t * zero-fill element values for other cpus (just as what happens when\n\t * not using prealloc). Otherwise, bpf program has no way to ensure\n\t * known initial values for cpus other than current one\n\t * (onallcpus=false always when coming from bpf prog).\n\t */\n\tif (htab_is_prealloc(htab) && !onallcpus) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint current_cpu = raw_smp_processor_id();\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tif (cpu == current_cpu)\n\t\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu), value,\n\t\t\t\t\t\tsize);\n\t\t\telse\n\t\t\t\tmemset(per_cpu_ptr(pptr, cpu), 0, size);\n\t\t}\n\t} else {\n\t\tpcpu_copy_value(htab, pptr, value, onallcpus);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 979
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "l_new"
          ],
          "line": 978
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_alloc_percpu",
          "args": [
            "&htab->map",
            "size",
            "8",
            "GFP_ATOMIC | __GFP_NOWARN"
          ],
          "line": 975
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_alloc_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "452-463",
          "snippet": "void __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l_new",
            "key_size"
          ],
          "line": 972
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "size",
            "8"
          ],
          "line": 970
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_and_init_map_value",
          "args": [
            "&htab->map",
            "l_new->key + round_up(key_size, 8)"
          ],
          "line": 964
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "key_size",
            "8"
          ],
          "line": 965
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 961
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_kmalloc_node",
          "args": [
            "&htab->map",
            "htab->elem_size",
            "GFP_ATOMIC | __GFP_NOWARN",
            "htab->map.numa_node"
          ],
          "line": 957
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_kmalloc_node",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "427-438",
          "snippet": "void *bpf_map_kmalloc_node(const struct bpf_map *map, size_t size, gfp_t flags,\n\t\t\t   int node)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = kmalloc_node(size, flags | __GFP_ACCOUNT, node);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_kmalloc_node(const struct bpf_map *map, size_t size, gfp_t flags,\n\t\t\t   int node)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = kmalloc_node(size, flags | __GFP_ACCOUNT, node);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-E2BIG"
          ],
          "line": 954
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc_return",
          "args": [
            "&htab->count"
          ],
          "line": 947
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "l",
            "structhtab_elem",
            "fnode"
          ],
          "line": 944
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-E2BIG"
          ],
          "line": 943
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pcpu_freelist_pop",
          "args": [
            "&htab->freelist"
          ],
          "line": 941
        },
        "resolved": true,
        "details": {
          "function_name": "__pcpu_freelist_pop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "193-198",
          "snippet": "struct pcpu_freelist_node *__pcpu_freelist_pop(struct pcpu_freelist *s)\n{\n\tif (in_nmi())\n\t\treturn ___pcpu_freelist_pop_nmi(s);\n\treturn ___pcpu_freelist_pop(s);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nstruct pcpu_freelist_node *__pcpu_freelist_pop(struct pcpu_freelist *s)\n{\n\tif (in_nmi())\n\t\treturn ___pcpu_freelist_pop_nmi(s);\n\treturn ___pcpu_freelist_pop(s);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_put_fd_value",
          "args": [
            "htab",
            "old_elem"
          ],
          "line": 936
        },
        "resolved": true,
        "details": {
          "function_name": "htab_put_fd_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "844-853",
          "snippet": "static void htab_put_fd_value(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tstruct bpf_map *map = &htab->map;\n\tvoid *ptr;\n\n\tif (map->ops->map_fd_put_ptr) {\n\t\tptr = fd_htab_map_get_ptr(map, l);\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_put_fd_value(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tstruct bpf_map *map = &htab->map;\n\tvoid *ptr;\n\n\tif (map->ops->map_fd_put_ptr) {\n\t\tptr = fd_htab_map_get_ptr(map, l);\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "htab->extra_elems"
          ],
          "line": 934
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 925
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *alloc_htab_elem(struct bpf_htab *htab, void *key,\n\t\t\t\t\t void *value, u32 key_size, u32 hash,\n\t\t\t\t\t bool percpu, bool onallcpus,\n\t\t\t\t\t struct htab_elem *old_elem)\n{\n\tu32 size = htab->map.value_size;\n\tbool prealloc = htab_is_prealloc(htab);\n\tstruct htab_elem *l_new, **pl_new;\n\tvoid __percpu *pptr;\n\n\tif (prealloc) {\n\t\tif (old_elem) {\n\t\t\t/* if we're updating the existing element,\n\t\t\t * use per-cpu extra elems to avoid freelist_pop/push\n\t\t\t */\n\t\t\tpl_new = this_cpu_ptr(htab->extra_elems);\n\t\t\tl_new = *pl_new;\n\t\t\thtab_put_fd_value(htab, old_elem);\n\t\t\t*pl_new = old_elem;\n\t\t} else {\n\t\t\tstruct pcpu_freelist_node *l;\n\n\t\t\tl = __pcpu_freelist_pop(&htab->freelist);\n\t\t\tif (!l)\n\t\t\t\treturn ERR_PTR(-E2BIG);\n\t\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t}\n\t} else {\n\t\tif (atomic_inc_return(&htab->count) > htab->map.max_entries)\n\t\t\tif (!old_elem) {\n\t\t\t\t/* when map is full and update() is replacing\n\t\t\t\t * old element, it's ok to allocate, since\n\t\t\t\t * old element will be freed immediately.\n\t\t\t\t * Otherwise return an error\n\t\t\t\t */\n\t\t\t\tl_new = ERR_PTR(-E2BIG);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\tl_new = bpf_map_kmalloc_node(&htab->map, htab->elem_size,\n\t\t\t\t\t     GFP_ATOMIC | __GFP_NOWARN,\n\t\t\t\t\t     htab->map.numa_node);\n\t\tif (!l_new) {\n\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\tgoto dec_count;\n\t\t}\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l_new->key + round_up(key_size, 8));\n\t}\n\n\tmemcpy(l_new->key, key, key_size);\n\tif (percpu) {\n\t\tsize = round_up(size, 8);\n\t\tif (prealloc) {\n\t\t\tpptr = htab_elem_get_ptr(l_new, key_size);\n\t\t} else {\n\t\t\t/* alloc_percpu zero-fills */\n\t\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t\t    GFP_ATOMIC | __GFP_NOWARN);\n\t\t\tif (!pptr) {\n\t\t\t\tkfree(l_new);\n\t\t\t\tl_new = ERR_PTR(-ENOMEM);\n\t\t\t\tgoto dec_count;\n\t\t\t}\n\t\t}\n\n\t\tpcpu_init_value(htab, pptr, value, onallcpus);\n\n\t\tif (!prealloc)\n\t\t\thtab_elem_set_ptr(l_new, key_size, pptr);\n\t} else if (fd_htab_map_needs_adjust(htab)) {\n\t\tsize = round_up(size, 8);\n\t\tmemcpy(l_new->key + round_up(key_size, 8), value, size);\n\t} else {\n\t\tcopy_map_value(&htab->map,\n\t\t\t       l_new->key + round_up(key_size, 8),\n\t\t\t       value);\n\t}\n\n\tl_new->hash = hash;\n\treturn l_new;\ndec_count:\n\tatomic_dec(&htab->count);\n\treturn l_new;\n}"
  },
  {
    "function_name": "fd_htab_map_needs_adjust",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "913-917",
    "snippet": "static bool fd_htab_map_needs_adjust(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_HASH_OF_MAPS &&\n\t       BITS_PER_LONG == 64;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool fd_htab_map_needs_adjust(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_HASH_OF_MAPS &&\n\t       BITS_PER_LONG == 64;\n}"
  },
  {
    "function_name": "pcpu_init_value",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "887-911",
    "snippet": "static void pcpu_init_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\t/* When using prealloc and not setting the initial value on all cpus,\n\t * zero-fill element values for other cpus (just as what happens when\n\t * not using prealloc). Otherwise, bpf program has no way to ensure\n\t * known initial values for cpus other than current one\n\t * (onallcpus=false always when coming from bpf prog).\n\t */\n\tif (htab_is_prealloc(htab) && !onallcpus) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint current_cpu = raw_smp_processor_id();\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tif (cpu == current_cpu)\n\t\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu), value,\n\t\t\t\t\t\tsize);\n\t\t\telse\n\t\t\t\tmemset(per_cpu_ptr(pptr, cpu), 0, size);\n\t\t}\n\t} else {\n\t\tpcpu_copy_value(htab, pptr, value, onallcpus);\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pcpu_copy_value",
          "args": [
            "htab",
            "pptr",
            "value",
            "onallcpus"
          ],
          "line": 909
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_copy_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "869-885",
          "snippet": "static void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "per_cpu_ptr(pptr, cpu)",
            "0",
            "size"
          ],
          "line": 906
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 906
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_long_memcpy",
          "args": [
            "per_cpu_ptr(pptr, cpu)",
            "value",
            "size"
          ],
          "line": 903
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 903
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 898
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.value_size",
            "8"
          ],
          "line": 897
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 896
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_init_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\t/* When using prealloc and not setting the initial value on all cpus,\n\t * zero-fill element values for other cpus (just as what happens when\n\t * not using prealloc). Otherwise, bpf program has no way to ensure\n\t * known initial values for cpus other than current one\n\t * (onallcpus=false always when coming from bpf prog).\n\t */\n\tif (htab_is_prealloc(htab) && !onallcpus) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint current_cpu = raw_smp_processor_id();\n\t\tint cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tif (cpu == current_cpu)\n\t\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu), value,\n\t\t\t\t\t\tsize);\n\t\t\telse\n\t\t\t\tmemset(per_cpu_ptr(pptr, cpu), 0, size);\n\t\t}\n\t} else {\n\t\tpcpu_copy_value(htab, pptr, value, onallcpus);\n\t}\n}"
  },
  {
    "function_name": "pcpu_copy_value",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "869-885",
    "snippet": "static void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_long_memcpy",
          "args": [
            "per_cpu_ptr(pptr, cpu)",
            "value + off",
            "size"
          ],
          "line": 880
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 880
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.value_size",
            "8"
          ],
          "line": 876
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "this_cpu_ptr(pptr)",
            "value",
            "htab->map.value_size"
          ],
          "line": 874
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "pptr"
          ],
          "line": 874
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void pcpu_copy_value(struct bpf_htab *htab, void __percpu *pptr,\n\t\t\t    void *value, bool onallcpus)\n{\n\tif (!onallcpus) {\n\t\t/* copy true value_size bytes */\n\t\tmemcpy(this_cpu_ptr(pptr), value, htab->map.value_size);\n\t} else {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tint off = 0, cpu;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tbpf_long_memcpy(per_cpu_ptr(pptr, cpu),\n\t\t\t\t\tvalue + off, size);\n\t\t\toff += size;\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "free_htab_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "855-867",
    "snippet": "static void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu",
          "args": [
            "&l->rcu",
            "htab_elem_free_rcu"
          ],
          "line": 865
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1533-1536",
          "snippet": "void call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&htab->count"
          ],
          "line": 863
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pcpu_freelist_push",
          "args": [
            "&htab->freelist",
            "&l->fnode"
          ],
          "line": 861
        },
        "resolved": true,
        "details": {
          "function_name": "__pcpu_freelist_push",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "82-89",
          "snippet": "void __pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tif (in_nmi())\n\t\t___pcpu_freelist_push_nmi(s, node);\n\telse\n\t\t___pcpu_freelist_push(this_cpu_ptr(s->freelist), node);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid __pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tif (in_nmi())\n\t\t___pcpu_freelist_push_nmi(s, node);\n\telse\n\t\t___pcpu_freelist_push(this_cpu_ptr(s->freelist), node);\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_and_free_timer",
          "args": [
            "htab",
            "l"
          ],
          "line": 860
        },
        "resolved": true,
        "details": {
          "function_name": "check_and_free_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "728-734",
          "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 859
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_put_fd_value",
          "args": [
            "htab",
            "l"
          ],
          "line": 857
        },
        "resolved": true,
        "details": {
          "function_name": "htab_put_fd_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "844-853",
          "snippet": "static void htab_put_fd_value(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tstruct bpf_map *map = &htab->map;\n\tvoid *ptr;\n\n\tif (map->ops->map_fd_put_ptr) {\n\t\tptr = fd_htab_map_get_ptr(map, l);\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_put_fd_value(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tstruct bpf_map *map = &htab->map;\n\tvoid *ptr;\n\n\tif (map->ops->map_fd_put_ptr) {\n\t\tptr = fd_htab_map_get_ptr(map, l);\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void free_htab_elem(struct bpf_htab *htab, struct htab_elem *l)\n{\n\thtab_put_fd_value(htab, l);\n\n\tif (htab_is_prealloc(htab)) {\n\t\tcheck_and_free_timer(htab, l);\n\t\t__pcpu_freelist_push(&htab->freelist, &l->fnode);\n\t} else {\n\t\tatomic_dec(&htab->count);\n\t\tl->htab = htab;\n\t\tcall_rcu(&l->rcu, htab_elem_free_rcu);\n\t}\n}"
  },
  {
    "function_name": "htab_put_fd_value",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "844-853",
    "snippet": "static void htab_put_fd_value(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tstruct bpf_map *map = &htab->map;\n\tvoid *ptr;\n\n\tif (map->ops->map_fd_put_ptr) {\n\t\tptr = fd_htab_map_get_ptr(map, l);\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "map->ops->map_fd_put_ptr",
          "args": [
            "ptr"
          ],
          "line": 851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fd_htab_map_get_ptr",
          "args": [
            "map",
            "l"
          ],
          "line": 850
        },
        "resolved": true,
        "details": {
          "function_name": "fd_htab_map_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "221-224",
          "snippet": "static void *fd_htab_map_get_ptr(const struct bpf_map *map, struct htab_elem *l)\n{\n\treturn *(void **)(l->key + roundup(map->key_size, 8));\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *fd_htab_map_get_ptr(const struct bpf_map *map, struct htab_elem *l)\n{\n\treturn *(void **)(l->key + roundup(map->key_size, 8));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_put_fd_value(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tstruct bpf_map *map = &htab->map;\n\tvoid *ptr;\n\n\tif (map->ops->map_fd_put_ptr) {\n\t\tptr = fd_htab_map_get_ptr(map, l);\n\t\tmap->ops->map_fd_put_ptr(ptr);\n\t}\n}"
  },
  {
    "function_name": "htab_elem_free_rcu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "836-842",
    "snippet": "static void htab_elem_free_rcu(struct rcu_head *head)\n{\n\tstruct htab_elem *l = container_of(head, struct htab_elem, rcu);\n\tstruct bpf_htab *htab = l->htab;\n\n\thtab_elem_free(htab, l);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_elem_free",
          "args": [
            "htab",
            "l"
          ],
          "line": 841
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "828-834",
          "snippet": "static void htab_elem_free(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tif (htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH)\n\t\tfree_percpu(htab_elem_get_ptr(l, htab->map.key_size));\n\tcheck_and_free_timer(htab, l);\n\tkfree(l);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_elem_free(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tif (htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH)\n\t\tfree_percpu(htab_elem_get_ptr(l, htab->map.key_size));\n\tcheck_and_free_timer(htab, l);\n\tkfree(l);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "head",
            "structhtab_elem",
            "rcu"
          ],
          "line": 838
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_elem_free_rcu(struct rcu_head *head)\n{\n\tstruct htab_elem *l = container_of(head, struct htab_elem, rcu);\n\tstruct bpf_htab *htab = l->htab;\n\n\thtab_elem_free(htab, l);\n}"
  },
  {
    "function_name": "htab_elem_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "828-834",
    "snippet": "static void htab_elem_free(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tif (htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH)\n\t\tfree_percpu(htab_elem_get_ptr(l, htab->map.key_size));\n\tcheck_and_free_timer(htab, l);\n\tkfree(l);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "l"
          ],
          "line": 833
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_and_free_timer",
          "args": [
            "htab",
            "l"
          ],
          "line": 832
        },
        "resolved": true,
        "details": {
          "function_name": "check_and_free_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "728-734",
          "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "htab_elem_get_ptr(l, htab->map.key_size)"
          ],
          "line": 831
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/arraymap.c",
          "lines": "21-29",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "l",
            "htab->map.key_size"
          ],
          "line": 831
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_elem_free(struct bpf_htab *htab, struct htab_elem *l)\n{\n\tif (htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH)\n\t\tfree_percpu(htab_elem_get_ptr(l, htab->map.key_size));\n\tcheck_and_free_timer(htab, l);\n\tkfree(l);\n}"
  },
  {
    "function_name": "htab_map_get_next_key",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "770-826",
    "snippet": "static int htab_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l, *next_l;\n\tu32 hash, key_size;\n\tint i = 0;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\n\tkey_size = map->key_size;\n\n\tif (!key)\n\t\tgoto find_first_elem;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\t/* lookup the key */\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\tif (!l)\n\t\tgoto find_first_elem;\n\n\t/* key was found, get next key in the same bucket */\n\tnext_l = hlist_nulls_entry_safe(rcu_dereference_raw(hlist_nulls_next_rcu(&l->hash_node)),\n\t\t\t\t  struct htab_elem, hash_node);\n\n\tif (next_l) {\n\t\t/* if next elem in this hash list is non-zero, just return it */\n\t\tmemcpy(next_key, next_l->key, key_size);\n\t\treturn 0;\n\t}\n\n\t/* no more elements in this hash list, go to the next bucket */\n\ti = hash & (htab->n_buckets - 1);\n\ti++;\n\nfind_first_elem:\n\t/* iterate over buckets */\n\tfor (; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\t/* pick first element in the bucket */\n\t\tnext_l = hlist_nulls_entry_safe(rcu_dereference_raw(hlist_nulls_first_rcu(head)),\n\t\t\t\t\t  struct htab_elem, hash_node);\n\t\tif (next_l) {\n\t\t\t/* if it's not empty, just return it */\n\t\t\tmemcpy(next_key, next_l->key, key_size);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* iterated over all buckets and all elements */\n\treturn -ENOENT;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "next_key",
            "next_l->key",
            "key_size"
          ],
          "line": 819
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_entry_safe",
          "args": [
            "rcu_dereference_raw(hlist_nulls_first_rcu(head))",
            "structhtab_elem",
            "hash_node"
          ],
          "line": 815
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference_raw",
          "args": [
            "hlist_nulls_first_rcu(head)"
          ],
          "line": 815
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_first_rcu",
          "args": [
            "head"
          ],
          "line": 815
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "select_bucket",
          "args": [
            "htab",
            "i"
          ],
          "line": 812
        },
        "resolved": true,
        "details": {
          "function_name": "select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "576-579",
          "snippet": "static inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_entry_safe",
          "args": [
            "rcu_dereference_raw(hlist_nulls_next_rcu(&l->hash_node))",
            "structhtab_elem",
            "hash_node"
          ],
          "line": 796
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference_raw",
          "args": [
            "hlist_nulls_next_rcu(&l->hash_node)"
          ],
          "line": 796
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_next_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 796
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lookup_nulls_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size",
            "htab->n_buckets"
          ],
          "line": 790
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_nulls_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "599-615",
          "snippet": "static struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 785
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held()"
          ],
          "line": 778
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 778
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 772
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l, *next_l;\n\tu32 hash, key_size;\n\tint i = 0;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\n\tkey_size = map->key_size;\n\n\tif (!key)\n\t\tgoto find_first_elem;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\t/* lookup the key */\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\tif (!l)\n\t\tgoto find_first_elem;\n\n\t/* key was found, get next key in the same bucket */\n\tnext_l = hlist_nulls_entry_safe(rcu_dereference_raw(hlist_nulls_next_rcu(&l->hash_node)),\n\t\t\t\t  struct htab_elem, hash_node);\n\n\tif (next_l) {\n\t\t/* if next elem in this hash list is non-zero, just return it */\n\t\tmemcpy(next_key, next_l->key, key_size);\n\t\treturn 0;\n\t}\n\n\t/* no more elements in this hash list, go to the next bucket */\n\ti = hash & (htab->n_buckets - 1);\n\ti++;\n\nfind_first_elem:\n\t/* iterate over buckets */\n\tfor (; i < htab->n_buckets; i++) {\n\t\thead = select_bucket(htab, i);\n\n\t\t/* pick first element in the bucket */\n\t\tnext_l = hlist_nulls_entry_safe(rcu_dereference_raw(hlist_nulls_first_rcu(head)),\n\t\t\t\t\t  struct htab_elem, hash_node);\n\t\tif (next_l) {\n\t\t\t/* if it's not empty, just return it */\n\t\t\tmemcpy(next_key, next_l->key, key_size);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* iterated over all buckets and all elements */\n\treturn -ENOENT;\n}"
  },
  {
    "function_name": "htab_lru_map_delete_node",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "739-767",
    "snippet": "static bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node)\n{\n\tstruct bpf_htab *htab = (struct bpf_htab *)arg;\n\tstruct htab_elem *l = NULL, *tgt_l;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tint ret;\n\n\ttgt_l = container_of(node, struct htab_elem, lru_node);\n\tb = __select_bucket(htab, tgt_l->hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, tgt_l->hash, &flags);\n\tif (ret)\n\t\treturn false;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l == tgt_l) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\t\tcheck_and_free_timer(htab, l);\n\t\t\tbreak;\n\t\t}\n\n\thtab_unlock_bucket(htab, b, tgt_l->hash, flags);\n\n\treturn l == tgt_l;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_unlock_bucket",
          "args": [
            "htab",
            "b",
            "tgt_l->hash",
            "flags"
          ],
          "line": 764
        },
        "resolved": true,
        "details": {
          "function_name": "htab_unlock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "183-194",
          "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_and_free_timer",
          "args": [
            "htab",
            "l"
          ],
          "line": 760
        },
        "resolved": true,
        "details": {
          "function_name": "check_and_free_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "728-734",
          "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hlist_nulls_del_rcu",
          "args": [
            "&l->hash_node"
          ],
          "line": 759
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_rcu",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_lock_bucket",
          "args": [
            "htab",
            "b",
            "tgt_l->hash",
            "&flags"
          ],
          "line": 753
        },
        "resolved": true,
        "details": {
          "function_name": "htab_lock_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "159-181",
          "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [
            "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "tgt_l->hash"
          ],
          "line": 750
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "node",
            "structhtab_elem",
            "lru_node"
          ],
          "line": 749
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);\n\nstatic bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node)\n{\n\tstruct bpf_htab *htab = (struct bpf_htab *)arg;\n\tstruct htab_elem *l = NULL, *tgt_l;\n\tstruct hlist_nulls_head *head;\n\tstruct hlist_nulls_node *n;\n\tunsigned long flags;\n\tstruct bucket *b;\n\tint ret;\n\n\ttgt_l = container_of(node, struct htab_elem, lru_node);\n\tb = __select_bucket(htab, tgt_l->hash);\n\thead = &b->head;\n\n\tret = htab_lock_bucket(htab, b, tgt_l->hash, &flags);\n\tif (ret)\n\t\treturn false;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l == tgt_l) {\n\t\t\thlist_nulls_del_rcu(&l->hash_node);\n\t\t\tcheck_and_free_timer(htab, l);\n\t\t\tbreak;\n\t\t}\n\n\thtab_unlock_bucket(htab, b, tgt_l->hash, flags);\n\n\treturn l == tgt_l;\n}"
  },
  {
    "function_name": "check_and_free_timer",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "728-734",
    "snippet": "static void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_timer_cancel_and_free",
          "args": [
            "elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off"
          ],
          "line": 731
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_timer_cancel_and_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "1302-1344",
          "snippet": "void bpf_timer_cancel_and_free(void *val)\n{\n\tstruct bpf_timer_kern *timer = val;\n\tstruct bpf_hrtimer *t;\n\n\t/* Performance optimization: read timer->timer without lock first. */\n\tif (!READ_ONCE(timer->timer))\n\t\treturn;\n\n\t__bpf_spin_lock_irqsave(&timer->lock);\n\t/* re-read it under lock */\n\tt = timer->timer;\n\tif (!t)\n\t\tgoto out;\n\tdrop_prog_refcnt(t);\n\t/* The subsequent bpf_timer_start/cancel() helpers won't be able to use\n\t * this timer, since it won't be initialized.\n\t */\n\ttimer->timer = NULL;\nout:\n\t__bpf_spin_unlock_irqrestore(&timer->lock);\n\tif (!t)\n\t\treturn;\n\t/* Cancel the timer and wait for callback to complete if it was running.\n\t * If hrtimer_cancel() can be safely called it's safe to call kfree(t)\n\t * right after for both preallocated and non-preallocated maps.\n\t * The timer->timer = NULL was already done and no code path can\n\t * see address 't' anymore.\n\t *\n\t * Check that bpf_map_delete/update_elem() wasn't called from timer\n\t * callback_fn. In such case don't call hrtimer_cancel() (since it will\n\t * deadlock) and don't call hrtimer_try_to_cancel() (since it will just\n\t * return -1). Though callback_fn is still running on this cpu it's\n\t * safe to do kfree(t) because bpf_timer_cb() read everything it needed\n\t * from 't'. The bpf subprog callback_fn won't be able to access 't',\n\t * since timer->timer = NULL was already done. The timer will be\n\t * effectively cancelled because bpf_timer_cb() will return\n\t * HRTIMER_NORESTART.\n\t */\n\tif (this_cpu_read(hrtimer_running) != t)\n\t\thrtimer_cancel(&t->timer);\n\tkfree(t);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct bpf_hrtimer *, hrtimer_running);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(struct bpf_hrtimer *, hrtimer_running);\n\nvoid bpf_timer_cancel_and_free(void *val)\n{\n\tstruct bpf_timer_kern *timer = val;\n\tstruct bpf_hrtimer *t;\n\n\t/* Performance optimization: read timer->timer without lock first. */\n\tif (!READ_ONCE(timer->timer))\n\t\treturn;\n\n\t__bpf_spin_lock_irqsave(&timer->lock);\n\t/* re-read it under lock */\n\tt = timer->timer;\n\tif (!t)\n\t\tgoto out;\n\tdrop_prog_refcnt(t);\n\t/* The subsequent bpf_timer_start/cancel() helpers won't be able to use\n\t * this timer, since it won't be initialized.\n\t */\n\ttimer->timer = NULL;\nout:\n\t__bpf_spin_unlock_irqrestore(&timer->lock);\n\tif (!t)\n\t\treturn;\n\t/* Cancel the timer and wait for callback to complete if it was running.\n\t * If hrtimer_cancel() can be safely called it's safe to call kfree(t)\n\t * right after for both preallocated and non-preallocated maps.\n\t * The timer->timer = NULL was already done and no code path can\n\t * see address 't' anymore.\n\t *\n\t * Check that bpf_map_delete/update_elem() wasn't called from timer\n\t * callback_fn. In such case don't call hrtimer_cancel() (since it will\n\t * deadlock) and don't call hrtimer_try_to_cancel() (since it will just\n\t * return -1). Though callback_fn is still running on this cpu it's\n\t * safe to do kfree(t) because bpf_timer_cb() read everything it needed\n\t * from 't'. The bpf subprog callback_fn won't be able to access 't',\n\t * since timer->timer = NULL was already done. The timer will be\n\t * effectively cancelled because bpf_timer_cb() will return\n\t * HRTIMER_NORESTART.\n\t */\n\tif (this_cpu_read(hrtimer_running) != t)\n\t\thrtimer_cancel(&t->timer);\n\tkfree(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.key_size",
            "8"
          ],
          "line": 732
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_value_has_timer(&htab->map)"
          ],
          "line": 730
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_value_has_timer",
          "args": [
            "&htab->map"
          ],
          "line": 730
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void check_and_free_timer(struct bpf_htab *htab, struct htab_elem *elem)\n{\n\tif (unlikely(map_value_has_timer(&htab->map)))\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n}"
  },
  {
    "function_name": "htab_lru_map_gen_lookup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "703-726",
    "snippet": "static int htab_lru_map_gen_lookup(struct bpf_map *map,\n\t\t\t\t   struct bpf_insn *insn_buf)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\tconst int ret = BPF_REG_0;\n\tconst int ref_reg = BPF_REG_1;\n\n\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);\n\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 4);\n\t*insn++ = BPF_LDX_MEM(BPF_B, ref_reg, ret,\n\t\t\t      offsetof(struct htab_elem, lru_node) +\n\t\t\t      offsetof(struct bpf_lru_node, ref));\n\t*insn++ = BPF_JMP_IMM(BPF_JNE, ref_reg, 0, 1);\n\t*insn++ = BPF_ST_MEM(BPF_B, ret,\n\t\t\t     offsetof(struct htab_elem, lru_node) +\n\t\t\t     offsetof(struct bpf_lru_node, ref),\n\t\t\t     1);\n\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,\n\t\t\t\toffsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8));\n\treturn insn - insn_buf;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BPF_ALU64_IMM",
          "args": [
            "BPF_ADD",
            "ret",
            "offsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8)"
          ],
          "line": 722
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 724
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_ST_MEM",
          "args": [
            "BPF_B",
            "ret",
            "offsetof(struct htab_elem, lru_node) +\n\t\t\t     offsetof(struct bpf_lru_node, ref)",
            "1"
          ],
          "line": 718
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_JMP_IMM",
          "args": [
            "BPF_JNE",
            "ref_reg",
            "0",
            "1"
          ],
          "line": 717
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_B",
            "ref_reg",
            "ret",
            "offsetof(struct htab_elem, lru_node) +\n\t\t\t      offsetof(struct bpf_lru_node, ref)"
          ],
          "line": 714
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_JMP_IMM",
          "args": [
            "BPF_JEQ",
            "ret",
            "0",
            "4"
          ],
          "line": 713
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_EMIT_CALL",
          "args": [
            "__htab_map_lookup_elem"
          ],
          "line": 712
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL)"
          ],
          "line": 710
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__same_type",
          "args": [
            "&__htab_map_lookup_elem",
            "(void *(*)(struct bpf_map *map, void *key))NULL"
          ],
          "line": 710
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_lru_map_gen_lookup(struct bpf_map *map,\n\t\t\t\t   struct bpf_insn *insn_buf)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\tconst int ret = BPF_REG_0;\n\tconst int ref_reg = BPF_REG_1;\n\n\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);\n\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 4);\n\t*insn++ = BPF_LDX_MEM(BPF_B, ref_reg, ret,\n\t\t\t      offsetof(struct htab_elem, lru_node) +\n\t\t\t      offsetof(struct bpf_lru_node, ref));\n\t*insn++ = BPF_JMP_IMM(BPF_JNE, ref_reg, 0, 1);\n\t*insn++ = BPF_ST_MEM(BPF_B, ret,\n\t\t\t     offsetof(struct htab_elem, lru_node) +\n\t\t\t     offsetof(struct bpf_lru_node, ref),\n\t\t\t     1);\n\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,\n\t\t\t\toffsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8));\n\treturn insn - insn_buf;\n}"
  },
  {
    "function_name": "htab_lru_map_lookup_elem_sys",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "698-701",
    "snippet": "static void *htab_lru_map_lookup_elem_sys(struct bpf_map *map, void *key)\n{\n\treturn __htab_lru_map_lookup_elem(map, key, false);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_lru_map_lookup_elem",
          "args": [
            "map",
            "key",
            "false"
          ],
          "line": 700
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_lru_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "679-691",
          "snippet": "static __always_inline void *__htab_lru_map_lookup_elem(struct bpf_map *map,\n\t\t\t\t\t\t\tvoid *key, const bool mark)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tif (mark)\n\t\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn l->key + round_up(map->key_size, 8);\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic __always_inline void *__htab_lru_map_lookup_elem(struct bpf_map *map,\n\t\t\t\t\t\t\tvoid *key, const bool mark)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tif (mark)\n\t\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn l->key + round_up(map->key_size, 8);\n\t}\n\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_lru_map_lookup_elem_sys(struct bpf_map *map, void *key)\n{\n\treturn __htab_lru_map_lookup_elem(map, key, false);\n}"
  },
  {
    "function_name": "htab_lru_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "693-696",
    "snippet": "static void *htab_lru_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn __htab_lru_map_lookup_elem(map, key, true);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__htab_lru_map_lookup_elem",
          "args": [
            "map",
            "key",
            "true"
          ],
          "line": 695
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_lru_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "679-691",
          "snippet": "static __always_inline void *__htab_lru_map_lookup_elem(struct bpf_map *map,\n\t\t\t\t\t\t\tvoid *key, const bool mark)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tif (mark)\n\t\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn l->key + round_up(map->key_size, 8);\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic __always_inline void *__htab_lru_map_lookup_elem(struct bpf_map *map,\n\t\t\t\t\t\t\tvoid *key, const bool mark)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tif (mark)\n\t\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn l->key + round_up(map->key_size, 8);\n\t}\n\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_lru_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn __htab_lru_map_lookup_elem(map, key, true);\n}"
  },
  {
    "function_name": "__htab_lru_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "679-691",
    "snippet": "static __always_inline void *__htab_lru_map_lookup_elem(struct bpf_map *map,\n\t\t\t\t\t\t\tvoid *key, const bool mark)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tif (mark)\n\t\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn l->key + round_up(map->key_size, 8);\n\t}\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 687
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_lru_node_set_ref",
          "args": [
            "&l->lru_node"
          ],
          "line": 686
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_node_set_ref",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.h",
          "lines": "64-71",
          "snippet": "static inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}",
          "includes": [
            "#include <linux/spinlock_types.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/spinlock_types.h>\n#include <linux/list.h>\n\nstatic inline void bpf_lru_node_set_ref(struct bpf_lru_node *node)\n{\n\t/* ref is an approximation on access frequency.  It does not\n\t * have to be very accurate.  Hence, no protection is used.\n\t */\n\tif (!node->ref)\n\t\tnode->ref = 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 682
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "622-641",
          "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic __always_inline void *__htab_lru_map_lookup_elem(struct bpf_map *map,\n\t\t\t\t\t\t\tvoid *key, const bool mark)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l) {\n\t\tif (mark)\n\t\t\tbpf_lru_node_set_ref(&l->lru_node);\n\t\treturn l->key + round_up(map->key_size, 8);\n\t}\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "htab_map_gen_lookup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "664-677",
    "snippet": "static int htab_map_gen_lookup(struct bpf_map *map, struct bpf_insn *insn_buf)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\tconst int ret = BPF_REG_0;\n\n\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);\n\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 1);\n\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,\n\t\t\t\toffsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8));\n\treturn insn - insn_buf;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BPF_ALU64_IMM",
          "args": [
            "BPF_ADD",
            "ret",
            "offsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8)"
          ],
          "line": 673
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 675
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_JMP_IMM",
          "args": [
            "BPF_JEQ",
            "ret",
            "0",
            "1"
          ],
          "line": 672
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_EMIT_CALL",
          "args": [
            "__htab_map_lookup_elem"
          ],
          "line": 671
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL)"
          ],
          "line": 669
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__same_type",
          "args": [
            "&__htab_map_lookup_elem",
            "(void *(*)(struct bpf_map *map, void *key))NULL"
          ],
          "line": 669
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int htab_map_gen_lookup(struct bpf_map *map, struct bpf_insn *insn_buf)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\tconst int ret = BPF_REG_0;\n\n\tBUILD_BUG_ON(!__same_type(&__htab_map_lookup_elem,\n\t\t     (void *(*)(struct bpf_map *map, void *key))NULL));\n\t*insn++ = BPF_EMIT_CALL(__htab_map_lookup_elem);\n\t*insn++ = BPF_JMP_IMM(BPF_JEQ, ret, 0, 1);\n\t*insn++ = BPF_ALU64_IMM(BPF_ADD, ret,\n\t\t\t\toffsetof(struct htab_elem, key) +\n\t\t\t\tround_up(map->key_size, 8));\n\treturn insn - insn_buf;\n}"
  },
  {
    "function_name": "htab_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "643-651",
    "snippet": "static void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 648
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__htab_map_lookup_elem",
          "args": [
            "map",
            "key"
          ],
          "line": 645
        },
        "resolved": true,
        "details": {
          "function_name": "__htab_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "622-641",
          "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct htab_elem *l = __htab_map_lookup_elem(map, key);\n\n\tif (l)\n\t\treturn l->key + round_up(map->key_size, 8);\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "__htab_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "622-641",
    "snippet": "static void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lookup_nulls_elem_raw",
          "args": [
            "head",
            "hash",
            "key",
            "key_size",
            "htab->n_buckets"
          ],
          "line": 638
        },
        "resolved": true,
        "details": {
          "function_name": "lookup_nulls_elem_raw",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "599-615",
          "snippet": "static struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 636
        },
        "resolved": true,
        "details": {
          "function_name": "select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "576-579",
          "snippet": "static inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_map_hash",
          "args": [
            "key",
            "key_size",
            "htab->hashrnd"
          ],
          "line": 634
        },
        "resolved": true,
        "details": {
          "function_name": "htab_map_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "566-569",
          "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held()"
          ],
          "line": 629
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 630
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_trace_held",
          "args": [],
          "line": 629
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 629
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_htab",
            "map"
          ],
          "line": 624
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *__htab_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_htab *htab = container_of(map, struct bpf_htab, map);\n\tstruct hlist_nulls_head *head;\n\tstruct htab_elem *l;\n\tu32 hash, key_size;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held() && !rcu_read_lock_trace_held() &&\n\t\t     !rcu_read_lock_bh_held());\n\n\tkey_size = map->key_size;\n\n\thash = htab_map_hash(key, key_size, htab->hashrnd);\n\n\thead = select_bucket(htab, hash);\n\n\tl = lookup_nulls_elem_raw(head, hash, key, key_size, htab->n_buckets);\n\n\treturn l;\n}"
  },
  {
    "function_name": "lookup_nulls_elem_raw",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "599-615",
    "snippet": "static struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "get_nulls_value(n) != (hash & (n_buckets - 1))"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_nulls_value",
          "args": [
            "n"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcmp",
          "args": [
            "&l->key",
            "key",
            "key_size"
          ],
          "line": 608
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_rcu",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 607
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_nulls_elem_raw(struct hlist_nulls_head *head,\n\t\t\t\t\t       u32 hash, void *key,\n\t\t\t\t\t       u32 key_size, u32 n_buckets)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\nagain:\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\tif (unlikely(get_nulls_value(n) != (hash & (n_buckets - 1))))\n\t\tgoto again;\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "lookup_elem_raw",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "582-593",
    "snippet": "static struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memcmp",
          "args": [
            "&l->key",
            "key",
            "key_size"
          ],
          "line": 589
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hlist_nulls_for_each_entry_rcu",
          "args": [
            "l",
            "n",
            "head",
            "hash_node"
          ],
          "line": 588
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *lookup_elem_raw(struct hlist_nulls_head *head, u32 hash,\n\t\t\t\t\t void *key, u32 key_size)\n{\n\tstruct hlist_nulls_node *n;\n\tstruct htab_elem *l;\n\n\thlist_nulls_for_each_entry_rcu(l, n, head, hash_node)\n\t\tif (l->hash == hash && !memcmp(&l->key, key, key_size))\n\t\t\treturn l;\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "select_bucket",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "576-579",
    "snippet": "static inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__select_bucket",
          "args": [
            "htab",
            "hash"
          ],
          "line": 578
        },
        "resolved": true,
        "details": {
          "function_name": "__select_bucket",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "571-574",
          "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct hlist_nulls_head *select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &__select_bucket(htab, hash)->head;\n}"
  },
  {
    "function_name": "__select_bucket",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "571-574",
    "snippet": "static inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline struct bucket *__select_bucket(struct bpf_htab *htab, u32 hash)\n{\n\treturn &htab->buckets[hash & (htab->n_buckets - 1)];\n}"
  },
  {
    "function_name": "htab_map_hash",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "566-569",
    "snippet": "static inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "jhash",
          "args": [
            "key",
            "key_len",
            "hashrnd"
          ],
          "line": 568
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline u32 htab_map_hash(const void *key, u32 key_len, u32 hashrnd)\n{\n\treturn jhash(key, key_len, hashrnd);\n}"
  },
  {
    "function_name": "htab_map_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "462-564",
    "snippet": "static struct bpf_map *htab_map_alloc(union bpf_attr *attr)\n{\n\tbool percpu = (attr->map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\t       attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\tbool lru = (attr->map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\t    attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\t/* percpu_lru means each cpu has its own LRU list.\n\t * it is different from BPF_MAP_TYPE_PERCPU_HASH where\n\t * the map's value itself is percpu.  percpu_lru has\n\t * nothing to do with the map's value.\n\t */\n\tbool percpu_lru = (attr->map_flags & BPF_F_NO_COMMON_LRU);\n\tbool prealloc = !(attr->map_flags & BPF_F_NO_PREALLOC);\n\tstruct bpf_htab *htab;\n\tint err, i;\n\n\thtab = kzalloc(sizeof(*htab), GFP_USER | __GFP_ACCOUNT);\n\tif (!htab)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlockdep_register_key(&htab->lockdep_key);\n\n\tbpf_map_init_from_attr(&htab->map, attr);\n\n\tif (percpu_lru) {\n\t\t/* ensure each CPU's lru list has >=1 elements.\n\t\t * since we are at it, make each lru list has the same\n\t\t * number of elements.\n\t\t */\n\t\thtab->map.max_entries = roundup(attr->max_entries,\n\t\t\t\t\t\tnum_possible_cpus());\n\t\tif (htab->map.max_entries < attr->max_entries)\n\t\t\thtab->map.max_entries = rounddown(attr->max_entries,\n\t\t\t\t\t\t\t  num_possible_cpus());\n\t}\n\n\t/* hash table size must be power of 2 */\n\thtab->n_buckets = roundup_pow_of_two(htab->map.max_entries);\n\n\thtab->elem_size = sizeof(struct htab_elem) +\n\t\t\t  round_up(htab->map.key_size, 8);\n\tif (percpu)\n\t\thtab->elem_size += sizeof(void *);\n\telse\n\t\thtab->elem_size += round_up(htab->map.value_size, 8);\n\n\terr = -E2BIG;\n\t/* prevent zero size kmalloc and check for u32 overflow */\n\tif (htab->n_buckets == 0 ||\n\t    htab->n_buckets > U32_MAX / sizeof(struct bucket))\n\t\tgoto free_htab;\n\n\terr = -ENOMEM;\n\thtab->buckets = bpf_map_area_alloc(htab->n_buckets *\n\t\t\t\t\t   sizeof(struct bucket),\n\t\t\t\t\t   htab->map.numa_node);\n\tif (!htab->buckets)\n\t\tgoto free_htab;\n\n\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++) {\n\t\thtab->map_locked[i] = bpf_map_alloc_percpu(&htab->map,\n\t\t\t\t\t\t\t   sizeof(int),\n\t\t\t\t\t\t\t   sizeof(int),\n\t\t\t\t\t\t\t   GFP_USER);\n\t\tif (!htab->map_locked[i])\n\t\t\tgoto free_map_locked;\n\t}\n\n\tif (htab->map.map_flags & BPF_F_ZERO_SEED)\n\t\thtab->hashrnd = 0;\n\telse\n\t\thtab->hashrnd = get_random_int();\n\n\thtab_init_buckets(htab);\n\n\tif (prealloc) {\n\t\terr = prealloc_init(htab);\n\t\tif (err)\n\t\t\tgoto free_map_locked;\n\n\t\tif (!percpu && !lru) {\n\t\t\t/* lru itself can remove the least used element, so\n\t\t\t * there is no need for an extra elem during map_update.\n\t\t\t */\n\t\t\terr = alloc_extra_elems(htab);\n\t\t\tif (err)\n\t\t\t\tgoto free_prealloc;\n\t\t}\n\t}\n\n\treturn &htab->map;\n\nfree_prealloc:\n\tprealloc_destroy(htab);\nfree_map_locked:\n\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++)\n\t\tfree_percpu(htab->map_locked[i]);\n\tbpf_map_area_free(htab->buckets);\nfree_htab:\n\tlockdep_unregister_key(&htab->lockdep_key);\n\tkfree(htab);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define HASHTAB_MAP_LOCK_COUNT 8"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 563
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "htab"
          ],
          "line": 562
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_unregister_key",
          "args": [
            "&htab->lockdep_key"
          ],
          "line": 561
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_unregister_key",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "6294-6328",
          "snippet": "void lockdep_unregister_key(struct lock_class_key *key)\n{\n\tstruct hlist_head *hash_head = keyhashentry(key);\n\tstruct lock_class_key *k;\n\tstruct pending_free *pf;\n\tunsigned long flags;\n\tbool found = false;\n\n\tmight_sleep();\n\n\tif (WARN_ON_ONCE(static_obj(key)))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tif (!graph_lock())\n\t\tgoto out_irq;\n\n\tpf = get_pending_free();\n\thlist_for_each_entry_rcu(k, hash_head, hash_entry) {\n\t\tif (k == key) {\n\t\t\thlist_del_rcu(&k->hash_entry);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tWARN_ON_ONCE(!found);\n\t__lockdep_free_key_range(pf, key, 1);\n\tcall_rcu_zapped(pf);\n\tgraph_unlock();\nout_irq:\n\traw_local_irq_restore(flags);\n\n\t/* Wait until is_dynamic_key() has finished accessing k->hash_entry. */\n\tsynchronize_rcu();\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct delayed_free {\n\tstruct rcu_head\t\trcu_head;\n\tint\t\t\tindex;\n\tint\t\t\tscheduled;\n\tstruct pending_free\tpf[2];\n} delayed_free;",
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic struct delayed_free {\n\tstruct rcu_head\t\trcu_head;\n\tint\t\t\tindex;\n\tint\t\t\tscheduled;\n\tstruct pending_free\tpf[2];\n} delayed_free;\nstatic noinstr struct;\n\nvoid lockdep_unregister_key(struct lock_class_key *key)\n{\n\tstruct hlist_head *hash_head = keyhashentry(key);\n\tstruct lock_class_key *k;\n\tstruct pending_free *pf;\n\tunsigned long flags;\n\tbool found = false;\n\n\tmight_sleep();\n\n\tif (WARN_ON_ONCE(static_obj(key)))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tif (!graph_lock())\n\t\tgoto out_irq;\n\n\tpf = get_pending_free();\n\thlist_for_each_entry_rcu(k, hash_head, hash_entry) {\n\t\tif (k == key) {\n\t\t\thlist_del_rcu(&k->hash_entry);\n\t\t\tfound = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tWARN_ON_ONCE(!found);\n\t__lockdep_free_key_range(pf, key, 1);\n\tcall_rcu_zapped(pf);\n\tgraph_unlock();\nout_irq:\n\traw_local_irq_restore(flags);\n\n\t/* Wait until is_dynamic_key() has finished accessing k->hash_entry. */\n\tsynchronize_rcu();\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "htab->buckets"
          ],
          "line": 559
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "htab->map_locked[i]"
          ],
          "line": 558
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/arraymap.c",
          "lines": "21-29",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "prealloc_destroy",
          "args": [
            "htab"
          ],
          "line": 555
        },
        "resolved": true,
        "details": {
          "function_name": "prealloc_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "365-373",
          "snippet": "static void prealloc_destroy(struct bpf_htab *htab)\n{\n\thtab_free_elems(htab);\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_destroy(&htab->lru);\n\telse\n\t\tpcpu_freelist_destroy(&htab->freelist);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void prealloc_destroy(struct bpf_htab *htab)\n{\n\thtab_free_elems(htab);\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_destroy(&htab->lru);\n\telse\n\t\tpcpu_freelist_destroy(&htab->freelist);\n}"
        }
      },
      {
        "call_info": {
          "callee": "alloc_extra_elems",
          "args": [
            "htab"
          ],
          "line": 546
        },
        "resolved": true,
        "details": {
          "function_name": "alloc_extra_elems",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "375-396",
          "snippet": "static int alloc_extra_elems(struct bpf_htab *htab)\n{\n\tstruct htab_elem *__percpu *pptr, *l_new;\n\tstruct pcpu_freelist_node *l;\n\tint cpu;\n\n\tpptr = bpf_map_alloc_percpu(&htab->map, sizeof(struct htab_elem *), 8,\n\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\tif (!pptr)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tl = pcpu_freelist_pop(&htab->freelist);\n\t\t/* pop will succeed, since prealloc_init()\n\t\t * preallocated extra num_possible_cpus elements\n\t\t */\n\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t*per_cpu_ptr(pptr, cpu) = l_new;\n\t}\n\thtab->extra_elems = pptr;\n\treturn 0;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int alloc_extra_elems(struct bpf_htab *htab)\n{\n\tstruct htab_elem *__percpu *pptr, *l_new;\n\tstruct pcpu_freelist_node *l;\n\tint cpu;\n\n\tpptr = bpf_map_alloc_percpu(&htab->map, sizeof(struct htab_elem *), 8,\n\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\tif (!pptr)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tl = pcpu_freelist_pop(&htab->freelist);\n\t\t/* pop will succeed, since prealloc_init()\n\t\t * preallocated extra num_possible_cpus elements\n\t\t */\n\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t*per_cpu_ptr(pptr, cpu) = l_new;\n\t}\n\thtab->extra_elems = pptr;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "prealloc_init",
          "args": [
            "htab"
          ],
          "line": 538
        },
        "resolved": true,
        "details": {
          "function_name": "prealloc_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "306-363",
          "snippet": "static int prealloc_init(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint err = -ENOMEM, i;\n\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\thtab->elems = bpf_map_area_alloc((u64)htab->elem_size * num_entries,\n\t\t\t\t\t htab->map.numa_node);\n\tif (!htab->elems)\n\t\treturn -ENOMEM;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto skip_percpu_elems;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\t\tif (!pptr)\n\t\t\tgoto free_elems;\n\t\thtab_elem_set_ptr(get_htab_elem(htab, i), htab->map.key_size,\n\t\t\t\t  pptr);\n\t\tcond_resched();\n\t}\n\nskip_percpu_elems:\n\tif (htab_is_lru(htab))\n\t\terr = bpf_lru_init(&htab->lru,\n\t\t\t\t   htab->map.map_flags & BPF_F_NO_COMMON_LRU,\n\t\t\t\t   offsetof(struct htab_elem, hash) -\n\t\t\t\t   offsetof(struct htab_elem, lru_node),\n\t\t\t\t   htab_lru_map_delete_node,\n\t\t\t\t   htab);\n\telse\n\t\terr = pcpu_freelist_init(&htab->freelist);\n\n\tif (err)\n\t\tgoto free_elems;\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_populate(&htab->lru, htab->elems,\n\t\t\t\t offsetof(struct htab_elem, lru_node),\n\t\t\t\t htab->elem_size, num_entries);\n\telse\n\t\tpcpu_freelist_populate(&htab->freelist,\n\t\t\t\t       htab->elems + offsetof(struct htab_elem, fnode),\n\t\t\t\t       htab->elem_size, num_entries);\n\n\treturn 0;\n\nfree_elems:\n\thtab_free_elems(htab);\n\treturn err;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int prealloc_init(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint err = -ENOMEM, i;\n\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\thtab->elems = bpf_map_area_alloc((u64)htab->elem_size * num_entries,\n\t\t\t\t\t htab->map.numa_node);\n\tif (!htab->elems)\n\t\treturn -ENOMEM;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto skip_percpu_elems;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\t\tif (!pptr)\n\t\t\tgoto free_elems;\n\t\thtab_elem_set_ptr(get_htab_elem(htab, i), htab->map.key_size,\n\t\t\t\t  pptr);\n\t\tcond_resched();\n\t}\n\nskip_percpu_elems:\n\tif (htab_is_lru(htab))\n\t\terr = bpf_lru_init(&htab->lru,\n\t\t\t\t   htab->map.map_flags & BPF_F_NO_COMMON_LRU,\n\t\t\t\t   offsetof(struct htab_elem, hash) -\n\t\t\t\t   offsetof(struct htab_elem, lru_node),\n\t\t\t\t   htab_lru_map_delete_node,\n\t\t\t\t   htab);\n\telse\n\t\terr = pcpu_freelist_init(&htab->freelist);\n\n\tif (err)\n\t\tgoto free_elems;\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_populate(&htab->lru, htab->elems,\n\t\t\t\t offsetof(struct htab_elem, lru_node),\n\t\t\t\t htab->elem_size, num_entries);\n\telse\n\t\tpcpu_freelist_populate(&htab->freelist,\n\t\t\t\t       htab->elems + offsetof(struct htab_elem, fnode),\n\t\t\t\t       htab->elem_size, num_entries);\n\n\treturn 0;\n\nfree_elems:\n\thtab_free_elems(htab);\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_init_buckets",
          "args": [
            "htab"
          ],
          "line": 535
        },
        "resolved": true,
        "details": {
          "function_name": "htab_init_buckets",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "140-157",
          "snippet": "static void htab_init_buckets(struct bpf_htab *htab)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tINIT_HLIST_NULLS_HEAD(&htab->buckets[i].head, i);\n\t\tif (htab_use_raw_lock(htab)) {\n\t\t\traw_spin_lock_init(&htab->buckets[i].raw_lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].raw_lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t} else {\n\t\t\tspin_lock_init(&htab->buckets[i].lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t}\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_init_buckets(struct bpf_htab *htab)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tINIT_HLIST_NULLS_HEAD(&htab->buckets[i].head, i);\n\t\tif (htab_use_raw_lock(htab)) {\n\t\t\traw_spin_lock_init(&htab->buckets[i].raw_lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].raw_lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t} else {\n\t\t\tspin_lock_init(&htab->buckets[i].lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t}\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_random_int",
          "args": [],
          "line": 533
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_alloc_percpu",
          "args": [
            "&htab->map",
            "sizeof(int)",
            "sizeof(int)",
            "GFP_USER"
          ],
          "line": 522
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_alloc_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "452-463",
          "snippet": "void __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "htab->n_buckets *\n\t\t\t\t\t   sizeof(struct bucket)",
            "htab->map.numa_node"
          ],
          "line": 515
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "334-337",
          "snippet": "void *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.value_size",
            "8"
          ],
          "line": 506
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.key_size",
            "8"
          ],
          "line": 502
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "roundup_pow_of_two",
          "args": [
            "htab->map.max_entries"
          ],
          "line": 499
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rounddown",
          "args": [
            "attr->max_entries",
            "num_possible_cpus()"
          ],
          "line": 494
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "roundup",
          "args": [
            "attr->max_entries",
            "num_possible_cpus()"
          ],
          "line": 491
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 492
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&htab->map",
            "attr"
          ],
          "line": 484
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "361-370",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_register_key",
          "args": [
            "&htab->lockdep_key"
          ],
          "line": 482
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_register_key",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "1187-1209",
          "snippet": "void lockdep_register_key(struct lock_class_key *key)\n{\n\tstruct hlist_head *hash_head;\n\tstruct lock_class_key *k;\n\tunsigned long flags;\n\n\tif (WARN_ON_ONCE(static_obj(key)))\n\t\treturn;\n\thash_head = keyhashentry(key);\n\n\traw_local_irq_save(flags);\n\tif (!graph_lock())\n\t\tgoto restore_irqs;\n\thlist_for_each_entry_rcu(k, hash_head, hash_entry) {\n\t\tif (WARN_ON_ONCE(k == key))\n\t\t\tgoto out_unlock;\n\t}\n\thlist_add_head_rcu(&key->hash_entry, hash_head);\nout_unlock:\n\tgraph_unlock();\nrestore_irqs:\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid lockdep_register_key(struct lock_class_key *key)\n{\n\tstruct hlist_head *hash_head;\n\tstruct lock_class_key *k;\n\tunsigned long flags;\n\n\tif (WARN_ON_ONCE(static_obj(key)))\n\t\treturn;\n\thash_head = keyhashentry(key);\n\n\traw_local_irq_save(flags);\n\tif (!graph_lock())\n\t\tgoto restore_irqs;\n\thlist_for_each_entry_rcu(k, hash_head, hash_entry) {\n\t\tif (WARN_ON_ONCE(k == key))\n\t\t\tgoto out_unlock;\n\t}\n\thlist_add_head_rcu(&key->hash_entry, hash_head);\nout_unlock:\n\tgraph_unlock();\nrestore_irqs:\n\traw_local_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 480
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*htab)",
            "GFP_USER | __GFP_ACCOUNT"
          ],
          "line": 478
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_COUNT 8\n\nstatic struct bpf_map *htab_map_alloc(union bpf_attr *attr)\n{\n\tbool percpu = (attr->map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\t       attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\tbool lru = (attr->map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\t    attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\t/* percpu_lru means each cpu has its own LRU list.\n\t * it is different from BPF_MAP_TYPE_PERCPU_HASH where\n\t * the map's value itself is percpu.  percpu_lru has\n\t * nothing to do with the map's value.\n\t */\n\tbool percpu_lru = (attr->map_flags & BPF_F_NO_COMMON_LRU);\n\tbool prealloc = !(attr->map_flags & BPF_F_NO_PREALLOC);\n\tstruct bpf_htab *htab;\n\tint err, i;\n\n\thtab = kzalloc(sizeof(*htab), GFP_USER | __GFP_ACCOUNT);\n\tif (!htab)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tlockdep_register_key(&htab->lockdep_key);\n\n\tbpf_map_init_from_attr(&htab->map, attr);\n\n\tif (percpu_lru) {\n\t\t/* ensure each CPU's lru list has >=1 elements.\n\t\t * since we are at it, make each lru list has the same\n\t\t * number of elements.\n\t\t */\n\t\thtab->map.max_entries = roundup(attr->max_entries,\n\t\t\t\t\t\tnum_possible_cpus());\n\t\tif (htab->map.max_entries < attr->max_entries)\n\t\t\thtab->map.max_entries = rounddown(attr->max_entries,\n\t\t\t\t\t\t\t  num_possible_cpus());\n\t}\n\n\t/* hash table size must be power of 2 */\n\thtab->n_buckets = roundup_pow_of_two(htab->map.max_entries);\n\n\thtab->elem_size = sizeof(struct htab_elem) +\n\t\t\t  round_up(htab->map.key_size, 8);\n\tif (percpu)\n\t\thtab->elem_size += sizeof(void *);\n\telse\n\t\thtab->elem_size += round_up(htab->map.value_size, 8);\n\n\terr = -E2BIG;\n\t/* prevent zero size kmalloc and check for u32 overflow */\n\tif (htab->n_buckets == 0 ||\n\t    htab->n_buckets > U32_MAX / sizeof(struct bucket))\n\t\tgoto free_htab;\n\n\terr = -ENOMEM;\n\thtab->buckets = bpf_map_area_alloc(htab->n_buckets *\n\t\t\t\t\t   sizeof(struct bucket),\n\t\t\t\t\t   htab->map.numa_node);\n\tif (!htab->buckets)\n\t\tgoto free_htab;\n\n\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++) {\n\t\thtab->map_locked[i] = bpf_map_alloc_percpu(&htab->map,\n\t\t\t\t\t\t\t   sizeof(int),\n\t\t\t\t\t\t\t   sizeof(int),\n\t\t\t\t\t\t\t   GFP_USER);\n\t\tif (!htab->map_locked[i])\n\t\t\tgoto free_map_locked;\n\t}\n\n\tif (htab->map.map_flags & BPF_F_ZERO_SEED)\n\t\thtab->hashrnd = 0;\n\telse\n\t\thtab->hashrnd = get_random_int();\n\n\thtab_init_buckets(htab);\n\n\tif (prealloc) {\n\t\terr = prealloc_init(htab);\n\t\tif (err)\n\t\t\tgoto free_map_locked;\n\n\t\tif (!percpu && !lru) {\n\t\t\t/* lru itself can remove the least used element, so\n\t\t\t * there is no need for an extra elem during map_update.\n\t\t\t */\n\t\t\terr = alloc_extra_elems(htab);\n\t\t\tif (err)\n\t\t\t\tgoto free_prealloc;\n\t\t}\n\t}\n\n\treturn &htab->map;\n\nfree_prealloc:\n\tprealloc_destroy(htab);\nfree_map_locked:\n\tfor (i = 0; i < HASHTAB_MAP_LOCK_COUNT; i++)\n\t\tfree_percpu(htab->map_locked[i]);\n\tbpf_map_area_free(htab->buckets);\nfree_htab:\n\tlockdep_unregister_key(&htab->lockdep_key);\n\tkfree(htab);\n\treturn ERR_PTR(err);\n}"
  },
  {
    "function_name": "htab_map_alloc_check",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "399-460",
    "snippet": "static int htab_map_alloc_check(union bpf_attr *attr)\n{\n\tbool percpu = (attr->map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\t       attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\tbool lru = (attr->map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\t    attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\t/* percpu_lru means each cpu has its own LRU list.\n\t * it is different from BPF_MAP_TYPE_PERCPU_HASH where\n\t * the map's value itself is percpu.  percpu_lru has\n\t * nothing to do with the map's value.\n\t */\n\tbool percpu_lru = (attr->map_flags & BPF_F_NO_COMMON_LRU);\n\tbool prealloc = !(attr->map_flags & BPF_F_NO_PREALLOC);\n\tbool zero_seed = (attr->map_flags & BPF_F_ZERO_SEED);\n\tint numa_node = bpf_map_attr_numa_node(attr);\n\n\tBUILD_BUG_ON(offsetof(struct htab_elem, htab) !=\n\t\t     offsetof(struct htab_elem, hash_node.pprev));\n\tBUILD_BUG_ON(offsetof(struct htab_elem, fnode.next) !=\n\t\t     offsetof(struct htab_elem, hash_node.pprev));\n\n\tif (lru && !bpf_capable())\n\t\t/* LRU implementation is much complicated than other\n\t\t * maps.  Hence, limit to CAP_BPF.\n\t\t */\n\t\treturn -EPERM;\n\n\tif (zero_seed && !capable(CAP_SYS_ADMIN))\n\t\t/* Guard against local DoS, and discourage production use. */\n\t\treturn -EPERM;\n\n\tif (attr->map_flags & ~HTAB_CREATE_FLAG_MASK ||\n\t    !bpf_map_flags_access_ok(attr->map_flags))\n\t\treturn -EINVAL;\n\n\tif (!lru && percpu_lru)\n\t\treturn -EINVAL;\n\n\tif (lru && !prealloc)\n\t\treturn -ENOTSUPP;\n\n\tif (numa_node != NUMA_NO_NODE && (percpu || percpu_lru))\n\t\treturn -EINVAL;\n\n\t/* check sanity of attributes.\n\t * value_size == 0 may be allowed in the future to use map as a set\n\t */\n\tif (attr->max_entries == 0 || attr->key_size == 0 ||\n\t    attr->value_size == 0)\n\t\treturn -EINVAL;\n\n\tif ((u64)attr->key_size + attr->value_size >= KMALLOC_MAX_SIZE -\n\t   sizeof(struct htab_elem))\n\t\t/* if key_size + value_size is bigger, the user space won't be\n\t\t * able to access the elements via bpf syscall. This check\n\t\t * also makes sure that the elem_size doesn't overflow and it's\n\t\t * kmalloc-able later in htab_map_update_elem()\n\t\t */\n\t\treturn -E2BIG;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define HTAB_CREATE_FLAG_MASK\t\t\t\t\t\t\\\n\t(BPF_F_NO_PREALLOC | BPF_F_NO_COMMON_LRU | BPF_F_NUMA_NODE |\t\\\n\t BPF_F_ACCESS_MASK | BPF_F_ZERO_SEED)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_map_flags_access_ok",
          "args": [
            "attr->map_flags"
          ],
          "line": 431
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_SYS_ADMIN"
          ],
          "line": 426
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/capability.c",
          "lines": "447-450",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_capable",
          "args": [],
          "line": 420
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "offsetof(struct htab_elem, htab) !=\n\t\t     offsetof(struct htab_elem, hash_node.pprev)"
          ],
          "line": 415
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_attr_numa_node",
          "args": [
            "attr"
          ],
          "line": 413
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HTAB_CREATE_FLAG_MASK\t\t\t\t\t\t\\\n\t(BPF_F_NO_PREALLOC | BPF_F_NO_COMMON_LRU | BPF_F_NUMA_NODE |\t\\\n\t BPF_F_ACCESS_MASK | BPF_F_ZERO_SEED)\n\nstatic int htab_map_alloc_check(union bpf_attr *attr)\n{\n\tbool percpu = (attr->map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\t       attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\tbool lru = (attr->map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\t    attr->map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH);\n\t/* percpu_lru means each cpu has its own LRU list.\n\t * it is different from BPF_MAP_TYPE_PERCPU_HASH where\n\t * the map's value itself is percpu.  percpu_lru has\n\t * nothing to do with the map's value.\n\t */\n\tbool percpu_lru = (attr->map_flags & BPF_F_NO_COMMON_LRU);\n\tbool prealloc = !(attr->map_flags & BPF_F_NO_PREALLOC);\n\tbool zero_seed = (attr->map_flags & BPF_F_ZERO_SEED);\n\tint numa_node = bpf_map_attr_numa_node(attr);\n\n\tBUILD_BUG_ON(offsetof(struct htab_elem, htab) !=\n\t\t     offsetof(struct htab_elem, hash_node.pprev));\n\tBUILD_BUG_ON(offsetof(struct htab_elem, fnode.next) !=\n\t\t     offsetof(struct htab_elem, hash_node.pprev));\n\n\tif (lru && !bpf_capable())\n\t\t/* LRU implementation is much complicated than other\n\t\t * maps.  Hence, limit to CAP_BPF.\n\t\t */\n\t\treturn -EPERM;\n\n\tif (zero_seed && !capable(CAP_SYS_ADMIN))\n\t\t/* Guard against local DoS, and discourage production use. */\n\t\treturn -EPERM;\n\n\tif (attr->map_flags & ~HTAB_CREATE_FLAG_MASK ||\n\t    !bpf_map_flags_access_ok(attr->map_flags))\n\t\treturn -EINVAL;\n\n\tif (!lru && percpu_lru)\n\t\treturn -EINVAL;\n\n\tif (lru && !prealloc)\n\t\treturn -ENOTSUPP;\n\n\tif (numa_node != NUMA_NO_NODE && (percpu || percpu_lru))\n\t\treturn -EINVAL;\n\n\t/* check sanity of attributes.\n\t * value_size == 0 may be allowed in the future to use map as a set\n\t */\n\tif (attr->max_entries == 0 || attr->key_size == 0 ||\n\t    attr->value_size == 0)\n\t\treturn -EINVAL;\n\n\tif ((u64)attr->key_size + attr->value_size >= KMALLOC_MAX_SIZE -\n\t   sizeof(struct htab_elem))\n\t\t/* if key_size + value_size is bigger, the user space won't be\n\t\t * able to access the elements via bpf syscall. This check\n\t\t * also makes sure that the elem_size doesn't overflow and it's\n\t\t * kmalloc-able later in htab_map_update_elem()\n\t\t */\n\t\treturn -E2BIG;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "alloc_extra_elems",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "375-396",
    "snippet": "static int alloc_extra_elems(struct bpf_htab *htab)\n{\n\tstruct htab_elem *__percpu *pptr, *l_new;\n\tstruct pcpu_freelist_node *l;\n\tint cpu;\n\n\tpptr = bpf_map_alloc_percpu(&htab->map, sizeof(struct htab_elem *), 8,\n\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\tif (!pptr)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tl = pcpu_freelist_pop(&htab->freelist);\n\t\t/* pop will succeed, since prealloc_init()\n\t\t * preallocated extra num_possible_cpus elements\n\t\t */\n\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t*per_cpu_ptr(pptr, cpu) = l_new;\n\t}\n\thtab->extra_elems = pptr;\n\treturn 0;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "pptr",
            "cpu"
          ],
          "line": 392
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "l",
            "structhtab_elem",
            "fnode"
          ],
          "line": 391
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_pop",
          "args": [
            "&htab->freelist"
          ],
          "line": 387
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_pop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "200-209",
          "snippet": "struct pcpu_freelist_node *pcpu_freelist_pop(struct pcpu_freelist *s)\n{\n\tstruct pcpu_freelist_node *ret;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tret = __pcpu_freelist_pop(s);\n\tlocal_irq_restore(flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nstruct pcpu_freelist_node *pcpu_freelist_pop(struct pcpu_freelist *s)\n{\n\tstruct pcpu_freelist_node *ret;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tret = __pcpu_freelist_pop(s);\n\tlocal_irq_restore(flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_alloc_percpu",
          "args": [
            "&htab->map",
            "sizeof(struct htab_elem *)",
            "8",
            "GFP_USER | __GFP_NOWARN"
          ],
          "line": 381
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_alloc_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "452-463",
          "snippet": "void __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int alloc_extra_elems(struct bpf_htab *htab)\n{\n\tstruct htab_elem *__percpu *pptr, *l_new;\n\tstruct pcpu_freelist_node *l;\n\tint cpu;\n\n\tpptr = bpf_map_alloc_percpu(&htab->map, sizeof(struct htab_elem *), 8,\n\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\tif (!pptr)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tl = pcpu_freelist_pop(&htab->freelist);\n\t\t/* pop will succeed, since prealloc_init()\n\t\t * preallocated extra num_possible_cpus elements\n\t\t */\n\t\tl_new = container_of(l, struct htab_elem, fnode);\n\t\t*per_cpu_ptr(pptr, cpu) = l_new;\n\t}\n\thtab->extra_elems = pptr;\n\treturn 0;\n}"
  },
  {
    "function_name": "prealloc_destroy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "365-373",
    "snippet": "static void prealloc_destroy(struct bpf_htab *htab)\n{\n\thtab_free_elems(htab);\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_destroy(&htab->lru);\n\telse\n\t\tpcpu_freelist_destroy(&htab->freelist);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pcpu_freelist_destroy",
          "args": [
            "&htab->freelist"
          ],
          "line": 372
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "25-28",
          "snippet": "void pcpu_freelist_destroy(struct pcpu_freelist *s)\n{\n\tfree_percpu(s->freelist);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_destroy(struct pcpu_freelist *s)\n{\n\tfree_percpu(s->freelist);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_lru_destroy",
          "args": [
            "&htab->lru"
          ],
          "line": 370
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.c",
          "lines": "689-695",
          "snippet": "void bpf_lru_destroy(struct bpf_lru *lru)\n{\n\tif (lru->percpu)\n\t\tfree_percpu(lru->percpu_lru);\n\telse\n\t\tfree_percpu(lru->common_lru.local_list);\n}",
          "includes": [
            "#include \"bpf_lru_list.h\"",
            "#include <linux/percpu.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/cpumask.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_lru_list.h\"\n#include <linux/percpu.h>\n#include <linux/spinlock.h>\n#include <linux/cpumask.h>\n\nvoid bpf_lru_destroy(struct bpf_lru *lru)\n{\n\tif (lru->percpu)\n\t\tfree_percpu(lru->percpu_lru);\n\telse\n\t\tfree_percpu(lru->common_lru.local_list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_lru",
          "args": [
            "htab"
          ],
          "line": 369
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_lru",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "198-202",
          "snippet": "static bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_free_elems",
          "args": [
            "htab"
          ],
          "line": 367
        },
        "resolved": true,
        "details": {
          "function_name": "htab_free_elems",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "257-274",
          "snippet": "static void htab_free_elems(struct bpf_htab *htab)\n{\n\tint i;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto free_elems;\n\n\tfor (i = 0; i < htab->map.max_entries; i++) {\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),\n\t\t\t\t\t htab->map.key_size);\n\t\tfree_percpu(pptr);\n\t\tcond_resched();\n\t}\nfree_elems:\n\tbpf_map_area_free(htab->elems);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_elems(struct bpf_htab *htab)\n{\n\tint i;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto free_elems;\n\n\tfor (i = 0; i < htab->map.max_entries; i++) {\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),\n\t\t\t\t\t htab->map.key_size);\n\t\tfree_percpu(pptr);\n\t\tcond_resched();\n\t}\nfree_elems:\n\tbpf_map_area_free(htab->elems);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void prealloc_destroy(struct bpf_htab *htab)\n{\n\thtab_free_elems(htab);\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_destroy(&htab->lru);\n\telse\n\t\tpcpu_freelist_destroy(&htab->freelist);\n}"
  },
  {
    "function_name": "prealloc_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "306-363",
    "snippet": "static int prealloc_init(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint err = -ENOMEM, i;\n\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\thtab->elems = bpf_map_area_alloc((u64)htab->elem_size * num_entries,\n\t\t\t\t\t htab->map.numa_node);\n\tif (!htab->elems)\n\t\treturn -ENOMEM;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto skip_percpu_elems;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\t\tif (!pptr)\n\t\t\tgoto free_elems;\n\t\thtab_elem_set_ptr(get_htab_elem(htab, i), htab->map.key_size,\n\t\t\t\t  pptr);\n\t\tcond_resched();\n\t}\n\nskip_percpu_elems:\n\tif (htab_is_lru(htab))\n\t\terr = bpf_lru_init(&htab->lru,\n\t\t\t\t   htab->map.map_flags & BPF_F_NO_COMMON_LRU,\n\t\t\t\t   offsetof(struct htab_elem, hash) -\n\t\t\t\t   offsetof(struct htab_elem, lru_node),\n\t\t\t\t   htab_lru_map_delete_node,\n\t\t\t\t   htab);\n\telse\n\t\terr = pcpu_freelist_init(&htab->freelist);\n\n\tif (err)\n\t\tgoto free_elems;\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_populate(&htab->lru, htab->elems,\n\t\t\t\t offsetof(struct htab_elem, lru_node),\n\t\t\t\t htab->elem_size, num_entries);\n\telse\n\t\tpcpu_freelist_populate(&htab->freelist,\n\t\t\t\t       htab->elems + offsetof(struct htab_elem, fnode),\n\t\t\t\t       htab->elem_size, num_entries);\n\n\treturn 0;\n\nfree_elems:\n\thtab_free_elems(htab);\n\treturn err;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_free_elems",
          "args": [
            "htab"
          ],
          "line": 361
        },
        "resolved": true,
        "details": {
          "function_name": "htab_free_elems",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "257-274",
          "snippet": "static void htab_free_elems(struct bpf_htab *htab)\n{\n\tint i;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto free_elems;\n\n\tfor (i = 0; i < htab->map.max_entries; i++) {\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),\n\t\t\t\t\t htab->map.key_size);\n\t\tfree_percpu(pptr);\n\t\tcond_resched();\n\t}\nfree_elems:\n\tbpf_map_area_free(htab->elems);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_elems(struct bpf_htab *htab)\n{\n\tint i;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto free_elems;\n\n\tfor (i = 0; i < htab->map.max_entries; i++) {\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),\n\t\t\t\t\t htab->map.key_size);\n\t\tfree_percpu(pptr);\n\t\tcond_resched();\n\t}\nfree_elems:\n\tbpf_map_area_free(htab->elems);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_populate",
          "args": [
            "&htab->freelist",
            "htab->elems + offsetof(struct htab_elem, fnode)",
            "htab->elem_size",
            "num_entries"
          ],
          "line": 354
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_populate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "101-122",
          "snippet": "void pcpu_freelist_populate(struct pcpu_freelist *s, void *buf, u32 elem_size,\n\t\t\t    u32 nr_elems)\n{\n\tstruct pcpu_freelist_head *head;\n\tint i, cpu, pcpu_entries;\n\n\tpcpu_entries = nr_elems / num_possible_cpus() + 1;\n\ti = 0;\n\n\tfor_each_possible_cpu(cpu) {\nagain:\n\t\thead = per_cpu_ptr(s->freelist, cpu);\n\t\t/* No locking required as this is not visible yet. */\n\t\tpcpu_freelist_push_node(head, buf);\n\t\ti++;\n\t\tbuf += elem_size;\n\t\tif (i == nr_elems)\n\t\t\tbreak;\n\t\tif (i % pcpu_entries)\n\t\t\tgoto again;\n\t}\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_populate(struct pcpu_freelist *s, void *buf, u32 elem_size,\n\t\t\t    u32 nr_elems)\n{\n\tstruct pcpu_freelist_head *head;\n\tint i, cpu, pcpu_entries;\n\n\tpcpu_entries = nr_elems / num_possible_cpus() + 1;\n\ti = 0;\n\n\tfor_each_possible_cpu(cpu) {\nagain:\n\t\thead = per_cpu_ptr(s->freelist, cpu);\n\t\t/* No locking required as this is not visible yet. */\n\t\tpcpu_freelist_push_node(head, buf);\n\t\ti++;\n\t\tbuf += elem_size;\n\t\tif (i == nr_elems)\n\t\t\tbreak;\n\t\tif (i % pcpu_entries)\n\t\t\tgoto again;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_lru_populate",
          "args": [
            "&htab->lru",
            "htab->elems",
            "offsetof(struct htab_elem, lru_node)",
            "htab->elem_size",
            "num_entries"
          ],
          "line": 350
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_populate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.c",
          "lines": "608-617",
          "snippet": "void bpf_lru_populate(struct bpf_lru *lru, void *buf, u32 node_offset,\n\t\t      u32 elem_size, u32 nr_elems)\n{\n\tif (lru->percpu)\n\t\tbpf_percpu_lru_populate(lru, buf, node_offset, elem_size,\n\t\t\t\t\tnr_elems);\n\telse\n\t\tbpf_common_lru_populate(lru, buf, node_offset, elem_size,\n\t\t\t\t\tnr_elems);\n}",
          "includes": [
            "#include \"bpf_lru_list.h\"",
            "#include <linux/percpu.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/cpumask.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_lru_list.h\"\n#include <linux/percpu.h>\n#include <linux/spinlock.h>\n#include <linux/cpumask.h>\n\nvoid bpf_lru_populate(struct bpf_lru *lru, void *buf, u32 node_offset,\n\t\t      u32 elem_size, u32 nr_elems)\n{\n\tif (lru->percpu)\n\t\tbpf_percpu_lru_populate(lru, buf, node_offset, elem_size,\n\t\t\t\t\tnr_elems);\n\telse\n\t\tbpf_common_lru_populate(lru, buf, node_offset, elem_size,\n\t\t\t\t\tnr_elems);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_lru",
          "args": [
            "htab"
          ],
          "line": 349
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_lru",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "198-202",
          "snippet": "static bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_init",
          "args": [
            "&htab->freelist"
          ],
          "line": 344
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "6-23",
          "snippet": "int pcpu_freelist_init(struct pcpu_freelist *s)\n{\n\tint cpu;\n\n\ts->freelist = alloc_percpu(struct pcpu_freelist_head);\n\tif (!s->freelist)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct pcpu_freelist_head *head = per_cpu_ptr(s->freelist, cpu);\n\n\t\traw_spin_lock_init(&head->lock);\n\t\thead->first = NULL;\n\t}\n\traw_spin_lock_init(&s->extralist.lock);\n\ts->extralist.first = NULL;\n\treturn 0;\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nint pcpu_freelist_init(struct pcpu_freelist *s)\n{\n\tint cpu;\n\n\ts->freelist = alloc_percpu(struct pcpu_freelist_head);\n\tif (!s->freelist)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct pcpu_freelist_head *head = per_cpu_ptr(s->freelist, cpu);\n\n\t\traw_spin_lock_init(&head->lock);\n\t\thead->first = NULL;\n\t}\n\traw_spin_lock_init(&s->extralist.lock);\n\ts->extralist.first = NULL;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_lru_init",
          "args": [
            "&htab->lru",
            "htab->map.map_flags & BPF_F_NO_COMMON_LRU",
            "offsetof(struct htab_elem, hash) -\n\t\t\t\t   offsetof(struct htab_elem, lru_node)",
            "htab_lru_map_delete_node",
            "htab"
          ],
          "line": 337
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.c",
          "lines": "646-687",
          "snippet": "int bpf_lru_init(struct bpf_lru *lru, bool percpu, u32 hash_offset,\n\t\t del_from_htab_func del_from_htab, void *del_arg)\n{\n\tint cpu;\n\n\tif (percpu) {\n\t\tlru->percpu_lru = alloc_percpu(struct bpf_lru_list);\n\t\tif (!lru->percpu_lru)\n\t\t\treturn -ENOMEM;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tstruct bpf_lru_list *l;\n\n\t\t\tl = per_cpu_ptr(lru->percpu_lru, cpu);\n\t\t\tbpf_lru_list_init(l);\n\t\t}\n\t\tlru->nr_scans = PERCPU_NR_SCANS;\n\t} else {\n\t\tstruct bpf_common_lru *clru = &lru->common_lru;\n\n\t\tclru->local_list = alloc_percpu(struct bpf_lru_locallist);\n\t\tif (!clru->local_list)\n\t\t\treturn -ENOMEM;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tstruct bpf_lru_locallist *loc_l;\n\n\t\t\tloc_l = per_cpu_ptr(clru->local_list, cpu);\n\t\t\tbpf_lru_locallist_init(loc_l, cpu);\n\t\t}\n\n\t\tbpf_lru_list_init(&clru->lru_list);\n\t\tlru->nr_scans = LOCAL_NR_SCANS;\n\t}\n\n\tlru->percpu = percpu;\n\tlru->del_from_htab = del_from_htab;\n\tlru->del_arg = del_arg;\n\tlru->hash_offset = hash_offset;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"bpf_lru_list.h\"",
            "#include <linux/percpu.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/cpumask.h>"
          ],
          "macros_used": [
            "#define PERCPU_NR_SCANS\t\t\tPERCPU_FREE_TARGET",
            "#define LOCAL_NR_SCANS\t\t\tLOCAL_FREE_TARGET"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_lru_list.h\"\n#include <linux/percpu.h>\n#include <linux/spinlock.h>\n#include <linux/cpumask.h>\n\n#define PERCPU_NR_SCANS\t\t\tPERCPU_FREE_TARGET\n#define LOCAL_NR_SCANS\t\t\tLOCAL_FREE_TARGET\n\nint bpf_lru_init(struct bpf_lru *lru, bool percpu, u32 hash_offset,\n\t\t del_from_htab_func del_from_htab, void *del_arg)\n{\n\tint cpu;\n\n\tif (percpu) {\n\t\tlru->percpu_lru = alloc_percpu(struct bpf_lru_list);\n\t\tif (!lru->percpu_lru)\n\t\t\treturn -ENOMEM;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tstruct bpf_lru_list *l;\n\n\t\t\tl = per_cpu_ptr(lru->percpu_lru, cpu);\n\t\t\tbpf_lru_list_init(l);\n\t\t}\n\t\tlru->nr_scans = PERCPU_NR_SCANS;\n\t} else {\n\t\tstruct bpf_common_lru *clru = &lru->common_lru;\n\n\t\tclru->local_list = alloc_percpu(struct bpf_lru_locallist);\n\t\tif (!clru->local_list)\n\t\t\treturn -ENOMEM;\n\n\t\tfor_each_possible_cpu(cpu) {\n\t\t\tstruct bpf_lru_locallist *loc_l;\n\n\t\t\tloc_l = per_cpu_ptr(clru->local_list, cpu);\n\t\t\tbpf_lru_locallist_init(loc_l, cpu);\n\t\t}\n\n\t\tbpf_lru_list_init(&clru->lru_list);\n\t\tlru->nr_scans = LOCAL_NR_SCANS;\n\t}\n\n\tlru->percpu = percpu;\n\tlru->del_from_htab = del_from_htab;\n\tlru->del_arg = del_arg;\n\tlru->hash_offset = hash_offset;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 332
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_set_ptr",
          "args": [
            "get_htab_elem(htab, i)",
            "htab->map.key_size",
            "pptr"
          ],
          "line": 330
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_set_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "210-214",
          "snippet": "static inline void htab_elem_set_ptr(struct htab_elem *l, u32 key_size,\n\t\t\t\t     void __percpu *pptr)\n{\n\t*(void __percpu **)(l->key + key_size) = pptr;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void htab_elem_set_ptr(struct htab_elem *l, u32 key_size,\n\t\t\t\t     void __percpu *pptr)\n{\n\t*(void __percpu **)(l->key + key_size) = pptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_htab_elem",
          "args": [
            "htab",
            "i"
          ],
          "line": 330
        },
        "resolved": true,
        "details": {
          "function_name": "get_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "226-229",
          "snippet": "static struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_alloc_percpu",
          "args": [
            "&htab->map",
            "size",
            "8",
            "GFP_USER | __GFP_NOWARN"
          ],
          "line": 326
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_alloc_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "452-463",
          "snippet": "void __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.value_size",
            "8"
          ],
          "line": 323
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_is_percpu",
          "args": [
            "htab"
          ],
          "line": 319
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "204-208",
          "snippet": "static bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "(u64)htab->elem_size * num_entries",
            "htab->map.numa_node"
          ],
          "line": 314
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "334-337",
          "snippet": "void *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 312
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_has_extra_elems",
          "args": [
            "htab"
          ],
          "line": 311
        },
        "resolved": true,
        "details": {
          "function_name": "htab_has_extra_elems",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "231-234",
          "snippet": "static bool htab_has_extra_elems(struct bpf_htab *htab)\n{\n\treturn !htab_is_percpu(htab) && !htab_is_lru(htab);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_has_extra_elems(struct bpf_htab *htab)\n{\n\treturn !htab_is_percpu(htab) && !htab_is_lru(htab);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic int prealloc_init(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint err = -ENOMEM, i;\n\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\thtab->elems = bpf_map_area_alloc((u64)htab->elem_size * num_entries,\n\t\t\t\t\t htab->map.numa_node);\n\tif (!htab->elems)\n\t\treturn -ENOMEM;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto skip_percpu_elems;\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tu32 size = round_up(htab->map.value_size, 8);\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = bpf_map_alloc_percpu(&htab->map, size, 8,\n\t\t\t\t\t    GFP_USER | __GFP_NOWARN);\n\t\tif (!pptr)\n\t\t\tgoto free_elems;\n\t\thtab_elem_set_ptr(get_htab_elem(htab, i), htab->map.key_size,\n\t\t\t\t  pptr);\n\t\tcond_resched();\n\t}\n\nskip_percpu_elems:\n\tif (htab_is_lru(htab))\n\t\terr = bpf_lru_init(&htab->lru,\n\t\t\t\t   htab->map.map_flags & BPF_F_NO_COMMON_LRU,\n\t\t\t\t   offsetof(struct htab_elem, hash) -\n\t\t\t\t   offsetof(struct htab_elem, lru_node),\n\t\t\t\t   htab_lru_map_delete_node,\n\t\t\t\t   htab);\n\telse\n\t\terr = pcpu_freelist_init(&htab->freelist);\n\n\tif (err)\n\t\tgoto free_elems;\n\n\tif (htab_is_lru(htab))\n\t\tbpf_lru_populate(&htab->lru, htab->elems,\n\t\t\t\t offsetof(struct htab_elem, lru_node),\n\t\t\t\t htab->elem_size, num_entries);\n\telse\n\t\tpcpu_freelist_populate(&htab->freelist,\n\t\t\t\t       htab->elems + offsetof(struct htab_elem, fnode),\n\t\t\t\t       htab->elem_size, num_entries);\n\n\treturn 0;\n\nfree_elems:\n\thtab_free_elems(htab);\n\treturn err;\n}"
  },
  {
    "function_name": "prealloc_lru_pop",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "287-304",
    "snippet": "static struct htab_elem *prealloc_lru_pop(struct bpf_htab *htab, void *key,\n\t\t\t\t\t  u32 hash)\n{\n\tstruct bpf_lru_node *node = bpf_lru_pop_free(&htab->lru, hash);\n\tstruct htab_elem *l;\n\n\tif (node) {\n\t\tu32 key_size = htab->map.key_size;\n\n\t\tl = container_of(node, struct htab_elem, lru_node);\n\t\tmemcpy(l->key, key, key_size);\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l->key + round_up(key_size, 8));\n\t\treturn l;\n\t}\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "check_and_init_map_value",
          "args": [
            "&htab->map",
            "l->key + round_up(key_size, 8)"
          ],
          "line": 298
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "key_size",
            "8"
          ],
          "line": 299
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "l->key",
            "key",
            "key_size"
          ],
          "line": 297
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "node",
            "structhtab_elem",
            "lru_node"
          ],
          "line": 296
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_lru_pop_free",
          "args": [
            "&htab->lru",
            "hash"
          ],
          "line": 290
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_lru_pop_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_lru_list.c",
          "lines": "494-500",
          "snippet": "struct bpf_lru_node *bpf_lru_pop_free(struct bpf_lru *lru, u32 hash)\n{\n\tif (lru->percpu)\n\t\treturn bpf_percpu_lru_pop_free(lru, hash);\n\telse\n\t\treturn bpf_common_lru_pop_free(lru, hash);\n}",
          "includes": [
            "#include \"bpf_lru_list.h\"",
            "#include <linux/percpu.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/cpumask.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_lru_list.h\"\n#include <linux/percpu.h>\n#include <linux/spinlock.h>\n#include <linux/cpumask.h>\n\nstruct bpf_lru_node *bpf_lru_pop_free(struct bpf_lru *lru, u32 hash)\n{\n\tif (lru->percpu)\n\t\treturn bpf_percpu_lru_pop_free(lru, hash);\n\telse\n\t\treturn bpf_common_lru_pop_free(lru, hash);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_lru_map_delete_node(void *arg, struct bpf_lru_node *node);\n\nstatic struct htab_elem *prealloc_lru_pop(struct bpf_htab *htab, void *key,\n\t\t\t\t\t  u32 hash)\n{\n\tstruct bpf_lru_node *node = bpf_lru_pop_free(&htab->lru, hash);\n\tstruct htab_elem *l;\n\n\tif (node) {\n\t\tu32 key_size = htab->map.key_size;\n\n\t\tl = container_of(node, struct htab_elem, lru_node);\n\t\tmemcpy(l->key, key, key_size);\n\t\tcheck_and_init_map_value(&htab->map,\n\t\t\t\t\t l->key + round_up(key_size, 8));\n\t\treturn l;\n\t}\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "htab_free_elems",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "257-274",
    "snippet": "static void htab_free_elems(struct bpf_htab *htab)\n{\n\tint i;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto free_elems;\n\n\tfor (i = 0; i < htab->map.max_entries; i++) {\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),\n\t\t\t\t\t htab->map.key_size);\n\t\tfree_percpu(pptr);\n\t\tcond_resched();\n\t}\nfree_elems:\n\tbpf_map_area_free(htab->elems);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "htab->elems"
          ],
          "line": 273
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 270
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "pptr"
          ],
          "line": 269
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/arraymap.c",
          "lines": "21-29",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_elem_get_ptr",
          "args": [
            "get_htab_elem(htab, i)",
            "htab->map.key_size"
          ],
          "line": 267
        },
        "resolved": true,
        "details": {
          "function_name": "htab_elem_get_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "216-219",
          "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_htab_elem",
          "args": [
            "htab",
            "i"
          ],
          "line": 267
        },
        "resolved": true,
        "details": {
          "function_name": "get_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "226-229",
          "snippet": "static struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_percpu",
          "args": [
            "htab"
          ],
          "line": 261
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "204-208",
          "snippet": "static bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_elems(struct bpf_htab *htab)\n{\n\tint i;\n\n\tif (!htab_is_percpu(htab))\n\t\tgoto free_elems;\n\n\tfor (i = 0; i < htab->map.max_entries; i++) {\n\t\tvoid __percpu *pptr;\n\n\t\tpptr = htab_elem_get_ptr(get_htab_elem(htab, i),\n\t\t\t\t\t htab->map.key_size);\n\t\tfree_percpu(pptr);\n\t\tcond_resched();\n\t}\nfree_elems:\n\tbpf_map_area_free(htab->elems);\n}"
  },
  {
    "function_name": "htab_free_prealloced_timers",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "236-255",
    "snippet": "static void htab_free_prealloced_timers(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint i;\n\n\tif (likely(!map_value_has_timer(&htab->map)))\n\t\treturn;\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tstruct htab_elem *elem;\n\n\t\telem = get_htab_elem(htab, i);\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n\t\tcond_resched();\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 253
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_timer_cancel_and_free",
          "args": [
            "elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off"
          ],
          "line": 250
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_timer_cancel_and_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "1302-1344",
          "snippet": "void bpf_timer_cancel_and_free(void *val)\n{\n\tstruct bpf_timer_kern *timer = val;\n\tstruct bpf_hrtimer *t;\n\n\t/* Performance optimization: read timer->timer without lock first. */\n\tif (!READ_ONCE(timer->timer))\n\t\treturn;\n\n\t__bpf_spin_lock_irqsave(&timer->lock);\n\t/* re-read it under lock */\n\tt = timer->timer;\n\tif (!t)\n\t\tgoto out;\n\tdrop_prog_refcnt(t);\n\t/* The subsequent bpf_timer_start/cancel() helpers won't be able to use\n\t * this timer, since it won't be initialized.\n\t */\n\ttimer->timer = NULL;\nout:\n\t__bpf_spin_unlock_irqrestore(&timer->lock);\n\tif (!t)\n\t\treturn;\n\t/* Cancel the timer and wait for callback to complete if it was running.\n\t * If hrtimer_cancel() can be safely called it's safe to call kfree(t)\n\t * right after for both preallocated and non-preallocated maps.\n\t * The timer->timer = NULL was already done and no code path can\n\t * see address 't' anymore.\n\t *\n\t * Check that bpf_map_delete/update_elem() wasn't called from timer\n\t * callback_fn. In such case don't call hrtimer_cancel() (since it will\n\t * deadlock) and don't call hrtimer_try_to_cancel() (since it will just\n\t * return -1). Though callback_fn is still running on this cpu it's\n\t * safe to do kfree(t) because bpf_timer_cb() read everything it needed\n\t * from 't'. The bpf subprog callback_fn won't be able to access 't',\n\t * since timer->timer = NULL was already done. The timer will be\n\t * effectively cancelled because bpf_timer_cb() will return\n\t * HRTIMER_NORESTART.\n\t */\n\tif (this_cpu_read(hrtimer_running) != t)\n\t\thrtimer_cancel(&t->timer);\n\tkfree(t);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct bpf_hrtimer *, hrtimer_running);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(struct bpf_hrtimer *, hrtimer_running);\n\nvoid bpf_timer_cancel_and_free(void *val)\n{\n\tstruct bpf_timer_kern *timer = val;\n\tstruct bpf_hrtimer *t;\n\n\t/* Performance optimization: read timer->timer without lock first. */\n\tif (!READ_ONCE(timer->timer))\n\t\treturn;\n\n\t__bpf_spin_lock_irqsave(&timer->lock);\n\t/* re-read it under lock */\n\tt = timer->timer;\n\tif (!t)\n\t\tgoto out;\n\tdrop_prog_refcnt(t);\n\t/* The subsequent bpf_timer_start/cancel() helpers won't be able to use\n\t * this timer, since it won't be initialized.\n\t */\n\ttimer->timer = NULL;\nout:\n\t__bpf_spin_unlock_irqrestore(&timer->lock);\n\tif (!t)\n\t\treturn;\n\t/* Cancel the timer and wait for callback to complete if it was running.\n\t * If hrtimer_cancel() can be safely called it's safe to call kfree(t)\n\t * right after for both preallocated and non-preallocated maps.\n\t * The timer->timer = NULL was already done and no code path can\n\t * see address 't' anymore.\n\t *\n\t * Check that bpf_map_delete/update_elem() wasn't called from timer\n\t * callback_fn. In such case don't call hrtimer_cancel() (since it will\n\t * deadlock) and don't call hrtimer_try_to_cancel() (since it will just\n\t * return -1). Though callback_fn is still running on this cpu it's\n\t * safe to do kfree(t) because bpf_timer_cb() read everything it needed\n\t * from 't'. The bpf subprog callback_fn won't be able to access 't',\n\t * since timer->timer = NULL was already done. The timer will be\n\t * effectively cancelled because bpf_timer_cb() will return\n\t * HRTIMER_NORESTART.\n\t */\n\tif (this_cpu_read(hrtimer_running) != t)\n\t\thrtimer_cancel(&t->timer);\n\tkfree(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "round_up",
          "args": [
            "htab->map.key_size",
            "8"
          ],
          "line": 251
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_htab_elem",
          "args": [
            "htab",
            "i"
          ],
          "line": 249
        },
        "resolved": true,
        "details": {
          "function_name": "get_htab_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "226-229",
          "snippet": "static struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "num_possible_cpus",
          "args": [],
          "line": 244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_has_extra_elems",
          "args": [
            "htab"
          ],
          "line": 243
        },
        "resolved": true,
        "details": {
          "function_name": "htab_has_extra_elems",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "231-234",
          "snippet": "static bool htab_has_extra_elems(struct bpf_htab *htab)\n{\n\treturn !htab_is_percpu(htab) && !htab_is_lru(htab);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_has_extra_elems(struct bpf_htab *htab)\n{\n\treturn !htab_is_percpu(htab) && !htab_is_lru(htab);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!map_value_has_timer(&htab->map)"
          ],
          "line": 241
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_value_has_timer",
          "args": [
            "&htab->map"
          ],
          "line": 241
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_free_prealloced_timers(struct bpf_htab *htab)\n{\n\tu32 num_entries = htab->map.max_entries;\n\tint i;\n\n\tif (likely(!map_value_has_timer(&htab->map)))\n\t\treturn;\n\tif (htab_has_extra_elems(htab))\n\t\tnum_entries += num_possible_cpus();\n\n\tfor (i = 0; i < num_entries; i++) {\n\t\tstruct htab_elem *elem;\n\n\t\telem = get_htab_elem(htab, i);\n\t\tbpf_timer_cancel_and_free(elem->key +\n\t\t\t\t\t  round_up(htab->map.key_size, 8) +\n\t\t\t\t\t  htab->map.timer_off);\n\t\tcond_resched();\n\t}\n}"
  },
  {
    "function_name": "htab_has_extra_elems",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "231-234",
    "snippet": "static bool htab_has_extra_elems(struct bpf_htab *htab)\n{\n\treturn !htab_is_percpu(htab) && !htab_is_lru(htab);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_is_lru",
          "args": [
            "htab"
          ],
          "line": 233
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_lru",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "198-202",
          "snippet": "static bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_is_percpu",
          "args": [
            "htab"
          ],
          "line": 233
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "204-208",
          "snippet": "static bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_has_extra_elems(struct bpf_htab *htab)\n{\n\treturn !htab_is_percpu(htab) && !htab_is_lru(htab);\n}"
  },
  {
    "function_name": "get_htab_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "226-229",
    "snippet": "static struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic struct htab_elem *get_htab_elem(struct bpf_htab *htab, int i)\n{\n\treturn (struct htab_elem *) (htab->elems + i * (u64)htab->elem_size);\n}"
  },
  {
    "function_name": "fd_htab_map_get_ptr",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "221-224",
    "snippet": "static void *fd_htab_map_get_ptr(const struct bpf_map *map, struct htab_elem *l)\n{\n\treturn *(void **)(l->key + roundup(map->key_size, 8));\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "roundup",
          "args": [
            "map->key_size",
            "8"
          ],
          "line": 223
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void *fd_htab_map_get_ptr(const struct bpf_map *map, struct htab_elem *l)\n{\n\treturn *(void **)(l->key + roundup(map->key_size, 8));\n}"
  },
  {
    "function_name": "htab_elem_get_ptr",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "216-219",
    "snippet": "static inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void __percpu *htab_elem_get_ptr(struct htab_elem *l, u32 key_size)\n{\n\treturn *(void __percpu **)(l->key + key_size);\n}"
  },
  {
    "function_name": "htab_elem_set_ptr",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "210-214",
    "snippet": "static inline void htab_elem_set_ptr(struct htab_elem *l, u32 key_size,\n\t\t\t\t     void __percpu *pptr)\n{\n\t*(void __percpu **)(l->key + key_size) = pptr;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline void htab_elem_set_ptr(struct htab_elem *l, u32 key_size,\n\t\t\t\t     void __percpu *pptr)\n{\n\t*(void __percpu **)(l->key + key_size) = pptr;\n}"
  },
  {
    "function_name": "htab_is_percpu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "204-208",
    "snippet": "static bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_percpu(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_PERCPU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
  },
  {
    "function_name": "htab_is_lru",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "198-202",
    "snippet": "static bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic bool htab_is_lru(const struct bpf_htab *htab)\n{\n\treturn htab->map.map_type == BPF_MAP_TYPE_LRU_HASH ||\n\t\thtab->map.map_type == BPF_MAP_TYPE_LRU_PERCPU_HASH;\n}"
  },
  {
    "function_name": "htab_unlock_bucket",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "183-194",
    "snippet": "static inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_enable",
          "args": [],
          "line": 193
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2178-2206",
          "snippet": "void migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__this_cpu_dec",
          "args": [
            "*(htab->map_locked[hash])"
          ],
          "line": 192
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock_irqrestore",
          "args": [
            "&b->lock",
            "flags"
          ],
          "line": 191
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_use_raw_lock",
          "args": [
            "htab"
          ],
          "line": 188
        },
        "resolved": true,
        "details": {
          "function_name": "htab_use_raw_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "135-138",
          "snippet": "static inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline void htab_unlock_bucket(const struct bpf_htab *htab,\n\t\t\t\t      struct bucket *b, u32 hash,\n\t\t\t\t      unsigned long flags)\n{\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_unlock_irqrestore(&b->raw_lock, flags);\n\telse\n\t\tspin_unlock_irqrestore(&b->lock, flags);\n\t__this_cpu_dec(*(htab->map_locked[hash]));\n\tmigrate_enable();\n}"
  },
  {
    "function_name": "htab_lock_bucket",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "159-181",
    "snippet": "static inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "spin_lock_irqsave",
          "args": [
            "&b->lock",
            "flags"
          ],
          "line": 177
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "htab_use_raw_lock",
          "args": [
            "htab"
          ],
          "line": 174
        },
        "resolved": true,
        "details": {
          "function_name": "htab_use_raw_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "135-138",
          "snippet": "static inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}"
        }
      },
      {
        "call_info": {
          "callee": "migrate_enable",
          "args": [],
          "line": 170
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2178-2206",
          "snippet": "void migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__this_cpu_dec",
          "args": [
            "*(htab->map_locked[hash])"
          ],
          "line": 169
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "__this_cpu_inc_return(*(htab->map_locked[hash])) != 1"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_inc_return",
          "args": [
            "*(htab->map_locked[hash])"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 167
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\n#define HASHTAB_MAP_LOCK_MASK (HASHTAB_MAP_LOCK_COUNT - 1)\n\nstatic inline int htab_lock_bucket(const struct bpf_htab *htab,\n\t\t\t\t   struct bucket *b, u32 hash,\n\t\t\t\t   unsigned long *pflags)\n{\n\tunsigned long flags;\n\n\thash = hash & HASHTAB_MAP_LOCK_MASK;\n\n\tmigrate_disable();\n\tif (unlikely(__this_cpu_inc_return(*(htab->map_locked[hash])) != 1)) {\n\t\t__this_cpu_dec(*(htab->map_locked[hash]));\n\t\tmigrate_enable();\n\t\treturn -EBUSY;\n\t}\n\n\tif (htab_use_raw_lock(htab))\n\t\traw_spin_lock_irqsave(&b->raw_lock, flags);\n\telse\n\t\tspin_lock_irqsave(&b->lock, flags);\n\t*pflags = flags;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "htab_init_buckets",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "140-157",
    "snippet": "static void htab_init_buckets(struct bpf_htab *htab)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tINIT_HLIST_NULLS_HEAD(&htab->buckets[i].head, i);\n\t\tif (htab_use_raw_lock(htab)) {\n\t\t\traw_spin_lock_init(&htab->buckets[i].raw_lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].raw_lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t} else {\n\t\t\tspin_lock_init(&htab->buckets[i].lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t}\n\t\tcond_resched();\n\t}\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 155
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_set_class",
          "args": [
            "&htab->buckets[i].lock",
            "&htab->lockdep_key"
          ],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock_init",
          "args": [
            "&htab->buckets[i].lock"
          ],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_set_class",
          "args": [
            "&htab->buckets[i].raw_lock",
            "&htab->lockdep_key"
          ],
          "line": 148
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&htab->buckets[i].raw_lock"
          ],
          "line": 147
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "htab_use_raw_lock",
          "args": [
            "htab"
          ],
          "line": 146
        },
        "resolved": true,
        "details": {
          "function_name": "htab_use_raw_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "135-138",
          "snippet": "static inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}"
        }
      },
      {
        "call_info": {
          "callee": "INIT_HLIST_NULLS_HEAD",
          "args": [
            "&htab->buckets[i].head",
            "i"
          ],
          "line": 145
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void htab_init_buckets(struct bpf_htab *htab)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < htab->n_buckets; i++) {\n\t\tINIT_HLIST_NULLS_HEAD(&htab->buckets[i].head, i);\n\t\tif (htab_use_raw_lock(htab)) {\n\t\t\traw_spin_lock_init(&htab->buckets[i].raw_lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].raw_lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t} else {\n\t\t\tspin_lock_init(&htab->buckets[i].lock);\n\t\t\tlockdep_set_class(&htab->buckets[i].lock,\n\t\t\t\t\t  &htab->lockdep_key);\n\t\t}\n\t\tcond_resched();\n\t}\n}"
  },
  {
    "function_name": "htab_use_raw_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "135-138",
    "snippet": "static inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "htab_is_prealloc",
          "args": [
            "htab"
          ],
          "line": 137
        },
        "resolved": true,
        "details": {
          "function_name": "htab_is_prealloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
          "lines": "130-133",
          "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include \"bpf_lru_list.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/random.h>",
            "#include <linux/rculist_nulls.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_PREEMPT_RT"
          ],
          "line": 137
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_use_raw_lock(const struct bpf_htab *htab)\n{\n\treturn (!IS_ENABLED(CONFIG_PREEMPT_RT) || htab_is_prealloc(htab));\n}"
  },
  {
    "function_name": "htab_is_prealloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/hashtab.c",
    "lines": "130-133",
    "snippet": "static inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}",
    "includes": [
      "#include \"map_in_map.h\"",
      "#include \"bpf_lru_list.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/rcupdate_trace.h>",
      "#include <uapi/linux/btf.h>",
      "#include <linux/random.h>",
      "#include <linux/rculist_nulls.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"map_in_map.h\"\n#include \"bpf_lru_list.h\"\n#include \"percpu_freelist.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/random.h>\n#include <linux/rculist_nulls.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic inline bool htab_is_prealloc(const struct bpf_htab *htab)\n{\n\treturn !(htab->map.map_flags & BPF_F_NO_PREALLOC);\n}"
  }
]