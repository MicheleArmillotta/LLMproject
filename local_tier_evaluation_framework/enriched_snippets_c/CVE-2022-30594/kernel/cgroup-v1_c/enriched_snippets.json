[
  {
    "function_name": "cgroup_no_v1",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "1248-1277",
    "snippet": "static int __init cgroup_no_v1(char *str)\n{\n\tstruct cgroup_subsys *ss;\n\tchar *token;\n\tint i;\n\n\twhile ((token = strsep(&str, \",\")) != NULL) {\n\t\tif (!*token)\n\t\t\tcontinue;\n\n\t\tif (!strcmp(token, \"all\")) {\n\t\t\tcgroup_no_v1_mask = U16_MAX;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strcmp(token, \"named\")) {\n\t\t\tcgroup_no_v1_named = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor_each_subsys(ss, i) {\n\t\t\tif (strcmp(token, ss->name) &&\n\t\t\t    strcmp(token, ss->legacy_name))\n\t\t\t\tcontinue;\n\n\t\t\tcgroup_no_v1_mask |= 1 << i;\n\t\t}\n\t}\n\treturn 1;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static u16 cgroup_no_v1_mask;",
      "static bool cgroup_no_v1_named;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "strcmp",
          "args": [
            "token",
            "ss->legacy_name"
          ],
          "line": 1270
        },
        "resolved": true,
        "details": {
          "function_name": "sym_strcmp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/report.c",
          "lines": "356-365",
          "snippet": "static int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}",
          "includes": [
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include <linux/stacktrace.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/printk.h>",
            "#include <linux/preempt.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/delay.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"encoding.h\"\n#include \"kcsan.h\"\n#include <linux/stacktrace.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/printk.h>\n#include <linux/preempt.h>\n#include <linux/lockdep.h>\n#include <linux/kernel.h>\n#include <linux/kallsyms.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/debug_locks.h>\n\nstatic int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_subsys",
          "args": [
            "ss",
            "i"
          ],
          "line": 1268
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strsep",
          "args": [
            "&str",
            "\",\""
          ],
          "line": 1254
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic u16 cgroup_no_v1_mask;\nstatic bool cgroup_no_v1_named;\n\nstatic int __init cgroup_no_v1(char *str)\n{\n\tstruct cgroup_subsys *ss;\n\tchar *token;\n\tint i;\n\n\twhile ((token = strsep(&str, \",\")) != NULL) {\n\t\tif (!*token)\n\t\t\tcontinue;\n\n\t\tif (!strcmp(token, \"all\")) {\n\t\t\tcgroup_no_v1_mask = U16_MAX;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!strcmp(token, \"named\")) {\n\t\t\tcgroup_no_v1_named = true;\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor_each_subsys(ss, i) {\n\t\t\tif (strcmp(token, ss->name) &&\n\t\t\t    strcmp(token, ss->legacy_name))\n\t\t\t\tcontinue;\n\n\t\t\tcgroup_no_v1_mask |= 1 << i;\n\t\t}\n\t}\n\treturn 1;\n}"
  },
  {
    "function_name": "cgroup1_wq_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "1235-1245",
    "snippet": "static int __init cgroup1_wq_init(void)\n{\n\t/*\n\t * Used to destroy pidlists and separate to serve as flush domain.\n\t * Cap @max_active to 1 too.\n\t */\n\tcgroup_pidlist_destroy_wq = alloc_workqueue(\"cgroup_pidlist_destroy\",\n\t\t\t\t\t\t    0, 1);\n\tBUG_ON(!cgroup_pidlist_destroy_wq);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct workqueue_struct *cgroup_pidlist_destroy_wq;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!cgroup_pidlist_destroy_wq"
          ],
          "line": 1243
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_workqueue",
          "args": [
            "\"cgroup_pidlist_destroy\"",
            "0",
            "1"
          ],
          "line": 1241
        },
        "resolved": true,
        "details": {
          "function_name": "alloc_workqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "4298-4392",
          "snippet": "struct workqueue_struct *alloc_workqueue(const char *fmt,\n\t\t\t\t\t unsigned int flags,\n\t\t\t\t\t int max_active, ...)\n{\n\tsize_t tbl_size = 0;\n\tva_list args;\n\tstruct workqueue_struct *wq;\n\tstruct pool_workqueue *pwq;\n\n\t/*\n\t * Unbound && max_active == 1 used to imply ordered, which is no\n\t * longer the case on NUMA machines due to per-node pools.  While\n\t * alloc_ordered_workqueue() is the right way to create an ordered\n\t * workqueue, keep the previous behavior to avoid subtle breakages\n\t * on NUMA.\n\t */\n\tif ((flags & WQ_UNBOUND) && max_active == 1)\n\t\tflags |= __WQ_ORDERED;\n\n\t/* see the comment above the definition of WQ_POWER_EFFICIENT */\n\tif ((flags & WQ_POWER_EFFICIENT) && wq_power_efficient)\n\t\tflags |= WQ_UNBOUND;\n\n\t/* allocate wq and format name */\n\tif (flags & WQ_UNBOUND)\n\t\ttbl_size = nr_node_ids * sizeof(wq->numa_pwq_tbl[0]);\n\n\twq = kzalloc(sizeof(*wq) + tbl_size, GFP_KERNEL);\n\tif (!wq)\n\t\treturn NULL;\n\n\tif (flags & WQ_UNBOUND) {\n\t\twq->unbound_attrs = alloc_workqueue_attrs();\n\t\tif (!wq->unbound_attrs)\n\t\t\tgoto err_free_wq;\n\t}\n\n\tva_start(args, max_active);\n\tvsnprintf(wq->name, sizeof(wq->name), fmt, args);\n\tva_end(args);\n\n\tmax_active = max_active ?: WQ_DFL_ACTIVE;\n\tmax_active = wq_clamp_max_active(max_active, flags, wq->name);\n\n\t/* init wq */\n\twq->flags = flags;\n\twq->saved_max_active = max_active;\n\tmutex_init(&wq->mutex);\n\tatomic_set(&wq->nr_pwqs_to_flush, 0);\n\tINIT_LIST_HEAD(&wq->pwqs);\n\tINIT_LIST_HEAD(&wq->flusher_queue);\n\tINIT_LIST_HEAD(&wq->flusher_overflow);\n\tINIT_LIST_HEAD(&wq->maydays);\n\n\twq_init_lockdep(wq);\n\tINIT_LIST_HEAD(&wq->list);\n\n\tif (alloc_and_link_pwqs(wq) < 0)\n\t\tgoto err_unreg_lockdep;\n\n\tif (wq_online && init_rescuer(wq) < 0)\n\t\tgoto err_destroy;\n\n\tif ((wq->flags & WQ_SYSFS) && workqueue_sysfs_register(wq))\n\t\tgoto err_destroy;\n\n\t/*\n\t * wq_pool_mutex protects global freeze state and workqueues list.\n\t * Grab it, adjust max_active and add the new @wq to workqueues\n\t * list.\n\t */\n\tmutex_lock(&wq_pool_mutex);\n\n\tmutex_lock(&wq->mutex);\n\tfor_each_pwq(pwq, wq)\n\t\tpwq_adjust_max_active(pwq);\n\tmutex_unlock(&wq->mutex);\n\n\tlist_add_tail_rcu(&wq->list, &workqueues);\n\n\tmutex_unlock(&wq_pool_mutex);\n\n\treturn wq;\n\nerr_unreg_lockdep:\n\twq_unregister_lockdep(wq);\n\twq_free_lockdep(wq);\nerr_free_wq:\n\tfree_workqueue_attrs(wq->unbound_attrs);\n\tkfree(wq);\n\treturn NULL;\nerr_destroy:\n\tdestroy_workqueue(wq);\n\treturn NULL;\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static bool wq_power_efficient = IS_ENABLED(CONFIG_WQ_POWER_EFFICIENT_DEFAULT);",
            "static bool wq_online;",
            "static DEFINE_MUTEX(wq_pool_mutex);",
            "static LIST_HEAD(workqueues);",
            "static void workqueue_sysfs_unregister(struct workqueue_struct *wq);",
            "static void show_pwq(struct pool_workqueue *pwq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic bool wq_power_efficient = IS_ENABLED(CONFIG_WQ_POWER_EFFICIENT_DEFAULT);\nstatic bool wq_online;\nstatic DEFINE_MUTEX(wq_pool_mutex);\nstatic LIST_HEAD(workqueues);\nstatic void workqueue_sysfs_unregister(struct workqueue_struct *wq);\nstatic void show_pwq(struct pool_workqueue *pwq);\n\nstruct workqueue_struct *alloc_workqueue(const char *fmt,\n\t\t\t\t\t unsigned int flags,\n\t\t\t\t\t int max_active, ...)\n{\n\tsize_t tbl_size = 0;\n\tva_list args;\n\tstruct workqueue_struct *wq;\n\tstruct pool_workqueue *pwq;\n\n\t/*\n\t * Unbound && max_active == 1 used to imply ordered, which is no\n\t * longer the case on NUMA machines due to per-node pools.  While\n\t * alloc_ordered_workqueue() is the right way to create an ordered\n\t * workqueue, keep the previous behavior to avoid subtle breakages\n\t * on NUMA.\n\t */\n\tif ((flags & WQ_UNBOUND) && max_active == 1)\n\t\tflags |= __WQ_ORDERED;\n\n\t/* see the comment above the definition of WQ_POWER_EFFICIENT */\n\tif ((flags & WQ_POWER_EFFICIENT) && wq_power_efficient)\n\t\tflags |= WQ_UNBOUND;\n\n\t/* allocate wq and format name */\n\tif (flags & WQ_UNBOUND)\n\t\ttbl_size = nr_node_ids * sizeof(wq->numa_pwq_tbl[0]);\n\n\twq = kzalloc(sizeof(*wq) + tbl_size, GFP_KERNEL);\n\tif (!wq)\n\t\treturn NULL;\n\n\tif (flags & WQ_UNBOUND) {\n\t\twq->unbound_attrs = alloc_workqueue_attrs();\n\t\tif (!wq->unbound_attrs)\n\t\t\tgoto err_free_wq;\n\t}\n\n\tva_start(args, max_active);\n\tvsnprintf(wq->name, sizeof(wq->name), fmt, args);\n\tva_end(args);\n\n\tmax_active = max_active ?: WQ_DFL_ACTIVE;\n\tmax_active = wq_clamp_max_active(max_active, flags, wq->name);\n\n\t/* init wq */\n\twq->flags = flags;\n\twq->saved_max_active = max_active;\n\tmutex_init(&wq->mutex);\n\tatomic_set(&wq->nr_pwqs_to_flush, 0);\n\tINIT_LIST_HEAD(&wq->pwqs);\n\tINIT_LIST_HEAD(&wq->flusher_queue);\n\tINIT_LIST_HEAD(&wq->flusher_overflow);\n\tINIT_LIST_HEAD(&wq->maydays);\n\n\twq_init_lockdep(wq);\n\tINIT_LIST_HEAD(&wq->list);\n\n\tif (alloc_and_link_pwqs(wq) < 0)\n\t\tgoto err_unreg_lockdep;\n\n\tif (wq_online && init_rescuer(wq) < 0)\n\t\tgoto err_destroy;\n\n\tif ((wq->flags & WQ_SYSFS) && workqueue_sysfs_register(wq))\n\t\tgoto err_destroy;\n\n\t/*\n\t * wq_pool_mutex protects global freeze state and workqueues list.\n\t * Grab it, adjust max_active and add the new @wq to workqueues\n\t * list.\n\t */\n\tmutex_lock(&wq_pool_mutex);\n\n\tmutex_lock(&wq->mutex);\n\tfor_each_pwq(pwq, wq)\n\t\tpwq_adjust_max_active(pwq);\n\tmutex_unlock(&wq->mutex);\n\n\tlist_add_tail_rcu(&wq->list, &workqueues);\n\n\tmutex_unlock(&wq_pool_mutex);\n\n\treturn wq;\n\nerr_unreg_lockdep:\n\twq_unregister_lockdep(wq);\n\twq_free_lockdep(wq);\nerr_free_wq:\n\tfree_workqueue_attrs(wq->unbound_attrs);\n\tkfree(wq);\n\treturn NULL;\nerr_destroy:\n\tdestroy_workqueue(wq);\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic struct workqueue_struct *cgroup_pidlist_destroy_wq;\n\nstatic int __init cgroup1_wq_init(void)\n{\n\t/*\n\t * Used to destroy pidlists and separate to serve as flush domain.\n\t * Cap @max_active to 1 too.\n\t */\n\tcgroup_pidlist_destroy_wq = alloc_workqueue(\"cgroup_pidlist_destroy\",\n\t\t\t\t\t\t    0, 1);\n\tBUG_ON(!cgroup_pidlist_destroy_wq);\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup1_get_tree",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "1203-1233",
    "snippet": "int cgroup1_get_tree(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tint ret;\n\n\t/* Check if the caller has permission to mount. */\n\tif (!ns_capable(ctx->ns->user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcgroup_lock_and_drain_offline(&cgrp_dfl_root.cgrp);\n\n\tret = cgroup1_root_to_use(fc);\n\tif (!ret && !percpu_ref_tryget_live(&ctx->root->cgrp.self.refcnt))\n\t\tret = 1;\t/* restart */\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tif (!ret)\n\t\tret = cgroup_do_get_tree(fc);\n\n\tif (!ret && percpu_ref_is_dying(&ctx->root->cgrp.self.refcnt)) {\n\t\tfc_drop_locked(fc);\n\t\tret = 1;\n\t}\n\n\tif (unlikely(ret > 0)) {\n\t\tmsleep(10);\n\t\treturn restart_syscall();\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "restart_syscall",
          "args": [],
          "line": 1230
        },
        "resolved": true,
        "details": {
          "function_name": "restart_syscall",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/signal.c",
          "lines": "3003-3007",
          "snippet": "SYSCALL_DEFINE0(restart_syscall)\n{\n\tstruct restart_block *restart = &current->restart_block;\n\treturn restart->fn(restart);\n}",
          "includes": [
            "#include <linux/kdb.h>",
            "#include <asm/syscall.h>\t/* for syscall_get_* */",
            "#include <asm/cacheflush.h>",
            "#include <asm/siginfo.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/param.h>",
            "#include <trace/events/signal.h>",
            "#include <linux/audit.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/compiler.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/compat.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/capability.h>",
            "#include <linux/task_work.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/signal.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/coredump.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/tty.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kdb.h>\n#include <asm/syscall.h>\t/* for syscall_get_* */\n#include <asm/cacheflush.h>\n#include <asm/siginfo.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <asm/param.h>\n#include <trace/events/signal.h>\n#include <linux/audit.h>\n#include <linux/cgroup.h>\n#include <linux/posix-timers.h>\n#include <linux/compiler.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/uprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/pid_namespace.h>\n#include <linux/freezer.h>\n#include <linux/capability.h>\n#include <linux/task_work.h>\n#include <linux/ratelimit.h>\n#include <linux/signalfd.h>\n#include <linux/signal.h>\n#include <linux/ptrace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/coredump.h>\n#include <linux/binfmts.h>\n#include <linux/tty.h>\n#include <linux/proc_fs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/user.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\nSYSCALL_DEFINE0(restart_syscall)\n{\n\tstruct restart_block *restart = &current->restart_block;\n\treturn restart->fn(restart);\n}"
        }
      },
      {
        "call_info": {
          "callee": "msleep",
          "args": [
            "10"
          ],
          "line": 1229
        },
        "resolved": true,
        "details": {
          "function_name": "msleep_interruptible",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/timer.c",
          "lines": "2045-2052",
          "snippet": "unsigned long msleep_interruptible(unsigned int msecs)\n{\n\tunsigned long timeout = msecs_to_jiffies(msecs) + 1;\n\n\twhile (timeout && !signal_pending(current))\n\t\ttimeout = schedule_timeout_interruptible(timeout);\n\treturn jiffies_to_msecs(timeout);\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/io.h>",
            "#include <asm/timex.h>",
            "#include <asm/div64.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/random.h>",
            "#include <linux/compat.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/tick.h>",
            "#include <linux/delay.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cpu.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/time.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/notifier.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/io.h>\n#include <asm/timex.h>\n#include <asm/div64.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/random.h>\n#include <linux/compat.h>\n#include <linux/slab.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/irq_work.h>\n#include <linux/kallsyms.h>\n#include <linux/tick.h>\n#include <linux/delay.h>\n#include <linux/syscalls.h>\n#include <linux/cpu.h>\n#include <linux/posix-timers.h>\n#include <linux/jiffies.h>\n#include <linux/time.h>\n#include <linux/thread_info.h>\n#include <linux/notifier.h>\n#include <linux/pid_namespace.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/kernel_stat.h>\n\nunsigned long msleep_interruptible(unsigned int msecs)\n{\n\tunsigned long timeout = msecs_to_jiffies(msecs) + 1;\n\n\twhile (timeout && !signal_pending(current))\n\t\ttimeout = schedule_timeout_interruptible(timeout);\n\treturn jiffies_to_msecs(timeout);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret > 0"
          ],
          "line": 1228
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fc_drop_locked",
          "args": [
            "fc"
          ],
          "line": 1224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "percpu_ref_is_dying",
          "args": [
            "&ctx->root->cgrp.self.refcnt"
          ],
          "line": 1223
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_do_get_tree",
          "args": [
            "fc"
          ],
          "line": 1221
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_do_get_tree",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2089-2132",
          "snippet": "int cgroup_do_get_tree(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tint ret;\n\n\tctx->kfc.root = ctx->root->kf_root;\n\tif (fc->fs_type == &cgroup2_fs_type)\n\t\tctx->kfc.magic = CGROUP2_SUPER_MAGIC;\n\telse\n\t\tctx->kfc.magic = CGROUP_SUPER_MAGIC;\n\tret = kernfs_get_tree(fc);\n\n\t/*\n\t * In non-init cgroup namespace, instead of root cgroup's dentry,\n\t * we return the dentry corresponding to the cgroupns->root_cgrp.\n\t */\n\tif (!ret && ctx->ns != &init_cgroup_ns) {\n\t\tstruct dentry *nsdentry;\n\t\tstruct super_block *sb = fc->root->d_sb;\n\t\tstruct cgroup *cgrp;\n\n\t\tmutex_lock(&cgroup_mutex);\n\t\tspin_lock_irq(&css_set_lock);\n\n\t\tcgrp = cset_cgroup_from_root(ctx->ns->root_cset, ctx->root);\n\n\t\tspin_unlock_irq(&css_set_lock);\n\t\tmutex_unlock(&cgroup_mutex);\n\n\t\tnsdentry = kernfs_node_dentry(cgrp->kn, sb);\n\t\tdput(fc->root);\n\t\tif (IS_ERR(nsdentry)) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\tret = PTR_ERR(nsdentry);\n\t\t\tnsdentry = NULL;\n\t\t}\n\t\tfc->root = nsdentry;\n\t}\n\n\tif (!ctx->kfc.new_sb_created)\n\t\tcgroup_put(&ctx->root->cgrp);\n\n\treturn ret;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct cgroup_namespace init_cgroup_ns = {\n\t.ns.count\t= REFCOUNT_INIT(2),\n\t.user_ns\t= &init_user_ns,\n\t.ns.ops\t\t= &cgroupns_operations,\n\t.ns.inum\t= PROC_CGROUP_INIT_INO,\n\t.root_cset\t= &init_css_set,\n};",
            "static struct file_system_type cgroup2_fs_type;",
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static void cgroup_finalize_control(struct cgroup *cgrp, int ret);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);",
            "static struct file_system_type cgroup2_fs_type = {\n\t.name\t\t\t= \"cgroup2\",\n\t.init_fs_context\t= cgroup_init_fs_context,\n\t.parameters\t\t= cgroup2_fs_parameters,\n\t.kill_sb\t\t= cgroup_kill_sb,\n\t.fs_flags\t\t= FS_USERNS_MOUNT,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct cgroup_namespace init_cgroup_ns = {\n\t.ns.count\t= REFCOUNT_INIT(2),\n\t.user_ns\t= &init_user_ns,\n\t.ns.ops\t\t= &cgroupns_operations,\n\t.ns.inum\t= PROC_CGROUP_INIT_INO,\n\t.root_cset\t= &init_css_set,\n};\nstatic struct file_system_type cgroup2_fs_type;\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\nstatic struct file_system_type cgroup2_fs_type = {\n\t.name\t\t\t= \"cgroup2\",\n\t.init_fs_context\t= cgroup_init_fs_context,\n\t.parameters\t\t= cgroup2_fs_parameters,\n\t.kill_sb\t\t= cgroup_kill_sb,\n\t.fs_flags\t\t= FS_USERNS_MOUNT,\n};\n\nint cgroup_do_get_tree(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tint ret;\n\n\tctx->kfc.root = ctx->root->kf_root;\n\tif (fc->fs_type == &cgroup2_fs_type)\n\t\tctx->kfc.magic = CGROUP2_SUPER_MAGIC;\n\telse\n\t\tctx->kfc.magic = CGROUP_SUPER_MAGIC;\n\tret = kernfs_get_tree(fc);\n\n\t/*\n\t * In non-init cgroup namespace, instead of root cgroup's dentry,\n\t * we return the dentry corresponding to the cgroupns->root_cgrp.\n\t */\n\tif (!ret && ctx->ns != &init_cgroup_ns) {\n\t\tstruct dentry *nsdentry;\n\t\tstruct super_block *sb = fc->root->d_sb;\n\t\tstruct cgroup *cgrp;\n\n\t\tmutex_lock(&cgroup_mutex);\n\t\tspin_lock_irq(&css_set_lock);\n\n\t\tcgrp = cset_cgroup_from_root(ctx->ns->root_cset, ctx->root);\n\n\t\tspin_unlock_irq(&css_set_lock);\n\t\tmutex_unlock(&cgroup_mutex);\n\n\t\tnsdentry = kernfs_node_dentry(cgrp->kn, sb);\n\t\tdput(fc->root);\n\t\tif (IS_ERR(nsdentry)) {\n\t\t\tdeactivate_locked_super(sb);\n\t\t\tret = PTR_ERR(nsdentry);\n\t\t\tnsdentry = NULL;\n\t\t}\n\t\tfc->root = nsdentry;\n\t}\n\n\tif (!ctx->kfc.new_sb_created)\n\t\tcgroup_put(&ctx->root->cgrp);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 1218
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "percpu_ref_tryget_live",
          "args": [
            "&ctx->root->cgrp.self.refcnt"
          ],
          "line": 1215
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup1_root_to_use",
          "args": [
            "fc"
          ],
          "line": 1214
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup1_root_to_use",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "1114-1201",
          "snippet": "static int cgroup1_root_to_use(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct cgroup_root *root;\n\tstruct cgroup_subsys *ss;\n\tint i, ret;\n\n\t/* First find the desired set of subsystems */\n\tret = check_cgroupfs_options(fc);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * Destruction of cgroup root is asynchronous, so subsystems may\n\t * still be dying after the previous unmount.  Let's drain the\n\t * dying subsystems.  We just need to ensure that the ones\n\t * unmounted previously finish dying and don't care about new ones\n\t * starting.  Testing ref liveliness is good enough.\n\t */\n\tfor_each_subsys(ss, i) {\n\t\tif (!(ctx->subsys_mask & (1 << i)) ||\n\t\t    ss->root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\tif (!percpu_ref_tryget_live(&ss->root->cgrp.self.refcnt))\n\t\t\treturn 1;\t/* restart */\n\t\tcgroup_put(&ss->root->cgrp);\n\t}\n\n\tfor_each_root(root) {\n\t\tbool name_match = false;\n\n\t\tif (root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If we asked for a name then it must match.  Also, if\n\t\t * name matches but sybsys_mask doesn't, we should fail.\n\t\t * Remember whether name matched.\n\t\t */\n\t\tif (ctx->name) {\n\t\t\tif (strcmp(ctx->name, root->name))\n\t\t\t\tcontinue;\n\t\t\tname_match = true;\n\t\t}\n\n\t\t/*\n\t\t * If we asked for subsystems (or explicitly for no\n\t\t * subsystems) then they must match.\n\t\t */\n\t\tif ((ctx->subsys_mask || ctx->none) &&\n\t\t    (ctx->subsys_mask != root->subsys_mask)) {\n\t\t\tif (!name_match)\n\t\t\t\tcontinue;\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\tif (root->flags ^ ctx->flags)\n\t\t\tpr_warn(\"new mount options do not match the existing superblock, will be ignored\\n\");\n\n\t\tctx->root = root;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * No such thing, create a new one.  name= matching without subsys\n\t * specification is allowed for already existing hierarchies but we\n\t * can't create new one without subsys specification.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none)\n\t\treturn invalfc(fc, \"No subsys list or none specified\");\n\n\t/* Hierarchies may only be created in the initial cgroup namespace. */\n\tif (ctx->ns != &init_cgroup_ns)\n\t\treturn -EPERM;\n\n\troot = kzalloc(sizeof(*root), GFP_KERNEL);\n\tif (!root)\n\t\treturn -ENOMEM;\n\n\tctx->root = root;\n\tinit_cgroup_root(ctx);\n\n\tret = cgroup_setup_root(root, ctx->subsys_mask);\n\tif (ret)\n\t\tcgroup_free_root(root);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup1_root_to_use(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct cgroup_root *root;\n\tstruct cgroup_subsys *ss;\n\tint i, ret;\n\n\t/* First find the desired set of subsystems */\n\tret = check_cgroupfs_options(fc);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * Destruction of cgroup root is asynchronous, so subsystems may\n\t * still be dying after the previous unmount.  Let's drain the\n\t * dying subsystems.  We just need to ensure that the ones\n\t * unmounted previously finish dying and don't care about new ones\n\t * starting.  Testing ref liveliness is good enough.\n\t */\n\tfor_each_subsys(ss, i) {\n\t\tif (!(ctx->subsys_mask & (1 << i)) ||\n\t\t    ss->root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\tif (!percpu_ref_tryget_live(&ss->root->cgrp.self.refcnt))\n\t\t\treturn 1;\t/* restart */\n\t\tcgroup_put(&ss->root->cgrp);\n\t}\n\n\tfor_each_root(root) {\n\t\tbool name_match = false;\n\n\t\tif (root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If we asked for a name then it must match.  Also, if\n\t\t * name matches but sybsys_mask doesn't, we should fail.\n\t\t * Remember whether name matched.\n\t\t */\n\t\tif (ctx->name) {\n\t\t\tif (strcmp(ctx->name, root->name))\n\t\t\t\tcontinue;\n\t\t\tname_match = true;\n\t\t}\n\n\t\t/*\n\t\t * If we asked for subsystems (or explicitly for no\n\t\t * subsystems) then they must match.\n\t\t */\n\t\tif ((ctx->subsys_mask || ctx->none) &&\n\t\t    (ctx->subsys_mask != root->subsys_mask)) {\n\t\t\tif (!name_match)\n\t\t\t\tcontinue;\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\tif (root->flags ^ ctx->flags)\n\t\t\tpr_warn(\"new mount options do not match the existing superblock, will be ignored\\n\");\n\n\t\tctx->root = root;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * No such thing, create a new one.  name= matching without subsys\n\t * specification is allowed for already existing hierarchies but we\n\t * can't create new one without subsys specification.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none)\n\t\treturn invalfc(fc, \"No subsys list or none specified\");\n\n\t/* Hierarchies may only be created in the initial cgroup namespace. */\n\tif (ctx->ns != &init_cgroup_ns)\n\t\treturn -EPERM;\n\n\troot = kzalloc(sizeof(*root), GFP_KERNEL);\n\tif (!root)\n\t\treturn -ENOMEM;\n\n\tctx->root = root;\n\tinit_cgroup_root(ctx);\n\n\tret = cgroup_setup_root(root, ctx->subsys_mask);\n\tif (ret)\n\t\tcgroup_free_root(root);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_lock_and_drain_offline",
          "args": [
            "&cgrp_dfl_root.cgrp"
          ],
          "line": 1212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ns_capable",
          "args": [
            "ctx->ns->user_ns",
            "CAP_SYS_ADMIN"
          ],
          "line": 1209
        },
        "resolved": true,
        "details": {
          "function_name": "ns_capable_setid",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/capability.c",
          "lines": "431-434",
          "snippet": "bool ns_capable_setid(struct user_namespace *ns, int cap)\n{\n\treturn ns_capable_common(ns, cap, CAP_OPT_INSETID);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool ns_capable_setid(struct user_namespace *ns, int cap)\n{\n\treturn ns_capable_common(ns, cap, CAP_OPT_INSETID);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_fc2context",
          "args": [
            "fc"
          ],
          "line": 1205
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_fc2context",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "61-66",
          "snippet": "static inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nint cgroup1_get_tree(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tint ret;\n\n\t/* Check if the caller has permission to mount. */\n\tif (!ns_capable(ctx->ns->user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcgroup_lock_and_drain_offline(&cgrp_dfl_root.cgrp);\n\n\tret = cgroup1_root_to_use(fc);\n\tif (!ret && !percpu_ref_tryget_live(&ctx->root->cgrp.self.refcnt))\n\t\tret = 1;\t/* restart */\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tif (!ret)\n\t\tret = cgroup_do_get_tree(fc);\n\n\tif (!ret && percpu_ref_is_dying(&ctx->root->cgrp.self.refcnt)) {\n\t\tfc_drop_locked(fc);\n\t\tret = 1;\n\t}\n\n\tif (unlikely(ret > 0)) {\n\t\tmsleep(10);\n\t\treturn restart_syscall();\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "cgroup1_root_to_use",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "1114-1201",
    "snippet": "static int cgroup1_root_to_use(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct cgroup_root *root;\n\tstruct cgroup_subsys *ss;\n\tint i, ret;\n\n\t/* First find the desired set of subsystems */\n\tret = check_cgroupfs_options(fc);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * Destruction of cgroup root is asynchronous, so subsystems may\n\t * still be dying after the previous unmount.  Let's drain the\n\t * dying subsystems.  We just need to ensure that the ones\n\t * unmounted previously finish dying and don't care about new ones\n\t * starting.  Testing ref liveliness is good enough.\n\t */\n\tfor_each_subsys(ss, i) {\n\t\tif (!(ctx->subsys_mask & (1 << i)) ||\n\t\t    ss->root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\tif (!percpu_ref_tryget_live(&ss->root->cgrp.self.refcnt))\n\t\t\treturn 1;\t/* restart */\n\t\tcgroup_put(&ss->root->cgrp);\n\t}\n\n\tfor_each_root(root) {\n\t\tbool name_match = false;\n\n\t\tif (root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If we asked for a name then it must match.  Also, if\n\t\t * name matches but sybsys_mask doesn't, we should fail.\n\t\t * Remember whether name matched.\n\t\t */\n\t\tif (ctx->name) {\n\t\t\tif (strcmp(ctx->name, root->name))\n\t\t\t\tcontinue;\n\t\t\tname_match = true;\n\t\t}\n\n\t\t/*\n\t\t * If we asked for subsystems (or explicitly for no\n\t\t * subsystems) then they must match.\n\t\t */\n\t\tif ((ctx->subsys_mask || ctx->none) &&\n\t\t    (ctx->subsys_mask != root->subsys_mask)) {\n\t\t\tif (!name_match)\n\t\t\t\tcontinue;\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\tif (root->flags ^ ctx->flags)\n\t\t\tpr_warn(\"new mount options do not match the existing superblock, will be ignored\\n\");\n\n\t\tctx->root = root;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * No such thing, create a new one.  name= matching without subsys\n\t * specification is allowed for already existing hierarchies but we\n\t * can't create new one without subsys specification.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none)\n\t\treturn invalfc(fc, \"No subsys list or none specified\");\n\n\t/* Hierarchies may only be created in the initial cgroup namespace. */\n\tif (ctx->ns != &init_cgroup_ns)\n\t\treturn -EPERM;\n\n\troot = kzalloc(sizeof(*root), GFP_KERNEL);\n\tif (!root)\n\t\treturn -ENOMEM;\n\n\tctx->root = root;\n\tinit_cgroup_root(ctx);\n\n\tret = cgroup_setup_root(root, ctx->subsys_mask);\n\tif (ret)\n\t\tcgroup_free_root(root);\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cgroup_free_root",
          "args": [
            "root"
          ],
          "line": 1199
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_free_root",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1331-1334",
          "snippet": "void cgroup_free_root(struct cgroup_root *root)\n{\n\tkfree(root);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid cgroup_free_root(struct cgroup_root *root)\n{\n\tkfree(root);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_setup_root",
          "args": [
            "root",
            "ctx->subsys_mask"
          ],
          "line": 1197
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_setup_root",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1986-2087",
          "snippet": "int cgroup_setup_root(struct cgroup_root *root, u16 ss_mask)\n{\n\tLIST_HEAD(tmp_links);\n\tstruct cgroup *root_cgrp = &root->cgrp;\n\tstruct kernfs_syscall_ops *kf_sops;\n\tstruct css_set *cset;\n\tint i, ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tret = percpu_ref_init(&root_cgrp->self.refcnt, css_release,\n\t\t\t      0, GFP_KERNEL);\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * We're accessing css_set_count without locking css_set_lock here,\n\t * but that's OK - it can only be increased by someone holding\n\t * cgroup_lock, and that's us.  Later rebinding may disable\n\t * controllers on the default hierarchy and thus create new csets,\n\t * which can't be more than the existing ones.  Allocate 2x.\n\t */\n\tret = allocate_cgrp_cset_links(2 * css_set_count, &tmp_links);\n\tif (ret)\n\t\tgoto cancel_ref;\n\n\tret = cgroup_init_root_id(root);\n\tif (ret)\n\t\tgoto cancel_ref;\n\n\tkf_sops = root == &cgrp_dfl_root ?\n\t\t&cgroup_kf_syscall_ops : &cgroup1_kf_syscall_ops;\n\n\troot->kf_root = kernfs_create_root(kf_sops,\n\t\t\t\t\t   KERNFS_ROOT_CREATE_DEACTIVATED |\n\t\t\t\t\t   KERNFS_ROOT_SUPPORT_EXPORTOP |\n\t\t\t\t\t   KERNFS_ROOT_SUPPORT_USER_XATTR,\n\t\t\t\t\t   root_cgrp);\n\tif (IS_ERR(root->kf_root)) {\n\t\tret = PTR_ERR(root->kf_root);\n\t\tgoto exit_root_id;\n\t}\n\troot_cgrp->kn = root->kf_root->kn;\n\tWARN_ON_ONCE(cgroup_ino(root_cgrp) != 1);\n\troot_cgrp->ancestor_ids[0] = cgroup_id(root_cgrp);\n\n\tret = css_populate_dir(&root_cgrp->self);\n\tif (ret)\n\t\tgoto destroy_root;\n\n\tret = cgroup_rstat_init(root_cgrp);\n\tif (ret)\n\t\tgoto destroy_root;\n\n\tret = rebind_subsystems(root, ss_mask);\n\tif (ret)\n\t\tgoto exit_stats;\n\n\tret = cgroup_bpf_inherit(root_cgrp);\n\tWARN_ON_ONCE(ret);\n\n\ttrace_cgroup_setup_root(root);\n\n\t/*\n\t * There must be no failure case after here, since rebinding takes\n\t * care of subsystems' refcounts, which are explicitly dropped in\n\t * the failure exit path.\n\t */\n\tlist_add(&root->root_list, &cgroup_roots);\n\tcgroup_root_count++;\n\n\t/*\n\t * Link the root cgroup in this hierarchy into all the css_set\n\t * objects.\n\t */\n\tspin_lock_irq(&css_set_lock);\n\thash_for_each(css_set_table, i, cset, hlist) {\n\t\tlink_css_set(&tmp_links, cset, root_cgrp);\n\t\tif (css_set_populated(cset))\n\t\t\tcgroup_update_populated(root_cgrp, true);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\tBUG_ON(!list_empty(&root_cgrp->self.children));\n\tBUG_ON(atomic_read(&root->nr_cgrps) != 1);\n\n\tret = 0;\n\tgoto out;\n\nexit_stats:\n\tcgroup_rstat_exit(root_cgrp);\ndestroy_root:\n\tkernfs_destroy_root(root->kf_root);\n\troot->kf_root = NULL;\nexit_root_id:\n\tcgroup_exit_root_id(root);\ncancel_ref:\n\tpercpu_ref_exit(&root_cgrp->self.refcnt);\nout:\n\tfree_cgrp_cset_links(&tmp_links);\n\treturn ret;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct cgroup_root cgrp_dfl_root = { .cgrp.rstat_cpu = &cgrp_dfl_root_rstat_cpu };",
            "static int cgroup_root_count;",
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static void cgroup_finalize_control(struct cgroup *cgrp, int ret);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);",
            "static int css_set_count\t= 1;",
            "static struct kernfs_syscall_ops cgroup_kf_syscall_ops;",
            "static struct kernfs_syscall_ops cgroup_kf_syscall_ops = {\n\t.show_options\t\t= cgroup_show_options,\n\t.mkdir\t\t\t= cgroup_mkdir,\n\t.rmdir\t\t\t= cgroup_rmdir,\n\t.show_path\t\t= cgroup_show_path,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct cgroup_root cgrp_dfl_root = { .cgrp.rstat_cpu = &cgrp_dfl_root_rstat_cpu };\nstatic int cgroup_root_count;\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\nstatic int css_set_count\t= 1;\nstatic struct kernfs_syscall_ops cgroup_kf_syscall_ops;\nstatic struct kernfs_syscall_ops cgroup_kf_syscall_ops = {\n\t.show_options\t\t= cgroup_show_options,\n\t.mkdir\t\t\t= cgroup_mkdir,\n\t.rmdir\t\t\t= cgroup_rmdir,\n\t.show_path\t\t= cgroup_show_path,\n};\n\nint cgroup_setup_root(struct cgroup_root *root, u16 ss_mask)\n{\n\tLIST_HEAD(tmp_links);\n\tstruct cgroup *root_cgrp = &root->cgrp;\n\tstruct kernfs_syscall_ops *kf_sops;\n\tstruct css_set *cset;\n\tint i, ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tret = percpu_ref_init(&root_cgrp->self.refcnt, css_release,\n\t\t\t      0, GFP_KERNEL);\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * We're accessing css_set_count without locking css_set_lock here,\n\t * but that's OK - it can only be increased by someone holding\n\t * cgroup_lock, and that's us.  Later rebinding may disable\n\t * controllers on the default hierarchy and thus create new csets,\n\t * which can't be more than the existing ones.  Allocate 2x.\n\t */\n\tret = allocate_cgrp_cset_links(2 * css_set_count, &tmp_links);\n\tif (ret)\n\t\tgoto cancel_ref;\n\n\tret = cgroup_init_root_id(root);\n\tif (ret)\n\t\tgoto cancel_ref;\n\n\tkf_sops = root == &cgrp_dfl_root ?\n\t\t&cgroup_kf_syscall_ops : &cgroup1_kf_syscall_ops;\n\n\troot->kf_root = kernfs_create_root(kf_sops,\n\t\t\t\t\t   KERNFS_ROOT_CREATE_DEACTIVATED |\n\t\t\t\t\t   KERNFS_ROOT_SUPPORT_EXPORTOP |\n\t\t\t\t\t   KERNFS_ROOT_SUPPORT_USER_XATTR,\n\t\t\t\t\t   root_cgrp);\n\tif (IS_ERR(root->kf_root)) {\n\t\tret = PTR_ERR(root->kf_root);\n\t\tgoto exit_root_id;\n\t}\n\troot_cgrp->kn = root->kf_root->kn;\n\tWARN_ON_ONCE(cgroup_ino(root_cgrp) != 1);\n\troot_cgrp->ancestor_ids[0] = cgroup_id(root_cgrp);\n\n\tret = css_populate_dir(&root_cgrp->self);\n\tif (ret)\n\t\tgoto destroy_root;\n\n\tret = cgroup_rstat_init(root_cgrp);\n\tif (ret)\n\t\tgoto destroy_root;\n\n\tret = rebind_subsystems(root, ss_mask);\n\tif (ret)\n\t\tgoto exit_stats;\n\n\tret = cgroup_bpf_inherit(root_cgrp);\n\tWARN_ON_ONCE(ret);\n\n\ttrace_cgroup_setup_root(root);\n\n\t/*\n\t * There must be no failure case after here, since rebinding takes\n\t * care of subsystems' refcounts, which are explicitly dropped in\n\t * the failure exit path.\n\t */\n\tlist_add(&root->root_list, &cgroup_roots);\n\tcgroup_root_count++;\n\n\t/*\n\t * Link the root cgroup in this hierarchy into all the css_set\n\t * objects.\n\t */\n\tspin_lock_irq(&css_set_lock);\n\thash_for_each(css_set_table, i, cset, hlist) {\n\t\tlink_css_set(&tmp_links, cset, root_cgrp);\n\t\tif (css_set_populated(cset))\n\t\t\tcgroup_update_populated(root_cgrp, true);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\tBUG_ON(!list_empty(&root_cgrp->self.children));\n\tBUG_ON(atomic_read(&root->nr_cgrps) != 1);\n\n\tret = 0;\n\tgoto out;\n\nexit_stats:\n\tcgroup_rstat_exit(root_cgrp);\ndestroy_root:\n\tkernfs_destroy_root(root->kf_root);\n\troot->kf_root = NULL;\nexit_root_id:\n\tcgroup_exit_root_id(root);\ncancel_ref:\n\tpercpu_ref_exit(&root_cgrp->self.refcnt);\nout:\n\tfree_cgrp_cset_links(&tmp_links);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_cgroup_root",
          "args": [
            "ctx"
          ],
          "line": 1195
        },
        "resolved": true,
        "details": {
          "function_name": "init_cgroup_root",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1967-1984",
          "snippet": "void init_cgroup_root(struct cgroup_fs_context *ctx)\n{\n\tstruct cgroup_root *root = ctx->root;\n\tstruct cgroup *cgrp = &root->cgrp;\n\n\tINIT_LIST_HEAD(&root->root_list);\n\tatomic_set(&root->nr_cgrps, 1);\n\tcgrp->root = root;\n\tinit_cgroup_housekeeping(cgrp);\n\n\troot->flags = ctx->flags;\n\tif (ctx->release_agent)\n\t\tstrscpy(root->release_agent_path, ctx->release_agent, PATH_MAX);\n\tif (ctx->name)\n\t\tstrscpy(root->name, ctx->name, MAX_CGROUP_ROOT_NAMELEN);\n\tif (ctx->cpuset_clone_children)\n\t\tset_bit(CGRP_CPUSET_CLONE_CHILDREN, &root->cgrp.flags);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nvoid init_cgroup_root(struct cgroup_fs_context *ctx)\n{\n\tstruct cgroup_root *root = ctx->root;\n\tstruct cgroup *cgrp = &root->cgrp;\n\n\tINIT_LIST_HEAD(&root->root_list);\n\tatomic_set(&root->nr_cgrps, 1);\n\tcgrp->root = root;\n\tinit_cgroup_housekeeping(cgrp);\n\n\troot->flags = ctx->flags;\n\tif (ctx->release_agent)\n\t\tstrscpy(root->release_agent_path, ctx->release_agent, PATH_MAX);\n\tif (ctx->name)\n\t\tstrscpy(root->name, ctx->name, MAX_CGROUP_ROOT_NAMELEN);\n\tif (ctx->cpuset_clone_children)\n\t\tset_bit(CGRP_CPUSET_CLONE_CHILDREN, &root->cgrp.flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*root)",
            "GFP_KERNEL"
          ],
          "line": 1190
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"No subsys list or none specified\""
          ],
          "line": 1184
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_warn",
          "args": [
            "\"new mount options do not match the existing superblock, will be ignored\\n\""
          ],
          "line": 1172
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strcmp",
          "args": [
            "ctx->name",
            "root->name"
          ],
          "line": 1155
        },
        "resolved": true,
        "details": {
          "function_name": "sym_strcmp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/report.c",
          "lines": "356-365",
          "snippet": "static int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}",
          "includes": [
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include <linux/stacktrace.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/printk.h>",
            "#include <linux/preempt.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/delay.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"encoding.h\"\n#include \"kcsan.h\"\n#include <linux/stacktrace.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/printk.h>\n#include <linux/preempt.h>\n#include <linux/lockdep.h>\n#include <linux/kernel.h>\n#include <linux/kallsyms.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/debug_locks.h>\n\nstatic int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_put",
          "args": [
            "&ss->root->cgrp"
          ],
          "line": 1140
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "percpu_ref_tryget_live",
          "args": [
            "&ss->root->cgrp.self.refcnt"
          ],
          "line": 1138
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_subsys",
          "args": [
            "ss",
            "i"
          ],
          "line": 1133
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_cgroupfs_options",
          "args": [
            "fc"
          ],
          "line": 1122
        },
        "resolved": true,
        "details": {
          "function_name": "check_cgroupfs_options",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "988-1040",
          "snippet": "static int check_cgroupfs_options(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tu16 mask = U16_MAX;\n\tu16 enabled = 0;\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n#ifdef CONFIG_CPUSETS\n\tmask = ~((u16)1 << cpuset_cgrp_id);\n#endif\n\tfor_each_subsys(ss, i)\n\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))\n\t\t\tenabled |= 1 << i;\n\n\tctx->subsys_mask &= enabled;\n\n\t/*\n\t * In absence of 'none', 'name=' and subsystem name options,\n\t * let's default to 'all'.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)\n\t\tctx->all_ss = true;\n\n\tif (ctx->all_ss) {\n\t\t/* Mutually exclusive option 'all' + subsystem name */\n\t\tif (ctx->subsys_mask)\n\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");\n\t\t/* 'all' => select all the subsystems */\n\t\tctx->subsys_mask = enabled;\n\t}\n\n\t/*\n\t * We either have to specify by name or by subsystems. (So all\n\t * empty hierarchies must have a name).\n\t */\n\tif (!ctx->subsys_mask && !ctx->name)\n\t\treturn invalfc(fc, \"Need name or subsystem set\");\n\n\t/*\n\t * Option noprefix was introduced just for backward compatibility\n\t * with the old cpuset, so we allow noprefix only if mounting just\n\t * the cpuset subsystem.\n\t */\n\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))\n\t\treturn invalfc(fc, \"noprefix used incorrectly\");\n\n\t/* Can't specify \"none\" and some subsystems */\n\tif (ctx->subsys_mask && ctx->none)\n\t\treturn invalfc(fc, \"none used incorrectly\");\n\n\treturn 0;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int check_cgroupfs_options(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tu16 mask = U16_MAX;\n\tu16 enabled = 0;\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n#ifdef CONFIG_CPUSETS\n\tmask = ~((u16)1 << cpuset_cgrp_id);\n#endif\n\tfor_each_subsys(ss, i)\n\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))\n\t\t\tenabled |= 1 << i;\n\n\tctx->subsys_mask &= enabled;\n\n\t/*\n\t * In absence of 'none', 'name=' and subsystem name options,\n\t * let's default to 'all'.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)\n\t\tctx->all_ss = true;\n\n\tif (ctx->all_ss) {\n\t\t/* Mutually exclusive option 'all' + subsystem name */\n\t\tif (ctx->subsys_mask)\n\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");\n\t\t/* 'all' => select all the subsystems */\n\t\tctx->subsys_mask = enabled;\n\t}\n\n\t/*\n\t * We either have to specify by name or by subsystems. (So all\n\t * empty hierarchies must have a name).\n\t */\n\tif (!ctx->subsys_mask && !ctx->name)\n\t\treturn invalfc(fc, \"Need name or subsystem set\");\n\n\t/*\n\t * Option noprefix was introduced just for backward compatibility\n\t * with the old cpuset, so we allow noprefix only if mounting just\n\t * the cpuset subsystem.\n\t */\n\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))\n\t\treturn invalfc(fc, \"noprefix used incorrectly\");\n\n\t/* Can't specify \"none\" and some subsystems */\n\tif (ctx->subsys_mask && ctx->none)\n\t\treturn invalfc(fc, \"none used incorrectly\");\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_fc2context",
          "args": [
            "fc"
          ],
          "line": 1116
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_fc2context",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "61-66",
          "snippet": "static inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup1_root_to_use(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct cgroup_root *root;\n\tstruct cgroup_subsys *ss;\n\tint i, ret;\n\n\t/* First find the desired set of subsystems */\n\tret = check_cgroupfs_options(fc);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * Destruction of cgroup root is asynchronous, so subsystems may\n\t * still be dying after the previous unmount.  Let's drain the\n\t * dying subsystems.  We just need to ensure that the ones\n\t * unmounted previously finish dying and don't care about new ones\n\t * starting.  Testing ref liveliness is good enough.\n\t */\n\tfor_each_subsys(ss, i) {\n\t\tif (!(ctx->subsys_mask & (1 << i)) ||\n\t\t    ss->root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\tif (!percpu_ref_tryget_live(&ss->root->cgrp.self.refcnt))\n\t\t\treturn 1;\t/* restart */\n\t\tcgroup_put(&ss->root->cgrp);\n\t}\n\n\tfor_each_root(root) {\n\t\tbool name_match = false;\n\n\t\tif (root == &cgrp_dfl_root)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If we asked for a name then it must match.  Also, if\n\t\t * name matches but sybsys_mask doesn't, we should fail.\n\t\t * Remember whether name matched.\n\t\t */\n\t\tif (ctx->name) {\n\t\t\tif (strcmp(ctx->name, root->name))\n\t\t\t\tcontinue;\n\t\t\tname_match = true;\n\t\t}\n\n\t\t/*\n\t\t * If we asked for subsystems (or explicitly for no\n\t\t * subsystems) then they must match.\n\t\t */\n\t\tif ((ctx->subsys_mask || ctx->none) &&\n\t\t    (ctx->subsys_mask != root->subsys_mask)) {\n\t\t\tif (!name_match)\n\t\t\t\tcontinue;\n\t\t\treturn -EBUSY;\n\t\t}\n\n\t\tif (root->flags ^ ctx->flags)\n\t\t\tpr_warn(\"new mount options do not match the existing superblock, will be ignored\\n\");\n\n\t\tctx->root = root;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * No such thing, create a new one.  name= matching without subsys\n\t * specification is allowed for already existing hierarchies but we\n\t * can't create new one without subsys specification.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none)\n\t\treturn invalfc(fc, \"No subsys list or none specified\");\n\n\t/* Hierarchies may only be created in the initial cgroup namespace. */\n\tif (ctx->ns != &init_cgroup_ns)\n\t\treturn -EPERM;\n\n\troot = kzalloc(sizeof(*root), GFP_KERNEL);\n\tif (!root)\n\t\treturn -ENOMEM;\n\n\tctx->root = root;\n\tinit_cgroup_root(ctx);\n\n\tret = cgroup_setup_root(root, ctx->subsys_mask);\n\tif (ret)\n\t\tcgroup_free_root(root);\n\treturn ret;\n}"
  },
  {
    "function_name": "cgroup1_reconfigure",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "1042-1096",
    "snippet": "int cgroup1_reconfigure(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct kernfs_root *kf_root = kernfs_root_from_sb(fc->root->d_sb);\n\tstruct cgroup_root *root = cgroup_root_from_kf(kf_root);\n\tint ret = 0;\n\tu16 added_mask, removed_mask;\n\n\tcgroup_lock_and_drain_offline(&cgrp_dfl_root.cgrp);\n\n\t/* See what subsystems are wanted */\n\tret = check_cgroupfs_options(fc);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tif (ctx->subsys_mask != root->subsys_mask || ctx->release_agent)\n\t\tpr_warn(\"option changes via remount are deprecated (pid=%d comm=%s)\\n\",\n\t\t\ttask_tgid_nr(current), current->comm);\n\n\tadded_mask = ctx->subsys_mask & ~root->subsys_mask;\n\tremoved_mask = root->subsys_mask & ~ctx->subsys_mask;\n\n\t/* Don't allow flags or name to change at remount */\n\tif ((ctx->flags ^ root->flags) ||\n\t    (ctx->name && strcmp(ctx->name, root->name))) {\n\t\terrorfc(fc, \"option or name mismatch, new: 0x%x \\\"%s\\\", old: 0x%x \\\"%s\\\"\",\n\t\t       ctx->flags, ctx->name ?: \"\", root->flags, root->name);\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\t/* remounting is not allowed for populated hierarchies */\n\tif (!list_empty(&root->cgrp.self.children)) {\n\t\tret = -EBUSY;\n\t\tgoto out_unlock;\n\t}\n\n\tret = rebind_subsystems(root, added_mask);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tWARN_ON(rebind_subsystems(&cgrp_dfl_root, removed_mask));\n\n\tif (ctx->release_agent) {\n\t\tspin_lock(&release_agent_path_lock);\n\t\tstrcpy(root->release_agent_path, ctx->release_agent);\n\t\tspin_unlock(&release_agent_path_lock);\n\t}\n\n\ttrace_cgroup_remount(root);\n\n out_unlock:\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_SPINLOCK(release_agent_path_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 1094
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_cgroup_remount",
          "args": [
            "root"
          ],
          "line": 1091
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 1088
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "strcpy",
          "args": [
            "root->release_agent_path",
            "ctx->release_agent"
          ],
          "line": 1087
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 1086
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "rebind_subsystems(&cgrp_dfl_root, removed_mask)"
          ],
          "line": 1083
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rebind_subsystems",
          "args": [
            "&cgrp_dfl_root",
            "removed_mask"
          ],
          "line": 1083
        },
        "resolved": true,
        "details": {
          "function_name": "rebind_subsystems",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1739-1836",
          "snippet": "int rebind_subsystems(struct cgroup_root *dst_root, u16 ss_mask)\n{\n\tstruct cgroup *dcgrp = &dst_root->cgrp;\n\tstruct cgroup_subsys *ss;\n\tint ssid, i, ret;\n\tu16 dfl_disable_ss_mask = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\t/*\n\t\t * If @ss has non-root csses attached to it, can't move.\n\t\t * If @ss is an implicit controller, it is exempt from this\n\t\t * rule and can be stolen.\n\t\t */\n\t\tif (css_next_child(NULL, cgroup_css(&ss->root->cgrp, ss)) &&\n\t\t    !ss->implicit_on_dfl)\n\t\t\treturn -EBUSY;\n\n\t\t/* can't move between two non-dummy roots either */\n\t\tif (ss->root != &cgrp_dfl_root && dst_root != &cgrp_dfl_root)\n\t\t\treturn -EBUSY;\n\n\t\t/*\n\t\t * Collect ssid's that need to be disabled from default\n\t\t * hierarchy.\n\t\t */\n\t\tif (ss->root == &cgrp_dfl_root)\n\t\t\tdfl_disable_ss_mask |= 1 << ssid;\n\n\t} while_each_subsys_mask();\n\n\tif (dfl_disable_ss_mask) {\n\t\tstruct cgroup *scgrp = &cgrp_dfl_root.cgrp;\n\n\t\t/*\n\t\t * Controllers from default hierarchy that need to be rebound\n\t\t * are all disabled together in one go.\n\t\t */\n\t\tcgrp_dfl_root.subsys_mask &= ~dfl_disable_ss_mask;\n\t\tWARN_ON(cgroup_apply_control(scgrp));\n\t\tcgroup_finalize_control(scgrp, 0);\n\t}\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\tstruct cgroup_root *src_root = ss->root;\n\t\tstruct cgroup *scgrp = &src_root->cgrp;\n\t\tstruct cgroup_subsys_state *css = cgroup_css(scgrp, ss);\n\t\tstruct css_set *cset;\n\n\t\tWARN_ON(!css || cgroup_css(dcgrp, ss));\n\n\t\tif (src_root != &cgrp_dfl_root) {\n\t\t\t/* disable from the source */\n\t\t\tsrc_root->subsys_mask &= ~(1 << ssid);\n\t\t\tWARN_ON(cgroup_apply_control(scgrp));\n\t\t\tcgroup_finalize_control(scgrp, 0);\n\t\t}\n\n\t\t/* rebind */\n\t\tRCU_INIT_POINTER(scgrp->subsys[ssid], NULL);\n\t\trcu_assign_pointer(dcgrp->subsys[ssid], css);\n\t\tss->root = dst_root;\n\t\tcss->cgroup = dcgrp;\n\n\t\tspin_lock_irq(&css_set_lock);\n\t\thash_for_each(css_set_table, i, cset, hlist)\n\t\t\tlist_move_tail(&cset->e_cset_node[ss->id],\n\t\t\t\t       &dcgrp->e_csets[ss->id]);\n\t\tspin_unlock_irq(&css_set_lock);\n\n\t\tif (ss->css_rstat_flush) {\n\t\t\tlist_del_rcu(&css->rstat_css_node);\n\t\t\tlist_add_rcu(&css->rstat_css_node,\n\t\t\t\t     &dcgrp->rstat_css_list);\n\t\t}\n\n\t\t/* default hierarchy doesn't enable controllers by default */\n\t\tdst_root->subsys_mask |= 1 << ssid;\n\t\tif (dst_root == &cgrp_dfl_root) {\n\t\t\tstatic_branch_enable(cgroup_subsys_on_dfl_key[ssid]);\n\t\t} else {\n\t\t\tdcgrp->subtree_control |= 1 << ssid;\n\t\t\tstatic_branch_disable(cgroup_subsys_on_dfl_key[ssid]);\n\t\t}\n\n\t\tret = cgroup_apply_control(dcgrp);\n\t\tif (ret)\n\t\t\tpr_warn(\"partial failure to rebind %s controller (err=%d)\\n\",\n\t\t\t\tss->name, ret);\n\n\t\tif (ss->bind)\n\t\t\tss->bind(css);\n\t} while_each_subsys_mask();\n\n\tkernfs_activate(dcgrp->kn);\n\treturn 0;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct static_key_true *cgroup_subsys_on_dfl_key[] = {\n#include <linux/cgroup_subsys.h>\n};",
            "struct cgroup_root cgrp_dfl_root = { .cgrp.rstat_cpu = &cgrp_dfl_root_rstat_cpu };",
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static void cgroup_finalize_control(struct cgroup *cgrp, int ret);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);",
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic struct static_key_true *cgroup_subsys_on_dfl_key[] = {\n#include <linux/cgroup_subsys.h>\n};\nstruct cgroup_root cgrp_dfl_root = { .cgrp.rstat_cpu = &cgrp_dfl_root_rstat_cpu };\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\n\nint rebind_subsystems(struct cgroup_root *dst_root, u16 ss_mask)\n{\n\tstruct cgroup *dcgrp = &dst_root->cgrp;\n\tstruct cgroup_subsys *ss;\n\tint ssid, i, ret;\n\tu16 dfl_disable_ss_mask = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\t/*\n\t\t * If @ss has non-root csses attached to it, can't move.\n\t\t * If @ss is an implicit controller, it is exempt from this\n\t\t * rule and can be stolen.\n\t\t */\n\t\tif (css_next_child(NULL, cgroup_css(&ss->root->cgrp, ss)) &&\n\t\t    !ss->implicit_on_dfl)\n\t\t\treturn -EBUSY;\n\n\t\t/* can't move between two non-dummy roots either */\n\t\tif (ss->root != &cgrp_dfl_root && dst_root != &cgrp_dfl_root)\n\t\t\treturn -EBUSY;\n\n\t\t/*\n\t\t * Collect ssid's that need to be disabled from default\n\t\t * hierarchy.\n\t\t */\n\t\tif (ss->root == &cgrp_dfl_root)\n\t\t\tdfl_disable_ss_mask |= 1 << ssid;\n\n\t} while_each_subsys_mask();\n\n\tif (dfl_disable_ss_mask) {\n\t\tstruct cgroup *scgrp = &cgrp_dfl_root.cgrp;\n\n\t\t/*\n\t\t * Controllers from default hierarchy that need to be rebound\n\t\t * are all disabled together in one go.\n\t\t */\n\t\tcgrp_dfl_root.subsys_mask &= ~dfl_disable_ss_mask;\n\t\tWARN_ON(cgroup_apply_control(scgrp));\n\t\tcgroup_finalize_control(scgrp, 0);\n\t}\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\tstruct cgroup_root *src_root = ss->root;\n\t\tstruct cgroup *scgrp = &src_root->cgrp;\n\t\tstruct cgroup_subsys_state *css = cgroup_css(scgrp, ss);\n\t\tstruct css_set *cset;\n\n\t\tWARN_ON(!css || cgroup_css(dcgrp, ss));\n\n\t\tif (src_root != &cgrp_dfl_root) {\n\t\t\t/* disable from the source */\n\t\t\tsrc_root->subsys_mask &= ~(1 << ssid);\n\t\t\tWARN_ON(cgroup_apply_control(scgrp));\n\t\t\tcgroup_finalize_control(scgrp, 0);\n\t\t}\n\n\t\t/* rebind */\n\t\tRCU_INIT_POINTER(scgrp->subsys[ssid], NULL);\n\t\trcu_assign_pointer(dcgrp->subsys[ssid], css);\n\t\tss->root = dst_root;\n\t\tcss->cgroup = dcgrp;\n\n\t\tspin_lock_irq(&css_set_lock);\n\t\thash_for_each(css_set_table, i, cset, hlist)\n\t\t\tlist_move_tail(&cset->e_cset_node[ss->id],\n\t\t\t\t       &dcgrp->e_csets[ss->id]);\n\t\tspin_unlock_irq(&css_set_lock);\n\n\t\tif (ss->css_rstat_flush) {\n\t\t\tlist_del_rcu(&css->rstat_css_node);\n\t\t\tlist_add_rcu(&css->rstat_css_node,\n\t\t\t\t     &dcgrp->rstat_css_list);\n\t\t}\n\n\t\t/* default hierarchy doesn't enable controllers by default */\n\t\tdst_root->subsys_mask |= 1 << ssid;\n\t\tif (dst_root == &cgrp_dfl_root) {\n\t\t\tstatic_branch_enable(cgroup_subsys_on_dfl_key[ssid]);\n\t\t} else {\n\t\t\tdcgrp->subtree_control |= 1 << ssid;\n\t\t\tstatic_branch_disable(cgroup_subsys_on_dfl_key[ssid]);\n\t\t}\n\n\t\tret = cgroup_apply_control(dcgrp);\n\t\tif (ret)\n\t\t\tpr_warn(\"partial failure to rebind %s controller (err=%d)\\n\",\n\t\t\t\tss->name, ret);\n\n\t\tif (ss->bind)\n\t\t\tss->bind(css);\n\t} while_each_subsys_mask();\n\n\tkernfs_activate(dcgrp->kn);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&root->cgrp.self.children"
          ],
          "line": 1074
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "errorfc",
          "args": [
            "fc",
            "\"option or name mismatch, new: 0x%x \\\"%s\\\", old: 0x%x \\\"%s\\\"\"",
            "ctx->flags",
            "ctx->name ?: \"\"",
            "root->flags",
            "root->name"
          ],
          "line": 1067
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strcmp",
          "args": [
            "ctx->name",
            "root->name"
          ],
          "line": 1066
        },
        "resolved": true,
        "details": {
          "function_name": "sym_strcmp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/report.c",
          "lines": "356-365",
          "snippet": "static int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}",
          "includes": [
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include <linux/stacktrace.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/printk.h>",
            "#include <linux/preempt.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/delay.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"encoding.h\"\n#include \"kcsan.h\"\n#include <linux/stacktrace.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/printk.h>\n#include <linux/preempt.h>\n#include <linux/lockdep.h>\n#include <linux/kernel.h>\n#include <linux/kallsyms.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/debug_locks.h>\n\nstatic int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_warn",
          "args": [
            "\"option changes via remount are deprecated (pid=%d comm=%s)\\n\"",
            "task_tgid_nr(current)",
            "current->comm"
          ],
          "line": 1058
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_tgid_nr",
          "args": [
            "current"
          ],
          "line": 1059
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "check_cgroupfs_options",
          "args": [
            "fc"
          ],
          "line": 1053
        },
        "resolved": true,
        "details": {
          "function_name": "check_cgroupfs_options",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "988-1040",
          "snippet": "static int check_cgroupfs_options(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tu16 mask = U16_MAX;\n\tu16 enabled = 0;\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n#ifdef CONFIG_CPUSETS\n\tmask = ~((u16)1 << cpuset_cgrp_id);\n#endif\n\tfor_each_subsys(ss, i)\n\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))\n\t\t\tenabled |= 1 << i;\n\n\tctx->subsys_mask &= enabled;\n\n\t/*\n\t * In absence of 'none', 'name=' and subsystem name options,\n\t * let's default to 'all'.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)\n\t\tctx->all_ss = true;\n\n\tif (ctx->all_ss) {\n\t\t/* Mutually exclusive option 'all' + subsystem name */\n\t\tif (ctx->subsys_mask)\n\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");\n\t\t/* 'all' => select all the subsystems */\n\t\tctx->subsys_mask = enabled;\n\t}\n\n\t/*\n\t * We either have to specify by name or by subsystems. (So all\n\t * empty hierarchies must have a name).\n\t */\n\tif (!ctx->subsys_mask && !ctx->name)\n\t\treturn invalfc(fc, \"Need name or subsystem set\");\n\n\t/*\n\t * Option noprefix was introduced just for backward compatibility\n\t * with the old cpuset, so we allow noprefix only if mounting just\n\t * the cpuset subsystem.\n\t */\n\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))\n\t\treturn invalfc(fc, \"noprefix used incorrectly\");\n\n\t/* Can't specify \"none\" and some subsystems */\n\tif (ctx->subsys_mask && ctx->none)\n\t\treturn invalfc(fc, \"none used incorrectly\");\n\n\treturn 0;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int check_cgroupfs_options(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tu16 mask = U16_MAX;\n\tu16 enabled = 0;\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n#ifdef CONFIG_CPUSETS\n\tmask = ~((u16)1 << cpuset_cgrp_id);\n#endif\n\tfor_each_subsys(ss, i)\n\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))\n\t\t\tenabled |= 1 << i;\n\n\tctx->subsys_mask &= enabled;\n\n\t/*\n\t * In absence of 'none', 'name=' and subsystem name options,\n\t * let's default to 'all'.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)\n\t\tctx->all_ss = true;\n\n\tif (ctx->all_ss) {\n\t\t/* Mutually exclusive option 'all' + subsystem name */\n\t\tif (ctx->subsys_mask)\n\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");\n\t\t/* 'all' => select all the subsystems */\n\t\tctx->subsys_mask = enabled;\n\t}\n\n\t/*\n\t * We either have to specify by name or by subsystems. (So all\n\t * empty hierarchies must have a name).\n\t */\n\tif (!ctx->subsys_mask && !ctx->name)\n\t\treturn invalfc(fc, \"Need name or subsystem set\");\n\n\t/*\n\t * Option noprefix was introduced just for backward compatibility\n\t * with the old cpuset, so we allow noprefix only if mounting just\n\t * the cpuset subsystem.\n\t */\n\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))\n\t\treturn invalfc(fc, \"noprefix used incorrectly\");\n\n\t/* Can't specify \"none\" and some subsystems */\n\tif (ctx->subsys_mask && ctx->none)\n\t\treturn invalfc(fc, \"none used incorrectly\");\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_lock_and_drain_offline",
          "args": [
            "&cgrp_dfl_root.cgrp"
          ],
          "line": 1050
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_root_from_kf",
          "args": [
            "kf_root"
          ],
          "line": 1046
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_root_from_kf",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1303-1308",
          "snippet": "struct cgroup_root *cgroup_root_from_kf(struct kernfs_root *kf_root)\n{\n\tstruct cgroup *root_cgrp = kf_root->kn->priv;\n\n\treturn root_cgrp->root;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct cgroup_root *cgroup_root_from_kf(struct kernfs_root *kf_root)\n{\n\tstruct cgroup *root_cgrp = kf_root->kn->priv;\n\n\treturn root_cgrp->root;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kernfs_root_from_sb",
          "args": [
            "fc->root->d_sb"
          ],
          "line": 1045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_fc2context",
          "args": [
            "fc"
          ],
          "line": 1044
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_fc2context",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "61-66",
          "snippet": "static inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic DEFINE_SPINLOCK(release_agent_path_lock);\n\nint cgroup1_reconfigure(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct kernfs_root *kf_root = kernfs_root_from_sb(fc->root->d_sb);\n\tstruct cgroup_root *root = cgroup_root_from_kf(kf_root);\n\tint ret = 0;\n\tu16 added_mask, removed_mask;\n\n\tcgroup_lock_and_drain_offline(&cgrp_dfl_root.cgrp);\n\n\t/* See what subsystems are wanted */\n\tret = check_cgroupfs_options(fc);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tif (ctx->subsys_mask != root->subsys_mask || ctx->release_agent)\n\t\tpr_warn(\"option changes via remount are deprecated (pid=%d comm=%s)\\n\",\n\t\t\ttask_tgid_nr(current), current->comm);\n\n\tadded_mask = ctx->subsys_mask & ~root->subsys_mask;\n\tremoved_mask = root->subsys_mask & ~ctx->subsys_mask;\n\n\t/* Don't allow flags or name to change at remount */\n\tif ((ctx->flags ^ root->flags) ||\n\t    (ctx->name && strcmp(ctx->name, root->name))) {\n\t\terrorfc(fc, \"option or name mismatch, new: 0x%x \\\"%s\\\", old: 0x%x \\\"%s\\\"\",\n\t\t       ctx->flags, ctx->name ?: \"\", root->flags, root->name);\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n\t/* remounting is not allowed for populated hierarchies */\n\tif (!list_empty(&root->cgrp.self.children)) {\n\t\tret = -EBUSY;\n\t\tgoto out_unlock;\n\t}\n\n\tret = rebind_subsystems(root, added_mask);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tWARN_ON(rebind_subsystems(&cgrp_dfl_root, removed_mask));\n\n\tif (ctx->release_agent) {\n\t\tspin_lock(&release_agent_path_lock);\n\t\tstrcpy(root->release_agent_path, ctx->release_agent);\n\t\tspin_unlock(&release_agent_path_lock);\n\t}\n\n\ttrace_cgroup_remount(root);\n\n out_unlock:\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}"
  },
  {
    "function_name": "check_cgroupfs_options",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "988-1040",
    "snippet": "static int check_cgroupfs_options(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tu16 mask = U16_MAX;\n\tu16 enabled = 0;\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n#ifdef CONFIG_CPUSETS\n\tmask = ~((u16)1 << cpuset_cgrp_id);\n#endif\n\tfor_each_subsys(ss, i)\n\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))\n\t\t\tenabled |= 1 << i;\n\n\tctx->subsys_mask &= enabled;\n\n\t/*\n\t * In absence of 'none', 'name=' and subsystem name options,\n\t * let's default to 'all'.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)\n\t\tctx->all_ss = true;\n\n\tif (ctx->all_ss) {\n\t\t/* Mutually exclusive option 'all' + subsystem name */\n\t\tif (ctx->subsys_mask)\n\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");\n\t\t/* 'all' => select all the subsystems */\n\t\tctx->subsys_mask = enabled;\n\t}\n\n\t/*\n\t * We either have to specify by name or by subsystems. (So all\n\t * empty hierarchies must have a name).\n\t */\n\tif (!ctx->subsys_mask && !ctx->name)\n\t\treturn invalfc(fc, \"Need name or subsystem set\");\n\n\t/*\n\t * Option noprefix was introduced just for backward compatibility\n\t * with the old cpuset, so we allow noprefix only if mounting just\n\t * the cpuset subsystem.\n\t */\n\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))\n\t\treturn invalfc(fc, \"noprefix used incorrectly\");\n\n\t/* Can't specify \"none\" and some subsystems */\n\tif (ctx->subsys_mask && ctx->none)\n\t\treturn invalfc(fc, \"none used incorrectly\");\n\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"none used incorrectly\""
          ],
          "line": 1037
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"noprefix used incorrectly\""
          ],
          "line": 1033
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"Need name or subsystem set\""
          ],
          "line": 1025
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"subsys name conflicts with all\""
          ],
          "line": 1015
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup1_ssid_disabled",
          "args": [
            "i"
          ],
          "line": 1000
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup1_ssid_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "44-47",
          "snippet": "bool cgroup1_ssid_disabled(int ssid)\n{\n\treturn cgroup_no_v1_mask & (1 << ssid);\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static u16 cgroup_no_v1_mask;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic u16 cgroup_no_v1_mask;\n\nbool cgroup1_ssid_disabled(int ssid)\n{\n\treturn cgroup_no_v1_mask & (1 << ssid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_ssid_enabled",
          "args": [
            "i"
          ],
          "line": 1000
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_ssid_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "258-264",
          "snippet": "bool cgroup_ssid_enabled(int ssid)\n{\n\tif (!CGROUP_HAS_SUBSYS_CONFIG)\n\t\treturn false;\n\n\treturn static_key_enabled(cgroup_subsys_enabled_key[ssid]);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct static_key_true *cgroup_subsys_enabled_key[] = {\n#include <linux/cgroup_subsys.h>\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct static_key_true *cgroup_subsys_enabled_key[] = {\n#include <linux/cgroup_subsys.h>\n};\n\nbool cgroup_ssid_enabled(int ssid)\n{\n\tif (!CGROUP_HAS_SUBSYS_CONFIG)\n\t\treturn false;\n\n\treturn static_key_enabled(cgroup_subsys_enabled_key[ssid]);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_subsys",
          "args": [
            "ss",
            "i"
          ],
          "line": 999
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_fc2context",
          "args": [
            "fc"
          ],
          "line": 990
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_fc2context",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "61-66",
          "snippet": "static inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int check_cgroupfs_options(struct fs_context *fc)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tu16 mask = U16_MAX;\n\tu16 enabled = 0;\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n#ifdef CONFIG_CPUSETS\n\tmask = ~((u16)1 << cpuset_cgrp_id);\n#endif\n\tfor_each_subsys(ss, i)\n\t\tif (cgroup_ssid_enabled(i) && !cgroup1_ssid_disabled(i))\n\t\t\tenabled |= 1 << i;\n\n\tctx->subsys_mask &= enabled;\n\n\t/*\n\t * In absence of 'none', 'name=' and subsystem name options,\n\t * let's default to 'all'.\n\t */\n\tif (!ctx->subsys_mask && !ctx->none && !ctx->name)\n\t\tctx->all_ss = true;\n\n\tif (ctx->all_ss) {\n\t\t/* Mutually exclusive option 'all' + subsystem name */\n\t\tif (ctx->subsys_mask)\n\t\t\treturn invalfc(fc, \"subsys name conflicts with all\");\n\t\t/* 'all' => select all the subsystems */\n\t\tctx->subsys_mask = enabled;\n\t}\n\n\t/*\n\t * We either have to specify by name or by subsystems. (So all\n\t * empty hierarchies must have a name).\n\t */\n\tif (!ctx->subsys_mask && !ctx->name)\n\t\treturn invalfc(fc, \"Need name or subsystem set\");\n\n\t/*\n\t * Option noprefix was introduced just for backward compatibility\n\t * with the old cpuset, so we allow noprefix only if mounting just\n\t * the cpuset subsystem.\n\t */\n\tif ((ctx->flags & CGRP_ROOT_NOPREFIX) && (ctx->subsys_mask & mask))\n\t\treturn invalfc(fc, \"noprefix used incorrectly\");\n\n\t/* Can't specify \"none\" and some subsystems */\n\tif (ctx->subsys_mask && ctx->none)\n\t\treturn invalfc(fc, \"none used incorrectly\");\n\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup1_parse_param",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "905-986",
    "snippet": "int cgroup1_parse_param(struct fs_context *fc, struct fs_parameter *param)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct cgroup_subsys *ss;\n\tstruct fs_parse_result result;\n\tint opt, i;\n\n\topt = fs_parse(fc, cgroup1_fs_parameters, param, &result);\n\tif (opt == -ENOPARAM) {\n\t\tint ret;\n\n\t\tret = vfs_parse_fs_param_source(fc, param);\n\t\tif (ret != -ENOPARAM)\n\t\t\treturn ret;\n\t\tfor_each_subsys(ss, i) {\n\t\t\tif (strcmp(param->key, ss->legacy_name))\n\t\t\t\tcontinue;\n\t\t\tif (!cgroup_ssid_enabled(i) || cgroup1_ssid_disabled(i))\n\t\t\t\treturn invalfc(fc, \"Disabled controller '%s'\",\n\t\t\t\t\t       param->key);\n\t\t\tctx->subsys_mask |= (1 << i);\n\t\t\treturn 0;\n\t\t}\n\t\treturn invalfc(fc, \"Unknown subsys name '%s'\", param->key);\n\t}\n\tif (opt < 0)\n\t\treturn opt;\n\n\tswitch (opt) {\n\tcase Opt_none:\n\t\t/* Explicitly have no subsystems */\n\t\tctx->none = true;\n\t\tbreak;\n\tcase Opt_all:\n\t\tctx->all_ss = true;\n\t\tbreak;\n\tcase Opt_noprefix:\n\t\tctx->flags |= CGRP_ROOT_NOPREFIX;\n\t\tbreak;\n\tcase Opt_clone_children:\n\t\tctx->cpuset_clone_children = true;\n\t\tbreak;\n\tcase Opt_cpuset_v2_mode:\n\t\tctx->flags |= CGRP_ROOT_CPUSET_V2_MODE;\n\t\tbreak;\n\tcase Opt_xattr:\n\t\tctx->flags |= CGRP_ROOT_XATTR;\n\t\tbreak;\n\tcase Opt_release_agent:\n\t\t/* Specifying two release agents is forbidden */\n\t\tif (ctx->release_agent)\n\t\t\treturn invalfc(fc, \"release_agent respecified\");\n\t\tctx->release_agent = param->string;\n\t\tparam->string = NULL;\n\t\tbreak;\n\tcase Opt_name:\n\t\t/* blocked by boot param? */\n\t\tif (cgroup_no_v1_named)\n\t\t\treturn -ENOENT;\n\t\t/* Can't specify an empty name */\n\t\tif (!param->size)\n\t\t\treturn invalfc(fc, \"Empty name\");\n\t\tif (param->size > MAX_CGROUP_ROOT_NAMELEN - 1)\n\t\t\treturn invalfc(fc, \"Name too long\");\n\t\t/* Must match [\\w.-]+ */\n\t\tfor (i = 0; i < param->size; i++) {\n\t\t\tchar c = param->string[i];\n\t\t\tif (isalnum(c))\n\t\t\t\tcontinue;\n\t\t\tif ((c == '.') || (c == '-') || (c == '_'))\n\t\t\t\tcontinue;\n\t\t\treturn invalfc(fc, \"Invalid name\");\n\t\t}\n\t\t/* Specifying two names is forbidden */\n\t\tif (ctx->name)\n\t\t\treturn invalfc(fc, \"name respecified\");\n\t\tctx->name = param->string;\n\t\tparam->string = NULL;\n\t\tbreak;\n\t}\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static bool cgroup_no_v1_named;",
      "const struct fs_parameter_spec cgroup1_fs_parameters[] = {\n\tfsparam_flag  (\"all\",\t\tOpt_all),\n\tfsparam_flag  (\"clone_children\", Opt_clone_children),\n\tfsparam_flag  (\"cpuset_v2_mode\", Opt_cpuset_v2_mode),\n\tfsparam_string(\"name\",\t\tOpt_name),\n\tfsparam_flag  (\"none\",\t\tOpt_none),\n\tfsparam_flag  (\"noprefix\",\tOpt_noprefix),\n\tfsparam_string(\"release_agent\",\tOpt_release_agent),\n\tfsparam_flag  (\"xattr\",\t\tOpt_xattr),\n\t{}\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"name respecified\""
          ],
          "line": 980
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"Invalid name\""
          ],
          "line": 976
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "isalnum",
          "args": [
            "c"
          ],
          "line": 972
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"Name too long\""
          ],
          "line": 968
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"Empty name\""
          ],
          "line": 966
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"release_agent respecified\""
          ],
          "line": 956
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"Unknown subsys name '%s'\"",
            "param->key"
          ],
          "line": 928
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "invalfc",
          "args": [
            "fc",
            "\"Disabled controller '%s'\"",
            "param->key"
          ],
          "line": 923
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup1_ssid_disabled",
          "args": [
            "i"
          ],
          "line": 922
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup1_ssid_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "44-47",
          "snippet": "bool cgroup1_ssid_disabled(int ssid)\n{\n\treturn cgroup_no_v1_mask & (1 << ssid);\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static u16 cgroup_no_v1_mask;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic u16 cgroup_no_v1_mask;\n\nbool cgroup1_ssid_disabled(int ssid)\n{\n\treturn cgroup_no_v1_mask & (1 << ssid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_ssid_enabled",
          "args": [
            "i"
          ],
          "line": 922
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_ssid_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "258-264",
          "snippet": "bool cgroup_ssid_enabled(int ssid)\n{\n\tif (!CGROUP_HAS_SUBSYS_CONFIG)\n\t\treturn false;\n\n\treturn static_key_enabled(cgroup_subsys_enabled_key[ssid]);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct static_key_true *cgroup_subsys_enabled_key[] = {\n#include <linux/cgroup_subsys.h>\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct static_key_true *cgroup_subsys_enabled_key[] = {\n#include <linux/cgroup_subsys.h>\n};\n\nbool cgroup_ssid_enabled(int ssid)\n{\n\tif (!CGROUP_HAS_SUBSYS_CONFIG)\n\t\treturn false;\n\n\treturn static_key_enabled(cgroup_subsys_enabled_key[ssid]);\n}"
        }
      },
      {
        "call_info": {
          "callee": "strcmp",
          "args": [
            "param->key",
            "ss->legacy_name"
          ],
          "line": 920
        },
        "resolved": true,
        "details": {
          "function_name": "sym_strcmp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/report.c",
          "lines": "356-365",
          "snippet": "static int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}",
          "includes": [
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include <linux/stacktrace.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/printk.h>",
            "#include <linux/preempt.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/delay.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"encoding.h\"\n#include \"kcsan.h\"\n#include <linux/stacktrace.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/printk.h>\n#include <linux/preempt.h>\n#include <linux/lockdep.h>\n#include <linux/kernel.h>\n#include <linux/kallsyms.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/debug_locks.h>\n\nstatic int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_subsys",
          "args": [
            "ss",
            "i"
          ],
          "line": 919
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "vfs_parse_fs_param_source",
          "args": [
            "fc",
            "param"
          ],
          "line": 916
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fs_parse",
          "args": [
            "fc",
            "cgroup1_fs_parameters",
            "param",
            "&result"
          ],
          "line": 912
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_fc2context",
          "args": [
            "fc"
          ],
          "line": 907
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_fc2context",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "61-66",
          "snippet": "static inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline struct cgroup_fs_context *cgroup_fc2context(struct fs_context *fc)\n{\n\tstruct kernfs_fs_context *kfc = fc->fs_private;\n\n\treturn container_of(kfc, struct cgroup_fs_context, kfc);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic bool cgroup_no_v1_named;\nconst struct fs_parameter_spec cgroup1_fs_parameters[] = {\n\tfsparam_flag  (\"all\",\t\tOpt_all),\n\tfsparam_flag  (\"clone_children\", Opt_clone_children),\n\tfsparam_flag  (\"cpuset_v2_mode\", Opt_cpuset_v2_mode),\n\tfsparam_string(\"name\",\t\tOpt_name),\n\tfsparam_flag  (\"none\",\t\tOpt_none),\n\tfsparam_flag  (\"noprefix\",\tOpt_noprefix),\n\tfsparam_string(\"release_agent\",\tOpt_release_agent),\n\tfsparam_flag  (\"xattr\",\t\tOpt_xattr),\n\t{}\n};\n\nint cgroup1_parse_param(struct fs_context *fc, struct fs_parameter *param)\n{\n\tstruct cgroup_fs_context *ctx = cgroup_fc2context(fc);\n\tstruct cgroup_subsys *ss;\n\tstruct fs_parse_result result;\n\tint opt, i;\n\n\topt = fs_parse(fc, cgroup1_fs_parameters, param, &result);\n\tif (opt == -ENOPARAM) {\n\t\tint ret;\n\n\t\tret = vfs_parse_fs_param_source(fc, param);\n\t\tif (ret != -ENOPARAM)\n\t\t\treturn ret;\n\t\tfor_each_subsys(ss, i) {\n\t\t\tif (strcmp(param->key, ss->legacy_name))\n\t\t\t\tcontinue;\n\t\t\tif (!cgroup_ssid_enabled(i) || cgroup1_ssid_disabled(i))\n\t\t\t\treturn invalfc(fc, \"Disabled controller '%s'\",\n\t\t\t\t\t       param->key);\n\t\t\tctx->subsys_mask |= (1 << i);\n\t\t\treturn 0;\n\t\t}\n\t\treturn invalfc(fc, \"Unknown subsys name '%s'\", param->key);\n\t}\n\tif (opt < 0)\n\t\treturn opt;\n\n\tswitch (opt) {\n\tcase Opt_none:\n\t\t/* Explicitly have no subsystems */\n\t\tctx->none = true;\n\t\tbreak;\n\tcase Opt_all:\n\t\tctx->all_ss = true;\n\t\tbreak;\n\tcase Opt_noprefix:\n\t\tctx->flags |= CGRP_ROOT_NOPREFIX;\n\t\tbreak;\n\tcase Opt_clone_children:\n\t\tctx->cpuset_clone_children = true;\n\t\tbreak;\n\tcase Opt_cpuset_v2_mode:\n\t\tctx->flags |= CGRP_ROOT_CPUSET_V2_MODE;\n\t\tbreak;\n\tcase Opt_xattr:\n\t\tctx->flags |= CGRP_ROOT_XATTR;\n\t\tbreak;\n\tcase Opt_release_agent:\n\t\t/* Specifying two release agents is forbidden */\n\t\tif (ctx->release_agent)\n\t\t\treturn invalfc(fc, \"release_agent respecified\");\n\t\tctx->release_agent = param->string;\n\t\tparam->string = NULL;\n\t\tbreak;\n\tcase Opt_name:\n\t\t/* blocked by boot param? */\n\t\tif (cgroup_no_v1_named)\n\t\t\treturn -ENOENT;\n\t\t/* Can't specify an empty name */\n\t\tif (!param->size)\n\t\t\treturn invalfc(fc, \"Empty name\");\n\t\tif (param->size > MAX_CGROUP_ROOT_NAMELEN - 1)\n\t\t\treturn invalfc(fc, \"Name too long\");\n\t\t/* Must match [\\w.-]+ */\n\t\tfor (i = 0; i < param->size; i++) {\n\t\t\tchar c = param->string[i];\n\t\t\tif (isalnum(c))\n\t\t\t\tcontinue;\n\t\t\tif ((c == '.') || (c == '-') || (c == '_'))\n\t\t\t\tcontinue;\n\t\t\treturn invalfc(fc, \"Invalid name\");\n\t\t}\n\t\t/* Specifying two names is forbidden */\n\t\tif (ctx->name)\n\t\t\treturn invalfc(fc, \"name respecified\");\n\t\tctx->name = param->string;\n\t\tparam->string = NULL;\n\t\tbreak;\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup1_show_options",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "853-880",
    "snippet": "static int cgroup1_show_options(struct seq_file *seq, struct kernfs_root *kf_root)\n{\n\tstruct cgroup_root *root = cgroup_root_from_kf(kf_root);\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\tfor_each_subsys(ss, ssid)\n\t\tif (root->subsys_mask & (1 << ssid))\n\t\t\tseq_show_option(seq, ss->legacy_name, NULL);\n\tif (root->flags & CGRP_ROOT_NOPREFIX)\n\t\tseq_puts(seq, \",noprefix\");\n\tif (root->flags & CGRP_ROOT_XATTR)\n\t\tseq_puts(seq, \",xattr\");\n\tif (root->flags & CGRP_ROOT_CPUSET_V2_MODE)\n\t\tseq_puts(seq, \",cpuset_v2_mode\");\n\n\tspin_lock(&release_agent_path_lock);\n\tif (strlen(root->release_agent_path))\n\t\tseq_show_option(seq, \"release_agent\",\n\t\t\t\troot->release_agent_path);\n\tspin_unlock(&release_agent_path_lock);\n\n\tif (test_bit(CGRP_CPUSET_CLONE_CHILDREN, &root->cgrp.flags))\n\t\tseq_puts(seq, \",clone_children\");\n\tif (strlen(root->name))\n\t\tseq_show_option(seq, \"name\", root->name);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_SPINLOCK(release_agent_path_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "seq_show_option",
          "args": [
            "seq",
            "\"name\"",
            "root->name"
          ],
          "line": 878
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strlen",
          "args": [
            "root->name"
          ],
          "line": 877
        },
        "resolved": true,
        "details": {
          "function_name": "fetch_store_strlen",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_eprobe.c",
          "lines": "384-401",
          "snippet": "static nokprobe_inline int\nfetch_store_strlen(unsigned long addr)\n{\n\tint ret, len = 0;\n\tu8 c;\n\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tif (addr < TASK_SIZE)\n\t\treturn fetch_store_strlen_user(addr);\n#endif\n\n\tdo {\n\t\tret = copy_from_kernel_nofault(&c, (u8 *)addr + len, 1);\n\t\tlen++;\n\t} while (c && ret == 0 && len < MAX_STRING_SIZE);\n\n\treturn (ret < 0) ? ret : len;\n}",
          "includes": [
            "#include \"trace_probe_tmpl.h\"",
            "#include \"trace_probe.h\"",
            "#include \"trace_dynevent.h\"",
            "#include <linux/ftrace.h>",
            "#include <linux/mutex.h>",
            "#include <linux/module.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "NOKPROBE_SYMBOL(process_fetch_insn)\n\n/* Return the length of string -- including null terminal byte */\nstatic nokprobe_inline"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_probe_tmpl.h\"\n#include \"trace_probe.h\"\n#include \"trace_dynevent.h\"\n#include <linux/ftrace.h>\n#include <linux/mutex.h>\n#include <linux/module.h>\n\nNOKPROBE_SYMBOL(process_fetch_insn)\n\n/* Return the length of string -- including null terminal byte */\nstatic nokprobe_inline;\n\nstatic nokprobe_inline int\nfetch_store_strlen(unsigned long addr)\n{\n\tint ret, len = 0;\n\tu8 c;\n\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tif (addr < TASK_SIZE)\n\t\treturn fetch_store_strlen_user(addr);\n#endif\n\n\tdo {\n\t\tret = copy_from_kernel_nofault(&c, (u8 *)addr + len, 1);\n\t\tlen++;\n\t} while (c && ret == 0 && len < MAX_STRING_SIZE);\n\n\treturn (ret < 0) ? ret : len;\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_puts",
          "args": [
            "seq",
            "\",clone_children\""
          ],
          "line": 876
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "205-220",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      },
      {
        "call_info": {
          "callee": "test_bit",
          "args": [
            "CGRP_CPUSET_CLONE_CHILDREN",
            "&root->cgrp.flags"
          ],
          "line": 875
        },
        "resolved": true,
        "details": {
          "function_name": "memory_bm_test_bit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/power/snapshot.c",
          "lines": "849-858",
          "snippet": "static int memory_bm_test_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\treturn test_bit(bit, addr);\n}",
          "includes": [
            "#include \"power.h\"",
            "#include <asm/io.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/ktime.h>",
            "#include <linux/compiler.h>",
            "#include <linux/slab.h>",
            "#include <linux/list.h>",
            "#include <linux/highmem.h>",
            "#include <linux/console.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/nmi.h>",
            "#include <linux/memblock.h>",
            "#include <linux/init.h>",
            "#include <linux/device.h>",
            "#include <linux/pm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bitops.h>",
            "#include <linux/delay.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/version.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"power.h\"\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <linux/set_memory.h>\n#include <linux/ktime.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/console.h>\n#include <linux/syscalls.h>\n#include <linux/nmi.h>\n#include <linux/memblock.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/pm.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/suspend.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/version.h>\n\nstatic int memory_bm_test_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\treturn test_bit(bit, addr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 873
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_show_option",
          "args": [
            "seq",
            "\"release_agent\"",
            "root->release_agent_path"
          ],
          "line": 871
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 869
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_show_option",
          "args": [
            "seq",
            "ss->legacy_name",
            "NULL"
          ],
          "line": 861
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_subsys",
          "args": [
            "ss",
            "ssid"
          ],
          "line": 859
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_root_from_kf",
          "args": [
            "kf_root"
          ],
          "line": 855
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_root_from_kf",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1303-1308",
          "snippet": "struct cgroup_root *cgroup_root_from_kf(struct kernfs_root *kf_root)\n{\n\tstruct cgroup *root_cgrp = kf_root->kn->priv;\n\n\treturn root_cgrp->root;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct cgroup_root *cgroup_root_from_kf(struct kernfs_root *kf_root)\n{\n\tstruct cgroup *root_cgrp = kf_root->kn->priv;\n\n\treturn root_cgrp->root;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic DEFINE_SPINLOCK(release_agent_path_lock);\n\nstatic int cgroup1_show_options(struct seq_file *seq, struct kernfs_root *kf_root)\n{\n\tstruct cgroup_root *root = cgroup_root_from_kf(kf_root);\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\tfor_each_subsys(ss, ssid)\n\t\tif (root->subsys_mask & (1 << ssid))\n\t\t\tseq_show_option(seq, ss->legacy_name, NULL);\n\tif (root->flags & CGRP_ROOT_NOPREFIX)\n\t\tseq_puts(seq, \",noprefix\");\n\tif (root->flags & CGRP_ROOT_XATTR)\n\t\tseq_puts(seq, \",xattr\");\n\tif (root->flags & CGRP_ROOT_CPUSET_V2_MODE)\n\t\tseq_puts(seq, \",cpuset_v2_mode\");\n\n\tspin_lock(&release_agent_path_lock);\n\tif (strlen(root->release_agent_path))\n\t\tseq_show_option(seq, \"release_agent\",\n\t\t\t\troot->release_agent_path);\n\tspin_unlock(&release_agent_path_lock);\n\n\tif (test_bit(CGRP_CPUSET_CLONE_CHILDREN, &root->cgrp.flags))\n\t\tseq_puts(seq, \",clone_children\");\n\tif (strlen(root->name))\n\t\tseq_show_option(seq, \"name\", root->name);\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup1_rename",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "817-851",
    "snippet": "static int cgroup1_rename(struct kernfs_node *kn, struct kernfs_node *new_parent,\n\t\t\t  const char *new_name_str)\n{\n\tstruct cgroup *cgrp = kn->priv;\n\tint ret;\n\n\t/* do not accept '\\n' to prevent making /proc/<pid>/cgroup unparsable */\n\tif (strchr(new_name_str, '\\n'))\n\t\treturn -EINVAL;\n\n\tif (kernfs_type(kn) != KERNFS_DIR)\n\t\treturn -ENOTDIR;\n\tif (kn->parent != new_parent)\n\t\treturn -EIO;\n\n\t/*\n\t * We're gonna grab cgroup_mutex which nests outside kernfs\n\t * active_ref.  kernfs_rename() doesn't require active_ref\n\t * protection.  Break them before grabbing cgroup_mutex.\n\t */\n\tkernfs_break_active_protection(new_parent);\n\tkernfs_break_active_protection(kn);\n\n\tmutex_lock(&cgroup_mutex);\n\n\tret = kernfs_rename(kn, new_parent, new_name_str);\n\tif (!ret)\n\t\tTRACE_CGROUP_PATH(rename, cgrp);\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tkernfs_unbreak_active_protection(kn);\n\tkernfs_unbreak_active_protection(new_parent);\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kernfs_unbreak_active_protection",
          "args": [
            "new_parent"
          ],
          "line": 849
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kernfs_unbreak_active_protection",
          "args": [
            "kn"
          ],
          "line": 848
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 846
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "TRACE_CGROUP_PATH",
          "args": [
            "rename",
            "cgrp"
          ],
          "line": 844
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kernfs_rename",
          "args": [
            "kn",
            "new_parent",
            "new_name_str"
          ],
          "line": 842
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 840
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kernfs_break_active_protection",
          "args": [
            "kn"
          ],
          "line": 838
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kernfs_break_active_protection",
          "args": [
            "new_parent"
          ],
          "line": 837
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kernfs_type",
          "args": [
            "kn"
          ],
          "line": 827
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strchr",
          "args": [
            "new_name_str",
            "'\\n'"
          ],
          "line": 824
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup1_rename(struct kernfs_node *kn, struct kernfs_node *new_parent,\n\t\t\t  const char *new_name_str)\n{\n\tstruct cgroup *cgrp = kn->priv;\n\tint ret;\n\n\t/* do not accept '\\n' to prevent making /proc/<pid>/cgroup unparsable */\n\tif (strchr(new_name_str, '\\n'))\n\t\treturn -EINVAL;\n\n\tif (kernfs_type(kn) != KERNFS_DIR)\n\t\treturn -ENOTDIR;\n\tif (kn->parent != new_parent)\n\t\treturn -EIO;\n\n\t/*\n\t * We're gonna grab cgroup_mutex which nests outside kernfs\n\t * active_ref.  kernfs_rename() doesn't require active_ref\n\t * protection.  Break them before grabbing cgroup_mutex.\n\t */\n\tkernfs_break_active_protection(new_parent);\n\tkernfs_break_active_protection(kn);\n\n\tmutex_lock(&cgroup_mutex);\n\n\tret = kernfs_rename(kn, new_parent, new_name_str);\n\tif (!ret)\n\t\tTRACE_CGROUP_PATH(rename, cgrp);\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tkernfs_unbreak_active_protection(kn);\n\tkernfs_unbreak_active_protection(new_parent);\n\treturn ret;\n}"
  },
  {
    "function_name": "cgroup1_release_agent",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "771-812",
    "snippet": "void cgroup1_release_agent(struct work_struct *work)\n{\n\tstruct cgroup *cgrp =\n\t\tcontainer_of(work, struct cgroup, release_agent_work);\n\tchar *pathbuf, *agentbuf;\n\tchar *argv[3], *envp[3];\n\tint ret;\n\n\t/* snoop agent path and exit early if empty */\n\tif (!cgrp->root->release_agent_path[0])\n\t\treturn;\n\n\t/* prepare argument buffers */\n\tpathbuf = kmalloc(PATH_MAX, GFP_KERNEL);\n\tagentbuf = kmalloc(PATH_MAX, GFP_KERNEL);\n\tif (!pathbuf || !agentbuf)\n\t\tgoto out_free;\n\n\tspin_lock(&release_agent_path_lock);\n\tstrlcpy(agentbuf, cgrp->root->release_agent_path, PATH_MAX);\n\tspin_unlock(&release_agent_path_lock);\n\tif (!agentbuf[0])\n\t\tgoto out_free;\n\n\tret = cgroup_path_ns(cgrp, pathbuf, PATH_MAX, &init_cgroup_ns);\n\tif (ret < 0 || ret >= PATH_MAX)\n\t\tgoto out_free;\n\n\targv[0] = agentbuf;\n\targv[1] = pathbuf;\n\targv[2] = NULL;\n\n\t/* minimal command environment */\n\tenvp[0] = \"HOME=/\";\n\tenvp[1] = \"PATH=/sbin:/bin:/usr/sbin:/usr/bin\";\n\tenvp[2] = NULL;\n\n\tcall_usermodehelper(argv[0], argv, envp, UMH_WAIT_EXEC);\nout_free:\n\tkfree(agentbuf);\n\tkfree(pathbuf);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_SPINLOCK(release_agent_path_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "pathbuf"
          ],
          "line": 811
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "call_usermodehelper",
          "args": [
            "argv[0]",
            "argv",
            "envp",
            "UMH_WAIT_EXEC"
          ],
          "line": 808
        },
        "resolved": true,
        "details": {
          "function_name": "call_usermodehelper",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/umh.c",
          "lines": "474-485",
          "snippet": "int call_usermodehelper(const char *path, char **argv, char **envp, int wait)\n{\n\tstruct subprocess_info *info;\n\tgfp_t gfp_mask = (wait == UMH_NO_WAIT) ? GFP_ATOMIC : GFP_KERNEL;\n\n\tinfo = call_usermodehelper_setup(path, argv, envp, gfp_mask,\n\t\t\t\t\t NULL, NULL, NULL);\n\tif (info == NULL)\n\t\treturn -ENOMEM;\n\n\treturn call_usermodehelper_exec(info, wait);\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include <linux/initrd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/async.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/suspend.h>",
            "#include <linux/notifier.h>",
            "#include <linux/resource.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/mount.h>",
            "#include <linux/security.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/cred.h>",
            "#include <linux/completion.h>",
            "#include <linux/slab.h>",
            "#include <linux/kmod.h>",
            "#include <linux/unistd.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/module.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include <linux/initrd.h>\n#include <linux/uaccess.h>\n#include <linux/async.h>\n#include <linux/ptrace.h>\n#include <linux/rwsem.h>\n#include <linux/suspend.h>\n#include <linux/notifier.h>\n#include <linux/resource.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/mount.h>\n#include <linux/security.h>\n#include <linux/workqueue.h>\n#include <linux/fs_struct.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/cred.h>\n#include <linux/completion.h>\n#include <linux/slab.h>\n#include <linux/kmod.h>\n#include <linux/unistd.h>\n#include <linux/syscalls.h>\n#include <linux/binfmts.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n\nint call_usermodehelper(const char *path, char **argv, char **envp, int wait)\n{\n\tstruct subprocess_info *info;\n\tgfp_t gfp_mask = (wait == UMH_NO_WAIT) ? GFP_ATOMIC : GFP_KERNEL;\n\n\tinfo = call_usermodehelper_setup(path, argv, envp, gfp_mask,\n\t\t\t\t\t NULL, NULL, NULL);\n\tif (info == NULL)\n\t\treturn -ENOMEM;\n\n\treturn call_usermodehelper_exec(info, wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_path_ns",
          "args": [
            "cgrp",
            "pathbuf",
            "PATH_MAX",
            "&init_cgroup_ns"
          ],
          "line": 795
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_path_ns",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2290-2304",
          "snippet": "int cgroup_path_ns(struct cgroup *cgrp, char *buf, size_t buflen,\n\t\t   struct cgroup_namespace *ns)\n{\n\tint ret;\n\n\tmutex_lock(&cgroup_mutex);\n\tspin_lock_irq(&css_set_lock);\n\n\tret = cgroup_path_ns_locked(cgrp, buf, buflen, ns);\n\n\tspin_unlock_irq(&css_set_lock);\n\tmutex_unlock(&cgroup_mutex);\n\n\treturn ret;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static void cgroup_finalize_control(struct cgroup *cgrp, int ret);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nint cgroup_path_ns(struct cgroup *cgrp, char *buf, size_t buflen,\n\t\t   struct cgroup_namespace *ns)\n{\n\tint ret;\n\n\tmutex_lock(&cgroup_mutex);\n\tspin_lock_irq(&css_set_lock);\n\n\tret = cgroup_path_ns_locked(cgrp, buf, buflen, ns);\n\n\tspin_unlock_irq(&css_set_lock);\n\tmutex_unlock(&cgroup_mutex);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 791
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "strlcpy",
          "args": [
            "agentbuf",
            "cgrp->root->release_agent_path",
            "PATH_MAX"
          ],
          "line": 790
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 789
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kmalloc",
          "args": [
            "PATH_MAX",
            "GFP_KERNEL"
          ],
          "line": 785
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmalloc",
          "args": [
            "PATH_MAX",
            "GFP_KERNEL"
          ],
          "line": 784
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structcgroup",
            "release_agent_work"
          ],
          "line": 774
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic DEFINE_SPINLOCK(release_agent_path_lock);\n\nvoid cgroup1_release_agent(struct work_struct *work)\n{\n\tstruct cgroup *cgrp =\n\t\tcontainer_of(work, struct cgroup, release_agent_work);\n\tchar *pathbuf, *agentbuf;\n\tchar *argv[3], *envp[3];\n\tint ret;\n\n\t/* snoop agent path and exit early if empty */\n\tif (!cgrp->root->release_agent_path[0])\n\t\treturn;\n\n\t/* prepare argument buffers */\n\tpathbuf = kmalloc(PATH_MAX, GFP_KERNEL);\n\tagentbuf = kmalloc(PATH_MAX, GFP_KERNEL);\n\tif (!pathbuf || !agentbuf)\n\t\tgoto out_free;\n\n\tspin_lock(&release_agent_path_lock);\n\tstrlcpy(agentbuf, cgrp->root->release_agent_path, PATH_MAX);\n\tspin_unlock(&release_agent_path_lock);\n\tif (!agentbuf[0])\n\t\tgoto out_free;\n\n\tret = cgroup_path_ns(cgrp, pathbuf, PATH_MAX, &init_cgroup_ns);\n\tif (ret < 0 || ret >= PATH_MAX)\n\t\tgoto out_free;\n\n\targv[0] = agentbuf;\n\targv[1] = pathbuf;\n\targv[2] = NULL;\n\n\t/* minimal command environment */\n\tenvp[0] = \"HOME=/\";\n\tenvp[1] = \"PATH=/sbin:/bin:/usr/sbin:/usr/bin\";\n\tenvp[2] = NULL;\n\n\tcall_usermodehelper(argv[0], argv, envp, UMH_WAIT_EXEC);\nout_free:\n\tkfree(agentbuf);\n\tkfree(pathbuf);\n}"
  },
  {
    "function_name": "cgroup1_check_for_release",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "741-746",
    "snippet": "void cgroup1_check_for_release(struct cgroup *cgrp)\n{\n\tif (notify_on_release(cgrp) && !cgroup_is_populated(cgrp) &&\n\t    !css_has_online_children(&cgrp->self) && !cgroup_is_dead(cgrp))\n\t\tschedule_work(&cgrp->release_agent_work);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_work",
          "args": [
            "&cgrp->release_agent_work"
          ],
          "line": 745
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_is_dead",
          "args": [
            "cgrp"
          ],
          "line": 744
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_is_dead",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "187-190",
          "snippet": "static inline bool cgroup_is_dead(const struct cgroup *cgrp)\n{\n\treturn !(cgrp->self.flags & CSS_ONLINE);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline bool cgroup_is_dead(const struct cgroup *cgrp)\n{\n\treturn !(cgrp->self.flags & CSS_ONLINE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_has_online_children",
          "args": [
            "&cgrp->self"
          ],
          "line": 744
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_is_populated",
          "args": [
            "cgrp"
          ],
          "line": 743
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "notify_on_release",
          "args": [
            "cgrp"
          ],
          "line": 743
        },
        "resolved": true,
        "details": {
          "function_name": "notify_on_release",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "192-195",
          "snippet": "static inline bool notify_on_release(const struct cgroup *cgrp)\n{\n\treturn test_bit(CGRP_NOTIFY_ON_RELEASE, &cgrp->flags);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline bool notify_on_release(const struct cgroup *cgrp)\n{\n\treturn test_bit(CGRP_NOTIFY_ON_RELEASE, &cgrp->flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nvoid cgroup1_check_for_release(struct cgroup *cgrp)\n{\n\tif (notify_on_release(cgrp) && !cgroup_is_populated(cgrp) &&\n\t    !css_has_online_children(&cgrp->self) && !cgroup_is_dead(cgrp))\n\t\tschedule_work(&cgrp->release_agent_work);\n}"
  },
  {
    "function_name": "cgroupstats_build",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "689-739",
    "snippet": "int cgroupstats_build(struct cgroupstats *stats, struct dentry *dentry)\n{\n\tstruct kernfs_node *kn = kernfs_node_from_dentry(dentry);\n\tstruct cgroup *cgrp;\n\tstruct css_task_iter it;\n\tstruct task_struct *tsk;\n\n\t/* it should be kernfs_node belonging to cgroupfs and is a directory */\n\tif (dentry->d_sb->s_type != &cgroup_fs_type || !kn ||\n\t    kernfs_type(kn) != KERNFS_DIR)\n\t\treturn -EINVAL;\n\n\t/*\n\t * We aren't being called from kernfs and there's no guarantee on\n\t * @kn->priv's validity.  For this and css_tryget_online_from_dir(),\n\t * @kn->priv is RCU safe.  Let's do the RCU dancing.\n\t */\n\trcu_read_lock();\n\tcgrp = rcu_dereference(*(void __rcu __force **)&kn->priv);\n\tif (!cgrp || !cgroup_tryget(cgrp)) {\n\t\trcu_read_unlock();\n\t\treturn -ENOENT;\n\t}\n\trcu_read_unlock();\n\n\tcss_task_iter_start(&cgrp->self, 0, &it);\n\twhile ((tsk = css_task_iter_next(&it))) {\n\t\tswitch (READ_ONCE(tsk->__state)) {\n\t\tcase TASK_RUNNING:\n\t\t\tstats->nr_running++;\n\t\t\tbreak;\n\t\tcase TASK_INTERRUPTIBLE:\n\t\t\tstats->nr_sleeping++;\n\t\t\tbreak;\n\t\tcase TASK_UNINTERRUPTIBLE:\n\t\t\tstats->nr_uninterruptible++;\n\t\t\tbreak;\n\t\tcase TASK_STOPPED:\n\t\t\tstats->nr_stopped++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (tsk->in_iowait)\n\t\t\t\tstats->nr_io_wait++;\n\t\t\tbreak;\n\t\t}\n\t}\n\tcss_task_iter_end(&it);\n\n\tcgroup_put(cgrp);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cgroup_put",
          "args": [
            "cgrp"
          ],
          "line": 737
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "css_task_iter_end",
          "args": [
            "&it"
          ],
          "line": 735
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4761-4775",
          "snippet": "void css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "tsk->__state"
          ],
          "line": 716
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "css_task_iter_next",
          "args": [
            "&it"
          ],
          "line": 715
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_next",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4730-4753",
          "snippet": "struct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_start",
          "args": [
            "&cgrp->self",
            "0",
            "&it"
          ],
          "line": 714
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4700-4720",
          "snippet": "void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\n\nvoid css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 712
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_tryget",
          "args": [
            "cgrp"
          ],
          "line": 708
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "*(void __rcu __force **)&kn->priv"
          ],
          "line": 707
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 706
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "kernfs_type",
          "args": [
            "kn"
          ],
          "line": 698
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kernfs_node_from_dentry",
          "args": [
            "dentry"
          ],
          "line": 691
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nint cgroupstats_build(struct cgroupstats *stats, struct dentry *dentry)\n{\n\tstruct kernfs_node *kn = kernfs_node_from_dentry(dentry);\n\tstruct cgroup *cgrp;\n\tstruct css_task_iter it;\n\tstruct task_struct *tsk;\n\n\t/* it should be kernfs_node belonging to cgroupfs and is a directory */\n\tif (dentry->d_sb->s_type != &cgroup_fs_type || !kn ||\n\t    kernfs_type(kn) != KERNFS_DIR)\n\t\treturn -EINVAL;\n\n\t/*\n\t * We aren't being called from kernfs and there's no guarantee on\n\t * @kn->priv's validity.  For this and css_tryget_online_from_dir(),\n\t * @kn->priv is RCU safe.  Let's do the RCU dancing.\n\t */\n\trcu_read_lock();\n\tcgrp = rcu_dereference(*(void __rcu __force **)&kn->priv);\n\tif (!cgrp || !cgroup_tryget(cgrp)) {\n\t\trcu_read_unlock();\n\t\treturn -ENOENT;\n\t}\n\trcu_read_unlock();\n\n\tcss_task_iter_start(&cgrp->self, 0, &it);\n\twhile ((tsk = css_task_iter_next(&it))) {\n\t\tswitch (READ_ONCE(tsk->__state)) {\n\t\tcase TASK_RUNNING:\n\t\t\tstats->nr_running++;\n\t\t\tbreak;\n\t\tcase TASK_INTERRUPTIBLE:\n\t\t\tstats->nr_sleeping++;\n\t\t\tbreak;\n\t\tcase TASK_UNINTERRUPTIBLE:\n\t\t\tstats->nr_uninterruptible++;\n\t\t\tbreak;\n\t\tcase TASK_STOPPED:\n\t\t\tstats->nr_stopped++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (tsk->in_iowait)\n\t\t\t\tstats->nr_io_wait++;\n\t\t\tbreak;\n\t\t}\n\t}\n\tcss_task_iter_end(&it);\n\n\tcgroup_put(cgrp);\n\treturn 0;\n}"
  },
  {
    "function_name": "proc_cgroupstats_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "658-676",
    "snippet": "int proc_cgroupstats_show(struct seq_file *m, void *v)\n{\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n\tseq_puts(m, \"#subsys_name\\thierarchy\\tnum_cgroups\\tenabled\\n\");\n\t/*\n\t * Grab the subsystems state racily. No need to add avenue to\n\t * cgroup_mutex contention.\n\t */\n\n\tfor_each_subsys(ss, i)\n\t\tseq_printf(m, \"%s\\t%d\\t%d\\t%d\\n\",\n\t\t\t   ss->legacy_name, ss->root->hierarchy_id,\n\t\t\t   atomic_read(&ss->root->nr_cgrps),\n\t\t\t   cgroup_ssid_enabled(i));\n\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "seq_printf",
          "args": [
            "m",
            "\"%s\\t%d\\t%d\\t%d\\n\"",
            "ss->legacy_name",
            "ss->root->hierarchy_id",
            "atomic_read(&ss->root->nr_cgrps)",
            "cgroup_ssid_enabled(i)"
          ],
          "line": 670
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_printf",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "81-100",
          "snippet": "void trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_ssid_enabled",
          "args": [
            "i"
          ],
          "line": 673
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_ssid_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "258-264",
          "snippet": "bool cgroup_ssid_enabled(int ssid)\n{\n\tif (!CGROUP_HAS_SUBSYS_CONFIG)\n\t\treturn false;\n\n\treturn static_key_enabled(cgroup_subsys_enabled_key[ssid]);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct static_key_true *cgroup_subsys_enabled_key[] = {\n#include <linux/cgroup_subsys.h>\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct static_key_true *cgroup_subsys_enabled_key[] = {\n#include <linux/cgroup_subsys.h>\n};\n\nbool cgroup_ssid_enabled(int ssid)\n{\n\tif (!CGROUP_HAS_SUBSYS_CONFIG)\n\t\treturn false;\n\n\treturn static_key_enabled(cgroup_subsys_enabled_key[ssid]);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&ss->root->nr_cgrps"
          ],
          "line": 672
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_subsys",
          "args": [
            "ss",
            "i"
          ],
          "line": 669
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "seq_puts",
          "args": [
            "m",
            "\"#subsys_name\\thierarchy\\tnum_cgroups\\tenabled\\n\""
          ],
          "line": 663
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "205-220",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nint proc_cgroupstats_show(struct seq_file *m, void *v)\n{\n\tstruct cgroup_subsys *ss;\n\tint i;\n\n\tseq_puts(m, \"#subsys_name\\thierarchy\\tnum_cgroups\\tenabled\\n\");\n\t/*\n\t * Grab the subsystems state racily. No need to add avenue to\n\t * cgroup_mutex contention.\n\t */\n\n\tfor_each_subsys(ss, i)\n\t\tseq_printf(m, \"%s\\t%d\\t%d\\t%d\\n\",\n\t\t\t   ss->legacy_name, ss->root->hierarchy_id,\n\t\t\t   atomic_read(&ss->root->nr_cgrps),\n\t\t\t   cgroup_ssid_enabled(i));\n\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_clone_children_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "602-610",
    "snippet": "static int cgroup_clone_children_write(struct cgroup_subsys_state *css,\n\t\t\t\t       struct cftype *cft, u64 val)\n{\n\tif (val)\n\t\tset_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);\n\telse\n\t\tclear_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "clear_bit",
          "args": [
            "CGRP_CPUSET_CLONE_CHILDREN",
            "&css->cgroup->flags"
          ],
          "line": 608
        },
        "resolved": true,
        "details": {
          "function_name": "memory_bm_clear_bit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/power/snapshot.c",
          "lines": "830-839",
          "snippet": "static void memory_bm_clear_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\tclear_bit(bit, addr);\n}",
          "includes": [
            "#include \"power.h\"",
            "#include <asm/io.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/ktime.h>",
            "#include <linux/compiler.h>",
            "#include <linux/slab.h>",
            "#include <linux/list.h>",
            "#include <linux/highmem.h>",
            "#include <linux/console.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/nmi.h>",
            "#include <linux/memblock.h>",
            "#include <linux/init.h>",
            "#include <linux/device.h>",
            "#include <linux/pm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bitops.h>",
            "#include <linux/delay.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/version.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"power.h\"\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <linux/set_memory.h>\n#include <linux/ktime.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/console.h>\n#include <linux/syscalls.h>\n#include <linux/nmi.h>\n#include <linux/memblock.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/pm.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/suspend.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/version.h>\n\nstatic void memory_bm_clear_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\tclear_bit(bit, addr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_bit",
          "args": [
            "CGRP_CPUSET_CLONE_CHILDREN",
            "&css->cgroup->flags"
          ],
          "line": 606
        },
        "resolved": true,
        "details": {
          "function_name": "mem_bm_set_bit_check",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/power/snapshot.c",
          "lines": "817-828",
          "snippet": "static int mem_bm_set_bit_check(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tif (!error)\n\t\tset_bit(bit, addr);\n\n\treturn error;\n}",
          "includes": [
            "#include \"power.h\"",
            "#include <asm/io.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/ktime.h>",
            "#include <linux/compiler.h>",
            "#include <linux/slab.h>",
            "#include <linux/list.h>",
            "#include <linux/highmem.h>",
            "#include <linux/console.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/nmi.h>",
            "#include <linux/memblock.h>",
            "#include <linux/init.h>",
            "#include <linux/device.h>",
            "#include <linux/pm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bitops.h>",
            "#include <linux/delay.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/version.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"power.h\"\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <linux/set_memory.h>\n#include <linux/ktime.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/console.h>\n#include <linux/syscalls.h>\n#include <linux/nmi.h>\n#include <linux/memblock.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/pm.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/suspend.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/version.h>\n\nstatic int mem_bm_set_bit_check(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tif (!error)\n\t\tset_bit(bit, addr);\n\n\treturn error;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_clone_children_write(struct cgroup_subsys_state *css,\n\t\t\t\t       struct cftype *cft, u64 val)\n{\n\tif (val)\n\t\tset_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);\n\telse\n\t\tclear_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_clone_children_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "596-600",
    "snippet": "static u64 cgroup_clone_children_read(struct cgroup_subsys_state *css,\n\t\t\t\t      struct cftype *cft)\n{\n\treturn test_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "test_bit",
          "args": [
            "CGRP_CPUSET_CLONE_CHILDREN",
            "&css->cgroup->flags"
          ],
          "line": 599
        },
        "resolved": true,
        "details": {
          "function_name": "memory_bm_test_bit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/power/snapshot.c",
          "lines": "849-858",
          "snippet": "static int memory_bm_test_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\treturn test_bit(bit, addr);\n}",
          "includes": [
            "#include \"power.h\"",
            "#include <asm/io.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/ktime.h>",
            "#include <linux/compiler.h>",
            "#include <linux/slab.h>",
            "#include <linux/list.h>",
            "#include <linux/highmem.h>",
            "#include <linux/console.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/nmi.h>",
            "#include <linux/memblock.h>",
            "#include <linux/init.h>",
            "#include <linux/device.h>",
            "#include <linux/pm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bitops.h>",
            "#include <linux/delay.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/version.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"power.h\"\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <linux/set_memory.h>\n#include <linux/ktime.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/console.h>\n#include <linux/syscalls.h>\n#include <linux/nmi.h>\n#include <linux/memblock.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/pm.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/suspend.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/version.h>\n\nstatic int memory_bm_test_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\treturn test_bit(bit, addr);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic u64 cgroup_clone_children_read(struct cgroup_subsys_state *css,\n\t\t\t\t      struct cftype *cft)\n{\n\treturn test_bit(CGRP_CPUSET_CLONE_CHILDREN, &css->cgroup->flags);\n}"
  },
  {
    "function_name": "cgroup_write_notify_on_release",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "586-594",
    "snippet": "static int cgroup_write_notify_on_release(struct cgroup_subsys_state *css,\n\t\t\t\t\t  struct cftype *cft, u64 val)\n{\n\tif (val)\n\t\tset_bit(CGRP_NOTIFY_ON_RELEASE, &css->cgroup->flags);\n\telse\n\t\tclear_bit(CGRP_NOTIFY_ON_RELEASE, &css->cgroup->flags);\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "clear_bit",
          "args": [
            "CGRP_NOTIFY_ON_RELEASE",
            "&css->cgroup->flags"
          ],
          "line": 592
        },
        "resolved": true,
        "details": {
          "function_name": "memory_bm_clear_bit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/power/snapshot.c",
          "lines": "830-839",
          "snippet": "static void memory_bm_clear_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\tclear_bit(bit, addr);\n}",
          "includes": [
            "#include \"power.h\"",
            "#include <asm/io.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/ktime.h>",
            "#include <linux/compiler.h>",
            "#include <linux/slab.h>",
            "#include <linux/list.h>",
            "#include <linux/highmem.h>",
            "#include <linux/console.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/nmi.h>",
            "#include <linux/memblock.h>",
            "#include <linux/init.h>",
            "#include <linux/device.h>",
            "#include <linux/pm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bitops.h>",
            "#include <linux/delay.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/version.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"power.h\"\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <linux/set_memory.h>\n#include <linux/ktime.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/console.h>\n#include <linux/syscalls.h>\n#include <linux/nmi.h>\n#include <linux/memblock.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/pm.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/suspend.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/version.h>\n\nstatic void memory_bm_clear_bit(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tBUG_ON(error);\n\tclear_bit(bit, addr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_bit",
          "args": [
            "CGRP_NOTIFY_ON_RELEASE",
            "&css->cgroup->flags"
          ],
          "line": 590
        },
        "resolved": true,
        "details": {
          "function_name": "mem_bm_set_bit_check",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/power/snapshot.c",
          "lines": "817-828",
          "snippet": "static int mem_bm_set_bit_check(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tif (!error)\n\t\tset_bit(bit, addr);\n\n\treturn error;\n}",
          "includes": [
            "#include \"power.h\"",
            "#include <asm/io.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/set_memory.h>",
            "#include <linux/ktime.h>",
            "#include <linux/compiler.h>",
            "#include <linux/slab.h>",
            "#include <linux/list.h>",
            "#include <linux/highmem.h>",
            "#include <linux/console.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/nmi.h>",
            "#include <linux/memblock.h>",
            "#include <linux/init.h>",
            "#include <linux/device.h>",
            "#include <linux/pm.h>",
            "#include <linux/kernel.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/bitops.h>",
            "#include <linux/delay.h>",
            "#include <linux/suspend.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>",
            "#include <linux/version.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"power.h\"\n#include <asm/io.h>\n#include <asm/tlbflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <linux/set_memory.h>\n#include <linux/ktime.h>\n#include <linux/compiler.h>\n#include <linux/slab.h>\n#include <linux/list.h>\n#include <linux/highmem.h>\n#include <linux/console.h>\n#include <linux/syscalls.h>\n#include <linux/nmi.h>\n#include <linux/memblock.h>\n#include <linux/init.h>\n#include <linux/device.h>\n#include <linux/pm.h>\n#include <linux/kernel.h>\n#include <linux/spinlock.h>\n#include <linux/bitops.h>\n#include <linux/delay.h>\n#include <linux/suspend.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/version.h>\n\nstatic int mem_bm_set_bit_check(struct memory_bitmap *bm, unsigned long pfn)\n{\n\tvoid *addr;\n\tunsigned int bit;\n\tint error;\n\n\terror = memory_bm_find_bit(bm, pfn, &addr, &bit);\n\tif (!error)\n\t\tset_bit(bit, addr);\n\n\treturn error;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_write_notify_on_release(struct cgroup_subsys_state *css,\n\t\t\t\t\t  struct cftype *cft, u64 val)\n{\n\tif (val)\n\t\tset_bit(CGRP_NOTIFY_ON_RELEASE, &css->cgroup->flags);\n\telse\n\t\tclear_bit(CGRP_NOTIFY_ON_RELEASE, &css->cgroup->flags);\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_read_notify_on_release",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "580-584",
    "snippet": "static u64 cgroup_read_notify_on_release(struct cgroup_subsys_state *css,\n\t\t\t\t\t struct cftype *cft)\n{\n\treturn notify_on_release(css->cgroup);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "notify_on_release",
          "args": [
            "css->cgroup"
          ],
          "line": 583
        },
        "resolved": true,
        "details": {
          "function_name": "notify_on_release",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-internal.h",
          "lines": "192-195",
          "snippet": "static inline bool notify_on_release(const struct cgroup *cgrp)\n{\n\treturn test_bit(CGRP_NOTIFY_ON_RELEASE, &cgrp->flags);\n}",
          "includes": [
            "#include <linux/fs_parser.h>",
            "#include <linux/refcount.h>",
            "#include <linux/list.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/kernfs.h>",
            "#include <linux/cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/fs_parser.h>\n#include <linux/refcount.h>\n#include <linux/list.h>\n#include <linux/workqueue.h>\n#include <linux/kernfs.h>\n#include <linux/cgroup.h>\n\nstatic inline bool notify_on_release(const struct cgroup *cgrp)\n{\n\treturn test_bit(CGRP_NOTIFY_ON_RELEASE, &cgrp->flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic u64 cgroup_read_notify_on_release(struct cgroup_subsys_state *css,\n\t\t\t\t\t struct cftype *cft)\n{\n\treturn notify_on_release(css->cgroup);\n}"
  },
  {
    "function_name": "cgroup_sane_behavior_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "574-578",
    "snippet": "static int cgroup_sane_behavior_show(struct seq_file *seq, void *v)\n{\n\tseq_puts(seq, \"0\\n\");\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "seq_puts",
          "args": [
            "seq",
            "\"0\\n\""
          ],
          "line": 576
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "205-220",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_sane_behavior_show(struct seq_file *seq, void *v)\n{\n\tseq_puts(seq, \"0\\n\");\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_release_agent_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "563-572",
    "snippet": "static int cgroup_release_agent_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tspin_lock(&release_agent_path_lock);\n\tseq_puts(seq, cgrp->root->release_agent_path);\n\tspin_unlock(&release_agent_path_lock);\n\tseq_putc(seq, '\\n');\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_SPINLOCK(release_agent_path_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "seq_putc",
          "args": [
            "seq",
            "'\\n'"
          ],
          "line": 570
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_putc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "233-246",
          "snippet": "void trace_seq_putc(struct trace_seq *s, unsigned char c)\n{\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (TRACE_SEQ_BUF_LEFT(s) < 1) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putc(&s->seq, c);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_putc(struct trace_seq *s, unsigned char c)\n{\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (TRACE_SEQ_BUF_LEFT(s) < 1) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putc(&s->seq, c);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 569
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_puts",
          "args": [
            "seq",
            "cgrp->root->release_agent_path"
          ],
          "line": 568
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_puts",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "205-220",
          "snippet": "void trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_puts(struct trace_seq *s, const char *str)\n{\n\tunsigned int len = strlen(str);\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tif (len > TRACE_SEQ_BUF_LEFT(s)) {\n\t\ts->full = 1;\n\t\treturn;\n\t}\n\n\tseq_buf_putmem(&s->seq, str, len);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 567
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_css",
          "args": [
            "seq"
          ],
          "line": 565
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic DEFINE_SPINLOCK(release_agent_path_lock);\n\nstatic int cgroup_release_agent_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tspin_lock(&release_agent_path_lock);\n\tseq_puts(seq, cgrp->root->release_agent_path);\n\tspin_unlock(&release_agent_path_lock);\n\tseq_putc(seq, '\\n');\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_release_agent_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "545-561",
    "snippet": "static ssize_t cgroup_release_agent_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\n\tBUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\tspin_lock(&release_agent_path_lock);\n\tstrlcpy(cgrp->root->release_agent_path, strstrip(buf),\n\t\tsizeof(cgrp->root->release_agent_path));\n\tspin_unlock(&release_agent_path_lock);\n\tcgroup_kn_unlock(of->kn);\n\treturn nbytes;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_SPINLOCK(release_agent_path_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cgroup_kn_unlock",
          "args": [
            "of->kn"
          ],
          "line": 559
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_kn_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1583-1596",
          "snippet": "void cgroup_kn_unlock(struct kernfs_node *kn)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tkernfs_unbreak_active_protection(kn);\n\tcgroup_put(cgrp);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nvoid cgroup_kn_unlock(struct kernfs_node *kn)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tkernfs_unbreak_active_protection(kn);\n\tcgroup_put(cgrp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 558
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "strlcpy",
          "args": [
            "cgrp->root->release_agent_path",
            "strstrip(buf)",
            "sizeof(cgrp->root->release_agent_path)"
          ],
          "line": 556
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strstrip",
          "args": [
            "buf"
          ],
          "line": 556
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&release_agent_path_lock"
          ],
          "line": 555
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_kn_lock_live",
          "args": [
            "of->kn",
            "false"
          ],
          "line": 552
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_kn_lock_live",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1615-1644",
          "snippet": "struct cgroup *cgroup_kn_lock_live(struct kernfs_node *kn, bool drain_offline)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\t/*\n\t * We're gonna grab cgroup_mutex which nests outside kernfs\n\t * active_ref.  cgroup liveliness check alone provides enough\n\t * protection against removal.  Ensure @cgrp stays accessible and\n\t * break the active_ref protection.\n\t */\n\tif (!cgroup_tryget(cgrp))\n\t\treturn NULL;\n\tkernfs_break_active_protection(kn);\n\n\tif (drain_offline)\n\t\tcgroup_lock_and_drain_offline(cgrp);\n\telse\n\t\tmutex_lock(&cgroup_mutex);\n\n\tif (!cgroup_is_dead(cgrp))\n\t\treturn cgrp;\n\n\tcgroup_kn_unlock(kn);\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nstruct cgroup *cgroup_kn_lock_live(struct kernfs_node *kn, bool drain_offline)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\t/*\n\t * We're gonna grab cgroup_mutex which nests outside kernfs\n\t * active_ref.  cgroup liveliness check alone provides enough\n\t * protection against removal.  Ensure @cgrp stays accessible and\n\t * break the active_ref protection.\n\t */\n\tif (!cgroup_tryget(cgrp))\n\t\treturn NULL;\n\tkernfs_break_active_protection(kn);\n\n\tif (drain_offline)\n\t\tcgroup_lock_and_drain_offline(cgrp);\n\telse\n\t\tmutex_lock(&cgroup_mutex);\n\n\tif (!cgroup_is_dead(cgrp))\n\t\treturn cgrp;\n\n\tcgroup_kn_unlock(kn);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "sizeof(cgrp->root->release_agent_path) < PATH_MAX"
          ],
          "line": 550
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic DEFINE_SPINLOCK(release_agent_path_lock);\n\nstatic ssize_t cgroup_release_agent_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\n\tBUILD_BUG_ON(sizeof(cgrp->root->release_agent_path) < PATH_MAX);\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\tspin_lock(&release_agent_path_lock);\n\tstrlcpy(cgrp->root->release_agent_path, strstrip(buf),\n\t\tsizeof(cgrp->root->release_agent_path));\n\tspin_unlock(&release_agent_path_lock);\n\tcgroup_kn_unlock(of->kn);\n\treturn nbytes;\n}"
  },
  {
    "function_name": "cgroup1_tasks_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "539-543",
    "snippet": "static ssize_t cgroup1_tasks_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\treturn __cgroup1_procs_write(of, buf, nbytes, off, false);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cgroup1_procs_write",
          "args": [
            "of",
            "buf",
            "nbytes",
            "off",
            "false"
          ],
          "line": 542
        },
        "resolved": true,
        "details": {
          "function_name": "__cgroup1_procs_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "489-531",
          "snippet": "static ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t     char *buf, size_t nbytes, loff_t off,\n\t\t\t\t     bool threadgroup)\n{\n\tstruct cgroup *cgrp;\n\tstruct task_struct *task;\n\tconst struct cred *cred, *tcred;\n\tssize_t ret;\n\tbool locked;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);\n\tret = PTR_ERR_OR_ZERO(task);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/*\n\t * Even if we're attaching all tasks in the thread group, we only need\n\t * to check permissions on one of them. Check permissions using the\n\t * credentials from file open to protect against inherited fd attacks.\n\t */\n\tcred = of->file->f_cred;\n\ttcred = get_task_cred(task);\n\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&\n\t    !uid_eq(cred->euid, tcred->uid) &&\n\t    !uid_eq(cred->euid, tcred->suid))\n\t\tret = -EACCES;\n\tput_cred(tcred);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tret = cgroup_attach_task(cgrp, task, threadgroup);\n\nout_finish:\n\tcgroup_procs_write_finish(task, locked);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t     char *buf, size_t nbytes, loff_t off,\n\t\t\t\t     bool threadgroup)\n{\n\tstruct cgroup *cgrp;\n\tstruct task_struct *task;\n\tconst struct cred *cred, *tcred;\n\tssize_t ret;\n\tbool locked;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);\n\tret = PTR_ERR_OR_ZERO(task);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/*\n\t * Even if we're attaching all tasks in the thread group, we only need\n\t * to check permissions on one of them. Check permissions using the\n\t * credentials from file open to protect against inherited fd attacks.\n\t */\n\tcred = of->file->f_cred;\n\ttcred = get_task_cred(task);\n\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&\n\t    !uid_eq(cred->euid, tcred->uid) &&\n\t    !uid_eq(cred->euid, tcred->suid))\n\t\tret = -EACCES;\n\tput_cred(tcred);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tret = cgroup_attach_task(cgrp, task, threadgroup);\n\nout_finish:\n\tcgroup_procs_write_finish(task, locked);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic ssize_t cgroup1_tasks_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\treturn __cgroup1_procs_write(of, buf, nbytes, off, false);\n}"
  },
  {
    "function_name": "cgroup1_procs_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "533-537",
    "snippet": "static ssize_t cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\treturn __cgroup1_procs_write(of, buf, nbytes, off, true);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cgroup1_procs_write",
          "args": [
            "of",
            "buf",
            "nbytes",
            "off",
            "true"
          ],
          "line": 536
        },
        "resolved": true,
        "details": {
          "function_name": "__cgroup1_procs_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "489-531",
          "snippet": "static ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t     char *buf, size_t nbytes, loff_t off,\n\t\t\t\t     bool threadgroup)\n{\n\tstruct cgroup *cgrp;\n\tstruct task_struct *task;\n\tconst struct cred *cred, *tcred;\n\tssize_t ret;\n\tbool locked;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);\n\tret = PTR_ERR_OR_ZERO(task);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/*\n\t * Even if we're attaching all tasks in the thread group, we only need\n\t * to check permissions on one of them. Check permissions using the\n\t * credentials from file open to protect against inherited fd attacks.\n\t */\n\tcred = of->file->f_cred;\n\ttcred = get_task_cred(task);\n\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&\n\t    !uid_eq(cred->euid, tcred->uid) &&\n\t    !uid_eq(cred->euid, tcred->suid))\n\t\tret = -EACCES;\n\tput_cred(tcred);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tret = cgroup_attach_task(cgrp, task, threadgroup);\n\nout_finish:\n\tcgroup_procs_write_finish(task, locked);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t     char *buf, size_t nbytes, loff_t off,\n\t\t\t\t     bool threadgroup)\n{\n\tstruct cgroup *cgrp;\n\tstruct task_struct *task;\n\tconst struct cred *cred, *tcred;\n\tssize_t ret;\n\tbool locked;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);\n\tret = PTR_ERR_OR_ZERO(task);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/*\n\t * Even if we're attaching all tasks in the thread group, we only need\n\t * to check permissions on one of them. Check permissions using the\n\t * credentials from file open to protect against inherited fd attacks.\n\t */\n\tcred = of->file->f_cred;\n\ttcred = get_task_cred(task);\n\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&\n\t    !uid_eq(cred->euid, tcred->uid) &&\n\t    !uid_eq(cred->euid, tcred->suid))\n\t\tret = -EACCES;\n\tput_cred(tcred);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tret = cgroup_attach_task(cgrp, task, threadgroup);\n\nout_finish:\n\tcgroup_procs_write_finish(task, locked);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic ssize_t cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\treturn __cgroup1_procs_write(of, buf, nbytes, off, true);\n}"
  },
  {
    "function_name": "__cgroup1_procs_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "489-531",
    "snippet": "static ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t     char *buf, size_t nbytes, loff_t off,\n\t\t\t\t     bool threadgroup)\n{\n\tstruct cgroup *cgrp;\n\tstruct task_struct *task;\n\tconst struct cred *cred, *tcred;\n\tssize_t ret;\n\tbool locked;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);\n\tret = PTR_ERR_OR_ZERO(task);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/*\n\t * Even if we're attaching all tasks in the thread group, we only need\n\t * to check permissions on one of them. Check permissions using the\n\t * credentials from file open to protect against inherited fd attacks.\n\t */\n\tcred = of->file->f_cred;\n\ttcred = get_task_cred(task);\n\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&\n\t    !uid_eq(cred->euid, tcred->uid) &&\n\t    !uid_eq(cred->euid, tcred->suid))\n\t\tret = -EACCES;\n\tput_cred(tcred);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tret = cgroup_attach_task(cgrp, task, threadgroup);\n\nout_finish:\n\tcgroup_procs_write_finish(task, locked);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cgroup_kn_unlock",
          "args": [
            "of->kn"
          ],
          "line": 528
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_kn_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1583-1596",
          "snippet": "void cgroup_kn_unlock(struct kernfs_node *kn)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tkernfs_unbreak_active_protection(kn);\n\tcgroup_put(cgrp);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nvoid cgroup_kn_unlock(struct kernfs_node *kn)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\tmutex_unlock(&cgroup_mutex);\n\n\tkernfs_unbreak_active_protection(kn);\n\tcgroup_put(cgrp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_procs_write_finish",
          "args": [
            "task",
            "locked"
          ],
          "line": 526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_attach_task",
          "args": [
            "cgrp",
            "task",
            "threadgroup"
          ],
          "line": 523
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_attach_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2783-4623",
          "snippet": "int cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,\n\t\t       bool threadgroup)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct task_struct *task;\n\tint ret = 0;\n\n\t/* look up all src csets */\n\tspin_lock_irq(&css_set_lock);\n\trcu_read_lock();\n\ttask = leader;\n\tdo {\n\t\tcgroup_migrate_add_src(task_css_set(task), dst_cgrp, &mgctx);\n\t\tif (!threadgroup)\n\t\t\tbreak;\n\t} while_each_thread(leader, task);\n\trcu_read_unlock();\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* prepare dst csets and commit */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (!ret)\n\t\tret = cgroup_migrate(leader, threadgroup, &mgctx);\n\n\tcgroup_migrate_finish(&mgctx);\n\n\tif (!ret)\n\t\tTRACE_CGROUP_PATH(attach_task, dst_cgrp, leader, threadgroup);\n\n\treturn ret;\n}\n\nstruct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup,\n\t\t\t\t\t     bool *locked)\n\t__acquires(&cgroup_threadgroup_rwsem)\n{\n\tstruct task_struct *tsk;\n\tpid_t pid;\n\n\tif (kstrtoint(strstrip(buf), 0, &pid) || pid < 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * If we migrate a single thread, we don't care about threadgroup\n\t * stability. If the thread is `current`, it won't exit(2) under our\n\t * hands or change PID through exec(2). We exclude\n\t * cgroup_update_dfl_csses and other cgroup_{proc,thread}s_write\n\t * callers by cgroup_mutex.\n\t * Therefore, we can skip the global lock.\n\t */\n\tlockdep_assert_held(&cgroup_mutex);\n\tif (pid || threadgroup) {\n\t\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = true;\n\t} else {\n\t\t*locked = false;\n\t}\n\n\trcu_read_lock();\n\tif (pid) {\n\t\ttsk = find_task_by_vpid(pid);\n\t\tif (!tsk) {\n\t\t\ttsk = ERR_PTR(-ESRCH);\n\t\t\tgoto out_unlock_threadgroup;\n\t\t}\n\t} else {\n\t\ttsk = current;\n\t}\n\n\tif (threadgroup)\n\t\ttsk = tsk->group_leader;\n\n\t/*\n\t * kthreads may acquire PF_NO_SETAFFINITY during initialization.\n\t * If userland migrates such a kthread to a non-root cgroup, it can\n\t * become trapped in a cpuset, or RT kthread may be born in a\n\t * cgroup with no rt_runtime allocated.  Just say no.\n\t */\n\tif (tsk->no_cgroup_migration || (tsk->flags & PF_NO_SETAFFINITY)) {\n\t\ttsk = ERR_PTR(-EINVAL);\n\t\tgoto out_unlock_threadgroup;\n\t}\n\n\tget_task_struct(tsk);\n\tgoto out_unlock_rcu;\n\nout_unlock_threadgroup:\n\tif (*locked) {\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = false;\n\t}\nout_unlock_rcu:\n\trcu_read_unlock();\n\treturn tsk;\n}\n\nvoid cgroup_procs_write_finish(struct task_struct *task, bool locked)\n\t__releases(&cgroup_threadgroup_rwsem)\n{\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\t/* release reference from cgroup_procs_write_start() */\n\tput_task_struct(task);\n\n\tif (locked)\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tfor_each_subsys(ss, ssid)\n\t\tif (ss->post_attach)\n\t\t\tss->post_attach();\n}\n\nstatic void cgroup_print_ss_mask(struct seq_file *seq, u16 ss_mask)\n{\n\tstruct cgroup_subsys *ss;\n\tbool printed = false;\n\tint ssid;\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\tif (printed)\n\t\t\tseq_putc(seq, ' ');\n\t\tseq_puts(seq, ss->name);\n\t\tprinted = true;\n\t} while_each_subsys_mask();\n\tif (printed)\n\t\tseq_putc(seq, '\\n');\n}\n\n/* show controllers which are enabled from the parent */\nstatic int cgroup_controllers_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgroup_control(cgrp));\n\treturn 0;\n}\n\n/* show controllers which are enabled for a given cgroup's children */\nstatic int cgroup_subtree_control_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgrp->subtree_control);\n\treturn 0;\n}\n\n/**\n * cgroup_update_dfl_csses - update css assoc of a subtree in default hierarchy\n * @cgrp: root of the subtree to update csses for\n *\n * @cgrp's control masks have changed and its subtree's css associations\n * need to be updated accordingly.  This function looks up all css_sets\n * which are attached to the subtree, creates the matching updated css_sets\n * and migrates the tasks to the new ones.\n */\nstatic int cgroup_update_dfl_csses(struct cgroup *cgrp)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup *dsct;\n\tstruct css_set *src_cset;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\n\t/* look up all csses currently attached to @cgrp's subtree */\n\tspin_lock_irq(&css_set_lock);\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tstruct cgrp_cset_link *link;\n\n\t\tlist_for_each_entry(link, &dsct->cset_links, cset_link)\n\t\t\tcgroup_migrate_add_src(link->cset, dsct, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* NULL dst indicates self on default hierarchy */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tspin_lock_irq(&css_set_lock);\n\tlist_for_each_entry(src_cset, &mgctx.preloaded_src_csets, mg_preload_node) {\n\t\tstruct task_struct *task, *ntask;\n\n\t\t/* all tasks in src_csets need to be migrated */\n\t\tlist_for_each_entry_safe(task, ntask, &src_cset->tasks, cg_list)\n\t\t\tcgroup_migrate_add_task(task, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\tret = cgroup_migrate_execute(&mgctx);\nout_finish:\n\tcgroup_migrate_finish(&mgctx);\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\treturn ret;\n}\n\n/**\n * cgroup_lock_and_drain_offline - lock cgroup_mutex and drain offlined csses\n * @cgrp: root of the target subtree\n *\n * Because css offlining is asynchronous, userland may try to re-enable a\n * controller while the previous css is still around.  This function grabs\n * cgroup_mutex and drains the previous css instances of @cgrp's subtree.\n */\nvoid cgroup_lock_and_drain_offline(struct cgroup *cgrp)\n\t__acquires(&cgroup_mutex)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\nrestart:\n\tmutex_lock(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\t\t\tDEFINE_WAIT(wait);\n\n\t\t\tif (!css || !percpu_ref_is_dying(&css->refcnt))\n\t\t\t\tcontinue;\n\n\t\t\tcgroup_get_live(dsct);\n\t\t\tprepare_to_wait(&dsct->offline_waitq, &wait,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE);\n\n\t\t\tmutex_unlock(&cgroup_mutex);\n\t\t\tschedule();\n\t\t\tfinish_wait(&dsct->offline_waitq, &wait);\n\n\t\t\tcgroup_put(dsct);\n\t\t\tgoto restart;\n\t\t}\n\t}\n}\n\n/**\n * cgroup_save_control - save control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Save ->subtree_control, ->subtree_ss_mask and ->dom_cgrp to the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_save_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->old_subtree_control = dsct->subtree_control;\n\t\tdsct->old_subtree_ss_mask = dsct->subtree_ss_mask;\n\t\tdsct->old_dom_cgrp = dsct->dom_cgrp;\n\t}\n}\n\n/**\n * cgroup_propagate_control - refresh control masks of a subtree\n * @cgrp: root of the target subtree\n *\n * For @cgrp and its subtree, ensure ->subtree_ss_mask matches\n * ->subtree_control and propagate controller availability through the\n * subtree so that descendants don't have unavailable controllers enabled.\n */\nstatic void cgroup_propagate_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control &= cgroup_control(dsct);\n\t\tdsct->subtree_ss_mask =\n\t\t\tcgroup_calc_subtree_ss_mask(dsct->subtree_control,\n\t\t\t\t\t\t    cgroup_ss_mask(dsct));\n\t}\n}\n\n/**\n * cgroup_restore_control - restore control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Restore ->subtree_control, ->subtree_ss_mask and ->dom_cgrp from the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_restore_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control = dsct->old_subtree_control;\n\t\tdsct->subtree_ss_mask = dsct->old_subtree_ss_mask;\n\t\tdsct->dom_cgrp = dsct->old_dom_cgrp;\n\t}\n}\n\nstatic bool css_visible(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys *ss = css->ss;\n\tstruct cgroup *cgrp = css->cgroup;\n\n\tif (cgroup_control(cgrp) & (1 << ss->id))\n\t\treturn true;\n\tif (!(cgroup_ss_mask(cgrp) & (1 << ss->id)))\n\t\treturn false;\n\treturn cgroup_on_dfl(cgrp) && ss->implicit_on_dfl;\n}\n\n/**\n * cgroup_apply_control_enable - enable or show csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and create new csses or make the existing ones\n * visible.  A css is created invisible if it's being implicitly enabled\n * through dependency.  An invisible css is made visible when the userland\n * explicitly enables it.\n *\n * Returns 0 on success, -errno on failure.  On failure, csses which have\n * been processed already aren't cleaned up.  The caller is responsible for\n * cleaning up with cgroup_apply_control_disable().\n */\nstatic int cgroup_apply_control_enable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid, ret;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!(cgroup_ss_mask(dsct) & (1 << ss->id)))\n\t\t\t\tcontinue;\n\n\t\t\tif (!css) {\n\t\t\t\tcss = css_create(dsct, ss);\n\t\t\t\tif (IS_ERR(css))\n\t\t\t\t\treturn PTR_ERR(css);\n\t\t\t}\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css_visible(css)) {\n\t\t\t\tret = css_populate_dir(css);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_apply_control_disable - kill or hide csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and kill and hide csses so that they match\n * cgroup_ss_mask() and cgroup_visible_mask().\n *\n * A css is hidden when the userland requests it to be disabled while other\n * subsystems are still depending on it.  The css must not actively control\n * resources and be in the vanilla state if it's made visible again later.\n * Controllers which may be depended upon should provide ->css_reset() for\n * this purpose.\n */\nstatic void cgroup_apply_control_disable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!css)\n\t\t\t\tcontinue;\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css->parent &&\n\t\t\t    !(cgroup_ss_mask(dsct) & (1 << ss->id))) {\n\t\t\t\tkill_css(css);\n\t\t\t} else if (!css_visible(css)) {\n\t\t\t\tcss_clear_dir(css);\n\t\t\t\tif (ss->css_reset)\n\t\t\t\t\tss->css_reset(css);\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * cgroup_apply_control - apply control mask updates to the subtree\n * @cgrp: root of the target subtree\n *\n * subsystems can be enabled and disabled in a subtree using the following\n * steps.\n *\n * 1. Call cgroup_save_control() to stash the current state.\n * 2. Update ->subtree_control masks in the subtree as desired.\n * 3. Call cgroup_apply_control() to apply the changes.\n * 4. Optionally perform other related operations.\n * 5. Call cgroup_finalize_control() to finish up.\n *\n * This function implements step 3 and propagates the mask changes\n * throughout @cgrp's subtree, updates csses accordingly and perform\n * process migrations.\n */\nstatic int cgroup_apply_control(struct cgroup *cgrp)\n{\n\tint ret;\n\n\tcgroup_propagate_control(cgrp);\n\n\tret = cgroup_apply_control_enable(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * At this point, cgroup_e_css_by_mask() results reflect the new csses\n\t * making the following cgroup_update_dfl_csses() properly update\n\t * css associations of all tasks in the subtree.\n\t */\n\tret = cgroup_update_dfl_csses(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/**\n * cgroup_finalize_control - finalize control mask update\n * @cgrp: root of the target subtree\n * @ret: the result of the update\n *\n * Finalize control mask update.  See cgroup_apply_control() for more info.\n */\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret)\n{\n\tif (ret) {\n\t\tcgroup_restore_control(cgrp);\n\t\tcgroup_propagate_control(cgrp);\n\t}\n\n\tcgroup_apply_control_disable(cgrp);\n}\n\nstatic int cgroup_vet_subtree_control_enable(struct cgroup *cgrp, u16 enable)\n{\n\tu16 domain_enable = enable & ~cgrp_dfl_threaded_ss_mask;\n\n\t/* if nothing is getting enabled, nothing to worry about */\n\tif (!enable)\n\t\treturn 0;\n\n\t/* can @cgrp host any resources? */\n\tif (!cgroup_is_valid_domain(cgrp->dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/* mixables don't care */\n\tif (cgroup_is_mixable(cgrp))\n\t\treturn 0;\n\n\tif (domain_enable) {\n\t\t/* can't enable domain controllers inside a thread subtree */\n\t\tif (cgroup_is_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn -EOPNOTSUPP;\n\t} else {\n\t\t/*\n\t\t * Threaded controllers can handle internal competitions\n\t\t * and are always allowed inside a (prospective) thread\n\t\t * subtree.\n\t\t */\n\t\tif (cgroup_can_be_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * Controllers can't be enabled for a cgroup with tasks to avoid\n\t * child cgroups competing against tasks.\n\t */\n\tif (cgroup_has_tasks(cgrp))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\n/* change the enabled child controllers for a cgroup in the default hierarchy */\nstatic ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,\n\t\t\t\t\t    char *buf, size_t nbytes,\n\t\t\t\t\t    loff_t off)\n{\n\tu16 enable = 0, disable = 0;\n\tstruct cgroup *cgrp, *child;\n\tstruct cgroup_subsys *ss;\n\tchar *tok;\n\tint ssid, ret;\n\n\t/*\n\t * Parse input - space separated list of subsystem names prefixed\n\t * with either + or -.\n\t */\n\tbuf = strstrip(buf);\n\twhile ((tok = strsep(&buf, \" \"))) {\n\t\tif (tok[0] == '\\0')\n\t\t\tcontinue;\n\t\tdo_each_subsys_mask(ss, ssid, ~cgrp_dfl_inhibit_ss_mask) {\n\t\t\tif (!cgroup_ssid_enabled(ssid) ||\n\t\t\t    strcmp(tok + 1, ss->name))\n\t\t\t\tcontinue;\n\n\t\t\tif (*tok == '+') {\n\t\t\t\tenable |= 1 << ssid;\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t} else if (*tok == '-') {\n\t\t\t\tdisable |= 1 << ssid;\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t} else {\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tbreak;\n\t\t} while_each_subsys_mask();\n\t\tif (ssid == CGROUP_SUBSYS_COUNT)\n\t\t\treturn -EINVAL;\n\t}\n\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tfor_each_subsys(ss, ssid) {\n\t\tif (enable & (1 << ssid)) {\n\t\t\tif (cgrp->subtree_control & (1 << ssid)) {\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(cgroup_control(cgrp) & (1 << ssid))) {\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t} else if (disable & (1 << ssid)) {\n\t\t\tif (!(cgrp->subtree_control & (1 << ssid))) {\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* a child has it enabled? */\n\t\t\tcgroup_for_each_live_child(child, cgrp) {\n\t\t\t\tif (child->subtree_control & (1 << ssid)) {\n\t\t\t\t\tret = -EBUSY;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!enable && !disable) {\n\t\tret = 0;\n\t\tgoto out_unlock;\n\t}\n\n\tret = cgroup_vet_subtree_control_enable(cgrp, enable);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/* save and update control masks and prepare csses */\n\tcgroup_save_control(cgrp);\n\n\tcgrp->subtree_control |= enable;\n\tcgrp->subtree_control &= ~disable;\n\n\tret = cgroup_apply_control(cgrp);\n\tcgroup_finalize_control(cgrp, ret);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tkernfs_activate(cgrp->kn);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\n/**\n * cgroup_enable_threaded - make @cgrp threaded\n * @cgrp: the target cgroup\n *\n * Called when \"threaded\" is written to the cgroup.type interface file and\n * tries to make @cgrp threaded and join the parent's resource domain.\n * This function is never called on the root cgroup as cgroup.type doesn't\n * exist on it.\n */\nstatic int cgroup_enable_threaded(struct cgroup *cgrp)\n{\n\tstruct cgroup *parent = cgroup_parent(cgrp);\n\tstruct cgroup *dom_cgrp = parent->dom_cgrp;\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* noop if already threaded */\n\tif (cgroup_is_threaded(cgrp))\n\t\treturn 0;\n\n\t/*\n\t * If @cgroup is populated or has domain controllers enabled, it\n\t * can't be switched.  While the below cgroup_can_be_thread_root()\n\t * test can catch the same conditions, that's only when @parent is\n\t * not mixable, so let's check it explicitly.\n\t */\n\tif (cgroup_is_populated(cgrp) ||\n\t    cgrp->subtree_control & ~cgrp_dfl_threaded_ss_mask)\n\t\treturn -EOPNOTSUPP;\n\n\t/* we're joining the parent's domain, ensure its validity */\n\tif (!cgroup_is_valid_domain(dom_cgrp) ||\n\t    !cgroup_can_be_thread_root(dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * The following shouldn't cause actual migrations and should\n\t * always succeed.\n\t */\n\tcgroup_save_control(cgrp);\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp)\n\t\tif (dsct == cgrp || cgroup_is_threaded(dsct))\n\t\t\tdsct->dom_cgrp = dom_cgrp;\n\n\tret = cgroup_apply_control(cgrp);\n\tif (!ret)\n\t\tparent->nr_threaded_children++;\n\n\tcgroup_finalize_control(cgrp, ret);\n\treturn ret;\n}\n\nstatic int cgroup_type_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tif (cgroup_is_threaded(cgrp))\n\t\tseq_puts(seq, \"threaded\\n\");\n\telse if (!cgroup_is_valid_domain(cgrp))\n\t\tseq_puts(seq, \"domain invalid\\n\");\n\telse if (cgroup_is_thread_root(cgrp))\n\t\tseq_puts(seq, \"domain threaded\\n\");\n\telse\n\t\tseq_puts(seq, \"domain\\n\");\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_type_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint ret;\n\n\t/* only switching to threaded mode is supported */\n\tif (strcmp(strstrip(buf), \"threaded\"))\n\t\treturn -EINVAL;\n\n\t/* drain dying csses before we re-apply (threaded) subtree control */\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/* threaded can only be enabled */\n\tret = cgroup_enable_threaded(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_max_descendants_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint descendants = READ_ONCE(cgrp->max_descendants);\n\n\tif (descendants == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", descendants);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_descendants_write(struct kernfs_open_file *of,\n\t\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint descendants;\n\tssize_t ret;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdescendants = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &descendants);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (descendants < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_descendants = descendants;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_max_depth_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint depth = READ_ONCE(cgrp->max_depth);\n\n\tif (depth == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", depth);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_depth_write(struct kernfs_open_file *of,\n\t\t\t\t      char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint depth;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdepth = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &depth);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (depth < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_depth = depth;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_events_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"populated %d\\n\", cgroup_is_populated(cgrp));\n\tseq_printf(seq, \"frozen %d\\n\", test_bit(CGRP_FROZEN, &cgrp->flags));\n\n\treturn 0;\n}\n\nstatic int cgroup_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgroup = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"nr_descendants %d\\n\",\n\t\t   cgroup->nr_descendants);\n\tseq_printf(seq, \"nr_dying_descendants %d\\n\",\n\t\t   cgroup->nr_dying_descendants);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused cgroup_extra_stat_show(struct seq_file *seq,\n\t\t\t\t\t\t struct cgroup *cgrp, int ssid)\n{\n\tstruct cgroup_subsys *ss = cgroup_subsys[ssid];\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!ss->css_extra_stat_show)\n\t\treturn 0;\n\n\tcss = cgroup_tryget_css(cgrp, ss);\n\tif (!css)\n\t\treturn 0;\n\n\tret = ss->css_extra_stat_show(seq, css);\n\tcss_put(css);\n\treturn ret;\n}\n\nstatic int cpu_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup __maybe_unused *cgrp = seq_css(seq)->cgroup;\n\tint ret = 0;\n\n\tcgroup_base_stat_cputime_show(seq);\n#ifdef CONFIG_CGROUP_SCHED\n\tret = cgroup_extra_stat_show(seq, cgrp, cpu_cgrp_id);\n#endif\n\treturn ret;\n}\n\n#ifdef CONFIG_PSI\nstatic int cgroup_io_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_IO);\n}\nstatic int cgroup_memory_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_MEM);\n}\nstatic int cgroup_cpu_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_CPU);\n}\n\nstatic ssize_t cgroup_pressure_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t\t  size_t nbytes, enum psi_res res)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct psi_trigger *new;\n\tstruct cgroup *cgrp;\n\tstruct psi_group *psi;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tcgroup_get(cgrp);\n\tcgroup_kn_unlock(of->kn);\n\n\tpsi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\tnew = psi_trigger_create(psi, buf, nbytes, res);\n\tif (IS_ERR(new)) {\n\t\tcgroup_put(cgrp);\n\t\treturn PTR_ERR(new);\n\t}\n\n\tpsi_trigger_replace(&ctx->psi.trigger, new);\n\n\tcgroup_put(cgrp);\n\n\treturn nbytes;\n}\n\nstatic ssize_t cgroup_io_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_IO);\n}\n\nstatic ssize_t cgroup_memory_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_MEM);\n}\n\nstatic ssize_t cgroup_cpu_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_CPU);\n}\n\nstatic __poll_t cgroup_pressure_poll(struct kernfs_open_file *of,\n\t\t\t\t\t  poll_table *pt)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\treturn psi_trigger_poll(&ctx->psi.trigger, of->file, pt);\n}\n\nstatic void cgroup_pressure_release(struct kernfs_open_file *of)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tpsi_trigger_replace(&ctx->psi.trigger, NULL);\n}\n\nbool cgroup_psi_enabled(void)\n{\n\treturn (cgroup_feature_disable_mask & (1 << OPT_FEATURE_PRESSURE)) == 0;\n}\n\n#else /* CONFIG_PSI */\nbool cgroup_psi_enabled(void)\n{\n\treturn false;\n}\n\n#endif /* CONFIG_PSI */\n\nstatic int cgroup_freeze_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"%d\\n\", cgrp->freezer.freeze);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_freeze_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint freeze;\n\n\tret = kstrtoint(strstrip(buf), 0, &freeze);\n\tif (ret)\n\t\treturn ret;\n\n\tif (freeze < 0 || freeze > 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgroup_freeze(cgrp, freeze);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic void __cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct css_task_iter it;\n\tstruct task_struct *task;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tspin_lock_irq(&css_set_lock);\n\tset_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n\n\tcss_task_iter_start(&cgrp->self, CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED, &it);\n\twhile ((task = css_task_iter_next(&it))) {\n\t\t/* Ignore kernel threads here. */\n\t\tif (task->flags & PF_KTHREAD)\n\t\t\tcontinue;\n\n\t\t/* Skip tasks that are already dying. */\n\t\tif (__fatal_signal_pending(task))\n\t\t\tcontinue;\n\n\t\tsend_sig(SIGKILL, task, 0);\n\t}\n\tcss_task_iter_end(&it);\n\n\tspin_lock_irq(&css_set_lock);\n\tclear_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n}\n\nstatic void cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct cgroup_subsys_state *css;\n\tstruct cgroup *dsct;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_pre(dsct, css, cgrp)\n\t\t__cgroup_kill(dsct);\n}\n\nstatic ssize_t cgroup_kill_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tssize_t ret = 0;\n\tint kill;\n\tstruct cgroup *cgrp;\n\n\tret = kstrtoint(strstrip(buf), 0, &kill);\n\tif (ret)\n\t\treturn ret;\n\n\tif (kill != 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/*\n\t * Killing is a process directed operation, i.e. the whole thread-group\n\t * is taken down so act like we do for cgroup.procs and only make this\n\t * writable in non-threaded cgroups.\n\t */\n\tif (cgroup_is_threaded(cgrp))\n\t\tret = -EOPNOTSUPP;\n\telse\n\t\tcgroup_kill(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_file_open(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->ns = current->nsproxy->cgroup_ns;\n\tget_cgroup_ns(ctx->ns);\n\tof->priv = ctx;\n\n\tif (!cft->open)\n\t\treturn 0;\n\n\tret = cft->open(of);\n\tif (ret) {\n\t\tput_cgroup_ns(ctx->ns);\n\t\tkfree(ctx);\n\t}\n\treturn ret;\n}\n\nstatic void cgroup_file_release(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tif (cft->release)\n\t\tcft->release(of);\n\tput_cgroup_ns(ctx->ns);\n\tkfree(ctx);\n}\n\nstatic ssize_t cgroup_file_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup *cgrp = of->kn->parent->priv;\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!nbytes)\n\t\treturn 0;\n\n\t/*\n\t * If namespaces are delegation boundaries, disallow writes to\n\t * files in an non-init namespace root from inside the namespace\n\t * except for the files explicitly marked delegatable -\n\t * cgroup.procs and cgroup.subtree_control.\n\t */\n\tif ((cgrp->root->flags & CGRP_ROOT_NS_DELEGATE) &&\n\t    !(cft->flags & CFTYPE_NS_DELEGATABLE) &&\n\t    ctx->ns != &init_cgroup_ns && ctx->ns->root_cset->dfl_cgrp == cgrp)\n\t\treturn -EPERM;\n\n\tif (cft->write)\n\t\treturn cft->write(of, buf, nbytes, off);\n\n\t/*\n\t * kernfs guarantees that a file isn't deleted with operations in\n\t * flight, which means that the matching css is and stays alive and\n\t * doesn't need to be pinned.  The RCU locking is not necessary\n\t * either.  It's just for the convenience of using cgroup_css().\n\t */\n\trcu_read_lock();\n\tcss = cgroup_css(cgrp, cft->ss);\n\trcu_read_unlock();\n\n\tif (cft->write_u64) {\n\t\tunsigned long long v;\n\t\tret = kstrtoull(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_u64(css, cft, v);\n\t} else if (cft->write_s64) {\n\t\tlong long v;\n\t\tret = kstrtoll(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_s64(css, cft, v);\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret ?: nbytes;\n}\n\nstatic __poll_t cgroup_file_poll(struct kernfs_open_file *of, poll_table *pt)\n{\n\tstruct cftype *cft = of_cft(of);\n\n\tif (cft->poll)\n\t\treturn cft->poll(of, pt);\n\n\treturn kernfs_generic_poll(of, pt);\n}\n\nstatic void *cgroup_seqfile_start(struct seq_file *seq, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_start(seq, ppos);\n}\n\nstatic void *cgroup_seqfile_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_next(seq, v, ppos);\n}\n\nstatic void cgroup_seqfile_stop(struct seq_file *seq, void *v)\n{\n\tif (seq_cft(seq)->seq_stop)\n\t\tseq_cft(seq)->seq_stop(seq, v);\n}\n\nstatic int cgroup_seqfile_show(struct seq_file *m, void *arg)\n{\n\tstruct cftype *cft = seq_cft(m);\n\tstruct cgroup_subsys_state *css = seq_css(m);\n\n\tif (cft->seq_show)\n\t\treturn cft->seq_show(m, arg);\n\n\tif (cft->read_u64)\n\t\tseq_printf(m, \"%llu\\n\", cft->read_u64(css, cft));\n\telse if (cft->read_s64)\n\t\tseq_printf(m, \"%lld\\n\", cft->read_s64(css, cft));\n\telse\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic struct kernfs_ops cgroup_kf_single_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\nstatic struct kernfs_ops cgroup_kf_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_start\t\t= cgroup_seqfile_start,\n\t.seq_next\t\t= cgroup_seqfile_next,\n\t.seq_stop\t\t= cgroup_seqfile_stop,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\n/* set uid and gid of cgroup dirs and files to that of the creator */\nstatic int cgroup_kn_set_ugid(struct kernfs_node *kn)\n{\n\tstruct iattr iattr = { .ia_valid = ATTR_UID | ATTR_GID,\n\t\t\t       .ia_uid = current_fsuid(),\n\t\t\t       .ia_gid = current_fsgid(), };\n\n\tif (uid_eq(iattr.ia_uid, GLOBAL_ROOT_UID) &&\n\t    gid_eq(iattr.ia_gid, GLOBAL_ROOT_GID))\n\t\treturn 0;\n\n\treturn kernfs_setattr(kn, &iattr);\n}\n\nstatic void cgroup_file_notify_timer(struct timer_list *timer)\n{\n\tcgroup_file_notify(container_of(timer, struct cgroup_file,\n\t\t\t\t\tnotify_timer));\n}\n\nstatic int cgroup_add_file(struct cgroup_subsys_state *css, struct cgroup *cgrp,\n\t\t\t   struct cftype *cft)\n{\n\tchar name[CGROUP_FILE_NAME_MAX];\n\tstruct kernfs_node *kn;\n\tstruct lock_class_key *key = NULL;\n\tint ret;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tkey = &cft->lockdep_key;\n#endif\n\tkn = __kernfs_create_file(cgrp->kn, cgroup_file_name(cgrp, cft, name),\n\t\t\t\t  cgroup_file_mode(cft),\n\t\t\t\t  GLOBAL_ROOT_UID, GLOBAL_ROOT_GID,\n\t\t\t\t  0, cft->kf_ops, cft,\n\t\t\t\t  NULL, key);\n\tif (IS_ERR(kn))\n\t\treturn PTR_ERR(kn);\n\n\tret = cgroup_kn_set_ugid(kn);\n\tif (ret) {\n\t\tkernfs_remove(kn);\n\t\treturn ret;\n\t}\n\n\tif (cft->file_offset) {\n\t\tstruct cgroup_file *cfile = (void *)css + cft->file_offset;\n\n\t\ttimer_setup(&cfile->notify_timer, cgroup_file_notify_timer, 0);\n\n\t\tspin_lock_irq(&cgroup_file_kn_lock);\n\t\tcfile->kn = kn;\n\t\tspin_unlock_irq(&cgroup_file_kn_lock);\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_addrm_files - add or remove files to a cgroup directory\n * @css: the target css\n * @cgrp: the target cgroup (usually css->cgroup)\n * @cfts: array of cftypes to be added\n * @is_add: whether to add or remove\n *\n * Depending on @is_add, add or remove files defined by @cfts on @cgrp.\n * For removals, this function never fails.\n */\nstatic int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add)\n{\n\tstruct cftype *cft, *cft_end = NULL;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\nrestart:\n\tfor (cft = cfts; cft != cft_end && cft->name[0] != '\\0'; cft++) {\n\t\t/* does cft->flags tell us to skip this file on @cgrp? */\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_ONLY_ON_DFL) && !cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_NOT_ON_DFL) && cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_NOT_ON_ROOT) && !cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_ONLY_ON_ROOT) && cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_DEBUG) && !cgroup_debug)\n\t\t\tcontinue;\n\t\tif (is_add) {\n\t\t\tret = cgroup_add_file(css, cgrp, cft);\n\t\t\tif (ret) {\n\t\t\t\tpr_warn(\"%s: failed to add %s, err=%d\\n\",\n\t\t\t\t\t__func__, cft->name, ret);\n\t\t\t\tcft_end = cft;\n\t\t\t\tis_add = false;\n\t\t\t\tgoto restart;\n\t\t\t}\n\t\t} else {\n\t\t\tcgroup_rm_file(cgrp, cft);\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int cgroup_apply_cftypes(struct cftype *cfts, bool is_add)\n{\n\tstruct cgroup_subsys *ss = cfts[0].ss;\n\tstruct cgroup *root = &ss->root->cgrp;\n\tstruct cgroup_subsys_state *css;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* add/rm files for all cgroups created before */\n\tcss_for_each_descendant_pre(css, cgroup_css(root, ss)) {\n\t\tstruct cgroup *cgrp = css->cgroup;\n\n\t\tif (!(css->flags & CSS_VISIBLE))\n\t\t\tcontinue;\n\n\t\tret = cgroup_addrm_files(css, cgrp, cfts, is_add);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tif (is_add && !ret)\n\t\tkernfs_activate(root->kn);\n\treturn ret;\n}\n\nstatic void cgroup_exit_cftypes(struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\t/* free copy for custom atomic_write_len, see init_cftypes() */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE)\n\t\t\tkfree(cft->kf_ops);\n\t\tcft->kf_ops = NULL;\n\t\tcft->ss = NULL;\n\n\t\t/* revert flags set by cgroup core while adding @cfts */\n\t\tcft->flags &= ~(__CFTYPE_ONLY_ON_DFL | __CFTYPE_NOT_ON_DFL);\n\t}\n}\n\nstatic int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\tstruct kernfs_ops *kf_ops;\n\n\t\tWARN_ON(cft->ss || cft->kf_ops);\n\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\n\t\tif (cft->seq_start)\n\t\t\tkf_ops = &cgroup_kf_ops;\n\t\telse\n\t\t\tkf_ops = &cgroup_kf_single_ops;\n\n\t\t/*\n\t\t * Ugh... if @cft wants a custom max_write_len, we need to\n\t\t * make a copy of kf_ops to set its atomic_write_len.\n\t\t */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE) {\n\t\t\tkf_ops = kmemdup(kf_ops, sizeof(*kf_ops), GFP_KERNEL);\n\t\t\tif (!kf_ops) {\n\t\t\t\tcgroup_exit_cftypes(cfts);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tkf_ops->atomic_write_len = cft->max_write_len;\n\t\t}\n\n\t\tcft->kf_ops = kf_ops;\n\t\tcft->ss = ss;\n\t}\n\n\treturn 0;\n}\n\nstatic int cgroup_rm_cftypes_locked(struct cftype *cfts)\n{\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tif (!cfts || !cfts[0].ss)\n\t\treturn -ENOENT;\n\n\tlist_del(&cfts->node);\n\tcgroup_apply_cftypes(cfts, false);\n\tcgroup_exit_cftypes(cfts);\n\treturn 0;\n}\n\n/**\n * cgroup_rm_cftypes - remove an array of cftypes from a subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Unregister @cfts.  Files described by @cfts are removed from all\n * existing cgroups and all future cgroups won't have them either.  This\n * function can be called anytime whether @cfts' subsys is attached or not.\n *\n * Returns 0 on successful unregistration, -ENOENT if @cfts is not\n * registered.\n */\nint cgroup_rm_cftypes(struct cftype *cfts)\n{\n\tint ret;\n\n\tmutex_lock(&cgroup_mutex);\n\tret = cgroup_rm_cftypes_locked(cfts);\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_cftypes - add an array of cftypes to a subsystem\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Register @cfts to @ss.  Files described by @cfts are created for all\n * existing cgroups to which @ss is attached and all future cgroups will\n * have them too.  This function can be called anytime whether @ss is\n * attached or not.\n *\n * Returns 0 on successful registration, -errno on failure.  Note that this\n * function currently returns 0 as long as @cfts registration is successful\n * even if some file creation attempts on existing cgroups fail.\n */\nstatic int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tint ret;\n\n\tif (!cgroup_ssid_enabled(ss->id))\n\t\treturn 0;\n\n\tif (!cfts || cfts[0].name[0] == '\\0')\n\t\treturn 0;\n\n\tret = cgroup_init_cftypes(ss, cfts);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&cgroup_mutex);\n\n\tlist_add_tail(&cfts->node, &ss->cfts);\n\tret = cgroup_apply_cftypes(cfts, true);\n\tif (ret)\n\t\tcgroup_rm_cftypes_locked(cfts);\n\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_dfl_cftypes - add an array of cftypes for default hierarchy\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the default hierarchy.\n */\nint cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_ONLY_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_add_legacy_cftypes - add an array of cftypes for legacy hierarchies\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the legacy hierarchies.\n */\nint cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_NOT_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_file_notify - generate a file modified event for a cgroup_file\n * @cfile: target cgroup_file\n *\n * @cfile must have been obtained by setting cftype->file_offset.\n */\nvoid cgroup_file_notify(struct cgroup_file *cfile)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cgroup_file_kn_lock, flags);\n\tif (cfile->kn) {\n\t\tunsigned long last = cfile->notified_at;\n\t\tunsigned long next = last + CGROUP_FILE_NOTIFY_MIN_INTV;\n\n\t\tif (time_in_range(jiffies, last, next)) {\n\t\t\ttimer_reduce(&cfile->notify_timer, next);\n\t\t} else {\n\t\t\tkernfs_notify(cfile->kn);\n\t\t\tcfile->notified_at = jiffies;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cgroup_file_kn_lock, flags);\n}\n\n/**\n * css_next_child - find the next child of a given css\n * @pos: the current position (%NULL to initiate traversal)\n * @parent: css whose children to walk\n *\n * This function returns the next child of @parent and should be called\n * under either cgroup_mutex or RCU read lock.  The only requirement is\n * that @parent and @pos are accessible.  The next sibling is guaranteed to\n * be returned regardless of their states.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,\n\t\t\t\t\t   struct cgroup_subsys_state *parent)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/*\n\t * @pos could already have been unlinked from the sibling list.\n\t * Once a cgroup is removed, its ->sibling.next is no longer\n\t * updated when its next sibling changes.  CSS_RELEASED is set when\n\t * @pos is taken off list, at which time its next pointer is valid,\n\t * and, as releases are serialized, the one pointed to by the next\n\t * pointer is guaranteed to not have started release yet.  This\n\t * implies that if we observe !CSS_RELEASED on @pos in this RCU\n\t * critical section, the one pointed to by its next pointer is\n\t * guaranteed to not have finished its RCU grace period even if we\n\t * have dropped rcu_read_lock() in-between iterations.\n\t *\n\t * If @pos has CSS_RELEASED set, its next pointer can't be\n\t * dereferenced; however, as each css is given a monotonically\n\t * increasing unique serial number and always appended to the\n\t * sibling list, the next one can be found by walking the parent's\n\t * children until the first css with higher serial number than\n\t * @pos's.  While this path can be slower, it happens iff iteration\n\t * races against release and the race window is very small.\n\t */\n\tif (!pos) {\n\t\tnext = list_entry_rcu(parent->children.next, struct cgroup_subsys_state, sibling);\n\t} else if (likely(!(pos->flags & CSS_RELEASED))) {\n\t\tnext = list_entry_rcu(pos->sibling.next, struct cgroup_subsys_state, sibling);\n\t} else {\n\t\tlist_for_each_entry_rcu(next, &parent->children, sibling,\n\t\t\t\t\tlockdep_is_held(&cgroup_mutex))\n\t\t\tif (next->serial_nr > pos->serial_nr)\n\t\t\t\tbreak;\n\t}\n\n\t/*\n\t * @next, if not pointing to the head, can be dereferenced and is\n\t * the next sibling.\n\t */\n\tif (&next->sibling != &parent->children)\n\t\treturn next;\n\treturn NULL;\n}\n\n/**\n * css_next_descendant_pre - find the next descendant for pre-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_pre().  Find the next descendant\n * to visit for pre-order traversal of @root's descendants.  @root is\n * included in the iteration and the first node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @root are accessible and @pos is a descendant of @root.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_pre(struct cgroup_subsys_state *pos,\n\t\t\tstruct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit @root */\n\tif (!pos)\n\t\treturn root;\n\n\t/* visit the first child if exists */\n\tnext = css_next_child(NULL, pos);\n\tif (next)\n\t\treturn next;\n\n\t/* no child, visit my or the closest ancestor's next sibling */\n\twhile (pos != root) {\n\t\tnext = css_next_child(pos, pos->parent);\n\t\tif (next)\n\t\t\treturn next;\n\t\tpos = pos->parent;\n\t}\n\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(css_next_descendant_pre);\n\n/**\n * css_rightmost_descendant - return the rightmost descendant of a css\n * @pos: css of interest\n *\n * Return the rightmost descendant of @pos.  If there's no descendant, @pos\n * is returned.  This can be used during pre-order traversal to skip\n * subtree of @pos.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct rightmost descendant as\n * long as @pos is accessible.\n */\nstruct cgroup_subsys_state *\ncss_rightmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last, *tmp;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\tdo {\n\t\tlast = pos;\n\t\t/* ->prev isn't RCU safe, walk ->next till the end */\n\t\tpos = NULL;\n\t\tcss_for_each_child(tmp, last)\n\t\t\tpos = tmp;\n\t} while (pos);\n\n\treturn last;\n}\n\nstatic struct cgroup_subsys_state *\ncss_leftmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last;\n\n\tdo {\n\t\tlast = pos;\n\t\tpos = css_next_child(NULL, pos);\n\t} while (pos);\n\n\treturn last;\n}\n\n/**\n * css_next_descendant_post - find the next descendant for post-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_post().  Find the next descendant\n * to visit for post-order traversal of @root's descendants.  @root is\n * included in the iteration and the last node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @cgroup are accessible and @pos is a descendant of\n * @cgroup.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_post(struct cgroup_subsys_state *pos,\n\t\t\t struct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit leftmost descendant which may be @root */\n\tif (!pos)\n\t\treturn css_leftmost_descendant(root);\n\n\t/* if we visited @root, we're done */\n\tif (pos == root)\n\t\treturn NULL;\n\n\t/* if there's an unvisited sibling, visit its leftmost descendant */\n\tnext = css_next_child(pos, pos->parent);\n\tif (next)\n\t\treturn css_leftmost_descendant(next);\n\n\t/* no sibling left, visit parent */\n\treturn pos->parent;\n}\n\n/**\n * css_has_online_children - does a css have online children\n * @css: the target css\n *\n * Returns %true if @css has any online children; otherwise, %false.  This\n * function can be called from any context but the caller is responsible\n * for synchronizing against on/offlining as necessary.\n */\nbool css_has_online_children(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys_state *child;\n\tbool ret = false;\n\n\trcu_read_lock();\n\tcss_for_each_child(child, css) {\n\t\tif (child->flags & CSS_ONLINE) {\n\t\t\tret = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)\n{\n\tstruct list_head *l;\n\tstruct cgrp_cset_link *link;\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* find the next threaded cset */\n\tif (it->tcset_pos) {\n\t\tl = it->tcset_pos->next;\n\n\t\tif (l != it->tcset_head) {\n\t\t\tit->tcset_pos = l;\n\t\t\treturn container_of(l, struct css_set,\n\t\t\t\t\t    threaded_csets_node);\n\t\t}\n\n\t\tit->tcset_pos = NULL;\n\t}\n\n\t/* find the next cset */\n\tl = it->cset_pos;\n\tl = l->next;\n\tif (l == it->cset_head) {\n\t\tit->cset_pos = NULL;\n\t\treturn NULL;\n\t}\n\n\tif (it->ss) {\n\t\tcset = container_of(l, struct css_set, e_cset_node[it->ss->id]);\n\t} else {\n\t\tlink = list_entry(l, struct cgrp_cset_link, cset_link);\n\t\tcset = link->cset;\n\t}\n\n\tit->cset_pos = l;\n\n\t/* initialize threaded css_set walking */\n\tif (it->flags & CSS_TASK_ITER_THREADED) {\n\t\tif (it->cur_dcset)\n\t\t\tput_css_set_locked(it->cur_dcset);\n\t\tit->cur_dcset = cset;\n\t\tget_css_set(cset);\n\n\t\tit->tcset_head = &cset->threaded_csets;\n\t\tit->tcset_pos = &cset->threaded_csets;\n\t}\n\n\treturn cset;\n}\n\n/**\n * css_task_iter_advance_css_set - advance a task iterator to the next css_set\n * @it: the iterator to advance\n *\n * Advance @it to the next css_set to walk.\n */\nstatic void css_task_iter_advance_css_set(struct css_task_iter *it)\n{\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* Advance to the next non-empty css_set and find first non-empty tasks list*/\n\twhile ((cset = css_task_iter_next_css_set(it))) {\n\t\tif (!list_empty(&cset->tasks)) {\n\t\t\tit->cur_tasks_head = &cset->tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->mg_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->mg_tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->dying_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->dying_tasks;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cset) {\n\t\tit->task_pos = NULL;\n\t\treturn;\n\t}\n\tit->task_pos = it->cur_tasks_head->next;\n\n\t/*\n\t * We don't keep css_sets locked across iteration steps and thus\n\t * need to take steps to ensure that iteration can be resumed after\n\t * the lock is re-acquired.  Iteration is performed at two levels -\n\t * css_sets and tasks in them.\n\t *\n\t * Once created, a css_set never leaves its cgroup lists, so a\n\t * pinned css_set is guaranteed to stay put and we can resume\n\t * iteration afterwards.\n\t *\n\t * Tasks may leave @cset across iteration steps.  This is resolved\n\t * by registering each iterator with the css_set currently being\n\t * walked and making css_set_move_task() advance iterators whose\n\t * next task is leaving.\n\t */\n\tif (it->cur_cset) {\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t}\n\tget_css_set(cset);\n\tit->cur_cset = cset;\n\tlist_add(&it->iters_node, &cset->task_iters);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_FILE_NOTIFY_MIN_INTV\tDIV_ROUND_UP(HZ, 100)",
            "#define CGROUP_FILE_NAME_MAX\t\t(MAX_CGROUP_TYPE_NAMELEN +\t\\\n\t\t\t\t\t MAX_CFTYPE_NAME + 2)"
          ],
          "globals_used": [
            "bool cgroup_debug",
            "static DEFINE_SPINLOCK(cgroup_file_kn_lock);",
            "static u16 cgrp_dfl_inhibit_ss_mask;",
            "static u16 cgrp_dfl_threaded_ss_mask;",
            "struct cgroup_namespace init_cgroup_ns = {\n\t.ns.count\t= REFCOUNT_INIT(2),\n\t.user_ns\t= &init_user_ns,\n\t.ns.ops\t\t= &cgroupns_operations,\n\t.ns.inum\t= PROC_CGROUP_INIT_INO,\n\t.root_cset\t= &init_css_set,\n};",
            "static u16 cgroup_feature_disable_mask",
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static void cgroup_finalize_control(struct cgroup *cgrp, int ret);",
            "static void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);",
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);",
            "static int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_FILE_NOTIFY_MIN_INTV\tDIV_ROUND_UP(HZ, 100)\n#define CGROUP_FILE_NAME_MAX\t\t(MAX_CGROUP_TYPE_NAMELEN +\t\\\n\t\t\t\t\t MAX_CFTYPE_NAME + 2)\n\nbool cgroup_debug;\nstatic DEFINE_SPINLOCK(cgroup_file_kn_lock);\nstatic u16 cgrp_dfl_inhibit_ss_mask;\nstatic u16 cgrp_dfl_threaded_ss_mask;\nstruct cgroup_namespace init_cgroup_ns = {\n\t.ns.count\t= REFCOUNT_INIT(2),\n\t.user_ns\t= &init_user_ns,\n\t.ns.ops\t\t= &cgroupns_operations,\n\t.ns.inum\t= PROC_CGROUP_INIT_INO,\n\t.root_cset\t= &init_css_set,\n};\nstatic u16 cgroup_feature_disable_mask;\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret);\nstatic void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\nstatic int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add);\n\nint cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,\n\t\t       bool threadgroup)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct task_struct *task;\n\tint ret = 0;\n\n\t/* look up all src csets */\n\tspin_lock_irq(&css_set_lock);\n\trcu_read_lock();\n\ttask = leader;\n\tdo {\n\t\tcgroup_migrate_add_src(task_css_set(task), dst_cgrp, &mgctx);\n\t\tif (!threadgroup)\n\t\t\tbreak;\n\t} while_each_thread(leader, task);\n\trcu_read_unlock();\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* prepare dst csets and commit */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (!ret)\n\t\tret = cgroup_migrate(leader, threadgroup, &mgctx);\n\n\tcgroup_migrate_finish(&mgctx);\n\n\tif (!ret)\n\t\tTRACE_CGROUP_PATH(attach_task, dst_cgrp, leader, threadgroup);\n\n\treturn ret;\n}\n\nstruct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup,\n\t\t\t\t\t     bool *locked)\n\t__acquires(&cgroup_threadgroup_rwsem)\n{\n\tstruct task_struct *tsk;\n\tpid_t pid;\n\n\tif (kstrtoint(strstrip(buf), 0, &pid) || pid < 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * If we migrate a single thread, we don't care about threadgroup\n\t * stability. If the thread is `current`, it won't exit(2) under our\n\t * hands or change PID through exec(2). We exclude\n\t * cgroup_update_dfl_csses and other cgroup_{proc,thread}s_write\n\t * callers by cgroup_mutex.\n\t * Therefore, we can skip the global lock.\n\t */\n\tlockdep_assert_held(&cgroup_mutex);\n\tif (pid || threadgroup) {\n\t\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = true;\n\t} else {\n\t\t*locked = false;\n\t}\n\n\trcu_read_lock();\n\tif (pid) {\n\t\ttsk = find_task_by_vpid(pid);\n\t\tif (!tsk) {\n\t\t\ttsk = ERR_PTR(-ESRCH);\n\t\t\tgoto out_unlock_threadgroup;\n\t\t}\n\t} else {\n\t\ttsk = current;\n\t}\n\n\tif (threadgroup)\n\t\ttsk = tsk->group_leader;\n\n\t/*\n\t * kthreads may acquire PF_NO_SETAFFINITY during initialization.\n\t * If userland migrates such a kthread to a non-root cgroup, it can\n\t * become trapped in a cpuset, or RT kthread may be born in a\n\t * cgroup with no rt_runtime allocated.  Just say no.\n\t */\n\tif (tsk->no_cgroup_migration || (tsk->flags & PF_NO_SETAFFINITY)) {\n\t\ttsk = ERR_PTR(-EINVAL);\n\t\tgoto out_unlock_threadgroup;\n\t}\n\n\tget_task_struct(tsk);\n\tgoto out_unlock_rcu;\n\nout_unlock_threadgroup:\n\tif (*locked) {\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = false;\n\t}\nout_unlock_rcu:\n\trcu_read_unlock();\n\treturn tsk;\n}\n\nvoid cgroup_procs_write_finish(struct task_struct *task, bool locked)\n\t__releases(&cgroup_threadgroup_rwsem)\n{\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\t/* release reference from cgroup_procs_write_start() */\n\tput_task_struct(task);\n\n\tif (locked)\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tfor_each_subsys(ss, ssid)\n\t\tif (ss->post_attach)\n\t\t\tss->post_attach();\n}\n\nstatic void cgroup_print_ss_mask(struct seq_file *seq, u16 ss_mask)\n{\n\tstruct cgroup_subsys *ss;\n\tbool printed = false;\n\tint ssid;\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\tif (printed)\n\t\t\tseq_putc(seq, ' ');\n\t\tseq_puts(seq, ss->name);\n\t\tprinted = true;\n\t} while_each_subsys_mask();\n\tif (printed)\n\t\tseq_putc(seq, '\\n');\n}\n\n/* show controllers which are enabled from the parent */\nstatic int cgroup_controllers_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgroup_control(cgrp));\n\treturn 0;\n}\n\n/* show controllers which are enabled for a given cgroup's children */\nstatic int cgroup_subtree_control_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgrp->subtree_control);\n\treturn 0;\n}\n\n/**\n * cgroup_update_dfl_csses - update css assoc of a subtree in default hierarchy\n * @cgrp: root of the subtree to update csses for\n *\n * @cgrp's control masks have changed and its subtree's css associations\n * need to be updated accordingly.  This function looks up all css_sets\n * which are attached to the subtree, creates the matching updated css_sets\n * and migrates the tasks to the new ones.\n */\nstatic int cgroup_update_dfl_csses(struct cgroup *cgrp)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup *dsct;\n\tstruct css_set *src_cset;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\n\t/* look up all csses currently attached to @cgrp's subtree */\n\tspin_lock_irq(&css_set_lock);\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tstruct cgrp_cset_link *link;\n\n\t\tlist_for_each_entry(link, &dsct->cset_links, cset_link)\n\t\t\tcgroup_migrate_add_src(link->cset, dsct, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* NULL dst indicates self on default hierarchy */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tspin_lock_irq(&css_set_lock);\n\tlist_for_each_entry(src_cset, &mgctx.preloaded_src_csets, mg_preload_node) {\n\t\tstruct task_struct *task, *ntask;\n\n\t\t/* all tasks in src_csets need to be migrated */\n\t\tlist_for_each_entry_safe(task, ntask, &src_cset->tasks, cg_list)\n\t\t\tcgroup_migrate_add_task(task, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\tret = cgroup_migrate_execute(&mgctx);\nout_finish:\n\tcgroup_migrate_finish(&mgctx);\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\treturn ret;\n}\n\n/**\n * cgroup_lock_and_drain_offline - lock cgroup_mutex and drain offlined csses\n * @cgrp: root of the target subtree\n *\n * Because css offlining is asynchronous, userland may try to re-enable a\n * controller while the previous css is still around.  This function grabs\n * cgroup_mutex and drains the previous css instances of @cgrp's subtree.\n */\nvoid cgroup_lock_and_drain_offline(struct cgroup *cgrp)\n\t__acquires(&cgroup_mutex)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\nrestart:\n\tmutex_lock(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\t\t\tDEFINE_WAIT(wait);\n\n\t\t\tif (!css || !percpu_ref_is_dying(&css->refcnt))\n\t\t\t\tcontinue;\n\n\t\t\tcgroup_get_live(dsct);\n\t\t\tprepare_to_wait(&dsct->offline_waitq, &wait,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE);\n\n\t\t\tmutex_unlock(&cgroup_mutex);\n\t\t\tschedule();\n\t\t\tfinish_wait(&dsct->offline_waitq, &wait);\n\n\t\t\tcgroup_put(dsct);\n\t\t\tgoto restart;\n\t\t}\n\t}\n}\n\n/**\n * cgroup_save_control - save control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Save ->subtree_control, ->subtree_ss_mask and ->dom_cgrp to the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_save_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->old_subtree_control = dsct->subtree_control;\n\t\tdsct->old_subtree_ss_mask = dsct->subtree_ss_mask;\n\t\tdsct->old_dom_cgrp = dsct->dom_cgrp;\n\t}\n}\n\n/**\n * cgroup_propagate_control - refresh control masks of a subtree\n * @cgrp: root of the target subtree\n *\n * For @cgrp and its subtree, ensure ->subtree_ss_mask matches\n * ->subtree_control and propagate controller availability through the\n * subtree so that descendants don't have unavailable controllers enabled.\n */\nstatic void cgroup_propagate_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control &= cgroup_control(dsct);\n\t\tdsct->subtree_ss_mask =\n\t\t\tcgroup_calc_subtree_ss_mask(dsct->subtree_control,\n\t\t\t\t\t\t    cgroup_ss_mask(dsct));\n\t}\n}\n\n/**\n * cgroup_restore_control - restore control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Restore ->subtree_control, ->subtree_ss_mask and ->dom_cgrp from the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_restore_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control = dsct->old_subtree_control;\n\t\tdsct->subtree_ss_mask = dsct->old_subtree_ss_mask;\n\t\tdsct->dom_cgrp = dsct->old_dom_cgrp;\n\t}\n}\n\nstatic bool css_visible(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys *ss = css->ss;\n\tstruct cgroup *cgrp = css->cgroup;\n\n\tif (cgroup_control(cgrp) & (1 << ss->id))\n\t\treturn true;\n\tif (!(cgroup_ss_mask(cgrp) & (1 << ss->id)))\n\t\treturn false;\n\treturn cgroup_on_dfl(cgrp) && ss->implicit_on_dfl;\n}\n\n/**\n * cgroup_apply_control_enable - enable or show csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and create new csses or make the existing ones\n * visible.  A css is created invisible if it's being implicitly enabled\n * through dependency.  An invisible css is made visible when the userland\n * explicitly enables it.\n *\n * Returns 0 on success, -errno on failure.  On failure, csses which have\n * been processed already aren't cleaned up.  The caller is responsible for\n * cleaning up with cgroup_apply_control_disable().\n */\nstatic int cgroup_apply_control_enable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid, ret;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!(cgroup_ss_mask(dsct) & (1 << ss->id)))\n\t\t\t\tcontinue;\n\n\t\t\tif (!css) {\n\t\t\t\tcss = css_create(dsct, ss);\n\t\t\t\tif (IS_ERR(css))\n\t\t\t\t\treturn PTR_ERR(css);\n\t\t\t}\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css_visible(css)) {\n\t\t\t\tret = css_populate_dir(css);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_apply_control_disable - kill or hide csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and kill and hide csses so that they match\n * cgroup_ss_mask() and cgroup_visible_mask().\n *\n * A css is hidden when the userland requests it to be disabled while other\n * subsystems are still depending on it.  The css must not actively control\n * resources and be in the vanilla state if it's made visible again later.\n * Controllers which may be depended upon should provide ->css_reset() for\n * this purpose.\n */\nstatic void cgroup_apply_control_disable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!css)\n\t\t\t\tcontinue;\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css->parent &&\n\t\t\t    !(cgroup_ss_mask(dsct) & (1 << ss->id))) {\n\t\t\t\tkill_css(css);\n\t\t\t} else if (!css_visible(css)) {\n\t\t\t\tcss_clear_dir(css);\n\t\t\t\tif (ss->css_reset)\n\t\t\t\t\tss->css_reset(css);\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * cgroup_apply_control - apply control mask updates to the subtree\n * @cgrp: root of the target subtree\n *\n * subsystems can be enabled and disabled in a subtree using the following\n * steps.\n *\n * 1. Call cgroup_save_control() to stash the current state.\n * 2. Update ->subtree_control masks in the subtree as desired.\n * 3. Call cgroup_apply_control() to apply the changes.\n * 4. Optionally perform other related operations.\n * 5. Call cgroup_finalize_control() to finish up.\n *\n * This function implements step 3 and propagates the mask changes\n * throughout @cgrp's subtree, updates csses accordingly and perform\n * process migrations.\n */\nstatic int cgroup_apply_control(struct cgroup *cgrp)\n{\n\tint ret;\n\n\tcgroup_propagate_control(cgrp);\n\n\tret = cgroup_apply_control_enable(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * At this point, cgroup_e_css_by_mask() results reflect the new csses\n\t * making the following cgroup_update_dfl_csses() properly update\n\t * css associations of all tasks in the subtree.\n\t */\n\tret = cgroup_update_dfl_csses(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/**\n * cgroup_finalize_control - finalize control mask update\n * @cgrp: root of the target subtree\n * @ret: the result of the update\n *\n * Finalize control mask update.  See cgroup_apply_control() for more info.\n */\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret)\n{\n\tif (ret) {\n\t\tcgroup_restore_control(cgrp);\n\t\tcgroup_propagate_control(cgrp);\n\t}\n\n\tcgroup_apply_control_disable(cgrp);\n}\n\nstatic int cgroup_vet_subtree_control_enable(struct cgroup *cgrp, u16 enable)\n{\n\tu16 domain_enable = enable & ~cgrp_dfl_threaded_ss_mask;\n\n\t/* if nothing is getting enabled, nothing to worry about */\n\tif (!enable)\n\t\treturn 0;\n\n\t/* can @cgrp host any resources? */\n\tif (!cgroup_is_valid_domain(cgrp->dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/* mixables don't care */\n\tif (cgroup_is_mixable(cgrp))\n\t\treturn 0;\n\n\tif (domain_enable) {\n\t\t/* can't enable domain controllers inside a thread subtree */\n\t\tif (cgroup_is_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn -EOPNOTSUPP;\n\t} else {\n\t\t/*\n\t\t * Threaded controllers can handle internal competitions\n\t\t * and are always allowed inside a (prospective) thread\n\t\t * subtree.\n\t\t */\n\t\tif (cgroup_can_be_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * Controllers can't be enabled for a cgroup with tasks to avoid\n\t * child cgroups competing against tasks.\n\t */\n\tif (cgroup_has_tasks(cgrp))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\n/* change the enabled child controllers for a cgroup in the default hierarchy */\nstatic ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,\n\t\t\t\t\t    char *buf, size_t nbytes,\n\t\t\t\t\t    loff_t off)\n{\n\tu16 enable = 0, disable = 0;\n\tstruct cgroup *cgrp, *child;\n\tstruct cgroup_subsys *ss;\n\tchar *tok;\n\tint ssid, ret;\n\n\t/*\n\t * Parse input - space separated list of subsystem names prefixed\n\t * with either + or -.\n\t */\n\tbuf = strstrip(buf);\n\twhile ((tok = strsep(&buf, \" \"))) {\n\t\tif (tok[0] == '\\0')\n\t\t\tcontinue;\n\t\tdo_each_subsys_mask(ss, ssid, ~cgrp_dfl_inhibit_ss_mask) {\n\t\t\tif (!cgroup_ssid_enabled(ssid) ||\n\t\t\t    strcmp(tok + 1, ss->name))\n\t\t\t\tcontinue;\n\n\t\t\tif (*tok == '+') {\n\t\t\t\tenable |= 1 << ssid;\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t} else if (*tok == '-') {\n\t\t\t\tdisable |= 1 << ssid;\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t} else {\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tbreak;\n\t\t} while_each_subsys_mask();\n\t\tif (ssid == CGROUP_SUBSYS_COUNT)\n\t\t\treturn -EINVAL;\n\t}\n\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tfor_each_subsys(ss, ssid) {\n\t\tif (enable & (1 << ssid)) {\n\t\t\tif (cgrp->subtree_control & (1 << ssid)) {\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(cgroup_control(cgrp) & (1 << ssid))) {\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t} else if (disable & (1 << ssid)) {\n\t\t\tif (!(cgrp->subtree_control & (1 << ssid))) {\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* a child has it enabled? */\n\t\t\tcgroup_for_each_live_child(child, cgrp) {\n\t\t\t\tif (child->subtree_control & (1 << ssid)) {\n\t\t\t\t\tret = -EBUSY;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!enable && !disable) {\n\t\tret = 0;\n\t\tgoto out_unlock;\n\t}\n\n\tret = cgroup_vet_subtree_control_enable(cgrp, enable);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/* save and update control masks and prepare csses */\n\tcgroup_save_control(cgrp);\n\n\tcgrp->subtree_control |= enable;\n\tcgrp->subtree_control &= ~disable;\n\n\tret = cgroup_apply_control(cgrp);\n\tcgroup_finalize_control(cgrp, ret);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tkernfs_activate(cgrp->kn);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\n/**\n * cgroup_enable_threaded - make @cgrp threaded\n * @cgrp: the target cgroup\n *\n * Called when \"threaded\" is written to the cgroup.type interface file and\n * tries to make @cgrp threaded and join the parent's resource domain.\n * This function is never called on the root cgroup as cgroup.type doesn't\n * exist on it.\n */\nstatic int cgroup_enable_threaded(struct cgroup *cgrp)\n{\n\tstruct cgroup *parent = cgroup_parent(cgrp);\n\tstruct cgroup *dom_cgrp = parent->dom_cgrp;\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* noop if already threaded */\n\tif (cgroup_is_threaded(cgrp))\n\t\treturn 0;\n\n\t/*\n\t * If @cgroup is populated or has domain controllers enabled, it\n\t * can't be switched.  While the below cgroup_can_be_thread_root()\n\t * test can catch the same conditions, that's only when @parent is\n\t * not mixable, so let's check it explicitly.\n\t */\n\tif (cgroup_is_populated(cgrp) ||\n\t    cgrp->subtree_control & ~cgrp_dfl_threaded_ss_mask)\n\t\treturn -EOPNOTSUPP;\n\n\t/* we're joining the parent's domain, ensure its validity */\n\tif (!cgroup_is_valid_domain(dom_cgrp) ||\n\t    !cgroup_can_be_thread_root(dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * The following shouldn't cause actual migrations and should\n\t * always succeed.\n\t */\n\tcgroup_save_control(cgrp);\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp)\n\t\tif (dsct == cgrp || cgroup_is_threaded(dsct))\n\t\t\tdsct->dom_cgrp = dom_cgrp;\n\n\tret = cgroup_apply_control(cgrp);\n\tif (!ret)\n\t\tparent->nr_threaded_children++;\n\n\tcgroup_finalize_control(cgrp, ret);\n\treturn ret;\n}\n\nstatic int cgroup_type_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tif (cgroup_is_threaded(cgrp))\n\t\tseq_puts(seq, \"threaded\\n\");\n\telse if (!cgroup_is_valid_domain(cgrp))\n\t\tseq_puts(seq, \"domain invalid\\n\");\n\telse if (cgroup_is_thread_root(cgrp))\n\t\tseq_puts(seq, \"domain threaded\\n\");\n\telse\n\t\tseq_puts(seq, \"domain\\n\");\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_type_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint ret;\n\n\t/* only switching to threaded mode is supported */\n\tif (strcmp(strstrip(buf), \"threaded\"))\n\t\treturn -EINVAL;\n\n\t/* drain dying csses before we re-apply (threaded) subtree control */\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/* threaded can only be enabled */\n\tret = cgroup_enable_threaded(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_max_descendants_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint descendants = READ_ONCE(cgrp->max_descendants);\n\n\tif (descendants == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", descendants);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_descendants_write(struct kernfs_open_file *of,\n\t\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint descendants;\n\tssize_t ret;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdescendants = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &descendants);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (descendants < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_descendants = descendants;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_max_depth_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint depth = READ_ONCE(cgrp->max_depth);\n\n\tif (depth == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", depth);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_depth_write(struct kernfs_open_file *of,\n\t\t\t\t      char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint depth;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdepth = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &depth);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (depth < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_depth = depth;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_events_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"populated %d\\n\", cgroup_is_populated(cgrp));\n\tseq_printf(seq, \"frozen %d\\n\", test_bit(CGRP_FROZEN, &cgrp->flags));\n\n\treturn 0;\n}\n\nstatic int cgroup_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgroup = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"nr_descendants %d\\n\",\n\t\t   cgroup->nr_descendants);\n\tseq_printf(seq, \"nr_dying_descendants %d\\n\",\n\t\t   cgroup->nr_dying_descendants);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused cgroup_extra_stat_show(struct seq_file *seq,\n\t\t\t\t\t\t struct cgroup *cgrp, int ssid)\n{\n\tstruct cgroup_subsys *ss = cgroup_subsys[ssid];\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!ss->css_extra_stat_show)\n\t\treturn 0;\n\n\tcss = cgroup_tryget_css(cgrp, ss);\n\tif (!css)\n\t\treturn 0;\n\n\tret = ss->css_extra_stat_show(seq, css);\n\tcss_put(css);\n\treturn ret;\n}\n\nstatic int cpu_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup __maybe_unused *cgrp = seq_css(seq)->cgroup;\n\tint ret = 0;\n\n\tcgroup_base_stat_cputime_show(seq);\n#ifdef CONFIG_CGROUP_SCHED\n\tret = cgroup_extra_stat_show(seq, cgrp, cpu_cgrp_id);\n#endif\n\treturn ret;\n}\n\n#ifdef CONFIG_PSI\nstatic int cgroup_io_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_IO);\n}\nstatic int cgroup_memory_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_MEM);\n}\nstatic int cgroup_cpu_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_CPU);\n}\n\nstatic ssize_t cgroup_pressure_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t\t  size_t nbytes, enum psi_res res)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct psi_trigger *new;\n\tstruct cgroup *cgrp;\n\tstruct psi_group *psi;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tcgroup_get(cgrp);\n\tcgroup_kn_unlock(of->kn);\n\n\tpsi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\tnew = psi_trigger_create(psi, buf, nbytes, res);\n\tif (IS_ERR(new)) {\n\t\tcgroup_put(cgrp);\n\t\treturn PTR_ERR(new);\n\t}\n\n\tpsi_trigger_replace(&ctx->psi.trigger, new);\n\n\tcgroup_put(cgrp);\n\n\treturn nbytes;\n}\n\nstatic ssize_t cgroup_io_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_IO);\n}\n\nstatic ssize_t cgroup_memory_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_MEM);\n}\n\nstatic ssize_t cgroup_cpu_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_CPU);\n}\n\nstatic __poll_t cgroup_pressure_poll(struct kernfs_open_file *of,\n\t\t\t\t\t  poll_table *pt)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\treturn psi_trigger_poll(&ctx->psi.trigger, of->file, pt);\n}\n\nstatic void cgroup_pressure_release(struct kernfs_open_file *of)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tpsi_trigger_replace(&ctx->psi.trigger, NULL);\n}\n\nbool cgroup_psi_enabled(void)\n{\n\treturn (cgroup_feature_disable_mask & (1 << OPT_FEATURE_PRESSURE)) == 0;\n}\n\n#else /* CONFIG_PSI */\nbool cgroup_psi_enabled(void)\n{\n\treturn false;\n}\n\n#endif /* CONFIG_PSI */\n\nstatic int cgroup_freeze_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"%d\\n\", cgrp->freezer.freeze);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_freeze_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint freeze;\n\n\tret = kstrtoint(strstrip(buf), 0, &freeze);\n\tif (ret)\n\t\treturn ret;\n\n\tif (freeze < 0 || freeze > 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgroup_freeze(cgrp, freeze);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic void __cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct css_task_iter it;\n\tstruct task_struct *task;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tspin_lock_irq(&css_set_lock);\n\tset_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n\n\tcss_task_iter_start(&cgrp->self, CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED, &it);\n\twhile ((task = css_task_iter_next(&it))) {\n\t\t/* Ignore kernel threads here. */\n\t\tif (task->flags & PF_KTHREAD)\n\t\t\tcontinue;\n\n\t\t/* Skip tasks that are already dying. */\n\t\tif (__fatal_signal_pending(task))\n\t\t\tcontinue;\n\n\t\tsend_sig(SIGKILL, task, 0);\n\t}\n\tcss_task_iter_end(&it);\n\n\tspin_lock_irq(&css_set_lock);\n\tclear_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n}\n\nstatic void cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct cgroup_subsys_state *css;\n\tstruct cgroup *dsct;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_pre(dsct, css, cgrp)\n\t\t__cgroup_kill(dsct);\n}\n\nstatic ssize_t cgroup_kill_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tssize_t ret = 0;\n\tint kill;\n\tstruct cgroup *cgrp;\n\n\tret = kstrtoint(strstrip(buf), 0, &kill);\n\tif (ret)\n\t\treturn ret;\n\n\tif (kill != 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/*\n\t * Killing is a process directed operation, i.e. the whole thread-group\n\t * is taken down so act like we do for cgroup.procs and only make this\n\t * writable in non-threaded cgroups.\n\t */\n\tif (cgroup_is_threaded(cgrp))\n\t\tret = -EOPNOTSUPP;\n\telse\n\t\tcgroup_kill(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_file_open(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->ns = current->nsproxy->cgroup_ns;\n\tget_cgroup_ns(ctx->ns);\n\tof->priv = ctx;\n\n\tif (!cft->open)\n\t\treturn 0;\n\n\tret = cft->open(of);\n\tif (ret) {\n\t\tput_cgroup_ns(ctx->ns);\n\t\tkfree(ctx);\n\t}\n\treturn ret;\n}\n\nstatic void cgroup_file_release(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tif (cft->release)\n\t\tcft->release(of);\n\tput_cgroup_ns(ctx->ns);\n\tkfree(ctx);\n}\n\nstatic ssize_t cgroup_file_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup *cgrp = of->kn->parent->priv;\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!nbytes)\n\t\treturn 0;\n\n\t/*\n\t * If namespaces are delegation boundaries, disallow writes to\n\t * files in an non-init namespace root from inside the namespace\n\t * except for the files explicitly marked delegatable -\n\t * cgroup.procs and cgroup.subtree_control.\n\t */\n\tif ((cgrp->root->flags & CGRP_ROOT_NS_DELEGATE) &&\n\t    !(cft->flags & CFTYPE_NS_DELEGATABLE) &&\n\t    ctx->ns != &init_cgroup_ns && ctx->ns->root_cset->dfl_cgrp == cgrp)\n\t\treturn -EPERM;\n\n\tif (cft->write)\n\t\treturn cft->write(of, buf, nbytes, off);\n\n\t/*\n\t * kernfs guarantees that a file isn't deleted with operations in\n\t * flight, which means that the matching css is and stays alive and\n\t * doesn't need to be pinned.  The RCU locking is not necessary\n\t * either.  It's just for the convenience of using cgroup_css().\n\t */\n\trcu_read_lock();\n\tcss = cgroup_css(cgrp, cft->ss);\n\trcu_read_unlock();\n\n\tif (cft->write_u64) {\n\t\tunsigned long long v;\n\t\tret = kstrtoull(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_u64(css, cft, v);\n\t} else if (cft->write_s64) {\n\t\tlong long v;\n\t\tret = kstrtoll(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_s64(css, cft, v);\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret ?: nbytes;\n}\n\nstatic __poll_t cgroup_file_poll(struct kernfs_open_file *of, poll_table *pt)\n{\n\tstruct cftype *cft = of_cft(of);\n\n\tif (cft->poll)\n\t\treturn cft->poll(of, pt);\n\n\treturn kernfs_generic_poll(of, pt);\n}\n\nstatic void *cgroup_seqfile_start(struct seq_file *seq, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_start(seq, ppos);\n}\n\nstatic void *cgroup_seqfile_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_next(seq, v, ppos);\n}\n\nstatic void cgroup_seqfile_stop(struct seq_file *seq, void *v)\n{\n\tif (seq_cft(seq)->seq_stop)\n\t\tseq_cft(seq)->seq_stop(seq, v);\n}\n\nstatic int cgroup_seqfile_show(struct seq_file *m, void *arg)\n{\n\tstruct cftype *cft = seq_cft(m);\n\tstruct cgroup_subsys_state *css = seq_css(m);\n\n\tif (cft->seq_show)\n\t\treturn cft->seq_show(m, arg);\n\n\tif (cft->read_u64)\n\t\tseq_printf(m, \"%llu\\n\", cft->read_u64(css, cft));\n\telse if (cft->read_s64)\n\t\tseq_printf(m, \"%lld\\n\", cft->read_s64(css, cft));\n\telse\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic struct kernfs_ops cgroup_kf_single_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\nstatic struct kernfs_ops cgroup_kf_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_start\t\t= cgroup_seqfile_start,\n\t.seq_next\t\t= cgroup_seqfile_next,\n\t.seq_stop\t\t= cgroup_seqfile_stop,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\n/* set uid and gid of cgroup dirs and files to that of the creator */\nstatic int cgroup_kn_set_ugid(struct kernfs_node *kn)\n{\n\tstruct iattr iattr = { .ia_valid = ATTR_UID | ATTR_GID,\n\t\t\t       .ia_uid = current_fsuid(),\n\t\t\t       .ia_gid = current_fsgid(), };\n\n\tif (uid_eq(iattr.ia_uid, GLOBAL_ROOT_UID) &&\n\t    gid_eq(iattr.ia_gid, GLOBAL_ROOT_GID))\n\t\treturn 0;\n\n\treturn kernfs_setattr(kn, &iattr);\n}\n\nstatic void cgroup_file_notify_timer(struct timer_list *timer)\n{\n\tcgroup_file_notify(container_of(timer, struct cgroup_file,\n\t\t\t\t\tnotify_timer));\n}\n\nstatic int cgroup_add_file(struct cgroup_subsys_state *css, struct cgroup *cgrp,\n\t\t\t   struct cftype *cft)\n{\n\tchar name[CGROUP_FILE_NAME_MAX];\n\tstruct kernfs_node *kn;\n\tstruct lock_class_key *key = NULL;\n\tint ret;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tkey = &cft->lockdep_key;\n#endif\n\tkn = __kernfs_create_file(cgrp->kn, cgroup_file_name(cgrp, cft, name),\n\t\t\t\t  cgroup_file_mode(cft),\n\t\t\t\t  GLOBAL_ROOT_UID, GLOBAL_ROOT_GID,\n\t\t\t\t  0, cft->kf_ops, cft,\n\t\t\t\t  NULL, key);\n\tif (IS_ERR(kn))\n\t\treturn PTR_ERR(kn);\n\n\tret = cgroup_kn_set_ugid(kn);\n\tif (ret) {\n\t\tkernfs_remove(kn);\n\t\treturn ret;\n\t}\n\n\tif (cft->file_offset) {\n\t\tstruct cgroup_file *cfile = (void *)css + cft->file_offset;\n\n\t\ttimer_setup(&cfile->notify_timer, cgroup_file_notify_timer, 0);\n\n\t\tspin_lock_irq(&cgroup_file_kn_lock);\n\t\tcfile->kn = kn;\n\t\tspin_unlock_irq(&cgroup_file_kn_lock);\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_addrm_files - add or remove files to a cgroup directory\n * @css: the target css\n * @cgrp: the target cgroup (usually css->cgroup)\n * @cfts: array of cftypes to be added\n * @is_add: whether to add or remove\n *\n * Depending on @is_add, add or remove files defined by @cfts on @cgrp.\n * For removals, this function never fails.\n */\nstatic int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add)\n{\n\tstruct cftype *cft, *cft_end = NULL;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\nrestart:\n\tfor (cft = cfts; cft != cft_end && cft->name[0] != '\\0'; cft++) {\n\t\t/* does cft->flags tell us to skip this file on @cgrp? */\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_ONLY_ON_DFL) && !cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_NOT_ON_DFL) && cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_NOT_ON_ROOT) && !cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_ONLY_ON_ROOT) && cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_DEBUG) && !cgroup_debug)\n\t\t\tcontinue;\n\t\tif (is_add) {\n\t\t\tret = cgroup_add_file(css, cgrp, cft);\n\t\t\tif (ret) {\n\t\t\t\tpr_warn(\"%s: failed to add %s, err=%d\\n\",\n\t\t\t\t\t__func__, cft->name, ret);\n\t\t\t\tcft_end = cft;\n\t\t\t\tis_add = false;\n\t\t\t\tgoto restart;\n\t\t\t}\n\t\t} else {\n\t\t\tcgroup_rm_file(cgrp, cft);\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int cgroup_apply_cftypes(struct cftype *cfts, bool is_add)\n{\n\tstruct cgroup_subsys *ss = cfts[0].ss;\n\tstruct cgroup *root = &ss->root->cgrp;\n\tstruct cgroup_subsys_state *css;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* add/rm files for all cgroups created before */\n\tcss_for_each_descendant_pre(css, cgroup_css(root, ss)) {\n\t\tstruct cgroup *cgrp = css->cgroup;\n\n\t\tif (!(css->flags & CSS_VISIBLE))\n\t\t\tcontinue;\n\n\t\tret = cgroup_addrm_files(css, cgrp, cfts, is_add);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tif (is_add && !ret)\n\t\tkernfs_activate(root->kn);\n\treturn ret;\n}\n\nstatic void cgroup_exit_cftypes(struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\t/* free copy for custom atomic_write_len, see init_cftypes() */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE)\n\t\t\tkfree(cft->kf_ops);\n\t\tcft->kf_ops = NULL;\n\t\tcft->ss = NULL;\n\n\t\t/* revert flags set by cgroup core while adding @cfts */\n\t\tcft->flags &= ~(__CFTYPE_ONLY_ON_DFL | __CFTYPE_NOT_ON_DFL);\n\t}\n}\n\nstatic int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\tstruct kernfs_ops *kf_ops;\n\n\t\tWARN_ON(cft->ss || cft->kf_ops);\n\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\n\t\tif (cft->seq_start)\n\t\t\tkf_ops = &cgroup_kf_ops;\n\t\telse\n\t\t\tkf_ops = &cgroup_kf_single_ops;\n\n\t\t/*\n\t\t * Ugh... if @cft wants a custom max_write_len, we need to\n\t\t * make a copy of kf_ops to set its atomic_write_len.\n\t\t */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE) {\n\t\t\tkf_ops = kmemdup(kf_ops, sizeof(*kf_ops), GFP_KERNEL);\n\t\t\tif (!kf_ops) {\n\t\t\t\tcgroup_exit_cftypes(cfts);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tkf_ops->atomic_write_len = cft->max_write_len;\n\t\t}\n\n\t\tcft->kf_ops = kf_ops;\n\t\tcft->ss = ss;\n\t}\n\n\treturn 0;\n}\n\nstatic int cgroup_rm_cftypes_locked(struct cftype *cfts)\n{\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tif (!cfts || !cfts[0].ss)\n\t\treturn -ENOENT;\n\n\tlist_del(&cfts->node);\n\tcgroup_apply_cftypes(cfts, false);\n\tcgroup_exit_cftypes(cfts);\n\treturn 0;\n}\n\n/**\n * cgroup_rm_cftypes - remove an array of cftypes from a subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Unregister @cfts.  Files described by @cfts are removed from all\n * existing cgroups and all future cgroups won't have them either.  This\n * function can be called anytime whether @cfts' subsys is attached or not.\n *\n * Returns 0 on successful unregistration, -ENOENT if @cfts is not\n * registered.\n */\nint cgroup_rm_cftypes(struct cftype *cfts)\n{\n\tint ret;\n\n\tmutex_lock(&cgroup_mutex);\n\tret = cgroup_rm_cftypes_locked(cfts);\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_cftypes - add an array of cftypes to a subsystem\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Register @cfts to @ss.  Files described by @cfts are created for all\n * existing cgroups to which @ss is attached and all future cgroups will\n * have them too.  This function can be called anytime whether @ss is\n * attached or not.\n *\n * Returns 0 on successful registration, -errno on failure.  Note that this\n * function currently returns 0 as long as @cfts registration is successful\n * even if some file creation attempts on existing cgroups fail.\n */\nstatic int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tint ret;\n\n\tif (!cgroup_ssid_enabled(ss->id))\n\t\treturn 0;\n\n\tif (!cfts || cfts[0].name[0] == '\\0')\n\t\treturn 0;\n\n\tret = cgroup_init_cftypes(ss, cfts);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&cgroup_mutex);\n\n\tlist_add_tail(&cfts->node, &ss->cfts);\n\tret = cgroup_apply_cftypes(cfts, true);\n\tif (ret)\n\t\tcgroup_rm_cftypes_locked(cfts);\n\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_dfl_cftypes - add an array of cftypes for default hierarchy\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the default hierarchy.\n */\nint cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_ONLY_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_add_legacy_cftypes - add an array of cftypes for legacy hierarchies\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the legacy hierarchies.\n */\nint cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_NOT_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_file_notify - generate a file modified event for a cgroup_file\n * @cfile: target cgroup_file\n *\n * @cfile must have been obtained by setting cftype->file_offset.\n */\nvoid cgroup_file_notify(struct cgroup_file *cfile)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cgroup_file_kn_lock, flags);\n\tif (cfile->kn) {\n\t\tunsigned long last = cfile->notified_at;\n\t\tunsigned long next = last + CGROUP_FILE_NOTIFY_MIN_INTV;\n\n\t\tif (time_in_range(jiffies, last, next)) {\n\t\t\ttimer_reduce(&cfile->notify_timer, next);\n\t\t} else {\n\t\t\tkernfs_notify(cfile->kn);\n\t\t\tcfile->notified_at = jiffies;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cgroup_file_kn_lock, flags);\n}\n\n/**\n * css_next_child - find the next child of a given css\n * @pos: the current position (%NULL to initiate traversal)\n * @parent: css whose children to walk\n *\n * This function returns the next child of @parent and should be called\n * under either cgroup_mutex or RCU read lock.  The only requirement is\n * that @parent and @pos are accessible.  The next sibling is guaranteed to\n * be returned regardless of their states.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,\n\t\t\t\t\t   struct cgroup_subsys_state *parent)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/*\n\t * @pos could already have been unlinked from the sibling list.\n\t * Once a cgroup is removed, its ->sibling.next is no longer\n\t * updated when its next sibling changes.  CSS_RELEASED is set when\n\t * @pos is taken off list, at which time its next pointer is valid,\n\t * and, as releases are serialized, the one pointed to by the next\n\t * pointer is guaranteed to not have started release yet.  This\n\t * implies that if we observe !CSS_RELEASED on @pos in this RCU\n\t * critical section, the one pointed to by its next pointer is\n\t * guaranteed to not have finished its RCU grace period even if we\n\t * have dropped rcu_read_lock() in-between iterations.\n\t *\n\t * If @pos has CSS_RELEASED set, its next pointer can't be\n\t * dereferenced; however, as each css is given a monotonically\n\t * increasing unique serial number and always appended to the\n\t * sibling list, the next one can be found by walking the parent's\n\t * children until the first css with higher serial number than\n\t * @pos's.  While this path can be slower, it happens iff iteration\n\t * races against release and the race window is very small.\n\t */\n\tif (!pos) {\n\t\tnext = list_entry_rcu(parent->children.next, struct cgroup_subsys_state, sibling);\n\t} else if (likely(!(pos->flags & CSS_RELEASED))) {\n\t\tnext = list_entry_rcu(pos->sibling.next, struct cgroup_subsys_state, sibling);\n\t} else {\n\t\tlist_for_each_entry_rcu(next, &parent->children, sibling,\n\t\t\t\t\tlockdep_is_held(&cgroup_mutex))\n\t\t\tif (next->serial_nr > pos->serial_nr)\n\t\t\t\tbreak;\n\t}\n\n\t/*\n\t * @next, if not pointing to the head, can be dereferenced and is\n\t * the next sibling.\n\t */\n\tif (&next->sibling != &parent->children)\n\t\treturn next;\n\treturn NULL;\n}\n\n/**\n * css_next_descendant_pre - find the next descendant for pre-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_pre().  Find the next descendant\n * to visit for pre-order traversal of @root's descendants.  @root is\n * included in the iteration and the first node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @root are accessible and @pos is a descendant of @root.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_pre(struct cgroup_subsys_state *pos,\n\t\t\tstruct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit @root */\n\tif (!pos)\n\t\treturn root;\n\n\t/* visit the first child if exists */\n\tnext = css_next_child(NULL, pos);\n\tif (next)\n\t\treturn next;\n\n\t/* no child, visit my or the closest ancestor's next sibling */\n\twhile (pos != root) {\n\t\tnext = css_next_child(pos, pos->parent);\n\t\tif (next)\n\t\t\treturn next;\n\t\tpos = pos->parent;\n\t}\n\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(css_next_descendant_pre);\n\n/**\n * css_rightmost_descendant - return the rightmost descendant of a css\n * @pos: css of interest\n *\n * Return the rightmost descendant of @pos.  If there's no descendant, @pos\n * is returned.  This can be used during pre-order traversal to skip\n * subtree of @pos.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct rightmost descendant as\n * long as @pos is accessible.\n */\nstruct cgroup_subsys_state *\ncss_rightmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last, *tmp;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\tdo {\n\t\tlast = pos;\n\t\t/* ->prev isn't RCU safe, walk ->next till the end */\n\t\tpos = NULL;\n\t\tcss_for_each_child(tmp, last)\n\t\t\tpos = tmp;\n\t} while (pos);\n\n\treturn last;\n}\n\nstatic struct cgroup_subsys_state *\ncss_leftmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last;\n\n\tdo {\n\t\tlast = pos;\n\t\tpos = css_next_child(NULL, pos);\n\t} while (pos);\n\n\treturn last;\n}\n\n/**\n * css_next_descendant_post - find the next descendant for post-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_post().  Find the next descendant\n * to visit for post-order traversal of @root's descendants.  @root is\n * included in the iteration and the last node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @cgroup are accessible and @pos is a descendant of\n * @cgroup.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_post(struct cgroup_subsys_state *pos,\n\t\t\t struct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit leftmost descendant which may be @root */\n\tif (!pos)\n\t\treturn css_leftmost_descendant(root);\n\n\t/* if we visited @root, we're done */\n\tif (pos == root)\n\t\treturn NULL;\n\n\t/* if there's an unvisited sibling, visit its leftmost descendant */\n\tnext = css_next_child(pos, pos->parent);\n\tif (next)\n\t\treturn css_leftmost_descendant(next);\n\n\t/* no sibling left, visit parent */\n\treturn pos->parent;\n}\n\n/**\n * css_has_online_children - does a css have online children\n * @css: the target css\n *\n * Returns %true if @css has any online children; otherwise, %false.  This\n * function can be called from any context but the caller is responsible\n * for synchronizing against on/offlining as necessary.\n */\nbool css_has_online_children(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys_state *child;\n\tbool ret = false;\n\n\trcu_read_lock();\n\tcss_for_each_child(child, css) {\n\t\tif (child->flags & CSS_ONLINE) {\n\t\t\tret = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)\n{\n\tstruct list_head *l;\n\tstruct cgrp_cset_link *link;\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* find the next threaded cset */\n\tif (it->tcset_pos) {\n\t\tl = it->tcset_pos->next;\n\n\t\tif (l != it->tcset_head) {\n\t\t\tit->tcset_pos = l;\n\t\t\treturn container_of(l, struct css_set,\n\t\t\t\t\t    threaded_csets_node);\n\t\t}\n\n\t\tit->tcset_pos = NULL;\n\t}\n\n\t/* find the next cset */\n\tl = it->cset_pos;\n\tl = l->next;\n\tif (l == it->cset_head) {\n\t\tit->cset_pos = NULL;\n\t\treturn NULL;\n\t}\n\n\tif (it->ss) {\n\t\tcset = container_of(l, struct css_set, e_cset_node[it->ss->id]);\n\t} else {\n\t\tlink = list_entry(l, struct cgrp_cset_link, cset_link);\n\t\tcset = link->cset;\n\t}\n\n\tit->cset_pos = l;\n\n\t/* initialize threaded css_set walking */\n\tif (it->flags & CSS_TASK_ITER_THREADED) {\n\t\tif (it->cur_dcset)\n\t\t\tput_css_set_locked(it->cur_dcset);\n\t\tit->cur_dcset = cset;\n\t\tget_css_set(cset);\n\n\t\tit->tcset_head = &cset->threaded_csets;\n\t\tit->tcset_pos = &cset->threaded_csets;\n\t}\n\n\treturn cset;\n}\n\n/**\n * css_task_iter_advance_css_set - advance a task iterator to the next css_set\n * @it: the iterator to advance\n *\n * Advance @it to the next css_set to walk.\n */\nstatic void css_task_iter_advance_css_set(struct css_task_iter *it)\n{\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* Advance to the next non-empty css_set and find first non-empty tasks list*/\n\twhile ((cset = css_task_iter_next_css_set(it))) {\n\t\tif (!list_empty(&cset->tasks)) {\n\t\t\tit->cur_tasks_head = &cset->tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->mg_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->mg_tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->dying_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->dying_tasks;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cset) {\n\t\tit->task_pos = NULL;\n\t\treturn;\n\t}\n\tit->task_pos = it->cur_tasks_head->next;\n\n\t/*\n\t * We don't keep css_sets locked across iteration steps and thus\n\t * need to take steps to ensure that iteration can be resumed after\n\t * the lock is re-acquired.  Iteration is performed at two levels -\n\t * css_sets and tasks in them.\n\t *\n\t * Once created, a css_set never leaves its cgroup lists, so a\n\t * pinned css_set is guaranteed to stay put and we can resume\n\t * iteration afterwards.\n\t *\n\t * Tasks may leave @cset across iteration steps.  This is resolved\n\t * by registering each iterator with the css_set currently being\n\t * walked and making css_set_move_task() advance iterators whose\n\t * next task is leaving.\n\t */\n\tif (it->cur_cset) {\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t}\n\tget_css_set(cset);\n\tit->cur_cset = cset;\n\tlist_add(&it->iters_node, &cset->task_iters);\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_cred",
          "args": [
            "tcred"
          ],
          "line": 519
        },
        "resolved": true,
        "details": {
          "function_name": "__put_cred",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cred.c",
          "lines": "135-154",
          "snippet": "void __put_cred(struct cred *cred)\n{\n\tkdebug(\"__put_cred(%p{%d,%d})\", cred,\n\t       atomic_read(&cred->usage),\n\t       read_cred_subscribers(cred));\n\n\tBUG_ON(atomic_read(&cred->usage) != 0);\n#ifdef CONFIG_DEBUG_CREDENTIALS\n\tBUG_ON(read_cred_subscribers(cred) != 0);\n\tcred->magic = CRED_MAGIC_DEAD;\n\tcred->put_addr = __builtin_return_address(0);\n#endif\n\tBUG_ON(cred == current->cred);\n\tBUG_ON(cred == current->real_cred);\n\n\tif (cred->non_rcu)\n\t\tput_cred_rcu(&cred->rcu);\n\telse\n\t\tcall_rcu(&cred->rcu, put_cred_rcu);\n}",
          "includes": [
            "#include <linux/uidgid.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/security.h>",
            "#include <linux/init_task.h>",
            "#include <linux/keyctl.h>",
            "#include <linux/key.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/cred.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uidgid.h>\n#include <linux/cn_proc.h>\n#include <linux/binfmts.h>\n#include <linux/security.h>\n#include <linux/init_task.h>\n#include <linux/keyctl.h>\n#include <linux/key.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/cred.h>\n#include <linux/export.h>\n\nvoid __put_cred(struct cred *cred)\n{\n\tkdebug(\"__put_cred(%p{%d,%d})\", cred,\n\t       atomic_read(&cred->usage),\n\t       read_cred_subscribers(cred));\n\n\tBUG_ON(atomic_read(&cred->usage) != 0);\n#ifdef CONFIG_DEBUG_CREDENTIALS\n\tBUG_ON(read_cred_subscribers(cred) != 0);\n\tcred->magic = CRED_MAGIC_DEAD;\n\tcred->put_addr = __builtin_return_address(0);\n#endif\n\tBUG_ON(cred == current->cred);\n\tBUG_ON(cred == current->real_cred);\n\n\tif (cred->non_rcu)\n\t\tput_cred_rcu(&cred->rcu);\n\telse\n\t\tcall_rcu(&cred->rcu, put_cred_rcu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "uid_eq",
          "args": [
            "cred->euid",
            "tcred->suid"
          ],
          "line": 517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "uid_eq",
          "args": [
            "cred->euid",
            "tcred->uid"
          ],
          "line": 516
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "uid_eq",
          "args": [
            "cred->euid",
            "GLOBAL_ROOT_UID"
          ],
          "line": 515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_task_cred",
          "args": [
            "task"
          ],
          "line": 514
        },
        "resolved": true,
        "details": {
          "function_name": "get_task_cred",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cred.c",
          "lines": "196-209",
          "snippet": "const struct cred *get_task_cred(struct task_struct *task)\n{\n\tconst struct cred *cred;\n\n\trcu_read_lock();\n\n\tdo {\n\t\tcred = __task_cred((task));\n\t\tBUG_ON(!cred);\n\t} while (!get_cred_rcu(cred));\n\n\trcu_read_unlock();\n\treturn cred;\n}",
          "includes": [
            "#include <linux/uidgid.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/security.h>",
            "#include <linux/init_task.h>",
            "#include <linux/keyctl.h>",
            "#include <linux/key.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched.h>",
            "#include <linux/slab.h>",
            "#include <linux/cred.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uidgid.h>\n#include <linux/cn_proc.h>\n#include <linux/binfmts.h>\n#include <linux/security.h>\n#include <linux/init_task.h>\n#include <linux/keyctl.h>\n#include <linux/key.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched.h>\n#include <linux/slab.h>\n#include <linux/cred.h>\n#include <linux/export.h>\n\nconst struct cred *get_task_cred(struct task_struct *task)\n{\n\tconst struct cred *cred;\n\n\trcu_read_lock();\n\n\tdo {\n\t\tcred = __task_cred((task));\n\t\tBUG_ON(!cred);\n\t} while (!get_cred_rcu(cred));\n\n\trcu_read_unlock();\n\treturn cred;\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR_OR_ZERO",
          "args": [
            "task"
          ],
          "line": 504
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_procs_write_start",
          "args": [
            "buf",
            "threadgroup",
            "&locked"
          ],
          "line": 503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_kn_lock_live",
          "args": [
            "of->kn",
            "false"
          ],
          "line": 499
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_kn_lock_live",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1615-1644",
          "snippet": "struct cgroup *cgroup_kn_lock_live(struct kernfs_node *kn, bool drain_offline)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\t/*\n\t * We're gonna grab cgroup_mutex which nests outside kernfs\n\t * active_ref.  cgroup liveliness check alone provides enough\n\t * protection against removal.  Ensure @cgrp stays accessible and\n\t * break the active_ref protection.\n\t */\n\tif (!cgroup_tryget(cgrp))\n\t\treturn NULL;\n\tkernfs_break_active_protection(kn);\n\n\tif (drain_offline)\n\t\tcgroup_lock_and_drain_offline(cgrp);\n\telse\n\t\tmutex_lock(&cgroup_mutex);\n\n\tif (!cgroup_is_dead(cgrp))\n\t\treturn cgrp;\n\n\tcgroup_kn_unlock(kn);\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nstruct cgroup *cgroup_kn_lock_live(struct kernfs_node *kn, bool drain_offline)\n{\n\tstruct cgroup *cgrp;\n\n\tif (kernfs_type(kn) == KERNFS_DIR)\n\t\tcgrp = kn->priv;\n\telse\n\t\tcgrp = kn->parent->priv;\n\n\t/*\n\t * We're gonna grab cgroup_mutex which nests outside kernfs\n\t * active_ref.  cgroup liveliness check alone provides enough\n\t * protection against removal.  Ensure @cgrp stays accessible and\n\t * break the active_ref protection.\n\t */\n\tif (!cgroup_tryget(cgrp))\n\t\treturn NULL;\n\tkernfs_break_active_protection(kn);\n\n\tif (drain_offline)\n\t\tcgroup_lock_and_drain_offline(cgrp);\n\telse\n\t\tmutex_lock(&cgroup_mutex);\n\n\tif (!cgroup_is_dead(cgrp))\n\t\treturn cgrp;\n\n\tcgroup_kn_unlock(kn);\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic ssize_t __cgroup1_procs_write(struct kernfs_open_file *of,\n\t\t\t\t     char *buf, size_t nbytes, loff_t off,\n\t\t\t\t     bool threadgroup)\n{\n\tstruct cgroup *cgrp;\n\tstruct task_struct *task;\n\tconst struct cred *cred, *tcred;\n\tssize_t ret;\n\tbool locked;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\ttask = cgroup_procs_write_start(buf, threadgroup, &locked);\n\tret = PTR_ERR_OR_ZERO(task);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/*\n\t * Even if we're attaching all tasks in the thread group, we only need\n\t * to check permissions on one of them. Check permissions using the\n\t * credentials from file open to protect against inherited fd attacks.\n\t */\n\tcred = of->file->f_cred;\n\ttcred = get_task_cred(task);\n\tif (!uid_eq(cred->euid, GLOBAL_ROOT_UID) &&\n\t    !uid_eq(cred->euid, tcred->uid) &&\n\t    !uid_eq(cred->euid, tcred->suid))\n\t\tret = -EACCES;\n\tput_cred(tcred);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tret = cgroup_attach_task(cgrp, task, threadgroup);\n\nout_finish:\n\tcgroup_procs_write_finish(task, locked);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}"
  },
  {
    "function_name": "cgroup_pidlist_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "482-487",
    "snippet": "static int cgroup_pidlist_show(struct seq_file *s, void *v)\n{\n\tseq_printf(s, \"%d\\n\", *(int *)v);\n\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "seq_printf",
          "args": [
            "s",
            "\"%d\\n\"",
            "*(int *)v"
          ],
          "line": 484
        },
        "resolved": true,
        "details": {
          "function_name": "trace_seq_printf",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_seq.c",
          "lines": "81-100",
          "snippet": "void trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}",
          "includes": [
            "#include <linux/trace_seq.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/uaccess.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/trace_seq.h>\n#include <linux/seq_file.h>\n#include <linux/uaccess.h>\n\nvoid trace_seq_printf(struct trace_seq *s, const char *fmt, ...)\n{\n\tunsigned int save_len = s->seq.len;\n\tva_list ap;\n\n\tif (s->full)\n\t\treturn;\n\n\t__trace_seq_init(s);\n\n\tva_start(ap, fmt);\n\tseq_buf_vprintf(&s->seq, fmt, ap);\n\tva_end(ap);\n\n\t/* If we can't write it all, don't bother writing anything */\n\tif (unlikely(seq_buf_has_overflowed(&s->seq))) {\n\t\ts->seq.len = save_len;\n\t\ts->full = 1;\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_pidlist_show(struct seq_file *s, void *v)\n{\n\tseq_printf(s, \"%d\\n\", *(int *)v);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_pidlist_next",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "461-480",
    "snippet": "static void *cgroup_pidlist_next(struct seq_file *s, void *v, loff_t *pos)\n{\n\tstruct kernfs_open_file *of = s->private;\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup_pidlist *l = ctx->procs1.pidlist;\n\tpid_t *p = v;\n\tpid_t *end = l->list + l->length;\n\t/*\n\t * Advance to the next pid in the array. If this goes off the\n\t * end, we're done\n\t */\n\tp++;\n\tif (p >= end) {\n\t\t(*pos)++;\n\t\treturn NULL;\n\t} else {\n\t\t*pos = *p;\n\t\treturn p;\n\t}\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic void *cgroup_pidlist_next(struct seq_file *s, void *v, loff_t *pos)\n{\n\tstruct kernfs_open_file *of = s->private;\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup_pidlist *l = ctx->procs1.pidlist;\n\tpid_t *p = v;\n\tpid_t *end = l->list + l->length;\n\t/*\n\t * Advance to the next pid in the array. If this goes off the\n\t * end, we're done\n\t */\n\tp++;\n\tif (p >= end) {\n\t\t(*pos)++;\n\t\treturn NULL;\n\t} else {\n\t\t*pos = *p;\n\t\treturn p;\n\t}\n}"
  },
  {
    "function_name": "cgroup_pidlist_stop",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "449-459",
    "snippet": "static void cgroup_pidlist_stop(struct seq_file *s, void *v)\n{\n\tstruct kernfs_open_file *of = s->private;\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup_pidlist *l = ctx->procs1.pidlist;\n\n\tif (l)\n\t\tmod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork,\n\t\t\t\t CGROUP_PIDLIST_DESTROY_DELAY);\n\tmutex_unlock(&seq_css(s)->cgroup->pidlist_mutex);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [
      "#define CGROUP_PIDLIST_DESTROY_DELAY\tHZ"
    ],
    "globals_used": [
      "static struct workqueue_struct *cgroup_pidlist_destroy_wq;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&seq_css(s)->cgroup->pidlist_mutex"
          ],
          "line": 458
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_css",
          "args": [
            "s"
          ],
          "line": 458
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mod_delayed_work",
          "args": [
            "cgroup_pidlist_destroy_wq",
            "&l->destroy_dwork",
            "CGROUP_PIDLIST_DESTROY_DELAY"
          ],
          "line": 456
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_mod_delayed_work",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "1239-1283",
          "snippet": "bool kthread_mod_delayed_work(struct kthread_worker *worker,\n\t\t\t      struct kthread_delayed_work *dwork,\n\t\t\t      unsigned long delay)\n{\n\tstruct kthread_work *work = &dwork->work;\n\tunsigned long flags;\n\tint ret;\n\n\traw_spin_lock_irqsave(&worker->lock, flags);\n\n\t/* Do not bother with canceling when never queued. */\n\tif (!work->worker) {\n\t\tret = false;\n\t\tgoto fast_queue;\n\t}\n\n\t/* Work must not be used with >1 worker, see kthread_queue_work() */\n\tWARN_ON_ONCE(work->worker != worker);\n\n\t/*\n\t * Temporary cancel the work but do not fight with another command\n\t * that is canceling the work as well.\n\t *\n\t * It is a bit tricky because of possible races with another\n\t * mod_delayed_work() and cancel_delayed_work() callers.\n\t *\n\t * The timer must be canceled first because worker->lock is released\n\t * when doing so. But the work can be removed from the queue (list)\n\t * only when it can be queued again so that the return value can\n\t * be used for reference counting.\n\t */\n\tkthread_cancel_delayed_work_timer(work, &flags);\n\tif (work->canceling) {\n\t\t/* The number of works in the queue does not change. */\n\t\tret = true;\n\t\tgoto out;\n\t}\n\tret = __kthread_cancel_work(work);\n\nfast_queue:\n\t__kthread_queue_delayed_work(worker, dwork, delay);\nout:\n\traw_spin_unlock_irqrestore(&worker->lock, flags);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_mod_delayed_work(struct kthread_worker *worker,\n\t\t\t      struct kthread_delayed_work *dwork,\n\t\t\t      unsigned long delay)\n{\n\tstruct kthread_work *work = &dwork->work;\n\tunsigned long flags;\n\tint ret;\n\n\traw_spin_lock_irqsave(&worker->lock, flags);\n\n\t/* Do not bother with canceling when never queued. */\n\tif (!work->worker) {\n\t\tret = false;\n\t\tgoto fast_queue;\n\t}\n\n\t/* Work must not be used with >1 worker, see kthread_queue_work() */\n\tWARN_ON_ONCE(work->worker != worker);\n\n\t/*\n\t * Temporary cancel the work but do not fight with another command\n\t * that is canceling the work as well.\n\t *\n\t * It is a bit tricky because of possible races with another\n\t * mod_delayed_work() and cancel_delayed_work() callers.\n\t *\n\t * The timer must be canceled first because worker->lock is released\n\t * when doing so. But the work can be removed from the queue (list)\n\t * only when it can be queued again so that the return value can\n\t * be used for reference counting.\n\t */\n\tkthread_cancel_delayed_work_timer(work, &flags);\n\tif (work->canceling) {\n\t\t/* The number of works in the queue does not change. */\n\t\tret = true;\n\t\tgoto out;\n\t}\n\tret = __kthread_cancel_work(work);\n\nfast_queue:\n\t__kthread_queue_delayed_work(worker, dwork, delay);\nout:\n\traw_spin_unlock_irqrestore(&worker->lock, flags);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_PIDLIST_DESTROY_DELAY\tHZ\n\nstatic struct workqueue_struct *cgroup_pidlist_destroy_wq;\n\nstatic void cgroup_pidlist_stop(struct seq_file *s, void *v)\n{\n\tstruct kernfs_open_file *of = s->private;\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup_pidlist *l = ctx->procs1.pidlist;\n\n\tif (l)\n\t\tmod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork,\n\t\t\t\t CGROUP_PIDLIST_DESTROY_DELAY);\n\tmutex_unlock(&seq_css(s)->cgroup->pidlist_mutex);\n}"
  },
  {
    "function_name": "cgroup_pidlist_start",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "388-447",
    "snippet": "static void *cgroup_pidlist_start(struct seq_file *s, loff_t *pos)\n{\n\t/*\n\t * Initially we receive a position value that corresponds to\n\t * one more than the last pid shown (or 0 on the first call or\n\t * after a seek to the start). Use a binary-search to find the\n\t * next pid to display, if any\n\t */\n\tstruct kernfs_open_file *of = s->private;\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup *cgrp = seq_css(s)->cgroup;\n\tstruct cgroup_pidlist *l;\n\tenum cgroup_filetype type = seq_cft(s)->private;\n\tint index = 0, pid = *pos;\n\tint *iter, ret;\n\n\tmutex_lock(&cgrp->pidlist_mutex);\n\n\t/*\n\t * !NULL @ctx->procs1.pidlist indicates that this isn't the first\n\t * start() after open. If the matching pidlist is around, we can use\n\t * that. Look for it. Note that @ctx->procs1.pidlist can't be used\n\t * directly. It could already have been destroyed.\n\t */\n\tif (ctx->procs1.pidlist)\n\t\tctx->procs1.pidlist = cgroup_pidlist_find(cgrp, type);\n\n\t/*\n\t * Either this is the first start() after open or the matching\n\t * pidlist has been destroyed inbetween.  Create a new one.\n\t */\n\tif (!ctx->procs1.pidlist) {\n\t\tret = pidlist_array_load(cgrp, type, &ctx->procs1.pidlist);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t}\n\tl = ctx->procs1.pidlist;\n\n\tif (pid) {\n\t\tint end = l->length;\n\n\t\twhile (index < end) {\n\t\t\tint mid = (index + end) / 2;\n\t\t\tif (l->list[mid] == pid) {\n\t\t\t\tindex = mid;\n\t\t\t\tbreak;\n\t\t\t} else if (l->list[mid] <= pid)\n\t\t\t\tindex = mid + 1;\n\t\t\telse\n\t\t\t\tend = mid;\n\t\t}\n\t}\n\t/* If we're off the end of the array, we're done */\n\tif (index >= l->length)\n\t\treturn NULL;\n\t/* Update the abstract position to be the actual pid that we found */\n\titer = l->list + index;\n\t*pos = *iter;\n\treturn iter;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "ret"
          ],
          "line": 422
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pidlist_array_load",
          "args": [
            "cgrp",
            "type",
            "&ctx->procs1.pidlist"
          ],
          "line": 420
        },
        "resolved": true,
        "details": {
          "function_name": "pidlist_array_load",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "326-380",
          "snippet": "static int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,\n\t\t\t      struct cgroup_pidlist **lp)\n{\n\tpid_t *array;\n\tint length;\n\tint pid, n = 0; /* used for populating the array */\n\tstruct css_task_iter it;\n\tstruct task_struct *tsk;\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\t/*\n\t * If cgroup gets more users after we read count, we won't have\n\t * enough space - tough.  This race is indistinguishable to the\n\t * caller from the case that the additional cgroup users didn't\n\t * show up until sometime later on.\n\t */\n\tlength = cgroup_task_count(cgrp);\n\tarray = kvmalloc_array(length, sizeof(pid_t), GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\t/* now, populate the array */\n\tcss_task_iter_start(&cgrp->self, 0, &it);\n\twhile ((tsk = css_task_iter_next(&it))) {\n\t\tif (unlikely(n == length))\n\t\t\tbreak;\n\t\t/* get tgid or pid for procs or tasks file respectively */\n\t\tif (type == CGROUP_FILE_PROCS)\n\t\t\tpid = task_tgid_vnr(tsk);\n\t\telse\n\t\t\tpid = task_pid_vnr(tsk);\n\t\tif (pid > 0) /* make sure to only use valid results */\n\t\t\tarray[n++] = pid;\n\t}\n\tcss_task_iter_end(&it);\n\tlength = n;\n\t/* now sort & (if procs) strip out duplicates */\n\tsort(array, length, sizeof(pid_t), cmppid, NULL);\n\tif (type == CGROUP_FILE_PROCS)\n\t\tlength = pidlist_uniq(array, length);\n\n\tl = cgroup_pidlist_find_create(cgrp, type);\n\tif (!l) {\n\t\tkvfree(array);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* store array, freeing old if necessary */\n\tkvfree(l->list);\n\tl->list = array;\n\tl->length = length;\n\t*lp = l;\n\treturn 0;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,\n\t\t\t      struct cgroup_pidlist **lp)\n{\n\tpid_t *array;\n\tint length;\n\tint pid, n = 0; /* used for populating the array */\n\tstruct css_task_iter it;\n\tstruct task_struct *tsk;\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\t/*\n\t * If cgroup gets more users after we read count, we won't have\n\t * enough space - tough.  This race is indistinguishable to the\n\t * caller from the case that the additional cgroup users didn't\n\t * show up until sometime later on.\n\t */\n\tlength = cgroup_task_count(cgrp);\n\tarray = kvmalloc_array(length, sizeof(pid_t), GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\t/* now, populate the array */\n\tcss_task_iter_start(&cgrp->self, 0, &it);\n\twhile ((tsk = css_task_iter_next(&it))) {\n\t\tif (unlikely(n == length))\n\t\t\tbreak;\n\t\t/* get tgid or pid for procs or tasks file respectively */\n\t\tif (type == CGROUP_FILE_PROCS)\n\t\t\tpid = task_tgid_vnr(tsk);\n\t\telse\n\t\t\tpid = task_pid_vnr(tsk);\n\t\tif (pid > 0) /* make sure to only use valid results */\n\t\t\tarray[n++] = pid;\n\t}\n\tcss_task_iter_end(&it);\n\tlength = n;\n\t/* now sort & (if procs) strip out duplicates */\n\tsort(array, length, sizeof(pid_t), cmppid, NULL);\n\tif (type == CGROUP_FILE_PROCS)\n\t\tlength = pidlist_uniq(array, length);\n\n\tl = cgroup_pidlist_find_create(cgrp, type);\n\tif (!l) {\n\t\tkvfree(array);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* store array, freeing old if necessary */\n\tkvfree(l->list);\n\tl->list = array;\n\tl->length = length;\n\t*lp = l;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_pidlist_find",
          "args": [
            "cgrp",
            "type"
          ],
          "line": 413
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_pidlist_find_create",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "298-321",
          "snippet": "static struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&cgrp->pidlist_mutex"
          ],
          "line": 404
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "seq_cft",
          "args": [
            "s"
          ],
          "line": 400
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "seq_css",
          "args": [
            "s"
          ],
          "line": 398
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic void *cgroup_pidlist_start(struct seq_file *s, loff_t *pos)\n{\n\t/*\n\t * Initially we receive a position value that corresponds to\n\t * one more than the last pid shown (or 0 on the first call or\n\t * after a seek to the start). Use a binary-search to find the\n\t * next pid to display, if any\n\t */\n\tstruct kernfs_open_file *of = s->private;\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup *cgrp = seq_css(s)->cgroup;\n\tstruct cgroup_pidlist *l;\n\tenum cgroup_filetype type = seq_cft(s)->private;\n\tint index = 0, pid = *pos;\n\tint *iter, ret;\n\n\tmutex_lock(&cgrp->pidlist_mutex);\n\n\t/*\n\t * !NULL @ctx->procs1.pidlist indicates that this isn't the first\n\t * start() after open. If the matching pidlist is around, we can use\n\t * that. Look for it. Note that @ctx->procs1.pidlist can't be used\n\t * directly. It could already have been destroyed.\n\t */\n\tif (ctx->procs1.pidlist)\n\t\tctx->procs1.pidlist = cgroup_pidlist_find(cgrp, type);\n\n\t/*\n\t * Either this is the first start() after open or the matching\n\t * pidlist has been destroyed inbetween.  Create a new one.\n\t */\n\tif (!ctx->procs1.pidlist) {\n\t\tret = pidlist_array_load(cgrp, type, &ctx->procs1.pidlist);\n\t\tif (ret)\n\t\t\treturn ERR_PTR(ret);\n\t}\n\tl = ctx->procs1.pidlist;\n\n\tif (pid) {\n\t\tint end = l->length;\n\n\t\twhile (index < end) {\n\t\t\tint mid = (index + end) / 2;\n\t\t\tif (l->list[mid] == pid) {\n\t\t\t\tindex = mid;\n\t\t\t\tbreak;\n\t\t\t} else if (l->list[mid] <= pid)\n\t\t\t\tindex = mid + 1;\n\t\t\telse\n\t\t\t\tend = mid;\n\t\t}\n\t}\n\t/* If we're off the end of the array, we're done */\n\tif (index >= l->length)\n\t\treturn NULL;\n\t/* Update the abstract position to be the actual pid that we found */\n\titer = l->list + index;\n\t*pos = *iter;\n\treturn iter;\n}"
  },
  {
    "function_name": "pidlist_array_load",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "326-380",
    "snippet": "static int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,\n\t\t\t      struct cgroup_pidlist **lp)\n{\n\tpid_t *array;\n\tint length;\n\tint pid, n = 0; /* used for populating the array */\n\tstruct css_task_iter it;\n\tstruct task_struct *tsk;\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\t/*\n\t * If cgroup gets more users after we read count, we won't have\n\t * enough space - tough.  This race is indistinguishable to the\n\t * caller from the case that the additional cgroup users didn't\n\t * show up until sometime later on.\n\t */\n\tlength = cgroup_task_count(cgrp);\n\tarray = kvmalloc_array(length, sizeof(pid_t), GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\t/* now, populate the array */\n\tcss_task_iter_start(&cgrp->self, 0, &it);\n\twhile ((tsk = css_task_iter_next(&it))) {\n\t\tif (unlikely(n == length))\n\t\t\tbreak;\n\t\t/* get tgid or pid for procs or tasks file respectively */\n\t\tif (type == CGROUP_FILE_PROCS)\n\t\t\tpid = task_tgid_vnr(tsk);\n\t\telse\n\t\t\tpid = task_pid_vnr(tsk);\n\t\tif (pid > 0) /* make sure to only use valid results */\n\t\t\tarray[n++] = pid;\n\t}\n\tcss_task_iter_end(&it);\n\tlength = n;\n\t/* now sort & (if procs) strip out duplicates */\n\tsort(array, length, sizeof(pid_t), cmppid, NULL);\n\tif (type == CGROUP_FILE_PROCS)\n\t\tlength = pidlist_uniq(array, length);\n\n\tl = cgroup_pidlist_find_create(cgrp, type);\n\tif (!l) {\n\t\tkvfree(array);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* store array, freeing old if necessary */\n\tkvfree(l->list);\n\tl->list = array;\n\tl->length = length;\n\t*lp = l;\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "l->list"
          ],
          "line": 375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "array"
          ],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_pidlist_find_create",
          "args": [
            "cgrp",
            "type"
          ],
          "line": 368
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_pidlist_find_create",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "298-321",
          "snippet": "static struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pidlist_uniq",
          "args": [
            "array",
            "length"
          ],
          "line": 366
        },
        "resolved": true,
        "details": {
          "function_name": "pidlist_uniq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "237-261",
          "snippet": "static int pidlist_uniq(pid_t *list, int length)\n{\n\tint src, dest = 1;\n\n\t/*\n\t * we presume the 0th element is unique, so i starts at 1. trivial\n\t * edge cases first; no work needs to be done for either\n\t */\n\tif (length == 0 || length == 1)\n\t\treturn length;\n\t/* src and dest walk down the list; dest counts unique elements */\n\tfor (src = 1; src < length; src++) {\n\t\t/* find next unique element */\n\t\twhile (list[src] == list[src-1]) {\n\t\t\tsrc++;\n\t\t\tif (src == length)\n\t\t\t\tgoto after;\n\t\t}\n\t\t/* dest always points to where the next unique element goes */\n\t\tlist[dest] = list[src];\n\t\tdest++;\n\t}\nafter:\n\treturn dest;\n}",
          "includes": [
            "#include <trace/events/cgroup.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/cgroupstats.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/magic.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/delay.h>",
            "#include <linux/sort.h>",
            "#include <linux/kmod.h>",
            "#include <linux/ctype.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int pidlist_uniq(pid_t *list, int length)\n{\n\tint src, dest = 1;\n\n\t/*\n\t * we presume the 0th element is unique, so i starts at 1. trivial\n\t * edge cases first; no work needs to be done for either\n\t */\n\tif (length == 0 || length == 1)\n\t\treturn length;\n\t/* src and dest walk down the list; dest counts unique elements */\n\tfor (src = 1; src < length; src++) {\n\t\t/* find next unique element */\n\t\twhile (list[src] == list[src-1]) {\n\t\t\tsrc++;\n\t\t\tif (src == length)\n\t\t\t\tgoto after;\n\t\t}\n\t\t/* dest always points to where the next unique element goes */\n\t\tlist[dest] = list[src];\n\t\tdest++;\n\t}\nafter:\n\treturn dest;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sort",
          "args": [
            "array",
            "length",
            "sizeof(pid_t)",
            "cmppid",
            "NULL"
          ],
          "line": 364
        },
        "resolved": true,
        "details": {
          "function_name": "sort_secondary",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/tracing_map.c",
          "lines": "998-1043",
          "snippet": "static void sort_secondary(struct tracing_map *map,\n\t\t\t   const struct tracing_map_sort_entry **entries,\n\t\t\t   unsigned int n_entries,\n\t\t\t   struct tracing_map_sort_key *primary_key,\n\t\t\t   struct tracing_map_sort_key *secondary_key)\n{\n\tint (*primary_fn)(const void *, const void *);\n\tint (*secondary_fn)(const void *, const void *);\n\tunsigned i, start = 0, n_sub = 1;\n\n\tif (is_key(map, primary_key->field_idx))\n\t\tprimary_fn = cmp_entries_key;\n\telse\n\t\tprimary_fn = cmp_entries_sum;\n\n\tif (is_key(map, secondary_key->field_idx))\n\t\tsecondary_fn = cmp_entries_key;\n\telse\n\t\tsecondary_fn = cmp_entries_sum;\n\n\tfor (i = 0; i < n_entries - 1; i++) {\n\t\tconst struct tracing_map_sort_entry **a = &entries[i];\n\t\tconst struct tracing_map_sort_entry **b = &entries[i + 1];\n\n\t\tif (primary_fn(a, b) == 0) {\n\t\t\tn_sub++;\n\t\t\tif (i < n_entries - 2)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (n_sub < 2) {\n\t\t\tstart = i + 1;\n\t\t\tn_sub = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tset_sort_key(map, secondary_key);\n\t\tsort(&entries[start], n_sub,\n\t\t     sizeof(struct tracing_map_sort_entry *),\n\t\t     (int (*)(const void *, const void *))secondary_fn, NULL);\n\t\tset_sort_key(map, primary_key);\n\n\t\tstart = i + 1;\n\t\tn_sub = 1;\n\t}\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include \"tracing_map.h\"",
            "#include <linux/kmemleak.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/jhash.h>",
            "#include <linux/vmalloc.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include \"tracing_map.h\"\n#include <linux/kmemleak.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/jhash.h>\n#include <linux/vmalloc.h>\n\nstatic void sort_secondary(struct tracing_map *map,\n\t\t\t   const struct tracing_map_sort_entry **entries,\n\t\t\t   unsigned int n_entries,\n\t\t\t   struct tracing_map_sort_key *primary_key,\n\t\t\t   struct tracing_map_sort_key *secondary_key)\n{\n\tint (*primary_fn)(const void *, const void *);\n\tint (*secondary_fn)(const void *, const void *);\n\tunsigned i, start = 0, n_sub = 1;\n\n\tif (is_key(map, primary_key->field_idx))\n\t\tprimary_fn = cmp_entries_key;\n\telse\n\t\tprimary_fn = cmp_entries_sum;\n\n\tif (is_key(map, secondary_key->field_idx))\n\t\tsecondary_fn = cmp_entries_key;\n\telse\n\t\tsecondary_fn = cmp_entries_sum;\n\n\tfor (i = 0; i < n_entries - 1; i++) {\n\t\tconst struct tracing_map_sort_entry **a = &entries[i];\n\t\tconst struct tracing_map_sort_entry **b = &entries[i + 1];\n\n\t\tif (primary_fn(a, b) == 0) {\n\t\t\tn_sub++;\n\t\t\tif (i < n_entries - 2)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (n_sub < 2) {\n\t\t\tstart = i + 1;\n\t\t\tn_sub = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tset_sort_key(map, secondary_key);\n\t\tsort(&entries[start], n_sub,\n\t\t     sizeof(struct tracing_map_sort_entry *),\n\t\t     (int (*)(const void *, const void *))secondary_fn, NULL);\n\t\tset_sort_key(map, primary_key);\n\n\t\tstart = i + 1;\n\t\tn_sub = 1;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_end",
          "args": [
            "&it"
          ],
          "line": 361
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4761-4775",
          "snippet": "void css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_pid_vnr",
          "args": [
            "tsk"
          ],
          "line": 357
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_tgid_vnr",
          "args": [
            "tsk"
          ],
          "line": 355
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "n == length"
          ],
          "line": 351
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "css_task_iter_next",
          "args": [
            "&it"
          ],
          "line": 350
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_next",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4730-4753",
          "snippet": "struct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_start",
          "args": [
            "&cgrp->self",
            "0",
            "&it"
          ],
          "line": 349
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4700-4720",
          "snippet": "void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\n\nvoid css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvmalloc_array",
          "args": [
            "length",
            "sizeof(pid_t)",
            "GFP_KERNEL"
          ],
          "line": 345
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_task_count",
          "args": [
            "cgrp"
          ],
          "line": 344
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_task_count",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "641-650",
          "snippet": "int cgroup_task_count(const struct cgroup *cgrp)\n{\n\tint count;\n\n\tspin_lock_irq(&css_set_lock);\n\tcount = __cgroup_task_count(cgrp);\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn count;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nint cgroup_task_count(const struct cgroup *cgrp)\n{\n\tint count;\n\n\tspin_lock_irq(&css_set_lock);\n\tcount = __cgroup_task_count(cgrp);\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn count;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&cgrp->pidlist_mutex"
          ],
          "line": 336
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int pidlist_array_load(struct cgroup *cgrp, enum cgroup_filetype type,\n\t\t\t      struct cgroup_pidlist **lp)\n{\n\tpid_t *array;\n\tint length;\n\tint pid, n = 0; /* used for populating the array */\n\tstruct css_task_iter it;\n\tstruct task_struct *tsk;\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\t/*\n\t * If cgroup gets more users after we read count, we won't have\n\t * enough space - tough.  This race is indistinguishable to the\n\t * caller from the case that the additional cgroup users didn't\n\t * show up until sometime later on.\n\t */\n\tlength = cgroup_task_count(cgrp);\n\tarray = kvmalloc_array(length, sizeof(pid_t), GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\t/* now, populate the array */\n\tcss_task_iter_start(&cgrp->self, 0, &it);\n\twhile ((tsk = css_task_iter_next(&it))) {\n\t\tif (unlikely(n == length))\n\t\t\tbreak;\n\t\t/* get tgid or pid for procs or tasks file respectively */\n\t\tif (type == CGROUP_FILE_PROCS)\n\t\t\tpid = task_tgid_vnr(tsk);\n\t\telse\n\t\t\tpid = task_pid_vnr(tsk);\n\t\tif (pid > 0) /* make sure to only use valid results */\n\t\t\tarray[n++] = pid;\n\t}\n\tcss_task_iter_end(&it);\n\tlength = n;\n\t/* now sort & (if procs) strip out duplicates */\n\tsort(array, length, sizeof(pid_t), cmppid, NULL);\n\tif (type == CGROUP_FILE_PROCS)\n\t\tlength = pidlist_uniq(array, length);\n\n\tl = cgroup_pidlist_find_create(cgrp, type);\n\tif (!l) {\n\t\tkvfree(array);\n\t\treturn -ENOMEM;\n\t}\n\n\t/* store array, freeing old if necessary */\n\tkvfree(l->list);\n\tl->list = array;\n\tl->length = length;\n\t*lp = l;\n\treturn 0;\n}"
  },
  {
    "function_name": "cgroup_pidlist_find_create",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "298-321",
    "snippet": "static struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&l->links",
            "&cgrp->pidlists"
          ],
          "line": 319
        },
        "resolved": true,
        "details": {
          "function_name": "cmp_filterlist_addrs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/debugfs.c",
          "lines": "95-101",
          "snippet": "static int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}",
          "includes": [
            "#include \"kcsan.h\"",
            "#include <linux/uaccess.h>",
            "#include <linux/string.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/bug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kcsan.h\"\n#include <linux/uaccess.h>\n#include <linux/string.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/sched.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/debugfs.h>\n#include <linux/bug.h>\n#include <linux/bsearch.h>\n#include <linux/atomic.h>\n\nstatic int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_pid_ns",
          "args": [
            "task_active_pid_ns(current)"
          ],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_active_pid_ns",
          "args": [
            "current"
          ],
          "line": 317
        },
        "resolved": true,
        "details": {
          "function_name": "task_active_pid_ns",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/pid.c",
          "lines": "507-510",
          "snippet": "struct pid_namespace *task_active_pid_ns(struct task_struct *tsk)\n{\n\treturn ns_of_pid(task_pid(tsk));\n}",
          "includes": [
            "#include <uapi/linux/pidfd.h>",
            "#include <net/sock.h>",
            "#include <linux/idr.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/refcount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/init_task.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/memblock.h>",
            "#include <linux/rculist.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <uapi/linux/pidfd.h>\n#include <net/sock.h>\n#include <linux/idr.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/anon_inodes.h>\n#include <linux/refcount.h>\n#include <linux/proc_ns.h>\n#include <linux/syscalls.h>\n#include <linux/init_task.h>\n#include <linux/pid_namespace.h>\n#include <linux/memblock.h>\n#include <linux/rculist.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n\nstruct pid_namespace *task_active_pid_ns(struct task_struct *tsk)\n{\n\treturn ns_of_pid(task_pid(tsk));\n}"
        }
      },
      {
        "call_info": {
          "callee": "INIT_DELAYED_WORK",
          "args": [
            "&l->destroy_dwork",
            "cgroup_pidlist_destroy_work_fn"
          ],
          "line": 314
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(struct cgroup_pidlist)",
            "GFP_KERNEL"
          ],
          "line": 310
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_pidlist_find",
          "args": [
            "cgrp",
            "type"
          ],
          "line": 305
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_pidlist_find_create",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
          "lines": "298-321",
          "snippet": "static struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&cgrp->pidlist_mutex"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic struct cgroup_pidlist *cgroup_pidlist_find_create(struct cgroup *cgrp,\n\t\t\t\t\t\tenum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tl = cgroup_pidlist_find(cgrp, type);\n\tif (l)\n\t\treturn l;\n\n\t/* entry not found; create a new one */\n\tl = kzalloc(sizeof(struct cgroup_pidlist), GFP_KERNEL);\n\tif (!l)\n\t\treturn l;\n\n\tINIT_DELAYED_WORK(&l->destroy_dwork, cgroup_pidlist_destroy_work_fn);\n\tl->key.type = type;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tl->key.ns = get_pid_ns(task_active_pid_ns(current));\n\tl->owner = cgrp;\n\tlist_add(&l->links, &cgrp->pidlists);\n\treturn l;\n}"
  },
  {
    "function_name": "cgroup_pidlist_find",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "277-290",
    "snippet": "static struct cgroup_pidlist *cgroup_pidlist_find(struct cgroup *cgrp,\n\t\t\t\t\t\t  enum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tstruct pid_namespace *ns = task_active_pid_ns(current);\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tlist_for_each_entry(l, &cgrp->pidlists, links)\n\t\tif (l->key.type == type && l->key.ns == ns)\n\t\t\treturn l;\n\treturn NULL;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "l",
            "&cgrp->pidlists",
            "links"
          ],
          "line": 286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&cgrp->pidlist_mutex"
          ],
          "line": 284
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_active_pid_ns",
          "args": [
            "current"
          ],
          "line": 282
        },
        "resolved": true,
        "details": {
          "function_name": "task_active_pid_ns",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/pid.c",
          "lines": "507-510",
          "snippet": "struct pid_namespace *task_active_pid_ns(struct task_struct *tsk)\n{\n\treturn ns_of_pid(task_pid(tsk));\n}",
          "includes": [
            "#include <uapi/linux/pidfd.h>",
            "#include <net/sock.h>",
            "#include <linux/idr.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/refcount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/init_task.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/memblock.h>",
            "#include <linux/rculist.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <uapi/linux/pidfd.h>\n#include <net/sock.h>\n#include <linux/idr.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/anon_inodes.h>\n#include <linux/refcount.h>\n#include <linux/proc_ns.h>\n#include <linux/syscalls.h>\n#include <linux/init_task.h>\n#include <linux/pid_namespace.h>\n#include <linux/memblock.h>\n#include <linux/rculist.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n\nstruct pid_namespace *task_active_pid_ns(struct task_struct *tsk)\n{\n\treturn ns_of_pid(task_pid(tsk));\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic struct cgroup_pidlist *cgroup_pidlist_find(struct cgroup *cgrp,\n\t\t\t\t\t\t  enum cgroup_filetype type)\n{\n\tstruct cgroup_pidlist *l;\n\t/* don't need task_nsproxy() if we're looking at ourself */\n\tstruct pid_namespace *ns = task_active_pid_ns(current);\n\n\tlockdep_assert_held(&cgrp->pidlist_mutex);\n\n\tlist_for_each_entry(l, &cgrp->pidlists, links)\n\t\tif (l->key.type == type && l->key.ns == ns)\n\t\t\treturn l;\n\treturn NULL;\n}"
  },
  {
    "function_name": "cmppid",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "272-275",
    "snippet": "static int cmppid(const void *a, const void *b)\n{\n\treturn *(pid_t *)a - *(pid_t *)b;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int cmppid(const void *a, const void *b)\n{\n\treturn *(pid_t *)a - *(pid_t *)b;\n}"
  },
  {
    "function_name": "pidlist_uniq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "237-261",
    "snippet": "static int pidlist_uniq(pid_t *list, int length)\n{\n\tint src, dest = 1;\n\n\t/*\n\t * we presume the 0th element is unique, so i starts at 1. trivial\n\t * edge cases first; no work needs to be done for either\n\t */\n\tif (length == 0 || length == 1)\n\t\treturn length;\n\t/* src and dest walk down the list; dest counts unique elements */\n\tfor (src = 1; src < length; src++) {\n\t\t/* find next unique element */\n\t\twhile (list[src] == list[src-1]) {\n\t\t\tsrc++;\n\t\t\tif (src == length)\n\t\t\t\tgoto after;\n\t\t}\n\t\t/* dest always points to where the next unique element goes */\n\t\tlist[dest] = list[src];\n\t\tdest++;\n\t}\nafter:\n\treturn dest;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic int pidlist_uniq(pid_t *list, int length)\n{\n\tint src, dest = 1;\n\n\t/*\n\t * we presume the 0th element is unique, so i starts at 1. trivial\n\t * edge cases first; no work needs to be done for either\n\t */\n\tif (length == 0 || length == 1)\n\t\treturn length;\n\t/* src and dest walk down the list; dest counts unique elements */\n\tfor (src = 1; src < length; src++) {\n\t\t/* find next unique element */\n\t\twhile (list[src] == list[src-1]) {\n\t\t\tsrc++;\n\t\t\tif (src == length)\n\t\t\t\tgoto after;\n\t\t}\n\t\t/* dest always points to where the next unique element goes */\n\t\tlist[dest] = list[src];\n\t\tdest++;\n\t}\nafter:\n\treturn dest;\n}"
  },
  {
    "function_name": "cgroup_pidlist_destroy_work_fn",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "209-231",
    "snippet": "static void cgroup_pidlist_destroy_work_fn(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct cgroup_pidlist *l = container_of(dwork, struct cgroup_pidlist,\n\t\t\t\t\t\tdestroy_dwork);\n\tstruct cgroup_pidlist *tofree = NULL;\n\n\tmutex_lock(&l->owner->pidlist_mutex);\n\n\t/*\n\t * Destroy iff we didn't get queued again.  The state won't change\n\t * as destroy_dwork can only be queued while locked.\n\t */\n\tif (!delayed_work_pending(dwork)) {\n\t\tlist_del(&l->links);\n\t\tkvfree(l->list);\n\t\tput_pid_ns(l->key.ns);\n\t\ttofree = l;\n\t}\n\n\tmutex_unlock(&l->owner->pidlist_mutex);\n\tkfree(tofree);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "tofree"
          ],
          "line": 230
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&l->owner->pidlist_mutex"
          ],
          "line": 229
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_pid_ns",
          "args": [
            "l->key.ns"
          ],
          "line": 225
        },
        "resolved": true,
        "details": {
          "function_name": "put_pid_ns",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/pid_namespace.c",
          "lines": "152-163",
          "snippet": "void put_pid_ns(struct pid_namespace *ns)\n{\n\tstruct pid_namespace *parent;\n\n\twhile (ns != &init_pid_ns) {\n\t\tparent = ns->parent;\n\t\tif (!refcount_dec_and_test(&ns->ns.count))\n\t\t\tbreak;\n\t\tdestroy_pid_namespace(ns);\n\t\tns = parent;\n\t}\n}",
          "includes": [
            "#include <linux/idr.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/export.h>",
            "#include <linux/reboot.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/slab.h>",
            "#include <linux/acct.h>",
            "#include <linux/err.h>",
            "#include <linux/cred.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/pid.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/idr.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n#include <linux/export.h>\n#include <linux/reboot.h>\n#include <linux/proc_ns.h>\n#include <linux/slab.h>\n#include <linux/acct.h>\n#include <linux/err.h>\n#include <linux/cred.h>\n#include <linux/syscalls.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/pid.h>\n\nvoid put_pid_ns(struct pid_namespace *ns)\n{\n\tstruct pid_namespace *parent;\n\n\twhile (ns != &init_pid_ns) {\n\t\tparent = ns->parent;\n\t\tif (!refcount_dec_and_test(&ns->ns.count))\n\t\t\tbreak;\n\t\tdestroy_pid_namespace(ns);\n\t\tns = parent;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "kvfree",
          "args": [
            "l->list"
          ],
          "line": 224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&l->links"
          ],
          "line": 223
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/fair.c",
          "lines": "475-477",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);",
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "delayed_work_pending",
          "args": [
            "dwork"
          ],
          "line": 222
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&l->owner->pidlist_mutex"
          ],
          "line": 216
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "dwork",
            "structcgroup_pidlist",
            "destroy_dwork"
          ],
          "line": 212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_delayed_work",
          "args": [
            "work"
          ],
          "line": 211
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic void cgroup_pidlist_destroy_work_fn(struct work_struct *work)\n{\n\tstruct delayed_work *dwork = to_delayed_work(work);\n\tstruct cgroup_pidlist *l = container_of(dwork, struct cgroup_pidlist,\n\t\t\t\t\t\tdestroy_dwork);\n\tstruct cgroup_pidlist *tofree = NULL;\n\n\tmutex_lock(&l->owner->pidlist_mutex);\n\n\t/*\n\t * Destroy iff we didn't get queued again.  The state won't change\n\t * as destroy_dwork can only be queued while locked.\n\t */\n\tif (!delayed_work_pending(dwork)) {\n\t\tlist_del(&l->links);\n\t\tkvfree(l->list);\n\t\tput_pid_ns(l->key.ns);\n\t\ttofree = l;\n\t}\n\n\tmutex_unlock(&l->owner->pidlist_mutex);\n\tkfree(tofree);\n}"
  },
  {
    "function_name": "cgroup1_pidlist_destroy_all",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "196-207",
    "snippet": "void cgroup1_pidlist_destroy_all(struct cgroup *cgrp)\n{\n\tstruct cgroup_pidlist *l, *tmp_l;\n\n\tmutex_lock(&cgrp->pidlist_mutex);\n\tlist_for_each_entry_safe(l, tmp_l, &cgrp->pidlists, links)\n\t\tmod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork, 0);\n\tmutex_unlock(&cgrp->pidlist_mutex);\n\n\tflush_workqueue(cgroup_pidlist_destroy_wq);\n\tBUG_ON(!list_empty(&cgrp->pidlists));\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct workqueue_struct *cgroup_pidlist_destroy_wq;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!list_empty(&cgrp->pidlists)"
          ],
          "line": 206
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&cgrp->pidlists"
          ],
          "line": 206
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "flush_workqueue",
          "args": [
            "cgroup_pidlist_destroy_wq"
          ],
          "line": 205
        },
        "resolved": true,
        "details": {
          "function_name": "flush_workqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "2815-2963",
          "snippet": "void flush_workqueue(struct workqueue_struct *wq)\n{\n\tstruct wq_flusher this_flusher = {\n\t\t.list = LIST_HEAD_INIT(this_flusher.list),\n\t\t.flush_color = -1,\n\t\t.done = COMPLETION_INITIALIZER_ONSTACK_MAP(this_flusher.done, wq->lockdep_map),\n\t};\n\tint next_color;\n\n\tif (WARN_ON(!wq_online))\n\t\treturn;\n\n\tlock_map_acquire(&wq->lockdep_map);\n\tlock_map_release(&wq->lockdep_map);\n\n\tmutex_lock(&wq->mutex);\n\n\t/*\n\t * Start-to-wait phase\n\t */\n\tnext_color = work_next_color(wq->work_color);\n\n\tif (next_color != wq->flush_color) {\n\t\t/*\n\t\t * Color space is not full.  The current work_color\n\t\t * becomes our flush_color and work_color is advanced\n\t\t * by one.\n\t\t */\n\t\tWARN_ON_ONCE(!list_empty(&wq->flusher_overflow));\n\t\tthis_flusher.flush_color = wq->work_color;\n\t\twq->work_color = next_color;\n\n\t\tif (!wq->first_flusher) {\n\t\t\t/* no flush in progress, become the first flusher */\n\t\t\tWARN_ON_ONCE(wq->flush_color != this_flusher.flush_color);\n\n\t\t\twq->first_flusher = &this_flusher;\n\n\t\t\tif (!flush_workqueue_prep_pwqs(wq, wq->flush_color,\n\t\t\t\t\t\t       wq->work_color)) {\n\t\t\t\t/* nothing to flush, done */\n\t\t\t\twq->flush_color = next_color;\n\t\t\t\twq->first_flusher = NULL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t} else {\n\t\t\t/* wait in queue */\n\t\t\tWARN_ON_ONCE(wq->flush_color == this_flusher.flush_color);\n\t\t\tlist_add_tail(&this_flusher.list, &wq->flusher_queue);\n\t\t\tflush_workqueue_prep_pwqs(wq, -1, wq->work_color);\n\t\t}\n\t} else {\n\t\t/*\n\t\t * Oops, color space is full, wait on overflow queue.\n\t\t * The next flush completion will assign us\n\t\t * flush_color and transfer to flusher_queue.\n\t\t */\n\t\tlist_add_tail(&this_flusher.list, &wq->flusher_overflow);\n\t}\n\n\tcheck_flush_dependency(wq, NULL);\n\n\tmutex_unlock(&wq->mutex);\n\n\twait_for_completion(&this_flusher.done);\n\n\t/*\n\t * Wake-up-and-cascade phase\n\t *\n\t * First flushers are responsible for cascading flushes and\n\t * handling overflow.  Non-first flushers can simply return.\n\t */\n\tif (READ_ONCE(wq->first_flusher) != &this_flusher)\n\t\treturn;\n\n\tmutex_lock(&wq->mutex);\n\n\t/* we might have raced, check again with mutex held */\n\tif (wq->first_flusher != &this_flusher)\n\t\tgoto out_unlock;\n\n\tWRITE_ONCE(wq->first_flusher, NULL);\n\n\tWARN_ON_ONCE(!list_empty(&this_flusher.list));\n\tWARN_ON_ONCE(wq->flush_color != this_flusher.flush_color);\n\n\twhile (true) {\n\t\tstruct wq_flusher *next, *tmp;\n\n\t\t/* complete all the flushers sharing the current flush color */\n\t\tlist_for_each_entry_safe(next, tmp, &wq->flusher_queue, list) {\n\t\t\tif (next->flush_color != wq->flush_color)\n\t\t\t\tbreak;\n\t\t\tlist_del_init(&next->list);\n\t\t\tcomplete(&next->done);\n\t\t}\n\n\t\tWARN_ON_ONCE(!list_empty(&wq->flusher_overflow) &&\n\t\t\t     wq->flush_color != work_next_color(wq->work_color));\n\n\t\t/* this flush_color is finished, advance by one */\n\t\twq->flush_color = work_next_color(wq->flush_color);\n\n\t\t/* one color has been freed, handle overflow queue */\n\t\tif (!list_empty(&wq->flusher_overflow)) {\n\t\t\t/*\n\t\t\t * Assign the same color to all overflowed\n\t\t\t * flushers, advance work_color and append to\n\t\t\t * flusher_queue.  This is the start-to-wait\n\t\t\t * phase for these overflowed flushers.\n\t\t\t */\n\t\t\tlist_for_each_entry(tmp, &wq->flusher_overflow, list)\n\t\t\t\ttmp->flush_color = wq->work_color;\n\n\t\t\twq->work_color = work_next_color(wq->work_color);\n\n\t\t\tlist_splice_tail_init(&wq->flusher_overflow,\n\t\t\t\t\t      &wq->flusher_queue);\n\t\t\tflush_workqueue_prep_pwqs(wq, -1, wq->work_color);\n\t\t}\n\n\t\tif (list_empty(&wq->flusher_queue)) {\n\t\t\tWARN_ON_ONCE(wq->flush_color != wq->work_color);\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Need to flush more colors.  Make the next flusher\n\t\t * the new first flusher and arm pwqs.\n\t\t */\n\t\tWARN_ON_ONCE(wq->flush_color == wq->work_color);\n\t\tWARN_ON_ONCE(wq->flush_color != next->flush_color);\n\n\t\tlist_del_init(&next->list);\n\t\twq->first_flusher = next;\n\n\t\tif (flush_workqueue_prep_pwqs(wq, wq->flush_color, -1))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Meh... this color is already done, clear first\n\t\t * flusher and repeat cascading.\n\t\t */\n\t\twq->first_flusher = NULL;\n\t}\n\nout_unlock:\n\tmutex_unlock(&wq->mutex);\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static bool wq_online;",
            "static void workqueue_sysfs_unregister(struct workqueue_struct *wq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic bool wq_online;\nstatic void workqueue_sysfs_unregister(struct workqueue_struct *wq);\n\nvoid flush_workqueue(struct workqueue_struct *wq)\n{\n\tstruct wq_flusher this_flusher = {\n\t\t.list = LIST_HEAD_INIT(this_flusher.list),\n\t\t.flush_color = -1,\n\t\t.done = COMPLETION_INITIALIZER_ONSTACK_MAP(this_flusher.done, wq->lockdep_map),\n\t};\n\tint next_color;\n\n\tif (WARN_ON(!wq_online))\n\t\treturn;\n\n\tlock_map_acquire(&wq->lockdep_map);\n\tlock_map_release(&wq->lockdep_map);\n\n\tmutex_lock(&wq->mutex);\n\n\t/*\n\t * Start-to-wait phase\n\t */\n\tnext_color = work_next_color(wq->work_color);\n\n\tif (next_color != wq->flush_color) {\n\t\t/*\n\t\t * Color space is not full.  The current work_color\n\t\t * becomes our flush_color and work_color is advanced\n\t\t * by one.\n\t\t */\n\t\tWARN_ON_ONCE(!list_empty(&wq->flusher_overflow));\n\t\tthis_flusher.flush_color = wq->work_color;\n\t\twq->work_color = next_color;\n\n\t\tif (!wq->first_flusher) {\n\t\t\t/* no flush in progress, become the first flusher */\n\t\t\tWARN_ON_ONCE(wq->flush_color != this_flusher.flush_color);\n\n\t\t\twq->first_flusher = &this_flusher;\n\n\t\t\tif (!flush_workqueue_prep_pwqs(wq, wq->flush_color,\n\t\t\t\t\t\t       wq->work_color)) {\n\t\t\t\t/* nothing to flush, done */\n\t\t\t\twq->flush_color = next_color;\n\t\t\t\twq->first_flusher = NULL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t} else {\n\t\t\t/* wait in queue */\n\t\t\tWARN_ON_ONCE(wq->flush_color == this_flusher.flush_color);\n\t\t\tlist_add_tail(&this_flusher.list, &wq->flusher_queue);\n\t\t\tflush_workqueue_prep_pwqs(wq, -1, wq->work_color);\n\t\t}\n\t} else {\n\t\t/*\n\t\t * Oops, color space is full, wait on overflow queue.\n\t\t * The next flush completion will assign us\n\t\t * flush_color and transfer to flusher_queue.\n\t\t */\n\t\tlist_add_tail(&this_flusher.list, &wq->flusher_overflow);\n\t}\n\n\tcheck_flush_dependency(wq, NULL);\n\n\tmutex_unlock(&wq->mutex);\n\n\twait_for_completion(&this_flusher.done);\n\n\t/*\n\t * Wake-up-and-cascade phase\n\t *\n\t * First flushers are responsible for cascading flushes and\n\t * handling overflow.  Non-first flushers can simply return.\n\t */\n\tif (READ_ONCE(wq->first_flusher) != &this_flusher)\n\t\treturn;\n\n\tmutex_lock(&wq->mutex);\n\n\t/* we might have raced, check again with mutex held */\n\tif (wq->first_flusher != &this_flusher)\n\t\tgoto out_unlock;\n\n\tWRITE_ONCE(wq->first_flusher, NULL);\n\n\tWARN_ON_ONCE(!list_empty(&this_flusher.list));\n\tWARN_ON_ONCE(wq->flush_color != this_flusher.flush_color);\n\n\twhile (true) {\n\t\tstruct wq_flusher *next, *tmp;\n\n\t\t/* complete all the flushers sharing the current flush color */\n\t\tlist_for_each_entry_safe(next, tmp, &wq->flusher_queue, list) {\n\t\t\tif (next->flush_color != wq->flush_color)\n\t\t\t\tbreak;\n\t\t\tlist_del_init(&next->list);\n\t\t\tcomplete(&next->done);\n\t\t}\n\n\t\tWARN_ON_ONCE(!list_empty(&wq->flusher_overflow) &&\n\t\t\t     wq->flush_color != work_next_color(wq->work_color));\n\n\t\t/* this flush_color is finished, advance by one */\n\t\twq->flush_color = work_next_color(wq->flush_color);\n\n\t\t/* one color has been freed, handle overflow queue */\n\t\tif (!list_empty(&wq->flusher_overflow)) {\n\t\t\t/*\n\t\t\t * Assign the same color to all overflowed\n\t\t\t * flushers, advance work_color and append to\n\t\t\t * flusher_queue.  This is the start-to-wait\n\t\t\t * phase for these overflowed flushers.\n\t\t\t */\n\t\t\tlist_for_each_entry(tmp, &wq->flusher_overflow, list)\n\t\t\t\ttmp->flush_color = wq->work_color;\n\n\t\t\twq->work_color = work_next_color(wq->work_color);\n\n\t\t\tlist_splice_tail_init(&wq->flusher_overflow,\n\t\t\t\t\t      &wq->flusher_queue);\n\t\t\tflush_workqueue_prep_pwqs(wq, -1, wq->work_color);\n\t\t}\n\n\t\tif (list_empty(&wq->flusher_queue)) {\n\t\t\tWARN_ON_ONCE(wq->flush_color != wq->work_color);\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Need to flush more colors.  Make the next flusher\n\t\t * the new first flusher and arm pwqs.\n\t\t */\n\t\tWARN_ON_ONCE(wq->flush_color == wq->work_color);\n\t\tWARN_ON_ONCE(wq->flush_color != next->flush_color);\n\n\t\tlist_del_init(&next->list);\n\t\twq->first_flusher = next;\n\n\t\tif (flush_workqueue_prep_pwqs(wq, wq->flush_color, -1))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Meh... this color is already done, clear first\n\t\t * flusher and repeat cascading.\n\t\t */\n\t\twq->first_flusher = NULL;\n\t}\n\nout_unlock:\n\tmutex_unlock(&wq->mutex);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&cgrp->pidlist_mutex"
          ],
          "line": 203
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mod_delayed_work",
          "args": [
            "cgroup_pidlist_destroy_wq",
            "&l->destroy_dwork",
            "0"
          ],
          "line": 202
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_mod_delayed_work",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "1239-1283",
          "snippet": "bool kthread_mod_delayed_work(struct kthread_worker *worker,\n\t\t\t      struct kthread_delayed_work *dwork,\n\t\t\t      unsigned long delay)\n{\n\tstruct kthread_work *work = &dwork->work;\n\tunsigned long flags;\n\tint ret;\n\n\traw_spin_lock_irqsave(&worker->lock, flags);\n\n\t/* Do not bother with canceling when never queued. */\n\tif (!work->worker) {\n\t\tret = false;\n\t\tgoto fast_queue;\n\t}\n\n\t/* Work must not be used with >1 worker, see kthread_queue_work() */\n\tWARN_ON_ONCE(work->worker != worker);\n\n\t/*\n\t * Temporary cancel the work but do not fight with another command\n\t * that is canceling the work as well.\n\t *\n\t * It is a bit tricky because of possible races with another\n\t * mod_delayed_work() and cancel_delayed_work() callers.\n\t *\n\t * The timer must be canceled first because worker->lock is released\n\t * when doing so. But the work can be removed from the queue (list)\n\t * only when it can be queued again so that the return value can\n\t * be used for reference counting.\n\t */\n\tkthread_cancel_delayed_work_timer(work, &flags);\n\tif (work->canceling) {\n\t\t/* The number of works in the queue does not change. */\n\t\tret = true;\n\t\tgoto out;\n\t}\n\tret = __kthread_cancel_work(work);\n\nfast_queue:\n\t__kthread_queue_delayed_work(worker, dwork, delay);\nout:\n\traw_spin_unlock_irqrestore(&worker->lock, flags);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_mod_delayed_work(struct kthread_worker *worker,\n\t\t\t      struct kthread_delayed_work *dwork,\n\t\t\t      unsigned long delay)\n{\n\tstruct kthread_work *work = &dwork->work;\n\tunsigned long flags;\n\tint ret;\n\n\traw_spin_lock_irqsave(&worker->lock, flags);\n\n\t/* Do not bother with canceling when never queued. */\n\tif (!work->worker) {\n\t\tret = false;\n\t\tgoto fast_queue;\n\t}\n\n\t/* Work must not be used with >1 worker, see kthread_queue_work() */\n\tWARN_ON_ONCE(work->worker != worker);\n\n\t/*\n\t * Temporary cancel the work but do not fight with another command\n\t * that is canceling the work as well.\n\t *\n\t * It is a bit tricky because of possible races with another\n\t * mod_delayed_work() and cancel_delayed_work() callers.\n\t *\n\t * The timer must be canceled first because worker->lock is released\n\t * when doing so. But the work can be removed from the queue (list)\n\t * only when it can be queued again so that the return value can\n\t * be used for reference counting.\n\t */\n\tkthread_cancel_delayed_work_timer(work, &flags);\n\tif (work->canceling) {\n\t\t/* The number of works in the queue does not change. */\n\t\tret = true;\n\t\tgoto out;\n\t}\n\tret = __kthread_cancel_work(work);\n\nfast_queue:\n\t__kthread_queue_delayed_work(worker, dwork, delay);\nout:\n\traw_spin_unlock_irqrestore(&worker->lock, flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "l",
            "tmp_l",
            "&cgrp->pidlists",
            "links"
          ],
          "line": 201
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&cgrp->pidlist_mutex"
          ],
          "line": 200
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic struct workqueue_struct *cgroup_pidlist_destroy_wq;\n\nvoid cgroup1_pidlist_destroy_all(struct cgroup *cgrp)\n{\n\tstruct cgroup_pidlist *l, *tmp_l;\n\n\tmutex_lock(&cgrp->pidlist_mutex);\n\tlist_for_each_entry_safe(l, tmp_l, &cgrp->pidlists, links)\n\t\tmod_delayed_work(cgroup_pidlist_destroy_wq, &l->destroy_dwork, 0);\n\tmutex_unlock(&cgrp->pidlist_mutex);\n\n\tflush_workqueue(cgroup_pidlist_destroy_wq);\n\tBUG_ON(!list_empty(&cgrp->pidlists));\n}"
  },
  {
    "function_name": "cgroup_transfer_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "94-150",
    "snippet": "int cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct cgrp_cset_link *link;\n\tstruct css_task_iter it;\n\tstruct task_struct *task;\n\tint ret;\n\n\tif (cgroup_on_dfl(to))\n\t\treturn -EINVAL;\n\n\tret = cgroup_migrate_vet_dst(to);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&cgroup_mutex);\n\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\n\t/* all tasks in @from are being moved, all csets are source */\n\tspin_lock_irq(&css_set_lock);\n\tlist_for_each_entry(link, &from->cset_links, cset_link)\n\t\tcgroup_migrate_add_src(link->cset, to, &mgctx);\n\tspin_unlock_irq(&css_set_lock);\n\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (ret)\n\t\tgoto out_err;\n\n\t/*\n\t * Migrate tasks one-by-one until @from is empty.  This fails iff\n\t * ->can_attach() fails.\n\t */\n\tdo {\n\t\tcss_task_iter_start(&from->self, 0, &it);\n\n\t\tdo {\n\t\t\ttask = css_task_iter_next(&it);\n\t\t} while (task && (task->flags & PF_EXITING));\n\n\t\tif (task)\n\t\t\tget_task_struct(task);\n\t\tcss_task_iter_end(&it);\n\n\t\tif (task) {\n\t\t\tret = cgroup_migrate(task, false, &mgctx);\n\t\t\tif (!ret)\n\t\t\t\tTRACE_CGROUP_PATH(transfer_tasks, to, task, false);\n\t\t\tput_task_struct(task);\n\t\t}\n\t} while (task && !ret);\nout_err:\n\tcgroup_migrate_finish(&mgctx);\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 148
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "percpu_up_write",
          "args": [
            "&cgroup_threadgroup_rwsem"
          ],
          "line": 147
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_migrate_finish",
          "args": [
            "&mgctx"
          ],
          "line": 146
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_migrate_finish",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2598-2619",
          "snippet": "void cgroup_migrate_finish(struct cgroup_mgctx *mgctx)\n{\n\tLIST_HEAD(preloaded);\n\tstruct css_set *cset, *tmp_cset;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tspin_lock_irq(&css_set_lock);\n\n\tlist_splice_tail_init(&mgctx->preloaded_src_csets, &preloaded);\n\tlist_splice_tail_init(&mgctx->preloaded_dst_csets, &preloaded);\n\n\tlist_for_each_entry_safe(cset, tmp_cset, &preloaded, mg_preload_node) {\n\t\tcset->mg_src_cgrp = NULL;\n\t\tcset->mg_dst_cgrp = NULL;\n\t\tcset->mg_dst_cset = NULL;\n\t\tlist_del_init(&cset->mg_preload_node);\n\t\tput_css_set_locked(cset);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid cgroup_migrate_finish(struct cgroup_mgctx *mgctx)\n{\n\tLIST_HEAD(preloaded);\n\tstruct css_set *cset, *tmp_cset;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tspin_lock_irq(&css_set_lock);\n\n\tlist_splice_tail_init(&mgctx->preloaded_src_csets, &preloaded);\n\tlist_splice_tail_init(&mgctx->preloaded_dst_csets, &preloaded);\n\n\tlist_for_each_entry_safe(cset, tmp_cset, &preloaded, mg_preload_node) {\n\t\tcset->mg_src_cgrp = NULL;\n\t\tcset->mg_dst_cgrp = NULL;\n\t\tcset->mg_dst_cset = NULL;\n\t\tlist_del_init(&cset->mg_preload_node);\n\t\tput_css_set_locked(cset);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_task_struct",
          "args": [
            "task"
          ],
          "line": 142
        },
        "resolved": true,
        "details": {
          "function_name": "__put_task_struct",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/fork.c",
          "lines": "745-761",
          "snippet": "void __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <linux/bpf.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/scs.h>",
            "#include <linux/kasan.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/anon_inodes.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <linux/bpf.h>\n#include <linux/io_uring.h>\n#include <linux/scs.h>\n#include <linux/kasan.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm_inline.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/seq_file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n\nstatic __latent_entropy struct;\n\nvoid __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "TRACE_CGROUP_PATH",
          "args": [
            "transfer_tasks",
            "to",
            "task",
            "false"
          ],
          "line": 141
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cgroup_migrate",
          "args": [
            "task",
            "false",
            "&mgctx"
          ],
          "line": 139
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_migrate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2751-2773",
          "snippet": "int cgroup_migrate(struct task_struct *leader, bool threadgroup,\n\t\t   struct cgroup_mgctx *mgctx)\n{\n\tstruct task_struct *task;\n\n\t/*\n\t * Prevent freeing of tasks while we take a snapshot. Tasks that are\n\t * already PF_EXITING could be freed from underneath us unless we\n\t * take an rcu_read_lock.\n\t */\n\tspin_lock_irq(&css_set_lock);\n\trcu_read_lock();\n\ttask = leader;\n\tdo {\n\t\tcgroup_migrate_add_task(task, mgctx);\n\t\tif (!threadgroup)\n\t\t\tbreak;\n\t} while_each_thread(leader, task);\n\trcu_read_unlock();\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn cgroup_migrate_execute(mgctx);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);\n\nint cgroup_migrate(struct task_struct *leader, bool threadgroup,\n\t\t   struct cgroup_mgctx *mgctx)\n{\n\tstruct task_struct *task;\n\n\t/*\n\t * Prevent freeing of tasks while we take a snapshot. Tasks that are\n\t * already PF_EXITING could be freed from underneath us unless we\n\t * take an rcu_read_lock.\n\t */\n\tspin_lock_irq(&css_set_lock);\n\trcu_read_lock();\n\ttask = leader;\n\tdo {\n\t\tcgroup_migrate_add_task(task, mgctx);\n\t\tif (!threadgroup)\n\t\t\tbreak;\n\t} while_each_thread(leader, task);\n\trcu_read_unlock();\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn cgroup_migrate_execute(mgctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_end",
          "args": [
            "&it"
          ],
          "line": 136
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4761-4775",
          "snippet": "void css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_task_struct",
          "args": [
            "task"
          ],
          "line": 135
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "css_task_iter_next",
          "args": [
            "&it"
          ],
          "line": 131
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_next",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4730-4753",
          "snippet": "struct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_start",
          "args": [
            "&from->self",
            "0",
            "&it"
          ],
          "line": 128
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4700-4720",
          "snippet": "void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\n\nvoid css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_migrate_prepare_dst",
          "args": [
            "&mgctx"
          ],
          "line": 119
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_migrate_prepare_dst",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2684-2731",
          "snippet": "int cgroup_migrate_prepare_dst(struct cgroup_mgctx *mgctx)\n{\n\tstruct css_set *src_cset, *tmp_cset;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* look up the dst cset for each src cset and link it to src */\n\tlist_for_each_entry_safe(src_cset, tmp_cset, &mgctx->preloaded_src_csets,\n\t\t\t\t mg_preload_node) {\n\t\tstruct css_set *dst_cset;\n\t\tstruct cgroup_subsys *ss;\n\t\tint ssid;\n\n\t\tdst_cset = find_css_set(src_cset, src_cset->mg_dst_cgrp);\n\t\tif (!dst_cset)\n\t\t\treturn -ENOMEM;\n\n\t\tWARN_ON_ONCE(src_cset->mg_dst_cset || dst_cset->mg_dst_cset);\n\n\t\t/*\n\t\t * If src cset equals dst, it's noop.  Drop the src.\n\t\t * cgroup_migrate() will skip the cset too.  Note that we\n\t\t * can't handle src == dst as some nodes are used by both.\n\t\t */\n\t\tif (src_cset == dst_cset) {\n\t\t\tsrc_cset->mg_src_cgrp = NULL;\n\t\t\tsrc_cset->mg_dst_cgrp = NULL;\n\t\t\tlist_del_init(&src_cset->mg_preload_node);\n\t\t\tput_css_set(src_cset);\n\t\t\tput_css_set(dst_cset);\n\t\t\tcontinue;\n\t\t}\n\n\t\tsrc_cset->mg_dst_cset = dst_cset;\n\n\t\tif (list_empty(&dst_cset->mg_preload_node))\n\t\t\tlist_add_tail(&dst_cset->mg_preload_node,\n\t\t\t\t      &mgctx->preloaded_dst_csets);\n\t\telse\n\t\t\tput_css_set(dst_cset);\n\n\t\tfor_each_subsys(ss, ssid)\n\t\t\tif (src_cset->subsys[ssid] != dst_cset->subsys[ssid])\n\t\t\t\tmgctx->ss_mask |= 1 << ssid;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\n\nint cgroup_migrate_prepare_dst(struct cgroup_mgctx *mgctx)\n{\n\tstruct css_set *src_cset, *tmp_cset;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* look up the dst cset for each src cset and link it to src */\n\tlist_for_each_entry_safe(src_cset, tmp_cset, &mgctx->preloaded_src_csets,\n\t\t\t\t mg_preload_node) {\n\t\tstruct css_set *dst_cset;\n\t\tstruct cgroup_subsys *ss;\n\t\tint ssid;\n\n\t\tdst_cset = find_css_set(src_cset, src_cset->mg_dst_cgrp);\n\t\tif (!dst_cset)\n\t\t\treturn -ENOMEM;\n\n\t\tWARN_ON_ONCE(src_cset->mg_dst_cset || dst_cset->mg_dst_cset);\n\n\t\t/*\n\t\t * If src cset equals dst, it's noop.  Drop the src.\n\t\t * cgroup_migrate() will skip the cset too.  Note that we\n\t\t * can't handle src == dst as some nodes are used by both.\n\t\t */\n\t\tif (src_cset == dst_cset) {\n\t\t\tsrc_cset->mg_src_cgrp = NULL;\n\t\t\tsrc_cset->mg_dst_cgrp = NULL;\n\t\t\tlist_del_init(&src_cset->mg_preload_node);\n\t\t\tput_css_set(src_cset);\n\t\t\tput_css_set(dst_cset);\n\t\t\tcontinue;\n\t\t}\n\n\t\tsrc_cset->mg_dst_cset = dst_cset;\n\n\t\tif (list_empty(&dst_cset->mg_preload_node))\n\t\t\tlist_add_tail(&dst_cset->mg_preload_node,\n\t\t\t\t      &mgctx->preloaded_dst_csets);\n\t\telse\n\t\t\tput_css_set(dst_cset);\n\n\t\tfor_each_subsys(ss, ssid)\n\t\t\tif (src_cset->subsys[ssid] != dst_cset->subsys[ssid])\n\t\t\t\tmgctx->ss_mask |= 1 << ssid;\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock_irq",
          "args": [
            "&css_set_lock"
          ],
          "line": 117
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_migrate_add_src",
          "args": [
            "link->cset",
            "to",
            "&mgctx"
          ],
          "line": 116
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_migrate_add_src",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2637-2668",
          "snippet": "void cgroup_migrate_add_src(struct css_set *src_cset,\n\t\t\t    struct cgroup *dst_cgrp,\n\t\t\t    struct cgroup_mgctx *mgctx)\n{\n\tstruct cgroup *src_cgrp;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\tlockdep_assert_held(&css_set_lock);\n\n\t/*\n\t * If ->dead, @src_set is associated with one or more dead cgroups\n\t * and doesn't contain any migratable tasks.  Ignore it early so\n\t * that the rest of migration path doesn't get confused by it.\n\t */\n\tif (src_cset->dead)\n\t\treturn;\n\n\tif (!list_empty(&src_cset->mg_preload_node))\n\t\treturn;\n\n\tsrc_cgrp = cset_cgroup_from_root(src_cset, dst_cgrp->root);\n\n\tWARN_ON(src_cset->mg_src_cgrp);\n\tWARN_ON(src_cset->mg_dst_cgrp);\n\tWARN_ON(!list_empty(&src_cset->mg_tasks));\n\tWARN_ON(!list_empty(&src_cset->mg_node));\n\n\tsrc_cset->mg_src_cgrp = src_cgrp;\n\tsrc_cset->mg_dst_cgrp = dst_cgrp;\n\tget_css_set(src_cset);\n\tlist_add_tail(&src_cset->mg_preload_node, &mgctx->preloaded_src_csets);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid cgroup_migrate_add_src(struct css_set *src_cset,\n\t\t\t    struct cgroup *dst_cgrp,\n\t\t\t    struct cgroup_mgctx *mgctx)\n{\n\tstruct cgroup *src_cgrp;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\tlockdep_assert_held(&css_set_lock);\n\n\t/*\n\t * If ->dead, @src_set is associated with one or more dead cgroups\n\t * and doesn't contain any migratable tasks.  Ignore it early so\n\t * that the rest of migration path doesn't get confused by it.\n\t */\n\tif (src_cset->dead)\n\t\treturn;\n\n\tif (!list_empty(&src_cset->mg_preload_node))\n\t\treturn;\n\n\tsrc_cgrp = cset_cgroup_from_root(src_cset, dst_cgrp->root);\n\n\tWARN_ON(src_cset->mg_src_cgrp);\n\tWARN_ON(src_cset->mg_dst_cgrp);\n\tWARN_ON(!list_empty(&src_cset->mg_tasks));\n\tWARN_ON(!list_empty(&src_cset->mg_node));\n\n\tsrc_cset->mg_src_cgrp = src_cgrp;\n\tsrc_cset->mg_dst_cgrp = dst_cgrp;\n\tget_css_set(src_cset);\n\tlist_add_tail(&src_cset->mg_preload_node, &mgctx->preloaded_src_csets);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "link",
            "&from->cset_links",
            "cset_link"
          ],
          "line": 115
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock_irq",
          "args": [
            "&css_set_lock"
          ],
          "line": 114
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_lock_irqsave",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "293-300",
          "snippet": "static inline void __bpf_spin_lock_irqsave(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__bpf_spin_lock(lock);\n\t__this_cpu_write(irqsave_flags, flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_lock_irqsave(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__bpf_spin_lock(lock);\n\t__this_cpu_write(irqsave_flags, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "percpu_down_write",
          "args": [
            "&cgroup_threadgroup_rwsem"
          ],
          "line": 111
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 109
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_migrate_vet_dst",
          "args": [
            "to"
          ],
          "line": 105
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_migrate_vet_dst",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2563-2589",
          "snippet": "int cgroup_migrate_vet_dst(struct cgroup *dst_cgrp)\n{\n\t/* v1 doesn't have any restriction */\n\tif (!cgroup_on_dfl(dst_cgrp))\n\t\treturn 0;\n\n\t/* verify @dst_cgrp can host resources */\n\tif (!cgroup_is_valid_domain(dst_cgrp->dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/* mixables don't care */\n\tif (cgroup_is_mixable(dst_cgrp))\n\t\treturn 0;\n\n\t/*\n\t * If @dst_cgrp is already or can become a thread root or is\n\t * threaded, it doesn't matter.\n\t */\n\tif (cgroup_can_be_thread_root(dst_cgrp) || cgroup_is_threaded(dst_cgrp))\n\t\treturn 0;\n\n\t/* apply no-internal-process constraint */\n\tif (dst_cgrp->subtree_control)\n\t\treturn -EBUSY;\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nint cgroup_migrate_vet_dst(struct cgroup *dst_cgrp)\n{\n\t/* v1 doesn't have any restriction */\n\tif (!cgroup_on_dfl(dst_cgrp))\n\t\treturn 0;\n\n\t/* verify @dst_cgrp can host resources */\n\tif (!cgroup_is_valid_domain(dst_cgrp->dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/* mixables don't care */\n\tif (cgroup_is_mixable(dst_cgrp))\n\t\treturn 0;\n\n\t/*\n\t * If @dst_cgrp is already or can become a thread root or is\n\t * threaded, it doesn't matter.\n\t */\n\tif (cgroup_can_be_thread_root(dst_cgrp) || cgroup_is_threaded(dst_cgrp))\n\t\treturn 0;\n\n\t/* apply no-internal-process constraint */\n\tif (dst_cgrp->subtree_control)\n\t\treturn -EBUSY;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_on_dfl",
          "args": [
            "to"
          ],
          "line": 102
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_on_dfl",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "313-316",
          "snippet": "bool cgroup_on_dfl(const struct cgroup *cgrp)\n{\n\treturn cgrp->root == &cgrp_dfl_root;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct cgroup_root cgrp_dfl_root = { .cgrp.rstat_cpu = &cgrp_dfl_root_rstat_cpu };",
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct cgroup_root cgrp_dfl_root = { .cgrp.rstat_cpu = &cgrp_dfl_root_rstat_cpu };\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\n\nbool cgroup_on_dfl(const struct cgroup *cgrp)\n{\n\treturn cgrp->root == &cgrp_dfl_root;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEFINE_CGROUP_MGCTX",
          "args": [
            "mgctx"
          ],
          "line": 96
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nint cgroup_transfer_tasks(struct cgroup *to, struct cgroup *from)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct cgrp_cset_link *link;\n\tstruct css_task_iter it;\n\tstruct task_struct *task;\n\tint ret;\n\n\tif (cgroup_on_dfl(to))\n\t\treturn -EINVAL;\n\n\tret = cgroup_migrate_vet_dst(to);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&cgroup_mutex);\n\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\n\t/* all tasks in @from are being moved, all csets are source */\n\tspin_lock_irq(&css_set_lock);\n\tlist_for_each_entry(link, &from->cset_links, cset_link)\n\t\tcgroup_migrate_add_src(link->cset, to, &mgctx);\n\tspin_unlock_irq(&css_set_lock);\n\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (ret)\n\t\tgoto out_err;\n\n\t/*\n\t * Migrate tasks one-by-one until @from is empty.  This fails iff\n\t * ->can_attach() fails.\n\t */\n\tdo {\n\t\tcss_task_iter_start(&from->self, 0, &it);\n\n\t\tdo {\n\t\t\ttask = css_task_iter_next(&it);\n\t\t} while (task && (task->flags & PF_EXITING));\n\n\t\tif (task)\n\t\t\tget_task_struct(task);\n\t\tcss_task_iter_end(&it);\n\n\t\tif (task) {\n\t\t\tret = cgroup_migrate(task, false, &mgctx);\n\t\t\tif (!ret)\n\t\t\t\tTRACE_CGROUP_PATH(transfer_tasks, to, task, false);\n\t\t\tput_task_struct(task);\n\t\t}\n\t} while (task && !ret);\nout_err:\n\tcgroup_migrate_finish(&mgctx);\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}"
  },
  {
    "function_name": "cgroup_attach_task_all",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "56-78",
    "snippet": "int cgroup_attach_task_all(struct task_struct *from, struct task_struct *tsk)\n{\n\tstruct cgroup_root *root;\n\tint retval = 0;\n\n\tmutex_lock(&cgroup_mutex);\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\tfor_each_root(root) {\n\t\tstruct cgroup *from_cgrp;\n\n\t\tspin_lock_irq(&css_set_lock);\n\t\tfrom_cgrp = task_cgroup_from_root(from, root);\n\t\tspin_unlock_irq(&css_set_lock);\n\n\t\tretval = cgroup_attach_task(from_cgrp, tsk, false);\n\t\tif (retval)\n\t\t\tbreak;\n\t}\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tmutex_unlock(&cgroup_mutex);\n\n\treturn retval;\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 75
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "percpu_up_write",
          "args": [
            "&cgroup_threadgroup_rwsem"
          ],
          "line": 74
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_attach_task",
          "args": [
            "from_cgrp",
            "tsk",
            "false"
          ],
          "line": 70
        },
        "resolved": true,
        "details": {
          "function_name": "cgroup_attach_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "2783-4623",
          "snippet": "int cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,\n\t\t       bool threadgroup)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct task_struct *task;\n\tint ret = 0;\n\n\t/* look up all src csets */\n\tspin_lock_irq(&css_set_lock);\n\trcu_read_lock();\n\ttask = leader;\n\tdo {\n\t\tcgroup_migrate_add_src(task_css_set(task), dst_cgrp, &mgctx);\n\t\tif (!threadgroup)\n\t\t\tbreak;\n\t} while_each_thread(leader, task);\n\trcu_read_unlock();\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* prepare dst csets and commit */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (!ret)\n\t\tret = cgroup_migrate(leader, threadgroup, &mgctx);\n\n\tcgroup_migrate_finish(&mgctx);\n\n\tif (!ret)\n\t\tTRACE_CGROUP_PATH(attach_task, dst_cgrp, leader, threadgroup);\n\n\treturn ret;\n}\n\nstruct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup,\n\t\t\t\t\t     bool *locked)\n\t__acquires(&cgroup_threadgroup_rwsem)\n{\n\tstruct task_struct *tsk;\n\tpid_t pid;\n\n\tif (kstrtoint(strstrip(buf), 0, &pid) || pid < 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * If we migrate a single thread, we don't care about threadgroup\n\t * stability. If the thread is `current`, it won't exit(2) under our\n\t * hands or change PID through exec(2). We exclude\n\t * cgroup_update_dfl_csses and other cgroup_{proc,thread}s_write\n\t * callers by cgroup_mutex.\n\t * Therefore, we can skip the global lock.\n\t */\n\tlockdep_assert_held(&cgroup_mutex);\n\tif (pid || threadgroup) {\n\t\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = true;\n\t} else {\n\t\t*locked = false;\n\t}\n\n\trcu_read_lock();\n\tif (pid) {\n\t\ttsk = find_task_by_vpid(pid);\n\t\tif (!tsk) {\n\t\t\ttsk = ERR_PTR(-ESRCH);\n\t\t\tgoto out_unlock_threadgroup;\n\t\t}\n\t} else {\n\t\ttsk = current;\n\t}\n\n\tif (threadgroup)\n\t\ttsk = tsk->group_leader;\n\n\t/*\n\t * kthreads may acquire PF_NO_SETAFFINITY during initialization.\n\t * If userland migrates such a kthread to a non-root cgroup, it can\n\t * become trapped in a cpuset, or RT kthread may be born in a\n\t * cgroup with no rt_runtime allocated.  Just say no.\n\t */\n\tif (tsk->no_cgroup_migration || (tsk->flags & PF_NO_SETAFFINITY)) {\n\t\ttsk = ERR_PTR(-EINVAL);\n\t\tgoto out_unlock_threadgroup;\n\t}\n\n\tget_task_struct(tsk);\n\tgoto out_unlock_rcu;\n\nout_unlock_threadgroup:\n\tif (*locked) {\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = false;\n\t}\nout_unlock_rcu:\n\trcu_read_unlock();\n\treturn tsk;\n}\n\nvoid cgroup_procs_write_finish(struct task_struct *task, bool locked)\n\t__releases(&cgroup_threadgroup_rwsem)\n{\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\t/* release reference from cgroup_procs_write_start() */\n\tput_task_struct(task);\n\n\tif (locked)\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tfor_each_subsys(ss, ssid)\n\t\tif (ss->post_attach)\n\t\t\tss->post_attach();\n}\n\nstatic void cgroup_print_ss_mask(struct seq_file *seq, u16 ss_mask)\n{\n\tstruct cgroup_subsys *ss;\n\tbool printed = false;\n\tint ssid;\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\tif (printed)\n\t\t\tseq_putc(seq, ' ');\n\t\tseq_puts(seq, ss->name);\n\t\tprinted = true;\n\t} while_each_subsys_mask();\n\tif (printed)\n\t\tseq_putc(seq, '\\n');\n}\n\n/* show controllers which are enabled from the parent */\nstatic int cgroup_controllers_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgroup_control(cgrp));\n\treturn 0;\n}\n\n/* show controllers which are enabled for a given cgroup's children */\nstatic int cgroup_subtree_control_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgrp->subtree_control);\n\treturn 0;\n}\n\n/**\n * cgroup_update_dfl_csses - update css assoc of a subtree in default hierarchy\n * @cgrp: root of the subtree to update csses for\n *\n * @cgrp's control masks have changed and its subtree's css associations\n * need to be updated accordingly.  This function looks up all css_sets\n * which are attached to the subtree, creates the matching updated css_sets\n * and migrates the tasks to the new ones.\n */\nstatic int cgroup_update_dfl_csses(struct cgroup *cgrp)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup *dsct;\n\tstruct css_set *src_cset;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\n\t/* look up all csses currently attached to @cgrp's subtree */\n\tspin_lock_irq(&css_set_lock);\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tstruct cgrp_cset_link *link;\n\n\t\tlist_for_each_entry(link, &dsct->cset_links, cset_link)\n\t\t\tcgroup_migrate_add_src(link->cset, dsct, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* NULL dst indicates self on default hierarchy */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tspin_lock_irq(&css_set_lock);\n\tlist_for_each_entry(src_cset, &mgctx.preloaded_src_csets, mg_preload_node) {\n\t\tstruct task_struct *task, *ntask;\n\n\t\t/* all tasks in src_csets need to be migrated */\n\t\tlist_for_each_entry_safe(task, ntask, &src_cset->tasks, cg_list)\n\t\t\tcgroup_migrate_add_task(task, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\tret = cgroup_migrate_execute(&mgctx);\nout_finish:\n\tcgroup_migrate_finish(&mgctx);\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\treturn ret;\n}\n\n/**\n * cgroup_lock_and_drain_offline - lock cgroup_mutex and drain offlined csses\n * @cgrp: root of the target subtree\n *\n * Because css offlining is asynchronous, userland may try to re-enable a\n * controller while the previous css is still around.  This function grabs\n * cgroup_mutex and drains the previous css instances of @cgrp's subtree.\n */\nvoid cgroup_lock_and_drain_offline(struct cgroup *cgrp)\n\t__acquires(&cgroup_mutex)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\nrestart:\n\tmutex_lock(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\t\t\tDEFINE_WAIT(wait);\n\n\t\t\tif (!css || !percpu_ref_is_dying(&css->refcnt))\n\t\t\t\tcontinue;\n\n\t\t\tcgroup_get_live(dsct);\n\t\t\tprepare_to_wait(&dsct->offline_waitq, &wait,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE);\n\n\t\t\tmutex_unlock(&cgroup_mutex);\n\t\t\tschedule();\n\t\t\tfinish_wait(&dsct->offline_waitq, &wait);\n\n\t\t\tcgroup_put(dsct);\n\t\t\tgoto restart;\n\t\t}\n\t}\n}\n\n/**\n * cgroup_save_control - save control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Save ->subtree_control, ->subtree_ss_mask and ->dom_cgrp to the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_save_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->old_subtree_control = dsct->subtree_control;\n\t\tdsct->old_subtree_ss_mask = dsct->subtree_ss_mask;\n\t\tdsct->old_dom_cgrp = dsct->dom_cgrp;\n\t}\n}\n\n/**\n * cgroup_propagate_control - refresh control masks of a subtree\n * @cgrp: root of the target subtree\n *\n * For @cgrp and its subtree, ensure ->subtree_ss_mask matches\n * ->subtree_control and propagate controller availability through the\n * subtree so that descendants don't have unavailable controllers enabled.\n */\nstatic void cgroup_propagate_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control &= cgroup_control(dsct);\n\t\tdsct->subtree_ss_mask =\n\t\t\tcgroup_calc_subtree_ss_mask(dsct->subtree_control,\n\t\t\t\t\t\t    cgroup_ss_mask(dsct));\n\t}\n}\n\n/**\n * cgroup_restore_control - restore control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Restore ->subtree_control, ->subtree_ss_mask and ->dom_cgrp from the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_restore_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control = dsct->old_subtree_control;\n\t\tdsct->subtree_ss_mask = dsct->old_subtree_ss_mask;\n\t\tdsct->dom_cgrp = dsct->old_dom_cgrp;\n\t}\n}\n\nstatic bool css_visible(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys *ss = css->ss;\n\tstruct cgroup *cgrp = css->cgroup;\n\n\tif (cgroup_control(cgrp) & (1 << ss->id))\n\t\treturn true;\n\tif (!(cgroup_ss_mask(cgrp) & (1 << ss->id)))\n\t\treturn false;\n\treturn cgroup_on_dfl(cgrp) && ss->implicit_on_dfl;\n}\n\n/**\n * cgroup_apply_control_enable - enable or show csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and create new csses or make the existing ones\n * visible.  A css is created invisible if it's being implicitly enabled\n * through dependency.  An invisible css is made visible when the userland\n * explicitly enables it.\n *\n * Returns 0 on success, -errno on failure.  On failure, csses which have\n * been processed already aren't cleaned up.  The caller is responsible for\n * cleaning up with cgroup_apply_control_disable().\n */\nstatic int cgroup_apply_control_enable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid, ret;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!(cgroup_ss_mask(dsct) & (1 << ss->id)))\n\t\t\t\tcontinue;\n\n\t\t\tif (!css) {\n\t\t\t\tcss = css_create(dsct, ss);\n\t\t\t\tif (IS_ERR(css))\n\t\t\t\t\treturn PTR_ERR(css);\n\t\t\t}\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css_visible(css)) {\n\t\t\t\tret = css_populate_dir(css);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_apply_control_disable - kill or hide csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and kill and hide csses so that they match\n * cgroup_ss_mask() and cgroup_visible_mask().\n *\n * A css is hidden when the userland requests it to be disabled while other\n * subsystems are still depending on it.  The css must not actively control\n * resources and be in the vanilla state if it's made visible again later.\n * Controllers which may be depended upon should provide ->css_reset() for\n * this purpose.\n */\nstatic void cgroup_apply_control_disable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!css)\n\t\t\t\tcontinue;\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css->parent &&\n\t\t\t    !(cgroup_ss_mask(dsct) & (1 << ss->id))) {\n\t\t\t\tkill_css(css);\n\t\t\t} else if (!css_visible(css)) {\n\t\t\t\tcss_clear_dir(css);\n\t\t\t\tif (ss->css_reset)\n\t\t\t\t\tss->css_reset(css);\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * cgroup_apply_control - apply control mask updates to the subtree\n * @cgrp: root of the target subtree\n *\n * subsystems can be enabled and disabled in a subtree using the following\n * steps.\n *\n * 1. Call cgroup_save_control() to stash the current state.\n * 2. Update ->subtree_control masks in the subtree as desired.\n * 3. Call cgroup_apply_control() to apply the changes.\n * 4. Optionally perform other related operations.\n * 5. Call cgroup_finalize_control() to finish up.\n *\n * This function implements step 3 and propagates the mask changes\n * throughout @cgrp's subtree, updates csses accordingly and perform\n * process migrations.\n */\nstatic int cgroup_apply_control(struct cgroup *cgrp)\n{\n\tint ret;\n\n\tcgroup_propagate_control(cgrp);\n\n\tret = cgroup_apply_control_enable(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * At this point, cgroup_e_css_by_mask() results reflect the new csses\n\t * making the following cgroup_update_dfl_csses() properly update\n\t * css associations of all tasks in the subtree.\n\t */\n\tret = cgroup_update_dfl_csses(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/**\n * cgroup_finalize_control - finalize control mask update\n * @cgrp: root of the target subtree\n * @ret: the result of the update\n *\n * Finalize control mask update.  See cgroup_apply_control() for more info.\n */\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret)\n{\n\tif (ret) {\n\t\tcgroup_restore_control(cgrp);\n\t\tcgroup_propagate_control(cgrp);\n\t}\n\n\tcgroup_apply_control_disable(cgrp);\n}\n\nstatic int cgroup_vet_subtree_control_enable(struct cgroup *cgrp, u16 enable)\n{\n\tu16 domain_enable = enable & ~cgrp_dfl_threaded_ss_mask;\n\n\t/* if nothing is getting enabled, nothing to worry about */\n\tif (!enable)\n\t\treturn 0;\n\n\t/* can @cgrp host any resources? */\n\tif (!cgroup_is_valid_domain(cgrp->dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/* mixables don't care */\n\tif (cgroup_is_mixable(cgrp))\n\t\treturn 0;\n\n\tif (domain_enable) {\n\t\t/* can't enable domain controllers inside a thread subtree */\n\t\tif (cgroup_is_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn -EOPNOTSUPP;\n\t} else {\n\t\t/*\n\t\t * Threaded controllers can handle internal competitions\n\t\t * and are always allowed inside a (prospective) thread\n\t\t * subtree.\n\t\t */\n\t\tif (cgroup_can_be_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * Controllers can't be enabled for a cgroup with tasks to avoid\n\t * child cgroups competing against tasks.\n\t */\n\tif (cgroup_has_tasks(cgrp))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\n/* change the enabled child controllers for a cgroup in the default hierarchy */\nstatic ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,\n\t\t\t\t\t    char *buf, size_t nbytes,\n\t\t\t\t\t    loff_t off)\n{\n\tu16 enable = 0, disable = 0;\n\tstruct cgroup *cgrp, *child;\n\tstruct cgroup_subsys *ss;\n\tchar *tok;\n\tint ssid, ret;\n\n\t/*\n\t * Parse input - space separated list of subsystem names prefixed\n\t * with either + or -.\n\t */\n\tbuf = strstrip(buf);\n\twhile ((tok = strsep(&buf, \" \"))) {\n\t\tif (tok[0] == '\\0')\n\t\t\tcontinue;\n\t\tdo_each_subsys_mask(ss, ssid, ~cgrp_dfl_inhibit_ss_mask) {\n\t\t\tif (!cgroup_ssid_enabled(ssid) ||\n\t\t\t    strcmp(tok + 1, ss->name))\n\t\t\t\tcontinue;\n\n\t\t\tif (*tok == '+') {\n\t\t\t\tenable |= 1 << ssid;\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t} else if (*tok == '-') {\n\t\t\t\tdisable |= 1 << ssid;\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t} else {\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tbreak;\n\t\t} while_each_subsys_mask();\n\t\tif (ssid == CGROUP_SUBSYS_COUNT)\n\t\t\treturn -EINVAL;\n\t}\n\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tfor_each_subsys(ss, ssid) {\n\t\tif (enable & (1 << ssid)) {\n\t\t\tif (cgrp->subtree_control & (1 << ssid)) {\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(cgroup_control(cgrp) & (1 << ssid))) {\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t} else if (disable & (1 << ssid)) {\n\t\t\tif (!(cgrp->subtree_control & (1 << ssid))) {\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* a child has it enabled? */\n\t\t\tcgroup_for_each_live_child(child, cgrp) {\n\t\t\t\tif (child->subtree_control & (1 << ssid)) {\n\t\t\t\t\tret = -EBUSY;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!enable && !disable) {\n\t\tret = 0;\n\t\tgoto out_unlock;\n\t}\n\n\tret = cgroup_vet_subtree_control_enable(cgrp, enable);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/* save and update control masks and prepare csses */\n\tcgroup_save_control(cgrp);\n\n\tcgrp->subtree_control |= enable;\n\tcgrp->subtree_control &= ~disable;\n\n\tret = cgroup_apply_control(cgrp);\n\tcgroup_finalize_control(cgrp, ret);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tkernfs_activate(cgrp->kn);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\n/**\n * cgroup_enable_threaded - make @cgrp threaded\n * @cgrp: the target cgroup\n *\n * Called when \"threaded\" is written to the cgroup.type interface file and\n * tries to make @cgrp threaded and join the parent's resource domain.\n * This function is never called on the root cgroup as cgroup.type doesn't\n * exist on it.\n */\nstatic int cgroup_enable_threaded(struct cgroup *cgrp)\n{\n\tstruct cgroup *parent = cgroup_parent(cgrp);\n\tstruct cgroup *dom_cgrp = parent->dom_cgrp;\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* noop if already threaded */\n\tif (cgroup_is_threaded(cgrp))\n\t\treturn 0;\n\n\t/*\n\t * If @cgroup is populated or has domain controllers enabled, it\n\t * can't be switched.  While the below cgroup_can_be_thread_root()\n\t * test can catch the same conditions, that's only when @parent is\n\t * not mixable, so let's check it explicitly.\n\t */\n\tif (cgroup_is_populated(cgrp) ||\n\t    cgrp->subtree_control & ~cgrp_dfl_threaded_ss_mask)\n\t\treturn -EOPNOTSUPP;\n\n\t/* we're joining the parent's domain, ensure its validity */\n\tif (!cgroup_is_valid_domain(dom_cgrp) ||\n\t    !cgroup_can_be_thread_root(dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * The following shouldn't cause actual migrations and should\n\t * always succeed.\n\t */\n\tcgroup_save_control(cgrp);\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp)\n\t\tif (dsct == cgrp || cgroup_is_threaded(dsct))\n\t\t\tdsct->dom_cgrp = dom_cgrp;\n\n\tret = cgroup_apply_control(cgrp);\n\tif (!ret)\n\t\tparent->nr_threaded_children++;\n\n\tcgroup_finalize_control(cgrp, ret);\n\treturn ret;\n}\n\nstatic int cgroup_type_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tif (cgroup_is_threaded(cgrp))\n\t\tseq_puts(seq, \"threaded\\n\");\n\telse if (!cgroup_is_valid_domain(cgrp))\n\t\tseq_puts(seq, \"domain invalid\\n\");\n\telse if (cgroup_is_thread_root(cgrp))\n\t\tseq_puts(seq, \"domain threaded\\n\");\n\telse\n\t\tseq_puts(seq, \"domain\\n\");\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_type_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint ret;\n\n\t/* only switching to threaded mode is supported */\n\tif (strcmp(strstrip(buf), \"threaded\"))\n\t\treturn -EINVAL;\n\n\t/* drain dying csses before we re-apply (threaded) subtree control */\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/* threaded can only be enabled */\n\tret = cgroup_enable_threaded(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_max_descendants_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint descendants = READ_ONCE(cgrp->max_descendants);\n\n\tif (descendants == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", descendants);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_descendants_write(struct kernfs_open_file *of,\n\t\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint descendants;\n\tssize_t ret;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdescendants = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &descendants);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (descendants < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_descendants = descendants;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_max_depth_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint depth = READ_ONCE(cgrp->max_depth);\n\n\tif (depth == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", depth);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_depth_write(struct kernfs_open_file *of,\n\t\t\t\t      char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint depth;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdepth = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &depth);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (depth < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_depth = depth;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_events_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"populated %d\\n\", cgroup_is_populated(cgrp));\n\tseq_printf(seq, \"frozen %d\\n\", test_bit(CGRP_FROZEN, &cgrp->flags));\n\n\treturn 0;\n}\n\nstatic int cgroup_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgroup = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"nr_descendants %d\\n\",\n\t\t   cgroup->nr_descendants);\n\tseq_printf(seq, \"nr_dying_descendants %d\\n\",\n\t\t   cgroup->nr_dying_descendants);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused cgroup_extra_stat_show(struct seq_file *seq,\n\t\t\t\t\t\t struct cgroup *cgrp, int ssid)\n{\n\tstruct cgroup_subsys *ss = cgroup_subsys[ssid];\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!ss->css_extra_stat_show)\n\t\treturn 0;\n\n\tcss = cgroup_tryget_css(cgrp, ss);\n\tif (!css)\n\t\treturn 0;\n\n\tret = ss->css_extra_stat_show(seq, css);\n\tcss_put(css);\n\treturn ret;\n}\n\nstatic int cpu_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup __maybe_unused *cgrp = seq_css(seq)->cgroup;\n\tint ret = 0;\n\n\tcgroup_base_stat_cputime_show(seq);\n#ifdef CONFIG_CGROUP_SCHED\n\tret = cgroup_extra_stat_show(seq, cgrp, cpu_cgrp_id);\n#endif\n\treturn ret;\n}\n\n#ifdef CONFIG_PSI\nstatic int cgroup_io_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_IO);\n}\nstatic int cgroup_memory_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_MEM);\n}\nstatic int cgroup_cpu_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_CPU);\n}\n\nstatic ssize_t cgroup_pressure_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t\t  size_t nbytes, enum psi_res res)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct psi_trigger *new;\n\tstruct cgroup *cgrp;\n\tstruct psi_group *psi;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tcgroup_get(cgrp);\n\tcgroup_kn_unlock(of->kn);\n\n\tpsi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\tnew = psi_trigger_create(psi, buf, nbytes, res);\n\tif (IS_ERR(new)) {\n\t\tcgroup_put(cgrp);\n\t\treturn PTR_ERR(new);\n\t}\n\n\tpsi_trigger_replace(&ctx->psi.trigger, new);\n\n\tcgroup_put(cgrp);\n\n\treturn nbytes;\n}\n\nstatic ssize_t cgroup_io_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_IO);\n}\n\nstatic ssize_t cgroup_memory_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_MEM);\n}\n\nstatic ssize_t cgroup_cpu_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_CPU);\n}\n\nstatic __poll_t cgroup_pressure_poll(struct kernfs_open_file *of,\n\t\t\t\t\t  poll_table *pt)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\treturn psi_trigger_poll(&ctx->psi.trigger, of->file, pt);\n}\n\nstatic void cgroup_pressure_release(struct kernfs_open_file *of)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tpsi_trigger_replace(&ctx->psi.trigger, NULL);\n}\n\nbool cgroup_psi_enabled(void)\n{\n\treturn (cgroup_feature_disable_mask & (1 << OPT_FEATURE_PRESSURE)) == 0;\n}\n\n#else /* CONFIG_PSI */\nbool cgroup_psi_enabled(void)\n{\n\treturn false;\n}\n\n#endif /* CONFIG_PSI */\n\nstatic int cgroup_freeze_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"%d\\n\", cgrp->freezer.freeze);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_freeze_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint freeze;\n\n\tret = kstrtoint(strstrip(buf), 0, &freeze);\n\tif (ret)\n\t\treturn ret;\n\n\tif (freeze < 0 || freeze > 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgroup_freeze(cgrp, freeze);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic void __cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct css_task_iter it;\n\tstruct task_struct *task;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tspin_lock_irq(&css_set_lock);\n\tset_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n\n\tcss_task_iter_start(&cgrp->self, CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED, &it);\n\twhile ((task = css_task_iter_next(&it))) {\n\t\t/* Ignore kernel threads here. */\n\t\tif (task->flags & PF_KTHREAD)\n\t\t\tcontinue;\n\n\t\t/* Skip tasks that are already dying. */\n\t\tif (__fatal_signal_pending(task))\n\t\t\tcontinue;\n\n\t\tsend_sig(SIGKILL, task, 0);\n\t}\n\tcss_task_iter_end(&it);\n\n\tspin_lock_irq(&css_set_lock);\n\tclear_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n}\n\nstatic void cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct cgroup_subsys_state *css;\n\tstruct cgroup *dsct;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_pre(dsct, css, cgrp)\n\t\t__cgroup_kill(dsct);\n}\n\nstatic ssize_t cgroup_kill_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tssize_t ret = 0;\n\tint kill;\n\tstruct cgroup *cgrp;\n\n\tret = kstrtoint(strstrip(buf), 0, &kill);\n\tif (ret)\n\t\treturn ret;\n\n\tif (kill != 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/*\n\t * Killing is a process directed operation, i.e. the whole thread-group\n\t * is taken down so act like we do for cgroup.procs and only make this\n\t * writable in non-threaded cgroups.\n\t */\n\tif (cgroup_is_threaded(cgrp))\n\t\tret = -EOPNOTSUPP;\n\telse\n\t\tcgroup_kill(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_file_open(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->ns = current->nsproxy->cgroup_ns;\n\tget_cgroup_ns(ctx->ns);\n\tof->priv = ctx;\n\n\tif (!cft->open)\n\t\treturn 0;\n\n\tret = cft->open(of);\n\tif (ret) {\n\t\tput_cgroup_ns(ctx->ns);\n\t\tkfree(ctx);\n\t}\n\treturn ret;\n}\n\nstatic void cgroup_file_release(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tif (cft->release)\n\t\tcft->release(of);\n\tput_cgroup_ns(ctx->ns);\n\tkfree(ctx);\n}\n\nstatic ssize_t cgroup_file_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup *cgrp = of->kn->parent->priv;\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!nbytes)\n\t\treturn 0;\n\n\t/*\n\t * If namespaces are delegation boundaries, disallow writes to\n\t * files in an non-init namespace root from inside the namespace\n\t * except for the files explicitly marked delegatable -\n\t * cgroup.procs and cgroup.subtree_control.\n\t */\n\tif ((cgrp->root->flags & CGRP_ROOT_NS_DELEGATE) &&\n\t    !(cft->flags & CFTYPE_NS_DELEGATABLE) &&\n\t    ctx->ns != &init_cgroup_ns && ctx->ns->root_cset->dfl_cgrp == cgrp)\n\t\treturn -EPERM;\n\n\tif (cft->write)\n\t\treturn cft->write(of, buf, nbytes, off);\n\n\t/*\n\t * kernfs guarantees that a file isn't deleted with operations in\n\t * flight, which means that the matching css is and stays alive and\n\t * doesn't need to be pinned.  The RCU locking is not necessary\n\t * either.  It's just for the convenience of using cgroup_css().\n\t */\n\trcu_read_lock();\n\tcss = cgroup_css(cgrp, cft->ss);\n\trcu_read_unlock();\n\n\tif (cft->write_u64) {\n\t\tunsigned long long v;\n\t\tret = kstrtoull(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_u64(css, cft, v);\n\t} else if (cft->write_s64) {\n\t\tlong long v;\n\t\tret = kstrtoll(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_s64(css, cft, v);\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret ?: nbytes;\n}\n\nstatic __poll_t cgroup_file_poll(struct kernfs_open_file *of, poll_table *pt)\n{\n\tstruct cftype *cft = of_cft(of);\n\n\tif (cft->poll)\n\t\treturn cft->poll(of, pt);\n\n\treturn kernfs_generic_poll(of, pt);\n}\n\nstatic void *cgroup_seqfile_start(struct seq_file *seq, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_start(seq, ppos);\n}\n\nstatic void *cgroup_seqfile_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_next(seq, v, ppos);\n}\n\nstatic void cgroup_seqfile_stop(struct seq_file *seq, void *v)\n{\n\tif (seq_cft(seq)->seq_stop)\n\t\tseq_cft(seq)->seq_stop(seq, v);\n}\n\nstatic int cgroup_seqfile_show(struct seq_file *m, void *arg)\n{\n\tstruct cftype *cft = seq_cft(m);\n\tstruct cgroup_subsys_state *css = seq_css(m);\n\n\tif (cft->seq_show)\n\t\treturn cft->seq_show(m, arg);\n\n\tif (cft->read_u64)\n\t\tseq_printf(m, \"%llu\\n\", cft->read_u64(css, cft));\n\telse if (cft->read_s64)\n\t\tseq_printf(m, \"%lld\\n\", cft->read_s64(css, cft));\n\telse\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic struct kernfs_ops cgroup_kf_single_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\nstatic struct kernfs_ops cgroup_kf_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_start\t\t= cgroup_seqfile_start,\n\t.seq_next\t\t= cgroup_seqfile_next,\n\t.seq_stop\t\t= cgroup_seqfile_stop,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\n/* set uid and gid of cgroup dirs and files to that of the creator */\nstatic int cgroup_kn_set_ugid(struct kernfs_node *kn)\n{\n\tstruct iattr iattr = { .ia_valid = ATTR_UID | ATTR_GID,\n\t\t\t       .ia_uid = current_fsuid(),\n\t\t\t       .ia_gid = current_fsgid(), };\n\n\tif (uid_eq(iattr.ia_uid, GLOBAL_ROOT_UID) &&\n\t    gid_eq(iattr.ia_gid, GLOBAL_ROOT_GID))\n\t\treturn 0;\n\n\treturn kernfs_setattr(kn, &iattr);\n}\n\nstatic void cgroup_file_notify_timer(struct timer_list *timer)\n{\n\tcgroup_file_notify(container_of(timer, struct cgroup_file,\n\t\t\t\t\tnotify_timer));\n}\n\nstatic int cgroup_add_file(struct cgroup_subsys_state *css, struct cgroup *cgrp,\n\t\t\t   struct cftype *cft)\n{\n\tchar name[CGROUP_FILE_NAME_MAX];\n\tstruct kernfs_node *kn;\n\tstruct lock_class_key *key = NULL;\n\tint ret;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tkey = &cft->lockdep_key;\n#endif\n\tkn = __kernfs_create_file(cgrp->kn, cgroup_file_name(cgrp, cft, name),\n\t\t\t\t  cgroup_file_mode(cft),\n\t\t\t\t  GLOBAL_ROOT_UID, GLOBAL_ROOT_GID,\n\t\t\t\t  0, cft->kf_ops, cft,\n\t\t\t\t  NULL, key);\n\tif (IS_ERR(kn))\n\t\treturn PTR_ERR(kn);\n\n\tret = cgroup_kn_set_ugid(kn);\n\tif (ret) {\n\t\tkernfs_remove(kn);\n\t\treturn ret;\n\t}\n\n\tif (cft->file_offset) {\n\t\tstruct cgroup_file *cfile = (void *)css + cft->file_offset;\n\n\t\ttimer_setup(&cfile->notify_timer, cgroup_file_notify_timer, 0);\n\n\t\tspin_lock_irq(&cgroup_file_kn_lock);\n\t\tcfile->kn = kn;\n\t\tspin_unlock_irq(&cgroup_file_kn_lock);\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_addrm_files - add or remove files to a cgroup directory\n * @css: the target css\n * @cgrp: the target cgroup (usually css->cgroup)\n * @cfts: array of cftypes to be added\n * @is_add: whether to add or remove\n *\n * Depending on @is_add, add or remove files defined by @cfts on @cgrp.\n * For removals, this function never fails.\n */\nstatic int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add)\n{\n\tstruct cftype *cft, *cft_end = NULL;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\nrestart:\n\tfor (cft = cfts; cft != cft_end && cft->name[0] != '\\0'; cft++) {\n\t\t/* does cft->flags tell us to skip this file on @cgrp? */\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_ONLY_ON_DFL) && !cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_NOT_ON_DFL) && cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_NOT_ON_ROOT) && !cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_ONLY_ON_ROOT) && cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_DEBUG) && !cgroup_debug)\n\t\t\tcontinue;\n\t\tif (is_add) {\n\t\t\tret = cgroup_add_file(css, cgrp, cft);\n\t\t\tif (ret) {\n\t\t\t\tpr_warn(\"%s: failed to add %s, err=%d\\n\",\n\t\t\t\t\t__func__, cft->name, ret);\n\t\t\t\tcft_end = cft;\n\t\t\t\tis_add = false;\n\t\t\t\tgoto restart;\n\t\t\t}\n\t\t} else {\n\t\t\tcgroup_rm_file(cgrp, cft);\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int cgroup_apply_cftypes(struct cftype *cfts, bool is_add)\n{\n\tstruct cgroup_subsys *ss = cfts[0].ss;\n\tstruct cgroup *root = &ss->root->cgrp;\n\tstruct cgroup_subsys_state *css;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* add/rm files for all cgroups created before */\n\tcss_for_each_descendant_pre(css, cgroup_css(root, ss)) {\n\t\tstruct cgroup *cgrp = css->cgroup;\n\n\t\tif (!(css->flags & CSS_VISIBLE))\n\t\t\tcontinue;\n\n\t\tret = cgroup_addrm_files(css, cgrp, cfts, is_add);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tif (is_add && !ret)\n\t\tkernfs_activate(root->kn);\n\treturn ret;\n}\n\nstatic void cgroup_exit_cftypes(struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\t/* free copy for custom atomic_write_len, see init_cftypes() */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE)\n\t\t\tkfree(cft->kf_ops);\n\t\tcft->kf_ops = NULL;\n\t\tcft->ss = NULL;\n\n\t\t/* revert flags set by cgroup core while adding @cfts */\n\t\tcft->flags &= ~(__CFTYPE_ONLY_ON_DFL | __CFTYPE_NOT_ON_DFL);\n\t}\n}\n\nstatic int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\tstruct kernfs_ops *kf_ops;\n\n\t\tWARN_ON(cft->ss || cft->kf_ops);\n\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\n\t\tif (cft->seq_start)\n\t\t\tkf_ops = &cgroup_kf_ops;\n\t\telse\n\t\t\tkf_ops = &cgroup_kf_single_ops;\n\n\t\t/*\n\t\t * Ugh... if @cft wants a custom max_write_len, we need to\n\t\t * make a copy of kf_ops to set its atomic_write_len.\n\t\t */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE) {\n\t\t\tkf_ops = kmemdup(kf_ops, sizeof(*kf_ops), GFP_KERNEL);\n\t\t\tif (!kf_ops) {\n\t\t\t\tcgroup_exit_cftypes(cfts);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tkf_ops->atomic_write_len = cft->max_write_len;\n\t\t}\n\n\t\tcft->kf_ops = kf_ops;\n\t\tcft->ss = ss;\n\t}\n\n\treturn 0;\n}\n\nstatic int cgroup_rm_cftypes_locked(struct cftype *cfts)\n{\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tif (!cfts || !cfts[0].ss)\n\t\treturn -ENOENT;\n\n\tlist_del(&cfts->node);\n\tcgroup_apply_cftypes(cfts, false);\n\tcgroup_exit_cftypes(cfts);\n\treturn 0;\n}\n\n/**\n * cgroup_rm_cftypes - remove an array of cftypes from a subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Unregister @cfts.  Files described by @cfts are removed from all\n * existing cgroups and all future cgroups won't have them either.  This\n * function can be called anytime whether @cfts' subsys is attached or not.\n *\n * Returns 0 on successful unregistration, -ENOENT if @cfts is not\n * registered.\n */\nint cgroup_rm_cftypes(struct cftype *cfts)\n{\n\tint ret;\n\n\tmutex_lock(&cgroup_mutex);\n\tret = cgroup_rm_cftypes_locked(cfts);\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_cftypes - add an array of cftypes to a subsystem\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Register @cfts to @ss.  Files described by @cfts are created for all\n * existing cgroups to which @ss is attached and all future cgroups will\n * have them too.  This function can be called anytime whether @ss is\n * attached or not.\n *\n * Returns 0 on successful registration, -errno on failure.  Note that this\n * function currently returns 0 as long as @cfts registration is successful\n * even if some file creation attempts on existing cgroups fail.\n */\nstatic int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tint ret;\n\n\tif (!cgroup_ssid_enabled(ss->id))\n\t\treturn 0;\n\n\tif (!cfts || cfts[0].name[0] == '\\0')\n\t\treturn 0;\n\n\tret = cgroup_init_cftypes(ss, cfts);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&cgroup_mutex);\n\n\tlist_add_tail(&cfts->node, &ss->cfts);\n\tret = cgroup_apply_cftypes(cfts, true);\n\tif (ret)\n\t\tcgroup_rm_cftypes_locked(cfts);\n\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_dfl_cftypes - add an array of cftypes for default hierarchy\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the default hierarchy.\n */\nint cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_ONLY_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_add_legacy_cftypes - add an array of cftypes for legacy hierarchies\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the legacy hierarchies.\n */\nint cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_NOT_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_file_notify - generate a file modified event for a cgroup_file\n * @cfile: target cgroup_file\n *\n * @cfile must have been obtained by setting cftype->file_offset.\n */\nvoid cgroup_file_notify(struct cgroup_file *cfile)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cgroup_file_kn_lock, flags);\n\tif (cfile->kn) {\n\t\tunsigned long last = cfile->notified_at;\n\t\tunsigned long next = last + CGROUP_FILE_NOTIFY_MIN_INTV;\n\n\t\tif (time_in_range(jiffies, last, next)) {\n\t\t\ttimer_reduce(&cfile->notify_timer, next);\n\t\t} else {\n\t\t\tkernfs_notify(cfile->kn);\n\t\t\tcfile->notified_at = jiffies;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cgroup_file_kn_lock, flags);\n}\n\n/**\n * css_next_child - find the next child of a given css\n * @pos: the current position (%NULL to initiate traversal)\n * @parent: css whose children to walk\n *\n * This function returns the next child of @parent and should be called\n * under either cgroup_mutex or RCU read lock.  The only requirement is\n * that @parent and @pos are accessible.  The next sibling is guaranteed to\n * be returned regardless of their states.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,\n\t\t\t\t\t   struct cgroup_subsys_state *parent)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/*\n\t * @pos could already have been unlinked from the sibling list.\n\t * Once a cgroup is removed, its ->sibling.next is no longer\n\t * updated when its next sibling changes.  CSS_RELEASED is set when\n\t * @pos is taken off list, at which time its next pointer is valid,\n\t * and, as releases are serialized, the one pointed to by the next\n\t * pointer is guaranteed to not have started release yet.  This\n\t * implies that if we observe !CSS_RELEASED on @pos in this RCU\n\t * critical section, the one pointed to by its next pointer is\n\t * guaranteed to not have finished its RCU grace period even if we\n\t * have dropped rcu_read_lock() in-between iterations.\n\t *\n\t * If @pos has CSS_RELEASED set, its next pointer can't be\n\t * dereferenced; however, as each css is given a monotonically\n\t * increasing unique serial number and always appended to the\n\t * sibling list, the next one can be found by walking the parent's\n\t * children until the first css with higher serial number than\n\t * @pos's.  While this path can be slower, it happens iff iteration\n\t * races against release and the race window is very small.\n\t */\n\tif (!pos) {\n\t\tnext = list_entry_rcu(parent->children.next, struct cgroup_subsys_state, sibling);\n\t} else if (likely(!(pos->flags & CSS_RELEASED))) {\n\t\tnext = list_entry_rcu(pos->sibling.next, struct cgroup_subsys_state, sibling);\n\t} else {\n\t\tlist_for_each_entry_rcu(next, &parent->children, sibling,\n\t\t\t\t\tlockdep_is_held(&cgroup_mutex))\n\t\t\tif (next->serial_nr > pos->serial_nr)\n\t\t\t\tbreak;\n\t}\n\n\t/*\n\t * @next, if not pointing to the head, can be dereferenced and is\n\t * the next sibling.\n\t */\n\tif (&next->sibling != &parent->children)\n\t\treturn next;\n\treturn NULL;\n}\n\n/**\n * css_next_descendant_pre - find the next descendant for pre-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_pre().  Find the next descendant\n * to visit for pre-order traversal of @root's descendants.  @root is\n * included in the iteration and the first node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @root are accessible and @pos is a descendant of @root.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_pre(struct cgroup_subsys_state *pos,\n\t\t\tstruct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit @root */\n\tif (!pos)\n\t\treturn root;\n\n\t/* visit the first child if exists */\n\tnext = css_next_child(NULL, pos);\n\tif (next)\n\t\treturn next;\n\n\t/* no child, visit my or the closest ancestor's next sibling */\n\twhile (pos != root) {\n\t\tnext = css_next_child(pos, pos->parent);\n\t\tif (next)\n\t\t\treturn next;\n\t\tpos = pos->parent;\n\t}\n\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(css_next_descendant_pre);\n\n/**\n * css_rightmost_descendant - return the rightmost descendant of a css\n * @pos: css of interest\n *\n * Return the rightmost descendant of @pos.  If there's no descendant, @pos\n * is returned.  This can be used during pre-order traversal to skip\n * subtree of @pos.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct rightmost descendant as\n * long as @pos is accessible.\n */\nstruct cgroup_subsys_state *\ncss_rightmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last, *tmp;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\tdo {\n\t\tlast = pos;\n\t\t/* ->prev isn't RCU safe, walk ->next till the end */\n\t\tpos = NULL;\n\t\tcss_for_each_child(tmp, last)\n\t\t\tpos = tmp;\n\t} while (pos);\n\n\treturn last;\n}\n\nstatic struct cgroup_subsys_state *\ncss_leftmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last;\n\n\tdo {\n\t\tlast = pos;\n\t\tpos = css_next_child(NULL, pos);\n\t} while (pos);\n\n\treturn last;\n}\n\n/**\n * css_next_descendant_post - find the next descendant for post-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_post().  Find the next descendant\n * to visit for post-order traversal of @root's descendants.  @root is\n * included in the iteration and the last node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @cgroup are accessible and @pos is a descendant of\n * @cgroup.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_post(struct cgroup_subsys_state *pos,\n\t\t\t struct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit leftmost descendant which may be @root */\n\tif (!pos)\n\t\treturn css_leftmost_descendant(root);\n\n\t/* if we visited @root, we're done */\n\tif (pos == root)\n\t\treturn NULL;\n\n\t/* if there's an unvisited sibling, visit its leftmost descendant */\n\tnext = css_next_child(pos, pos->parent);\n\tif (next)\n\t\treturn css_leftmost_descendant(next);\n\n\t/* no sibling left, visit parent */\n\treturn pos->parent;\n}\n\n/**\n * css_has_online_children - does a css have online children\n * @css: the target css\n *\n * Returns %true if @css has any online children; otherwise, %false.  This\n * function can be called from any context but the caller is responsible\n * for synchronizing against on/offlining as necessary.\n */\nbool css_has_online_children(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys_state *child;\n\tbool ret = false;\n\n\trcu_read_lock();\n\tcss_for_each_child(child, css) {\n\t\tif (child->flags & CSS_ONLINE) {\n\t\t\tret = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)\n{\n\tstruct list_head *l;\n\tstruct cgrp_cset_link *link;\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* find the next threaded cset */\n\tif (it->tcset_pos) {\n\t\tl = it->tcset_pos->next;\n\n\t\tif (l != it->tcset_head) {\n\t\t\tit->tcset_pos = l;\n\t\t\treturn container_of(l, struct css_set,\n\t\t\t\t\t    threaded_csets_node);\n\t\t}\n\n\t\tit->tcset_pos = NULL;\n\t}\n\n\t/* find the next cset */\n\tl = it->cset_pos;\n\tl = l->next;\n\tif (l == it->cset_head) {\n\t\tit->cset_pos = NULL;\n\t\treturn NULL;\n\t}\n\n\tif (it->ss) {\n\t\tcset = container_of(l, struct css_set, e_cset_node[it->ss->id]);\n\t} else {\n\t\tlink = list_entry(l, struct cgrp_cset_link, cset_link);\n\t\tcset = link->cset;\n\t}\n\n\tit->cset_pos = l;\n\n\t/* initialize threaded css_set walking */\n\tif (it->flags & CSS_TASK_ITER_THREADED) {\n\t\tif (it->cur_dcset)\n\t\t\tput_css_set_locked(it->cur_dcset);\n\t\tit->cur_dcset = cset;\n\t\tget_css_set(cset);\n\n\t\tit->tcset_head = &cset->threaded_csets;\n\t\tit->tcset_pos = &cset->threaded_csets;\n\t}\n\n\treturn cset;\n}\n\n/**\n * css_task_iter_advance_css_set - advance a task iterator to the next css_set\n * @it: the iterator to advance\n *\n * Advance @it to the next css_set to walk.\n */\nstatic void css_task_iter_advance_css_set(struct css_task_iter *it)\n{\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* Advance to the next non-empty css_set and find first non-empty tasks list*/\n\twhile ((cset = css_task_iter_next_css_set(it))) {\n\t\tif (!list_empty(&cset->tasks)) {\n\t\t\tit->cur_tasks_head = &cset->tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->mg_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->mg_tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->dying_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->dying_tasks;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cset) {\n\t\tit->task_pos = NULL;\n\t\treturn;\n\t}\n\tit->task_pos = it->cur_tasks_head->next;\n\n\t/*\n\t * We don't keep css_sets locked across iteration steps and thus\n\t * need to take steps to ensure that iteration can be resumed after\n\t * the lock is re-acquired.  Iteration is performed at two levels -\n\t * css_sets and tasks in them.\n\t *\n\t * Once created, a css_set never leaves its cgroup lists, so a\n\t * pinned css_set is guaranteed to stay put and we can resume\n\t * iteration afterwards.\n\t *\n\t * Tasks may leave @cset across iteration steps.  This is resolved\n\t * by registering each iterator with the css_set currently being\n\t * walked and making css_set_move_task() advance iterators whose\n\t * next task is leaving.\n\t */\n\tif (it->cur_cset) {\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t}\n\tget_css_set(cset);\n\tit->cur_cset = cset;\n\tlist_add(&it->iters_node, &cset->task_iters);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_FILE_NOTIFY_MIN_INTV\tDIV_ROUND_UP(HZ, 100)",
            "#define CGROUP_FILE_NAME_MAX\t\t(MAX_CGROUP_TYPE_NAMELEN +\t\\\n\t\t\t\t\t MAX_CFTYPE_NAME + 2)"
          ],
          "globals_used": [
            "bool cgroup_debug",
            "static DEFINE_SPINLOCK(cgroup_file_kn_lock);",
            "static u16 cgrp_dfl_inhibit_ss_mask;",
            "static u16 cgrp_dfl_threaded_ss_mask;",
            "struct cgroup_namespace init_cgroup_ns = {\n\t.ns.count\t= REFCOUNT_INIT(2),\n\t.user_ns\t= &init_user_ns,\n\t.ns.ops\t\t= &cgroupns_operations,\n\t.ns.inum\t= PROC_CGROUP_INIT_INO,\n\t.root_cset\t= &init_css_set,\n};",
            "static u16 cgroup_feature_disable_mask",
            "static int cgroup_apply_control(struct cgroup *cgrp);",
            "static void cgroup_finalize_control(struct cgroup *cgrp, int ret);",
            "static void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);",
            "static int cgroup_destroy_locked(struct cgroup *cgrp);",
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);",
            "static int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_FILE_NOTIFY_MIN_INTV\tDIV_ROUND_UP(HZ, 100)\n#define CGROUP_FILE_NAME_MAX\t\t(MAX_CGROUP_TYPE_NAMELEN +\t\\\n\t\t\t\t\t MAX_CFTYPE_NAME + 2)\n\nbool cgroup_debug;\nstatic DEFINE_SPINLOCK(cgroup_file_kn_lock);\nstatic u16 cgrp_dfl_inhibit_ss_mask;\nstatic u16 cgrp_dfl_threaded_ss_mask;\nstruct cgroup_namespace init_cgroup_ns = {\n\t.ns.count\t= REFCOUNT_INIT(2),\n\t.user_ns\t= &init_user_ns,\n\t.ns.ops\t\t= &cgroupns_operations,\n\t.ns.inum\t= PROC_CGROUP_INIT_INO,\n\t.root_cset\t= &init_css_set,\n};\nstatic u16 cgroup_feature_disable_mask;\nstatic int cgroup_apply_control(struct cgroup *cgrp);\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret);\nstatic void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);\nstatic int cgroup_destroy_locked(struct cgroup *cgrp);\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\nstatic int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add);\n\nint cgroup_attach_task(struct cgroup *dst_cgrp, struct task_struct *leader,\n\t\t       bool threadgroup)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct task_struct *task;\n\tint ret = 0;\n\n\t/* look up all src csets */\n\tspin_lock_irq(&css_set_lock);\n\trcu_read_lock();\n\ttask = leader;\n\tdo {\n\t\tcgroup_migrate_add_src(task_css_set(task), dst_cgrp, &mgctx);\n\t\tif (!threadgroup)\n\t\t\tbreak;\n\t} while_each_thread(leader, task);\n\trcu_read_unlock();\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* prepare dst csets and commit */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (!ret)\n\t\tret = cgroup_migrate(leader, threadgroup, &mgctx);\n\n\tcgroup_migrate_finish(&mgctx);\n\n\tif (!ret)\n\t\tTRACE_CGROUP_PATH(attach_task, dst_cgrp, leader, threadgroup);\n\n\treturn ret;\n}\n\nstruct task_struct *cgroup_procs_write_start(char *buf, bool threadgroup,\n\t\t\t\t\t     bool *locked)\n\t__acquires(&cgroup_threadgroup_rwsem)\n{\n\tstruct task_struct *tsk;\n\tpid_t pid;\n\n\tif (kstrtoint(strstrip(buf), 0, &pid) || pid < 0)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * If we migrate a single thread, we don't care about threadgroup\n\t * stability. If the thread is `current`, it won't exit(2) under our\n\t * hands or change PID through exec(2). We exclude\n\t * cgroup_update_dfl_csses and other cgroup_{proc,thread}s_write\n\t * callers by cgroup_mutex.\n\t * Therefore, we can skip the global lock.\n\t */\n\tlockdep_assert_held(&cgroup_mutex);\n\tif (pid || threadgroup) {\n\t\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = true;\n\t} else {\n\t\t*locked = false;\n\t}\n\n\trcu_read_lock();\n\tif (pid) {\n\t\ttsk = find_task_by_vpid(pid);\n\t\tif (!tsk) {\n\t\t\ttsk = ERR_PTR(-ESRCH);\n\t\t\tgoto out_unlock_threadgroup;\n\t\t}\n\t} else {\n\t\ttsk = current;\n\t}\n\n\tif (threadgroup)\n\t\ttsk = tsk->group_leader;\n\n\t/*\n\t * kthreads may acquire PF_NO_SETAFFINITY during initialization.\n\t * If userland migrates such a kthread to a non-root cgroup, it can\n\t * become trapped in a cpuset, or RT kthread may be born in a\n\t * cgroup with no rt_runtime allocated.  Just say no.\n\t */\n\tif (tsk->no_cgroup_migration || (tsk->flags & PF_NO_SETAFFINITY)) {\n\t\ttsk = ERR_PTR(-EINVAL);\n\t\tgoto out_unlock_threadgroup;\n\t}\n\n\tget_task_struct(tsk);\n\tgoto out_unlock_rcu;\n\nout_unlock_threadgroup:\n\tif (*locked) {\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\t\t*locked = false;\n\t}\nout_unlock_rcu:\n\trcu_read_unlock();\n\treturn tsk;\n}\n\nvoid cgroup_procs_write_finish(struct task_struct *task, bool locked)\n\t__releases(&cgroup_threadgroup_rwsem)\n{\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\t/* release reference from cgroup_procs_write_start() */\n\tput_task_struct(task);\n\n\tif (locked)\n\t\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tfor_each_subsys(ss, ssid)\n\t\tif (ss->post_attach)\n\t\t\tss->post_attach();\n}\n\nstatic void cgroup_print_ss_mask(struct seq_file *seq, u16 ss_mask)\n{\n\tstruct cgroup_subsys *ss;\n\tbool printed = false;\n\tint ssid;\n\n\tdo_each_subsys_mask(ss, ssid, ss_mask) {\n\t\tif (printed)\n\t\t\tseq_putc(seq, ' ');\n\t\tseq_puts(seq, ss->name);\n\t\tprinted = true;\n\t} while_each_subsys_mask();\n\tif (printed)\n\t\tseq_putc(seq, '\\n');\n}\n\n/* show controllers which are enabled from the parent */\nstatic int cgroup_controllers_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgroup_control(cgrp));\n\treturn 0;\n}\n\n/* show controllers which are enabled for a given cgroup's children */\nstatic int cgroup_subtree_control_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tcgroup_print_ss_mask(seq, cgrp->subtree_control);\n\treturn 0;\n}\n\n/**\n * cgroup_update_dfl_csses - update css assoc of a subtree in default hierarchy\n * @cgrp: root of the subtree to update csses for\n *\n * @cgrp's control masks have changed and its subtree's css associations\n * need to be updated accordingly.  This function looks up all css_sets\n * which are attached to the subtree, creates the matching updated css_sets\n * and migrates the tasks to the new ones.\n */\nstatic int cgroup_update_dfl_csses(struct cgroup *cgrp)\n{\n\tDEFINE_CGROUP_MGCTX(mgctx);\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup *dsct;\n\tstruct css_set *src_cset;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\n\t/* look up all csses currently attached to @cgrp's subtree */\n\tspin_lock_irq(&css_set_lock);\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tstruct cgrp_cset_link *link;\n\n\t\tlist_for_each_entry(link, &dsct->cset_links, cset_link)\n\t\t\tcgroup_migrate_add_src(link->cset, dsct, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\t/* NULL dst indicates self on default hierarchy */\n\tret = cgroup_migrate_prepare_dst(&mgctx);\n\tif (ret)\n\t\tgoto out_finish;\n\n\tspin_lock_irq(&css_set_lock);\n\tlist_for_each_entry(src_cset, &mgctx.preloaded_src_csets, mg_preload_node) {\n\t\tstruct task_struct *task, *ntask;\n\n\t\t/* all tasks in src_csets need to be migrated */\n\t\tlist_for_each_entry_safe(task, ntask, &src_cset->tasks, cg_list)\n\t\t\tcgroup_migrate_add_task(task, &mgctx);\n\t}\n\tspin_unlock_irq(&css_set_lock);\n\n\tret = cgroup_migrate_execute(&mgctx);\nout_finish:\n\tcgroup_migrate_finish(&mgctx);\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\treturn ret;\n}\n\n/**\n * cgroup_lock_and_drain_offline - lock cgroup_mutex and drain offlined csses\n * @cgrp: root of the target subtree\n *\n * Because css offlining is asynchronous, userland may try to re-enable a\n * controller while the previous css is still around.  This function grabs\n * cgroup_mutex and drains the previous css instances of @cgrp's subtree.\n */\nvoid cgroup_lock_and_drain_offline(struct cgroup *cgrp)\n\t__acquires(&cgroup_mutex)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\nrestart:\n\tmutex_lock(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\t\t\tDEFINE_WAIT(wait);\n\n\t\t\tif (!css || !percpu_ref_is_dying(&css->refcnt))\n\t\t\t\tcontinue;\n\n\t\t\tcgroup_get_live(dsct);\n\t\t\tprepare_to_wait(&dsct->offline_waitq, &wait,\n\t\t\t\t\tTASK_UNINTERRUPTIBLE);\n\n\t\t\tmutex_unlock(&cgroup_mutex);\n\t\t\tschedule();\n\t\t\tfinish_wait(&dsct->offline_waitq, &wait);\n\n\t\t\tcgroup_put(dsct);\n\t\t\tgoto restart;\n\t\t}\n\t}\n}\n\n/**\n * cgroup_save_control - save control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Save ->subtree_control, ->subtree_ss_mask and ->dom_cgrp to the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_save_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->old_subtree_control = dsct->subtree_control;\n\t\tdsct->old_subtree_ss_mask = dsct->subtree_ss_mask;\n\t\tdsct->old_dom_cgrp = dsct->dom_cgrp;\n\t}\n}\n\n/**\n * cgroup_propagate_control - refresh control masks of a subtree\n * @cgrp: root of the target subtree\n *\n * For @cgrp and its subtree, ensure ->subtree_ss_mask matches\n * ->subtree_control and propagate controller availability through the\n * subtree so that descendants don't have unavailable controllers enabled.\n */\nstatic void cgroup_propagate_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control &= cgroup_control(dsct);\n\t\tdsct->subtree_ss_mask =\n\t\t\tcgroup_calc_subtree_ss_mask(dsct->subtree_control,\n\t\t\t\t\t\t    cgroup_ss_mask(dsct));\n\t}\n}\n\n/**\n * cgroup_restore_control - restore control masks and dom_cgrp of a subtree\n * @cgrp: root of the target subtree\n *\n * Restore ->subtree_control, ->subtree_ss_mask and ->dom_cgrp from the\n * respective old_ prefixed fields for @cgrp's subtree including @cgrp\n * itself.\n */\nstatic void cgroup_restore_control(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tdsct->subtree_control = dsct->old_subtree_control;\n\t\tdsct->subtree_ss_mask = dsct->old_subtree_ss_mask;\n\t\tdsct->dom_cgrp = dsct->old_dom_cgrp;\n\t}\n}\n\nstatic bool css_visible(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys *ss = css->ss;\n\tstruct cgroup *cgrp = css->cgroup;\n\n\tif (cgroup_control(cgrp) & (1 << ss->id))\n\t\treturn true;\n\tif (!(cgroup_ss_mask(cgrp) & (1 << ss->id)))\n\t\treturn false;\n\treturn cgroup_on_dfl(cgrp) && ss->implicit_on_dfl;\n}\n\n/**\n * cgroup_apply_control_enable - enable or show csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and create new csses or make the existing ones\n * visible.  A css is created invisible if it's being implicitly enabled\n * through dependency.  An invisible css is made visible when the userland\n * explicitly enables it.\n *\n * Returns 0 on success, -errno on failure.  On failure, csses which have\n * been processed already aren't cleaned up.  The caller is responsible for\n * cleaning up with cgroup_apply_control_disable().\n */\nstatic int cgroup_apply_control_enable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid, ret;\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!(cgroup_ss_mask(dsct) & (1 << ss->id)))\n\t\t\t\tcontinue;\n\n\t\t\tif (!css) {\n\t\t\t\tcss = css_create(dsct, ss);\n\t\t\t\tif (IS_ERR(css))\n\t\t\t\t\treturn PTR_ERR(css);\n\t\t\t}\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css_visible(css)) {\n\t\t\t\tret = css_populate_dir(css);\n\t\t\t\tif (ret)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_apply_control_disable - kill or hide csses according to control\n * @cgrp: root of the target subtree\n *\n * Walk @cgrp's subtree and kill and hide csses so that they match\n * cgroup_ss_mask() and cgroup_visible_mask().\n *\n * A css is hidden when the userland requests it to be disabled while other\n * subsystems are still depending on it.  The css must not actively control\n * resources and be in the vanilla state if it's made visible again later.\n * Controllers which may be depended upon should provide ->css_reset() for\n * this purpose.\n */\nstatic void cgroup_apply_control_disable(struct cgroup *cgrp)\n{\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tstruct cgroup_subsys *ss;\n\tint ssid;\n\n\tcgroup_for_each_live_descendant_post(dsct, d_css, cgrp) {\n\t\tfor_each_subsys(ss, ssid) {\n\t\t\tstruct cgroup_subsys_state *css = cgroup_css(dsct, ss);\n\n\t\t\tif (!css)\n\t\t\t\tcontinue;\n\n\t\t\tWARN_ON_ONCE(percpu_ref_is_dying(&css->refcnt));\n\n\t\t\tif (css->parent &&\n\t\t\t    !(cgroup_ss_mask(dsct) & (1 << ss->id))) {\n\t\t\t\tkill_css(css);\n\t\t\t} else if (!css_visible(css)) {\n\t\t\t\tcss_clear_dir(css);\n\t\t\t\tif (ss->css_reset)\n\t\t\t\t\tss->css_reset(css);\n\t\t\t}\n\t\t}\n\t}\n}\n\n/**\n * cgroup_apply_control - apply control mask updates to the subtree\n * @cgrp: root of the target subtree\n *\n * subsystems can be enabled and disabled in a subtree using the following\n * steps.\n *\n * 1. Call cgroup_save_control() to stash the current state.\n * 2. Update ->subtree_control masks in the subtree as desired.\n * 3. Call cgroup_apply_control() to apply the changes.\n * 4. Optionally perform other related operations.\n * 5. Call cgroup_finalize_control() to finish up.\n *\n * This function implements step 3 and propagates the mask changes\n * throughout @cgrp's subtree, updates csses accordingly and perform\n * process migrations.\n */\nstatic int cgroup_apply_control(struct cgroup *cgrp)\n{\n\tint ret;\n\n\tcgroup_propagate_control(cgrp);\n\n\tret = cgroup_apply_control_enable(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\t/*\n\t * At this point, cgroup_e_css_by_mask() results reflect the new csses\n\t * making the following cgroup_update_dfl_csses() properly update\n\t * css associations of all tasks in the subtree.\n\t */\n\tret = cgroup_update_dfl_csses(cgrp);\n\tif (ret)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/**\n * cgroup_finalize_control - finalize control mask update\n * @cgrp: root of the target subtree\n * @ret: the result of the update\n *\n * Finalize control mask update.  See cgroup_apply_control() for more info.\n */\nstatic void cgroup_finalize_control(struct cgroup *cgrp, int ret)\n{\n\tif (ret) {\n\t\tcgroup_restore_control(cgrp);\n\t\tcgroup_propagate_control(cgrp);\n\t}\n\n\tcgroup_apply_control_disable(cgrp);\n}\n\nstatic int cgroup_vet_subtree_control_enable(struct cgroup *cgrp, u16 enable)\n{\n\tu16 domain_enable = enable & ~cgrp_dfl_threaded_ss_mask;\n\n\t/* if nothing is getting enabled, nothing to worry about */\n\tif (!enable)\n\t\treturn 0;\n\n\t/* can @cgrp host any resources? */\n\tif (!cgroup_is_valid_domain(cgrp->dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/* mixables don't care */\n\tif (cgroup_is_mixable(cgrp))\n\t\treturn 0;\n\n\tif (domain_enable) {\n\t\t/* can't enable domain controllers inside a thread subtree */\n\t\tif (cgroup_is_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn -EOPNOTSUPP;\n\t} else {\n\t\t/*\n\t\t * Threaded controllers can handle internal competitions\n\t\t * and are always allowed inside a (prospective) thread\n\t\t * subtree.\n\t\t */\n\t\tif (cgroup_can_be_thread_root(cgrp) || cgroup_is_threaded(cgrp))\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * Controllers can't be enabled for a cgroup with tasks to avoid\n\t * child cgroups competing against tasks.\n\t */\n\tif (cgroup_has_tasks(cgrp))\n\t\treturn -EBUSY;\n\n\treturn 0;\n}\n\n/* change the enabled child controllers for a cgroup in the default hierarchy */\nstatic ssize_t cgroup_subtree_control_write(struct kernfs_open_file *of,\n\t\t\t\t\t    char *buf, size_t nbytes,\n\t\t\t\t\t    loff_t off)\n{\n\tu16 enable = 0, disable = 0;\n\tstruct cgroup *cgrp, *child;\n\tstruct cgroup_subsys *ss;\n\tchar *tok;\n\tint ssid, ret;\n\n\t/*\n\t * Parse input - space separated list of subsystem names prefixed\n\t * with either + or -.\n\t */\n\tbuf = strstrip(buf);\n\twhile ((tok = strsep(&buf, \" \"))) {\n\t\tif (tok[0] == '\\0')\n\t\t\tcontinue;\n\t\tdo_each_subsys_mask(ss, ssid, ~cgrp_dfl_inhibit_ss_mask) {\n\t\t\tif (!cgroup_ssid_enabled(ssid) ||\n\t\t\t    strcmp(tok + 1, ss->name))\n\t\t\t\tcontinue;\n\n\t\t\tif (*tok == '+') {\n\t\t\t\tenable |= 1 << ssid;\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t} else if (*tok == '-') {\n\t\t\t\tdisable |= 1 << ssid;\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t} else {\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tbreak;\n\t\t} while_each_subsys_mask();\n\t\tif (ssid == CGROUP_SUBSYS_COUNT)\n\t\t\treturn -EINVAL;\n\t}\n\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tfor_each_subsys(ss, ssid) {\n\t\tif (enable & (1 << ssid)) {\n\t\t\tif (cgrp->subtree_control & (1 << ssid)) {\n\t\t\t\tenable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (!(cgroup_control(cgrp) & (1 << ssid))) {\n\t\t\t\tret = -ENOENT;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t} else if (disable & (1 << ssid)) {\n\t\t\tif (!(cgrp->subtree_control & (1 << ssid))) {\n\t\t\t\tdisable &= ~(1 << ssid);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t/* a child has it enabled? */\n\t\t\tcgroup_for_each_live_child(child, cgrp) {\n\t\t\t\tif (child->subtree_control & (1 << ssid)) {\n\t\t\t\t\tret = -EBUSY;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!enable && !disable) {\n\t\tret = 0;\n\t\tgoto out_unlock;\n\t}\n\n\tret = cgroup_vet_subtree_control_enable(cgrp, enable);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\t/* save and update control masks and prepare csses */\n\tcgroup_save_control(cgrp);\n\n\tcgrp->subtree_control |= enable;\n\tcgrp->subtree_control &= ~disable;\n\n\tret = cgroup_apply_control(cgrp);\n\tcgroup_finalize_control(cgrp, ret);\n\tif (ret)\n\t\tgoto out_unlock;\n\n\tkernfs_activate(cgrp->kn);\nout_unlock:\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\n/**\n * cgroup_enable_threaded - make @cgrp threaded\n * @cgrp: the target cgroup\n *\n * Called when \"threaded\" is written to the cgroup.type interface file and\n * tries to make @cgrp threaded and join the parent's resource domain.\n * This function is never called on the root cgroup as cgroup.type doesn't\n * exist on it.\n */\nstatic int cgroup_enable_threaded(struct cgroup *cgrp)\n{\n\tstruct cgroup *parent = cgroup_parent(cgrp);\n\tstruct cgroup *dom_cgrp = parent->dom_cgrp;\n\tstruct cgroup *dsct;\n\tstruct cgroup_subsys_state *d_css;\n\tint ret;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* noop if already threaded */\n\tif (cgroup_is_threaded(cgrp))\n\t\treturn 0;\n\n\t/*\n\t * If @cgroup is populated or has domain controllers enabled, it\n\t * can't be switched.  While the below cgroup_can_be_thread_root()\n\t * test can catch the same conditions, that's only when @parent is\n\t * not mixable, so let's check it explicitly.\n\t */\n\tif (cgroup_is_populated(cgrp) ||\n\t    cgrp->subtree_control & ~cgrp_dfl_threaded_ss_mask)\n\t\treturn -EOPNOTSUPP;\n\n\t/* we're joining the parent's domain, ensure its validity */\n\tif (!cgroup_is_valid_domain(dom_cgrp) ||\n\t    !cgroup_can_be_thread_root(dom_cgrp))\n\t\treturn -EOPNOTSUPP;\n\n\t/*\n\t * The following shouldn't cause actual migrations and should\n\t * always succeed.\n\t */\n\tcgroup_save_control(cgrp);\n\n\tcgroup_for_each_live_descendant_pre(dsct, d_css, cgrp)\n\t\tif (dsct == cgrp || cgroup_is_threaded(dsct))\n\t\t\tdsct->dom_cgrp = dom_cgrp;\n\n\tret = cgroup_apply_control(cgrp);\n\tif (!ret)\n\t\tparent->nr_threaded_children++;\n\n\tcgroup_finalize_control(cgrp, ret);\n\treturn ret;\n}\n\nstatic int cgroup_type_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tif (cgroup_is_threaded(cgrp))\n\t\tseq_puts(seq, \"threaded\\n\");\n\telse if (!cgroup_is_valid_domain(cgrp))\n\t\tseq_puts(seq, \"domain invalid\\n\");\n\telse if (cgroup_is_thread_root(cgrp))\n\t\tseq_puts(seq, \"domain threaded\\n\");\n\telse\n\t\tseq_puts(seq, \"domain\\n\");\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_type_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint ret;\n\n\t/* only switching to threaded mode is supported */\n\tif (strcmp(strstrip(buf), \"threaded\"))\n\t\treturn -EINVAL;\n\n\t/* drain dying csses before we re-apply (threaded) subtree control */\n\tcgrp = cgroup_kn_lock_live(of->kn, true);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/* threaded can only be enabled */\n\tret = cgroup_enable_threaded(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_max_descendants_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint descendants = READ_ONCE(cgrp->max_descendants);\n\n\tif (descendants == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", descendants);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_descendants_write(struct kernfs_open_file *of,\n\t\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tint descendants;\n\tssize_t ret;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdescendants = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &descendants);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (descendants < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_descendants = descendants;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_max_depth_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tint depth = READ_ONCE(cgrp->max_depth);\n\n\tif (depth == INT_MAX)\n\t\tseq_puts(seq, \"max\\n\");\n\telse\n\t\tseq_printf(seq, \"%d\\n\", depth);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_max_depth_write(struct kernfs_open_file *of,\n\t\t\t\t      char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint depth;\n\n\tbuf = strstrip(buf);\n\tif (!strcmp(buf, \"max\")) {\n\t\tdepth = INT_MAX;\n\t} else {\n\t\tret = kstrtoint(buf, 0, &depth);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\tif (depth < 0)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgrp->max_depth = depth;\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic int cgroup_events_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"populated %d\\n\", cgroup_is_populated(cgrp));\n\tseq_printf(seq, \"frozen %d\\n\", test_bit(CGRP_FROZEN, &cgrp->flags));\n\n\treturn 0;\n}\n\nstatic int cgroup_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgroup = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"nr_descendants %d\\n\",\n\t\t   cgroup->nr_descendants);\n\tseq_printf(seq, \"nr_dying_descendants %d\\n\",\n\t\t   cgroup->nr_dying_descendants);\n\n\treturn 0;\n}\n\nstatic int __maybe_unused cgroup_extra_stat_show(struct seq_file *seq,\n\t\t\t\t\t\t struct cgroup *cgrp, int ssid)\n{\n\tstruct cgroup_subsys *ss = cgroup_subsys[ssid];\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!ss->css_extra_stat_show)\n\t\treturn 0;\n\n\tcss = cgroup_tryget_css(cgrp, ss);\n\tif (!css)\n\t\treturn 0;\n\n\tret = ss->css_extra_stat_show(seq, css);\n\tcss_put(css);\n\treturn ret;\n}\n\nstatic int cpu_stat_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup __maybe_unused *cgrp = seq_css(seq)->cgroup;\n\tint ret = 0;\n\n\tcgroup_base_stat_cputime_show(seq);\n#ifdef CONFIG_CGROUP_SCHED\n\tret = cgroup_extra_stat_show(seq, cgrp, cpu_cgrp_id);\n#endif\n\treturn ret;\n}\n\n#ifdef CONFIG_PSI\nstatic int cgroup_io_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_IO);\n}\nstatic int cgroup_memory_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_MEM);\n}\nstatic int cgroup_cpu_pressure_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\tstruct psi_group *psi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\n\treturn psi_show(seq, psi, PSI_CPU);\n}\n\nstatic ssize_t cgroup_pressure_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t\t  size_t nbytes, enum psi_res res)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct psi_trigger *new;\n\tstruct cgroup *cgrp;\n\tstruct psi_group *psi;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENODEV;\n\n\tcgroup_get(cgrp);\n\tcgroup_kn_unlock(of->kn);\n\n\tpsi = cgroup_ino(cgrp) == 1 ? &psi_system : &cgrp->psi;\n\tnew = psi_trigger_create(psi, buf, nbytes, res);\n\tif (IS_ERR(new)) {\n\t\tcgroup_put(cgrp);\n\t\treturn PTR_ERR(new);\n\t}\n\n\tpsi_trigger_replace(&ctx->psi.trigger, new);\n\n\tcgroup_put(cgrp);\n\n\treturn nbytes;\n}\n\nstatic ssize_t cgroup_io_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_IO);\n}\n\nstatic ssize_t cgroup_memory_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_MEM);\n}\n\nstatic ssize_t cgroup_cpu_pressure_write(struct kernfs_open_file *of,\n\t\t\t\t\t  char *buf, size_t nbytes,\n\t\t\t\t\t  loff_t off)\n{\n\treturn cgroup_pressure_write(of, buf, nbytes, PSI_CPU);\n}\n\nstatic __poll_t cgroup_pressure_poll(struct kernfs_open_file *of,\n\t\t\t\t\t  poll_table *pt)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\treturn psi_trigger_poll(&ctx->psi.trigger, of->file, pt);\n}\n\nstatic void cgroup_pressure_release(struct kernfs_open_file *of)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tpsi_trigger_replace(&ctx->psi.trigger, NULL);\n}\n\nbool cgroup_psi_enabled(void)\n{\n\treturn (cgroup_feature_disable_mask & (1 << OPT_FEATURE_PRESSURE)) == 0;\n}\n\n#else /* CONFIG_PSI */\nbool cgroup_psi_enabled(void)\n{\n\treturn false;\n}\n\n#endif /* CONFIG_PSI */\n\nstatic int cgroup_freeze_show(struct seq_file *seq, void *v)\n{\n\tstruct cgroup *cgrp = seq_css(seq)->cgroup;\n\n\tseq_printf(seq, \"%d\\n\", cgrp->freezer.freeze);\n\n\treturn 0;\n}\n\nstatic ssize_t cgroup_freeze_write(struct kernfs_open_file *of,\n\t\t\t\t   char *buf, size_t nbytes, loff_t off)\n{\n\tstruct cgroup *cgrp;\n\tssize_t ret;\n\tint freeze;\n\n\tret = kstrtoint(strstrip(buf), 0, &freeze);\n\tif (ret)\n\t\treturn ret;\n\n\tif (freeze < 0 || freeze > 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\tcgroup_freeze(cgrp, freeze);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn nbytes;\n}\n\nstatic void __cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct css_task_iter it;\n\tstruct task_struct *task;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tspin_lock_irq(&css_set_lock);\n\tset_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n\n\tcss_task_iter_start(&cgrp->self, CSS_TASK_ITER_PROCS | CSS_TASK_ITER_THREADED, &it);\n\twhile ((task = css_task_iter_next(&it))) {\n\t\t/* Ignore kernel threads here. */\n\t\tif (task->flags & PF_KTHREAD)\n\t\t\tcontinue;\n\n\t\t/* Skip tasks that are already dying. */\n\t\tif (__fatal_signal_pending(task))\n\t\t\tcontinue;\n\n\t\tsend_sig(SIGKILL, task, 0);\n\t}\n\tcss_task_iter_end(&it);\n\n\tspin_lock_irq(&css_set_lock);\n\tclear_bit(CGRP_KILL, &cgrp->flags);\n\tspin_unlock_irq(&css_set_lock);\n}\n\nstatic void cgroup_kill(struct cgroup *cgrp)\n{\n\tstruct cgroup_subsys_state *css;\n\tstruct cgroup *dsct;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tcgroup_for_each_live_descendant_pre(dsct, css, cgrp)\n\t\t__cgroup_kill(dsct);\n}\n\nstatic ssize_t cgroup_kill_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tssize_t ret = 0;\n\tint kill;\n\tstruct cgroup *cgrp;\n\n\tret = kstrtoint(strstrip(buf), 0, &kill);\n\tif (ret)\n\t\treturn ret;\n\n\tif (kill != 1)\n\t\treturn -ERANGE;\n\n\tcgrp = cgroup_kn_lock_live(of->kn, false);\n\tif (!cgrp)\n\t\treturn -ENOENT;\n\n\t/*\n\t * Killing is a process directed operation, i.e. the whole thread-group\n\t * is taken down so act like we do for cgroup.procs and only make this\n\t * writable in non-threaded cgroups.\n\t */\n\tif (cgroup_is_threaded(cgrp))\n\t\tret = -EOPNOTSUPP;\n\telse\n\t\tcgroup_kill(cgrp);\n\n\tcgroup_kn_unlock(of->kn);\n\n\treturn ret ?: nbytes;\n}\n\nstatic int cgroup_file_open(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx;\n\tint ret;\n\n\tctx = kzalloc(sizeof(*ctx), GFP_KERNEL);\n\tif (!ctx)\n\t\treturn -ENOMEM;\n\n\tctx->ns = current->nsproxy->cgroup_ns;\n\tget_cgroup_ns(ctx->ns);\n\tof->priv = ctx;\n\n\tif (!cft->open)\n\t\treturn 0;\n\n\tret = cft->open(of);\n\tif (ret) {\n\t\tput_cgroup_ns(ctx->ns);\n\t\tkfree(ctx);\n\t}\n\treturn ret;\n}\n\nstatic void cgroup_file_release(struct kernfs_open_file *of)\n{\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\n\tif (cft->release)\n\t\tcft->release(of);\n\tput_cgroup_ns(ctx->ns);\n\tkfree(ctx);\n}\n\nstatic ssize_t cgroup_file_write(struct kernfs_open_file *of, char *buf,\n\t\t\t\t size_t nbytes, loff_t off)\n{\n\tstruct cgroup_file_ctx *ctx = of->priv;\n\tstruct cgroup *cgrp = of->kn->parent->priv;\n\tstruct cftype *cft = of_cft(of);\n\tstruct cgroup_subsys_state *css;\n\tint ret;\n\n\tif (!nbytes)\n\t\treturn 0;\n\n\t/*\n\t * If namespaces are delegation boundaries, disallow writes to\n\t * files in an non-init namespace root from inside the namespace\n\t * except for the files explicitly marked delegatable -\n\t * cgroup.procs and cgroup.subtree_control.\n\t */\n\tif ((cgrp->root->flags & CGRP_ROOT_NS_DELEGATE) &&\n\t    !(cft->flags & CFTYPE_NS_DELEGATABLE) &&\n\t    ctx->ns != &init_cgroup_ns && ctx->ns->root_cset->dfl_cgrp == cgrp)\n\t\treturn -EPERM;\n\n\tif (cft->write)\n\t\treturn cft->write(of, buf, nbytes, off);\n\n\t/*\n\t * kernfs guarantees that a file isn't deleted with operations in\n\t * flight, which means that the matching css is and stays alive and\n\t * doesn't need to be pinned.  The RCU locking is not necessary\n\t * either.  It's just for the convenience of using cgroup_css().\n\t */\n\trcu_read_lock();\n\tcss = cgroup_css(cgrp, cft->ss);\n\trcu_read_unlock();\n\n\tif (cft->write_u64) {\n\t\tunsigned long long v;\n\t\tret = kstrtoull(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_u64(css, cft, v);\n\t} else if (cft->write_s64) {\n\t\tlong long v;\n\t\tret = kstrtoll(buf, 0, &v);\n\t\tif (!ret)\n\t\t\tret = cft->write_s64(css, cft, v);\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret ?: nbytes;\n}\n\nstatic __poll_t cgroup_file_poll(struct kernfs_open_file *of, poll_table *pt)\n{\n\tstruct cftype *cft = of_cft(of);\n\n\tif (cft->poll)\n\t\treturn cft->poll(of, pt);\n\n\treturn kernfs_generic_poll(of, pt);\n}\n\nstatic void *cgroup_seqfile_start(struct seq_file *seq, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_start(seq, ppos);\n}\n\nstatic void *cgroup_seqfile_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn seq_cft(seq)->seq_next(seq, v, ppos);\n}\n\nstatic void cgroup_seqfile_stop(struct seq_file *seq, void *v)\n{\n\tif (seq_cft(seq)->seq_stop)\n\t\tseq_cft(seq)->seq_stop(seq, v);\n}\n\nstatic int cgroup_seqfile_show(struct seq_file *m, void *arg)\n{\n\tstruct cftype *cft = seq_cft(m);\n\tstruct cgroup_subsys_state *css = seq_css(m);\n\n\tif (cft->seq_show)\n\t\treturn cft->seq_show(m, arg);\n\n\tif (cft->read_u64)\n\t\tseq_printf(m, \"%llu\\n\", cft->read_u64(css, cft));\n\telse if (cft->read_s64)\n\t\tseq_printf(m, \"%lld\\n\", cft->read_s64(css, cft));\n\telse\n\t\treturn -EINVAL;\n\treturn 0;\n}\n\nstatic struct kernfs_ops cgroup_kf_single_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\nstatic struct kernfs_ops cgroup_kf_ops = {\n\t.atomic_write_len\t= PAGE_SIZE,\n\t.open\t\t\t= cgroup_file_open,\n\t.release\t\t= cgroup_file_release,\n\t.write\t\t\t= cgroup_file_write,\n\t.poll\t\t\t= cgroup_file_poll,\n\t.seq_start\t\t= cgroup_seqfile_start,\n\t.seq_next\t\t= cgroup_seqfile_next,\n\t.seq_stop\t\t= cgroup_seqfile_stop,\n\t.seq_show\t\t= cgroup_seqfile_show,\n};\n\n/* set uid and gid of cgroup dirs and files to that of the creator */\nstatic int cgroup_kn_set_ugid(struct kernfs_node *kn)\n{\n\tstruct iattr iattr = { .ia_valid = ATTR_UID | ATTR_GID,\n\t\t\t       .ia_uid = current_fsuid(),\n\t\t\t       .ia_gid = current_fsgid(), };\n\n\tif (uid_eq(iattr.ia_uid, GLOBAL_ROOT_UID) &&\n\t    gid_eq(iattr.ia_gid, GLOBAL_ROOT_GID))\n\t\treturn 0;\n\n\treturn kernfs_setattr(kn, &iattr);\n}\n\nstatic void cgroup_file_notify_timer(struct timer_list *timer)\n{\n\tcgroup_file_notify(container_of(timer, struct cgroup_file,\n\t\t\t\t\tnotify_timer));\n}\n\nstatic int cgroup_add_file(struct cgroup_subsys_state *css, struct cgroup *cgrp,\n\t\t\t   struct cftype *cft)\n{\n\tchar name[CGROUP_FILE_NAME_MAX];\n\tstruct kernfs_node *kn;\n\tstruct lock_class_key *key = NULL;\n\tint ret;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tkey = &cft->lockdep_key;\n#endif\n\tkn = __kernfs_create_file(cgrp->kn, cgroup_file_name(cgrp, cft, name),\n\t\t\t\t  cgroup_file_mode(cft),\n\t\t\t\t  GLOBAL_ROOT_UID, GLOBAL_ROOT_GID,\n\t\t\t\t  0, cft->kf_ops, cft,\n\t\t\t\t  NULL, key);\n\tif (IS_ERR(kn))\n\t\treturn PTR_ERR(kn);\n\n\tret = cgroup_kn_set_ugid(kn);\n\tif (ret) {\n\t\tkernfs_remove(kn);\n\t\treturn ret;\n\t}\n\n\tif (cft->file_offset) {\n\t\tstruct cgroup_file *cfile = (void *)css + cft->file_offset;\n\n\t\ttimer_setup(&cfile->notify_timer, cgroup_file_notify_timer, 0);\n\n\t\tspin_lock_irq(&cgroup_file_kn_lock);\n\t\tcfile->kn = kn;\n\t\tspin_unlock_irq(&cgroup_file_kn_lock);\n\t}\n\n\treturn 0;\n}\n\n/**\n * cgroup_addrm_files - add or remove files to a cgroup directory\n * @css: the target css\n * @cgrp: the target cgroup (usually css->cgroup)\n * @cfts: array of cftypes to be added\n * @is_add: whether to add or remove\n *\n * Depending on @is_add, add or remove files defined by @cfts on @cgrp.\n * For removals, this function never fails.\n */\nstatic int cgroup_addrm_files(struct cgroup_subsys_state *css,\n\t\t\t      struct cgroup *cgrp, struct cftype cfts[],\n\t\t\t      bool is_add)\n{\n\tstruct cftype *cft, *cft_end = NULL;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\nrestart:\n\tfor (cft = cfts; cft != cft_end && cft->name[0] != '\\0'; cft++) {\n\t\t/* does cft->flags tell us to skip this file on @cgrp? */\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_ONLY_ON_DFL) && !cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & __CFTYPE_NOT_ON_DFL) && cgroup_on_dfl(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_NOT_ON_ROOT) && !cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_ONLY_ON_ROOT) && cgroup_parent(cgrp))\n\t\t\tcontinue;\n\t\tif ((cft->flags & CFTYPE_DEBUG) && !cgroup_debug)\n\t\t\tcontinue;\n\t\tif (is_add) {\n\t\t\tret = cgroup_add_file(css, cgrp, cft);\n\t\t\tif (ret) {\n\t\t\t\tpr_warn(\"%s: failed to add %s, err=%d\\n\",\n\t\t\t\t\t__func__, cft->name, ret);\n\t\t\t\tcft_end = cft;\n\t\t\t\tis_add = false;\n\t\t\t\tgoto restart;\n\t\t\t}\n\t\t} else {\n\t\t\tcgroup_rm_file(cgrp, cft);\n\t\t}\n\t}\n\treturn ret;\n}\n\nstatic int cgroup_apply_cftypes(struct cftype *cfts, bool is_add)\n{\n\tstruct cgroup_subsys *ss = cfts[0].ss;\n\tstruct cgroup *root = &ss->root->cgrp;\n\tstruct cgroup_subsys_state *css;\n\tint ret = 0;\n\n\tlockdep_assert_held(&cgroup_mutex);\n\n\t/* add/rm files for all cgroups created before */\n\tcss_for_each_descendant_pre(css, cgroup_css(root, ss)) {\n\t\tstruct cgroup *cgrp = css->cgroup;\n\n\t\tif (!(css->flags & CSS_VISIBLE))\n\t\t\tcontinue;\n\n\t\tret = cgroup_addrm_files(css, cgrp, cfts, is_add);\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\tif (is_add && !ret)\n\t\tkernfs_activate(root->kn);\n\treturn ret;\n}\n\nstatic void cgroup_exit_cftypes(struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\t/* free copy for custom atomic_write_len, see init_cftypes() */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE)\n\t\t\tkfree(cft->kf_ops);\n\t\tcft->kf_ops = NULL;\n\t\tcft->ss = NULL;\n\n\t\t/* revert flags set by cgroup core while adding @cfts */\n\t\tcft->flags &= ~(__CFTYPE_ONLY_ON_DFL | __CFTYPE_NOT_ON_DFL);\n\t}\n}\n\nstatic int cgroup_init_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft->name[0] != '\\0'; cft++) {\n\t\tstruct kernfs_ops *kf_ops;\n\n\t\tWARN_ON(cft->ss || cft->kf_ops);\n\n\t\tif ((cft->flags & CFTYPE_PRESSURE) && !cgroup_psi_enabled())\n\t\t\tcontinue;\n\n\t\tif (cft->seq_start)\n\t\t\tkf_ops = &cgroup_kf_ops;\n\t\telse\n\t\t\tkf_ops = &cgroup_kf_single_ops;\n\n\t\t/*\n\t\t * Ugh... if @cft wants a custom max_write_len, we need to\n\t\t * make a copy of kf_ops to set its atomic_write_len.\n\t\t */\n\t\tif (cft->max_write_len && cft->max_write_len != PAGE_SIZE) {\n\t\t\tkf_ops = kmemdup(kf_ops, sizeof(*kf_ops), GFP_KERNEL);\n\t\t\tif (!kf_ops) {\n\t\t\t\tcgroup_exit_cftypes(cfts);\n\t\t\t\treturn -ENOMEM;\n\t\t\t}\n\t\t\tkf_ops->atomic_write_len = cft->max_write_len;\n\t\t}\n\n\t\tcft->kf_ops = kf_ops;\n\t\tcft->ss = ss;\n\t}\n\n\treturn 0;\n}\n\nstatic int cgroup_rm_cftypes_locked(struct cftype *cfts)\n{\n\tlockdep_assert_held(&cgroup_mutex);\n\n\tif (!cfts || !cfts[0].ss)\n\t\treturn -ENOENT;\n\n\tlist_del(&cfts->node);\n\tcgroup_apply_cftypes(cfts, false);\n\tcgroup_exit_cftypes(cfts);\n\treturn 0;\n}\n\n/**\n * cgroup_rm_cftypes - remove an array of cftypes from a subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Unregister @cfts.  Files described by @cfts are removed from all\n * existing cgroups and all future cgroups won't have them either.  This\n * function can be called anytime whether @cfts' subsys is attached or not.\n *\n * Returns 0 on successful unregistration, -ENOENT if @cfts is not\n * registered.\n */\nint cgroup_rm_cftypes(struct cftype *cfts)\n{\n\tint ret;\n\n\tmutex_lock(&cgroup_mutex);\n\tret = cgroup_rm_cftypes_locked(cfts);\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_cftypes - add an array of cftypes to a subsystem\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Register @cfts to @ss.  Files described by @cfts are created for all\n * existing cgroups to which @ss is attached and all future cgroups will\n * have them too.  This function can be called anytime whether @ss is\n * attached or not.\n *\n * Returns 0 on successful registration, -errno on failure.  Note that this\n * function currently returns 0 as long as @cfts registration is successful\n * even if some file creation attempts on existing cgroups fail.\n */\nstatic int cgroup_add_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tint ret;\n\n\tif (!cgroup_ssid_enabled(ss->id))\n\t\treturn 0;\n\n\tif (!cfts || cfts[0].name[0] == '\\0')\n\t\treturn 0;\n\n\tret = cgroup_init_cftypes(ss, cfts);\n\tif (ret)\n\t\treturn ret;\n\n\tmutex_lock(&cgroup_mutex);\n\n\tlist_add_tail(&cfts->node, &ss->cfts);\n\tret = cgroup_apply_cftypes(cfts, true);\n\tif (ret)\n\t\tcgroup_rm_cftypes_locked(cfts);\n\n\tmutex_unlock(&cgroup_mutex);\n\treturn ret;\n}\n\n/**\n * cgroup_add_dfl_cftypes - add an array of cftypes for default hierarchy\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the default hierarchy.\n */\nint cgroup_add_dfl_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_ONLY_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_add_legacy_cftypes - add an array of cftypes for legacy hierarchies\n * @ss: target cgroup subsystem\n * @cfts: zero-length name terminated array of cftypes\n *\n * Similar to cgroup_add_cftypes() but the added files are only used for\n * the legacy hierarchies.\n */\nint cgroup_add_legacy_cftypes(struct cgroup_subsys *ss, struct cftype *cfts)\n{\n\tstruct cftype *cft;\n\n\tfor (cft = cfts; cft && cft->name[0] != '\\0'; cft++)\n\t\tcft->flags |= __CFTYPE_NOT_ON_DFL;\n\treturn cgroup_add_cftypes(ss, cfts);\n}\n\n/**\n * cgroup_file_notify - generate a file modified event for a cgroup_file\n * @cfile: target cgroup_file\n *\n * @cfile must have been obtained by setting cftype->file_offset.\n */\nvoid cgroup_file_notify(struct cgroup_file *cfile)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&cgroup_file_kn_lock, flags);\n\tif (cfile->kn) {\n\t\tunsigned long last = cfile->notified_at;\n\t\tunsigned long next = last + CGROUP_FILE_NOTIFY_MIN_INTV;\n\n\t\tif (time_in_range(jiffies, last, next)) {\n\t\t\ttimer_reduce(&cfile->notify_timer, next);\n\t\t} else {\n\t\t\tkernfs_notify(cfile->kn);\n\t\t\tcfile->notified_at = jiffies;\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&cgroup_file_kn_lock, flags);\n}\n\n/**\n * css_next_child - find the next child of a given css\n * @pos: the current position (%NULL to initiate traversal)\n * @parent: css whose children to walk\n *\n * This function returns the next child of @parent and should be called\n * under either cgroup_mutex or RCU read lock.  The only requirement is\n * that @parent and @pos are accessible.  The next sibling is guaranteed to\n * be returned regardless of their states.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *css_next_child(struct cgroup_subsys_state *pos,\n\t\t\t\t\t   struct cgroup_subsys_state *parent)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/*\n\t * @pos could already have been unlinked from the sibling list.\n\t * Once a cgroup is removed, its ->sibling.next is no longer\n\t * updated when its next sibling changes.  CSS_RELEASED is set when\n\t * @pos is taken off list, at which time its next pointer is valid,\n\t * and, as releases are serialized, the one pointed to by the next\n\t * pointer is guaranteed to not have started release yet.  This\n\t * implies that if we observe !CSS_RELEASED on @pos in this RCU\n\t * critical section, the one pointed to by its next pointer is\n\t * guaranteed to not have finished its RCU grace period even if we\n\t * have dropped rcu_read_lock() in-between iterations.\n\t *\n\t * If @pos has CSS_RELEASED set, its next pointer can't be\n\t * dereferenced; however, as each css is given a monotonically\n\t * increasing unique serial number and always appended to the\n\t * sibling list, the next one can be found by walking the parent's\n\t * children until the first css with higher serial number than\n\t * @pos's.  While this path can be slower, it happens iff iteration\n\t * races against release and the race window is very small.\n\t */\n\tif (!pos) {\n\t\tnext = list_entry_rcu(parent->children.next, struct cgroup_subsys_state, sibling);\n\t} else if (likely(!(pos->flags & CSS_RELEASED))) {\n\t\tnext = list_entry_rcu(pos->sibling.next, struct cgroup_subsys_state, sibling);\n\t} else {\n\t\tlist_for_each_entry_rcu(next, &parent->children, sibling,\n\t\t\t\t\tlockdep_is_held(&cgroup_mutex))\n\t\t\tif (next->serial_nr > pos->serial_nr)\n\t\t\t\tbreak;\n\t}\n\n\t/*\n\t * @next, if not pointing to the head, can be dereferenced and is\n\t * the next sibling.\n\t */\n\tif (&next->sibling != &parent->children)\n\t\treturn next;\n\treturn NULL;\n}\n\n/**\n * css_next_descendant_pre - find the next descendant for pre-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_pre().  Find the next descendant\n * to visit for pre-order traversal of @root's descendants.  @root is\n * included in the iteration and the first node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @root are accessible and @pos is a descendant of @root.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_pre(struct cgroup_subsys_state *pos,\n\t\t\tstruct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit @root */\n\tif (!pos)\n\t\treturn root;\n\n\t/* visit the first child if exists */\n\tnext = css_next_child(NULL, pos);\n\tif (next)\n\t\treturn next;\n\n\t/* no child, visit my or the closest ancestor's next sibling */\n\twhile (pos != root) {\n\t\tnext = css_next_child(pos, pos->parent);\n\t\tif (next)\n\t\t\treturn next;\n\t\tpos = pos->parent;\n\t}\n\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(css_next_descendant_pre);\n\n/**\n * css_rightmost_descendant - return the rightmost descendant of a css\n * @pos: css of interest\n *\n * Return the rightmost descendant of @pos.  If there's no descendant, @pos\n * is returned.  This can be used during pre-order traversal to skip\n * subtree of @pos.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct rightmost descendant as\n * long as @pos is accessible.\n */\nstruct cgroup_subsys_state *\ncss_rightmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last, *tmp;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\tdo {\n\t\tlast = pos;\n\t\t/* ->prev isn't RCU safe, walk ->next till the end */\n\t\tpos = NULL;\n\t\tcss_for_each_child(tmp, last)\n\t\t\tpos = tmp;\n\t} while (pos);\n\n\treturn last;\n}\n\nstatic struct cgroup_subsys_state *\ncss_leftmost_descendant(struct cgroup_subsys_state *pos)\n{\n\tstruct cgroup_subsys_state *last;\n\n\tdo {\n\t\tlast = pos;\n\t\tpos = css_next_child(NULL, pos);\n\t} while (pos);\n\n\treturn last;\n}\n\n/**\n * css_next_descendant_post - find the next descendant for post-order walk\n * @pos: the current position (%NULL to initiate traversal)\n * @root: css whose descendants to walk\n *\n * To be used by css_for_each_descendant_post().  Find the next descendant\n * to visit for post-order traversal of @root's descendants.  @root is\n * included in the iteration and the last node to be visited.\n *\n * While this function requires cgroup_mutex or RCU read locking, it\n * doesn't require the whole traversal to be contained in a single critical\n * section.  This function will return the correct next descendant as long\n * as both @pos and @cgroup are accessible and @pos is a descendant of\n * @cgroup.\n *\n * If a subsystem synchronizes ->css_online() and the start of iteration, a\n * css which finished ->css_online() is guaranteed to be visible in the\n * future iterations and will stay visible until the last reference is put.\n * A css which hasn't finished ->css_online() or already finished\n * ->css_offline() may show up during traversal.  It's each subsystem's\n * responsibility to synchronize against on/offlining.\n */\nstruct cgroup_subsys_state *\ncss_next_descendant_post(struct cgroup_subsys_state *pos,\n\t\t\t struct cgroup_subsys_state *root)\n{\n\tstruct cgroup_subsys_state *next;\n\n\tcgroup_assert_mutex_or_rcu_locked();\n\n\t/* if first iteration, visit leftmost descendant which may be @root */\n\tif (!pos)\n\t\treturn css_leftmost_descendant(root);\n\n\t/* if we visited @root, we're done */\n\tif (pos == root)\n\t\treturn NULL;\n\n\t/* if there's an unvisited sibling, visit its leftmost descendant */\n\tnext = css_next_child(pos, pos->parent);\n\tif (next)\n\t\treturn css_leftmost_descendant(next);\n\n\t/* no sibling left, visit parent */\n\treturn pos->parent;\n}\n\n/**\n * css_has_online_children - does a css have online children\n * @css: the target css\n *\n * Returns %true if @css has any online children; otherwise, %false.  This\n * function can be called from any context but the caller is responsible\n * for synchronizing against on/offlining as necessary.\n */\nbool css_has_online_children(struct cgroup_subsys_state *css)\n{\n\tstruct cgroup_subsys_state *child;\n\tbool ret = false;\n\n\trcu_read_lock();\n\tcss_for_each_child(child, css) {\n\t\tif (child->flags & CSS_ONLINE) {\n\t\t\tret = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\trcu_read_unlock();\n\treturn ret;\n}\n\nstatic struct css_set *css_task_iter_next_css_set(struct css_task_iter *it)\n{\n\tstruct list_head *l;\n\tstruct cgrp_cset_link *link;\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* find the next threaded cset */\n\tif (it->tcset_pos) {\n\t\tl = it->tcset_pos->next;\n\n\t\tif (l != it->tcset_head) {\n\t\t\tit->tcset_pos = l;\n\t\t\treturn container_of(l, struct css_set,\n\t\t\t\t\t    threaded_csets_node);\n\t\t}\n\n\t\tit->tcset_pos = NULL;\n\t}\n\n\t/* find the next cset */\n\tl = it->cset_pos;\n\tl = l->next;\n\tif (l == it->cset_head) {\n\t\tit->cset_pos = NULL;\n\t\treturn NULL;\n\t}\n\n\tif (it->ss) {\n\t\tcset = container_of(l, struct css_set, e_cset_node[it->ss->id]);\n\t} else {\n\t\tlink = list_entry(l, struct cgrp_cset_link, cset_link);\n\t\tcset = link->cset;\n\t}\n\n\tit->cset_pos = l;\n\n\t/* initialize threaded css_set walking */\n\tif (it->flags & CSS_TASK_ITER_THREADED) {\n\t\tif (it->cur_dcset)\n\t\t\tput_css_set_locked(it->cur_dcset);\n\t\tit->cur_dcset = cset;\n\t\tget_css_set(cset);\n\n\t\tit->tcset_head = &cset->threaded_csets;\n\t\tit->tcset_pos = &cset->threaded_csets;\n\t}\n\n\treturn cset;\n}\n\n/**\n * css_task_iter_advance_css_set - advance a task iterator to the next css_set\n * @it: the iterator to advance\n *\n * Advance @it to the next css_set to walk.\n */\nstatic void css_task_iter_advance_css_set(struct css_task_iter *it)\n{\n\tstruct css_set *cset;\n\n\tlockdep_assert_held(&css_set_lock);\n\n\t/* Advance to the next non-empty css_set and find first non-empty tasks list*/\n\twhile ((cset = css_task_iter_next_css_set(it))) {\n\t\tif (!list_empty(&cset->tasks)) {\n\t\t\tit->cur_tasks_head = &cset->tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->mg_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->mg_tasks;\n\t\t\tbreak;\n\t\t} else if (!list_empty(&cset->dying_tasks)) {\n\t\t\tit->cur_tasks_head = &cset->dying_tasks;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cset) {\n\t\tit->task_pos = NULL;\n\t\treturn;\n\t}\n\tit->task_pos = it->cur_tasks_head->next;\n\n\t/*\n\t * We don't keep css_sets locked across iteration steps and thus\n\t * need to take steps to ensure that iteration can be resumed after\n\t * the lock is re-acquired.  Iteration is performed at two levels -\n\t * css_sets and tasks in them.\n\t *\n\t * Once created, a css_set never leaves its cgroup lists, so a\n\t * pinned css_set is guaranteed to stay put and we can resume\n\t * iteration afterwards.\n\t *\n\t * Tasks may leave @cset across iteration steps.  This is resolved\n\t * by registering each iterator with the css_set currently being\n\t * walked and making css_set_move_task() advance iterators whose\n\t * next task is leaving.\n\t */\n\tif (it->cur_cset) {\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t}\n\tget_css_set(cset);\n\tit->cur_cset = cset;\n\tlist_add(&it->iters_node, &cset->task_iters);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_unlock_irq",
          "args": [
            "&css_set_lock"
          ],
          "line": 68
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_cgroup_from_root",
          "args": [
            "from",
            "root"
          ],
          "line": 67
        },
        "resolved": true,
        "details": {
          "function_name": "task_cgroup_from_root",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "1450-1458",
          "snippet": "struct cgroup *task_cgroup_from_root(struct task_struct *task,\n\t\t\t\t     struct cgroup_root *root)\n{\n\t/*\n\t * No need to lock the task - since we hold css_set_lock the\n\t * task can't change groups.\n\t */\n\treturn cset_cgroup_from_root(task_css_set(task), root);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstatic void css_task_iter_skip(struct css_task_iter *it,\n\t\t\t       struct task_struct *task);\n\nstruct cgroup *task_cgroup_from_root(struct task_struct *task,\n\t\t\t\t     struct cgroup_root *root)\n{\n\t/*\n\t * No need to lock the task - since we hold css_set_lock the\n\t * task can't change groups.\n\t */\n\treturn cset_cgroup_from_root(task_css_set(task), root);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_lock_irq",
          "args": [
            "&css_set_lock"
          ],
          "line": 66
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_lock_irqsave",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "293-300",
          "snippet": "static inline void __bpf_spin_lock_irqsave(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__bpf_spin_lock(lock);\n\t__this_cpu_write(irqsave_flags, flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_lock_irqsave(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__bpf_spin_lock(lock);\n\t__this_cpu_write(irqsave_flags, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "percpu_down_write",
          "args": [
            "&cgroup_threadgroup_rwsem"
          ],
          "line": 62
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&cgroup_mutex"
          ],
          "line": 61
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nint cgroup_attach_task_all(struct task_struct *from, struct task_struct *tsk)\n{\n\tstruct cgroup_root *root;\n\tint retval = 0;\n\n\tmutex_lock(&cgroup_mutex);\n\tpercpu_down_write(&cgroup_threadgroup_rwsem);\n\tfor_each_root(root) {\n\t\tstruct cgroup *from_cgrp;\n\n\t\tspin_lock_irq(&css_set_lock);\n\t\tfrom_cgrp = task_cgroup_from_root(from, root);\n\t\tspin_unlock_irq(&css_set_lock);\n\n\t\tretval = cgroup_attach_task(from_cgrp, tsk, false);\n\t\tif (retval)\n\t\t\tbreak;\n\t}\n\tpercpu_up_write(&cgroup_threadgroup_rwsem);\n\tmutex_unlock(&cgroup_mutex);\n\n\treturn retval;\n}"
  },
  {
    "function_name": "cgroup1_ssid_disabled",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup-v1.c",
    "lines": "44-47",
    "snippet": "bool cgroup1_ssid_disabled(int ssid)\n{\n\treturn cgroup_no_v1_mask & (1 << ssid);\n}",
    "includes": [
      "#include <trace/events/cgroup.h>",
      "#include <linux/fs_parser.h>",
      "#include <linux/cgroupstats.h>",
      "#include <linux/pid_namespace.h>",
      "#include <linux/delayacct.h>",
      "#include <linux/vmalloc.h>",
      "#include <linux/slab.h>",
      "#include <linux/magic.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>",
      "#include <linux/delay.h>",
      "#include <linux/sort.h>",
      "#include <linux/kmod.h>",
      "#include <linux/ctype.h>",
      "#include \"cgroup-internal.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static u16 cgroup_no_v1_mask;"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/cgroup.h>\n#include <linux/fs_parser.h>\n#include <linux/cgroupstats.h>\n#include <linux/pid_namespace.h>\n#include <linux/delayacct.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/magic.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/delay.h>\n#include <linux/sort.h>\n#include <linux/kmod.h>\n#include <linux/ctype.h>\n#include \"cgroup-internal.h\"\n\nstatic u16 cgroup_no_v1_mask;\n\nbool cgroup1_ssid_disabled(int ssid)\n{\n\treturn cgroup_no_v1_mask & (1 << ssid);\n}"
  }
]