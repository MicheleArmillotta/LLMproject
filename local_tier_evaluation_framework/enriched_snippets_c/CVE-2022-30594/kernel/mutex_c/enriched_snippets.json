[
  {
    "function_name": "atomic_dec_and_mutex_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1122-1136",
    "snippet": "int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)\n{\n\t/* dec if we can't possibly hit 0 */\n\tif (atomic_add_unless(cnt, -1, 1))\n\t\treturn 0;\n\t/* we might hit 0, so take the lock */\n\tmutex_lock(lock);\n\tif (!atomic_dec_and_test(cnt)) {\n\t\t/* when we actually did the dec, we didn't hit 0 */\n\t\tmutex_unlock(lock);\n\t\treturn 0;\n\t}\n\t/* we hit 0, and we hold the lock */\n\treturn 1;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 1131
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "555-559",
          "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec_and_test",
          "args": [
            "cnt"
          ],
          "line": 1129
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "lock"
          ],
          "line": 1128
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1030-1034",
          "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_add_unless",
          "args": [
            "cnt",
            "-1",
            "1"
          ],
          "line": 1125
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock)\n{\n\t/* dec if we can't possibly hit 0 */\n\tif (atomic_add_unless(cnt, -1, 1))\n\t\treturn 0;\n\t/* we might hit 0, so take the lock */\n\tmutex_lock(lock);\n\tif (!atomic_dec_and_test(cnt)) {\n\t\t/* when we actually did the dec, we didn't hit 0 */\n\t\tmutex_unlock(lock);\n\t\treturn 0;\n\t}\n\t/* we hit 0, and we hold the lock */\n\treturn 1;\n}"
  },
  {
    "function_name": "ww_mutex_lock_interruptible",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1097-1109",
    "snippet": "int __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock_interruptible_slowpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1108
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1043-1049",
          "snippet": "__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1104
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/ww_mutex.h",
          "lines": "377-410",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "&lock->base"
          ],
          "line": 1102
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "163-172",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1100
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_interruptible_slowpath(lock, ctx);\n}"
  },
  {
    "function_name": "ww_mutex_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1082-1094",
    "snippet": "int __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_slowpath(lock, ctx);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock_slowpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1093
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1036-1041",
          "snippet": "__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 1089
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/ww_mutex.h",
          "lines": "377-410",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "&lock->base"
          ],
          "line": 1087
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "163-172",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1085
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(&lock->base)) {\n\t\tif (ctx)\n\t\t\tww_mutex_set_context_fastpath(lock, ctx);\n\t\treturn 0;\n\t}\n\n\treturn __ww_mutex_lock_slowpath(lock, ctx);\n}"
  },
  {
    "function_name": "mutex_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1067-1078",
    "snippet": "int __sched mutex_trylock(struct mutex *lock)\n{\n\tbool locked;\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tlocked = __mutex_trylock(lock);\n\tif (locked)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn locked;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_acquire",
          "args": [
            "&lock->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 1075
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_trylock",
          "args": [
            "lock"
          ],
          "line": 1073
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "295-298",
          "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "lock->magic != lock"
          ],
          "line": 1071
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_trylock(struct mutex *lock)\n{\n\tbool locked;\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tlocked = __mutex_trylock(lock);\n\tif (locked)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn locked;\n}"
  },
  {
    "function_name": "__ww_mutex_lock_interruptible_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1043-1049",
    "snippet": "__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_INTERRUPTIBLE",
            "0",
            "_RET_IP_",
            "ctx"
          ],
          "line": 1047
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "736-741",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_interruptible_slowpath(struct ww_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}"
  },
  {
    "function_name": "__ww_mutex_lock_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1036-1041",
    "snippet": "__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "_RET_IP_",
            "ctx"
          ],
          "line": 1039
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "736-741",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__ww_mutex_lock_slowpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\treturn __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE, 0,\n\t\t\t       _RET_IP_, ctx);\n}"
  },
  {
    "function_name": "__mutex_lock_interruptible_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1030-1034",
    "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_INTERRUPTIBLE",
            "0",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1033
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "__mutex_lock_killable_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1024-1028",
    "snippet": "__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_KILLABLE",
            "0",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1027
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "__mutex_lock_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1018-1022",
    "snippet": "__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "NULL",
            "_RET_IP_"
          ],
          "line": 1021
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_lock_io",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "1008-1015",
    "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token;\n\n\ttoken = io_schedule_prepare();\n\tmutex_lock(lock);\n\tio_schedule_finish(token);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "io_schedule_finish",
          "args": [
            "token"
          ],
          "line": 1014
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_finish",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8387-8390",
          "snippet": "void io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "lock"
          ],
          "line": 1013
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1030-1034",
          "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "io_schedule_prepare",
          "args": [],
          "line": 1012
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_prepare",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8376-8385",
          "snippet": "int io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tif (current->plug)\n\t\tblk_flush_plug(current->plug, true);\n\n\treturn old_iowait;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tif (current->plug)\n\t\tblk_flush_plug(current->plug, true);\n\n\treturn old_iowait;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token;\n\n\ttoken = io_schedule_prepare();\n\tmutex_lock(lock);\n\tio_schedule_finish(token);\n}"
  },
  {
    "function_name": "mutex_lock_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "987-995",
    "snippet": "int __sched mutex_lock_killable(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_killable_slowpath(lock);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_killable_slowpath",
          "args": [
            "lock"
          ],
          "line": 994
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_killable_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1024-1028",
          "snippet": "__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_killable_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "lock"
          ],
          "line": 991
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "163-172",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 989
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_lock_killable(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_killable_slowpath(lock);\n}"
  },
  {
    "function_name": "mutex_lock_interruptible",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "963-971",
    "snippet": "int __sched mutex_lock_interruptible(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_interruptible_slowpath(lock);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_interruptible_slowpath",
          "args": [
            "lock"
          ],
          "line": 970
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_interruptible_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1030-1034",
          "snippet": "__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_interruptible_slowpath(struct mutex *lock)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "lock"
          ],
          "line": 967
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "163-172",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 965
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_lock_interruptible(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (__mutex_trylock_fast(lock))\n\t\treturn 0;\n\n\treturn __mutex_lock_interruptible_slowpath(lock);\n}"
  },
  {
    "function_name": "__mutex_unlock_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "887-938",
    "snippet": "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\traw_spin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_PICKUP\t0x04",
      "#define MUTEX_FLAG_HANDOFF\t0x02",
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 937
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_up_q",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "469-482",
          "snippet": "static __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 935
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_handoff",
          "args": [
            "lock",
            "next"
          ],
          "line": 933
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_handoff",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "228-246",
          "snippet": "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long new;\n\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))\n\t\t\tbreak;\n\t}\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long new;\n\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))\n\t\t\tbreak;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "wake_q_add",
          "args": [
            "&wake_q",
            "next"
          ],
          "line": 929
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_q_add",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "463-467",
          "snippet": "static __always_inline void rt_mutex_wake_q_add(struct rt_wake_q_head *wqh,\n\t\t\t\t\t\tstruct rt_mutex_waiter *w)\n{\n\trt_mutex_wake_q_add_task(wqh, w->task, w->wake_state);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_q_add(struct rt_wake_q_head *wqh,\n\t\t\t\t\t\tstruct rt_mutex_waiter *w)\n{\n\trt_mutex_wake_q_add_task(wqh, w->task, w->wake_state);\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_wake_waiter",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 928
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_wake_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "36-42",
          "snippet": "void debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tlockdep_assert_held(&lock->wait_lock);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));\n\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_wake_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tlockdep_assert_held(&lock->wait_lock);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&lock->wait_list));\n\tDEBUG_LOCKS_WARN_ON(waiter->magic != waiter);\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_first_entry",
          "args": [
            "&lock->wait_list",
            "structmutex_waiter",
            "list"
          ],
          "line": 923
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&lock->wait_list"
          ],
          "line": 920
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 919
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "71-77",
          "snippet": "void debug_mutex_unlock(struct mutex *lock)\n{\n\tif (likely(debug_locks)) {\n\t\tDEBUG_LOCKS_WARN_ON(lock->magic != lock);\n\t\tDEBUG_LOCKS_WARN_ON(!lock->wait_list.prev && !lock->wait_list.next);\n\t}\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_unlock(struct mutex *lock)\n{\n\tif (likely(debug_locks)) {\n\t\tDEBUG_LOCKS_WARN_ON(lock->magic != lock);\n\t\tDEBUG_LOCKS_WARN_ON(!lock->wait_list.prev && !lock->wait_list.next);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 918
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_release",
          "args": [
            "&lock->owner",
            "&owner",
            "__owner_flags(owner)"
          ],
          "line": 910
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_flags",
          "args": [
            "owner"
          ],
          "line": 910
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "92-95",
          "snippet": "static inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "owner & MUTEX_FLAG_PICKUP"
          ],
          "line": 905
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "__owner_task(owner) != current"
          ],
          "line": 904
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_task",
          "args": [
            "owner"
          ],
          "line": 904
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "81-84",
          "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 902
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_release",
          "args": [
            "&lock->dep_map",
            "ip"
          ],
          "line": 893
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 890
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n#define MUTEX_FLAG_WAITERS\t0x01\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\traw_spin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}"
  },
  {
    "function_name": "ww_mutex_lock_interruptible",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "866-879",
    "snippet": "int __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,\n\t\t\t      0, _RET_IP_, ctx);\n\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ww_mutex_deadlock_injection",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 876
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_deadlock_injection",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "825-849",
          "snippet": "static inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_INTERRUPTIBLE",
            "0",
            "_RET_IP_",
            "ctx"
          ],
          "line": 872
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "736-741",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 871
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock_interruptible(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret = __ww_mutex_lock(&lock->base, TASK_INTERRUPTIBLE,\n\t\t\t      0, _RET_IP_, ctx);\n\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "851-863",
    "snippet": "int __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,\n\t\t\t       0, _RET_IP_, ctx);\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ww_mutex_deadlock_injection",
          "args": [
            "lock",
            "ctx"
          ],
          "line": 860
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_deadlock_injection",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "825-849",
          "snippet": "static inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_lock",
          "args": [
            "&lock->base",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "_RET_IP_",
            "ctx"
          ],
          "line": 857
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "736-741",
          "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 856
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nww_mutex_lock(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tint ret;\n\n\tmight_sleep();\n\tret =  __ww_mutex_lock(&lock->base, TASK_UNINTERRUPTIBLE,\n\t\t\t       0, _RET_IP_, ctx);\n\tif (!ret && ctx && ctx->acquired > 1)\n\t\treturn ww_mutex_deadlock_injection(lock, ctx);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_deadlock_injection",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "825-849",
    "snippet": "static inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ww_mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 842
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "555-559",
          "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int\nww_mutex_deadlock_injection(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n#ifdef CONFIG_DEBUG_WW_MUTEX_SLOWPATH\n\tunsigned tmp;\n\n\tif (ctx->deadlock_inject_countdown-- == 0) {\n\t\ttmp = ctx->deadlock_inject_interval;\n\t\tif (tmp > UINT_MAX/4)\n\t\t\ttmp = UINT_MAX;\n\t\telse\n\t\t\ttmp = tmp*2 + tmp + tmp/2;\n\n\t\tctx->deadlock_inject_interval = tmp;\n\t\tctx->deadlock_inject_countdown = tmp;\n\t\tctx->contending_lock = lock;\n\n\t\tww_mutex_unlock(lock);\n\n\t\treturn -EDEADLK;\n\t}\n#endif\n\n\treturn 0;\n}"
  },
  {
    "function_name": "mutex_lock_io_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "811-822",
    "snippet": "void __sched\nmutex_lock_io_nested(struct mutex *lock, unsigned int subclass)\n{\n\tint token;\n\n\tmight_sleep();\n\n\ttoken = io_schedule_prepare();\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,\n\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);\n\tio_schedule_finish(token);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "io_schedule_finish",
          "args": [
            "token"
          ],
          "line": 821
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_finish",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8387-8390",
          "snippet": "void io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid io_schedule_finish(int token)\n{\n\tcurrent->in_iowait = token;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_lock_common",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "subclass",
            "NULL",
            "_RET_IP_",
            "NULL",
            "0"
          ],
          "line": 819
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "565-727",
          "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "io_schedule_prepare",
          "args": [],
          "line": 818
        },
        "resolved": true,
        "details": {
          "function_name": "io_schedule_prepare",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8376-8385",
          "snippet": "int io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tif (current->plug)\n\t\tblk_flush_plug(current->plug, true);\n\n\treturn old_iowait;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint io_schedule_prepare(void)\n{\n\tint old_iowait = current->in_iowait;\n\n\tcurrent->in_iowait = 1;\n\tif (current->plug)\n\t\tblk_flush_plug(current->plug, true);\n\n\treturn old_iowait;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 816
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched\nmutex_lock_io_nested(struct mutex *lock, unsigned int subclass)\n{\n\tint token;\n\n\tmight_sleep();\n\n\ttoken = io_schedule_prepare();\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE,\n\t\t\t    subclass, NULL, _RET_IP_, NULL, 0);\n\tio_schedule_finish(token);\n}"
  },
  {
    "function_name": "mutex_lock_interruptible_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "804-808",
    "snippet": "int __sched\nmutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_INTERRUPTIBLE",
            "subclass",
            "NULL",
            "_RET_IP_"
          ],
          "line": 807
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nmutex_lock_interruptible_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_INTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_lock_killable_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "797-801",
    "snippet": "int __sched\nmutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_KILLABLE",
            "subclass",
            "NULL",
            "_RET_IP_"
          ],
          "line": 800
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched\nmutex_lock_killable_nested(struct mutex *lock, unsigned int subclass)\n{\n\treturn __mutex_lock(lock, TASK_KILLABLE, subclass, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "_mutex_lock_nest_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "790-794",
    "snippet": "void __sched\n_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "0",
            "nest",
            "_RET_IP_"
          ],
          "line": 793
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched\n_mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, nest, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_lock_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "782-786",
    "snippet": "void __sched\nmutex_lock_nested(struct mutex *lock, unsigned int subclass)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock",
          "args": [
            "lock",
            "TASK_UNINTERRUPTIBLE",
            "subclass",
            "NULL",
            "_RET_IP_"
          ],
          "line": 785
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "729-734",
          "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched\nmutex_lock_nested(struct mutex *lock, unsigned int subclass)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, subclass, NULL, _RET_IP_);\n}"
  },
  {
    "function_name": "ww_mutex_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "756-778",
    "snippet": "int ww_mutex_trylock(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx)\n\t\treturn mutex_trylock(&ww->base);\n\n\tMUTEX_WARN_ON(ww->base.magic != &ww->base);\n\n\t/*\n\t * Reset the wounded flag after a kill. No other process can\n\t * race and wound us here, since they can't have a valid owner\n\t * pointer if we don't have any locks held.\n\t */\n\tif (ww_ctx->acquired == 0)\n\t\tww_ctx->wounded = 0;\n\n\tif (__mutex_trylock(&ww->base)) {\n\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tmutex_acquire_nest(&ww->base.dep_map, 0, 1, &ww_ctx->dep_map, _RET_IP_);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_acquire_nest",
          "args": [
            "&ww->base.dep_map",
            "0",
            "1",
            "&ww_ctx->dep_map",
            "_RET_IP_"
          ],
          "line": 773
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "ww",
            "ww_ctx"
          ],
          "line": 772
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/ww_mutex.h",
          "lines": "377-410",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock",
          "args": [
            "&ww->base"
          ],
          "line": 771
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "295-298",
          "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "ww->base.magic != &ww->base"
          ],
          "line": 761
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_trylock",
          "args": [
            "&ww->base"
          ],
          "line": 759
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1067-1078",
          "snippet": "int __sched mutex_trylock(struct mutex *lock)\n{\n\tbool locked;\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tlocked = __mutex_trylock(lock);\n\tif (locked)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn locked;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint __sched mutex_trylock(struct mutex *lock)\n{\n\tbool locked;\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tlocked = __mutex_trylock(lock);\n\tif (locked)\n\t\tmutex_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\n\treturn locked;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nint ww_mutex_trylock(struct ww_mutex *ww, struct ww_acquire_ctx *ww_ctx)\n{\n\tif (!ww_ctx)\n\t\treturn mutex_trylock(&ww->base);\n\n\tMUTEX_WARN_ON(ww->base.magic != &ww->base);\n\n\t/*\n\t * Reset the wounded flag after a kill. No other process can\n\t * race and wound us here, since they can't have a valid owner\n\t * pointer if we don't have any locks held.\n\t */\n\tif (ww_ctx->acquired == 0)\n\t\tww_ctx->wounded = 0;\n\n\tif (__mutex_trylock(&ww->base)) {\n\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tmutex_acquire_nest(&ww->base.dep_map, 0, 1, &ww_ctx->dep_map, _RET_IP_);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__ww_mutex_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "736-741",
    "snippet": "static int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_common",
          "args": [
            "lock",
            "state",
            "subclass",
            "NULL",
            "ip",
            "ww_ctx",
            "true"
          ],
          "line": 740
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "565-727",
          "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__ww_mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\tunsigned long ip, struct ww_acquire_ctx *ww_ctx)\n{\n\treturn __mutex_lock_common(lock, state, subclass, NULL, ip, ww_ctx, true);\n}"
  },
  {
    "function_name": "__mutex_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "729-734",
    "snippet": "static int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_common",
          "args": [
            "lock",
            "state",
            "subclass",
            "nest_lock",
            "ip",
            "NULL",
            "false"
          ],
          "line": 733
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "565-727",
          "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic int __sched\n__mutex_lock(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t     struct lockdep_map *nest_lock, unsigned long ip)\n{\n\treturn __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false);\n}"
  },
  {
    "function_name": "__mutex_lock_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "565-727",
    "snippet": "__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 725
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_release",
          "args": [
            "&lock->dep_map",
            "ip"
          ],
          "line": 724
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_mutex_free_waiter",
          "args": [
            "&waiter"
          ],
          "line": 723
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_free_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "44-48",
          "snippet": "void debug_mutex_free_waiter(struct mutex_waiter *waiter)\n{\n\tDEBUG_LOCKS_WARN_ON(!list_empty(&waiter->list));\n\tmemset(waiter, MUTEX_DEBUG_FREE, sizeof(*waiter));\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_free_waiter(struct mutex_waiter *waiter)\n{\n\tDEBUG_LOCKS_WARN_ON(!list_empty(&waiter->list));\n\tmemset(waiter, MUTEX_DEBUG_FREE, sizeof(*waiter));\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 722
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_remove_waiter",
          "args": [
            "lock",
            "&waiter"
          ],
          "line": 720
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_remove_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "212-220",
          "snippet": "static void\n__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tlist_del(&waiter->list);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_remove_waiter(lock, waiter, current);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic void\n__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tlist_del(&waiter->list);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_remove_waiter(lock, waiter, current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 719
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 715
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_lock_acquired",
          "args": [
            "ww",
            "ww_ctx"
          ],
          "line": 712
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_lock_acquired",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "45-48",
          "snippet": "static inline void ww_mutex_lock_acquired(struct ww_mutex *lock,\n\t\t\t\t\t  struct ww_acquire_ctx *ww_ctx)\n{\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline void ww_mutex_lock_acquired(struct ww_mutex *lock,\n\t\t\t\t\t  struct ww_acquire_ctx *ww_ctx)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_check_waiters",
          "args": [
            "lock",
            "ww_ctx"
          ],
          "line": 700
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_check_waiters",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "40-43",
          "snippet": "static inline void __ww_mutex_check_waiters(struct rt_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ww_ctx)\n{\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline void __ww_mutex_check_waiters(struct rt_mutex *lock,\n\t\t\t\t\t    struct ww_acquire_ctx *ww_ctx)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_waiter_is_first",
          "args": [
            "lock",
            "&waiter"
          ],
          "line": 699
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_waiter_is_first",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "192-195",
          "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 691
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 689
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_optimistic_spin",
          "args": [
            "lock",
            "ww_ctx",
            "&waiter"
          ],
          "line": 684
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_optimistic_spin",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "513-518",
          "snippet": "static __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      struct mutex_waiter *waiter)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      struct mutex_waiter *waiter)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_or_handoff",
          "args": [
            "lock",
            "first"
          ],
          "line": 683
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_handoff",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "139-142",
          "snippet": "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)\n{\n\treturn !__mutex_trylock_common(lock, handoff);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)\n{\n\treturn !__mutex_trylock_common(lock, handoff);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 677
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule_preempt_disabled",
          "args": [],
          "line": 673
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_check_kill",
          "args": [
            "lock",
            "&waiter",
            "ww_ctx"
          ],
          "line": 667
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_check_kill",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "50-55",
          "snippet": "static inline int __ww_mutex_check_kill(struct rt_mutex *lock,\n\t\t\t\t\tstruct rt_mutex_waiter *waiter,\n\t\t\t\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn 0;\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline int __ww_mutex_check_kill(struct rt_mutex *lock,\n\t\t\t\t\tstruct rt_mutex_waiter *waiter,\n\t\t\t\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "signal_pending_state",
          "args": [
            "state",
            "current"
          ],
          "line": 661
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_trylock",
          "args": [
            "lock"
          ],
          "line": 653
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "295-298",
          "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ww_mutex_add_waiter",
          "args": [
            "&waiter",
            "lock",
            "ww_ctx"
          ],
          "line": 638
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_add_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "33-38",
          "snippet": "static inline int __ww_mutex_add_waiter(struct rt_mutex_waiter *waiter,\n\t\t\t\t\tstruct rt_mutex *lock,\n\t\t\t\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn 0;\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline int __ww_mutex_add_waiter(struct rt_mutex_waiter *waiter,\n\t\t\t\t\tstruct rt_mutex *lock,\n\t\t\t\t\tstruct ww_acquire_ctx *ww_ctx)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_add_waiter",
          "args": [
            "lock",
            "&waiter",
            "&lock->wait_list"
          ],
          "line": 632
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_add_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "201-210",
          "snippet": "static void\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lock_contended",
          "args": [
            "&lock->dep_map",
            "ip"
          ],
          "line": 628
        },
        "resolved": true,
        "details": {
          "function_name": "lock_contended",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "5862-5877",
          "snippet": "void lock_contended(struct lockdep_map *lock, unsigned long ip)\n{\n\tunsigned long flags;\n\n\ttrace_lock_contended(lock, ip);\n\n\tif (unlikely(!lock_stat || !lockdep_enabled()))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tcheck_flags(flags);\n\tlockdep_recursion_inc();\n\t__lock_contended(lock, ip);\n\tlockdep_recursion_finish();\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define lock_stat 0"
          ],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\n#define lock_stat 0\n\nstatic noinstr struct;\n\nvoid lock_contended(struct lockdep_map *lock, unsigned long ip)\n{\n\tunsigned long flags;\n\n\ttrace_lock_contended(lock, ip);\n\n\tif (unlikely(!lock_stat || !lockdep_enabled()))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tcheck_flags(flags);\n\tlockdep_recursion_inc();\n\t__lock_contended(lock, ip);\n\tlockdep_recursion_finish();\n\traw_local_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_mutex_lock_common",
          "args": [
            "lock",
            "&waiter"
          ],
          "line": 623
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_lock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "28-34",
          "snippet": "void debug_mutex_lock_common(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tmemset(waiter, MUTEX_DEBUG_INIT, sizeof(*waiter));\n\twaiter->magic = waiter;\n\tINIT_LIST_HEAD(&waiter->list);\n\twaiter->ww_ctx = MUTEX_POISON_WW_CTX;\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_lock_common(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tmemset(waiter, MUTEX_DEBUG_INIT, sizeof(*waiter));\n\twaiter->magic = waiter;\n\tINIT_LIST_HEAD(&waiter->list);\n\twaiter->ww_ctx = MUTEX_POISON_WW_CTX;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 608
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_set_context_fastpath",
          "args": [
            "ww",
            "ww_ctx"
          ],
          "line": 607
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_set_context_fastpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/ww_mutex.h",
          "lines": "377-410",
          "snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline void\nww_mutex_set_context_fastpath(struct ww_mutex *lock, struct ww_acquire_ctx *ctx)\n{\n\tww_mutex_lock_acquired(lock, ctx);\n\n\t/*\n\t * The lock->ctx update should be visible on all cores before\n\t * the WAITERS check is done, otherwise contended waiters might be\n\t * missed. The contended waiters will either see ww_ctx == NULL\n\t * and keep spinning, or it will acquire wait_lock, add itself\n\t * to waiter list and sleep.\n\t */\n\tsmp_mb(); /* See comments above and below. */\n\n\t/*\n\t * [W] ww->ctx = ctx\t    [W] MUTEX_FLAG_WAITERS\n\t *     MB\t\t        MB\n\t * [R] MUTEX_FLAG_WAITERS   [R] ww->ctx\n\t *\n\t * The memory barrier above pairs with the memory barrier in\n\t * __ww_mutex_add_waiter() and makes sure we either observe ww->ctx\n\t * and/or !empty list.\n\t */\n\tif (likely(!__ww_mutex_has_waiters(&lock->base)))\n\t\treturn;\n\n\t/*\n\t * Uh oh, we raced in fastpath, check if any of the waiters need to\n\t * die or wound us.\n\t */\n\tlock_wait_lock(&lock->base);\n\t__ww_mutex_check_waiters(&lock->base, ctx);\n\tunlock_wait_lock(&lock->base);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_acquire_nest",
          "args": [
            "&lock->dep_map",
            "subclass",
            "0",
            "nest_lock",
            "ip"
          ],
          "line": 600
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ww_ctx == READ_ONCE(ww->ctx)"
          ],
          "line": 583
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "ww->ctx"
          ],
          "line": 583
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 581
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "lock->magic != lock"
          ],
          "line": 579
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 577
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_common(struct mutex *lock, unsigned int state, unsigned int subclass,\n\t\t    struct lockdep_map *nest_lock, unsigned long ip,\n\t\t    struct ww_acquire_ctx *ww_ctx, const bool use_ww_ctx)\n{\n\tstruct mutex_waiter waiter;\n\tstruct ww_mutex *ww;\n\tint ret;\n\n\tif (!use_ww_ctx)\n\t\tww_ctx = NULL;\n\n\tmight_sleep();\n\n\tMUTEX_WARN_ON(lock->magic != lock);\n\n\tww = container_of(lock, struct ww_mutex, base);\n\tif (ww_ctx) {\n\t\tif (unlikely(ww_ctx == READ_ONCE(ww->ctx)))\n\t\t\treturn -EALREADY;\n\n\t\t/*\n\t\t * Reset the wounded flag after a kill. No other process can\n\t\t * race and wound us here since they can't have a valid owner\n\t\t * pointer if we don't have any locks held.\n\t\t */\n\t\tif (ww_ctx->acquired == 0)\n\t\t\tww_ctx->wounded = 0;\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t\tnest_lock = &ww_ctx->dep_map;\n#endif\n\t}\n\n\tpreempt_disable();\n\tmutex_acquire_nest(&lock->dep_map, subclass, 0, nest_lock, ip);\n\n\tif (__mutex_trylock(lock) ||\n\t    mutex_optimistic_spin(lock, ww_ctx, NULL)) {\n\t\t/* got the lock, yay! */\n\t\tlock_acquired(&lock->dep_map, ip);\n\t\tif (ww_ctx)\n\t\t\tww_mutex_set_context_fastpath(ww, ww_ctx);\n\t\tpreempt_enable();\n\t\treturn 0;\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\t/*\n\t * After waiting to acquire the wait_lock, try again.\n\t */\n\tif (__mutex_trylock(lock)) {\n\t\tif (ww_ctx)\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\n\t\tgoto skip_wait;\n\t}\n\n\tdebug_mutex_lock_common(lock, &waiter);\n\twaiter.task = current;\n\tif (use_ww_ctx)\n\t\twaiter.ww_ctx = ww_ctx;\n\n\tlock_contended(&lock->dep_map, ip);\n\n\tif (!use_ww_ctx) {\n\t\t/* add waiting tasks to the end of the waitqueue (FIFO): */\n\t\t__mutex_add_waiter(lock, &waiter, &lock->wait_list);\n\t} else {\n\t\t/*\n\t\t * Add in stamp order, waking up waiters that must kill\n\t\t * themselves.\n\t\t */\n\t\tret = __ww_mutex_add_waiter(&waiter, lock, ww_ctx);\n\t\tif (ret)\n\t\t\tgoto err_early_kill;\n\t}\n\n\tset_current_state(state);\n\tfor (;;) {\n\t\tbool first;\n\n\t\t/*\n\t\t * Once we hold wait_lock, we're serialized against\n\t\t * mutex_unlock() handing the lock off to us, do a trylock\n\t\t * before testing the error conditions to make sure we pick up\n\t\t * the handoff.\n\t\t */\n\t\tif (__mutex_trylock(lock))\n\t\t\tgoto acquired;\n\n\t\t/*\n\t\t * Check for signals and kill conditions while holding\n\t\t * wait_lock. This ensures the lock cancellation is ordered\n\t\t * against mutex_unlock() and wake-ups do not go missing.\n\t\t */\n\t\tif (signal_pending_state(state, current)) {\n\t\t\tret = -EINTR;\n\t\t\tgoto err;\n\t\t}\n\n\t\tif (ww_ctx) {\n\t\t\tret = __ww_mutex_check_kill(lock, &waiter, ww_ctx);\n\t\t\tif (ret)\n\t\t\t\tgoto err;\n\t\t}\n\n\t\traw_spin_unlock(&lock->wait_lock);\n\t\tschedule_preempt_disabled();\n\n\t\tfirst = __mutex_waiter_is_first(lock, &waiter);\n\n\t\tset_current_state(state);\n\t\t/*\n\t\t * Here we order against unlock; we must either see it change\n\t\t * state back to RUNNING and fall through the next schedule(),\n\t\t * or we must see its unlock and acquire.\n\t\t */\n\t\tif (__mutex_trylock_or_handoff(lock, first) ||\n\t\t    (first && mutex_optimistic_spin(lock, ww_ctx, &waiter)))\n\t\t\tbreak;\n\n\t\traw_spin_lock(&lock->wait_lock);\n\t}\n\traw_spin_lock(&lock->wait_lock);\nacquired:\n\t__set_current_state(TASK_RUNNING);\n\n\tif (ww_ctx) {\n\t\t/*\n\t\t * Wound-Wait; we stole the lock (!first_waiter), check the\n\t\t * waiters as anyone might want to wound us.\n\t\t */\n\t\tif (!ww_ctx->is_wait_die &&\n\t\t    !__mutex_waiter_is_first(lock, &waiter))\n\t\t\t__ww_mutex_check_waiters(lock, ww_ctx);\n\t}\n\n\t__mutex_remove_waiter(lock, &waiter);\n\n\tdebug_mutex_free_waiter(&waiter);\n\nskip_wait:\n\t/* got the lock - cleanup and rejoice! */\n\tlock_acquired(&lock->dep_map, ip);\n\n\tif (ww_ctx)\n\t\tww_mutex_lock_acquired(ww, ww_ctx);\n\n\traw_spin_unlock(&lock->wait_lock);\n\tpreempt_enable();\n\treturn 0;\n\nerr:\n\t__set_current_state(TASK_RUNNING);\n\t__mutex_remove_waiter(lock, &waiter);\nerr_early_kill:\n\traw_spin_unlock(&lock->wait_lock);\n\tdebug_mutex_free_waiter(&waiter);\n\tmutex_release(&lock->dep_map, ip);\n\tpreempt_enable();\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "555-559",
    "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&lock->base"
          ],
          "line": 558
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "555-559",
          "snippet": "void __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "__ww_mutex_unlock",
          "args": [
            "lock"
          ],
          "line": 557
        },
        "resolved": true,
        "details": {
          "function_name": "__ww_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/ww_mutex.h",
          "lines": "559-569",
          "snippet": "static inline void __ww_mutex_unlock(struct ww_mutex *lock)\n{\n\tif (lock->ctx) {\n#ifdef DEBUG_WW_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void __ww_mutex_unlock(struct ww_mutex *lock)\n{\n\tif (lock->ctx) {\n#ifdef DEBUG_WW_MUTEXES\n\t\tDEBUG_LOCKS_WARN_ON(!lock->ctx->acquired);\n#endif\n\t\tif (lock->ctx->acquired > 0)\n\t\t\tlock->ctx->acquired--;\n\t\tlock->ctx = NULL;\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched ww_mutex_unlock(struct ww_mutex *lock)\n{\n\t__ww_mutex_unlock(lock);\n\tmutex_unlock(&lock->base);\n}"
  },
  {
    "function_name": "mutex_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "534-541",
    "snippet": "void __sched mutex_unlock(struct mutex *lock)\n{\n#ifndef CONFIG_DEBUG_LOCK_ALLOC\n\tif (__mutex_unlock_fast(lock))\n\t\treturn;\n#endif\n\t__mutex_unlock_slowpath(lock, _RET_IP_);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_unlock_slowpath",
          "args": [
            "lock",
            "_RET_IP_"
          ],
          "line": 540
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_unlock_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "887-938",
          "snippet": "__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\traw_spin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02",
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n#define MUTEX_FLAG_WAITERS\t0x01\n\n__sched __mutex_unlock_slowpath(struct mutex *lock, unsigned long ip)\n{\n\tstruct task_struct *next = NULL;\n\tDEFINE_WAKE_Q(wake_q);\n\tunsigned long owner;\n\n\tmutex_release(&lock->dep_map, ip);\n\n\t/*\n\t * Release the lock before (potentially) taking the spinlock such that\n\t * other contenders can get on with things ASAP.\n\t *\n\t * Except when HANDOFF, in that case we must not clear the owner field,\n\t * but instead set it to the top waiter.\n\t */\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) {\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t\tbreak;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, __owner_flags(owner))) {\n\t\t\tif (owner & MUTEX_FLAG_WAITERS)\n\t\t\t\tbreak;\n\n\t\t\treturn;\n\t\t}\n\t}\n\n\traw_spin_lock(&lock->wait_lock);\n\tdebug_mutex_unlock(lock);\n\tif (!list_empty(&lock->wait_list)) {\n\t\t/* get the first entry from the wait-list: */\n\t\tstruct mutex_waiter *waiter =\n\t\t\tlist_first_entry(&lock->wait_list,\n\t\t\t\t\t struct mutex_waiter, list);\n\n\t\tnext = waiter->task;\n\n\t\tdebug_mutex_wake_waiter(lock, waiter);\n\t\twake_q_add(&wake_q, next);\n\t}\n\n\tif (owner & MUTEX_FLAG_HANDOFF)\n\t\t__mutex_handoff(lock, next);\n\n\traw_spin_unlock(&lock->wait_lock);\n\n\twake_up_q(&wake_q);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_unlock_fast",
          "args": [
            "lock"
          ],
          "line": 537
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_unlock_fast",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "174-179",
          "snippet": "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched mutex_unlock(struct mutex *lock)\n{\n#ifndef CONFIG_DEBUG_LOCK_ALLOC\n\tif (__mutex_unlock_fast(lock))\n\t\treturn;\n#endif\n\t__mutex_unlock_slowpath(lock, _RET_IP_);\n}"
  },
  {
    "function_name": "mutex_optimistic_spin",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "513-518",
    "snippet": "static __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      struct mutex_waiter *waiter)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      struct mutex_waiter *waiter)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "mutex_optimistic_spin",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "437-511",
    "snippet": "static __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      struct mutex_waiter *waiter)\n{\n\tif (!waiter) {\n\t\t/*\n\t\t * The purpose of the mutex_can_spin_on_owner() function is\n\t\t * to eliminate the overhead of osq_lock() and osq_unlock()\n\t\t * in case spinning isn't possible. As a waiter-spinner\n\t\t * is not going to take OSQ lock anyway, there is no need\n\t\t * to call mutex_can_spin_on_owner().\n\t\t */\n\t\tif (!mutex_can_spin_on_owner(lock))\n\t\t\tgoto fail;\n\n\t\t/*\n\t\t * In order to avoid a stampede of mutex spinners trying to\n\t\t * acquire the mutex all at once, the spinners need to take a\n\t\t * MCS (queued) lock first before spinning on the owner field.\n\t\t */\n\t\tif (!osq_lock(&lock->osq))\n\t\t\tgoto fail;\n\t}\n\n\tfor (;;) {\n\t\tstruct task_struct *owner;\n\n\t\t/* Try to acquire the mutex... */\n\t\towner = __mutex_trylock_or_owner(lock);\n\t\tif (!owner)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * There's an owner, wait for it to either\n\t\t * release the lock or go to sleep.\n\t\t */\n\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))\n\t\t\tgoto fail_unlock;\n\n\t\t/*\n\t\t * The cpu_relax() call is a compiler barrier which forces\n\t\t * everything in this loop to be re-loaded. We don't need\n\t\t * memory barriers as we'll eventually observe the right\n\t\t * values at the cost of a few extra spins.\n\t\t */\n\t\tcpu_relax();\n\t}\n\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\n\treturn true;\n\n\nfail_unlock:\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\nfail:\n\t/*\n\t * If we fell out of the spin path because of need_resched(),\n\t * reschedule now, before we try-lock the mutex. This avoids getting\n\t * scheduled out right after we obtained the mutex.\n\t */\n\tif (need_resched()) {\n\t\t/*\n\t\t * We _should_ have TASK_RUNNING here, but just in case\n\t\t * we do not, make it so, otherwise we might get stuck.\n\t\t */\n\t\t__set_current_state(TASK_RUNNING);\n\t\tschedule_preempt_disabled();\n\t}\n\n\treturn false;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_preempt_disabled",
          "args": [],
          "line": 507
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 506
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 501
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "osq_unlock",
          "args": [
            "&lock->osq"
          ],
          "line": 493
        },
        "resolved": true,
        "details": {
          "function_name": "osq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/osq_lock.c",
          "lines": "207-232",
          "snippet": "void osq_unlock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\n\t/*\n\t * Fast path for the uncontended case.\n\t */\n\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,\n\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))\n\t\treturn;\n\n\t/*\n\t * Second most likely case.\n\t */\n\tnode = this_cpu_ptr(&osq_node);\n\tnext = xchg(&node->next, NULL);\n\tif (next) {\n\t\tWRITE_ONCE(next->locked, 1);\n\t\treturn;\n\t}\n\n\tnext = osq_wait_next(lock, node, NULL);\n\tif (next)\n\t\tWRITE_ONCE(next->locked, 1);\n}",
          "includes": [
            "#include <linux/osq_lock.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/osq_lock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);\n\nvoid osq_unlock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\n\t/*\n\t * Fast path for the uncontended case.\n\t */\n\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,\n\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))\n\t\treturn;\n\n\t/*\n\t * Second most likely case.\n\t */\n\tnode = this_cpu_ptr(&osq_node);\n\tnext = xchg(&node->next, NULL);\n\tif (next) {\n\t\tWRITE_ONCE(next->locked, 1);\n\t\treturn;\n\t}\n\n\tnext = osq_wait_next(lock, node, NULL);\n\tif (next)\n\t\tWRITE_ONCE(next->locked, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 482
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_spin_on_owner",
          "args": [
            "lock",
            "owner",
            "ww_ctx",
            "waiter"
          ],
          "line": 473
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_spin_on_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "348-384",
          "snippet": "static noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\tlockdep_assert_preemption_disabled();\n\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. And we already\n\t\t * disabled preemption which is equal to the RCU read-side\n\t\t * crital section in optimistic spinning code. Thus the\n\t\t * task_strcut structure won't go away during the spinning\n\t\t * period\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner_on_cpu(owner) || need_resched()) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\tlockdep_assert_preemption_disabled();\n\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. And we already\n\t\t * disabled preemption which is equal to the RCU read-side\n\t\t * crital section in optimistic spinning code. Thus the\n\t\t * task_strcut structure won't go away during the spinning\n\t\t * period\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner_on_cpu(owner) || need_resched()) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_or_owner",
          "args": [
            "lock"
          ],
          "line": 465
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_or_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "295-298",
          "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "osq_lock",
          "args": [
            "&lock->osq"
          ],
          "line": 457
        },
        "resolved": true,
        "details": {
          "function_name": "osq_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/osq_lock.c",
          "lines": "90-205",
          "snippet": "bool osq_lock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);\n\tstruct optimistic_spin_node *prev, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\tint old;\n\n\tnode->locked = 0;\n\tnode->next = NULL;\n\tnode->cpu = curr;\n\n\t/*\n\t * We need both ACQUIRE (pairs with corresponding RELEASE in\n\t * unlock() uncontended, or fastpath) and RELEASE (to publish\n\t * the node fields we just initialised) semantics when updating\n\t * the lock tail.\n\t */\n\told = atomic_xchg(&lock->tail, curr);\n\tif (old == OSQ_UNLOCKED_VAL)\n\t\treturn true;\n\n\tprev = decode_cpu(old);\n\tnode->prev = prev;\n\n\t/*\n\t * osq_lock()\t\t\tunqueue\n\t *\n\t * node->prev = prev\t\tosq_wait_next()\n\t * WMB\t\t\t\tMB\n\t * prev->next = node\t\tnext->prev = prev // unqueue-C\n\t *\n\t * Here 'node->prev' and 'next->prev' are the same variable and we need\n\t * to ensure these stores happen in-order to avoid corrupting the list.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(prev->next, node);\n\n\t/*\n\t * Normally @prev is untouchable after the above store; because at that\n\t * moment unlock can proceed and wipe the node element from stack.\n\t *\n\t * However, since our nodes are static per-cpu storage, we're\n\t * guaranteed their existence -- this allows us to apply\n\t * cmpxchg in an attempt to undo our queueing.\n\t */\n\n\t/*\n\t * Wait to acquire the lock or cancellation. Note that need_resched()\n\t * will come with an IPI, which will wake smp_cond_load_relaxed() if it\n\t * is implemented with a monitor-wait. vcpu_is_preempted() relies on\n\t * polling, be careful.\n\t */\n\tif (smp_cond_load_relaxed(&node->locked, VAL || need_resched() ||\n\t\t\t\t  vcpu_is_preempted(node_cpu(node->prev))))\n\t\treturn true;\n\n\t/* unqueue */\n\t/*\n\t * Step - A  -- stabilize @prev\n\t *\n\t * Undo our @prev->next assignment; this will make @prev's\n\t * unlock()/unqueue() wait for a next pointer since @lock points to us\n\t * (or later).\n\t */\n\n\tfor (;;) {\n\t\t/*\n\t\t * cpu_relax() below implies a compiler barrier which would\n\t\t * prevent this comparison being optimized away.\n\t\t */\n\t\tif (data_race(prev->next) == node &&\n\t\t    cmpxchg(&prev->next, node, NULL) == node)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We can only fail the cmpxchg() racing against an unlock(),\n\t\t * in which case we should observe @node->locked becoming\n\t\t * true.\n\t\t */\n\t\tif (smp_load_acquire(&node->locked))\n\t\t\treturn true;\n\n\t\tcpu_relax();\n\n\t\t/*\n\t\t * Or we race against a concurrent unqueue()'s step-B, in which\n\t\t * case its step-C will write us a new @node->prev pointer.\n\t\t */\n\t\tprev = READ_ONCE(node->prev);\n\t}\n\n\t/*\n\t * Step - B -- stabilize @next\n\t *\n\t * Similar to unlock(), wait for @node->next or move @lock from @node\n\t * back to @prev.\n\t */\n\n\tnext = osq_wait_next(lock, node, prev);\n\tif (!next)\n\t\treturn false;\n\n\t/*\n\t * Step - C -- unlink\n\t *\n\t * @prev is stable because its still waiting for a new @prev->next\n\t * pointer, @next is stable because our @node->next pointer is NULL and\n\t * it will wait in Step-A.\n\t */\n\n\tWRITE_ONCE(next->prev, prev);\n\tWRITE_ONCE(prev->next, next);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/osq_lock.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/osq_lock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);\n\nbool osq_lock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);\n\tstruct optimistic_spin_node *prev, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\tint old;\n\n\tnode->locked = 0;\n\tnode->next = NULL;\n\tnode->cpu = curr;\n\n\t/*\n\t * We need both ACQUIRE (pairs with corresponding RELEASE in\n\t * unlock() uncontended, or fastpath) and RELEASE (to publish\n\t * the node fields we just initialised) semantics when updating\n\t * the lock tail.\n\t */\n\told = atomic_xchg(&lock->tail, curr);\n\tif (old == OSQ_UNLOCKED_VAL)\n\t\treturn true;\n\n\tprev = decode_cpu(old);\n\tnode->prev = prev;\n\n\t/*\n\t * osq_lock()\t\t\tunqueue\n\t *\n\t * node->prev = prev\t\tosq_wait_next()\n\t * WMB\t\t\t\tMB\n\t * prev->next = node\t\tnext->prev = prev // unqueue-C\n\t *\n\t * Here 'node->prev' and 'next->prev' are the same variable and we need\n\t * to ensure these stores happen in-order to avoid corrupting the list.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(prev->next, node);\n\n\t/*\n\t * Normally @prev is untouchable after the above store; because at that\n\t * moment unlock can proceed and wipe the node element from stack.\n\t *\n\t * However, since our nodes are static per-cpu storage, we're\n\t * guaranteed their existence -- this allows us to apply\n\t * cmpxchg in an attempt to undo our queueing.\n\t */\n\n\t/*\n\t * Wait to acquire the lock or cancellation. Note that need_resched()\n\t * will come with an IPI, which will wake smp_cond_load_relaxed() if it\n\t * is implemented with a monitor-wait. vcpu_is_preempted() relies on\n\t * polling, be careful.\n\t */\n\tif (smp_cond_load_relaxed(&node->locked, VAL || need_resched() ||\n\t\t\t\t  vcpu_is_preempted(node_cpu(node->prev))))\n\t\treturn true;\n\n\t/* unqueue */\n\t/*\n\t * Step - A  -- stabilize @prev\n\t *\n\t * Undo our @prev->next assignment; this will make @prev's\n\t * unlock()/unqueue() wait for a next pointer since @lock points to us\n\t * (or later).\n\t */\n\n\tfor (;;) {\n\t\t/*\n\t\t * cpu_relax() below implies a compiler barrier which would\n\t\t * prevent this comparison being optimized away.\n\t\t */\n\t\tif (data_race(prev->next) == node &&\n\t\t    cmpxchg(&prev->next, node, NULL) == node)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We can only fail the cmpxchg() racing against an unlock(),\n\t\t * in which case we should observe @node->locked becoming\n\t\t * true.\n\t\t */\n\t\tif (smp_load_acquire(&node->locked))\n\t\t\treturn true;\n\n\t\tcpu_relax();\n\n\t\t/*\n\t\t * Or we race against a concurrent unqueue()'s step-B, in which\n\t\t * case its step-C will write us a new @node->prev pointer.\n\t\t */\n\t\tprev = READ_ONCE(node->prev);\n\t}\n\n\t/*\n\t * Step - B -- stabilize @next\n\t *\n\t * Similar to unlock(), wait for @node->next or move @lock from @node\n\t * back to @prev.\n\t */\n\n\tnext = osq_wait_next(lock, node, prev);\n\tif (!next)\n\t\treturn false;\n\n\t/*\n\t * Step - C -- unlink\n\t *\n\t * @prev is stable because its still waiting for a new @prev->next\n\t * pointer, @next is stable because our @node->next pointer is NULL and\n\t * it will wait in Step-A.\n\t */\n\n\tWRITE_ONCE(next->prev, prev);\n\tWRITE_ONCE(prev->next, next);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_can_spin_on_owner",
          "args": [
            "lock"
          ],
          "line": 449
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_can_spin_on_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "389-414",
          "snippet": "static inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tlockdep_assert_preemption_disabled();\n\n\tif (need_resched())\n\t\treturn 0;\n\n\t/*\n\t * We already disabled preemption which is equal to the RCU read-side\n\t * crital section in optimistic spinning code. Thus the task_strcut\n\t * structure won't go away during the spinning period.\n\t */\n\towner = __mutex_owner(lock);\n\tif (owner)\n\t\tretval = owner_on_cpu(owner);\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tlockdep_assert_preemption_disabled();\n\n\tif (need_resched())\n\t\treturn 0;\n\n\t/*\n\t * We already disabled preemption which is equal to the RCU read-side\n\t * crital section in optimistic spinning code. Thus the task_strcut\n\t * structure won't go away during the spinning period.\n\t */\n\towner = __mutex_owner(lock);\n\tif (owner)\n\t\tretval = owner_on_cpu(owner);\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool\nmutex_optimistic_spin(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t      struct mutex_waiter *waiter)\n{\n\tif (!waiter) {\n\t\t/*\n\t\t * The purpose of the mutex_can_spin_on_owner() function is\n\t\t * to eliminate the overhead of osq_lock() and osq_unlock()\n\t\t * in case spinning isn't possible. As a waiter-spinner\n\t\t * is not going to take OSQ lock anyway, there is no need\n\t\t * to call mutex_can_spin_on_owner().\n\t\t */\n\t\tif (!mutex_can_spin_on_owner(lock))\n\t\t\tgoto fail;\n\n\t\t/*\n\t\t * In order to avoid a stampede of mutex spinners trying to\n\t\t * acquire the mutex all at once, the spinners need to take a\n\t\t * MCS (queued) lock first before spinning on the owner field.\n\t\t */\n\t\tif (!osq_lock(&lock->osq))\n\t\t\tgoto fail;\n\t}\n\n\tfor (;;) {\n\t\tstruct task_struct *owner;\n\n\t\t/* Try to acquire the mutex... */\n\t\towner = __mutex_trylock_or_owner(lock);\n\t\tif (!owner)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * There's an owner, wait for it to either\n\t\t * release the lock or go to sleep.\n\t\t */\n\t\tif (!mutex_spin_on_owner(lock, owner, ww_ctx, waiter))\n\t\t\tgoto fail_unlock;\n\n\t\t/*\n\t\t * The cpu_relax() call is a compiler barrier which forces\n\t\t * everything in this loop to be re-loaded. We don't need\n\t\t * memory barriers as we'll eventually observe the right\n\t\t * values at the cost of a few extra spins.\n\t\t */\n\t\tcpu_relax();\n\t}\n\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\n\treturn true;\n\n\nfail_unlock:\n\tif (!waiter)\n\t\tosq_unlock(&lock->osq);\n\nfail:\n\t/*\n\t * If we fell out of the spin path because of need_resched(),\n\t * reschedule now, before we try-lock the mutex. This avoids getting\n\t * scheduled out right after we obtained the mutex.\n\t */\n\tif (need_resched()) {\n\t\t/*\n\t\t * We _should_ have TASK_RUNNING here, but just in case\n\t\t * we do not, make it so, otherwise we might get stuck.\n\t\t */\n\t\t__set_current_state(TASK_RUNNING);\n\t\tschedule_preempt_disabled();\n\t}\n\n\treturn false;\n}"
  },
  {
    "function_name": "mutex_can_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "389-414",
    "snippet": "static inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tlockdep_assert_preemption_disabled();\n\n\tif (need_resched())\n\t\treturn 0;\n\n\t/*\n\t * We already disabled preemption which is equal to the RCU read-side\n\t * crital section in optimistic spinning code. Thus the task_strcut\n\t * structure won't go away during the spinning period.\n\t */\n\towner = __mutex_owner(lock);\n\tif (owner)\n\t\tretval = owner_on_cpu(owner);\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "owner_on_cpu",
          "args": [
            "owner"
          ],
          "line": 406
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mutex_owner",
          "args": [
            "lock"
          ],
          "line": 404
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "76-79",
          "snippet": "static inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 396
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_preemption_disabled",
          "args": [],
          "line": 394
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline int mutex_can_spin_on_owner(struct mutex *lock)\n{\n\tstruct task_struct *owner;\n\tint retval = 1;\n\n\tlockdep_assert_preemption_disabled();\n\n\tif (need_resched())\n\t\treturn 0;\n\n\t/*\n\t * We already disabled preemption which is equal to the RCU read-side\n\t * crital section in optimistic spinning code. Thus the task_strcut\n\t * structure won't go away during the spinning period.\n\t */\n\towner = __mutex_owner(lock);\n\tif (owner)\n\t\tretval = owner_on_cpu(owner);\n\n\t/*\n\t * If lock->owner is not set, the mutex has been released. Return true\n\t * such that we'll trylock in the spin path, which is a faster option\n\t * than the blocking slow path.\n\t */\n\treturn retval;\n}"
  },
  {
    "function_name": "mutex_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "348-384",
    "snippet": "static noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\tlockdep_assert_preemption_disabled();\n\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. And we already\n\t\t * disabled preemption which is equal to the RCU read-side\n\t\t * crital section in optimistic spinning code. Thus the\n\t\t * task_strcut structure won't go away during the spinning\n\t\t * period\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner_on_cpu(owner) || need_resched()) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\treturn ret;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 380
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ww_mutex_spin_on_owner",
          "args": [
            "lock",
            "ww_ctx",
            "waiter"
          ],
          "line": 375
        },
        "resolved": true,
        "details": {
          "function_name": "ww_mutex_spin_on_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "300-340",
          "snippet": "static inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAG_WAITERS\t0x01"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "owner_on_cpu",
          "args": [
            "owner"
          ],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 365
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
          "lines": "482-499",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ret;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ret;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_owner",
          "args": [
            "lock"
          ],
          "line": 356
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "76-79",
          "snippet": "static inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_preemption_disabled",
          "args": [],
          "line": 354
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic noinline\nbool mutex_spin_on_owner(struct mutex *lock, struct task_struct *owner,\n\t\t\t struct ww_acquire_ctx *ww_ctx, struct mutex_waiter *waiter)\n{\n\tbool ret = true;\n\n\tlockdep_assert_preemption_disabled();\n\n\twhile (__mutex_owner(lock) == owner) {\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking lock->owner still matches owner. And we already\n\t\t * disabled preemption which is equal to the RCU read-side\n\t\t * crital section in optimistic spinning code. Thus the\n\t\t * task_strcut structure won't go away during the spinning\n\t\t * period\n\t\t */\n\t\tbarrier();\n\n\t\t/*\n\t\t * Use vcpu_is_preempted to detect lock holder preemption issue.\n\t\t */\n\t\tif (!owner_on_cpu(owner) || need_resched()) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (ww_ctx && !ww_mutex_spin_on_owner(lock, ww_ctx, waiter)) {\n\t\t\tret = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\treturn ret;\n}"
  },
  {
    "function_name": "ww_mutex_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "300-340",
    "snippet": "static inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_waiter_is_first",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 336
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_waiter_is_first",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "192-195",
          "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 329
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "ww->ctx"
          ],
          "line": 319
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "lock",
            "structww_mutex",
            "base"
          ],
          "line": 306
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic inline\nbool ww_mutex_spin_on_owner(struct mutex *lock, struct ww_acquire_ctx *ww_ctx,\n\t\t\t    struct mutex_waiter *waiter)\n{\n\tstruct ww_mutex *ww;\n\n\tww = container_of(lock, struct ww_mutex, base);\n\n\t/*\n\t * If ww->ctx is set the contents are undefined, only\n\t * by acquiring wait_lock there is a guarantee that\n\t * they are not invalid when reading.\n\t *\n\t * As such, when deadlock detection needs to be\n\t * performed the optimistic spinning cannot be done.\n\t *\n\t * Check this in every inner iteration because we may\n\t * be racing against another thread's ww_mutex_lock.\n\t */\n\tif (ww_ctx->acquired > 0 && READ_ONCE(ww->ctx))\n\t\treturn false;\n\n\t/*\n\t * If we aren't on the wait list yet, cancel the spin\n\t * if there are waiters. We want  to avoid stealing the\n\t * lock from a waiter with an earlier stamp, since the\n\t * other thread may already own a lock that we also\n\t * need.\n\t */\n\tif (!waiter && (atomic_long_read(&lock->owner) & MUTEX_FLAG_WAITERS))\n\t\treturn false;\n\n\t/*\n\t * Similarly, stop spinning if we are no longer the\n\t * first waiter.\n\t */\n\tif (waiter && !__mutex_waiter_is_first(lock, waiter))\n\t\treturn false;\n\n\treturn true;\n}"
  },
  {
    "function_name": "__mutex_trylock_or_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "295-298",
    "snippet": "static inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_trylock_common",
          "args": [
            "lock",
            "false"
          ],
          "line": 297
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "100-134",
          "snippet": "static inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline struct task_struct *__mutex_trylock_or_owner(struct mutex *lock)\n{\n\treturn __mutex_trylock_common(lock, false);\n}"
  },
  {
    "function_name": "mutex_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "278-284",
    "snippet": "void __sched mutex_lock(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (!__mutex_trylock_fast(lock))\n\t\t__mutex_lock_slowpath(lock);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_lock_slowpath",
          "args": [
            "lock"
          ],
          "line": 283
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_lock_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "1018-1022",
          "snippet": "__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n__sched\n__mutex_lock_slowpath(struct mutex *lock)\n{\n\t__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_trylock_fast",
          "args": [
            "lock"
          ],
          "line": 282
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_fast",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "163-172",
          "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 280
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid __sched mutex_lock(struct mutex *lock)\n{\n\tmight_sleep();\n\n\tif (!__mutex_trylock_fast(lock))\n\t\t__mutex_lock_slowpath(lock);\n}"
  },
  {
    "function_name": "__mutex_handoff",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "228-246",
    "snippet": "static void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long new;\n\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))\n\t\t\tbreak;\n\t}\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_PICKUP\t0x04",
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_release",
          "args": [
            "&lock->owner",
            "&owner",
            "new"
          ],
          "line": 243
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "owner & MUTEX_FLAG_PICKUP"
          ],
          "line": 236
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "__owner_task(owner) != current"
          ],
          "line": 235
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_task",
          "args": [
            "owner"
          ],
          "line": 235
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "81-84",
          "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 230
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void __mutex_handoff(struct mutex *lock, struct task_struct *task)\n{\n\tunsigned long owner = atomic_long_read(&lock->owner);\n\n\tfor (;;) {\n\t\tunsigned long new;\n\n\t\tMUTEX_WARN_ON(__owner_task(owner) != current);\n\t\tMUTEX_WARN_ON(owner & MUTEX_FLAG_PICKUP);\n\n\t\tnew = (owner & MUTEX_FLAG_WAITERS);\n\t\tnew |= (unsigned long)task;\n\t\tif (task)\n\t\t\tnew |= MUTEX_FLAG_PICKUP;\n\n\t\tif (atomic_long_try_cmpxchg_release(&lock->owner, &owner, new))\n\t\t\tbreak;\n\t}\n}"
  },
  {
    "function_name": "__mutex_remove_waiter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "212-220",
    "snippet": "static void\n__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tlist_del(&waiter->list);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_remove_waiter(lock, waiter, current);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "debug_mutex_remove_waiter",
          "args": [
            "lock",
            "waiter",
            "current"
          ],
          "line": 219
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_remove_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "59-69",
          "snippet": "void debug_mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t struct task_struct *task)\n{\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n\tDEBUG_LOCKS_WARN_ON(waiter->task != task);\n\tDEBUG_LOCKS_WARN_ON(task->blocked_on != waiter);\n\ttask->blocked_on = NULL;\n\n\tINIT_LIST_HEAD(&waiter->list);\n\twaiter->task = NULL;\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t struct task_struct *task)\n{\n\tDEBUG_LOCKS_WARN_ON(list_empty(&waiter->list));\n\tDEBUG_LOCKS_WARN_ON(waiter->task != task);\n\tDEBUG_LOCKS_WARN_ON(task->blocked_on != waiter);\n\ttask->blocked_on = NULL;\n\n\tINIT_LIST_HEAD(&waiter->list);\n\twaiter->task = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_clear_flag",
          "args": [
            "lock",
            "MUTEX_FLAGS"
          ],
          "line": 217
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_clear_flag",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "187-190",
          "snippet": "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "list_empty(&lock->wait_list)"
          ],
          "line": 216
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&lock->wait_list"
          ],
          "line": 216
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&waiter->list"
          ],
          "line": 215
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/fair.c",
          "lines": "475-477",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);",
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic void\n__mutex_remove_waiter(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\tlist_del(&waiter->list);\n\tif (likely(list_empty(&lock->wait_list)))\n\t\t__mutex_clear_flag(lock, MUTEX_FLAGS);\n\n\tdebug_mutex_remove_waiter(lock, waiter, current);\n}"
  },
  {
    "function_name": "__mutex_add_waiter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "201-210",
    "snippet": "static void\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAG_WAITERS\t0x01"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_set_flag",
          "args": [
            "lock",
            "MUTEX_FLAG_WAITERS"
          ],
          "line": 209
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_set_flag",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "182-185",
          "snippet": "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__mutex_waiter_is_first",
          "args": [
            "lock",
            "waiter"
          ],
          "line": 208
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_waiter_is_first",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "192-195",
          "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&waiter->list",
            "list"
          ],
          "line": 207
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_mutex_add_waiter",
          "args": [
            "lock",
            "waiter",
            "current"
          ],
          "line": 205
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_add_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "50-57",
          "snippet": "void debug_mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t    struct task_struct *task)\n{\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/* Mark the current thread as blocked on the lock: */\n\ttask->blocked_on = waiter;\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t\t    struct task_struct *task)\n{\n\tlockdep_assert_held(&lock->wait_lock);\n\n\t/* Mark the current thread as blocked on the lock: */\n\ttask->blocked_on = waiter;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAG_WAITERS\t0x01\n\nstatic void\n__mutex_add_waiter(struct mutex *lock, struct mutex_waiter *waiter,\n\t\t   struct list_head *list)\n{\n\tdebug_mutex_add_waiter(lock, waiter, current);\n\n\tlist_add_tail(&waiter->list, list);\n\tif (__mutex_waiter_is_first(lock, waiter))\n\t\t__mutex_set_flag(lock, MUTEX_FLAG_WAITERS);\n}"
  },
  {
    "function_name": "__mutex_waiter_is_first",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "192-195",
    "snippet": "static inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_first_entry",
          "args": [
            "&lock->wait_list",
            "structmutex_waiter",
            "list"
          ],
          "line": 194
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_waiter_is_first(struct mutex *lock, struct mutex_waiter *waiter)\n{\n\treturn list_first_entry(&lock->wait_list, struct mutex_waiter, list) == waiter;\n}"
  },
  {
    "function_name": "__mutex_clear_flag",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "187-190",
    "snippet": "static inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_andnot",
          "args": [
            "flag",
            "&lock->owner"
          ],
          "line": 189
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_clear_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_andnot(flag, &lock->owner);\n}"
  },
  {
    "function_name": "__mutex_set_flag",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "182-185",
    "snippet": "static inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_or",
          "args": [
            "flag",
            "&lock->owner"
          ],
          "line": 184
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline void __mutex_set_flag(struct mutex *lock, unsigned long flag)\n{\n\tatomic_long_or(flag, &lock->owner);\n}"
  },
  {
    "function_name": "__mutex_unlock_fast",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "174-179",
    "snippet": "static __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_release",
          "args": [
            "&lock->owner",
            "&curr",
            "0UL"
          ],
          "line": 178
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_unlock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\n\treturn atomic_long_try_cmpxchg_release(&lock->owner, &curr, 0UL);\n}"
  },
  {
    "function_name": "__mutex_trylock_fast",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "163-172",
    "snippet": "static __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&lock->owner",
            "&zero",
            "curr"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic __always_inline bool __mutex_trylock_fast(struct mutex *lock)\n{\n\tunsigned long curr = (unsigned long)current;\n\tunsigned long zero = 0UL;\n\n\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &zero, curr))\n\t\treturn true;\n\n\treturn false;\n}"
  },
  {
    "function_name": "__mutex_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "147-150",
    "snippet": "static inline bool __mutex_trylock(struct mutex *lock)\n{\n\treturn !__mutex_trylock_common(lock, false);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_trylock_common",
          "args": [
            "lock",
            "false"
          ],
          "line": 149
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "100-134",
          "snippet": "static inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_trylock(struct mutex *lock)\n{\n\treturn !__mutex_trylock_common(lock, false);\n}"
  },
  {
    "function_name": "__mutex_trylock_or_handoff",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "139-142",
    "snippet": "static inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)\n{\n\treturn !__mutex_trylock_common(lock, handoff);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_trylock_common",
          "args": [
            "lock",
            "handoff"
          ],
          "line": 141
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_trylock_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "100-134",
          "snippet": "static inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07",
            "#define MUTEX_FLAG_PICKUP\t0x04",
            "#define MUTEX_FLAG_HANDOFF\t0x02"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nstatic inline bool __mutex_trylock_or_handoff(struct mutex *lock, bool handoff)\n{\n\treturn !__mutex_trylock_common(lock, handoff);\n}"
  },
  {
    "function_name": "__mutex_trylock_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "100-134",
    "snippet": "static inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07",
      "#define MUTEX_FLAG_PICKUP\t0x04",
      "#define MUTEX_FLAG_HANDOFF\t0x02"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__owner_task",
          "args": [
            "owner"
          ],
          "line": 133
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "81-84",
          "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&lock->owner",
            "&owner",
            "task | flags"
          ],
          "line": 126
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "MUTEX_WARN_ON",
          "args": [
            "flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP)"
          ],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__owner_flags",
          "args": [
            "owner"
          ],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "__owner_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "92-95",
          "snippet": "static inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 104
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n#define MUTEX_FLAG_PICKUP\t0x04\n#define MUTEX_FLAG_HANDOFF\t0x02\n\nstatic inline struct task_struct *__mutex_trylock_common(struct mutex *lock, bool handoff)\n{\n\tunsigned long owner, curr = (unsigned long)current;\n\n\towner = atomic_long_read(&lock->owner);\n\tfor (;;) { /* must loop, can race against a flag */\n\t\tunsigned long flags = __owner_flags(owner);\n\t\tunsigned long task = owner & ~MUTEX_FLAGS;\n\n\t\tif (task) {\n\t\t\tif (flags & MUTEX_FLAG_PICKUP) {\n\t\t\t\tif (task != curr)\n\t\t\t\t\tbreak;\n\t\t\t\tflags &= ~MUTEX_FLAG_PICKUP;\n\t\t\t} else if (handoff) {\n\t\t\t\tif (flags & MUTEX_FLAG_HANDOFF)\n\t\t\t\t\tbreak;\n\t\t\t\tflags |= MUTEX_FLAG_HANDOFF;\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else {\n\t\t\tMUTEX_WARN_ON(flags & (MUTEX_FLAG_HANDOFF | MUTEX_FLAG_PICKUP));\n\t\t\ttask = curr;\n\t\t}\n\n\t\tif (atomic_long_try_cmpxchg_acquire(&lock->owner, &owner, task | flags)) {\n\t\t\tif (task == curr)\n\t\t\t\treturn NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn __owner_task(owner);\n}"
  },
  {
    "function_name": "__owner_flags",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "92-95",
    "snippet": "static inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline unsigned long __owner_flags(unsigned long owner)\n{\n\treturn owner & MUTEX_FLAGS;\n}"
  },
  {
    "function_name": "mutex_is_locked",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "86-89",
    "snippet": "bool mutex_is_locked(struct mutex *lock)\n{\n\treturn __mutex_owner(lock) != NULL;\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mutex_owner",
          "args": [
            "lock"
          ],
          "line": 88
        },
        "resolved": true,
        "details": {
          "function_name": "__mutex_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
          "lines": "76-79",
          "snippet": "static inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}",
          "includes": [
            "#include \"ww_mutex.h\"",
            "#include \"mutex.h\"",
            "#include <linux/osq_lock.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/ww_mutex.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [
            "#define MUTEX_FLAGS\t\t0x07"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nbool mutex_is_locked(struct mutex *lock)\n{\n\treturn __mutex_owner(lock) != NULL;\n}"
  },
  {
    "function_name": "__owner_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "81-84",
    "snippet": "static inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__owner_task(unsigned long owner)\n{\n\treturn (struct task_struct *)(owner & ~MUTEX_FLAGS);\n}"
  },
  {
    "function_name": "__mutex_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "76-79",
    "snippet": "static inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [
      "#define MUTEX_FLAGS\t\t0x07"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&lock->owner"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\n#define MUTEX_FLAGS\t\t0x07\n\nstatic inline struct task_struct *__mutex_owner(struct mutex *lock)\n{\n\treturn (struct task_struct *)(atomic_long_read(&lock->owner) & ~MUTEX_FLAGS);\n}"
  },
  {
    "function_name": "__mutex_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex.c",
    "lines": "42-53",
    "snippet": "void\n__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)\n{\n\tatomic_long_set(&lock->owner, 0);\n\traw_spin_lock_init(&lock->wait_lock);\n\tINIT_LIST_HEAD(&lock->wait_list);\n#ifdef CONFIG_MUTEX_SPIN_ON_OWNER\n\tosq_lock_init(&lock->osq);\n#endif\n\n\tdebug_mutex_init(lock, name, key);\n}",
    "includes": [
      "#include \"ww_mutex.h\"",
      "#include \"mutex.h\"",
      "#include <linux/osq_lock.h>",
      "#include <linux/debug_locks.h>",
      "#include <linux/interrupt.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/ww_mutex.h>",
      "#include <linux/mutex.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "debug_mutex_init",
          "args": [
            "lock",
            "name",
            "key"
          ],
          "line": 52
        },
        "resolved": true,
        "details": {
          "function_name": "debug_mutex_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "79-90",
          "snippet": "void debug_mutex_init(struct mutex *lock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t/*\n\t * Make sure we are not reinitializing a held lock:\n\t */\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);\n#endif\n\tlock->magic = lock;\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid debug_mutex_init(struct mutex *lock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t/*\n\t * Make sure we are not reinitializing a held lock:\n\t */\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map_wait(&lock->dep_map, name, key, 0, LD_WAIT_SLEEP);\n#endif\n\tlock->magic = lock;\n}"
        }
      },
      {
        "call_info": {
          "callee": "osq_lock_init",
          "args": [
            "&lock->osq"
          ],
          "line": 49
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&lock->wait_list"
          ],
          "line": 47
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&lock->wait_lock"
          ],
          "line": 46
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&lock->owner",
            "0"
          ],
          "line": 45
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"ww_mutex.h\"\n#include \"mutex.h\"\n#include <linux/osq_lock.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/export.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/ww_mutex.h>\n#include <linux/mutex.h>\n\nvoid\n__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)\n{\n\tatomic_long_set(&lock->owner, 0);\n\traw_spin_lock_init(&lock->wait_lock);\n\tINIT_LIST_HEAD(&lock->wait_list);\n#ifdef CONFIG_MUTEX_SPIN_ON_OWNER\n\tosq_lock_init(&lock->osq);\n#endif\n\n\tdebug_mutex_init(lock, name, key);\n}"
  }
]