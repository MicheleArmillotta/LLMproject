[
  {
    "function_name": "futex_parse_waitv",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "197-221",
    "snippet": "static int futex_parse_waitv(struct futex_vector *futexv,\n\t\t\t     struct futex_waitv __user *uwaitv,\n\t\t\t     unsigned int nr_futexes)\n{\n\tstruct futex_waitv aux;\n\tunsigned int i;\n\n\tfor (i = 0; i < nr_futexes; i++) {\n\t\tif (copy_from_user(&aux, &uwaitv[i], sizeof(aux)))\n\t\t\treturn -EFAULT;\n\n\t\tif ((aux.flags & ~FUTEXV_WAITER_MASK) || aux.__reserved)\n\t\t\treturn -EINVAL;\n\n\t\tif (!(aux.flags & FUTEX_32))\n\t\t\treturn -EINVAL;\n\n\t\tfutexv[i].w.flags = aux.flags;\n\t\tfutexv[i].w.val = aux.val;\n\t\tfutexv[i].w.uaddr = aux.uaddr;\n\t\tfutexv[i].q = futex_q_init;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [
      "#define FUTEXV_WAITER_MASK (FUTEX_32 | FUTEX_PRIVATE_FLAG)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "&aux",
            "&uwaitv[i]",
            "sizeof(aux)"
          ],
          "line": 205
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\n#define FUTEXV_WAITER_MASK (FUTEX_32 | FUTEX_PRIVATE_FLAG)\n\nstatic int futex_parse_waitv(struct futex_vector *futexv,\n\t\t\t     struct futex_waitv __user *uwaitv,\n\t\t\t     unsigned int nr_futexes)\n{\n\tstruct futex_waitv aux;\n\tunsigned int i;\n\n\tfor (i = 0; i < nr_futexes; i++) {\n\t\tif (copy_from_user(&aux, &uwaitv[i], sizeof(aux)))\n\t\t\treturn -EFAULT;\n\n\t\tif ((aux.flags & ~FUTEXV_WAITER_MASK) || aux.__reserved)\n\t\t\treturn -EINVAL;\n\n\t\tif (!(aux.flags & FUTEX_32))\n\t\t\treturn -EINVAL;\n\n\t\tfutexv[i].w.flags = aux.flags;\n\t\tfutexv[i].w.val = aux.val;\n\t\tfutexv[i].w.uaddr = aux.uaddr;\n\t\tfutexv[i].q = futex_q_init;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "futex_init_timeout",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "150-162",
    "snippet": "static __always_inline int\nfutex_init_timeout(u32 cmd, u32 op, struct timespec64 *ts, ktime_t *t)\n{\n\tif (!timespec64_valid(ts))\n\t\treturn -EINVAL;\n\n\t*t = timespec64_to_ktime(*ts);\n\tif (cmd == FUTEX_WAIT)\n\t\t*t = ktime_add_safe(ktime_get(), *t);\n\telse if (cmd != FUTEX_LOCK_PI && !(op & FUTEX_CLOCK_REALTIME))\n\t\t*t = timens_ktime_to_host(CLOCK_MONOTONIC, *t);\n\treturn 0;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "timens_ktime_to_host",
          "args": [
            "CLOCK_MONOTONIC",
            "*t"
          ],
          "line": 160
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ktime_add_safe",
          "args": [
            "ktime_get()",
            "*t"
          ],
          "line": 158
        },
        "resolved": true,
        "details": {
          "function_name": "ktime_add_safe",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/hrtimer.c",
          "lines": "327-339",
          "snippet": "ktime_t ktime_add_safe(const ktime_t lhs, const ktime_t rhs)\n{\n\tktime_t res = ktime_add_unsafe(lhs, rhs);\n\n\t/*\n\t * We use KTIME_SEC_MAX here, the maximum timeout which we can\n\t * return to user space in a timespec:\n\t */\n\tif (res < 0 || res < lhs || res < rhs)\n\t\tres = ktime_set(KTIME_SEC_MAX, 0);\n\n\treturn res;\n}",
          "includes": [
            "#include \"tick-internal.h\"",
            "#include <trace/events/timer.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/freezer.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/debugobjects.h>",
            "#include <linux/err.h>",
            "#include <linux/tick.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/notifier.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tick-internal.h\"\n#include <trace/events/timer.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/freezer.h>\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/debugobjects.h>\n#include <linux/err.h>\n#include <linux/tick.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/notifier.h>\n#include <linux/hrtimer.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n\nktime_t ktime_add_safe(const ktime_t lhs, const ktime_t rhs)\n{\n\tktime_t res = ktime_add_unsafe(lhs, rhs);\n\n\t/*\n\t * We use KTIME_SEC_MAX here, the maximum timeout which we can\n\t * return to user space in a timespec:\n\t */\n\tif (res < 0 || res < lhs || res < rhs)\n\t\tres = ktime_set(KTIME_SEC_MAX, 0);\n\n\treturn res;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ktime_get",
          "args": [],
          "line": 158
        },
        "resolved": true,
        "details": {
          "function_name": "__ktime_get_real_seconds",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/timekeeping.c",
          "lines": "1025-1030",
          "snippet": "noinstr time64_t __ktime_get_real_seconds(void)\n{\n\tstruct timekeeper *tk = &tk_core.timekeeper;\n\n\treturn tk->xtime_sec;\n}",
          "includes": [
            "#include \"timekeeping_internal.h\"",
            "#include \"ntp_internal.h\"",
            "#include \"tick-internal.h\"",
            "#include <linux/audit.h>",
            "#include <linux/compiler.h>",
            "#include <linux/pvclock_gtod.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/tick.h>",
            "#include <linux/time.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/syscore_ops.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/module.h>",
            "#include <linux/timekeeper_internal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"timekeeping_internal.h\"\n#include \"ntp_internal.h\"\n#include \"tick-internal.h\"\n#include <linux/audit.h>\n#include <linux/compiler.h>\n#include <linux/pvclock_gtod.h>\n#include <linux/stop_machine.h>\n#include <linux/tick.h>\n#include <linux/time.h>\n#include <linux/jiffies.h>\n#include <linux/clocksource.h>\n#include <linux/syscore_ops.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched.h>\n#include <linux/nmi.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/module.h>\n#include <linux/timekeeper_internal.h>\n\nnoinstr time64_t __ktime_get_real_seconds(void)\n{\n\tstruct timekeeper *tk = &tk_core.timekeeper;\n\n\treturn tk->xtime_sec;\n}"
        }
      },
      {
        "call_info": {
          "callee": "timespec64_to_ktime",
          "args": [
            "*ts"
          ],
          "line": 156
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "timespec64_valid",
          "args": [
            "ts"
          ],
          "line": 153
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nstatic __always_inline int\nfutex_init_timeout(u32 cmd, u32 op, struct timespec64 *ts, ktime_t *t)\n{\n\tif (!timespec64_valid(ts))\n\t\treturn -EINVAL;\n\n\t*t = timespec64_to_ktime(*ts);\n\tif (cmd == FUTEX_WAIT)\n\t\t*t = ktime_add_safe(ktime_get(), *t);\n\telse if (cmd != FUTEX_LOCK_PI && !(op & FUTEX_CLOCK_REALTIME))\n\t\t*t = timens_ktime_to_host(CLOCK_MONOTONIC, *t);\n\treturn 0;\n}"
  },
  {
    "function_name": "futex_cmd_has_timeout",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "137-148",
    "snippet": "static __always_inline bool futex_cmd_has_timeout(u32 cmd)\n{\n\tswitch (cmd) {\n\tcase FUTEX_WAIT:\n\tcase FUTEX_LOCK_PI:\n\tcase FUTEX_LOCK_PI2:\n\tcase FUTEX_WAIT_BITSET:\n\tcase FUTEX_WAIT_REQUEUE_PI:\n\t\treturn true;\n\t}\n\treturn false;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nstatic __always_inline bool futex_cmd_has_timeout(u32 cmd)\n{\n\tswitch (cmd) {\n\tcase FUTEX_WAIT:\n\tcase FUTEX_LOCK_PI:\n\tcase FUTEX_LOCK_PI2:\n\tcase FUTEX_WAIT_BITSET:\n\tcase FUTEX_WAIT_REQUEUE_PI:\n\t\treturn true;\n\t}\n\treturn false;\n}"
  },
  {
    "function_name": "do_futex",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "85-135",
    "snippet": "long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,\n\t\tu32 __user *uaddr2, u32 val2, u32 val3)\n{\n\tint cmd = op & FUTEX_CMD_MASK;\n\tunsigned int flags = 0;\n\n\tif (!(op & FUTEX_PRIVATE_FLAG))\n\t\tflags |= FLAGS_SHARED;\n\n\tif (op & FUTEX_CLOCK_REALTIME) {\n\t\tflags |= FLAGS_CLOCKRT;\n\t\tif (cmd != FUTEX_WAIT_BITSET && cmd != FUTEX_WAIT_REQUEUE_PI &&\n\t\t    cmd != FUTEX_LOCK_PI2)\n\t\t\treturn -ENOSYS;\n\t}\n\n\tswitch (cmd) {\n\tcase FUTEX_WAIT:\n\t\tval3 = FUTEX_BITSET_MATCH_ANY;\n\t\tfallthrough;\n\tcase FUTEX_WAIT_BITSET:\n\t\treturn futex_wait(uaddr, flags, val, timeout, val3);\n\tcase FUTEX_WAKE:\n\t\tval3 = FUTEX_BITSET_MATCH_ANY;\n\t\tfallthrough;\n\tcase FUTEX_WAKE_BITSET:\n\t\treturn futex_wake(uaddr, flags, val, val3);\n\tcase FUTEX_REQUEUE:\n\t\treturn futex_requeue(uaddr, flags, uaddr2, val, val2, NULL, 0);\n\tcase FUTEX_CMP_REQUEUE:\n\t\treturn futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 0);\n\tcase FUTEX_WAKE_OP:\n\t\treturn futex_wake_op(uaddr, flags, uaddr2, val, val2, val3);\n\tcase FUTEX_LOCK_PI:\n\t\tflags |= FLAGS_CLOCKRT;\n\t\tfallthrough;\n\tcase FUTEX_LOCK_PI2:\n\t\treturn futex_lock_pi(uaddr, flags, timeout, 0);\n\tcase FUTEX_UNLOCK_PI:\n\t\treturn futex_unlock_pi(uaddr, flags);\n\tcase FUTEX_TRYLOCK_PI:\n\t\treturn futex_lock_pi(uaddr, flags, NULL, 1);\n\tcase FUTEX_WAIT_REQUEUE_PI:\n\t\tval3 = FUTEX_BITSET_MATCH_ANY;\n\t\treturn futex_wait_requeue_pi(uaddr, flags, val, timeout, val3,\n\t\t\t\t\t     uaddr2);\n\tcase FUTEX_CMP_REQUEUE_PI:\n\t\treturn futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 1);\n\t}\n\treturn -ENOSYS;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "futex_requeue",
          "args": [
            "uaddr",
            "flags",
            "uaddr2",
            "val",
            "val2",
            "&val3",
            "1"
          ],
          "line": 132
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "364-677",
          "snippet": "int futex_requeue(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,\n\t\t  int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * futex_requeue() allows the caller to define the number\n\t\t * of waiters to wake up via the @nr_wake argument. With\n\t\t * REQUEUE_PI, waking up more than one waiter is creating\n\t\t * more problems than it solves. Waking up a waiter makes\n\t\t * only sense if the PI futex @uaddr2 is uncontended as\n\t\t * this allows the requeue code to acquire the futex\n\t\t * @uaddr2 before waking the waiter. The waiter can then\n\t\t * return to user space without further action. A secondary\n\t\t * wakeup would just make the futex_wait_requeue_pi()\n\t\t * handling more complex, because that code would have to\n\t\t * look up pi_state and do more or less all the handling\n\t\t * which the requeue code has to do for the to be requeued\n\t\t * waiters. So restrict the number of waiters to wake to\n\t\t * one, and only wake it up when the PI futex is\n\t\t * uncontended. Otherwise requeue it and let the unlock of\n\t\t * the PI futex handle the wakeup.\n\t\t *\n\t\t * All REQUEUE_PI users, e.g. pthread_cond_signal() and\n\t\t * pthread_cond_broadcast() must use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? FUTEX_WRITE : FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && futex_match(&key1, &key2))\n\t\treturn -EINVAL;\n\n\thb1 = futex_hash(&key1);\n\thb2 = futex_hash(&key2);\n\nretry_private:\n\tfutex_hb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = futex_get_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi) {\n\t\tstruct task_struct *exiting = NULL;\n\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t *\n\t\t * Updates topwaiter::requeue_state if a top waiter exists.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state,\n\t\t\t\t\t\t &exiting, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or\n\t\t * is waiting on it. In both cases pi_state has been\n\t\t * established and an initial refcount on it. In case of an\n\t\t * error there's nothing.\n\t\t *\n\t\t * The top waiter's requeue_state is up to date:\n\t\t *\n\t\t *  - If the lock was acquired atomically (ret == 1), then\n\t\t *    the state is Q_REQUEUE_PI_LOCKED.\n\t\t *\n\t\t *    The top waiter has been dequeued and woken up and can\n\t\t *    return to user space immediately. The kernel/user\n\t\t *    space state is consistent. In case that there must be\n\t\t *    more waiters requeued the WAITERS bit in the user\n\t\t *    space futex is set so the top waiter task has to go\n\t\t *    into the syscall slowpath to unlock the futex. This\n\t\t *    will block until this requeue operation has been\n\t\t *    completed and the hash bucket locks have been\n\t\t *    dropped.\n\t\t *\n\t\t *  - If the trylock failed with an error (ret < 0) then\n\t\t *    the state is either Q_REQUEUE_PI_NONE, i.e. \"nothing\n\t\t *    happened\", or Q_REQUEUE_PI_IGNORE when there was an\n\t\t *    interleaved early wakeup.\n\t\t *\n\t\t *  - If the trylock did not succeed (ret == 0) then the\n\t\t *    state is either Q_REQUEUE_PI_IN_PROGRESS or\n\t\t *    Q_REQUEUE_PI_WAIT if an early wakeup interleaved.\n\t\t *    This will be cleaned up in the loop below, which\n\t\t *    cannot fail because futex_proxy_trylock_atomic() did\n\t\t *    the same sanity checks for requeue_pi as the loop\n\t\t *    below does.\n\t\t */\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\tcase 1:\n\t\t\t/*\n\t\t\t * futex_proxy_trylock_atomic() acquired the user space\n\t\t\t * futex. Adjust task_count.\n\t\t\t */\n\t\t\ttask_count++;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If the above failed, then pi_state is NULL and\n\t\t * waiter::requeue_state is correct.\n\t\t */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\treturn ret;\n\t\tcase -EBUSY:\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - EBUSY: Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - EAGAIN: The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\t/*\n\t\t\t * Handle the case where the owner is in the middle of\n\t\t\t * exiting. Wait for the exit to complete otherwise\n\t\t\t * this task might loop forever, aka. live lock.\n\t\t\t */\n\t\t\twait_for_owner_exiting(ret, exiting);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!futex_match(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQUEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Plain futexes just wake or requeue and are done */\n\t\tif (!requeue_pi) {\n\t\t\tif (++task_count <= nr_wake)\n\t\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\telse\n\t\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (!futex_match(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t *\n\t\t * Prepare the waiter to take the rt_mutex. Take a refcount\n\t\t * on the pi_state and store the pointer in the futex_q\n\t\t * object of the waiter.\n\t\t */\n\t\tget_pi_state(pi_state);\n\n\t\t/* Don't requeue when the waiter is already on the way out. */\n\t\tif (!futex_requeue_pi_prepare(this, pi_state)) {\n\t\t\t/*\n\t\t\t * Early woken waiter signaled that it is on the\n\t\t\t * way out. Drop the pi_state reference and try the\n\t\t\t * next waiter. @this->pi_state is still NULL.\n\t\t\t */\n\t\t\tput_pi_state(pi_state);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\tthis->task);\n\n\t\tif (ret == 1) {\n\t\t\t/*\n\t\t\t * We got the lock. We do neither drop the refcount\n\t\t\t * on pi_state nor clear this->pi_state because the\n\t\t\t * waiter needs the pi_state for cleaning up the\n\t\t\t * user space value. It will drop the refcount\n\t\t\t * after doing so. this::requeue_state is updated\n\t\t\t * in the wakeup as well.\n\t\t\t */\n\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\ttask_count++;\n\t\t} else if (!ret) {\n\t\t\t/* Waiter is queued, move it to hb2 */\n\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tfutex_requeue_pi_complete(this, 0);\n\t\t\ttask_count++;\n\t\t} else {\n\t\t\t/*\n\t\t\t * rt_mutex_start_proxy_lock() detected a potential\n\t\t\t * deadlock when we tried to queue that waiter.\n\t\t\t * Drop the pi_state reference which we took above\n\t\t\t * and remove the pointer to the state from the\n\t\t\t * waiters futex_q object.\n\t\t\t */\n\t\t\tthis->pi_state = NULL;\n\t\t\tput_pi_state(pi_state);\n\t\t\tfutex_requeue_pi_complete(this, ret);\n\t\t\t/*\n\t\t\t * We stop queueing more waiters and let user space\n\t\t\t * deal with the mess.\n\t\t\t */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state in\n\t * futex_proxy_trylock_atomic(). We need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\tfutex_hb_waiters_dec(hb2);\n\treturn ret ? ret : task_count;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nint futex_requeue(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,\n\t\t  int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * futex_requeue() allows the caller to define the number\n\t\t * of waiters to wake up via the @nr_wake argument. With\n\t\t * REQUEUE_PI, waking up more than one waiter is creating\n\t\t * more problems than it solves. Waking up a waiter makes\n\t\t * only sense if the PI futex @uaddr2 is uncontended as\n\t\t * this allows the requeue code to acquire the futex\n\t\t * @uaddr2 before waking the waiter. The waiter can then\n\t\t * return to user space without further action. A secondary\n\t\t * wakeup would just make the futex_wait_requeue_pi()\n\t\t * handling more complex, because that code would have to\n\t\t * look up pi_state and do more or less all the handling\n\t\t * which the requeue code has to do for the to be requeued\n\t\t * waiters. So restrict the number of waiters to wake to\n\t\t * one, and only wake it up when the PI futex is\n\t\t * uncontended. Otherwise requeue it and let the unlock of\n\t\t * the PI futex handle the wakeup.\n\t\t *\n\t\t * All REQUEUE_PI users, e.g. pthread_cond_signal() and\n\t\t * pthread_cond_broadcast() must use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? FUTEX_WRITE : FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && futex_match(&key1, &key2))\n\t\treturn -EINVAL;\n\n\thb1 = futex_hash(&key1);\n\thb2 = futex_hash(&key2);\n\nretry_private:\n\tfutex_hb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = futex_get_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi) {\n\t\tstruct task_struct *exiting = NULL;\n\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t *\n\t\t * Updates topwaiter::requeue_state if a top waiter exists.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state,\n\t\t\t\t\t\t &exiting, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or\n\t\t * is waiting on it. In both cases pi_state has been\n\t\t * established and an initial refcount on it. In case of an\n\t\t * error there's nothing.\n\t\t *\n\t\t * The top waiter's requeue_state is up to date:\n\t\t *\n\t\t *  - If the lock was acquired atomically (ret == 1), then\n\t\t *    the state is Q_REQUEUE_PI_LOCKED.\n\t\t *\n\t\t *    The top waiter has been dequeued and woken up and can\n\t\t *    return to user space immediately. The kernel/user\n\t\t *    space state is consistent. In case that there must be\n\t\t *    more waiters requeued the WAITERS bit in the user\n\t\t *    space futex is set so the top waiter task has to go\n\t\t *    into the syscall slowpath to unlock the futex. This\n\t\t *    will block until this requeue operation has been\n\t\t *    completed and the hash bucket locks have been\n\t\t *    dropped.\n\t\t *\n\t\t *  - If the trylock failed with an error (ret < 0) then\n\t\t *    the state is either Q_REQUEUE_PI_NONE, i.e. \"nothing\n\t\t *    happened\", or Q_REQUEUE_PI_IGNORE when there was an\n\t\t *    interleaved early wakeup.\n\t\t *\n\t\t *  - If the trylock did not succeed (ret == 0) then the\n\t\t *    state is either Q_REQUEUE_PI_IN_PROGRESS or\n\t\t *    Q_REQUEUE_PI_WAIT if an early wakeup interleaved.\n\t\t *    This will be cleaned up in the loop below, which\n\t\t *    cannot fail because futex_proxy_trylock_atomic() did\n\t\t *    the same sanity checks for requeue_pi as the loop\n\t\t *    below does.\n\t\t */\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\tcase 1:\n\t\t\t/*\n\t\t\t * futex_proxy_trylock_atomic() acquired the user space\n\t\t\t * futex. Adjust task_count.\n\t\t\t */\n\t\t\ttask_count++;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If the above failed, then pi_state is NULL and\n\t\t * waiter::requeue_state is correct.\n\t\t */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\treturn ret;\n\t\tcase -EBUSY:\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - EBUSY: Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - EAGAIN: The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\t/*\n\t\t\t * Handle the case where the owner is in the middle of\n\t\t\t * exiting. Wait for the exit to complete otherwise\n\t\t\t * this task might loop forever, aka. live lock.\n\t\t\t */\n\t\t\twait_for_owner_exiting(ret, exiting);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!futex_match(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQUEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Plain futexes just wake or requeue and are done */\n\t\tif (!requeue_pi) {\n\t\t\tif (++task_count <= nr_wake)\n\t\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\telse\n\t\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (!futex_match(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t *\n\t\t * Prepare the waiter to take the rt_mutex. Take a refcount\n\t\t * on the pi_state and store the pointer in the futex_q\n\t\t * object of the waiter.\n\t\t */\n\t\tget_pi_state(pi_state);\n\n\t\t/* Don't requeue when the waiter is already on the way out. */\n\t\tif (!futex_requeue_pi_prepare(this, pi_state)) {\n\t\t\t/*\n\t\t\t * Early woken waiter signaled that it is on the\n\t\t\t * way out. Drop the pi_state reference and try the\n\t\t\t * next waiter. @this->pi_state is still NULL.\n\t\t\t */\n\t\t\tput_pi_state(pi_state);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\tthis->task);\n\n\t\tif (ret == 1) {\n\t\t\t/*\n\t\t\t * We got the lock. We do neither drop the refcount\n\t\t\t * on pi_state nor clear this->pi_state because the\n\t\t\t * waiter needs the pi_state for cleaning up the\n\t\t\t * user space value. It will drop the refcount\n\t\t\t * after doing so. this::requeue_state is updated\n\t\t\t * in the wakeup as well.\n\t\t\t */\n\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\ttask_count++;\n\t\t} else if (!ret) {\n\t\t\t/* Waiter is queued, move it to hb2 */\n\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tfutex_requeue_pi_complete(this, 0);\n\t\t\ttask_count++;\n\t\t} else {\n\t\t\t/*\n\t\t\t * rt_mutex_start_proxy_lock() detected a potential\n\t\t\t * deadlock when we tried to queue that waiter.\n\t\t\t * Drop the pi_state reference which we took above\n\t\t\t * and remove the pointer to the state from the\n\t\t\t * waiters futex_q object.\n\t\t\t */\n\t\t\tthis->pi_state = NULL;\n\t\t\tput_pi_state(pi_state);\n\t\t\tfutex_requeue_pi_complete(this, ret);\n\t\t\t/*\n\t\t\t * We stop queueing more waiters and let user space\n\t\t\t * deal with the mess.\n\t\t\t */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state in\n\t * futex_proxy_trylock_atomic(). We need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\tfutex_hb_waiters_dec(hb2);\n\treturn ret ? ret : task_count;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wait_requeue_pi",
          "args": [
            "uaddr",
            "flags",
            "val",
            "timeout",
            "val3",
            "uaddr2"
          ],
          "line": 129
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wait_requeue_pi",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "762-896",
          "snippet": "int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,\n\t\t\t  u32 val, ktime_t *abs_time, u32 bitset,\n\t\t\t  u32 __user *uaddr2)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct futex_hash_bucket *hb;\n\tunion futex_key key2 = FUTEX_KEY_INIT;\n\tstruct futex_q q = futex_q_init;\n\tstruct rt_mutex_base *pi_mutex;\n\tint res, ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\n\tif (uaddr == uaddr2)\n\t\treturn -EINVAL;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tto = futex_setup_timer(abs_time, &timeout, flags,\n\t\t\t       current->timer_slack_ns);\n\n\t/*\n\t * The waiter is allocated on our stack, manipulated by the requeue\n\t * code while we sleep on uaddr.\n\t */\n\trt_mutex_init_waiter(&rt_waiter);\n\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\n\tq.bitset = bitset;\n\tq.rt_waiter = &rt_waiter;\n\tq.requeue_pi_key = &key2;\n\n\t/*\n\t * Prepare to wait on uaddr. On success, it holds hb->lock and q\n\t * is initialized.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (futex_match(&q.key, &key2)) {\n\t\tfutex_q_unlock(hb);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */\n\tfutex_wait_queue(hb, &q, to);\n\n\tswitch (futex_requeue_pi_wakeup_sync(&q)) {\n\tcase Q_REQUEUE_PI_IGNORE:\n\t\t/* The waiter is still on uaddr1 */\n\t\tspin_lock(&hb->lock);\n\t\tret = handle_early_requeue_pi_wakeup(hb, &q, to);\n\t\tspin_unlock(&hb->lock);\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_LOCKED:\n\t\t/* The requeue acquired the lock */\n\t\tif (q.pi_state && (q.pi_state->owner != current)) {\n\t\t\tspin_lock(q.lock_ptr);\n\t\t\tret = fixup_pi_owner(uaddr2, &q, true);\n\t\t\t/*\n\t\t\t * Drop the reference to the pi state which the\n\t\t\t * requeue_pi() code acquired for us.\n\t\t\t */\n\t\t\tput_pi_state(q.pi_state);\n\t\t\tspin_unlock(q.lock_ptr);\n\t\t\t/*\n\t\t\t * Adjust the return value. It's either -EFAULT or\n\t\t\t * success (1) but the caller expects 0 for success.\n\t\t\t */\n\t\t\tret = ret < 0 ? ret : 0;\n\t\t}\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_DONE:\n\t\t/* Requeue completed. Current is 'pi_blocked_on' the rtmutex */\n\t\tpi_mutex = &q.pi_state->pi_mutex;\n\t\tret = rt_mutex_wait_proxy_lock(pi_mutex, to, &rt_waiter);\n\n\t\t/* Current is not longer pi_blocked_on */\n\t\tspin_lock(q.lock_ptr);\n\t\tif (ret && !rt_mutex_cleanup_proxy_lock(pi_mutex, &rt_waiter))\n\t\t\tret = 0;\n\n\t\tdebug_rt_mutex_free_waiter(&rt_waiter);\n\t\t/*\n\t\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t\t * haven't already.\n\t\t */\n\t\tres = fixup_pi_owner(uaddr2, &q, !ret);\n\t\t/*\n\t\t * If fixup_pi_owner() returned an error, propagate that.  If it\n\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.\n\t\t */\n\t\tif (res)\n\t\t\tret = (res < 0) ? res : 0;\n\n\t\tfutex_unqueue_pi(&q);\n\t\tspin_unlock(q.lock_ptr);\n\n\t\tif (ret == -EINTR) {\n\t\t\t/*\n\t\t\t * We've already been requeued, but cannot restart\n\t\t\t * by calling futex_lock_pi() directly. We could\n\t\t\t * restart this syscall, but it would detect that\n\t\t\t * the user space \"val\" changed and return\n\t\t\t * -EWOULDBLOCK.  Save the overhead of the restart\n\t\t\t * and return -EWOULDBLOCK directly.\n\t\t\t */\n\t\t\tret = -EWOULDBLOCK;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "const struct futex_q futex_q_init = {\n\t/* list gets initialized in futex_queue()*/\n\t.key\t\t= FUTEX_KEY_INIT,\n\t.bitset\t\t= FUTEX_BITSET_MATCH_ANY,\n\t.requeue_state\t= ATOMIC_INIT(Q_REQUEUE_PI_NONE),\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nconst struct futex_q futex_q_init = {\n\t/* list gets initialized in futex_queue()*/\n\t.key\t\t= FUTEX_KEY_INIT,\n\t.bitset\t\t= FUTEX_BITSET_MATCH_ANY,\n\t.requeue_state\t= ATOMIC_INIT(Q_REQUEUE_PI_NONE),\n};\n\nint futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,\n\t\t\t  u32 val, ktime_t *abs_time, u32 bitset,\n\t\t\t  u32 __user *uaddr2)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct futex_hash_bucket *hb;\n\tunion futex_key key2 = FUTEX_KEY_INIT;\n\tstruct futex_q q = futex_q_init;\n\tstruct rt_mutex_base *pi_mutex;\n\tint res, ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\n\tif (uaddr == uaddr2)\n\t\treturn -EINVAL;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tto = futex_setup_timer(abs_time, &timeout, flags,\n\t\t\t       current->timer_slack_ns);\n\n\t/*\n\t * The waiter is allocated on our stack, manipulated by the requeue\n\t * code while we sleep on uaddr.\n\t */\n\trt_mutex_init_waiter(&rt_waiter);\n\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\n\tq.bitset = bitset;\n\tq.rt_waiter = &rt_waiter;\n\tq.requeue_pi_key = &key2;\n\n\t/*\n\t * Prepare to wait on uaddr. On success, it holds hb->lock and q\n\t * is initialized.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (futex_match(&q.key, &key2)) {\n\t\tfutex_q_unlock(hb);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */\n\tfutex_wait_queue(hb, &q, to);\n\n\tswitch (futex_requeue_pi_wakeup_sync(&q)) {\n\tcase Q_REQUEUE_PI_IGNORE:\n\t\t/* The waiter is still on uaddr1 */\n\t\tspin_lock(&hb->lock);\n\t\tret = handle_early_requeue_pi_wakeup(hb, &q, to);\n\t\tspin_unlock(&hb->lock);\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_LOCKED:\n\t\t/* The requeue acquired the lock */\n\t\tif (q.pi_state && (q.pi_state->owner != current)) {\n\t\t\tspin_lock(q.lock_ptr);\n\t\t\tret = fixup_pi_owner(uaddr2, &q, true);\n\t\t\t/*\n\t\t\t * Drop the reference to the pi state which the\n\t\t\t * requeue_pi() code acquired for us.\n\t\t\t */\n\t\t\tput_pi_state(q.pi_state);\n\t\t\tspin_unlock(q.lock_ptr);\n\t\t\t/*\n\t\t\t * Adjust the return value. It's either -EFAULT or\n\t\t\t * success (1) but the caller expects 0 for success.\n\t\t\t */\n\t\t\tret = ret < 0 ? ret : 0;\n\t\t}\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_DONE:\n\t\t/* Requeue completed. Current is 'pi_blocked_on' the rtmutex */\n\t\tpi_mutex = &q.pi_state->pi_mutex;\n\t\tret = rt_mutex_wait_proxy_lock(pi_mutex, to, &rt_waiter);\n\n\t\t/* Current is not longer pi_blocked_on */\n\t\tspin_lock(q.lock_ptr);\n\t\tif (ret && !rt_mutex_cleanup_proxy_lock(pi_mutex, &rt_waiter))\n\t\t\tret = 0;\n\n\t\tdebug_rt_mutex_free_waiter(&rt_waiter);\n\t\t/*\n\t\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t\t * haven't already.\n\t\t */\n\t\tres = fixup_pi_owner(uaddr2, &q, !ret);\n\t\t/*\n\t\t * If fixup_pi_owner() returned an error, propagate that.  If it\n\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.\n\t\t */\n\t\tif (res)\n\t\t\tret = (res < 0) ? res : 0;\n\n\t\tfutex_unqueue_pi(&q);\n\t\tspin_unlock(q.lock_ptr);\n\n\t\tif (ret == -EINTR) {\n\t\t\t/*\n\t\t\t * We've already been requeued, but cannot restart\n\t\t\t * by calling futex_lock_pi() directly. We could\n\t\t\t * restart this syscall, but it would detect that\n\t\t\t * the user space \"val\" changed and return\n\t\t\t * -EWOULDBLOCK.  Save the overhead of the restart\n\t\t\t * and return -EWOULDBLOCK directly.\n\t\t\t */\n\t\t\tret = -EWOULDBLOCK;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_lock_pi",
          "args": [
            "uaddr",
            "flags",
            "NULL",
            "1"
          ],
          "line": 126
        },
        "resolved": true,
        "details": {
          "function_name": "futex_lock_pi",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "930-1093",
          "snippet": "int futex_lock_pi(u32 __user *uaddr, unsigned int flags, ktime_t *time, int trylock)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct task_struct *exiting = NULL;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q q = futex_q_init;\n\tint res, ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\n\tif (refill_pi_state_cache())\n\t\treturn -ENOMEM;\n\n\tto = futex_setup_timer(time, &timeout, flags, 0);\n\nretry:\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &q.key, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\nretry_private:\n\thb = futex_q_lock(&q);\n\n\tret = futex_lock_pi_atomic(uaddr, hb, &q.key, &q.pi_state, current,\n\t\t\t\t   &exiting, 0);\n\tif (unlikely(ret)) {\n\t\t/*\n\t\t * Atomic work succeeded and we got the lock,\n\t\t * or failed. Either way, we do _not_ block.\n\t\t */\n\t\tswitch (ret) {\n\t\tcase 1:\n\t\t\t/* We got the lock. */\n\t\t\tret = 0;\n\t\t\tgoto out_unlock_put_key;\n\t\tcase -EFAULT:\n\t\t\tgoto uaddr_faulted;\n\t\tcase -EBUSY:\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - EBUSY: Task is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - EAGAIN: The user space value changed.\n\t\t\t */\n\t\t\tfutex_q_unlock(hb);\n\t\t\t/*\n\t\t\t * Handle the case where the owner is in the middle of\n\t\t\t * exiting. Wait for the exit to complete otherwise\n\t\t\t * this task might loop forever, aka. live lock.\n\t\t\t */\n\t\t\twait_for_owner_exiting(ret, exiting);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock_put_key;\n\t\t}\n\t}\n\n\tWARN_ON(!q.pi_state);\n\n\t/*\n\t * Only actually queue now that the atomic ops are done:\n\t */\n\t__futex_queue(&q, hb);\n\n\tif (trylock) {\n\t\tret = rt_mutex_futex_trylock(&q.pi_state->pi_mutex);\n\t\t/* Fixup the trylock return value: */\n\t\tret = ret ? 0 : -EWOULDBLOCK;\n\t\tgoto no_block;\n\t}\n\n\trt_mutex_init_waiter(&rt_waiter);\n\n\t/*\n\t * On PREEMPT_RT_FULL, when hb->lock becomes an rt_mutex, we must not\n\t * hold it while doing rt_mutex_start_proxy(), because then it will\n\t * include hb->lock in the blocking chain, even through we'll not in\n\t * fact hold it while blocking. This will lead it to report -EDEADLK\n\t * and BUG when futex_unlock_pi() interleaves with this.\n\t *\n\t * Therefore acquire wait_lock while holding hb->lock, but drop the\n\t * latter before calling __rt_mutex_start_proxy_lock(). This\n\t * interleaves with futex_unlock_pi() -- which does a similar lock\n\t * handoff -- such that the latter can observe the futex_q::pi_state\n\t * before __rt_mutex_start_proxy_lock() is done.\n\t */\n\traw_spin_lock_irq(&q.pi_state->pi_mutex.wait_lock);\n\tspin_unlock(q.lock_ptr);\n\t/*\n\t * __rt_mutex_start_proxy_lock() unconditionally enqueues the @rt_waiter\n\t * such that futex_unlock_pi() is guaranteed to observe the waiter when\n\t * it sees the futex_q::pi_state.\n\t */\n\tret = __rt_mutex_start_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter, current);\n\traw_spin_unlock_irq(&q.pi_state->pi_mutex.wait_lock);\n\n\tif (ret) {\n\t\tif (ret == 1)\n\t\t\tret = 0;\n\t\tgoto cleanup;\n\t}\n\n\tif (unlikely(to))\n\t\thrtimer_sleeper_start_expires(to, HRTIMER_MODE_ABS);\n\n\tret = rt_mutex_wait_proxy_lock(&q.pi_state->pi_mutex, to, &rt_waiter);\n\ncleanup:\n\tspin_lock(q.lock_ptr);\n\t/*\n\t * If we failed to acquire the lock (deadlock/signal/timeout), we must\n\t * first acquire the hb->lock before removing the lock from the\n\t * rt_mutex waitqueue, such that we can keep the hb and rt_mutex wait\n\t * lists consistent.\n\t *\n\t * In particular; it is important that futex_unlock_pi() can not\n\t * observe this inconsistency.\n\t */\n\tif (ret && !rt_mutex_cleanup_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter))\n\t\tret = 0;\n\nno_block:\n\t/*\n\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t * haven't already.\n\t */\n\tres = fixup_pi_owner(uaddr, &q, !ret);\n\t/*\n\t * If fixup_pi_owner() returned an error, propagate that.  If it acquired\n\t * the lock, clear our -ETIMEDOUT or -EINTR.\n\t */\n\tif (res)\n\t\tret = (res < 0) ? res : 0;\n\n\tfutex_unqueue_pi(&q);\n\tspin_unlock(q.lock_ptr);\n\tgoto out;\n\nout_unlock_put_key:\n\tfutex_q_unlock(hb);\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret != -EINTR ? ret : -ERESTARTNOINTR;\n\nuaddr_faulted:\n\tfutex_q_unlock(hb);\n\n\tret = fault_in_user_writeable(uaddr);\n\tif (ret)\n\t\tgoto out;\n\n\tif (!(flags & FLAGS_SHARED))\n\t\tgoto retry_private;\n\n\tgoto retry;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nint futex_lock_pi(u32 __user *uaddr, unsigned int flags, ktime_t *time, int trylock)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct task_struct *exiting = NULL;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q q = futex_q_init;\n\tint res, ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\n\tif (refill_pi_state_cache())\n\t\treturn -ENOMEM;\n\n\tto = futex_setup_timer(time, &timeout, flags, 0);\n\nretry:\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &q.key, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\nretry_private:\n\thb = futex_q_lock(&q);\n\n\tret = futex_lock_pi_atomic(uaddr, hb, &q.key, &q.pi_state, current,\n\t\t\t\t   &exiting, 0);\n\tif (unlikely(ret)) {\n\t\t/*\n\t\t * Atomic work succeeded and we got the lock,\n\t\t * or failed. Either way, we do _not_ block.\n\t\t */\n\t\tswitch (ret) {\n\t\tcase 1:\n\t\t\t/* We got the lock. */\n\t\t\tret = 0;\n\t\t\tgoto out_unlock_put_key;\n\t\tcase -EFAULT:\n\t\t\tgoto uaddr_faulted;\n\t\tcase -EBUSY:\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - EBUSY: Task is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - EAGAIN: The user space value changed.\n\t\t\t */\n\t\t\tfutex_q_unlock(hb);\n\t\t\t/*\n\t\t\t * Handle the case where the owner is in the middle of\n\t\t\t * exiting. Wait for the exit to complete otherwise\n\t\t\t * this task might loop forever, aka. live lock.\n\t\t\t */\n\t\t\twait_for_owner_exiting(ret, exiting);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock_put_key;\n\t\t}\n\t}\n\n\tWARN_ON(!q.pi_state);\n\n\t/*\n\t * Only actually queue now that the atomic ops are done:\n\t */\n\t__futex_queue(&q, hb);\n\n\tif (trylock) {\n\t\tret = rt_mutex_futex_trylock(&q.pi_state->pi_mutex);\n\t\t/* Fixup the trylock return value: */\n\t\tret = ret ? 0 : -EWOULDBLOCK;\n\t\tgoto no_block;\n\t}\n\n\trt_mutex_init_waiter(&rt_waiter);\n\n\t/*\n\t * On PREEMPT_RT_FULL, when hb->lock becomes an rt_mutex, we must not\n\t * hold it while doing rt_mutex_start_proxy(), because then it will\n\t * include hb->lock in the blocking chain, even through we'll not in\n\t * fact hold it while blocking. This will lead it to report -EDEADLK\n\t * and BUG when futex_unlock_pi() interleaves with this.\n\t *\n\t * Therefore acquire wait_lock while holding hb->lock, but drop the\n\t * latter before calling __rt_mutex_start_proxy_lock(). This\n\t * interleaves with futex_unlock_pi() -- which does a similar lock\n\t * handoff -- such that the latter can observe the futex_q::pi_state\n\t * before __rt_mutex_start_proxy_lock() is done.\n\t */\n\traw_spin_lock_irq(&q.pi_state->pi_mutex.wait_lock);\n\tspin_unlock(q.lock_ptr);\n\t/*\n\t * __rt_mutex_start_proxy_lock() unconditionally enqueues the @rt_waiter\n\t * such that futex_unlock_pi() is guaranteed to observe the waiter when\n\t * it sees the futex_q::pi_state.\n\t */\n\tret = __rt_mutex_start_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter, current);\n\traw_spin_unlock_irq(&q.pi_state->pi_mutex.wait_lock);\n\n\tif (ret) {\n\t\tif (ret == 1)\n\t\t\tret = 0;\n\t\tgoto cleanup;\n\t}\n\n\tif (unlikely(to))\n\t\thrtimer_sleeper_start_expires(to, HRTIMER_MODE_ABS);\n\n\tret = rt_mutex_wait_proxy_lock(&q.pi_state->pi_mutex, to, &rt_waiter);\n\ncleanup:\n\tspin_lock(q.lock_ptr);\n\t/*\n\t * If we failed to acquire the lock (deadlock/signal/timeout), we must\n\t * first acquire the hb->lock before removing the lock from the\n\t * rt_mutex waitqueue, such that we can keep the hb and rt_mutex wait\n\t * lists consistent.\n\t *\n\t * In particular; it is important that futex_unlock_pi() can not\n\t * observe this inconsistency.\n\t */\n\tif (ret && !rt_mutex_cleanup_proxy_lock(&q.pi_state->pi_mutex, &rt_waiter))\n\t\tret = 0;\n\nno_block:\n\t/*\n\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t * haven't already.\n\t */\n\tres = fixup_pi_owner(uaddr, &q, !ret);\n\t/*\n\t * If fixup_pi_owner() returned an error, propagate that.  If it acquired\n\t * the lock, clear our -ETIMEDOUT or -EINTR.\n\t */\n\tif (res)\n\t\tret = (res < 0) ? res : 0;\n\n\tfutex_unqueue_pi(&q);\n\tspin_unlock(q.lock_ptr);\n\tgoto out;\n\nout_unlock_put_key:\n\tfutex_q_unlock(hb);\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret != -EINTR ? ret : -ERESTARTNOINTR;\n\nuaddr_faulted:\n\tfutex_q_unlock(hb);\n\n\tret = fault_in_user_writeable(uaddr);\n\tif (ret)\n\t\tgoto out;\n\n\tif (!(flags & FLAGS_SHARED))\n\t\tgoto retry_private;\n\n\tgoto retry;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_unlock_pi",
          "args": [
            "uaddr",
            "flags"
          ],
          "line": 124
        },
        "resolved": true,
        "details": {
          "function_name": "futex_unlock_pi",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "1100-1232",
          "snippet": "int futex_unlock_pi(u32 __user *uaddr, unsigned int flags)\n{\n\tu32 curval, uval, vpid = task_pid_vnr(current);\n\tunion futex_key key = FUTEX_KEY_INIT;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q *top_waiter;\n\tint ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\nretry:\n\tif (get_user(uval, uaddr))\n\t\treturn -EFAULT;\n\t/*\n\t * We release only a lock we actually own:\n\t */\n\tif ((uval & FUTEX_TID_MASK) != vpid)\n\t\treturn -EPERM;\n\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &key, FUTEX_WRITE);\n\tif (ret)\n\t\treturn ret;\n\n\thb = futex_hash(&key);\n\tspin_lock(&hb->lock);\n\n\t/*\n\t * Check waiters first. We do not trust user space values at\n\t * all and we at least want to know if user space fiddled\n\t * with the futex value instead of blindly unlocking.\n\t */\n\ttop_waiter = futex_top_waiter(hb, &key);\n\tif (top_waiter) {\n\t\tstruct futex_pi_state *pi_state = top_waiter->pi_state;\n\n\t\tret = -EINVAL;\n\t\tif (!pi_state)\n\t\t\tgoto out_unlock;\n\n\t\t/*\n\t\t * If current does not own the pi_state then the futex is\n\t\t * inconsistent and user space fiddled with the futex value.\n\t\t */\n\t\tif (pi_state->owner != current)\n\t\t\tgoto out_unlock;\n\n\t\tget_pi_state(pi_state);\n\t\t/*\n\t\t * By taking wait_lock while still holding hb->lock, we ensure\n\t\t * there is no point where we hold neither; and therefore\n\t\t * wake_futex_p() must observe a state consistent with what we\n\t\t * observed.\n\t\t *\n\t\t * In particular; this forces __rt_mutex_start_proxy() to\n\t\t * complete such that we're guaranteed to observe the\n\t\t * rt_waiter. Also see the WARN in wake_futex_pi().\n\t\t */\n\t\traw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);\n\t\tspin_unlock(&hb->lock);\n\n\t\t/* drops pi_state->pi_mutex.wait_lock */\n\t\tret = wake_futex_pi(uaddr, uval, pi_state);\n\n\t\tput_pi_state(pi_state);\n\n\t\t/*\n\t\t * Success, we're done! No tricky corner cases.\n\t\t */\n\t\tif (!ret)\n\t\t\treturn ret;\n\t\t/*\n\t\t * The atomic access to the futex value generated a\n\t\t * pagefault, so retry the user-access and the wakeup:\n\t\t */\n\t\tif (ret == -EFAULT)\n\t\t\tgoto pi_faulted;\n\t\t/*\n\t\t * A unconditional UNLOCK_PI op raced against a waiter\n\t\t * setting the FUTEX_WAITERS bit. Try again.\n\t\t */\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto pi_retry;\n\t\t/*\n\t\t * wake_futex_pi has detected invalid state. Tell user\n\t\t * space.\n\t\t */\n\t\treturn ret;\n\t}\n\n\t/*\n\t * We have no kernel internal state, i.e. no waiters in the\n\t * kernel. Waiters which are about to queue themselves are stuck\n\t * on hb->lock. So we can safely ignore them. We do neither\n\t * preserve the WAITERS bit not the OWNER_DIED one. We are the\n\t * owner.\n\t */\n\tif ((ret = futex_cmpxchg_value_locked(&curval, uaddr, uval, 0))) {\n\t\tspin_unlock(&hb->lock);\n\t\tswitch (ret) {\n\t\tcase -EFAULT:\n\t\t\tgoto pi_faulted;\n\n\t\tcase -EAGAIN:\n\t\t\tgoto pi_retry;\n\n\t\tdefault:\n\t\t\tWARN_ON_ONCE(1);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t/*\n\t * If uval has changed, let user space handle it.\n\t */\n\tret = (curval == uval) ? 0 : -EAGAIN;\n\nout_unlock:\n\tspin_unlock(&hb->lock);\n\treturn ret;\n\npi_retry:\n\tcond_resched();\n\tgoto retry;\n\npi_faulted:\n\n\tret = fault_in_user_writeable(uaddr);\n\tif (!ret)\n\t\tgoto retry;\n\n\treturn ret;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nint futex_unlock_pi(u32 __user *uaddr, unsigned int flags)\n{\n\tu32 curval, uval, vpid = task_pid_vnr(current);\n\tunion futex_key key = FUTEX_KEY_INIT;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q *top_waiter;\n\tint ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\nretry:\n\tif (get_user(uval, uaddr))\n\t\treturn -EFAULT;\n\t/*\n\t * We release only a lock we actually own:\n\t */\n\tif ((uval & FUTEX_TID_MASK) != vpid)\n\t\treturn -EPERM;\n\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &key, FUTEX_WRITE);\n\tif (ret)\n\t\treturn ret;\n\n\thb = futex_hash(&key);\n\tspin_lock(&hb->lock);\n\n\t/*\n\t * Check waiters first. We do not trust user space values at\n\t * all and we at least want to know if user space fiddled\n\t * with the futex value instead of blindly unlocking.\n\t */\n\ttop_waiter = futex_top_waiter(hb, &key);\n\tif (top_waiter) {\n\t\tstruct futex_pi_state *pi_state = top_waiter->pi_state;\n\n\t\tret = -EINVAL;\n\t\tif (!pi_state)\n\t\t\tgoto out_unlock;\n\n\t\t/*\n\t\t * If current does not own the pi_state then the futex is\n\t\t * inconsistent and user space fiddled with the futex value.\n\t\t */\n\t\tif (pi_state->owner != current)\n\t\t\tgoto out_unlock;\n\n\t\tget_pi_state(pi_state);\n\t\t/*\n\t\t * By taking wait_lock while still holding hb->lock, we ensure\n\t\t * there is no point where we hold neither; and therefore\n\t\t * wake_futex_p() must observe a state consistent with what we\n\t\t * observed.\n\t\t *\n\t\t * In particular; this forces __rt_mutex_start_proxy() to\n\t\t * complete such that we're guaranteed to observe the\n\t\t * rt_waiter. Also see the WARN in wake_futex_pi().\n\t\t */\n\t\traw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);\n\t\tspin_unlock(&hb->lock);\n\n\t\t/* drops pi_state->pi_mutex.wait_lock */\n\t\tret = wake_futex_pi(uaddr, uval, pi_state);\n\n\t\tput_pi_state(pi_state);\n\n\t\t/*\n\t\t * Success, we're done! No tricky corner cases.\n\t\t */\n\t\tif (!ret)\n\t\t\treturn ret;\n\t\t/*\n\t\t * The atomic access to the futex value generated a\n\t\t * pagefault, so retry the user-access and the wakeup:\n\t\t */\n\t\tif (ret == -EFAULT)\n\t\t\tgoto pi_faulted;\n\t\t/*\n\t\t * A unconditional UNLOCK_PI op raced against a waiter\n\t\t * setting the FUTEX_WAITERS bit. Try again.\n\t\t */\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto pi_retry;\n\t\t/*\n\t\t * wake_futex_pi has detected invalid state. Tell user\n\t\t * space.\n\t\t */\n\t\treturn ret;\n\t}\n\n\t/*\n\t * We have no kernel internal state, i.e. no waiters in the\n\t * kernel. Waiters which are about to queue themselves are stuck\n\t * on hb->lock. So we can safely ignore them. We do neither\n\t * preserve the WAITERS bit not the OWNER_DIED one. We are the\n\t * owner.\n\t */\n\tif ((ret = futex_cmpxchg_value_locked(&curval, uaddr, uval, 0))) {\n\t\tspin_unlock(&hb->lock);\n\t\tswitch (ret) {\n\t\tcase -EFAULT:\n\t\t\tgoto pi_faulted;\n\n\t\tcase -EAGAIN:\n\t\t\tgoto pi_retry;\n\n\t\tdefault:\n\t\t\tWARN_ON_ONCE(1);\n\t\t\treturn ret;\n\t\t}\n\t}\n\n\t/*\n\t * If uval has changed, let user space handle it.\n\t */\n\tret = (curval == uval) ? 0 : -EAGAIN;\n\nout_unlock:\n\tspin_unlock(&hb->lock);\n\treturn ret;\n\npi_retry:\n\tcond_resched();\n\tgoto retry;\n\npi_faulted:\n\n\tret = fault_in_user_writeable(uaddr);\n\tif (!ret)\n\t\tgoto retry;\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wake_op",
          "args": [
            "uaddr",
            "flags",
            "uaddr2",
            "val",
            "val2",
            "val3"
          ],
          "line": 117
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wake_op",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/waitwake.c",
          "lines": "238-318",
          "snippet": "int futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,\n\t\t  int nr_wake, int nr_wake2, int op)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tint ret, op_ret;\n\tDEFINE_WAKE_Q(wake_q);\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\thb1 = futex_hash(&key1);\n\thb2 = futex_hash(&key2);\n\nretry_private:\n\tdouble_lock_hb(hb1, hb2);\n\top_ret = futex_atomic_op_inuser(op, uaddr2);\n\tif (unlikely(op_ret < 0)) {\n\t\tdouble_unlock_hb(hb1, hb2);\n\n\t\tif (!IS_ENABLED(CONFIG_MMU) ||\n\t\t    unlikely(op_ret != -EFAULT && op_ret != -EAGAIN)) {\n\t\t\t/*\n\t\t\t * we don't get EFAULT from MMU faults if we don't have\n\t\t\t * an MMU, but we might get them from range checking\n\t\t\t */\n\t\t\tret = op_ret;\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (op_ret == -EFAULT) {\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tcond_resched();\n\t\tif (!(flags & FLAGS_SHARED))\n\t\t\tgoto retry_private;\n\t\tgoto retry;\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (futex_match (&this->key, &key1)) {\n\t\t\tif (this->pi_state || this->rt_waiter) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\tif (++ret >= nr_wake)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (op_ret > 0) {\n\t\top_ret = 0;\n\t\tplist_for_each_entry_safe(this, next, &hb2->chain, list) {\n\t\t\tif (futex_match (&this->key, &key2)) {\n\t\t\t\tif (this->pi_state || this->rt_waiter) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\t\tif (++op_ret >= nr_wake2)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tret += op_ret;\n\t}\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\treturn ret;\n}",
          "includes": [
            "#include \"futex.h\"",
            "#include <linux/freezer.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"futex.h\"\n#include <linux/freezer.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n\nint futex_wake_op(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,\n\t\t  int nr_wake, int nr_wake2, int op)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tint ret, op_ret;\n\tDEFINE_WAKE_Q(wake_q);\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\thb1 = futex_hash(&key1);\n\thb2 = futex_hash(&key2);\n\nretry_private:\n\tdouble_lock_hb(hb1, hb2);\n\top_ret = futex_atomic_op_inuser(op, uaddr2);\n\tif (unlikely(op_ret < 0)) {\n\t\tdouble_unlock_hb(hb1, hb2);\n\n\t\tif (!IS_ENABLED(CONFIG_MMU) ||\n\t\t    unlikely(op_ret != -EFAULT && op_ret != -EAGAIN)) {\n\t\t\t/*\n\t\t\t * we don't get EFAULT from MMU faults if we don't have\n\t\t\t * an MMU, but we might get them from range checking\n\t\t\t */\n\t\t\tret = op_ret;\n\t\t\treturn ret;\n\t\t}\n\n\t\tif (op_ret == -EFAULT) {\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\t\t}\n\n\t\tcond_resched();\n\t\tif (!(flags & FLAGS_SHARED))\n\t\t\tgoto retry_private;\n\t\tgoto retry;\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (futex_match (&this->key, &key1)) {\n\t\t\tif (this->pi_state || this->rt_waiter) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\tif (++ret >= nr_wake)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (op_ret > 0) {\n\t\top_ret = 0;\n\t\tplist_for_each_entry_safe(this, next, &hb2->chain, list) {\n\t\t\tif (futex_match (&this->key, &key2)) {\n\t\t\t\tif (this->pi_state || this->rt_waiter) {\n\t\t\t\t\tret = -EINVAL;\n\t\t\t\t\tgoto out_unlock;\n\t\t\t\t}\n\t\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\t\tif (++op_ret >= nr_wake2)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tret += op_ret;\n\t}\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wake",
          "args": [
            "uaddr",
            "flags",
            "val",
            "val3"
          ],
          "line": 111
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/waitwake.c",
          "lines": "143-186",
          "snippet": "int futex_wake(u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset)\n{\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q *this, *next;\n\tunion futex_key key = FUTEX_KEY_INIT;\n\tint ret;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &key, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\thb = futex_hash(&key);\n\n\t/* Make sure we really have tasks to wakeup */\n\tif (!futex_hb_waiters_pending(hb))\n\t\treturn ret;\n\n\tspin_lock(&hb->lock);\n\n\tplist_for_each_entry_safe(this, next, &hb->chain, list) {\n\t\tif (futex_match (&this->key, &key)) {\n\t\t\tif (this->pi_state || this->rt_waiter) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check if one of the bits is set in both bitsets */\n\t\t\tif (!(this->bitset & bitset))\n\t\t\t\tcontinue;\n\n\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\tif (++ret >= nr_wake)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tspin_unlock(&hb->lock);\n\twake_up_q(&wake_q);\n\treturn ret;\n}",
          "includes": [
            "#include \"futex.h\"",
            "#include <linux/freezer.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"futex.h\"\n#include <linux/freezer.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n\nint futex_wake(u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset)\n{\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q *this, *next;\n\tunion futex_key key = FUTEX_KEY_INIT;\n\tint ret;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &key, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\thb = futex_hash(&key);\n\n\t/* Make sure we really have tasks to wakeup */\n\tif (!futex_hb_waiters_pending(hb))\n\t\treturn ret;\n\n\tspin_lock(&hb->lock);\n\n\tplist_for_each_entry_safe(this, next, &hb->chain, list) {\n\t\tif (futex_match (&this->key, &key)) {\n\t\t\tif (this->pi_state || this->rt_waiter) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check if one of the bits is set in both bitsets */\n\t\t\tif (!(this->bitset & bitset))\n\t\t\t\tcontinue;\n\n\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\tif (++ret >= nr_wake)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\n\tspin_unlock(&hb->lock);\n\twake_up_q(&wake_q);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wait",
          "args": [
            "uaddr",
            "flags",
            "val",
            "timeout",
            "val3"
          ],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wait",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/waitwake.c",
          "lines": "632-692",
          "snippet": "int futex_wait(u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct restart_block *restart;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q q = futex_q_init;\n\tint ret;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\tq.bitset = bitset;\n\n\tto = futex_setup_timer(abs_time, &timeout, flags,\n\t\t\t       current->timer_slack_ns);\nretry:\n\t/*\n\t * Prepare to wait on uaddr. On success, it holds hb->lock and q\n\t * is initialized.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/* futex_queue and wait for wakeup, timeout, or a signal. */\n\tfutex_wait_queue(hb, &q, to);\n\n\t/* If we were woken (and unqueued), we succeeded, whatever. */\n\tret = 0;\n\tif (!futex_unqueue(&q))\n\t\tgoto out;\n\tret = -ETIMEDOUT;\n\tif (to && !to->task)\n\t\tgoto out;\n\n\t/*\n\t * We expect signal_pending(current), but we might be the\n\t * victim of a spurious wakeup as well.\n\t */\n\tif (!signal_pending(current))\n\t\tgoto retry;\n\n\tret = -ERESTARTSYS;\n\tif (!abs_time)\n\t\tgoto out;\n\n\trestart = &current->restart_block;\n\trestart->futex.uaddr = uaddr;\n\trestart->futex.val = val;\n\trestart->futex.time = *abs_time;\n\trestart->futex.bitset = bitset;\n\trestart->futex.flags = flags | FLAGS_HAS_TIMEOUT;\n\n\tret = set_restart_fn(restart, futex_wait_restart);\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}",
          "includes": [
            "#include \"futex.h\"",
            "#include <linux/freezer.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static long futex_wait_restart(struct restart_block *restart);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"futex.h\"\n#include <linux/freezer.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n\nstatic long futex_wait_restart(struct restart_block *restart);\n\nint futex_wait(u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct restart_block *restart;\n\tstruct futex_hash_bucket *hb;\n\tstruct futex_q q = futex_q_init;\n\tint ret;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\tq.bitset = bitset;\n\n\tto = futex_setup_timer(abs_time, &timeout, flags,\n\t\t\t       current->timer_slack_ns);\nretry:\n\t/*\n\t * Prepare to wait on uaddr. On success, it holds hb->lock and q\n\t * is initialized.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/* futex_queue and wait for wakeup, timeout, or a signal. */\n\tfutex_wait_queue(hb, &q, to);\n\n\t/* If we were woken (and unqueued), we succeeded, whatever. */\n\tret = 0;\n\tif (!futex_unqueue(&q))\n\t\tgoto out;\n\tret = -ETIMEDOUT;\n\tif (to && !to->task)\n\t\tgoto out;\n\n\t/*\n\t * We expect signal_pending(current), but we might be the\n\t * victim of a spurious wakeup as well.\n\t */\n\tif (!signal_pending(current))\n\t\tgoto retry;\n\n\tret = -ERESTARTSYS;\n\tif (!abs_time)\n\t\tgoto out;\n\n\trestart = &current->restart_block;\n\trestart->futex.uaddr = uaddr;\n\trestart->futex.val = val;\n\trestart->futex.time = *abs_time;\n\trestart->futex.bitset = bitset;\n\trestart->futex.flags = flags | FLAGS_HAS_TIMEOUT;\n\n\tret = set_restart_fn(restart, futex_wait_restart);\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nlong do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,\n\t\tu32 __user *uaddr2, u32 val2, u32 val3)\n{\n\tint cmd = op & FUTEX_CMD_MASK;\n\tunsigned int flags = 0;\n\n\tif (!(op & FUTEX_PRIVATE_FLAG))\n\t\tflags |= FLAGS_SHARED;\n\n\tif (op & FUTEX_CLOCK_REALTIME) {\n\t\tflags |= FLAGS_CLOCKRT;\n\t\tif (cmd != FUTEX_WAIT_BITSET && cmd != FUTEX_WAIT_REQUEUE_PI &&\n\t\t    cmd != FUTEX_LOCK_PI2)\n\t\t\treturn -ENOSYS;\n\t}\n\n\tswitch (cmd) {\n\tcase FUTEX_WAIT:\n\t\tval3 = FUTEX_BITSET_MATCH_ANY;\n\t\tfallthrough;\n\tcase FUTEX_WAIT_BITSET:\n\t\treturn futex_wait(uaddr, flags, val, timeout, val3);\n\tcase FUTEX_WAKE:\n\t\tval3 = FUTEX_BITSET_MATCH_ANY;\n\t\tfallthrough;\n\tcase FUTEX_WAKE_BITSET:\n\t\treturn futex_wake(uaddr, flags, val, val3);\n\tcase FUTEX_REQUEUE:\n\t\treturn futex_requeue(uaddr, flags, uaddr2, val, val2, NULL, 0);\n\tcase FUTEX_CMP_REQUEUE:\n\t\treturn futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 0);\n\tcase FUTEX_WAKE_OP:\n\t\treturn futex_wake_op(uaddr, flags, uaddr2, val, val2, val3);\n\tcase FUTEX_LOCK_PI:\n\t\tflags |= FLAGS_CLOCKRT;\n\t\tfallthrough;\n\tcase FUTEX_LOCK_PI2:\n\t\treturn futex_lock_pi(uaddr, flags, timeout, 0);\n\tcase FUTEX_UNLOCK_PI:\n\t\treturn futex_unlock_pi(uaddr, flags);\n\tcase FUTEX_TRYLOCK_PI:\n\t\treturn futex_lock_pi(uaddr, flags, NULL, 1);\n\tcase FUTEX_WAIT_REQUEUE_PI:\n\t\tval3 = FUTEX_BITSET_MATCH_ANY;\n\t\treturn futex_wait_requeue_pi(uaddr, flags, val, timeout, val3,\n\t\t\t\t\t     uaddr2);\n\tcase FUTEX_CMP_REQUEUE_PI:\n\t\treturn futex_requeue(uaddr, flags, uaddr2, val, val2, &val3, 1);\n\t}\n\treturn -ENOSYS;\n}"
  },
  {
    "function_name": "set_robust_list",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "29-41",
    "snippet": "SYSCALL_DEFINE2(set_robust_list, struct robust_list_head __user *, head,\n\t\tsize_t, len)\n{\n\t/*\n\t * The kernel knows only one size for now:\n\t */\n\tif (unlikely(len != sizeof(*head)))\n\t\treturn -EINVAL;\n\n\tcurrent->robust_list = head;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE2(set_robust_list, struct robust_list_head __user *, head,\n\t\tsize_t, len)\n{\n\t/*\n\t * The kernel knows only one size for now:\n\t */\n\tif (unlikely(len != sizeof(*head)))\n\t\treturn -EINVAL;\n\n\tcurrent->robust_list = head;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "get_robust_list",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "49-83",
    "snippet": "SYSCALL_DEFINE3(get_robust_list, int, pid,\n\t\tstruct robust_list_head __user * __user *, head_ptr,\n\t\tsize_t __user *, len_ptr)\n{\n\tstruct robust_list_head __user *head;\n\tunsigned long ret;\n\tstruct task_struct *p;\n\n\trcu_read_lock();\n\n\tret = -ESRCH;\n\tif (!pid)\n\t\tp = current;\n\telse {\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto err_unlock;\n\t}\n\n\tret = -EPERM;\n\tif (!ptrace_may_access(p, PTRACE_MODE_READ_REALCREDS))\n\t\tgoto err_unlock;\n\n\thead = p->robust_list;\n\trcu_read_unlock();\n\n\tif (put_user(sizeof(*head), len_ptr))\n\t\treturn -EFAULT;\n\treturn put_user(head, head_ptr);\n\nerr_unlock:\n\trcu_read_unlock();\n\n\treturn ret;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE3(get_robust_list, int, pid,\n\t\tstruct robust_list_head __user * __user *, head_ptr,\n\t\tsize_t __user *, len_ptr)\n{\n\tstruct robust_list_head __user *head;\n\tunsigned long ret;\n\tstruct task_struct *p;\n\n\trcu_read_lock();\n\n\tret = -ESRCH;\n\tif (!pid)\n\t\tp = current;\n\telse {\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto err_unlock;\n\t}\n\n\tret = -EPERM;\n\tif (!ptrace_may_access(p, PTRACE_MODE_READ_REALCREDS))\n\t\tgoto err_unlock;\n\n\thead = p->robust_list;\n\trcu_read_unlock();\n\n\tif (put_user(sizeof(*head), len_ptr))\n\t\treturn -EFAULT;\n\treturn put_user(head, head_ptr);\n\nerr_unlock:\n\trcu_read_unlock();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "futex",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "164-184",
    "snippet": "SYSCALL_DEFINE6(futex, u32 __user *, uaddr, int, op, u32, val,\n\t\tconst struct __kernel_timespec __user *, utime,\n\t\tu32 __user *, uaddr2, u32, val3)\n{\n\tint ret, cmd = op & FUTEX_CMD_MASK;\n\tktime_t t, *tp = NULL;\n\tstruct timespec64 ts;\n\n\tif (utime && futex_cmd_has_timeout(cmd)) {\n\t\tif (unlikely(should_fail_futex(!(op & FUTEX_PRIVATE_FLAG))))\n\t\t\treturn -EFAULT;\n\t\tif (get_timespec64(&ts, utime))\n\t\t\treturn -EFAULT;\n\t\tret = futex_init_timeout(cmd, op, &ts, &t);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttp = &t;\n\t}\n\n\treturn do_futex(uaddr, op, val, tp, uaddr2, (unsigned long)utime, val3);\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE6(futex, u32 __user *, uaddr, int, op, u32, val,\n\t\tconst struct __kernel_timespec __user *, utime,\n\t\tu32 __user *, uaddr2, u32, val3)\n{\n\tint ret, cmd = op & FUTEX_CMD_MASK;\n\tktime_t t, *tp = NULL;\n\tstruct timespec64 ts;\n\n\tif (utime && futex_cmd_has_timeout(cmd)) {\n\t\tif (unlikely(should_fail_futex(!(op & FUTEX_PRIVATE_FLAG))))\n\t\t\treturn -EFAULT;\n\t\tif (get_timespec64(&ts, utime))\n\t\t\treturn -EFAULT;\n\t\tret = futex_init_timeout(cmd, op, &ts, &t);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttp = &t;\n\t}\n\n\treturn do_futex(uaddr, op, val, tp, uaddr2, (unsigned long)utime, val3);\n}"
  },
  {
    "function_name": "futex_waitv",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "246-303",
    "snippet": "SYSCALL_DEFINE5(futex_waitv, struct futex_waitv __user *, waiters,\n\t\tunsigned int, nr_futexes, unsigned int, flags,\n\t\tstruct __kernel_timespec __user *, timeout, clockid_t, clockid)\n{\n\tstruct hrtimer_sleeper to;\n\tstruct futex_vector *futexv;\n\tstruct timespec64 ts;\n\tktime_t time;\n\tint ret;\n\n\t/* This syscall supports no flags for now */\n\tif (flags)\n\t\treturn -EINVAL;\n\n\tif (!nr_futexes || nr_futexes > FUTEX_WAITV_MAX || !waiters)\n\t\treturn -EINVAL;\n\n\tif (timeout) {\n\t\tint flag_clkid = 0, flag_init = 0;\n\n\t\tif (clockid == CLOCK_REALTIME) {\n\t\t\tflag_clkid = FLAGS_CLOCKRT;\n\t\t\tflag_init = FUTEX_CLOCK_REALTIME;\n\t\t}\n\n\t\tif (clockid != CLOCK_REALTIME && clockid != CLOCK_MONOTONIC)\n\t\t\treturn -EINVAL;\n\n\t\tif (get_timespec64(&ts, timeout))\n\t\t\treturn -EFAULT;\n\n\t\t/*\n\t\t * Since there's no opcode for futex_waitv, use\n\t\t * FUTEX_WAIT_BITSET that uses absolute timeout as well\n\t\t */\n\t\tret = futex_init_timeout(FUTEX_WAIT_BITSET, flag_init, &ts, &time);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tfutex_setup_timer(&time, &to, flag_clkid, 0);\n\t}\n\n\tfutexv = kcalloc(nr_futexes, sizeof(*futexv), GFP_KERNEL);\n\tif (!futexv)\n\t\treturn -ENOMEM;\n\n\tret = futex_parse_waitv(futexv, waiters, nr_futexes);\n\tif (!ret)\n\t\tret = futex_wait_multiple(futexv, nr_futexes, timeout ? &to : NULL);\n\n\tif (timeout) {\n\t\thrtimer_cancel(&to.timer);\n\t\tdestroy_hrtimer_on_stack(&to.timer);\n\t}\n\n\tkfree(futexv);\n\treturn ret;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE5(futex_waitv, struct futex_waitv __user *, waiters,\n\t\tunsigned int, nr_futexes, unsigned int, flags,\n\t\tstruct __kernel_timespec __user *, timeout, clockid_t, clockid)\n{\n\tstruct hrtimer_sleeper to;\n\tstruct futex_vector *futexv;\n\tstruct timespec64 ts;\n\tktime_t time;\n\tint ret;\n\n\t/* This syscall supports no flags for now */\n\tif (flags)\n\t\treturn -EINVAL;\n\n\tif (!nr_futexes || nr_futexes > FUTEX_WAITV_MAX || !waiters)\n\t\treturn -EINVAL;\n\n\tif (timeout) {\n\t\tint flag_clkid = 0, flag_init = 0;\n\n\t\tif (clockid == CLOCK_REALTIME) {\n\t\t\tflag_clkid = FLAGS_CLOCKRT;\n\t\t\tflag_init = FUTEX_CLOCK_REALTIME;\n\t\t}\n\n\t\tif (clockid != CLOCK_REALTIME && clockid != CLOCK_MONOTONIC)\n\t\t\treturn -EINVAL;\n\n\t\tif (get_timespec64(&ts, timeout))\n\t\t\treturn -EFAULT;\n\n\t\t/*\n\t\t * Since there's no opcode for futex_waitv, use\n\t\t * FUTEX_WAIT_BITSET that uses absolute timeout as well\n\t\t */\n\t\tret = futex_init_timeout(FUTEX_WAIT_BITSET, flag_init, &ts, &time);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tfutex_setup_timer(&time, &to, flag_clkid, 0);\n\t}\n\n\tfutexv = kcalloc(nr_futexes, sizeof(*futexv), GFP_KERNEL);\n\tif (!futexv)\n\t\treturn -ENOMEM;\n\n\tret = futex_parse_waitv(futexv, waiters, nr_futexes);\n\tif (!ret)\n\t\tret = futex_wait_multiple(futexv, nr_futexes, timeout ? &to : NULL);\n\n\tif (timeout) {\n\t\thrtimer_cancel(&to.timer);\n\t\tdestroy_hrtimer_on_stack(&to.timer);\n\t}\n\n\tkfree(futexv);\n\treturn ret;\n}"
  },
  {
    "function_name": "set_robust_list",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "306-316",
    "snippet": "SYSCALL_DEFINE2(set_robust_list,\n\t\tstruct compat_robust_list_head __user *, head,\n\t\tcompat_size_t, len)\n{\n\tif (unlikely(len != sizeof(*head)))\n\t\treturn -EINVAL;\n\n\tcurrent->compat_robust_list = head;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE2(set_robust_list,\n\t\tstruct compat_robust_list_head __user *, head,\n\t\tcompat_size_t, len)\n{\n\tif (unlikely(len != sizeof(*head)))\n\t\treturn -EINVAL;\n\n\tcurrent->compat_robust_list = head;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "get_robust_list",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "318-352",
    "snippet": "SYSCALL_DEFINE3(get_robust_list, int, pid,\n\t\t\tcompat_uptr_t __user *, head_ptr,\n\t\t\tcompat_size_t __user *, len_ptr)\n{\n\tstruct compat_robust_list_head __user *head;\n\tunsigned long ret;\n\tstruct task_struct *p;\n\n\trcu_read_lock();\n\n\tret = -ESRCH;\n\tif (!pid)\n\t\tp = current;\n\telse {\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto err_unlock;\n\t}\n\n\tret = -EPERM;\n\tif (!ptrace_may_access(p, PTRACE_MODE_READ_REALCREDS))\n\t\tgoto err_unlock;\n\n\thead = p->compat_robust_list;\n\trcu_read_unlock();\n\n\tif (put_user(sizeof(*head), len_ptr))\n\t\treturn -EFAULT;\n\treturn put_user(ptr_to_compat(head), head_ptr);\n\nerr_unlock:\n\trcu_read_unlock();\n\n\treturn ret;\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE3(get_robust_list, int, pid,\n\t\t\tcompat_uptr_t __user *, head_ptr,\n\t\t\tcompat_size_t __user *, len_ptr)\n{\n\tstruct compat_robust_list_head __user *head;\n\tunsigned long ret;\n\tstruct task_struct *p;\n\n\trcu_read_lock();\n\n\tret = -ESRCH;\n\tif (!pid)\n\t\tp = current;\n\telse {\n\t\tp = find_task_by_vpid(pid);\n\t\tif (!p)\n\t\t\tgoto err_unlock;\n\t}\n\n\tret = -EPERM;\n\tif (!ptrace_may_access(p, PTRACE_MODE_READ_REALCREDS))\n\t\tgoto err_unlock;\n\n\thead = p->compat_robust_list;\n\trcu_read_unlock();\n\n\tif (put_user(sizeof(*head), len_ptr))\n\t\treturn -EFAULT;\n\treturn put_user(ptr_to_compat(head), head_ptr);\n\nerr_unlock:\n\trcu_read_unlock();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "futex_time32",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/syscalls.c",
    "lines": "356-374",
    "snippet": "SYSCALL_DEFINE6(futex_time32, u32 __user *, uaddr, int, op, u32, val,\n\t\tconst struct old_timespec32 __user *, utime, u32 __user *, uaddr2,\n\t\tu32, val3)\n{\n\tint ret, cmd = op & FUTEX_CMD_MASK;\n\tktime_t t, *tp = NULL;\n\tstruct timespec64 ts;\n\n\tif (utime && futex_cmd_has_timeout(cmd)) {\n\t\tif (get_old_timespec32(&ts, utime))\n\t\t\treturn -EFAULT;\n\t\tret = futex_init_timeout(cmd, op, &ts, &t);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttp = &t;\n\t}\n\n\treturn do_futex(uaddr, op, val, tp, uaddr2, (unsigned long)utime, val3);\n}",
    "includes": [
      "#include \"futex.h\"",
      "#include <linux/time_namespace.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/compat.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"futex.h\"\n#include <linux/time_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/compat.h>\n\nSYSCALL_DEFINE6(futex_time32, u32 __user *, uaddr, int, op, u32, val,\n\t\tconst struct old_timespec32 __user *, utime, u32 __user *, uaddr2,\n\t\tu32, val3)\n{\n\tint ret, cmd = op & FUTEX_CMD_MASK;\n\tktime_t t, *tp = NULL;\n\tstruct timespec64 ts;\n\n\tif (utime && futex_cmd_has_timeout(cmd)) {\n\t\tif (get_old_timespec32(&ts, utime))\n\t\t\treturn -EFAULT;\n\t\tret = futex_init_timeout(cmd, op, &ts, &t);\n\t\tif (ret)\n\t\t\treturn ret;\n\t\ttp = &t;\n\t}\n\n\treturn do_futex(uaddr, op, val, tp, uaddr2, (unsigned long)utime, val3);\n}"
  }
]