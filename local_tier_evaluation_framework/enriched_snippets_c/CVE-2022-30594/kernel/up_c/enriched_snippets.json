[
  {
    "function_name": "smp_call_on_cpu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
    "lines": "58-72",
    "snippet": "int smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par, bool phys)\n{\n\tint ret;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tif (phys)\n\t\thypervisor_pin_vcpu(0);\n\tret = func(par);\n\tif (phys)\n\t\thypervisor_pin_vcpu(-1);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "hypervisor_pin_vcpu",
          "args": [
            "-1"
          ],
          "line": 69
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "par"
          ],
          "line": 67
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/smp.c",
          "lines": "561-682",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tcall_single_data_t *csd, *csd_next;\n\tstruct llist_node *entry, *prev;\n\tstruct llist_head *head;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->handle, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HANDLE);\n\tentry = llist_del_all(head);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->dequeue,\n\t\t      /* Special meaning of source cpu: 0 == queue empty */\n\t\t      entry ? CFD_SEQ_NOCPU : 0,\n\t\t      smp_processor_id(), CFD_SEQ_DEQUEUE);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, node.llist) {\n\t\t\tswitch (CSD_TYPE(csd)) {\n\t\t\tcase CSD_TYPE_ASYNC:\n\t\t\tcase CSD_TYPE_SYNC:\n\t\t\tcase CSD_TYPE_IRQ_WORK:\n\t\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\t\tcsd->func);\n\t\t\t\tbreak;\n\n\t\t\tcase CSD_TYPE_TTWU:\n\t\t\t\tpr_warn(\"IPI task-wakeup sent to offline CPU\\n\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tpr_warn(\"IPI callback, unknown type %d, sent to offline CPU\\n\",\n\t\t\t\t\tCSD_TYPE(csd));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * First; run all SYNC callbacks, people are waiting for us.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\t/* Do we wait until *after* callback? */\n\t\tif (CSD_TYPE(csd) == CSD_TYPE_SYNC) {\n\t\t\tsmp_call_func_t func = csd->func;\n\t\t\tvoid *info = csd->info;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tcsd_lock_record(csd);\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t\tcsd_lock_record(NULL);\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend,\n\t\t\t      0, smp_processor_id(),\n\t\t\t      CFD_SEQ_HDLEND);\n\t\treturn;\n\t}\n\n\t/*\n\t * Second; run all !SYNC callbacks.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\tint type = CSD_TYPE(csd);\n\n\t\tif (type != CSD_TYPE_TTWU) {\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tif (type == CSD_TYPE_ASYNC) {\n\t\t\t\tsmp_call_func_t func = csd->func;\n\t\t\t\tvoid *info = csd->info;\n\n\t\t\t\tcsd_lock_record(csd);\n\t\t\t\tcsd_unlock(csd);\n\t\t\t\tfunc(info);\n\t\t\t\tcsd_lock_record(NULL);\n\t\t\t} else if (type == CSD_TYPE_IRQ_WORK) {\n\t\t\t\tirq_work_single(csd);\n\t\t\t}\n\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\t/*\n\t * Third; only CSD_TYPE_TTWU is left, issue those.\n\t */\n\tif (entry)\n\t\tsched_ttwu_pending(entry);\n\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HDLEND);\n}",
          "includes": [
            "#include \"sched/smp.h\"",
            "#include \"smpboot.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [
            "#define CFD_SEQ_HDLEND\t9",
            "#define CFD_SEQ_DEQUEUE\t6",
            "#define CFD_SEQ_HANDLE\t5",
            "#define CFD_SEQ_NOCPU\t0xffff"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched/smp.h\"\n#include \"smpboot.h\"\n#include <linux/jump_label.h>\n#include <linux/sched/debug.h>\n#include <linux/nmi.h>\n#include <linux/sched/clock.h>\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/interrupt.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\n#define CFD_SEQ_HDLEND\t9\n#define CFD_SEQ_DEQUEUE\t6\n#define CFD_SEQ_HANDLE\t5\n#define CFD_SEQ_NOCPU\t0xffff\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tcall_single_data_t *csd, *csd_next;\n\tstruct llist_node *entry, *prev;\n\tstruct llist_head *head;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->handle, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HANDLE);\n\tentry = llist_del_all(head);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->dequeue,\n\t\t      /* Special meaning of source cpu: 0 == queue empty */\n\t\t      entry ? CFD_SEQ_NOCPU : 0,\n\t\t      smp_processor_id(), CFD_SEQ_DEQUEUE);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, node.llist) {\n\t\t\tswitch (CSD_TYPE(csd)) {\n\t\t\tcase CSD_TYPE_ASYNC:\n\t\t\tcase CSD_TYPE_SYNC:\n\t\t\tcase CSD_TYPE_IRQ_WORK:\n\t\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\t\tcsd->func);\n\t\t\t\tbreak;\n\n\t\t\tcase CSD_TYPE_TTWU:\n\t\t\t\tpr_warn(\"IPI task-wakeup sent to offline CPU\\n\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tpr_warn(\"IPI callback, unknown type %d, sent to offline CPU\\n\",\n\t\t\t\t\tCSD_TYPE(csd));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * First; run all SYNC callbacks, people are waiting for us.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\t/* Do we wait until *after* callback? */\n\t\tif (CSD_TYPE(csd) == CSD_TYPE_SYNC) {\n\t\t\tsmp_call_func_t func = csd->func;\n\t\t\tvoid *info = csd->info;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tcsd_lock_record(csd);\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t\tcsd_lock_record(NULL);\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend,\n\t\t\t      0, smp_processor_id(),\n\t\t\t      CFD_SEQ_HDLEND);\n\t\treturn;\n\t}\n\n\t/*\n\t * Second; run all !SYNC callbacks.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\tint type = CSD_TYPE(csd);\n\n\t\tif (type != CSD_TYPE_TTWU) {\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tif (type == CSD_TYPE_ASYNC) {\n\t\t\t\tsmp_call_func_t func = csd->func;\n\t\t\t\tvoid *info = csd->info;\n\n\t\t\t\tcsd_lock_record(csd);\n\t\t\t\tcsd_unlock(csd);\n\t\t\t\tfunc(info);\n\t\t\t\tcsd_lock_record(NULL);\n\t\t\t} else if (type == CSD_TYPE_IRQ_WORK) {\n\t\t\t\tirq_work_single(csd);\n\t\t\t}\n\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\t/*\n\t * Third; only CSD_TYPE_TTWU is left, issue those.\n\t */\n\tif (entry)\n\t\tsched_ttwu_pending(entry);\n\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HDLEND);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hypervisor_pin_vcpu",
          "args": [
            "0"
          ],
          "line": 66
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_on_cpu(unsigned int cpu, int (*func)(void *), void *par, bool phys)\n{\n\tint ret;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tif (phys)\n\t\thypervisor_pin_vcpu(0);\n\tret = func(par);\n\tif (phys)\n\t\thypervisor_pin_vcpu(-1);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "on_each_cpu_cond_mask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
    "lines": "43-55",
    "snippet": "void on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,\n\t\t\t   void *info, bool wait, const struct cpumask *mask)\n{\n\tunsigned long flags;\n\n\tpreempt_disable();\n\tif ((!cond_func || cond_func(0, info)) && cpumask_test_cpu(0, mask)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n\tpreempt_enable();\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 54
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 52
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "info"
          ],
          "line": 51
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/smp.c",
          "lines": "561-682",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tcall_single_data_t *csd, *csd_next;\n\tstruct llist_node *entry, *prev;\n\tstruct llist_head *head;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->handle, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HANDLE);\n\tentry = llist_del_all(head);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->dequeue,\n\t\t      /* Special meaning of source cpu: 0 == queue empty */\n\t\t      entry ? CFD_SEQ_NOCPU : 0,\n\t\t      smp_processor_id(), CFD_SEQ_DEQUEUE);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, node.llist) {\n\t\t\tswitch (CSD_TYPE(csd)) {\n\t\t\tcase CSD_TYPE_ASYNC:\n\t\t\tcase CSD_TYPE_SYNC:\n\t\t\tcase CSD_TYPE_IRQ_WORK:\n\t\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\t\tcsd->func);\n\t\t\t\tbreak;\n\n\t\t\tcase CSD_TYPE_TTWU:\n\t\t\t\tpr_warn(\"IPI task-wakeup sent to offline CPU\\n\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tpr_warn(\"IPI callback, unknown type %d, sent to offline CPU\\n\",\n\t\t\t\t\tCSD_TYPE(csd));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * First; run all SYNC callbacks, people are waiting for us.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\t/* Do we wait until *after* callback? */\n\t\tif (CSD_TYPE(csd) == CSD_TYPE_SYNC) {\n\t\t\tsmp_call_func_t func = csd->func;\n\t\t\tvoid *info = csd->info;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tcsd_lock_record(csd);\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t\tcsd_lock_record(NULL);\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend,\n\t\t\t      0, smp_processor_id(),\n\t\t\t      CFD_SEQ_HDLEND);\n\t\treturn;\n\t}\n\n\t/*\n\t * Second; run all !SYNC callbacks.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\tint type = CSD_TYPE(csd);\n\n\t\tif (type != CSD_TYPE_TTWU) {\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tif (type == CSD_TYPE_ASYNC) {\n\t\t\t\tsmp_call_func_t func = csd->func;\n\t\t\t\tvoid *info = csd->info;\n\n\t\t\t\tcsd_lock_record(csd);\n\t\t\t\tcsd_unlock(csd);\n\t\t\t\tfunc(info);\n\t\t\t\tcsd_lock_record(NULL);\n\t\t\t} else if (type == CSD_TYPE_IRQ_WORK) {\n\t\t\t\tirq_work_single(csd);\n\t\t\t}\n\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\t/*\n\t * Third; only CSD_TYPE_TTWU is left, issue those.\n\t */\n\tif (entry)\n\t\tsched_ttwu_pending(entry);\n\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HDLEND);\n}",
          "includes": [
            "#include \"sched/smp.h\"",
            "#include \"smpboot.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [
            "#define CFD_SEQ_HDLEND\t9",
            "#define CFD_SEQ_DEQUEUE\t6",
            "#define CFD_SEQ_HANDLE\t5",
            "#define CFD_SEQ_NOCPU\t0xffff"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched/smp.h\"\n#include \"smpboot.h\"\n#include <linux/jump_label.h>\n#include <linux/sched/debug.h>\n#include <linux/nmi.h>\n#include <linux/sched/clock.h>\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/interrupt.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\n#define CFD_SEQ_HDLEND\t9\n#define CFD_SEQ_DEQUEUE\t6\n#define CFD_SEQ_HANDLE\t5\n#define CFD_SEQ_NOCPU\t0xffff\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tcall_single_data_t *csd, *csd_next;\n\tstruct llist_node *entry, *prev;\n\tstruct llist_head *head;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->handle, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HANDLE);\n\tentry = llist_del_all(head);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->dequeue,\n\t\t      /* Special meaning of source cpu: 0 == queue empty */\n\t\t      entry ? CFD_SEQ_NOCPU : 0,\n\t\t      smp_processor_id(), CFD_SEQ_DEQUEUE);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, node.llist) {\n\t\t\tswitch (CSD_TYPE(csd)) {\n\t\t\tcase CSD_TYPE_ASYNC:\n\t\t\tcase CSD_TYPE_SYNC:\n\t\t\tcase CSD_TYPE_IRQ_WORK:\n\t\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\t\tcsd->func);\n\t\t\t\tbreak;\n\n\t\t\tcase CSD_TYPE_TTWU:\n\t\t\t\tpr_warn(\"IPI task-wakeup sent to offline CPU\\n\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tpr_warn(\"IPI callback, unknown type %d, sent to offline CPU\\n\",\n\t\t\t\t\tCSD_TYPE(csd));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * First; run all SYNC callbacks, people are waiting for us.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\t/* Do we wait until *after* callback? */\n\t\tif (CSD_TYPE(csd) == CSD_TYPE_SYNC) {\n\t\t\tsmp_call_func_t func = csd->func;\n\t\t\tvoid *info = csd->info;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tcsd_lock_record(csd);\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t\tcsd_lock_record(NULL);\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend,\n\t\t\t      0, smp_processor_id(),\n\t\t\t      CFD_SEQ_HDLEND);\n\t\treturn;\n\t}\n\n\t/*\n\t * Second; run all !SYNC callbacks.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\tint type = CSD_TYPE(csd);\n\n\t\tif (type != CSD_TYPE_TTWU) {\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tif (type == CSD_TYPE_ASYNC) {\n\t\t\t\tsmp_call_func_t func = csd->func;\n\t\t\t\tvoid *info = csd->info;\n\n\t\t\t\tcsd_lock_record(csd);\n\t\t\t\tcsd_unlock(csd);\n\t\t\t\tfunc(info);\n\t\t\t\tcsd_lock_record(NULL);\n\t\t\t} else if (type == CSD_TYPE_IRQ_WORK) {\n\t\t\t\tirq_work_single(csd);\n\t\t\t}\n\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\t/*\n\t * Third; only CSD_TYPE_TTWU is left, issue those.\n\t */\n\tif (entry)\n\t\tsched_ttwu_pending(entry);\n\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HDLEND);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 50
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "0",
            "mask"
          ],
          "line": 49
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_func",
          "args": [
            "0",
            "info"
          ],
          "line": 49
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 48
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nvoid on_each_cpu_cond_mask(smp_cond_func_t cond_func, smp_call_func_t func,\n\t\t\t   void *info, bool wait, const struct cpumask *mask)\n{\n\tunsigned long flags;\n\n\tpreempt_disable();\n\tif ((!cond_func || cond_func(0, info)) && cpumask_test_cpu(0, mask)) {\n\t\tlocal_irq_save(flags);\n\t\tfunc(info);\n\t\tlocal_irq_restore(flags);\n\t}\n\tpreempt_enable();\n}"
  },
  {
    "function_name": "smp_call_function_single_async",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
    "lines": "28-36",
    "snippet": "int smp_call_function_single_async(int cpu, struct __call_single_data *csd)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tcsd->func(csd->info);\n\tlocal_irq_restore(flags);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 34
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "csd->func",
          "args": [
            "csd->info"
          ],
          "line": 33
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 32
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single_async(int cpu, struct __call_single_data *csd)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tcsd->func(csd->info);\n\tlocal_irq_restore(flags);\n\treturn 0;\n}"
  },
  {
    "function_name": "smp_call_function_single",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
    "lines": "12-25",
    "snippet": "int smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/hypervisor.h>",
      "#include <linux/smp.h>",
      "#include <linux/export.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 22
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "func",
          "args": [
            "info"
          ],
          "line": 21
        },
        "resolved": true,
        "details": {
          "function_name": "flush_smp_call_function_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/smp.c",
          "lines": "561-682",
          "snippet": "static void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tcall_single_data_t *csd, *csd_next;\n\tstruct llist_node *entry, *prev;\n\tstruct llist_head *head;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->handle, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HANDLE);\n\tentry = llist_del_all(head);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->dequeue,\n\t\t      /* Special meaning of source cpu: 0 == queue empty */\n\t\t      entry ? CFD_SEQ_NOCPU : 0,\n\t\t      smp_processor_id(), CFD_SEQ_DEQUEUE);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, node.llist) {\n\t\t\tswitch (CSD_TYPE(csd)) {\n\t\t\tcase CSD_TYPE_ASYNC:\n\t\t\tcase CSD_TYPE_SYNC:\n\t\t\tcase CSD_TYPE_IRQ_WORK:\n\t\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\t\tcsd->func);\n\t\t\t\tbreak;\n\n\t\t\tcase CSD_TYPE_TTWU:\n\t\t\t\tpr_warn(\"IPI task-wakeup sent to offline CPU\\n\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tpr_warn(\"IPI callback, unknown type %d, sent to offline CPU\\n\",\n\t\t\t\t\tCSD_TYPE(csd));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * First; run all SYNC callbacks, people are waiting for us.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\t/* Do we wait until *after* callback? */\n\t\tif (CSD_TYPE(csd) == CSD_TYPE_SYNC) {\n\t\t\tsmp_call_func_t func = csd->func;\n\t\t\tvoid *info = csd->info;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tcsd_lock_record(csd);\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t\tcsd_lock_record(NULL);\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend,\n\t\t\t      0, smp_processor_id(),\n\t\t\t      CFD_SEQ_HDLEND);\n\t\treturn;\n\t}\n\n\t/*\n\t * Second; run all !SYNC callbacks.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\tint type = CSD_TYPE(csd);\n\n\t\tif (type != CSD_TYPE_TTWU) {\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tif (type == CSD_TYPE_ASYNC) {\n\t\t\t\tsmp_call_func_t func = csd->func;\n\t\t\t\tvoid *info = csd->info;\n\n\t\t\t\tcsd_lock_record(csd);\n\t\t\t\tcsd_unlock(csd);\n\t\t\t\tfunc(info);\n\t\t\t\tcsd_lock_record(NULL);\n\t\t\t} else if (type == CSD_TYPE_IRQ_WORK) {\n\t\t\t\tirq_work_single(csd);\n\t\t\t}\n\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\t/*\n\t * Third; only CSD_TYPE_TTWU is left, issue those.\n\t */\n\tif (entry)\n\t\tsched_ttwu_pending(entry);\n\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HDLEND);\n}",
          "includes": [
            "#include \"sched/smp.h\"",
            "#include \"smpboot.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [
            "#define CFD_SEQ_HDLEND\t9",
            "#define CFD_SEQ_DEQUEUE\t6",
            "#define CFD_SEQ_HANDLE\t5",
            "#define CFD_SEQ_NOCPU\t0xffff"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);",
            "static void flush_smp_call_function_queue(bool warn_cpu_offline);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched/smp.h\"\n#include \"smpboot.h\"\n#include <linux/jump_label.h>\n#include <linux/sched/debug.h>\n#include <linux/nmi.h>\n#include <linux/sched/clock.h>\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/interrupt.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\n#define CFD_SEQ_HDLEND\t9\n#define CFD_SEQ_DEQUEUE\t6\n#define CFD_SEQ_HANDLE\t5\n#define CFD_SEQ_NOCPU\t0xffff\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct llist_head, call_single_queue);\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline);\n\nstatic void flush_smp_call_function_queue(bool warn_cpu_offline)\n{\n\tcall_single_data_t *csd, *csd_next;\n\tstruct llist_node *entry, *prev;\n\tstruct llist_head *head;\n\tstatic bool warned;\n\n\tlockdep_assert_irqs_disabled();\n\n\thead = this_cpu_ptr(&call_single_queue);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->handle, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HANDLE);\n\tentry = llist_del_all(head);\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->dequeue,\n\t\t      /* Special meaning of source cpu: 0 == queue empty */\n\t\t      entry ? CFD_SEQ_NOCPU : 0,\n\t\t      smp_processor_id(), CFD_SEQ_DEQUEUE);\n\tentry = llist_reverse_order(entry);\n\n\t/* There shouldn't be any pending callbacks on an offline CPU. */\n\tif (unlikely(warn_cpu_offline && !cpu_online(smp_processor_id()) &&\n\t\t     !warned && !llist_empty(head))) {\n\t\twarned = true;\n\t\tWARN(1, \"IPI on offline CPU %d\\n\", smp_processor_id());\n\n\t\t/*\n\t\t * We don't have to use the _safe() variant here\n\t\t * because we are not invoking the IPI handlers yet.\n\t\t */\n\t\tllist_for_each_entry(csd, entry, node.llist) {\n\t\t\tswitch (CSD_TYPE(csd)) {\n\t\t\tcase CSD_TYPE_ASYNC:\n\t\t\tcase CSD_TYPE_SYNC:\n\t\t\tcase CSD_TYPE_IRQ_WORK:\n\t\t\t\tpr_warn(\"IPI callback %pS sent to offline CPU\\n\",\n\t\t\t\t\tcsd->func);\n\t\t\t\tbreak;\n\n\t\t\tcase CSD_TYPE_TTWU:\n\t\t\t\tpr_warn(\"IPI task-wakeup sent to offline CPU\\n\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tpr_warn(\"IPI callback, unknown type %d, sent to offline CPU\\n\",\n\t\t\t\t\tCSD_TYPE(csd));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/*\n\t * First; run all SYNC callbacks, people are waiting for us.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\t/* Do we wait until *after* callback? */\n\t\tif (CSD_TYPE(csd) == CSD_TYPE_SYNC) {\n\t\t\tsmp_call_func_t func = csd->func;\n\t\t\tvoid *info = csd->info;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tcsd_lock_record(csd);\n\t\t\tfunc(info);\n\t\t\tcsd_unlock(csd);\n\t\t\tcsd_lock_record(NULL);\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\tif (!entry) {\n\t\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend,\n\t\t\t      0, smp_processor_id(),\n\t\t\t      CFD_SEQ_HDLEND);\n\t\treturn;\n\t}\n\n\t/*\n\t * Second; run all !SYNC callbacks.\n\t */\n\tprev = NULL;\n\tllist_for_each_entry_safe(csd, csd_next, entry, node.llist) {\n\t\tint type = CSD_TYPE(csd);\n\n\t\tif (type != CSD_TYPE_TTWU) {\n\t\t\tif (prev) {\n\t\t\t\tprev->next = &csd_next->node.llist;\n\t\t\t} else {\n\t\t\t\tentry = &csd_next->node.llist;\n\t\t\t}\n\n\t\t\tif (type == CSD_TYPE_ASYNC) {\n\t\t\t\tsmp_call_func_t func = csd->func;\n\t\t\t\tvoid *info = csd->info;\n\n\t\t\t\tcsd_lock_record(csd);\n\t\t\t\tcsd_unlock(csd);\n\t\t\t\tfunc(info);\n\t\t\t\tcsd_lock_record(NULL);\n\t\t\t} else if (type == CSD_TYPE_IRQ_WORK) {\n\t\t\t\tirq_work_single(csd);\n\t\t\t}\n\n\t\t} else {\n\t\t\tprev = &csd->node.llist;\n\t\t}\n\t}\n\n\t/*\n\t * Third; only CSD_TYPE_TTWU is left, issue those.\n\t */\n\tif (entry)\n\t\tsched_ttwu_pending(entry);\n\n\tcfd_seq_store(this_cpu_ptr(&cfd_seq_local)->hdlend, CFD_SEQ_NOCPU,\n\t\t      smp_processor_id(), CFD_SEQ_HDLEND);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 20
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}"
  }
]