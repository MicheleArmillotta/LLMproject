[
  {
    "function_name": "__rt_rwlock_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "273-278",
    "snippet": "void __rt_rwlock_init(rwlock_t *rwlock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n\tdebug_check_no_locks_freed((void *)rwlock, sizeof(*rwlock));\n\tlockdep_init_map_wait(&rwlock->dep_map, name, key, 0, LD_WAIT_CONFIG);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lockdep_init_map_wait",
          "args": [
            "&rwlock->dep_map",
            "name",
            "key",
            "0",
            "LD_WAIT_CONFIG"
          ],
          "line": 277
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_check_no_locks_freed",
          "args": [
            "(void *)rwlock",
            "sizeof(*rwlock)"
          ],
          "line": 276
        },
        "resolved": true,
        "details": {
          "function_name": "debug_check_no_locks_freed",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "6405-6427",
          "snippet": "void debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __rt_rwlock_init(rwlock_t *rwlock, const char *name,\n\t\t      struct lock_class_key *key)\n{\n\tdebug_check_no_locks_freed((void *)rwlock, sizeof(*rwlock));\n\tlockdep_init_map_wait(&rwlock->dep_map, name, key, 0, LD_WAIT_CONFIG);\n}"
  },
  {
    "function_name": "rt_write_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "263-269",
    "snippet": "void __sched rt_write_unlock(rwlock_t *rwlock)\n{\n\trwlock_release(&rwlock->dep_map, _RET_IP_);\n\trcu_read_unlock();\n\tmigrate_enable();\n\trwbase_write_unlock(&rwlock->rwbase);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_write_unlock",
          "args": [
            "&rwlock->rwbase"
          ],
          "line": 268
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "196-203",
          "snippet": "static inline void rwbase_write_unlock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\t__rwbase_write_unlock(rwb, WRITER_BIAS, flags);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void rwbase_write_unlock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\t__rwbase_write_unlock(rwb, WRITER_BIAS, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "migrate_enable",
          "args": [],
          "line": 267
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2178-2206",
          "snippet": "void migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 266
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_release",
          "args": [
            "&rwlock->dep_map",
            "_RET_IP_"
          ],
          "line": 265
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_write_unlock(rwlock_t *rwlock)\n{\n\trwlock_release(&rwlock->dep_map, _RET_IP_);\n\trcu_read_unlock();\n\tmigrate_enable();\n\trwbase_write_unlock(&rwlock->rwbase);\n}"
  },
  {
    "function_name": "rt_read_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "254-260",
    "snippet": "void __sched rt_read_unlock(rwlock_t *rwlock)\n{\n\trwlock_release(&rwlock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\trwbase_read_unlock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_read_unlock",
          "args": [
            "&rwlock->rwbase",
            "TASK_RTLOCK_WAIT"
          ],
          "line": 259
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "169-180",
          "snippet": "static __always_inline void rwbase_read_unlock(struct rwbase_rt *rwb,\n\t\t\t\t\t       unsigned int state)\n{\n\t/*\n\t * rwb->readers can only hit 0 when a writer is waiting for the\n\t * active readers to leave the critical section.\n\t *\n\t * dec_and_test() is fully ordered, provides RELEASE.\n\t */\n\tif (unlikely(atomic_dec_and_test(&rwb->readers)))\n\t\t__rwbase_read_unlock(rwb, state);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline void rwbase_read_unlock(struct rwbase_rt *rwb,\n\t\t\t\t\t       unsigned int state)\n{\n\t/*\n\t * rwb->readers can only hit 0 when a writer is waiting for the\n\t * active readers to leave the critical section.\n\t *\n\t * dec_and_test() is fully ordered, provides RELEASE.\n\t */\n\tif (unlikely(atomic_dec_and_test(&rwb->readers)))\n\t\t__rwbase_read_unlock(rwb, state);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 258
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "migrate_enable",
          "args": [],
          "line": 257
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2178-2206",
          "snippet": "void migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_release",
          "args": [
            "&rwlock->dep_map",
            "_RET_IP_"
          ],
          "line": 256
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_read_unlock(rwlock_t *rwlock)\n{\n\trwlock_release(&rwlock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\trwbase_read_unlock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n}"
  },
  {
    "function_name": "rt_write_lock_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "243-250",
    "snippet": "void __sched rt_write_lock_nested(rwlock_t *rwlock, int subclass)\n{\n\trtlock_might_resched();\n\trwlock_acquire(&rwlock->dep_map, subclass, 0, _RET_IP_);\n\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 249
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 248
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwbase_write_lock",
          "args": [
            "&rwlock->rwbase",
            "TASK_RTLOCK_WAIT"
          ],
          "line": 247
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "232-272",
          "snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_acquire",
          "args": [
            "&rwlock->dep_map",
            "subclass",
            "0",
            "_RET_IP_"
          ],
          "line": 246
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rtlock_might_resched",
          "args": [],
          "line": 245
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_write_lock_nested(rwlock_t *rwlock, int subclass)\n{\n\trtlock_might_resched();\n\trwlock_acquire(&rwlock->dep_map, subclass, 0, _RET_IP_);\n\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
  },
  {
    "function_name": "rt_write_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "232-239",
    "snippet": "void __sched rt_write_lock(rwlock_t *rwlock)\n{\n\trtlock_might_resched();\n\trwlock_acquire(&rwlock->dep_map, 0, 0, _RET_IP_);\n\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 238
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 237
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwbase_write_lock",
          "args": [
            "&rwlock->rwbase",
            "TASK_RTLOCK_WAIT"
          ],
          "line": 236
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "232-272",
          "snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_acquire",
          "args": [
            "&rwlock->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 235
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rtlock_might_resched",
          "args": [],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_write_lock(rwlock_t *rwlock)\n{\n\trtlock_might_resched();\n\trwlock_acquire(&rwlock->dep_map, 0, 0, _RET_IP_);\n\trwbase_write_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
  },
  {
    "function_name": "rt_read_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "222-229",
    "snippet": "void __sched rt_read_lock(rwlock_t *rwlock)\n{\n\trtlock_might_resched();\n\trwlock_acquire_read(&rwlock->dep_map, 0, 0, _RET_IP_);\n\trwbase_read_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 228
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 227
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwbase_read_lock",
          "args": [
            "&rwlock->rwbase",
            "TASK_RTLOCK_WAIT"
          ],
          "line": 226
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "136-143",
          "snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_acquire_read",
          "args": [
            "&rwlock->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 225
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rtlock_might_resched",
          "args": [],
          "line": 224
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_read_lock(rwlock_t *rwlock)\n{\n\trtlock_might_resched();\n\trwlock_acquire_read(&rwlock->dep_map, 0, 0, _RET_IP_);\n\trwbase_read_lock(&rwlock->rwbase, TASK_RTLOCK_WAIT);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
  },
  {
    "function_name": "rt_write_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "208-219",
    "snippet": "int __sched rt_write_trylock(rwlock_t *rwlock)\n{\n\tint ret;\n\n\tret = rwbase_write_trylock(&rwlock->rwbase);\n\tif (ret) {\n\t\trwlock_acquire(&rwlock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 216
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 215
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_acquire",
          "args": [
            "&rwlock->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 214
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwbase_write_trylock",
          "args": [
            "&rwlock->rwbase"
          ],
          "line": 212
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "274-291",
          "snippet": "static inline int rwbase_write_trylock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\tif (!rwbase_rtmutex_trylock(rtm))\n\t\treturn 0;\n\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb)) {\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\treturn 1;\n\t}\n\t__rwbase_write_unlock(rwb, 0, flags);\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline int rwbase_write_trylock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\tif (!rwbase_rtmutex_trylock(rtm))\n\t\treturn 0;\n\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb)) {\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\treturn 1;\n\t}\n\t__rwbase_write_unlock(rwb, 0, flags);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_write_trylock(rwlock_t *rwlock)\n{\n\tint ret;\n\n\tret = rwbase_write_trylock(&rwlock->rwbase);\n\tif (ret) {\n\t\trwlock_acquire(&rwlock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "rt_read_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "194-205",
    "snippet": "int __sched rt_read_trylock(rwlock_t *rwlock)\n{\n\tint ret;\n\n\tret = rwbase_read_trylock(&rwlock->rwbase);\n\tif (ret) {\n\t\trwlock_acquire_read(&rwlock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 202
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 201
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwlock_acquire_read",
          "args": [
            "&rwlock->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwbase_read_trylock",
          "args": [
            "&rwlock->rwbase"
          ],
          "line": 198
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "53-66",
          "snippet": "static __always_inline int rwbase_read_trylock(struct rwbase_rt *rwb)\n{\n\tint r;\n\n\t/*\n\t * Increment reader count, if sem->readers < 0, i.e. READER_BIAS is\n\t * set.\n\t */\n\tfor (r = atomic_read(&rwb->readers); r < 0;) {\n\t\tif (likely(atomic_try_cmpxchg_acquire(&rwb->readers, &r, r + 1)))\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline int rwbase_read_trylock(struct rwbase_rt *rwb)\n{\n\tint r;\n\n\t/*\n\t * Increment reader count, if sem->readers < 0, i.e. READER_BIAS is\n\t * set.\n\t */\n\tfor (r = atomic_read(&rwb->readers); r < 0;) {\n\t\tif (likely(atomic_try_cmpxchg_acquire(&rwb->readers, &r, r + 1)))\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_read_trylock(rwlock_t *rwlock)\n{\n\tint ret;\n\n\tret = rwbase_read_trylock(&rwlock->rwbase);\n\tif (ret) {\n\t\trwlock_acquire_read(&rwlock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "rwbase_rtmutex_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "177-183",
    "snippet": "static __always_inline int  rwbase_rtmutex_trylock(struct rt_mutex_base *rtm)\n{\n\tif (likely(rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\treturn 1;\n\n\treturn rt_mutex_slowtrylock(rtm);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_mutex_slowtrylock",
          "args": [
            "rtm"
          ],
          "line": 182
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_slowtrylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1252-1276",
          "snippet": "static int __sched rt_mutex_slowtrylock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\tint ret;\n\n\t/*\n\t * If the lock already has an owner we fail to get the lock.\n\t * This can be done without taking the @lock->wait_lock as\n\t * it is only being read, and this is a trylock anyway.\n\t */\n\tif (rt_mutex_owner(lock))\n\t\treturn 0;\n\n\t/*\n\t * The mutex has currently no owner. Lock the wait lock and try to\n\t * acquire the lock. We use irqsave here to support early boot calls.\n\t */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tret = __rt_mutex_slowtrylock(lock);\n\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\treturn ret;\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic int __sched rt_mutex_slowtrylock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\tint ret;\n\n\t/*\n\t * If the lock already has an owner we fail to get the lock.\n\t * This can be done without taking the @lock->wait_lock as\n\t * it is only being read, and this is a trylock anyway.\n\t */\n\tif (rt_mutex_owner(lock))\n\t\treturn 0;\n\n\t/*\n\t * The mutex has currently no owner. Lock the wait lock and try to\n\t * acquire the lock. We use irqsave here to support early boot calls.\n\t */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tret = __rt_mutex_slowtrylock(lock);\n\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "rt_mutex_cmpxchg_acquire(rtm, NULL, current)"
          ],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_cmpxchg_acquire",
          "args": [
            "rtm",
            "NULL",
            "current"
          ],
          "line": 179
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cmpxchg_acquire",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "253-259",
          "snippet": "static __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline int  rwbase_rtmutex_trylock(struct rt_mutex_base *rtm)\n{\n\tif (likely(rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\treturn 1;\n\n\treturn rt_mutex_slowtrylock(rtm);\n}"
  },
  {
    "function_name": "rwbase_rtmutex_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "169-175",
    "snippet": "static __always_inline void rwbase_rtmutex_unlock(struct rt_mutex_base *rtm)\n{\n\tif (likely(rt_mutex_cmpxchg_acquire(rtm, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(rtm);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_mutex_slowunlock",
          "args": [
            "rtm"
          ],
          "line": 174
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_slowunlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1289-1348",
          "snippet": "static void __sched rt_mutex_slowunlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\n\t/* irqsave required to support early boot calls */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tdebug_rt_mutex_unlock(lock);\n\n\t/*\n\t * We must be careful here if the fast path is enabled. If we\n\t * have no waiters queued we cannot set owner to NULL here\n\t * because of:\n\t *\n\t * foo->lock->owner = NULL;\n\t *\t\t\trtmutex_lock(foo->lock);   <- fast path\n\t *\t\t\tfree = atomic_dec_and_test(foo->refcnt);\n\t *\t\t\trtmutex_unlock(foo->lock); <- fast path\n\t *\t\t\tif (free)\n\t *\t\t\t\tkfree(foo);\n\t * raw_spin_unlock(foo->lock->wait_lock);\n\t *\n\t * So for the fastpath enabled kernel:\n\t *\n\t * Nothing can set the waiters bit as long as we hold\n\t * lock->wait_lock. So we do the following sequence:\n\t *\n\t *\towner = rt_mutex_owner(lock);\n\t *\tclear_rt_mutex_waiters(lock);\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t *\tif (cmpxchg(&lock->owner, owner, 0) == owner)\n\t *\t\treturn;\n\t *\tgoto retry;\n\t *\n\t * The fastpath disabled variant is simple as all access to\n\t * lock->owner is serialized by lock->wait_lock:\n\t *\n\t *\tlock->owner = NULL;\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t */\n\twhile (!rt_mutex_has_waiters(lock)) {\n\t\t/* Drops lock->wait_lock ! */\n\t\tif (unlock_rt_mutex_safe(lock, flags) == true)\n\t\t\treturn;\n\t\t/* Relock the rtmutex and try again */\n\t\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\t}\n\n\t/*\n\t * The wakeup next waiter path does not suffer from the above\n\t * race. See the comments there.\n\t *\n\t * Queue the next waiter for wakeup once we release the wait_lock.\n\t */\n\tmark_wakeup_next_waiter(&wqh, lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\trt_mutex_wake_up_q(&wqh);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic void __sched rt_mutex_slowunlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\n\t/* irqsave required to support early boot calls */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tdebug_rt_mutex_unlock(lock);\n\n\t/*\n\t * We must be careful here if the fast path is enabled. If we\n\t * have no waiters queued we cannot set owner to NULL here\n\t * because of:\n\t *\n\t * foo->lock->owner = NULL;\n\t *\t\t\trtmutex_lock(foo->lock);   <- fast path\n\t *\t\t\tfree = atomic_dec_and_test(foo->refcnt);\n\t *\t\t\trtmutex_unlock(foo->lock); <- fast path\n\t *\t\t\tif (free)\n\t *\t\t\t\tkfree(foo);\n\t * raw_spin_unlock(foo->lock->wait_lock);\n\t *\n\t * So for the fastpath enabled kernel:\n\t *\n\t * Nothing can set the waiters bit as long as we hold\n\t * lock->wait_lock. So we do the following sequence:\n\t *\n\t *\towner = rt_mutex_owner(lock);\n\t *\tclear_rt_mutex_waiters(lock);\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t *\tif (cmpxchg(&lock->owner, owner, 0) == owner)\n\t *\t\treturn;\n\t *\tgoto retry;\n\t *\n\t * The fastpath disabled variant is simple as all access to\n\t * lock->owner is serialized by lock->wait_lock:\n\t *\n\t *\tlock->owner = NULL;\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t */\n\twhile (!rt_mutex_has_waiters(lock)) {\n\t\t/* Drops lock->wait_lock ! */\n\t\tif (unlock_rt_mutex_safe(lock, flags) == true)\n\t\t\treturn;\n\t\t/* Relock the rtmutex and try again */\n\t\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\t}\n\n\t/*\n\t * The wakeup next waiter path does not suffer from the above\n\t * race. See the comments there.\n\t *\n\t * Queue the next waiter for wakeup once we release the wait_lock.\n\t */\n\tmark_wakeup_next_waiter(&wqh, lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\trt_mutex_wake_up_q(&wqh);\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "rt_mutex_cmpxchg_acquire(rtm, current, NULL)"
          ],
          "line": 171
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_cmpxchg_acquire",
          "args": [
            "rtm",
            "current",
            "NULL"
          ],
          "line": 171
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cmpxchg_acquire",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "253-259",
          "snippet": "static __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void rwbase_rtmutex_unlock(struct rt_mutex_base *rtm)\n{\n\tif (likely(rt_mutex_cmpxchg_acquire(rtm, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(rtm);\n}"
  },
  {
    "function_name": "rwbase_rtmutex_slowlock_locked",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "162-167",
    "snippet": "static __always_inline int\nrwbase_rtmutex_slowlock_locked(struct rt_mutex_base *rtm, unsigned int state)\n{\n\trtlock_slowlock_locked(rtm);\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rtlock_slowlock_locked",
          "args": [
            "rtm"
          ],
          "line": 165
        },
        "resolved": true,
        "details": {
          "function_name": "rtlock_slowlock_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1671-1715",
          "snippet": "static void __sched rtlock_slowlock_locked(struct rt_mutex_base *lock)\n{\n\tstruct rt_mutex_waiter waiter;\n\tstruct task_struct *owner;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tif (try_to_take_rt_mutex(lock, current, NULL))\n\t\treturn;\n\n\trt_mutex_init_rtlock_waiter(&waiter);\n\n\t/* Save current state and set state to TASK_RTLOCK_WAIT */\n\tcurrent_save_and_set_rtlock_wait_state();\n\n\ttask_blocks_on_rt_mutex(lock, &waiter, current, NULL, RT_MUTEX_MIN_CHAINWALK);\n\n\tfor (;;) {\n\t\t/* Try to acquire the lock again */\n\t\tif (try_to_take_rt_mutex(lock, current, &waiter))\n\t\t\tbreak;\n\n\t\tif (&waiter == rt_mutex_top_waiter(lock))\n\t\t\towner = rt_mutex_owner(lock);\n\t\telse\n\t\t\towner = NULL;\n\t\traw_spin_unlock_irq(&lock->wait_lock);\n\n\t\tif (!owner || !rtmutex_spin_on_owner(lock, &waiter, owner))\n\t\t\tschedule_rtlock();\n\n\t\traw_spin_lock_irq(&lock->wait_lock);\n\t\tset_current_state(TASK_RTLOCK_WAIT);\n\t}\n\n\t/* Restore the task state */\n\tcurrent_restore_rtlock_saved_state();\n\n\t/*\n\t * try_to_take_rt_mutex() sets the waiter bit unconditionally.\n\t * We might have to fix that up:\n\t */\n\tfixup_rt_mutex_waiters(lock);\n\tdebug_rt_mutex_free_waiter(&waiter);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic void __sched rtlock_slowlock_locked(struct rt_mutex_base *lock)\n{\n\tstruct rt_mutex_waiter waiter;\n\tstruct task_struct *owner;\n\n\tlockdep_assert_held(&lock->wait_lock);\n\n\tif (try_to_take_rt_mutex(lock, current, NULL))\n\t\treturn;\n\n\trt_mutex_init_rtlock_waiter(&waiter);\n\n\t/* Save current state and set state to TASK_RTLOCK_WAIT */\n\tcurrent_save_and_set_rtlock_wait_state();\n\n\ttask_blocks_on_rt_mutex(lock, &waiter, current, NULL, RT_MUTEX_MIN_CHAINWALK);\n\n\tfor (;;) {\n\t\t/* Try to acquire the lock again */\n\t\tif (try_to_take_rt_mutex(lock, current, &waiter))\n\t\t\tbreak;\n\n\t\tif (&waiter == rt_mutex_top_waiter(lock))\n\t\t\towner = rt_mutex_owner(lock);\n\t\telse\n\t\t\towner = NULL;\n\t\traw_spin_unlock_irq(&lock->wait_lock);\n\n\t\tif (!owner || !rtmutex_spin_on_owner(lock, &waiter, owner))\n\t\t\tschedule_rtlock();\n\n\t\traw_spin_lock_irq(&lock->wait_lock);\n\t\tset_current_state(TASK_RTLOCK_WAIT);\n\t}\n\n\t/* Restore the task state */\n\tcurrent_restore_rtlock_saved_state();\n\n\t/*\n\t * try_to_take_rt_mutex() sets the waiter bit unconditionally.\n\t * We might have to fix that up:\n\t */\n\tfixup_rt_mutex_waiters(lock);\n\tdebug_rt_mutex_free_waiter(&waiter);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline int\nrwbase_rtmutex_slowlock_locked(struct rt_mutex_base *rtm, unsigned int state)\n{\n\trtlock_slowlock_locked(rtm);\n\treturn 0;\n}"
  },
  {
    "function_name": "rwbase_rtmutex_lock_state",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "154-160",
    "snippet": "static __always_inline int\nrwbase_rtmutex_lock_state(struct rt_mutex_base *rtm, unsigned int state)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rtlock_slowlock",
          "args": [
            "rtm"
          ],
          "line": 158
        },
        "resolved": true,
        "details": {
          "function_name": "rtlock_slowlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1717-1724",
          "snippet": "__sched rtlock_slowlock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\trtlock_slowlock_locked(lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\n__sched rtlock_slowlock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\trtlock_slowlock_locked(lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rt_mutex_cmpxchg_acquire(rtm, NULL, current)"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_cmpxchg_acquire",
          "args": [
            "rtm",
            "NULL",
            "current"
          ],
          "line": 157
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cmpxchg_acquire",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "253-259",
          "snippet": "static __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline int\nrwbase_rtmutex_lock_state(struct rt_mutex_base *rtm, unsigned int state)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n\treturn 0;\n}"
  },
  {
    "function_name": "__rt_spin_lock_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "133-141",
    "snippet": "void __rt_spin_lock_init(spinlock_t *lock, const char *name,\n\t\t\t struct lock_class_key *key, bool percpu)\n{\n\tu8 type = percpu ? LD_LOCK_PERCPU : LD_LOCK_NORMAL;\n\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map_type(&lock->dep_map, name, key, 0, LD_WAIT_CONFIG,\n\t\t\t      LD_WAIT_INV, type);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lockdep_init_map_type",
          "args": [
            "&lock->dep_map",
            "name",
            "key",
            "0",
            "LD_WAIT_CONFIG",
            "LD_WAIT_INV",
            "type"
          ],
          "line": 139
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_init_map_type",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "4774-4833",
          "snippet": "void lockdep_init_map_type(struct lockdep_map *lock, const char *name,\n\t\t\t    struct lock_class_key *key, int subclass,\n\t\t\t    u8 inner, u8 outer, u8 lock_type)\n{\n\tint i;\n\n\tfor (i = 0; i < NR_LOCKDEP_CACHING_CLASSES; i++)\n\t\tlock->class_cache[i] = NULL;\n\n#ifdef CONFIG_LOCK_STAT\n\tlock->cpu = raw_smp_processor_id();\n#endif\n\n\t/*\n\t * Can't be having no nameless bastards around this place!\n\t */\n\tif (DEBUG_LOCKS_WARN_ON(!name)) {\n\t\tlock->name = \"NULL\";\n\t\treturn;\n\t}\n\n\tlock->name = name;\n\n\tlock->wait_type_outer = outer;\n\tlock->wait_type_inner = inner;\n\tlock->lock_type = lock_type;\n\n\t/*\n\t * No key, no joy, we need to hash something.\n\t */\n\tif (DEBUG_LOCKS_WARN_ON(!key))\n\t\treturn;\n\t/*\n\t * Sanity check, the lock-class key must either have been allocated\n\t * statically or must have been registered as a dynamic key.\n\t */\n\tif (!static_obj(key) && !is_dynamic_key(key)) {\n\t\tif (debug_locks)\n\t\t\tprintk(KERN_ERR \"BUG: key %px has not been registered!\\n\", key);\n\t\tDEBUG_LOCKS_WARN_ON(1);\n\t\treturn;\n\t}\n\tlock->key = key;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\tif (subclass) {\n\t\tunsigned long flags;\n\n\t\tif (DEBUG_LOCKS_WARN_ON(!lockdep_enabled()))\n\t\t\treturn;\n\n\t\traw_local_irq_save(flags);\n\t\tlockdep_recursion_inc();\n\t\tregister_lock_class(lock, subclass, 1);\n\t\tlockdep_recursion_finish();\n\t\traw_local_irq_restore(flags);\n\t}\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid lockdep_init_map_type(struct lockdep_map *lock, const char *name,\n\t\t\t    struct lock_class_key *key, int subclass,\n\t\t\t    u8 inner, u8 outer, u8 lock_type)\n{\n\tint i;\n\n\tfor (i = 0; i < NR_LOCKDEP_CACHING_CLASSES; i++)\n\t\tlock->class_cache[i] = NULL;\n\n#ifdef CONFIG_LOCK_STAT\n\tlock->cpu = raw_smp_processor_id();\n#endif\n\n\t/*\n\t * Can't be having no nameless bastards around this place!\n\t */\n\tif (DEBUG_LOCKS_WARN_ON(!name)) {\n\t\tlock->name = \"NULL\";\n\t\treturn;\n\t}\n\n\tlock->name = name;\n\n\tlock->wait_type_outer = outer;\n\tlock->wait_type_inner = inner;\n\tlock->lock_type = lock_type;\n\n\t/*\n\t * No key, no joy, we need to hash something.\n\t */\n\tif (DEBUG_LOCKS_WARN_ON(!key))\n\t\treturn;\n\t/*\n\t * Sanity check, the lock-class key must either have been allocated\n\t * statically or must have been registered as a dynamic key.\n\t */\n\tif (!static_obj(key) && !is_dynamic_key(key)) {\n\t\tif (debug_locks)\n\t\t\tprintk(KERN_ERR \"BUG: key %px has not been registered!\\n\", key);\n\t\tDEBUG_LOCKS_WARN_ON(1);\n\t\treturn;\n\t}\n\tlock->key = key;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\tif (subclass) {\n\t\tunsigned long flags;\n\n\t\tif (DEBUG_LOCKS_WARN_ON(!lockdep_enabled()))\n\t\t\treturn;\n\n\t\traw_local_irq_save(flags);\n\t\tlockdep_recursion_inc();\n\t\tregister_lock_class(lock, subclass, 1);\n\t\tlockdep_recursion_finish();\n\t\traw_local_irq_restore(flags);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_check_no_locks_freed",
          "args": [
            "(void *)lock",
            "sizeof(*lock)"
          ],
          "line": 138
        },
        "resolved": true,
        "details": {
          "function_name": "debug_check_no_locks_freed",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "6405-6427",
          "snippet": "void debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __rt_spin_lock_init(spinlock_t *lock, const char *name,\n\t\t\t struct lock_class_key *key, bool percpu)\n{\n\tu8 type = percpu ? LD_LOCK_PERCPU : LD_LOCK_NORMAL;\n\n\tdebug_check_no_locks_freed((void *)lock, sizeof(*lock));\n\tlockdep_init_map_type(&lock->dep_map, name, key, 0, LD_WAIT_CONFIG,\n\t\t\t      LD_WAIT_INV, type);\n}"
  },
  {
    "function_name": "rt_spin_trylock_bh",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "120-129",
    "snippet": "int __sched rt_spin_trylock_bh(spinlock_t *lock)\n{\n\tint ret;\n\n\tlocal_bh_disable();\n\tret = __rt_spin_trylock(lock);\n\tif (!ret)\n\t\tlocal_bh_enable();\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_bh_enable",
          "args": [],
          "line": 127
        },
        "resolved": true,
        "details": {
          "function_name": "_local_bh_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/softirq.c",
          "lines": "353-357",
          "snippet": "void _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}",
          "includes": [
            "#include <trace/events/irq.h>",
            "#include <asm/softirq_stack.h>",
            "#include <linux/wait_bit.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cpu.h>",
            "#include <linux/percpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/mm.h>",
            "#include <linux/local_lock.h>",
            "#include <linux/init.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/irq.h>\n#include <asm/softirq_stack.h>\n#include <linux/wait_bit.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/ftrace.h>\n#include <linux/rcupdate.h>\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n#include <linux/cpu.h>\n#include <linux/percpu.h>\n#include <linux/notifier.h>\n#include <linux/mm.h>\n#include <linux/local_lock.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel_stat.h>\n#include <linux/export.h>\n\nvoid _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__rt_spin_trylock",
          "args": [
            "lock"
          ],
          "line": 125
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_spin_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "99-112",
          "snippet": "static __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_bh_disable",
          "args": [],
          "line": 124
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_spin_trylock_bh(spinlock_t *lock)\n{\n\tint ret;\n\n\tlocal_bh_disable();\n\tret = __rt_spin_trylock(lock);\n\tif (!ret)\n\t\tlocal_bh_enable();\n\treturn ret;\n}"
  },
  {
    "function_name": "rt_spin_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "114-117",
    "snippet": "int __sched rt_spin_trylock(spinlock_t *lock)\n{\n\treturn __rt_spin_trylock(lock);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rt_spin_trylock",
          "args": [
            "lock"
          ],
          "line": 116
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_spin_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "99-112",
          "snippet": "static __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_spin_trylock(spinlock_t *lock)\n{\n\treturn __rt_spin_trylock(lock);\n}"
  },
  {
    "function_name": "__rt_spin_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "99-112",
    "snippet": "static __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 109
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 108
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_acquire",
          "args": [
            "&lock->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 107
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_slowtrylock",
          "args": [
            "&lock->lock"
          ],
          "line": 104
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_slowtrylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1252-1276",
          "snippet": "static int __sched rt_mutex_slowtrylock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\tint ret;\n\n\t/*\n\t * If the lock already has an owner we fail to get the lock.\n\t * This can be done without taking the @lock->wait_lock as\n\t * it is only being read, and this is a trylock anyway.\n\t */\n\tif (rt_mutex_owner(lock))\n\t\treturn 0;\n\n\t/*\n\t * The mutex has currently no owner. Lock the wait lock and try to\n\t * acquire the lock. We use irqsave here to support early boot calls.\n\t */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tret = __rt_mutex_slowtrylock(lock);\n\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\treturn ret;\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic int __sched rt_mutex_slowtrylock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\tint ret;\n\n\t/*\n\t * If the lock already has an owner we fail to get the lock.\n\t * This can be done without taking the @lock->wait_lock as\n\t * it is only being read, and this is a trylock anyway.\n\t */\n\tif (rt_mutex_owner(lock))\n\t\treturn 0;\n\n\t/*\n\t * The mutex has currently no owner. Lock the wait lock and try to\n\t * acquire the lock. We use irqsave here to support early boot calls.\n\t */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tret = __rt_mutex_slowtrylock(lock);\n\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)"
          ],
          "line": 103
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_cmpxchg_acquire",
          "args": [
            "&lock->lock",
            "NULL",
            "current"
          ],
          "line": 103
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cmpxchg_acquire",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "253-259",
          "snippet": "static __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline int __rt_spin_trylock(spinlock_t *lock)\n{\n\tint ret = 1;\n\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(&lock->lock, NULL, current)))\n\t\tret = rt_mutex_slowtrylock(&lock->lock);\n\n\tif (ret) {\n\t\tspin_acquire(&lock->dep_map, 0, 1, _RET_IP_);\n\t\trcu_read_lock();\n\t\tmigrate_disable();\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "rt_spin_lock_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "92-96",
    "snippet": "void __sched rt_spin_lock_unlock(spinlock_t *lock)\n{\n\tspin_lock(lock);\n\tspin_unlock(lock);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "lock"
          ],
          "line": 95
        },
        "resolved": true,
        "details": {
          "function_name": "rt_spin_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "76-84",
          "snippet": "void __sched rt_spin_unlock(spinlock_t *lock)\n{\n\tspin_release(&lock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\tif (unlikely(!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)))\n\t\trt_mutex_slowunlock(&lock->lock);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_spin_unlock(spinlock_t *lock)\n{\n\tspin_release(&lock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\tif (unlikely(!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)))\n\t\trt_mutex_slowunlock(&lock->lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "lock"
          ],
          "line": 94
        },
        "resolved": true,
        "details": {
          "function_name": "rt_spin_lock_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "92-96",
          "snippet": "void __sched rt_spin_lock_unlock(spinlock_t *lock)\n{\n\tspin_lock(lock);\n\tspin_unlock(lock);\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_spin_lock_unlock(spinlock_t *lock)\n{\n\tspin_lock(lock);\n\tspin_unlock(lock);\n}"
  },
  {
    "function_name": "rt_spin_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "76-84",
    "snippet": "void __sched rt_spin_unlock(spinlock_t *lock)\n{\n\tspin_release(&lock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\tif (unlikely(!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)))\n\t\trt_mutex_slowunlock(&lock->lock);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_mutex_slowunlock",
          "args": [
            "&lock->lock"
          ],
          "line": 83
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_slowunlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1289-1348",
          "snippet": "static void __sched rt_mutex_slowunlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\n\t/* irqsave required to support early boot calls */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tdebug_rt_mutex_unlock(lock);\n\n\t/*\n\t * We must be careful here if the fast path is enabled. If we\n\t * have no waiters queued we cannot set owner to NULL here\n\t * because of:\n\t *\n\t * foo->lock->owner = NULL;\n\t *\t\t\trtmutex_lock(foo->lock);   <- fast path\n\t *\t\t\tfree = atomic_dec_and_test(foo->refcnt);\n\t *\t\t\trtmutex_unlock(foo->lock); <- fast path\n\t *\t\t\tif (free)\n\t *\t\t\t\tkfree(foo);\n\t * raw_spin_unlock(foo->lock->wait_lock);\n\t *\n\t * So for the fastpath enabled kernel:\n\t *\n\t * Nothing can set the waiters bit as long as we hold\n\t * lock->wait_lock. So we do the following sequence:\n\t *\n\t *\towner = rt_mutex_owner(lock);\n\t *\tclear_rt_mutex_waiters(lock);\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t *\tif (cmpxchg(&lock->owner, owner, 0) == owner)\n\t *\t\treturn;\n\t *\tgoto retry;\n\t *\n\t * The fastpath disabled variant is simple as all access to\n\t * lock->owner is serialized by lock->wait_lock:\n\t *\n\t *\tlock->owner = NULL;\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t */\n\twhile (!rt_mutex_has_waiters(lock)) {\n\t\t/* Drops lock->wait_lock ! */\n\t\tif (unlock_rt_mutex_safe(lock, flags) == true)\n\t\t\treturn;\n\t\t/* Relock the rtmutex and try again */\n\t\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\t}\n\n\t/*\n\t * The wakeup next waiter path does not suffer from the above\n\t * race. See the comments there.\n\t *\n\t * Queue the next waiter for wakeup once we release the wait_lock.\n\t */\n\tmark_wakeup_next_waiter(&wqh, lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\trt_mutex_wake_up_q(&wqh);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic void __sched rt_mutex_slowunlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\n\t/* irqsave required to support early boot calls */\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\n\tdebug_rt_mutex_unlock(lock);\n\n\t/*\n\t * We must be careful here if the fast path is enabled. If we\n\t * have no waiters queued we cannot set owner to NULL here\n\t * because of:\n\t *\n\t * foo->lock->owner = NULL;\n\t *\t\t\trtmutex_lock(foo->lock);   <- fast path\n\t *\t\t\tfree = atomic_dec_and_test(foo->refcnt);\n\t *\t\t\trtmutex_unlock(foo->lock); <- fast path\n\t *\t\t\tif (free)\n\t *\t\t\t\tkfree(foo);\n\t * raw_spin_unlock(foo->lock->wait_lock);\n\t *\n\t * So for the fastpath enabled kernel:\n\t *\n\t * Nothing can set the waiters bit as long as we hold\n\t * lock->wait_lock. So we do the following sequence:\n\t *\n\t *\towner = rt_mutex_owner(lock);\n\t *\tclear_rt_mutex_waiters(lock);\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t *\tif (cmpxchg(&lock->owner, owner, 0) == owner)\n\t *\t\treturn;\n\t *\tgoto retry;\n\t *\n\t * The fastpath disabled variant is simple as all access to\n\t * lock->owner is serialized by lock->wait_lock:\n\t *\n\t *\tlock->owner = NULL;\n\t *\traw_spin_unlock(&lock->wait_lock);\n\t */\n\twhile (!rt_mutex_has_waiters(lock)) {\n\t\t/* Drops lock->wait_lock ! */\n\t\tif (unlock_rt_mutex_safe(lock, flags) == true)\n\t\t\treturn;\n\t\t/* Relock the rtmutex and try again */\n\t\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\t}\n\n\t/*\n\t * The wakeup next waiter path does not suffer from the above\n\t * race. See the comments there.\n\t *\n\t * Queue the next waiter for wakeup once we release the wait_lock.\n\t */\n\tmark_wakeup_next_waiter(&wqh, lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\trt_mutex_wake_up_q(&wqh);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)"
          ],
          "line": 82
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_cmpxchg_release",
          "args": [
            "&lock->lock",
            "current",
            "NULL"
          ],
          "line": 82
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cmpxchg_release",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "261-266",
          "snippet": "static __always_inline bool rt_mutex_cmpxchg_release(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline bool rt_mutex_cmpxchg_release(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 80
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "migrate_enable",
          "args": [],
          "line": 79
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2178-2206",
          "snippet": "void migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_enable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled > 1) {\n\t\tp->migration_disabled--;\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(!p->migration_disabled))\n\t\treturn;\n\n\t/*\n\t * Ensure stop_task runs either before or after this, and that\n\t * __set_cpus_allowed_ptr(SCA_MIGRATE_ENABLE) doesn't schedule().\n\t */\n\tpreempt_disable();\n\tif (p->cpus_ptr != &p->cpus_mask)\n\t\t__set_cpus_allowed_ptr(p, &p->cpus_mask, SCA_MIGRATE_ENABLE);\n\t/*\n\t * Mustn't clear migration_disabled() until cpus_ptr points back at the\n\t * regular cpus_mask, otherwise things that race (eg.\n\t * select_fallback_rq) get confused.\n\t */\n\tbarrier();\n\tp->migration_disabled = 0;\n\tthis_rq()->nr_pinned--;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_release",
          "args": [
            "&lock->dep_map",
            "_RET_IP_"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_spin_unlock(spinlock_t *lock)\n{\n\tspin_release(&lock->dep_map, _RET_IP_);\n\tmigrate_enable();\n\trcu_read_unlock();\n\n\tif (unlikely(!rt_mutex_cmpxchg_release(&lock->lock, current, NULL)))\n\t\trt_mutex_slowunlock(&lock->lock);\n}"
  },
  {
    "function_name": "rt_spin_lock_nest_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "67-72",
    "snippet": "void __sched rt_spin_lock_nest_lock(spinlock_t *lock,\n\t\t\t\t    struct lockdep_map *nest_lock)\n{\n\tspin_acquire_nest(&lock->dep_map, 0, 0, nest_lock, _RET_IP_);\n\t__rt_spin_lock(lock);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rt_spin_lock",
          "args": [
            "lock"
          ],
          "line": 71
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "44-50",
          "snippet": "static __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_acquire_nest",
          "args": [
            "&lock->dep_map",
            "0",
            "0",
            "nest_lock",
            "_RET_IP_"
          ],
          "line": 70
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_spin_lock_nest_lock(spinlock_t *lock,\n\t\t\t\t    struct lockdep_map *nest_lock)\n{\n\tspin_acquire_nest(&lock->dep_map, 0, 0, nest_lock, _RET_IP_);\n\t__rt_spin_lock(lock);\n}"
  },
  {
    "function_name": "rt_spin_lock_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "60-64",
    "snippet": "void __sched rt_spin_lock_nested(spinlock_t *lock, int subclass)\n{\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\t__rt_spin_lock(lock);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rt_spin_lock",
          "args": [
            "lock"
          ],
          "line": 63
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "44-50",
          "snippet": "static __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_acquire",
          "args": [
            "&lock->dep_map",
            "subclass",
            "0",
            "_RET_IP_"
          ],
          "line": 62
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_spin_lock_nested(spinlock_t *lock, int subclass)\n{\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\t__rt_spin_lock(lock);\n}"
  },
  {
    "function_name": "rt_spin_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "52-56",
    "snippet": "void __sched rt_spin_lock(spinlock_t *lock)\n{\n\tspin_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\t__rt_spin_lock(lock);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rt_spin_lock",
          "args": [
            "lock"
          ],
          "line": 55
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "44-50",
          "snippet": "static __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_acquire",
          "args": [
            "&lock->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 54
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_spin_lock(spinlock_t *lock)\n{\n\tspin_acquire(&lock->dep_map, 0, 0, _RET_IP_);\n\t__rt_spin_lock(lock);\n}"
  },
  {
    "function_name": "__rt_spin_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "44-50",
    "snippet": "static __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "migrate_disable",
          "args": [],
          "line": 49
        },
        "resolved": true,
        "details": {
          "function_name": "migrate_disable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2162-2175",
          "snippet": "void migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid migrate_disable(void)\n{\n\tstruct task_struct *p = current;\n\n\tif (p->migration_disabled) {\n\t\tp->migration_disabled++;\n\t\treturn;\n\t}\n\n\tpreempt_disable();\n\tthis_rq()->nr_pinned++;\n\tp->migration_disabled = 1;\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 48
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtlock_lock",
          "args": [
            "&lock->lock"
          ],
          "line": 47
        },
        "resolved": true,
        "details": {
          "function_name": "rtlock_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
          "lines": "38-42",
          "snippet": "static __always_inline void rtlock_lock(struct rt_mutex_base *rtm)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void rtlock_lock(struct rt_mutex_base *rtm)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtlock_might_resched",
          "args": [],
          "line": 46
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void __rt_spin_lock(spinlock_t *lock)\n{\n\trtlock_might_resched();\n\trtlock_lock(&lock->lock);\n\trcu_read_lock();\n\tmigrate_disable();\n}"
  },
  {
    "function_name": "rtlock_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock_rt.c",
    "lines": "38-42",
    "snippet": "static __always_inline void rtlock_lock(struct rt_mutex_base *rtm)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include <linux/export.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rtlock_slowlock",
          "args": [
            "rtm"
          ],
          "line": 41
        },
        "resolved": true,
        "details": {
          "function_name": "rtlock_slowlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1717-1724",
          "snippet": "__sched rtlock_slowlock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\trtlock_slowlock_locked(lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\n__sched rtlock_slowlock(struct rt_mutex_base *lock)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\trtlock_slowlock_locked(lock);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rt_mutex_cmpxchg_acquire(rtm, NULL, current)"
          ],
          "line": 40
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_cmpxchg_acquire",
          "args": [
            "rtm",
            "NULL",
            "current"
          ],
          "line": 40
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cmpxchg_acquire",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "253-259",
          "snippet": "static __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline bool rt_mutex_cmpxchg_acquire(struct rt_mutex_base *lock,\n\t\t\t\t\t\t     struct task_struct *old,\n\t\t\t\t\t\t     struct task_struct *new)\n{\n\treturn false;\n\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nstatic __always_inline void rtlock_lock(struct rt_mutex_base *rtm)\n{\n\tif (unlikely(!rt_mutex_cmpxchg_acquire(rtm, NULL, current)))\n\t\trtlock_slowlock(rtm);\n}"
  }
]