[
  {
    "function_name": "bpf_event_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2171-2175",
    "snippet": "static int __init bpf_event_init(void)\n{\n\tregister_module_notifier(&bpf_module_nb);\n\treturn 0;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "register_module_notifier",
          "args": [
            "&bpf_module_nb"
          ],
          "line": 2173
        },
        "resolved": true,
        "details": {
          "function_name": "unregister_module_notifier",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/module.c",
          "lines": "307-310",
          "snippet": "int unregister_module_notifier(struct notifier_block *nb)\n{\n\treturn blocking_notifier_chain_unregister(&module_notify_list, nb);\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include \"module-internal.h\"",
            "#include <uapi/linux/module.h>",
            "#include <linux/audit.h>",
            "#include <linux/dynamic_debug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/pfn.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/percpu.h>",
            "#include <linux/async.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/tracepoint.h>",
            "#include <asm/sections.h>",
            "#include <linux/license.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/set_memory.h>",
            "#include <asm/cacheflush.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/mutex.h>",
            "#include <linux/string.h>",
            "#include <linux/device.h>",
            "#include <linux/sched.h>",
            "#include <linux/notifier.h>",
            "#include <linux/vermagic.h>",
            "#include <linux/err.h>",
            "#include <linux/errno.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/elf.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel_read_file.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/buildid.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/module_signature.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/extable.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static BLOCKING_NOTIFIER_HEAD(module_notify_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include \"module-internal.h\"\n#include <uapi/linux/module.h>\n#include <linux/audit.h>\n#include <linux/dynamic_debug.h>\n#include <linux/bsearch.h>\n#include <linux/pfn.h>\n#include <linux/jump_label.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/async.h>\n#include <linux/livepatch.h>\n#include <linux/ftrace.h>\n#include <linux/tracepoint.h>\n#include <asm/sections.h>\n#include <linux/license.h>\n#include <asm/mmu_context.h>\n#include <linux/set_memory.h>\n#include <asm/cacheflush.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/mutex.h>\n#include <linux/string.h>\n#include <linux/device.h>\n#include <linux/sched.h>\n#include <linux/notifier.h>\n#include <linux/vermagic.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/moduleparam.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/rcupdate.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/elf.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/kernel_read_file.h>\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/buildid.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/trace_events.h>\n#include <linux/module_signature.h>\n#include <linux/moduleloader.h>\n#include <linux/extable.h>\n#include <linux/export.h>\n\nstatic BLOCKING_NOTIFIER_HEAD(module_notify_list);\n\nint unregister_module_notifier(struct notifier_block *nb)\n{\n\treturn blocking_notifier_chain_unregister(&module_notify_list, nb);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic int __init bpf_event_init(void)\n{\n\tregister_module_notifier(&bpf_module_nb);\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_event_notify",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2127-2165",
    "snippet": "static int bpf_event_notify(struct notifier_block *nb, unsigned long op,\n\t\t\t    void *module)\n{\n\tstruct bpf_trace_module *btm, *tmp;\n\tstruct module *mod = module;\n\tint ret = 0;\n\n\tif (mod->num_bpf_raw_events == 0 ||\n\t    (op != MODULE_STATE_COMING && op != MODULE_STATE_GOING))\n\t\tgoto out;\n\n\tmutex_lock(&bpf_module_mutex);\n\n\tswitch (op) {\n\tcase MODULE_STATE_COMING:\n\t\tbtm = kzalloc(sizeof(*btm), GFP_KERNEL);\n\t\tif (btm) {\n\t\t\tbtm->module = module;\n\t\t\tlist_add(&btm->list, &bpf_trace_modules);\n\t\t} else {\n\t\t\tret = -ENOMEM;\n\t\t}\n\t\tbreak;\n\tcase MODULE_STATE_GOING:\n\t\tlist_for_each_entry_safe(btm, tmp, &bpf_trace_modules, list) {\n\t\t\tif (btm->module == module) {\n\t\t\t\tlist_del(&btm->list);\n\t\t\t\tkfree(btm);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&bpf_module_mutex);\n\nout:\n\treturn notifier_from_errno(ret);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "notifier_from_errno",
          "args": [
            "ret"
          ],
          "line": 2164
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&bpf_module_mutex"
          ],
          "line": 2161
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "btm"
          ],
          "line": 2154
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&btm->list"
          ],
          "line": 2153
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/fair.c",
          "lines": "475-477",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);",
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "btm",
            "tmp",
            "&bpf_trace_modules",
            "list"
          ],
          "line": 2151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&btm->list",
            "&bpf_trace_modules"
          ],
          "line": 2145
        },
        "resolved": true,
        "details": {
          "function_name": "cmp_filterlist_addrs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/debugfs.c",
          "lines": "95-101",
          "snippet": "static int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}",
          "includes": [
            "#include \"kcsan.h\"",
            "#include <linux/uaccess.h>",
            "#include <linux/string.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/bug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kcsan.h\"\n#include <linux/uaccess.h>\n#include <linux/string.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/sched.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/debugfs.h>\n#include <linux/bug.h>\n#include <linux/bsearch.h>\n#include <linux/atomic.h>\n\nstatic int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*btm)",
            "GFP_KERNEL"
          ],
          "line": 2142
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&bpf_module_mutex"
          ],
          "line": 2138
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic int bpf_event_notify(struct notifier_block *nb, unsigned long op,\n\t\t\t    void *module)\n{\n\tstruct bpf_trace_module *btm, *tmp;\n\tstruct module *mod = module;\n\tint ret = 0;\n\n\tif (mod->num_bpf_raw_events == 0 ||\n\t    (op != MODULE_STATE_COMING && op != MODULE_STATE_GOING))\n\t\tgoto out;\n\n\tmutex_lock(&bpf_module_mutex);\n\n\tswitch (op) {\n\tcase MODULE_STATE_COMING:\n\t\tbtm = kzalloc(sizeof(*btm), GFP_KERNEL);\n\t\tif (btm) {\n\t\t\tbtm->module = module;\n\t\t\tlist_add(&btm->list, &bpf_trace_modules);\n\t\t} else {\n\t\t\tret = -ENOMEM;\n\t\t}\n\t\tbreak;\n\tcase MODULE_STATE_GOING:\n\t\tlist_for_each_entry_safe(btm, tmp, &bpf_trace_modules, list) {\n\t\t\tif (btm->module == module) {\n\t\t\t\tlist_del(&btm->list);\n\t\t\t\tkfree(btm);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\n\tmutex_unlock(&bpf_module_mutex);\n\nout:\n\treturn notifier_from_errno(ret);\n}"
  },
  {
    "function_name": "send_signal_irq_work_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2112-2122",
    "snippet": "static int __init send_signal_irq_work_init(void)\n{\n\tint cpu;\n\tstruct send_signal_irq_work *work;\n\n\tfor_each_possible_cpu(cpu) {\n\t\twork = per_cpu_ptr(&send_signal_work, cpu);\n\t\tinit_irq_work(&work->irq_work, do_bpf_send_signal);\n\t}\n\treturn 0;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct send_signal_irq_work, send_signal_work);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "init_irq_work",
          "args": [
            "&work->irq_work",
            "do_bpf_send_signal"
          ],
          "line": 2119
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "&send_signal_work",
            "cpu"
          ],
          "line": 2118
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_PER_CPU(struct send_signal_irq_work, send_signal_work);\n\nstatic int __init send_signal_irq_work_init(void)\n{\n\tint cpu;\n\tstruct send_signal_irq_work *work;\n\n\tfor_each_possible_cpu(cpu) {\n\t\twork = per_cpu_ptr(&send_signal_work, cpu);\n\t\tinit_irq_work(&work->irq_work, do_bpf_send_signal);\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_get_perf_event_info",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2065-2110",
    "snippet": "int bpf_get_perf_event_info(const struct perf_event *event, u32 *prog_id,\n\t\t\t    u32 *fd_type, const char **buf,\n\t\t\t    u64 *probe_offset, u64 *probe_addr)\n{\n\tbool is_tracepoint, is_syscall_tp;\n\tstruct bpf_prog *prog;\n\tint flags, err = 0;\n\n\tprog = event->prog;\n\tif (!prog)\n\t\treturn -ENOENT;\n\n\t/* not supporting BPF_PROG_TYPE_PERF_EVENT yet */\n\tif (prog->type == BPF_PROG_TYPE_PERF_EVENT)\n\t\treturn -EOPNOTSUPP;\n\n\t*prog_id = prog->aux->id;\n\tflags = event->tp_event->flags;\n\tis_tracepoint = flags & TRACE_EVENT_FL_TRACEPOINT;\n\tis_syscall_tp = is_syscall_trace_event(event->tp_event);\n\n\tif (is_tracepoint || is_syscall_tp) {\n\t\t*buf = is_tracepoint ? event->tp_event->tp->name\n\t\t\t\t     : event->tp_event->name;\n\t\t*fd_type = BPF_FD_TYPE_TRACEPOINT;\n\t\t*probe_offset = 0x0;\n\t\t*probe_addr = 0x0;\n\t} else {\n\t\t/* kprobe/uprobe */\n\t\terr = -EOPNOTSUPP;\n#ifdef CONFIG_KPROBE_EVENTS\n\t\tif (flags & TRACE_EVENT_FL_KPROBE)\n\t\t\terr = bpf_get_kprobe_info(event, fd_type, buf,\n\t\t\t\t\t\t  probe_offset, probe_addr,\n\t\t\t\t\t\t  event->attr.type == PERF_TYPE_TRACEPOINT);\n#endif\n#ifdef CONFIG_UPROBE_EVENTS\n\t\tif (flags & TRACE_EVENT_FL_UPROBE)\n\t\t\terr = bpf_get_uprobe_info(event, fd_type, buf,\n\t\t\t\t\t\t  probe_offset,\n\t\t\t\t\t\t  event->attr.type == PERF_TYPE_TRACEPOINT);\n#endif\n\t}\n\n\treturn err;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_get_uprobe_info",
          "args": [
            "event",
            "fd_type",
            "buf",
            "probe_offset",
            "event->attr.type == PERF_TYPE_TRACEPOINT"
          ],
          "line": 2103
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_uprobe_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_uprobe.c",
          "lines": "1414-1434",
          "snippet": "int bpf_get_uprobe_info(const struct perf_event *event, u32 *fd_type,\n\t\t\tconst char **filename, u64 *probe_offset,\n\t\t\tbool perf_type_tracepoint)\n{\n\tconst char *pevent = trace_event_name(event->tp_event);\n\tconst char *group = event->tp_event->class->system;\n\tstruct trace_uprobe *tu;\n\n\tif (perf_type_tracepoint)\n\t\ttu = find_probe_event(pevent, group);\n\telse\n\t\ttu = trace_uprobe_primary_from_call(event->tp_event);\n\tif (!tu)\n\t\treturn -EINVAL;\n\n\t*fd_type = is_ret_probe(tu) ? BPF_FD_TYPE_URETPROBE\n\t\t\t\t    : BPF_FD_TYPE_UPROBE;\n\t*filename = tu->filename;\n\t*probe_offset = tu->offset;\n\treturn 0;\n}",
          "includes": [
            "#include \"trace_probe_tmpl.h\"",
            "#include \"trace_probe.h\"",
            "#include \"trace_dynevent.h\"",
            "#include <linux/rculist.h>",
            "#include <linux/string.h>",
            "#include <linux/namei.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/module.h>",
            "#include <linux/ctype.h>",
            "#include <linux/security.h>",
            "#include <linux/bpf-cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int register_uprobe_event(struct trace_uprobe *tu);",
            "static int unregister_uprobe_event(struct trace_uprobe *tu);",
            "static nokprobe_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_probe_tmpl.h\"\n#include \"trace_probe.h\"\n#include \"trace_dynevent.h\"\n#include <linux/rculist.h>\n#include <linux/string.h>\n#include <linux/namei.h>\n#include <linux/uprobes.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/ctype.h>\n#include <linux/security.h>\n#include <linux/bpf-cgroup.h>\n\nstatic int register_uprobe_event(struct trace_uprobe *tu);\nstatic int unregister_uprobe_event(struct trace_uprobe *tu);\nstatic nokprobe_inline struct;\n\nint bpf_get_uprobe_info(const struct perf_event *event, u32 *fd_type,\n\t\t\tconst char **filename, u64 *probe_offset,\n\t\t\tbool perf_type_tracepoint)\n{\n\tconst char *pevent = trace_event_name(event->tp_event);\n\tconst char *group = event->tp_event->class->system;\n\tstruct trace_uprobe *tu;\n\n\tif (perf_type_tracepoint)\n\t\ttu = find_probe_event(pevent, group);\n\telse\n\t\ttu = trace_uprobe_primary_from_call(event->tp_event);\n\tif (!tu)\n\t\treturn -EINVAL;\n\n\t*fd_type = is_ret_probe(tu) ? BPF_FD_TYPE_URETPROBE\n\t\t\t\t    : BPF_FD_TYPE_UPROBE;\n\t*filename = tu->filename;\n\t*probe_offset = tu->offset;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_get_kprobe_info",
          "args": [
            "event",
            "fd_type",
            "buf",
            "probe_offset",
            "probe_addr",
            "event->attr.type == PERF_TYPE_TRACEPOINT"
          ],
          "line": 2097
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_kprobe_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_kprobe.c",
          "lines": "1638-1665",
          "snippet": "int bpf_get_kprobe_info(const struct perf_event *event, u32 *fd_type,\n\t\t\tconst char **symbol, u64 *probe_offset,\n\t\t\tu64 *probe_addr, bool perf_type_tracepoint)\n{\n\tconst char *pevent = trace_event_name(event->tp_event);\n\tconst char *group = event->tp_event->class->system;\n\tstruct trace_kprobe *tk;\n\n\tif (perf_type_tracepoint)\n\t\ttk = find_trace_kprobe(pevent, group);\n\telse\n\t\ttk = trace_kprobe_primary_from_call(event->tp_event);\n\tif (!tk)\n\t\treturn -EINVAL;\n\n\t*fd_type = trace_kprobe_is_return(tk) ? BPF_FD_TYPE_KRETPROBE\n\t\t\t\t\t      : BPF_FD_TYPE_KPROBE;\n\tif (tk->symbol) {\n\t\t*symbol = tk->symbol;\n\t\t*probe_offset = tk->rp.kp.offset;\n\t\t*probe_addr = 0;\n\t} else {\n\t\t*symbol = NULL;\n\t\t*probe_offset = 0;\n\t\t*probe_addr = (unsigned long)tk->rp.kp.addr;\n\t}\n\treturn 0;\n}",
          "includes": [
            "#include \"trace_probe_tmpl.h\"",
            "#include \"trace_probe.h\"",
            "#include \"trace_kprobe_selftest.h\"",
            "#include \"trace_dynevent.h\"",
            "#include <asm/setup.h>  /* for COMMAND_LINE_SIZE */",
            "#include <linux/error-injection.h>",
            "#include <linux/rculist.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/module.h>",
            "#include <linux/security.h>",
            "#include <linux/bpf-cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static nokprobe_inline struct",
            "static int register_kprobe_event(struct trace_kprobe *tk);",
            "static int unregister_kprobe_event(struct trace_kprobe *tk);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_probe_tmpl.h\"\n#include \"trace_probe.h\"\n#include \"trace_kprobe_selftest.h\"\n#include \"trace_dynevent.h\"\n#include <asm/setup.h>  /* for COMMAND_LINE_SIZE */\n#include <linux/error-injection.h>\n#include <linux/rculist.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/security.h>\n#include <linux/bpf-cgroup.h>\n\nstatic nokprobe_inline struct;\nstatic int register_kprobe_event(struct trace_kprobe *tk);\nstatic int unregister_kprobe_event(struct trace_kprobe *tk);\n\nint bpf_get_kprobe_info(const struct perf_event *event, u32 *fd_type,\n\t\t\tconst char **symbol, u64 *probe_offset,\n\t\t\tu64 *probe_addr, bool perf_type_tracepoint)\n{\n\tconst char *pevent = trace_event_name(event->tp_event);\n\tconst char *group = event->tp_event->class->system;\n\tstruct trace_kprobe *tk;\n\n\tif (perf_type_tracepoint)\n\t\ttk = find_trace_kprobe(pevent, group);\n\telse\n\t\ttk = trace_kprobe_primary_from_call(event->tp_event);\n\tif (!tk)\n\t\treturn -EINVAL;\n\n\t*fd_type = trace_kprobe_is_return(tk) ? BPF_FD_TYPE_KRETPROBE\n\t\t\t\t\t      : BPF_FD_TYPE_KPROBE;\n\tif (tk->symbol) {\n\t\t*symbol = tk->symbol;\n\t\t*probe_offset = tk->rp.kp.offset;\n\t\t*probe_addr = 0;\n\t} else {\n\t\t*symbol = NULL;\n\t\t*probe_offset = 0;\n\t\t*probe_addr = (unsigned long)tk->rp.kp.addr;\n\t}\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_syscall_trace_event",
          "args": [
            "event->tp_event"
          ],
          "line": 2084
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nint bpf_get_perf_event_info(const struct perf_event *event, u32 *prog_id,\n\t\t\t    u32 *fd_type, const char **buf,\n\t\t\t    u64 *probe_offset, u64 *probe_addr)\n{\n\tbool is_tracepoint, is_syscall_tp;\n\tstruct bpf_prog *prog;\n\tint flags, err = 0;\n\n\tprog = event->prog;\n\tif (!prog)\n\t\treturn -ENOENT;\n\n\t/* not supporting BPF_PROG_TYPE_PERF_EVENT yet */\n\tif (prog->type == BPF_PROG_TYPE_PERF_EVENT)\n\t\treturn -EOPNOTSUPP;\n\n\t*prog_id = prog->aux->id;\n\tflags = event->tp_event->flags;\n\tis_tracepoint = flags & TRACE_EVENT_FL_TRACEPOINT;\n\tis_syscall_tp = is_syscall_trace_event(event->tp_event);\n\n\tif (is_tracepoint || is_syscall_tp) {\n\t\t*buf = is_tracepoint ? event->tp_event->tp->name\n\t\t\t\t     : event->tp_event->name;\n\t\t*fd_type = BPF_FD_TYPE_TRACEPOINT;\n\t\t*probe_offset = 0x0;\n\t\t*probe_addr = 0x0;\n\t} else {\n\t\t/* kprobe/uprobe */\n\t\terr = -EOPNOTSUPP;\n#ifdef CONFIG_KPROBE_EVENTS\n\t\tif (flags & TRACE_EVENT_FL_KPROBE)\n\t\t\terr = bpf_get_kprobe_info(event, fd_type, buf,\n\t\t\t\t\t\t  probe_offset, probe_addr,\n\t\t\t\t\t\t  event->attr.type == PERF_TYPE_TRACEPOINT);\n#endif\n#ifdef CONFIG_UPROBE_EVENTS\n\t\tif (flags & TRACE_EVENT_FL_UPROBE)\n\t\t\terr = bpf_get_uprobe_info(event, fd_type, buf,\n\t\t\t\t\t\t  probe_offset,\n\t\t\t\t\t\t  event->attr.type == PERF_TYPE_TRACEPOINT);\n#endif\n\t}\n\n\treturn err;\n}"
  },
  {
    "function_name": "bpf_probe_unregister",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2060-2063",
    "snippet": "int bpf_probe_unregister(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\treturn tracepoint_probe_unregister(btp->tp, (void *)btp->bpf_func, prog);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "tracepoint_probe_unregister",
          "args": [
            "btp->tp",
            "(void *)btp->bpf_func",
            "prog"
          ],
          "line": 2062
        },
        "resolved": true,
        "details": {
          "function_name": "tracepoint_probe_unregister",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/tracepoint.c",
          "lines": "543-554",
          "snippet": "int tracepoint_probe_unregister(struct tracepoint *tp, void *probe, void *data)\n{\n\tstruct tracepoint_func tp_func;\n\tint ret;\n\n\tmutex_lock(&tracepoints_mutex);\n\ttp_func.func = probe;\n\ttp_func.data = data;\n\tret = tracepoint_remove_func(tp, &tp_func);\n\tmutex_unlock(&tracepoints_mutex);\n\treturn ret;\n}",
          "includes": [
            "#include <linux/static_key.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/tracepoint.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/list.h>",
            "#include <linux/jhash.h>",
            "#include <linux/types.h>",
            "#include <linux/mutex.h>",
            "#include <linux/module.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_MUTEX(tracepoints_mutex);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/static_key.h>\n#include <linux/sched/task.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/tracepoint.h>\n#include <linux/rcupdate.h>\n#include <linux/list.h>\n#include <linux/jhash.h>\n#include <linux/types.h>\n#include <linux/mutex.h>\n#include <linux/module.h>\n\nstatic DEFINE_MUTEX(tracepoints_mutex);\n\nint tracepoint_probe_unregister(struct tracepoint *tp, void *probe, void *data)\n{\n\tstruct tracepoint_func tp_func;\n\tint ret;\n\n\tmutex_lock(&tracepoints_mutex);\n\ttp_func.func = probe;\n\ttp_func.data = data;\n\tret = tracepoint_remove_func(tp, &tp_func);\n\tmutex_unlock(&tracepoints_mutex);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nint bpf_probe_unregister(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\treturn tracepoint_probe_unregister(btp->tp, (void *)btp->bpf_func, prog);\n}"
  },
  {
    "function_name": "bpf_probe_register",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2055-2058",
    "snippet": "int bpf_probe_register(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\treturn __bpf_probe_register(btp, prog);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__bpf_probe_register",
          "args": [
            "btp",
            "prog"
          ],
          "line": 2057
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_probe_register",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "2037-2053",
          "snippet": "static int __bpf_probe_register(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\tstruct tracepoint *tp = btp->tp;\n\n\t/*\n\t * check that program doesn't access arguments beyond what's\n\t * available in this tracepoint\n\t */\n\tif (prog->aux->max_ctx_offset > btp->num_args * sizeof(u64))\n\t\treturn -EINVAL;\n\n\tif (prog->aux->max_tp_access > btp->writable_size)\n\t\treturn -EINVAL;\n\n\treturn tracepoint_probe_register_may_exist(tp, (void *)btp->bpf_func,\n\t\t\t\t\t\t   prog);\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic int __bpf_probe_register(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\tstruct tracepoint *tp = btp->tp;\n\n\t/*\n\t * check that program doesn't access arguments beyond what's\n\t * available in this tracepoint\n\t */\n\tif (prog->aux->max_ctx_offset > btp->num_args * sizeof(u64))\n\t\treturn -EINVAL;\n\n\tif (prog->aux->max_tp_access > btp->writable_size)\n\t\treturn -EINVAL;\n\n\treturn tracepoint_probe_register_may_exist(tp, (void *)btp->bpf_func,\n\t\t\t\t\t\t   prog);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nint bpf_probe_register(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\treturn __bpf_probe_register(btp, prog);\n}"
  },
  {
    "function_name": "__bpf_probe_register",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "2037-2053",
    "snippet": "static int __bpf_probe_register(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\tstruct tracepoint *tp = btp->tp;\n\n\t/*\n\t * check that program doesn't access arguments beyond what's\n\t * available in this tracepoint\n\t */\n\tif (prog->aux->max_ctx_offset > btp->num_args * sizeof(u64))\n\t\treturn -EINVAL;\n\n\tif (prog->aux->max_tp_access > btp->writable_size)\n\t\treturn -EINVAL;\n\n\treturn tracepoint_probe_register_may_exist(tp, (void *)btp->bpf_func,\n\t\t\t\t\t\t   prog);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "tracepoint_probe_register_may_exist",
          "args": [
            "tp",
            "(void *)btp->bpf_func",
            "prog"
          ],
          "line": 2051
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic int __bpf_probe_register(struct bpf_raw_event_map *btp, struct bpf_prog *prog)\n{\n\tstruct tracepoint *tp = btp->tp;\n\n\t/*\n\t * check that program doesn't access arguments beyond what's\n\t * available in this tracepoint\n\t */\n\tif (prog->aux->max_ctx_offset > btp->num_args * sizeof(u64))\n\t\treturn -EINVAL;\n\n\tif (prog->aux->max_tp_access > btp->writable_size)\n\t\treturn -EINVAL;\n\n\treturn tracepoint_probe_register_may_exist(tp, (void *)btp->bpf_func,\n\t\t\t\t\t\t   prog);\n}"
  },
  {
    "function_name": "__bpf_trace_run",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1983-1990",
    "snippet": "static __always_inline\nvoid __bpf_trace_run(struct bpf_prog *prog, u64 *args)\n{\n\tcant_sleep();\n\trcu_read_lock();\n\t(void) bpf_prog_run(prog, args);\n\trcu_read_unlock();\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1989
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_run",
          "args": [
            "prog",
            "args"
          ],
          "line": 1988
        },
        "resolved": true,
        "details": {
          "function_name": "___bpf_prog_run",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "1383-1747",
          "snippet": "static u64 ___bpf_prog_run(u64 *regs, const struct bpf_insn *insn)\n{\n#define BPF_INSN_2_LBL(x, y)    [BPF_##x | BPF_##y] = &&x##_##y\n#define BPF_INSN_3_LBL(x, y, z) [BPF_##x | BPF_##y | BPF_##z] = &&x##_##y##_##z\n\tstatic const void * const jumptable[256] __annotate_jump_table = {\n\t\t[0 ... 255] = &&default_label,\n\t\t/* Now overwrite non-defaults ... */\n\t\tBPF_INSN_MAP(BPF_INSN_2_LBL, BPF_INSN_3_LBL),\n\t\t/* Non-UAPI available opcodes. */\n\t\t[BPF_JMP | BPF_CALL_ARGS] = &&JMP_CALL_ARGS,\n\t\t[BPF_JMP | BPF_TAIL_CALL] = &&JMP_TAIL_CALL,\n\t\t[BPF_ST  | BPF_NOSPEC] = &&ST_NOSPEC,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_B] = &&LDX_PROBE_MEM_B,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_H] = &&LDX_PROBE_MEM_H,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_W] = &&LDX_PROBE_MEM_W,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_DW] = &&LDX_PROBE_MEM_DW,\n\t};\n#undef BPF_INSN_3_LBL\n#undef BPF_INSN_2_LBL\n\tu32 tail_call_cnt = 0;\n\n#define CONT\t ({ insn++; goto select_insn; })\n#define CONT_JMP ({ insn++; goto select_insn; })\n\nselect_insn:\n\tgoto *jumptable[insn->code];\n\n\t/* Explicitly mask the register-based shift amounts with 63 or 31\n\t * to avoid undefined behavior. Normally this won't affect the\n\t * generated code, for example, in case of native 64 bit archs such\n\t * as x86-64 or arm64, the compiler is optimizing the AND away for\n\t * the interpreter. In case of JITs, each of the JIT backends compiles\n\t * the BPF shift operations to machine instructions which produce\n\t * implementation-defined results in such a case; the resulting\n\t * contents of the register may be arbitrary, but program behaviour\n\t * as a whole remains defined. In other words, in case of JIT backends,\n\t * the AND must /not/ be added to the emitted LSH/RSH/ARSH translation.\n\t */\n\t/* ALU (shifts) */\n#define SHT(OPCODE, OP)\t\t\t\t\t\\\n\tALU64_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = DST OP (SRC & 63);\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = (u32) DST OP ((u32) SRC & 31);\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU64_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = DST OP IMM;\t\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = (u32) DST OP (u32) IMM;\t\t\\\n\t\tCONT;\n\t/* ALU (rest) */\n#define ALU(OPCODE, OP)\t\t\t\t\t\\\n\tALU64_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = DST OP SRC;\t\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = (u32) DST OP (u32) SRC;\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU64_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = DST OP IMM;\t\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = (u32) DST OP (u32) IMM;\t\t\\\n\t\tCONT;\n\tALU(ADD,  +)\n\tALU(SUB,  -)\n\tALU(AND,  &)\n\tALU(OR,   |)\n\tALU(XOR,  ^)\n\tALU(MUL,  *)\n\tSHT(LSH, <<)\n\tSHT(RSH, >>)\n#undef SHT\n#undef ALU\n\tALU_NEG:\n\t\tDST = (u32) -DST;\n\t\tCONT;\n\tALU64_NEG:\n\t\tDST = -DST;\n\t\tCONT;\n\tALU_MOV_X:\n\t\tDST = (u32) SRC;\n\t\tCONT;\n\tALU_MOV_K:\n\t\tDST = (u32) IMM;\n\t\tCONT;\n\tALU64_MOV_X:\n\t\tDST = SRC;\n\t\tCONT;\n\tALU64_MOV_K:\n\t\tDST = IMM;\n\t\tCONT;\n\tLD_IMM_DW:\n\t\tDST = (u64) (u32) insn[0].imm | ((u64) (u32) insn[1].imm) << 32;\n\t\tinsn++;\n\t\tCONT;\n\tALU_ARSH_X:\n\t\tDST = (u64) (u32) (((s32) DST) >> (SRC & 31));\n\t\tCONT;\n\tALU_ARSH_K:\n\t\tDST = (u64) (u32) (((s32) DST) >> IMM);\n\t\tCONT;\n\tALU64_ARSH_X:\n\t\t(*(s64 *) &DST) >>= (SRC & 63);\n\t\tCONT;\n\tALU64_ARSH_K:\n\t\t(*(s64 *) &DST) >>= IMM;\n\t\tCONT;\n\tALU64_MOD_X:\n\t\tdiv64_u64_rem(DST, SRC, &AX);\n\t\tDST = AX;\n\t\tCONT;\n\tALU_MOD_X:\n\t\tAX = (u32) DST;\n\t\tDST = do_div(AX, (u32) SRC);\n\t\tCONT;\n\tALU64_MOD_K:\n\t\tdiv64_u64_rem(DST, IMM, &AX);\n\t\tDST = AX;\n\t\tCONT;\n\tALU_MOD_K:\n\t\tAX = (u32) DST;\n\t\tDST = do_div(AX, (u32) IMM);\n\t\tCONT;\n\tALU64_DIV_X:\n\t\tDST = div64_u64(DST, SRC);\n\t\tCONT;\n\tALU_DIV_X:\n\t\tAX = (u32) DST;\n\t\tdo_div(AX, (u32) SRC);\n\t\tDST = (u32) AX;\n\t\tCONT;\n\tALU64_DIV_K:\n\t\tDST = div64_u64(DST, IMM);\n\t\tCONT;\n\tALU_DIV_K:\n\t\tAX = (u32) DST;\n\t\tdo_div(AX, (u32) IMM);\n\t\tDST = (u32) AX;\n\t\tCONT;\n\tALU_END_TO_BE:\n\t\tswitch (IMM) {\n\t\tcase 16:\n\t\t\tDST = (__force u16) cpu_to_be16(DST);\n\t\t\tbreak;\n\t\tcase 32:\n\t\t\tDST = (__force u32) cpu_to_be32(DST);\n\t\t\tbreak;\n\t\tcase 64:\n\t\t\tDST = (__force u64) cpu_to_be64(DST);\n\t\t\tbreak;\n\t\t}\n\t\tCONT;\n\tALU_END_TO_LE:\n\t\tswitch (IMM) {\n\t\tcase 16:\n\t\t\tDST = (__force u16) cpu_to_le16(DST);\n\t\t\tbreak;\n\t\tcase 32:\n\t\t\tDST = (__force u32) cpu_to_le32(DST);\n\t\t\tbreak;\n\t\tcase 64:\n\t\t\tDST = (__force u64) cpu_to_le64(DST);\n\t\t\tbreak;\n\t\t}\n\t\tCONT;\n\n\t/* CALL */\n\tJMP_CALL:\n\t\t/* Function call scratches BPF_R1-BPF_R5 registers,\n\t\t * preserves BPF_R6-BPF_R9, and stores return value\n\t\t * into BPF_R0.\n\t\t */\n\t\tBPF_R0 = (__bpf_call_base + insn->imm)(BPF_R1, BPF_R2, BPF_R3,\n\t\t\t\t\t\t       BPF_R4, BPF_R5);\n\t\tCONT;\n\n\tJMP_CALL_ARGS:\n\t\tBPF_R0 = (__bpf_call_base_args + insn->imm)(BPF_R1, BPF_R2,\n\t\t\t\t\t\t\t    BPF_R3, BPF_R4,\n\t\t\t\t\t\t\t    BPF_R5,\n\t\t\t\t\t\t\t    insn + insn->off + 1);\n\t\tCONT;\n\n\tJMP_TAIL_CALL: {\n\t\tstruct bpf_map *map = (struct bpf_map *) (unsigned long) BPF_R2;\n\t\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\t\tstruct bpf_prog *prog;\n\t\tu32 index = BPF_R3;\n\n\t\tif (unlikely(index >= array->map.max_entries))\n\t\t\tgoto out;\n\n\t\tif (unlikely(tail_call_cnt >= MAX_TAIL_CALL_CNT))\n\t\t\tgoto out;\n\n\t\ttail_call_cnt++;\n\n\t\tprog = READ_ONCE(array->ptrs[index]);\n\t\tif (!prog)\n\t\t\tgoto out;\n\n\t\t/* ARG1 at this point is guaranteed to point to CTX from\n\t\t * the verifier side due to the fact that the tail call is\n\t\t * handled like a helper, that is, bpf_tail_call_proto,\n\t\t * where arg1_type is ARG_PTR_TO_CTX.\n\t\t */\n\t\tinsn = prog->insnsi;\n\t\tgoto select_insn;\nout:\n\t\tCONT;\n\t}\n\tJMP_JA:\n\t\tinsn += insn->off;\n\t\tCONT;\n\tJMP_EXIT:\n\t\treturn BPF_R0;\n\t/* JMP */\n#define COND_JMP(SIGN, OPCODE, CMP_OP)\t\t\t\t\\\n\tJMP_##OPCODE##_X:\t\t\t\t\t\\\n\t\tif ((SIGN##64) DST CMP_OP (SIGN##64) SRC) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\t\t\t\t\t\t\\\n\tJMP32_##OPCODE##_X:\t\t\t\t\t\\\n\t\tif ((SIGN##32) DST CMP_OP (SIGN##32) SRC) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\t\t\t\t\t\t\\\n\tJMP_##OPCODE##_K:\t\t\t\t\t\\\n\t\tif ((SIGN##64) DST CMP_OP (SIGN##64) IMM) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\t\t\t\t\t\t\\\n\tJMP32_##OPCODE##_K:\t\t\t\t\t\\\n\t\tif ((SIGN##32) DST CMP_OP (SIGN##32) IMM) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\n\tCOND_JMP(u, JEQ, ==)\n\tCOND_JMP(u, JNE, !=)\n\tCOND_JMP(u, JGT, >)\n\tCOND_JMP(u, JLT, <)\n\tCOND_JMP(u, JGE, >=)\n\tCOND_JMP(u, JLE, <=)\n\tCOND_JMP(u, JSET, &)\n\tCOND_JMP(s, JSGT, >)\n\tCOND_JMP(s, JSLT, <)\n\tCOND_JMP(s, JSGE, >=)\n\tCOND_JMP(s, JSLE, <=)\n#undef COND_JMP\n\t/* ST, STX and LDX*/\n\tST_NOSPEC:\n\t\t/* Speculation barrier for mitigating Speculative Store Bypass.\n\t\t * In case of arm64, we rely on the firmware mitigation as\n\t\t * controlled via the ssbd kernel parameter. Whenever the\n\t\t * mitigation is enabled, it works for all of the kernel code\n\t\t * with no need to provide any additional instructions here.\n\t\t * In case of x86, we use 'lfence' insn for mitigation. We\n\t\t * reuse preexisting logic from Spectre v1 mitigation that\n\t\t * happens to produce the required code on x86 for v4 as well.\n\t\t */\n#ifdef CONFIG_X86\n\t\tbarrier_nospec();\n#endif\n\t\tCONT;\n#define LDST(SIZEOP, SIZE)\t\t\t\t\t\t\\\n\tSTX_MEM_##SIZEOP:\t\t\t\t\t\t\\\n\t\t*(SIZE *)(unsigned long) (DST + insn->off) = SRC;\t\\\n\t\tCONT;\t\t\t\t\t\t\t\\\n\tST_MEM_##SIZEOP:\t\t\t\t\t\t\\\n\t\t*(SIZE *)(unsigned long) (DST + insn->off) = IMM;\t\\\n\t\tCONT;\t\t\t\t\t\t\t\\\n\tLDX_MEM_##SIZEOP:\t\t\t\t\t\t\\\n\t\tDST = *(SIZE *)(unsigned long) (SRC + insn->off);\t\\\n\t\tCONT;\n\n\tLDST(B,   u8)\n\tLDST(H,  u16)\n\tLDST(W,  u32)\n\tLDST(DW, u64)\n#undef LDST\n#define LDX_PROBE(SIZEOP, SIZE)\t\t\t\t\t\t\t\\\n\tLDX_PROBE_MEM_##SIZEOP:\t\t\t\t\t\t\t\\\n\t\tbpf_probe_read_kernel(&DST, SIZE, (const void *)(long) (SRC + insn->off));\t\\\n\t\tCONT;\n\tLDX_PROBE(B,  1)\n\tLDX_PROBE(H,  2)\n\tLDX_PROBE(W,  4)\n\tLDX_PROBE(DW, 8)\n#undef LDX_PROBE\n\n#define ATOMIC_ALU_OP(BOP, KOP)\t\t\t\t\t\t\\\n\t\tcase BOP:\t\t\t\t\t\t\\\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\t\t\\\n\t\t\t\tatomic_##KOP((u32) SRC, (atomic_t *)(unsigned long) \\\n\t\t\t\t\t     (DST + insn->off));\t\\\n\t\t\telse\t\t\t\t\t\t\\\n\t\t\t\tatomic64_##KOP((u64) SRC, (atomic64_t *)(unsigned long) \\\n\t\t\t\t\t       (DST + insn->off));\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\tcase BOP | BPF_FETCH:\t\t\t\t\t\\\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\t\t\\\n\t\t\t\tSRC = (u32) atomic_fetch_##KOP(\t\t\\\n\t\t\t\t\t(u32) SRC,\t\t\t\\\n\t\t\t\t\t(atomic_t *)(unsigned long) (DST + insn->off)); \\\n\t\t\telse\t\t\t\t\t\t\\\n\t\t\t\tSRC = (u64) atomic64_fetch_##KOP(\t\\\n\t\t\t\t\t(u64) SRC,\t\t\t\\\n\t\t\t\t\t(atomic64_t *)(unsigned long) (DST + insn->off)); \\\n\t\t\tbreak;\n\n\tSTX_ATOMIC_DW:\n\tSTX_ATOMIC_W:\n\t\tswitch (IMM) {\n\t\tATOMIC_ALU_OP(BPF_ADD, add)\n\t\tATOMIC_ALU_OP(BPF_AND, and)\n\t\tATOMIC_ALU_OP(BPF_OR, or)\n\t\tATOMIC_ALU_OP(BPF_XOR, xor)\n#undef ATOMIC_ALU_OP\n\n\t\tcase BPF_XCHG:\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\n\t\t\t\tSRC = (u32) atomic_xchg(\n\t\t\t\t\t(atomic_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u32) SRC);\n\t\t\telse\n\t\t\t\tSRC = (u64) atomic64_xchg(\n\t\t\t\t\t(atomic64_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u64) SRC);\n\t\t\tbreak;\n\t\tcase BPF_CMPXCHG:\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\n\t\t\t\tBPF_R0 = (u32) atomic_cmpxchg(\n\t\t\t\t\t(atomic_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u32) BPF_R0, (u32) SRC);\n\t\t\telse\n\t\t\t\tBPF_R0 = (u64) atomic64_cmpxchg(\n\t\t\t\t\t(atomic64_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u64) BPF_R0, (u64) SRC);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tgoto default_label;\n\t\t}\n\t\tCONT;\n\n\tdefault_label:\n\t\t/* If we ever reach this, we have a bug somewhere. Die hard here\n\t\t * instead of just returning 0; we could be somewhere in a subprog,\n\t\t * so execution could continue otherwise which we do /not/ want.\n\t\t *\n\t\t * Note, verifier whitelists all opcodes in bpf_opcode_in_insntable().\n\t\t */\n\t\tpr_warn(\"BPF interpreter: unknown opcode %02x (imm: 0x%x)\\n\",\n\t\t\tinsn->code, insn->imm);\n\t\tBUG_ON(1);\n\t\treturn 0;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [
            "#define CONT_JMP ({ insn++; goto select_insn; })",
            "#define CONT\t ({ insn++; goto select_insn; })",
            "#define IMM\tinsn->imm",
            "#define CTX\tregs[BPF_REG_CTX]",
            "#define ARG1\tregs[BPF_REG_ARG1]",
            "#define AX\tregs[BPF_REG_AX]",
            "#define SRC\tregs[insn->src_reg]",
            "#define DST\tregs[insn->dst_reg]",
            "#define BPF_R9\tregs[BPF_REG_9]",
            "#define BPF_R6\tregs[BPF_REG_6]",
            "#define BPF_R5\tregs[BPF_REG_5]",
            "#define BPF_R4\tregs[BPF_REG_4]",
            "#define BPF_R3\tregs[BPF_REG_3]",
            "#define BPF_R2\tregs[BPF_REG_2]",
            "#define BPF_R1\tregs[BPF_REG_1]",
            "#define BPF_R0\tregs[BPF_REG_0]"
          ],
          "globals_used": [
            "const struct bpf_func_proto bpf_tail_call_proto = {\n\t.func\t\t= NULL,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_VOID,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\n#define CONT_JMP ({ insn++; goto select_insn; })\n#define CONT\t ({ insn++; goto select_insn; })\n#define IMM\tinsn->imm\n#define CTX\tregs[BPF_REG_CTX]\n#define ARG1\tregs[BPF_REG_ARG1]\n#define AX\tregs[BPF_REG_AX]\n#define SRC\tregs[insn->src_reg]\n#define DST\tregs[insn->dst_reg]\n#define BPF_R9\tregs[BPF_REG_9]\n#define BPF_R6\tregs[BPF_REG_6]\n#define BPF_R5\tregs[BPF_REG_5]\n#define BPF_R4\tregs[BPF_REG_4]\n#define BPF_R3\tregs[BPF_REG_3]\n#define BPF_R2\tregs[BPF_REG_2]\n#define BPF_R1\tregs[BPF_REG_1]\n#define BPF_R0\tregs[BPF_REG_0]\n\nconst struct bpf_func_proto bpf_tail_call_proto = {\n\t.func\t\t= NULL,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_VOID,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};\n\nstatic u64 ___bpf_prog_run(u64 *regs, const struct bpf_insn *insn)\n{\n#define BPF_INSN_2_LBL(x, y)    [BPF_##x | BPF_##y] = &&x##_##y\n#define BPF_INSN_3_LBL(x, y, z) [BPF_##x | BPF_##y | BPF_##z] = &&x##_##y##_##z\n\tstatic const void * const jumptable[256] __annotate_jump_table = {\n\t\t[0 ... 255] = &&default_label,\n\t\t/* Now overwrite non-defaults ... */\n\t\tBPF_INSN_MAP(BPF_INSN_2_LBL, BPF_INSN_3_LBL),\n\t\t/* Non-UAPI available opcodes. */\n\t\t[BPF_JMP | BPF_CALL_ARGS] = &&JMP_CALL_ARGS,\n\t\t[BPF_JMP | BPF_TAIL_CALL] = &&JMP_TAIL_CALL,\n\t\t[BPF_ST  | BPF_NOSPEC] = &&ST_NOSPEC,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_B] = &&LDX_PROBE_MEM_B,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_H] = &&LDX_PROBE_MEM_H,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_W] = &&LDX_PROBE_MEM_W,\n\t\t[BPF_LDX | BPF_PROBE_MEM | BPF_DW] = &&LDX_PROBE_MEM_DW,\n\t};\n#undef BPF_INSN_3_LBL\n#undef BPF_INSN_2_LBL\n\tu32 tail_call_cnt = 0;\n\n#define CONT\t ({ insn++; goto select_insn; })\n#define CONT_JMP ({ insn++; goto select_insn; })\n\nselect_insn:\n\tgoto *jumptable[insn->code];\n\n\t/* Explicitly mask the register-based shift amounts with 63 or 31\n\t * to avoid undefined behavior. Normally this won't affect the\n\t * generated code, for example, in case of native 64 bit archs such\n\t * as x86-64 or arm64, the compiler is optimizing the AND away for\n\t * the interpreter. In case of JITs, each of the JIT backends compiles\n\t * the BPF shift operations to machine instructions which produce\n\t * implementation-defined results in such a case; the resulting\n\t * contents of the register may be arbitrary, but program behaviour\n\t * as a whole remains defined. In other words, in case of JIT backends,\n\t * the AND must /not/ be added to the emitted LSH/RSH/ARSH translation.\n\t */\n\t/* ALU (shifts) */\n#define SHT(OPCODE, OP)\t\t\t\t\t\\\n\tALU64_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = DST OP (SRC & 63);\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = (u32) DST OP ((u32) SRC & 31);\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU64_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = DST OP IMM;\t\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = (u32) DST OP (u32) IMM;\t\t\\\n\t\tCONT;\n\t/* ALU (rest) */\n#define ALU(OPCODE, OP)\t\t\t\t\t\\\n\tALU64_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = DST OP SRC;\t\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_X:\t\t\t\t\\\n\t\tDST = (u32) DST OP (u32) SRC;\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU64_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = DST OP IMM;\t\t\t\\\n\t\tCONT;\t\t\t\t\t\\\n\tALU_##OPCODE##_K:\t\t\t\t\\\n\t\tDST = (u32) DST OP (u32) IMM;\t\t\\\n\t\tCONT;\n\tALU(ADD,  +)\n\tALU(SUB,  -)\n\tALU(AND,  &)\n\tALU(OR,   |)\n\tALU(XOR,  ^)\n\tALU(MUL,  *)\n\tSHT(LSH, <<)\n\tSHT(RSH, >>)\n#undef SHT\n#undef ALU\n\tALU_NEG:\n\t\tDST = (u32) -DST;\n\t\tCONT;\n\tALU64_NEG:\n\t\tDST = -DST;\n\t\tCONT;\n\tALU_MOV_X:\n\t\tDST = (u32) SRC;\n\t\tCONT;\n\tALU_MOV_K:\n\t\tDST = (u32) IMM;\n\t\tCONT;\n\tALU64_MOV_X:\n\t\tDST = SRC;\n\t\tCONT;\n\tALU64_MOV_K:\n\t\tDST = IMM;\n\t\tCONT;\n\tLD_IMM_DW:\n\t\tDST = (u64) (u32) insn[0].imm | ((u64) (u32) insn[1].imm) << 32;\n\t\tinsn++;\n\t\tCONT;\n\tALU_ARSH_X:\n\t\tDST = (u64) (u32) (((s32) DST) >> (SRC & 31));\n\t\tCONT;\n\tALU_ARSH_K:\n\t\tDST = (u64) (u32) (((s32) DST) >> IMM);\n\t\tCONT;\n\tALU64_ARSH_X:\n\t\t(*(s64 *) &DST) >>= (SRC & 63);\n\t\tCONT;\n\tALU64_ARSH_K:\n\t\t(*(s64 *) &DST) >>= IMM;\n\t\tCONT;\n\tALU64_MOD_X:\n\t\tdiv64_u64_rem(DST, SRC, &AX);\n\t\tDST = AX;\n\t\tCONT;\n\tALU_MOD_X:\n\t\tAX = (u32) DST;\n\t\tDST = do_div(AX, (u32) SRC);\n\t\tCONT;\n\tALU64_MOD_K:\n\t\tdiv64_u64_rem(DST, IMM, &AX);\n\t\tDST = AX;\n\t\tCONT;\n\tALU_MOD_K:\n\t\tAX = (u32) DST;\n\t\tDST = do_div(AX, (u32) IMM);\n\t\tCONT;\n\tALU64_DIV_X:\n\t\tDST = div64_u64(DST, SRC);\n\t\tCONT;\n\tALU_DIV_X:\n\t\tAX = (u32) DST;\n\t\tdo_div(AX, (u32) SRC);\n\t\tDST = (u32) AX;\n\t\tCONT;\n\tALU64_DIV_K:\n\t\tDST = div64_u64(DST, IMM);\n\t\tCONT;\n\tALU_DIV_K:\n\t\tAX = (u32) DST;\n\t\tdo_div(AX, (u32) IMM);\n\t\tDST = (u32) AX;\n\t\tCONT;\n\tALU_END_TO_BE:\n\t\tswitch (IMM) {\n\t\tcase 16:\n\t\t\tDST = (__force u16) cpu_to_be16(DST);\n\t\t\tbreak;\n\t\tcase 32:\n\t\t\tDST = (__force u32) cpu_to_be32(DST);\n\t\t\tbreak;\n\t\tcase 64:\n\t\t\tDST = (__force u64) cpu_to_be64(DST);\n\t\t\tbreak;\n\t\t}\n\t\tCONT;\n\tALU_END_TO_LE:\n\t\tswitch (IMM) {\n\t\tcase 16:\n\t\t\tDST = (__force u16) cpu_to_le16(DST);\n\t\t\tbreak;\n\t\tcase 32:\n\t\t\tDST = (__force u32) cpu_to_le32(DST);\n\t\t\tbreak;\n\t\tcase 64:\n\t\t\tDST = (__force u64) cpu_to_le64(DST);\n\t\t\tbreak;\n\t\t}\n\t\tCONT;\n\n\t/* CALL */\n\tJMP_CALL:\n\t\t/* Function call scratches BPF_R1-BPF_R5 registers,\n\t\t * preserves BPF_R6-BPF_R9, and stores return value\n\t\t * into BPF_R0.\n\t\t */\n\t\tBPF_R0 = (__bpf_call_base + insn->imm)(BPF_R1, BPF_R2, BPF_R3,\n\t\t\t\t\t\t       BPF_R4, BPF_R5);\n\t\tCONT;\n\n\tJMP_CALL_ARGS:\n\t\tBPF_R0 = (__bpf_call_base_args + insn->imm)(BPF_R1, BPF_R2,\n\t\t\t\t\t\t\t    BPF_R3, BPF_R4,\n\t\t\t\t\t\t\t    BPF_R5,\n\t\t\t\t\t\t\t    insn + insn->off + 1);\n\t\tCONT;\n\n\tJMP_TAIL_CALL: {\n\t\tstruct bpf_map *map = (struct bpf_map *) (unsigned long) BPF_R2;\n\t\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\t\tstruct bpf_prog *prog;\n\t\tu32 index = BPF_R3;\n\n\t\tif (unlikely(index >= array->map.max_entries))\n\t\t\tgoto out;\n\n\t\tif (unlikely(tail_call_cnt >= MAX_TAIL_CALL_CNT))\n\t\t\tgoto out;\n\n\t\ttail_call_cnt++;\n\n\t\tprog = READ_ONCE(array->ptrs[index]);\n\t\tif (!prog)\n\t\t\tgoto out;\n\n\t\t/* ARG1 at this point is guaranteed to point to CTX from\n\t\t * the verifier side due to the fact that the tail call is\n\t\t * handled like a helper, that is, bpf_tail_call_proto,\n\t\t * where arg1_type is ARG_PTR_TO_CTX.\n\t\t */\n\t\tinsn = prog->insnsi;\n\t\tgoto select_insn;\nout:\n\t\tCONT;\n\t}\n\tJMP_JA:\n\t\tinsn += insn->off;\n\t\tCONT;\n\tJMP_EXIT:\n\t\treturn BPF_R0;\n\t/* JMP */\n#define COND_JMP(SIGN, OPCODE, CMP_OP)\t\t\t\t\\\n\tJMP_##OPCODE##_X:\t\t\t\t\t\\\n\t\tif ((SIGN##64) DST CMP_OP (SIGN##64) SRC) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\t\t\t\t\t\t\\\n\tJMP32_##OPCODE##_X:\t\t\t\t\t\\\n\t\tif ((SIGN##32) DST CMP_OP (SIGN##32) SRC) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\t\t\t\t\t\t\\\n\tJMP_##OPCODE##_K:\t\t\t\t\t\\\n\t\tif ((SIGN##64) DST CMP_OP (SIGN##64) IMM) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\t\t\t\t\t\t\\\n\tJMP32_##OPCODE##_K:\t\t\t\t\t\\\n\t\tif ((SIGN##32) DST CMP_OP (SIGN##32) IMM) {\t\\\n\t\t\tinsn += insn->off;\t\t\t\\\n\t\t\tCONT_JMP;\t\t\t\t\\\n\t\t}\t\t\t\t\t\t\\\n\t\tCONT;\n\tCOND_JMP(u, JEQ, ==)\n\tCOND_JMP(u, JNE, !=)\n\tCOND_JMP(u, JGT, >)\n\tCOND_JMP(u, JLT, <)\n\tCOND_JMP(u, JGE, >=)\n\tCOND_JMP(u, JLE, <=)\n\tCOND_JMP(u, JSET, &)\n\tCOND_JMP(s, JSGT, >)\n\tCOND_JMP(s, JSLT, <)\n\tCOND_JMP(s, JSGE, >=)\n\tCOND_JMP(s, JSLE, <=)\n#undef COND_JMP\n\t/* ST, STX and LDX*/\n\tST_NOSPEC:\n\t\t/* Speculation barrier for mitigating Speculative Store Bypass.\n\t\t * In case of arm64, we rely on the firmware mitigation as\n\t\t * controlled via the ssbd kernel parameter. Whenever the\n\t\t * mitigation is enabled, it works for all of the kernel code\n\t\t * with no need to provide any additional instructions here.\n\t\t * In case of x86, we use 'lfence' insn for mitigation. We\n\t\t * reuse preexisting logic from Spectre v1 mitigation that\n\t\t * happens to produce the required code on x86 for v4 as well.\n\t\t */\n#ifdef CONFIG_X86\n\t\tbarrier_nospec();\n#endif\n\t\tCONT;\n#define LDST(SIZEOP, SIZE)\t\t\t\t\t\t\\\n\tSTX_MEM_##SIZEOP:\t\t\t\t\t\t\\\n\t\t*(SIZE *)(unsigned long) (DST + insn->off) = SRC;\t\\\n\t\tCONT;\t\t\t\t\t\t\t\\\n\tST_MEM_##SIZEOP:\t\t\t\t\t\t\\\n\t\t*(SIZE *)(unsigned long) (DST + insn->off) = IMM;\t\\\n\t\tCONT;\t\t\t\t\t\t\t\\\n\tLDX_MEM_##SIZEOP:\t\t\t\t\t\t\\\n\t\tDST = *(SIZE *)(unsigned long) (SRC + insn->off);\t\\\n\t\tCONT;\n\n\tLDST(B,   u8)\n\tLDST(H,  u16)\n\tLDST(W,  u32)\n\tLDST(DW, u64)\n#undef LDST\n#define LDX_PROBE(SIZEOP, SIZE)\t\t\t\t\t\t\t\\\n\tLDX_PROBE_MEM_##SIZEOP:\t\t\t\t\t\t\t\\\n\t\tbpf_probe_read_kernel(&DST, SIZE, (const void *)(long) (SRC + insn->off));\t\\\n\t\tCONT;\n\tLDX_PROBE(B,  1)\n\tLDX_PROBE(H,  2)\n\tLDX_PROBE(W,  4)\n\tLDX_PROBE(DW, 8)\n#undef LDX_PROBE\n\n#define ATOMIC_ALU_OP(BOP, KOP)\t\t\t\t\t\t\\\n\t\tcase BOP:\t\t\t\t\t\t\\\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\t\t\\\n\t\t\t\tatomic_##KOP((u32) SRC, (atomic_t *)(unsigned long) \\\n\t\t\t\t\t     (DST + insn->off));\t\\\n\t\t\telse\t\t\t\t\t\t\\\n\t\t\t\tatomic64_##KOP((u64) SRC, (atomic64_t *)(unsigned long) \\\n\t\t\t\t\t       (DST + insn->off));\t\\\n\t\t\tbreak;\t\t\t\t\t\t\\\n\t\tcase BOP | BPF_FETCH:\t\t\t\t\t\\\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\t\t\\\n\t\t\t\tSRC = (u32) atomic_fetch_##KOP(\t\t\\\n\t\t\t\t\t(u32) SRC,\t\t\t\\\n\t\t\t\t\t(atomic_t *)(unsigned long) (DST + insn->off)); \\\n\t\t\telse\t\t\t\t\t\t\\\n\t\t\t\tSRC = (u64) atomic64_fetch_##KOP(\t\\\n\t\t\t\t\t(u64) SRC,\t\t\t\\\n\t\t\t\t\t(atomic64_t *)(unsigned long) (DST + insn->off)); \\\n\t\t\tbreak;\n\n\tSTX_ATOMIC_DW:\n\tSTX_ATOMIC_W:\n\t\tswitch (IMM) {\n\t\tATOMIC_ALU_OP(BPF_ADD, add)\n\t\tATOMIC_ALU_OP(BPF_AND, and)\n\t\tATOMIC_ALU_OP(BPF_OR, or)\n\t\tATOMIC_ALU_OP(BPF_XOR, xor)\n#undef ATOMIC_ALU_OP\n\n\t\tcase BPF_XCHG:\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\n\t\t\t\tSRC = (u32) atomic_xchg(\n\t\t\t\t\t(atomic_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u32) SRC);\n\t\t\telse\n\t\t\t\tSRC = (u64) atomic64_xchg(\n\t\t\t\t\t(atomic64_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u64) SRC);\n\t\t\tbreak;\n\t\tcase BPF_CMPXCHG:\n\t\t\tif (BPF_SIZE(insn->code) == BPF_W)\n\t\t\t\tBPF_R0 = (u32) atomic_cmpxchg(\n\t\t\t\t\t(atomic_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u32) BPF_R0, (u32) SRC);\n\t\t\telse\n\t\t\t\tBPF_R0 = (u64) atomic64_cmpxchg(\n\t\t\t\t\t(atomic64_t *)(unsigned long) (DST + insn->off),\n\t\t\t\t\t(u64) BPF_R0, (u64) SRC);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tgoto default_label;\n\t\t}\n\t\tCONT;\n\n\tdefault_label:\n\t\t/* If we ever reach this, we have a bug somewhere. Die hard here\n\t\t * instead of just returning 0; we could be somewhere in a subprog,\n\t\t * so execution could continue otherwise which we do /not/ want.\n\t\t *\n\t\t * Note, verifier whitelists all opcodes in bpf_opcode_in_insntable().\n\t\t */\n\t\tpr_warn(\"BPF interpreter: unknown opcode %02x (imm: 0x%x)\\n\",\n\t\t\tinsn->code, insn->imm);\n\t\tBUG_ON(1);\n\t\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1987
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "cant_sleep",
          "args": [],
          "line": 1986
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline\nvoid __bpf_trace_run(struct bpf_prog *prog, u64 *args)\n{\n\tcant_sleep();\n\trcu_read_lock();\n\t(void) bpf_prog_run(prog, args);\n\trcu_read_unlock();\n}"
  },
  {
    "function_name": "bpf_put_raw_tracepoint",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1973-1981",
    "snippet": "void bpf_put_raw_tracepoint(struct bpf_raw_event_map *btp)\n{\n\tstruct module *mod;\n\n\tpreempt_disable();\n\tmod = __module_address((unsigned long)btp);\n\tmodule_put(mod);\n\tpreempt_enable();\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 1980
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "module_put",
          "args": [
            "mod"
          ],
          "line": 1979
        },
        "resolved": true,
        "details": {
          "function_name": "module_put",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/module.c",
          "lines": "1087-1098",
          "snippet": "void module_put(struct module *module)\n{\n\tint ret;\n\n\tif (module) {\n\t\tpreempt_disable();\n\t\tret = atomic_dec_if_positive(&module->refcnt);\n\t\tWARN_ON(ret < 0);\t/* Failed to put refcount */\n\t\ttrace_module_put(module, _RET_IP_);\n\t\tpreempt_enable();\n\t}\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include \"module-internal.h\"",
            "#include <uapi/linux/module.h>",
            "#include <linux/audit.h>",
            "#include <linux/dynamic_debug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/pfn.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/percpu.h>",
            "#include <linux/async.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/tracepoint.h>",
            "#include <asm/sections.h>",
            "#include <linux/license.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/set_memory.h>",
            "#include <asm/cacheflush.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/mutex.h>",
            "#include <linux/string.h>",
            "#include <linux/device.h>",
            "#include <linux/sched.h>",
            "#include <linux/notifier.h>",
            "#include <linux/vermagic.h>",
            "#include <linux/err.h>",
            "#include <linux/errno.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/elf.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel_read_file.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/buildid.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/module_signature.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/extable.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include \"module-internal.h\"\n#include <uapi/linux/module.h>\n#include <linux/audit.h>\n#include <linux/dynamic_debug.h>\n#include <linux/bsearch.h>\n#include <linux/pfn.h>\n#include <linux/jump_label.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/async.h>\n#include <linux/livepatch.h>\n#include <linux/ftrace.h>\n#include <linux/tracepoint.h>\n#include <asm/sections.h>\n#include <linux/license.h>\n#include <asm/mmu_context.h>\n#include <linux/set_memory.h>\n#include <asm/cacheflush.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/mutex.h>\n#include <linux/string.h>\n#include <linux/device.h>\n#include <linux/sched.h>\n#include <linux/notifier.h>\n#include <linux/vermagic.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/moduleparam.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/rcupdate.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/elf.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/kernel_read_file.h>\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/buildid.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/trace_events.h>\n#include <linux/module_signature.h>\n#include <linux/moduleloader.h>\n#include <linux/extable.h>\n#include <linux/export.h>\n\nvoid module_put(struct module *module)\n{\n\tint ret;\n\n\tif (module) {\n\t\tpreempt_disable();\n\t\tret = atomic_dec_if_positive(&module->refcnt);\n\t\tWARN_ON(ret < 0);\t/* Failed to put refcount */\n\t\ttrace_module_put(module, _RET_IP_);\n\t\tpreempt_enable();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "__module_address",
          "args": [
            "(unsigned long)btp"
          ],
          "line": 1978
        },
        "resolved": true,
        "details": {
          "function_name": "__module_address",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/module.c",
          "lines": "4736-4752",
          "snippet": "struct module *__module_address(unsigned long addr)\n{\n\tstruct module *mod;\n\n\tif (addr < module_addr_min || addr > module_addr_max)\n\t\treturn NULL;\n\n\tmodule_assert_mutex_or_preempt();\n\n\tmod = mod_find(addr);\n\tif (mod) {\n\t\tBUG_ON(!within_module(addr, mod));\n\t\tif (mod->state == MODULE_STATE_UNFORMED)\n\t\t\tmod = NULL;\n\t}\n\treturn mod;\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include \"module-internal.h\"",
            "#include <uapi/linux/module.h>",
            "#include <linux/audit.h>",
            "#include <linux/dynamic_debug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/pfn.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/percpu.h>",
            "#include <linux/async.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/tracepoint.h>",
            "#include <asm/sections.h>",
            "#include <linux/license.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/set_memory.h>",
            "#include <asm/cacheflush.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/mutex.h>",
            "#include <linux/string.h>",
            "#include <linux/device.h>",
            "#include <linux/sched.h>",
            "#include <linux/notifier.h>",
            "#include <linux/vermagic.h>",
            "#include <linux/err.h>",
            "#include <linux/errno.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/elf.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel_read_file.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/buildid.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/module_signature.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/extable.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [
            "#define module_addr_max mod_tree.addr_max",
            "#define module_addr_min mod_tree.addr_min"
          ],
          "globals_used": [
            "static void cfi_cleanup(struct module *mod);",
            "static void cfi_init(struct module *mod);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include \"module-internal.h\"\n#include <uapi/linux/module.h>\n#include <linux/audit.h>\n#include <linux/dynamic_debug.h>\n#include <linux/bsearch.h>\n#include <linux/pfn.h>\n#include <linux/jump_label.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/async.h>\n#include <linux/livepatch.h>\n#include <linux/ftrace.h>\n#include <linux/tracepoint.h>\n#include <asm/sections.h>\n#include <linux/license.h>\n#include <asm/mmu_context.h>\n#include <linux/set_memory.h>\n#include <asm/cacheflush.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/mutex.h>\n#include <linux/string.h>\n#include <linux/device.h>\n#include <linux/sched.h>\n#include <linux/notifier.h>\n#include <linux/vermagic.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/moduleparam.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/rcupdate.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/elf.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/kernel_read_file.h>\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/buildid.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/trace_events.h>\n#include <linux/module_signature.h>\n#include <linux/moduleloader.h>\n#include <linux/extable.h>\n#include <linux/export.h>\n\n#define module_addr_max mod_tree.addr_max\n#define module_addr_min mod_tree.addr_min\n\nstatic void cfi_cleanup(struct module *mod);\nstatic void cfi_init(struct module *mod);\n\nstruct module *__module_address(unsigned long addr)\n{\n\tstruct module *mod;\n\n\tif (addr < module_addr_min || addr > module_addr_max)\n\t\treturn NULL;\n\n\tmodule_assert_mutex_or_preempt();\n\n\tmod = mod_find(addr);\n\tif (mod) {\n\t\tBUG_ON(!within_module(addr, mod));\n\t\tif (mod->state == MODULE_STATE_UNFORMED)\n\t\t\tmod = NULL;\n\t}\n\treturn mod;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 1977
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nvoid bpf_put_raw_tracepoint(struct bpf_raw_event_map *btp)\n{\n\tstruct module *mod;\n\n\tpreempt_disable();\n\tmod = __module_address((unsigned long)btp);\n\tmodule_put(mod);\n\tpreempt_enable();\n}"
  },
  {
    "function_name": "bpf_get_raw_tracepoint",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1961-1971",
    "snippet": "struct bpf_raw_event_map *bpf_get_raw_tracepoint(const char *name)\n{\n\tstruct bpf_raw_event_map *btp = __start__bpf_raw_tp;\n\n\tfor (; btp < __stop__bpf_raw_tp; btp++) {\n\t\tif (!strcmp(btp->tp->name, name))\n\t\t\treturn btp;\n\t}\n\n\treturn bpf_get_raw_tracepoint_module(name);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "extern struct bpf_raw_event_map __start__bpf_raw_tp[];",
      "extern struct bpf_raw_event_map __stop__bpf_raw_tp[];"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_get_raw_tracepoint_module",
          "args": [
            "name"
          ],
          "line": 1970
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_raw_tracepoint_module",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "68-71",
          "snippet": "static struct bpf_raw_event_map *bpf_get_raw_tracepoint_module(const char *name)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic struct bpf_raw_event_map *bpf_get_raw_tracepoint_module(const char *name)\n{\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "strcmp",
          "args": [
            "btp->tp->name",
            "name"
          ],
          "line": 1966
        },
        "resolved": true,
        "details": {
          "function_name": "sym_strcmp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/report.c",
          "lines": "356-365",
          "snippet": "static int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}",
          "includes": [
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include <linux/stacktrace.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/printk.h>",
            "#include <linux/preempt.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/delay.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"encoding.h\"\n#include \"kcsan.h\"\n#include <linux/stacktrace.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/printk.h>\n#include <linux/preempt.h>\n#include <linux/lockdep.h>\n#include <linux/kernel.h>\n#include <linux/kallsyms.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/debug_locks.h>\n\nstatic int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nextern struct bpf_raw_event_map __start__bpf_raw_tp[];\nextern struct bpf_raw_event_map __stop__bpf_raw_tp[];\n\nstruct bpf_raw_event_map *bpf_get_raw_tracepoint(const char *name)\n{\n\tstruct bpf_raw_event_map *btp = __start__bpf_raw_tp;\n\n\tfor (; btp < __stop__bpf_raw_tp; btp++) {\n\t\tif (!strcmp(btp->tp->name, name))\n\t\t\treturn btp;\n\t}\n\n\treturn bpf_get_raw_tracepoint_module(name);\n}"
  },
  {
    "function_name": "perf_event_query_prog_array",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1917-1956",
    "snippet": "int perf_event_query_prog_array(struct perf_event *event, void __user *info)\n{\n\tstruct perf_event_query_bpf __user *uquery = info;\n\tstruct perf_event_query_bpf query = {};\n\tstruct bpf_prog_array *progs;\n\tu32 *ids, prog_cnt, ids_len;\n\tint ret;\n\n\tif (!perfmon_capable())\n\t\treturn -EPERM;\n\tif (event->attr.type != PERF_TYPE_TRACEPOINT)\n\t\treturn -EINVAL;\n\tif (copy_from_user(&query, uquery, sizeof(query)))\n\t\treturn -EFAULT;\n\n\tids_len = query.ids_len;\n\tif (ids_len > BPF_TRACE_MAX_PROGS)\n\t\treturn -E2BIG;\n\tids = kcalloc(ids_len, sizeof(u32), GFP_USER | __GFP_NOWARN);\n\tif (!ids)\n\t\treturn -ENOMEM;\n\t/*\n\t * The above kcalloc returns ZERO_SIZE_PTR when ids_len = 0, which\n\t * is required when user only wants to check for uquery->prog_cnt.\n\t * There is no need to check for it since the case is handled\n\t * gracefully in bpf_prog_array_copy_info.\n\t */\n\n\tmutex_lock(&bpf_event_mutex);\n\tprogs = bpf_event_rcu_dereference(event->tp_event->prog_array);\n\tret = bpf_prog_array_copy_info(progs, ids, ids_len, &prog_cnt);\n\tmutex_unlock(&bpf_event_mutex);\n\n\tif (copy_to_user(&uquery->prog_cnt, &prog_cnt, sizeof(prog_cnt)) ||\n\t    copy_to_user(uquery->ids, ids, ids_len * sizeof(u32)))\n\t\tret = -EFAULT;\n\n\tkfree(ids);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [
      "#define BPF_TRACE_MAX_PROGS 64"
    ],
    "globals_used": [
      "static DEFINE_MUTEX(bpf_event_mutex);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "ids"
          ],
          "line": 1954
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_to_user",
          "args": [
            "uquery->ids",
            "ids",
            "ids_len * sizeof(u32)"
          ],
          "line": 1951
        },
        "resolved": true,
        "details": {
          "function_name": "sched_attr_copy_to_user",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "7847-7876",
          "snippet": "static int\nsched_attr_copy_to_user(struct sched_attr __user *uattr,\n\t\t\tstruct sched_attr *kattr,\n\t\t\tunsigned int usize)\n{\n\tunsigned int ksize = sizeof(*kattr);\n\n\tif (!access_ok(uattr, usize))\n\t\treturn -EFAULT;\n\n\t/*\n\t * sched_getattr() ABI forwards and backwards compatibility:\n\t *\n\t * If usize == ksize then we just copy everything to user-space and all is good.\n\t *\n\t * If usize < ksize then we only copy as much as user-space has space for,\n\t * this keeps ABI compatibility as well. We skip the rest.\n\t *\n\t * If usize > ksize then user-space is using a newer version of the ABI,\n\t * which part the kernel doesn't know about. Just ignore it - tooling can\n\t * detect the kernel's knowledge of attributes from the attr->size value\n\t * which is set to ksize in this case.\n\t */\n\tkattr->size = min(usize, ksize);\n\n\tif (copy_to_user(uattr, kattr, kattr->size))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nstatic int\nsched_attr_copy_to_user(struct sched_attr __user *uattr,\n\t\t\tstruct sched_attr *kattr,\n\t\t\tunsigned int usize)\n{\n\tunsigned int ksize = sizeof(*kattr);\n\n\tif (!access_ok(uattr, usize))\n\t\treturn -EFAULT;\n\n\t/*\n\t * sched_getattr() ABI forwards and backwards compatibility:\n\t *\n\t * If usize == ksize then we just copy everything to user-space and all is good.\n\t *\n\t * If usize < ksize then we only copy as much as user-space has space for,\n\t * this keeps ABI compatibility as well. We skip the rest.\n\t *\n\t * If usize > ksize then user-space is using a newer version of the ABI,\n\t * which part the kernel doesn't know about. Just ignore it - tooling can\n\t * detect the kernel's knowledge of attributes from the attr->size value\n\t * which is set to ksize in this case.\n\t */\n\tkattr->size = min(usize, ksize);\n\n\tif (copy_to_user(uattr, kattr, kattr->size))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&bpf_event_mutex"
          ],
          "line": 1948
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_copy_info",
          "args": [
            "progs",
            "ids",
            "ids_len",
            "&prog_cnt"
          ],
          "line": 1947
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_copy_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2207-2225",
          "snippet": "int bpf_prog_array_copy_info(struct bpf_prog_array *array,\n\t\t\t     u32 *prog_ids, u32 request_cnt,\n\t\t\t     u32 *prog_cnt)\n{\n\tu32 cnt = 0;\n\n\tif (array)\n\t\tcnt = bpf_prog_array_length(array);\n\n\t*prog_cnt = cnt;\n\n\t/* return early if user requested only program count or nothing to copy */\n\tif (!request_cnt || !cnt)\n\t\treturn 0;\n\n\t/* this function is called under trace/bpf_trace.c: bpf_event_mutex */\n\treturn bpf_prog_array_copy_core(array, prog_ids, request_cnt) ? -ENOSPC\n\t\t\t\t\t\t\t\t     : 0;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nint bpf_prog_array_copy_info(struct bpf_prog_array *array,\n\t\t\t     u32 *prog_ids, u32 request_cnt,\n\t\t\t     u32 *prog_cnt)\n{\n\tu32 cnt = 0;\n\n\tif (array)\n\t\tcnt = bpf_prog_array_length(array);\n\n\t*prog_cnt = cnt;\n\n\t/* return early if user requested only program count or nothing to copy */\n\tif (!request_cnt || !cnt)\n\t\treturn 0;\n\n\t/* this function is called under trace/bpf_trace.c: bpf_event_mutex */\n\treturn bpf_prog_array_copy_core(array, prog_ids, request_cnt) ? -ENOSPC\n\t\t\t\t\t\t\t\t     : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_event_rcu_dereference",
          "args": [
            "event->tp_event->prog_array"
          ],
          "line": 1946
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&bpf_event_mutex"
          ],
          "line": 1945
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kcalloc",
          "args": [
            "ids_len",
            "sizeof(u32)",
            "GFP_USER | __GFP_NOWARN"
          ],
          "line": 1935
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "&query",
            "uquery",
            "sizeof(query)"
          ],
          "line": 1929
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "perfmon_capable",
          "args": [],
          "line": 1925
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\n#define BPF_TRACE_MAX_PROGS 64\n\nstatic DEFINE_MUTEX(bpf_event_mutex);\n\nint perf_event_query_prog_array(struct perf_event *event, void __user *info)\n{\n\tstruct perf_event_query_bpf __user *uquery = info;\n\tstruct perf_event_query_bpf query = {};\n\tstruct bpf_prog_array *progs;\n\tu32 *ids, prog_cnt, ids_len;\n\tint ret;\n\n\tif (!perfmon_capable())\n\t\treturn -EPERM;\n\tif (event->attr.type != PERF_TYPE_TRACEPOINT)\n\t\treturn -EINVAL;\n\tif (copy_from_user(&query, uquery, sizeof(query)))\n\t\treturn -EFAULT;\n\n\tids_len = query.ids_len;\n\tif (ids_len > BPF_TRACE_MAX_PROGS)\n\t\treturn -E2BIG;\n\tids = kcalloc(ids_len, sizeof(u32), GFP_USER | __GFP_NOWARN);\n\tif (!ids)\n\t\treturn -ENOMEM;\n\t/*\n\t * The above kcalloc returns ZERO_SIZE_PTR when ids_len = 0, which\n\t * is required when user only wants to check for uquery->prog_cnt.\n\t * There is no need to check for it since the case is handled\n\t * gracefully in bpf_prog_array_copy_info.\n\t */\n\n\tmutex_lock(&bpf_event_mutex);\n\tprogs = bpf_event_rcu_dereference(event->tp_event->prog_array);\n\tret = bpf_prog_array_copy_info(progs, ids, ids_len, &prog_cnt);\n\tmutex_unlock(&bpf_event_mutex);\n\n\tif (copy_to_user(&uquery->prog_cnt, &prog_cnt, sizeof(prog_cnt)) ||\n\t    copy_to_user(uquery->ids, ids, ids_len * sizeof(u32)))\n\t\tret = -EFAULT;\n\n\tkfree(ids);\n\treturn ret;\n}"
  },
  {
    "function_name": "perf_event_detach_bpf_prog",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1888-1915",
    "snippet": "void perf_event_detach_bpf_prog(struct perf_event *event)\n{\n\tstruct bpf_prog_array *old_array;\n\tstruct bpf_prog_array *new_array;\n\tint ret;\n\n\tmutex_lock(&bpf_event_mutex);\n\n\tif (!event->prog)\n\t\tgoto unlock;\n\n\told_array = bpf_event_rcu_dereference(event->tp_event->prog_array);\n\tret = bpf_prog_array_copy(old_array, event->prog, NULL, 0, &new_array);\n\tif (ret == -ENOENT)\n\t\tgoto unlock;\n\tif (ret < 0) {\n\t\tbpf_prog_array_delete_safe(old_array, event->prog);\n\t} else {\n\t\trcu_assign_pointer(event->tp_event->prog_array, new_array);\n\t\tbpf_prog_array_free(old_array);\n\t}\n\n\tbpf_prog_put(event->prog);\n\tevent->prog = NULL;\n\nunlock:\n\tmutex_unlock(&bpf_event_mutex);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_MUTEX(bpf_event_mutex);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&bpf_event_mutex"
          ],
          "line": 1914
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_put",
          "args": [
            "event->prog"
          ],
          "line": 1910
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_put",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "1828-1831",
          "snippet": "void bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_free",
          "args": [
            "old_array"
          ],
          "line": 1907
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "1995-2000",
          "snippet": "void bpf_prog_array_free(struct bpf_prog_array *progs)\n{\n\tif (!progs || progs == &empty_prog_array.hdr)\n\t\treturn;\n\tkfree_rcu(progs, rcu);\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct {\n\tstruct bpf_prog_array hdr;\n\tstruct bpf_prog *null_prog;\n} empty_prog_array = {\n\t.null_prog = NULL,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nstatic struct {\n\tstruct bpf_prog_array hdr;\n\tstruct bpf_prog *null_prog;\n} empty_prog_array = {\n\t.null_prog = NULL,\n};\n\nvoid bpf_prog_array_free(struct bpf_prog_array *progs)\n{\n\tif (!progs || progs == &empty_prog_array.hdr)\n\t\treturn;\n\tkfree_rcu(progs, rcu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_assign_pointer",
          "args": [
            "event->tp_event->prog_array",
            "new_array"
          ],
          "line": 1906
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_delete_safe",
          "args": [
            "old_array",
            "event->prog"
          ],
          "line": 1904
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_delete_safe_at",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2096-2099",
          "snippet": "int bpf_prog_array_delete_safe_at(struct bpf_prog_array *array, int index)\n{\n\treturn bpf_prog_array_update_at(array, index, &dummy_bpf_prog.prog);\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nstatic struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};\n\nint bpf_prog_array_delete_safe_at(struct bpf_prog_array *array, int index)\n{\n\treturn bpf_prog_array_update_at(array, index, &dummy_bpf_prog.prog);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_copy",
          "args": [
            "old_array",
            "event->prog",
            "NULL",
            "0",
            "&new_array"
          ],
          "line": 1900
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_copy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2136-2205",
          "snippet": "int bpf_prog_array_copy(struct bpf_prog_array *old_array,\n\t\t\tstruct bpf_prog *exclude_prog,\n\t\t\tstruct bpf_prog *include_prog,\n\t\t\tu64 bpf_cookie,\n\t\t\tstruct bpf_prog_array **new_array)\n{\n\tint new_prog_cnt, carry_prog_cnt = 0;\n\tstruct bpf_prog_array_item *existing, *new;\n\tstruct bpf_prog_array *array;\n\tbool found_exclude = false;\n\n\t/* Figure out how many existing progs we need to carry over to\n\t * the new array.\n\t */\n\tif (old_array) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog) {\n\t\t\t\tfound_exclude = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (existing->prog != &dummy_bpf_prog.prog)\n\t\t\t\tcarry_prog_cnt++;\n\t\t\tif (existing->prog == include_prog)\n\t\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tif (exclude_prog && !found_exclude)\n\t\treturn -ENOENT;\n\n\t/* How many progs (not NULL) will be in the new array? */\n\tnew_prog_cnt = carry_prog_cnt;\n\tif (include_prog)\n\t\tnew_prog_cnt += 1;\n\n\t/* Do we have any prog (not NULL) in the new array? */\n\tif (!new_prog_cnt) {\n\t\t*new_array = NULL;\n\t\treturn 0;\n\t}\n\n\t/* +1 as the end of prog_array is marked with NULL */\n\tarray = bpf_prog_array_alloc(new_prog_cnt + 1, GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\tnew = array->items;\n\n\t/* Fill in the new prog array */\n\tif (carry_prog_cnt) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog ||\n\t\t\t    existing->prog == &dummy_bpf_prog.prog)\n\t\t\t\tcontinue;\n\n\t\t\tnew->prog = existing->prog;\n\t\t\tnew->bpf_cookie = existing->bpf_cookie;\n\t\t\tnew++;\n\t\t}\n\t}\n\tif (include_prog) {\n\t\tnew->prog = include_prog;\n\t\tnew->bpf_cookie = bpf_cookie;\n\t\tnew++;\n\t}\n\tnew->prog = NULL;\n\t*new_array = array;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nstatic struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};\n\nint bpf_prog_array_copy(struct bpf_prog_array *old_array,\n\t\t\tstruct bpf_prog *exclude_prog,\n\t\t\tstruct bpf_prog *include_prog,\n\t\t\tu64 bpf_cookie,\n\t\t\tstruct bpf_prog_array **new_array)\n{\n\tint new_prog_cnt, carry_prog_cnt = 0;\n\tstruct bpf_prog_array_item *existing, *new;\n\tstruct bpf_prog_array *array;\n\tbool found_exclude = false;\n\n\t/* Figure out how many existing progs we need to carry over to\n\t * the new array.\n\t */\n\tif (old_array) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog) {\n\t\t\t\tfound_exclude = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (existing->prog != &dummy_bpf_prog.prog)\n\t\t\t\tcarry_prog_cnt++;\n\t\t\tif (existing->prog == include_prog)\n\t\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tif (exclude_prog && !found_exclude)\n\t\treturn -ENOENT;\n\n\t/* How many progs (not NULL) will be in the new array? */\n\tnew_prog_cnt = carry_prog_cnt;\n\tif (include_prog)\n\t\tnew_prog_cnt += 1;\n\n\t/* Do we have any prog (not NULL) in the new array? */\n\tif (!new_prog_cnt) {\n\t\t*new_array = NULL;\n\t\treturn 0;\n\t}\n\n\t/* +1 as the end of prog_array is marked with NULL */\n\tarray = bpf_prog_array_alloc(new_prog_cnt + 1, GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\tnew = array->items;\n\n\t/* Fill in the new prog array */\n\tif (carry_prog_cnt) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog ||\n\t\t\t    existing->prog == &dummy_bpf_prog.prog)\n\t\t\t\tcontinue;\n\n\t\t\tnew->prog = existing->prog;\n\t\t\tnew->bpf_cookie = existing->bpf_cookie;\n\t\t\tnew++;\n\t\t}\n\t}\n\tif (include_prog) {\n\t\tnew->prog = include_prog;\n\t\tnew->bpf_cookie = bpf_cookie;\n\t\tnew++;\n\t}\n\tnew->prog = NULL;\n\t*new_array = array;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_event_rcu_dereference",
          "args": [
            "event->tp_event->prog_array"
          ],
          "line": 1899
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&bpf_event_mutex"
          ],
          "line": 1894
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_MUTEX(bpf_event_mutex);\n\nvoid perf_event_detach_bpf_prog(struct perf_event *event)\n{\n\tstruct bpf_prog_array *old_array;\n\tstruct bpf_prog_array *new_array;\n\tint ret;\n\n\tmutex_lock(&bpf_event_mutex);\n\n\tif (!event->prog)\n\t\tgoto unlock;\n\n\told_array = bpf_event_rcu_dereference(event->tp_event->prog_array);\n\tret = bpf_prog_array_copy(old_array, event->prog, NULL, 0, &new_array);\n\tif (ret == -ENOENT)\n\t\tgoto unlock;\n\tif (ret < 0) {\n\t\tbpf_prog_array_delete_safe(old_array, event->prog);\n\t} else {\n\t\trcu_assign_pointer(event->tp_event->prog_array, new_array);\n\t\tbpf_prog_array_free(old_array);\n\t}\n\n\tbpf_prog_put(event->prog);\n\tevent->prog = NULL;\n\nunlock:\n\tmutex_unlock(&bpf_event_mutex);\n}"
  },
  {
    "function_name": "perf_event_attach_bpf_prog",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1844-1886",
    "snippet": "int perf_event_attach_bpf_prog(struct perf_event *event,\n\t\t\t       struct bpf_prog *prog,\n\t\t\t       u64 bpf_cookie)\n{\n\tstruct bpf_prog_array *old_array;\n\tstruct bpf_prog_array *new_array;\n\tint ret = -EEXIST;\n\n\t/*\n\t * Kprobe override only works if they are on the function entry,\n\t * and only if they are on the opt-in list.\n\t */\n\tif (prog->kprobe_override &&\n\t    (!trace_kprobe_on_func_entry(event->tp_event) ||\n\t     !trace_kprobe_error_injectable(event->tp_event)))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&bpf_event_mutex);\n\n\tif (event->prog)\n\t\tgoto unlock;\n\n\told_array = bpf_event_rcu_dereference(event->tp_event->prog_array);\n\tif (old_array &&\n\t    bpf_prog_array_length(old_array) >= BPF_TRACE_MAX_PROGS) {\n\t\tret = -E2BIG;\n\t\tgoto unlock;\n\t}\n\n\tret = bpf_prog_array_copy(old_array, NULL, prog, bpf_cookie, &new_array);\n\tif (ret < 0)\n\t\tgoto unlock;\n\n\t/* set the new array to event->tp_event and set event->prog */\n\tevent->prog = prog;\n\tevent->bpf_cookie = bpf_cookie;\n\trcu_assign_pointer(event->tp_event->prog_array, new_array);\n\tbpf_prog_array_free(old_array);\n\nunlock:\n\tmutex_unlock(&bpf_event_mutex);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [
      "#define BPF_TRACE_MAX_PROGS 64"
    ],
    "globals_used": [
      "static DEFINE_MUTEX(bpf_event_mutex);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&bpf_event_mutex"
          ],
          "line": 1884
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_free",
          "args": [
            "old_array"
          ],
          "line": 1881
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "1995-2000",
          "snippet": "void bpf_prog_array_free(struct bpf_prog_array *progs)\n{\n\tif (!progs || progs == &empty_prog_array.hdr)\n\t\treturn;\n\tkfree_rcu(progs, rcu);\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct {\n\tstruct bpf_prog_array hdr;\n\tstruct bpf_prog *null_prog;\n} empty_prog_array = {\n\t.null_prog = NULL,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nstatic struct {\n\tstruct bpf_prog_array hdr;\n\tstruct bpf_prog *null_prog;\n} empty_prog_array = {\n\t.null_prog = NULL,\n};\n\nvoid bpf_prog_array_free(struct bpf_prog_array *progs)\n{\n\tif (!progs || progs == &empty_prog_array.hdr)\n\t\treturn;\n\tkfree_rcu(progs, rcu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_assign_pointer",
          "args": [
            "event->tp_event->prog_array",
            "new_array"
          ],
          "line": 1880
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_copy",
          "args": [
            "old_array",
            "NULL",
            "prog",
            "bpf_cookie",
            "&new_array"
          ],
          "line": 1873
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_copy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2136-2205",
          "snippet": "int bpf_prog_array_copy(struct bpf_prog_array *old_array,\n\t\t\tstruct bpf_prog *exclude_prog,\n\t\t\tstruct bpf_prog *include_prog,\n\t\t\tu64 bpf_cookie,\n\t\t\tstruct bpf_prog_array **new_array)\n{\n\tint new_prog_cnt, carry_prog_cnt = 0;\n\tstruct bpf_prog_array_item *existing, *new;\n\tstruct bpf_prog_array *array;\n\tbool found_exclude = false;\n\n\t/* Figure out how many existing progs we need to carry over to\n\t * the new array.\n\t */\n\tif (old_array) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog) {\n\t\t\t\tfound_exclude = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (existing->prog != &dummy_bpf_prog.prog)\n\t\t\t\tcarry_prog_cnt++;\n\t\t\tif (existing->prog == include_prog)\n\t\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tif (exclude_prog && !found_exclude)\n\t\treturn -ENOENT;\n\n\t/* How many progs (not NULL) will be in the new array? */\n\tnew_prog_cnt = carry_prog_cnt;\n\tif (include_prog)\n\t\tnew_prog_cnt += 1;\n\n\t/* Do we have any prog (not NULL) in the new array? */\n\tif (!new_prog_cnt) {\n\t\t*new_array = NULL;\n\t\treturn 0;\n\t}\n\n\t/* +1 as the end of prog_array is marked with NULL */\n\tarray = bpf_prog_array_alloc(new_prog_cnt + 1, GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\tnew = array->items;\n\n\t/* Fill in the new prog array */\n\tif (carry_prog_cnt) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog ||\n\t\t\t    existing->prog == &dummy_bpf_prog.prog)\n\t\t\t\tcontinue;\n\n\t\t\tnew->prog = existing->prog;\n\t\t\tnew->bpf_cookie = existing->bpf_cookie;\n\t\t\tnew++;\n\t\t}\n\t}\n\tif (include_prog) {\n\t\tnew->prog = include_prog;\n\t\tnew->bpf_cookie = bpf_cookie;\n\t\tnew++;\n\t}\n\tnew->prog = NULL;\n\t*new_array = array;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nstatic struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};\n\nint bpf_prog_array_copy(struct bpf_prog_array *old_array,\n\t\t\tstruct bpf_prog *exclude_prog,\n\t\t\tstruct bpf_prog *include_prog,\n\t\t\tu64 bpf_cookie,\n\t\t\tstruct bpf_prog_array **new_array)\n{\n\tint new_prog_cnt, carry_prog_cnt = 0;\n\tstruct bpf_prog_array_item *existing, *new;\n\tstruct bpf_prog_array *array;\n\tbool found_exclude = false;\n\n\t/* Figure out how many existing progs we need to carry over to\n\t * the new array.\n\t */\n\tif (old_array) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog) {\n\t\t\t\tfound_exclude = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (existing->prog != &dummy_bpf_prog.prog)\n\t\t\t\tcarry_prog_cnt++;\n\t\t\tif (existing->prog == include_prog)\n\t\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tif (exclude_prog && !found_exclude)\n\t\treturn -ENOENT;\n\n\t/* How many progs (not NULL) will be in the new array? */\n\tnew_prog_cnt = carry_prog_cnt;\n\tif (include_prog)\n\t\tnew_prog_cnt += 1;\n\n\t/* Do we have any prog (not NULL) in the new array? */\n\tif (!new_prog_cnt) {\n\t\t*new_array = NULL;\n\t\treturn 0;\n\t}\n\n\t/* +1 as the end of prog_array is marked with NULL */\n\tarray = bpf_prog_array_alloc(new_prog_cnt + 1, GFP_KERNEL);\n\tif (!array)\n\t\treturn -ENOMEM;\n\tnew = array->items;\n\n\t/* Fill in the new prog array */\n\tif (carry_prog_cnt) {\n\t\texisting = old_array->items;\n\t\tfor (; existing->prog; existing++) {\n\t\t\tif (existing->prog == exclude_prog ||\n\t\t\t    existing->prog == &dummy_bpf_prog.prog)\n\t\t\t\tcontinue;\n\n\t\t\tnew->prog = existing->prog;\n\t\t\tnew->bpf_cookie = existing->bpf_cookie;\n\t\t\tnew++;\n\t\t}\n\t}\n\tif (include_prog) {\n\t\tnew->prog = include_prog;\n\t\tnew->bpf_cookie = bpf_cookie;\n\t\tnew++;\n\t}\n\tnew->prog = NULL;\n\t*new_array = array;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_array_length",
          "args": [
            "old_array"
          ],
          "line": 1868
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_length",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2002-2011",
          "snippet": "int bpf_prog_array_length(struct bpf_prog_array *array)\n{\n\tstruct bpf_prog_array_item *item;\n\tu32 cnt = 0;\n\n\tfor (item = array->items; item->prog; item++)\n\t\tif (item->prog != &dummy_bpf_prog.prog)\n\t\t\tcnt++;\n\treturn cnt;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nstatic struct bpf_prog_dummy {\n\tstruct bpf_prog prog;\n} dummy_bpf_prog = {\n\t.prog = {\n\t\t.bpf_func = __bpf_prog_ret1,\n\t},\n};\n\nint bpf_prog_array_length(struct bpf_prog_array *array)\n{\n\tstruct bpf_prog_array_item *item;\n\tu32 cnt = 0;\n\n\tfor (item = array->items; item->prog; item++)\n\t\tif (item->prog != &dummy_bpf_prog.prog)\n\t\t\tcnt++;\n\treturn cnt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_event_rcu_dereference",
          "args": [
            "event->tp_event->prog_array"
          ],
          "line": 1866
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&bpf_event_mutex"
          ],
          "line": 1861
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kprobe_error_injectable",
          "args": [
            "event->tp_event"
          ],
          "line": 1858
        },
        "resolved": true,
        "details": {
          "function_name": "trace_kprobe_error_injectable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_kprobe.c",
          "lines": "226-232",
          "snippet": "bool trace_kprobe_error_injectable(struct trace_event_call *call)\n{\n\tstruct trace_kprobe *tk = trace_kprobe_primary_from_call(call);\n\n\treturn tk ? within_error_injection_list(trace_kprobe_address(tk)) :\n\t       false;\n}",
          "includes": [
            "#include \"trace_probe_tmpl.h\"",
            "#include \"trace_probe.h\"",
            "#include \"trace_kprobe_selftest.h\"",
            "#include \"trace_dynevent.h\"",
            "#include <asm/setup.h>  /* for COMMAND_LINE_SIZE */",
            "#include <linux/error-injection.h>",
            "#include <linux/rculist.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/module.h>",
            "#include <linux/security.h>",
            "#include <linux/bpf-cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static nokprobe_inline struct",
            "static int register_kprobe_event(struct trace_kprobe *tk);",
            "static int unregister_kprobe_event(struct trace_kprobe *tk);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_probe_tmpl.h\"\n#include \"trace_probe.h\"\n#include \"trace_kprobe_selftest.h\"\n#include \"trace_dynevent.h\"\n#include <asm/setup.h>  /* for COMMAND_LINE_SIZE */\n#include <linux/error-injection.h>\n#include <linux/rculist.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/security.h>\n#include <linux/bpf-cgroup.h>\n\nstatic nokprobe_inline struct;\nstatic int register_kprobe_event(struct trace_kprobe *tk);\nstatic int unregister_kprobe_event(struct trace_kprobe *tk);\n\nbool trace_kprobe_error_injectable(struct trace_event_call *call)\n{\n\tstruct trace_kprobe *tk = trace_kprobe_primary_from_call(call);\n\n\treturn tk ? within_error_injection_list(trace_kprobe_address(tk)) :\n\t       false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_kprobe_on_func_entry",
          "args": [
            "event->tp_event"
          ],
          "line": 1857
        },
        "resolved": true,
        "details": {
          "function_name": "trace_kprobe_on_func_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_kprobe.c",
          "lines": "217-224",
          "snippet": "bool trace_kprobe_on_func_entry(struct trace_event_call *call)\n{\n\tstruct trace_kprobe *tk = trace_kprobe_primary_from_call(call);\n\n\treturn tk ? (kprobe_on_func_entry(tk->rp.kp.addr,\n\t\t\ttk->rp.kp.addr ? NULL : tk->rp.kp.symbol_name,\n\t\t\ttk->rp.kp.addr ? 0 : tk->rp.kp.offset) == 0) : false;\n}",
          "includes": [
            "#include \"trace_probe_tmpl.h\"",
            "#include \"trace_probe.h\"",
            "#include \"trace_kprobe_selftest.h\"",
            "#include \"trace_dynevent.h\"",
            "#include <asm/setup.h>  /* for COMMAND_LINE_SIZE */",
            "#include <linux/error-injection.h>",
            "#include <linux/rculist.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/module.h>",
            "#include <linux/security.h>",
            "#include <linux/bpf-cgroup.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static nokprobe_inline struct",
            "static int register_kprobe_event(struct trace_kprobe *tk);",
            "static int unregister_kprobe_event(struct trace_kprobe *tk);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_probe_tmpl.h\"\n#include \"trace_probe.h\"\n#include \"trace_kprobe_selftest.h\"\n#include \"trace_dynevent.h\"\n#include <asm/setup.h>  /* for COMMAND_LINE_SIZE */\n#include <linux/error-injection.h>\n#include <linux/rculist.h>\n#include <linux/uaccess.h>\n#include <linux/module.h>\n#include <linux/security.h>\n#include <linux/bpf-cgroup.h>\n\nstatic nokprobe_inline struct;\nstatic int register_kprobe_event(struct trace_kprobe *tk);\nstatic int unregister_kprobe_event(struct trace_kprobe *tk);\n\nbool trace_kprobe_on_func_entry(struct trace_event_call *call)\n{\n\tstruct trace_kprobe *tk = trace_kprobe_primary_from_call(call);\n\n\treturn tk ? (kprobe_on_func_entry(tk->rp.kp.addr,\n\t\t\ttk->rp.kp.addr ? NULL : tk->rp.kp.symbol_name,\n\t\t\ttk->rp.kp.addr ? 0 : tk->rp.kp.offset) == 0) : false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\n#define BPF_TRACE_MAX_PROGS 64\n\nstatic DEFINE_MUTEX(bpf_event_mutex);\n\nint perf_event_attach_bpf_prog(struct perf_event *event,\n\t\t\t       struct bpf_prog *prog,\n\t\t\t       u64 bpf_cookie)\n{\n\tstruct bpf_prog_array *old_array;\n\tstruct bpf_prog_array *new_array;\n\tint ret = -EEXIST;\n\n\t/*\n\t * Kprobe override only works if they are on the function entry,\n\t * and only if they are on the opt-in list.\n\t */\n\tif (prog->kprobe_override &&\n\t    (!trace_kprobe_on_func_entry(event->tp_event) ||\n\t     !trace_kprobe_error_injectable(event->tp_event)))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&bpf_event_mutex);\n\n\tif (event->prog)\n\t\tgoto unlock;\n\n\told_array = bpf_event_rcu_dereference(event->tp_event->prog_array);\n\tif (old_array &&\n\t    bpf_prog_array_length(old_array) >= BPF_TRACE_MAX_PROGS) {\n\t\tret = -E2BIG;\n\t\tgoto unlock;\n\t}\n\n\tret = bpf_prog_array_copy(old_array, NULL, prog, bpf_cookie, &new_array);\n\tif (ret < 0)\n\t\tgoto unlock;\n\n\t/* set the new array to event->tp_event and set event->prog */\n\tevent->prog = prog;\n\tevent->bpf_cookie = bpf_cookie;\n\trcu_assign_pointer(event->tp_event->prog_array, new_array);\n\tbpf_prog_array_free(old_array);\n\nunlock:\n\tmutex_unlock(&bpf_event_mutex);\n\treturn ret;\n}"
  },
  {
    "function_name": "pe_prog_convert_ctx_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1795-1829",
    "snippet": "static u32 pe_prog_convert_ctx_access(enum bpf_access_type type,\n\t\t\t\t      const struct bpf_insn *si,\n\t\t\t\t      struct bpf_insn *insn_buf,\n\t\t\t\t      struct bpf_prog *prog, u32 *target_size)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\n\tswitch (si->off) {\n\tcase offsetof(struct bpf_perf_event_data, sample_period):\n\t\t*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       data), si->dst_reg, si->src_reg,\n\t\t\t\t      offsetof(struct bpf_perf_event_data_kern, data));\n\t\t*insn++ = BPF_LDX_MEM(BPF_DW, si->dst_reg, si->dst_reg,\n\t\t\t\t      bpf_target_off(struct perf_sample_data, period, 8,\n\t\t\t\t\t\t     target_size));\n\t\tbreak;\n\tcase offsetof(struct bpf_perf_event_data, addr):\n\t\t*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       data), si->dst_reg, si->src_reg,\n\t\t\t\t      offsetof(struct bpf_perf_event_data_kern, data));\n\t\t*insn++ = BPF_LDX_MEM(BPF_DW, si->dst_reg, si->dst_reg,\n\t\t\t\t      bpf_target_off(struct perf_sample_data, addr, 8,\n\t\t\t\t\t\t     target_size));\n\t\tbreak;\n\tdefault:\n\t\t*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       regs), si->dst_reg, si->src_reg,\n\t\t\t\t      offsetof(struct bpf_perf_event_data_kern, regs));\n\t\t*insn++ = BPF_LDX_MEM(BPF_SIZEOF(long), si->dst_reg, si->dst_reg,\n\t\t\t\t      si->off);\n\t\tbreak;\n\t}\n\n\treturn insn - insn_buf;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_SIZEOF(long)",
            "si->dst_reg",
            "si->dst_reg",
            "si->off"
          ],
          "line": 1823
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_SIZEOF",
          "args": [
            "long"
          ],
          "line": 1823
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       regs)",
            "si->dst_reg",
            "si->src_reg",
            "offsetof(struct bpf_perf_event_data_kern, regs)"
          ],
          "line": 1820
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_FIELD_SIZEOF",
          "args": [
            "structbpf_perf_event_data_kern",
            "regs"
          ],
          "line": 1820
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_DW",
            "si->dst_reg",
            "si->dst_reg",
            "bpf_target_off(struct perf_sample_data, addr, 8,\n\t\t\t\t\t\t     target_size)"
          ],
          "line": 1815
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_target_off",
          "args": [
            "structperf_sample_data",
            "addr",
            "8",
            "target_size"
          ],
          "line": 1816
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       data)",
            "si->dst_reg",
            "si->src_reg",
            "offsetof(struct bpf_perf_event_data_kern, data)"
          ],
          "line": 1812
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_FIELD_SIZEOF",
          "args": [
            "structbpf_perf_event_data_kern",
            "data"
          ],
          "line": 1812
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_DW",
            "si->dst_reg",
            "si->dst_reg",
            "bpf_target_off(struct perf_sample_data, period, 8,\n\t\t\t\t\t\t     target_size)"
          ],
          "line": 1807
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_target_off",
          "args": [
            "structperf_sample_data",
            "period",
            "8",
            "target_size"
          ],
          "line": 1808
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_LDX_MEM",
          "args": [
            "BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       data)",
            "si->dst_reg",
            "si->src_reg",
            "offsetof(struct bpf_perf_event_data_kern, data)"
          ],
          "line": 1804
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_FIELD_SIZEOF",
          "args": [
            "structbpf_perf_event_data_kern",
            "data"
          ],
          "line": 1804
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic u32 pe_prog_convert_ctx_access(enum bpf_access_type type,\n\t\t\t\t      const struct bpf_insn *si,\n\t\t\t\t      struct bpf_insn *insn_buf,\n\t\t\t\t      struct bpf_prog *prog, u32 *target_size)\n{\n\tstruct bpf_insn *insn = insn_buf;\n\n\tswitch (si->off) {\n\tcase offsetof(struct bpf_perf_event_data, sample_period):\n\t\t*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       data), si->dst_reg, si->src_reg,\n\t\t\t\t      offsetof(struct bpf_perf_event_data_kern, data));\n\t\t*insn++ = BPF_LDX_MEM(BPF_DW, si->dst_reg, si->dst_reg,\n\t\t\t\t      bpf_target_off(struct perf_sample_data, period, 8,\n\t\t\t\t\t\t     target_size));\n\t\tbreak;\n\tcase offsetof(struct bpf_perf_event_data, addr):\n\t\t*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       data), si->dst_reg, si->src_reg,\n\t\t\t\t      offsetof(struct bpf_perf_event_data_kern, data));\n\t\t*insn++ = BPF_LDX_MEM(BPF_DW, si->dst_reg, si->dst_reg,\n\t\t\t\t      bpf_target_off(struct perf_sample_data, addr, 8,\n\t\t\t\t\t\t     target_size));\n\t\tbreak;\n\tdefault:\n\t\t*insn++ = BPF_LDX_MEM(BPF_FIELD_SIZEOF(struct bpf_perf_event_data_kern,\n\t\t\t\t\t\t       regs), si->dst_reg, si->src_reg,\n\t\t\t\t      offsetof(struct bpf_perf_event_data_kern, regs));\n\t\t*insn++ = BPF_LDX_MEM(BPF_SIZEOF(long), si->dst_reg, si->dst_reg,\n\t\t\t\t      si->off);\n\t\tbreak;\n\t}\n\n\treturn insn - insn_buf;\n}"
  },
  {
    "function_name": "pe_prog_is_valid_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1757-1793",
    "snippet": "static bool pe_prog_is_valid_access(int off, int size, enum bpf_access_type type,\n\t\t\t\t    const struct bpf_prog *prog,\n\t\t\t\t    struct bpf_insn_access_aux *info)\n{\n\tconst int size_u64 = sizeof(u64);\n\n\tif (off < 0 || off >= sizeof(struct bpf_perf_event_data))\n\t\treturn false;\n\tif (type != BPF_READ)\n\t\treturn false;\n\tif (off % size != 0) {\n\t\tif (sizeof(unsigned long) != 4)\n\t\t\treturn false;\n\t\tif (size != 8)\n\t\t\treturn false;\n\t\tif (off % size != 4)\n\t\t\treturn false;\n\t}\n\n\tswitch (off) {\n\tcase bpf_ctx_range(struct bpf_perf_event_data, sample_period):\n\t\tbpf_ctx_record_field_size(info, size_u64);\n\t\tif (!bpf_ctx_narrow_access_ok(off, size, size_u64))\n\t\t\treturn false;\n\t\tbreak;\n\tcase bpf_ctx_range(struct bpf_perf_event_data, addr):\n\t\tbpf_ctx_record_field_size(info, size_u64);\n\t\tif (!bpf_ctx_narrow_access_ok(off, size, size_u64))\n\t\t\treturn false;\n\t\tbreak;\n\tdefault:\n\t\tif (size != sizeof(long))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_ctx_narrow_access_ok",
          "args": [
            "off",
            "size",
            "size_u64"
          ],
          "line": 1784
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_ctx_record_field_size",
          "args": [
            "info",
            "size_u64"
          ],
          "line": 1783
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_ctx_range",
          "args": [
            "structbpf_perf_event_data",
            "addr"
          ],
          "line": 1782
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_ctx_narrow_access_ok",
          "args": [
            "off",
            "size",
            "size_u64"
          ],
          "line": 1779
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_ctx_record_field_size",
          "args": [
            "info",
            "size_u64"
          ],
          "line": 1778
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_ctx_range",
          "args": [
            "structbpf_perf_event_data",
            "sample_period"
          ],
          "line": 1777
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool pe_prog_is_valid_access(int off, int size, enum bpf_access_type type,\n\t\t\t\t    const struct bpf_prog *prog,\n\t\t\t\t    struct bpf_insn_access_aux *info)\n{\n\tconst int size_u64 = sizeof(u64);\n\n\tif (off < 0 || off >= sizeof(struct bpf_perf_event_data))\n\t\treturn false;\n\tif (type != BPF_READ)\n\t\treturn false;\n\tif (off % size != 0) {\n\t\tif (sizeof(unsigned long) != 4)\n\t\t\treturn false;\n\t\tif (size != 8)\n\t\t\treturn false;\n\t\tif (off % size != 4)\n\t\t\treturn false;\n\t}\n\n\tswitch (off) {\n\tcase bpf_ctx_range(struct bpf_perf_event_data, sample_period):\n\t\tbpf_ctx_record_field_size(info, size_u64);\n\t\tif (!bpf_ctx_narrow_access_ok(off, size, size_u64))\n\t\t\treturn false;\n\t\tbreak;\n\tcase bpf_ctx_range(struct bpf_perf_event_data, addr):\n\t\tbpf_ctx_record_field_size(info, size_u64);\n\t\tif (!bpf_ctx_narrow_access_ok(off, size, size_u64))\n\t\t\treturn false;\n\t\tbreak;\n\tdefault:\n\t\tif (size != sizeof(long))\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}"
  },
  {
    "function_name": "raw_tp_writable_prog_is_valid_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1736-1747",
    "snippet": "static bool raw_tp_writable_prog_is_valid_access(int off, int size,\n\t\t\t\t\t\t enum bpf_access_type type,\n\t\t\t\t\t\t const struct bpf_prog *prog,\n\t\t\t\t\t\t struct bpf_insn_access_aux *info)\n{\n\tif (off == 0) {\n\t\tif (size != sizeof(u64) || type != BPF_READ)\n\t\t\treturn false;\n\t\tinfo->reg_type = PTR_TO_TP_BUFFER;\n\t}\n\treturn raw_tp_prog_is_valid_access(off, size, type, prog, info);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_tp_prog_is_valid_access",
          "args": [
            "off",
            "size",
            "type",
            "prog",
            "info"
          ],
          "line": 1746
        },
        "resolved": true,
        "details": {
          "function_name": "raw_tp_prog_is_valid_access",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "1693-1699",
          "snippet": "static bool raw_tp_prog_is_valid_access(int off, int size,\n\t\t\t\t\tenum bpf_access_type type,\n\t\t\t\t\tconst struct bpf_prog *prog,\n\t\t\t\t\tstruct bpf_insn_access_aux *info)\n{\n\treturn bpf_tracing_ctx_access(off, size, type);\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool raw_tp_prog_is_valid_access(int off, int size,\n\t\t\t\t\tenum bpf_access_type type,\n\t\t\t\t\tconst struct bpf_prog *prog,\n\t\t\t\t\tstruct bpf_insn_access_aux *info)\n{\n\treturn bpf_tracing_ctx_access(off, size, type);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool raw_tp_writable_prog_is_valid_access(int off, int size,\n\t\t\t\t\t\t enum bpf_access_type type,\n\t\t\t\t\t\t const struct bpf_prog *prog,\n\t\t\t\t\t\t struct bpf_insn_access_aux *info)\n{\n\tif (off == 0) {\n\t\tif (size != sizeof(u64) || type != BPF_READ)\n\t\t\treturn false;\n\t\tinfo->reg_type = PTR_TO_TP_BUFFER;\n\t}\n\treturn raw_tp_prog_is_valid_access(off, size, type, prog, info);\n}"
  },
  {
    "function_name": "bpf_prog_test_run_tracing",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1709-1714",
    "snippet": "int __weak bpf_prog_test_run_tracing(struct bpf_prog *prog,\n\t\t\t\t     const union bpf_attr *kattr,\n\t\t\t\t     union bpf_attr __user *uattr)\n{\n\treturn -ENOTSUPP;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nint __weak bpf_prog_test_run_tracing(struct bpf_prog *prog,\n\t\t\t\t     const union bpf_attr *kattr,\n\t\t\t\t     union bpf_attr __user *uattr)\n{\n\treturn -ENOTSUPP;\n}"
  },
  {
    "function_name": "tracing_prog_is_valid_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1701-1707",
    "snippet": "static bool tracing_prog_is_valid_access(int off, int size,\n\t\t\t\t\t enum bpf_access_type type,\n\t\t\t\t\t const struct bpf_prog *prog,\n\t\t\t\t\t struct bpf_insn_access_aux *info)\n{\n\treturn bpf_tracing_btf_ctx_access(off, size, type, prog, info);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_tracing_btf_ctx_access",
          "args": [
            "off",
            "size",
            "type",
            "prog",
            "info"
          ],
          "line": 1706
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool tracing_prog_is_valid_access(int off, int size,\n\t\t\t\t\t enum bpf_access_type type,\n\t\t\t\t\t const struct bpf_prog *prog,\n\t\t\t\t\t struct bpf_insn_access_aux *info)\n{\n\treturn bpf_tracing_btf_ctx_access(off, size, type, prog, info);\n}"
  },
  {
    "function_name": "raw_tp_prog_is_valid_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1693-1699",
    "snippet": "static bool raw_tp_prog_is_valid_access(int off, int size,\n\t\t\t\t\tenum bpf_access_type type,\n\t\t\t\t\tconst struct bpf_prog *prog,\n\t\t\t\t\tstruct bpf_insn_access_aux *info)\n{\n\treturn bpf_tracing_ctx_access(off, size, type);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_tracing_ctx_access",
          "args": [
            "off",
            "size",
            "type"
          ],
          "line": 1698
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool raw_tp_prog_is_valid_access(int off, int size,\n\t\t\t\t\tenum bpf_access_type type,\n\t\t\t\t\tconst struct bpf_prog *prog,\n\t\t\t\t\tstruct bpf_insn_access_aux *info)\n{\n\treturn bpf_tracing_ctx_access(off, size, type);\n}"
  },
  {
    "function_name": "tracing_prog_func_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1633-1691",
    "snippet": "const struct bpf_func_proto *\ntracing_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tconst struct bpf_func_proto *fn;\n\n\tswitch (func_id) {\n#ifdef CONFIG_NET\n\tcase BPF_FUNC_skb_output:\n\t\treturn &bpf_skb_output_proto;\n\tcase BPF_FUNC_xdp_output:\n\t\treturn &bpf_xdp_output_proto;\n\tcase BPF_FUNC_skc_to_tcp6_sock:\n\t\treturn &bpf_skc_to_tcp6_sock_proto;\n\tcase BPF_FUNC_skc_to_tcp_sock:\n\t\treturn &bpf_skc_to_tcp_sock_proto;\n\tcase BPF_FUNC_skc_to_tcp_timewait_sock:\n\t\treturn &bpf_skc_to_tcp_timewait_sock_proto;\n\tcase BPF_FUNC_skc_to_tcp_request_sock:\n\t\treturn &bpf_skc_to_tcp_request_sock_proto;\n\tcase BPF_FUNC_skc_to_udp6_sock:\n\t\treturn &bpf_skc_to_udp6_sock_proto;\n\tcase BPF_FUNC_skc_to_unix_sock:\n\t\treturn &bpf_skc_to_unix_sock_proto;\n\tcase BPF_FUNC_sk_storage_get:\n\t\treturn &bpf_sk_storage_get_tracing_proto;\n\tcase BPF_FUNC_sk_storage_delete:\n\t\treturn &bpf_sk_storage_delete_tracing_proto;\n\tcase BPF_FUNC_sock_from_file:\n\t\treturn &bpf_sock_from_file_proto;\n\tcase BPF_FUNC_get_socket_cookie:\n\t\treturn &bpf_get_socket_ptr_cookie_proto;\n#endif\n\tcase BPF_FUNC_seq_printf:\n\t\treturn prog->expected_attach_type == BPF_TRACE_ITER ?\n\t\t       &bpf_seq_printf_proto :\n\t\t       NULL;\n\tcase BPF_FUNC_seq_write:\n\t\treturn prog->expected_attach_type == BPF_TRACE_ITER ?\n\t\t       &bpf_seq_write_proto :\n\t\t       NULL;\n\tcase BPF_FUNC_seq_printf_btf:\n\t\treturn prog->expected_attach_type == BPF_TRACE_ITER ?\n\t\t       &bpf_seq_printf_btf_proto :\n\t\t       NULL;\n\tcase BPF_FUNC_d_path:\n\t\treturn &bpf_d_path_proto;\n\tcase BPF_FUNC_get_func_arg:\n\t\treturn bpf_prog_has_trampoline(prog) ? &bpf_get_func_arg_proto : NULL;\n\tcase BPF_FUNC_get_func_ret:\n\t\treturn bpf_prog_has_trampoline(prog) ? &bpf_get_func_ret_proto : NULL;\n\tcase BPF_FUNC_get_func_arg_cnt:\n\t\treturn bpf_prog_has_trampoline(prog) ? &bpf_get_func_arg_cnt_proto : NULL;\n\tdefault:\n\t\tfn = raw_tp_prog_func_proto(func_id, prog);\n\t\tif (!fn && prog->expected_attach_type == BPF_TRACE_ITER)\n\t\t\tfn = bpf_iter_get_func_proto(func_id, prog);\n\t\treturn fn;\n\t}\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_seq_printf_proto = {\n\t.func\t\t= bpf_seq_printf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_seq_file_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE,\n\t.arg4_type      = ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg5_type      = ARG_CONST_SIZE_OR_ZERO,\n};",
      "static const struct bpf_func_proto bpf_seq_write_proto = {\n\t.func\t\t= bpf_seq_write,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_seq_file_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
      "static const struct bpf_func_proto bpf_seq_printf_btf_proto = {\n\t.func\t\t= bpf_seq_printf_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_seq_file_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_d_path_proto = {\n\t.func\t\t= bpf_d_path,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &bpf_d_path_btf_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.allowed\t= bpf_d_path_allowed,\n};",
      "static const struct bpf_func_proto bpf_get_func_arg_proto = {\n\t.func\t\t= get_func_arg,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_LONG,\n};",
      "static const struct bpf_func_proto bpf_get_func_ret_proto = {\n\t.func\t\t= get_func_ret,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_LONG,\n};",
      "static const struct bpf_func_proto bpf_get_func_arg_cnt_proto = {\n\t.func\t\t= get_func_arg_cnt,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
      "extern const struct bpf_func_proto bpf_skb_output_proto;",
      "extern const struct bpf_func_proto bpf_xdp_output_proto;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_iter_get_func_proto",
          "args": [
            "func_id",
            "prog"
          ],
          "line": 1688
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_iter_get_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/bpf_iter.c",
          "lines": "363-383",
          "snippet": "const struct bpf_func_proto *\nbpf_iter_get_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tconst struct bpf_iter_target_info *tinfo;\n\tconst struct bpf_func_proto *fn = NULL;\n\n\tmutex_lock(&targets_mutex);\n\tlist_for_each_entry(tinfo, &targets, list) {\n\t\tif (tinfo->btf_id == prog->aux->attach_btf_id) {\n\t\t\tconst struct bpf_iter_reg *reg_info;\n\n\t\t\treg_info = tinfo->reg_info;\n\t\t\tif (reg_info->get_func_proto)\n\t\t\t\tfn = reg_info->get_func_proto(func_id, prog);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&targets_mutex);\n\n\treturn fn;\n}",
          "includes": [
            "#include <linux/bpf.h>",
            "#include <linux/filter.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct list_head targets = LIST_HEAD_INIT(targets);",
            "static DEFINE_MUTEX(targets_mutex);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf.h>\n#include <linux/filter.h>\n#include <linux/anon_inodes.h>\n#include <linux/fs.h>\n\nstatic struct list_head targets = LIST_HEAD_INIT(targets);\nstatic DEFINE_MUTEX(targets_mutex);\n\nconst struct bpf_func_proto *\nbpf_iter_get_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tconst struct bpf_iter_target_info *tinfo;\n\tconst struct bpf_func_proto *fn = NULL;\n\n\tmutex_lock(&targets_mutex);\n\tlist_for_each_entry(tinfo, &targets, list) {\n\t\tif (tinfo->btf_id == prog->aux->attach_btf_id) {\n\t\t\tconst struct bpf_iter_reg *reg_info;\n\n\t\t\treg_info = tinfo->reg_info;\n\t\t\tif (reg_info->get_func_proto)\n\t\t\t\tfn = reg_info->get_func_proto(func_id, prog);\n\t\t\tbreak;\n\t\t}\n\t}\n\tmutex_unlock(&targets_mutex);\n\n\treturn fn;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_tp_prog_func_proto",
          "args": [
            "func_id",
            "prog"
          ],
          "line": 1686
        },
        "resolved": true,
        "details": {
          "function_name": "raw_tp_prog_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "1618-1631",
          "snippet": "static const struct bpf_func_proto *\nraw_tp_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_raw_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_raw_tp;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_raw_tp;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static const struct bpf_func_proto bpf_perf_event_output_proto_raw_tp = {\n\t.func\t\t= bpf_perf_event_output_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
            "static const struct bpf_func_proto bpf_get_stackid_proto_raw_tp = {\n\t.func\t\t= bpf_get_stackid_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_get_stack_proto_raw_tp = {\n\t.func\t\t= bpf_get_stack_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_perf_event_output_proto_raw_tp = {\n\t.func\t\t= bpf_perf_event_output_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_get_stackid_proto_raw_tp = {\n\t.func\t\t= bpf_get_stackid_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_stack_proto_raw_tp = {\n\t.func\t\t= bpf_get_stack_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};\n\nstatic const struct bpf_func_proto *\nraw_tp_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_raw_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_raw_tp;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_raw_tp;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_has_trampoline",
          "args": [
            "prog"
          ],
          "line": 1684
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_has_trampoline",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/trampoline.c",
          "lines": "30-36",
          "snippet": "bool bpf_prog_has_trampoline(const struct bpf_prog *prog)\n{\n\tenum bpf_attach_type eatype = prog->expected_attach_type;\n\n\treturn eatype == BPF_TRACE_FENTRY || eatype == BPF_TRACE_FEXIT ||\n\t       eatype == BPF_MODIFY_RETURN;\n}",
          "includes": [
            "#include <linux/static_call.h>",
            "#include <linux/module.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/hash.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/static_call.h>\n#include <linux/module.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/rbtree_latch.h>\n#include <linux/ftrace.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/hash.h>\n\nbool bpf_prog_has_trampoline(const struct bpf_prog *prog)\n{\n\tenum bpf_attach_type eatype = prog->expected_attach_type;\n\n\treturn eatype == BPF_TRACE_FENTRY || eatype == BPF_TRACE_FEXIT ||\n\t       eatype == BPF_MODIFY_RETURN;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_seq_printf_proto = {\n\t.func\t\t= bpf_seq_printf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_seq_file_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE,\n\t.arg4_type      = ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg5_type      = ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_seq_write_proto = {\n\t.func\t\t= bpf_seq_write,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_seq_file_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_seq_printf_btf_proto = {\n\t.func\t\t= bpf_seq_printf_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_seq_file_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_d_path_proto = {\n\t.func\t\t= bpf_d_path,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &bpf_d_path_btf_ids[0],\n\t.arg2_type\t= ARG_PTR_TO_MEM,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.allowed\t= bpf_d_path_allowed,\n};\nstatic const struct bpf_func_proto bpf_get_func_arg_proto = {\n\t.func\t\t= get_func_arg,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_LONG,\n};\nstatic const struct bpf_func_proto bpf_get_func_ret_proto = {\n\t.func\t\t= get_func_ret,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_LONG,\n};\nstatic const struct bpf_func_proto bpf_get_func_arg_cnt_proto = {\n\t.func\t\t= get_func_arg_cnt,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nextern const struct bpf_func_proto bpf_skb_output_proto;\nextern const struct bpf_func_proto bpf_xdp_output_proto;\n\nconst struct bpf_func_proto *\ntracing_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tconst struct bpf_func_proto *fn;\n\n\tswitch (func_id) {\n#ifdef CONFIG_NET\n\tcase BPF_FUNC_skb_output:\n\t\treturn &bpf_skb_output_proto;\n\tcase BPF_FUNC_xdp_output:\n\t\treturn &bpf_xdp_output_proto;\n\tcase BPF_FUNC_skc_to_tcp6_sock:\n\t\treturn &bpf_skc_to_tcp6_sock_proto;\n\tcase BPF_FUNC_skc_to_tcp_sock:\n\t\treturn &bpf_skc_to_tcp_sock_proto;\n\tcase BPF_FUNC_skc_to_tcp_timewait_sock:\n\t\treturn &bpf_skc_to_tcp_timewait_sock_proto;\n\tcase BPF_FUNC_skc_to_tcp_request_sock:\n\t\treturn &bpf_skc_to_tcp_request_sock_proto;\n\tcase BPF_FUNC_skc_to_udp6_sock:\n\t\treturn &bpf_skc_to_udp6_sock_proto;\n\tcase BPF_FUNC_skc_to_unix_sock:\n\t\treturn &bpf_skc_to_unix_sock_proto;\n\tcase BPF_FUNC_sk_storage_get:\n\t\treturn &bpf_sk_storage_get_tracing_proto;\n\tcase BPF_FUNC_sk_storage_delete:\n\t\treturn &bpf_sk_storage_delete_tracing_proto;\n\tcase BPF_FUNC_sock_from_file:\n\t\treturn &bpf_sock_from_file_proto;\n\tcase BPF_FUNC_get_socket_cookie:\n\t\treturn &bpf_get_socket_ptr_cookie_proto;\n#endif\n\tcase BPF_FUNC_seq_printf:\n\t\treturn prog->expected_attach_type == BPF_TRACE_ITER ?\n\t\t       &bpf_seq_printf_proto :\n\t\t       NULL;\n\tcase BPF_FUNC_seq_write:\n\t\treturn prog->expected_attach_type == BPF_TRACE_ITER ?\n\t\t       &bpf_seq_write_proto :\n\t\t       NULL;\n\tcase BPF_FUNC_seq_printf_btf:\n\t\treturn prog->expected_attach_type == BPF_TRACE_ITER ?\n\t\t       &bpf_seq_printf_btf_proto :\n\t\t       NULL;\n\tcase BPF_FUNC_d_path:\n\t\treturn &bpf_d_path_proto;\n\tcase BPF_FUNC_get_func_arg:\n\t\treturn bpf_prog_has_trampoline(prog) ? &bpf_get_func_arg_proto : NULL;\n\tcase BPF_FUNC_get_func_ret:\n\t\treturn bpf_prog_has_trampoline(prog) ? &bpf_get_func_ret_proto : NULL;\n\tcase BPF_FUNC_get_func_arg_cnt:\n\t\treturn bpf_prog_has_trampoline(prog) ? &bpf_get_func_arg_cnt_proto : NULL;\n\tdefault:\n\t\tfn = raw_tp_prog_func_proto(func_id, prog);\n\t\tif (!fn && prog->expected_attach_type == BPF_TRACE_ITER)\n\t\t\tfn = bpf_iter_get_func_proto(func_id, prog);\n\t\treturn fn;\n\t}\n}"
  },
  {
    "function_name": "raw_tp_prog_func_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1618-1631",
    "snippet": "static const struct bpf_func_proto *\nraw_tp_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_raw_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_raw_tp;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_raw_tp;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_perf_event_output_proto_raw_tp = {\n\t.func\t\t= bpf_perf_event_output_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
      "static const struct bpf_func_proto bpf_get_stackid_proto_raw_tp = {\n\t.func\t\t= bpf_get_stackid_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_get_stack_proto_raw_tp = {\n\t.func\t\t= bpf_get_stack_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_tracing_func_proto",
          "args": [
            "func_id",
            "prog"
          ],
          "line": 1629
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_tracing_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "1141-1263",
          "snippet": "static const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "const struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};",
            "const struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};",
            "BTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};",
            "static const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
            "static const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nconst struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};\nconst struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\nBTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};\nstatic const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nstatic const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_perf_event_output_proto_raw_tp = {\n\t.func\t\t= bpf_perf_event_output_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_get_stackid_proto_raw_tp = {\n\t.func\t\t= bpf_get_stackid_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_stack_proto_raw_tp = {\n\t.func\t\t= bpf_get_stack_raw_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};\n\nstatic const struct bpf_func_proto *\nraw_tp_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_raw_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_raw_tp;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_raw_tp;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}"
  },
  {
    "function_name": "put_bpf_raw_tp_regs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1531-1534",
    "snippet": "static void put_bpf_raw_tp_regs(void)\n{\n\tthis_cpu_dec(bpf_raw_tp_nest_level);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(int, bpf_raw_tp_nest_level);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_dec",
          "args": [
            "bpf_raw_tp_nest_level"
          ],
          "line": 1533
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_PER_CPU(int, bpf_raw_tp_nest_level);\n\nstatic void put_bpf_raw_tp_regs(void)\n{\n\tthis_cpu_dec(bpf_raw_tp_nest_level);\n}"
  },
  {
    "function_name": "get_bpf_raw_tp_regs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1518-1529",
    "snippet": "static struct pt_regs *get_bpf_raw_tp_regs(void)\n{\n\tstruct bpf_raw_tp_regs *tp_regs = this_cpu_ptr(&bpf_raw_tp_regs);\n\tint nest_level = this_cpu_inc_return(bpf_raw_tp_nest_level);\n\n\tif (WARN_ON_ONCE(nest_level > ARRAY_SIZE(tp_regs->regs))) {\n\t\tthis_cpu_dec(bpf_raw_tp_nest_level);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\treturn &tp_regs->regs[nest_level - 1];\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct bpf_raw_tp_regs, bpf_raw_tp_regs);",
      "static DEFINE_PER_CPU(int, bpf_raw_tp_nest_level);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EBUSY"
          ],
          "line": 1525
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_dec",
          "args": [
            "bpf_raw_tp_nest_level"
          ],
          "line": 1524
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "nest_level > ARRAY_SIZE(tp_regs->regs)"
          ],
          "line": 1523
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ARRAY_SIZE",
          "args": [
            "tp_regs->regs"
          ],
          "line": 1523
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_inc_return",
          "args": [
            "bpf_raw_tp_nest_level"
          ],
          "line": 1521
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&bpf_raw_tp_regs"
          ],
          "line": 1520
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_PER_CPU(struct bpf_raw_tp_regs, bpf_raw_tp_regs);\nstatic DEFINE_PER_CPU(int, bpf_raw_tp_nest_level);\n\nstatic struct pt_regs *get_bpf_raw_tp_regs(void)\n{\n\tstruct bpf_raw_tp_regs *tp_regs = this_cpu_ptr(&bpf_raw_tp_regs);\n\tint nest_level = this_cpu_inc_return(bpf_raw_tp_nest_level);\n\n\tif (WARN_ON_ONCE(nest_level > ARRAY_SIZE(tp_regs->regs))) {\n\t\tthis_cpu_dec(bpf_raw_tp_nest_level);\n\t\treturn ERR_PTR(-EBUSY);\n\t}\n\n\treturn &tp_regs->regs[nest_level - 1];\n}"
  },
  {
    "function_name": "pe_prog_func_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1484-1503",
    "snippet": "static const struct bpf_func_proto *\npe_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_pe;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_pe;\n\tcase BPF_FUNC_perf_prog_read_value:\n\t\treturn &bpf_perf_prog_read_value_proto;\n\tcase BPF_FUNC_read_branch_records:\n\t\treturn &bpf_read_branch_records_proto;\n\tcase BPF_FUNC_get_attach_cookie:\n\t\treturn &bpf_get_attach_cookie_proto_pe;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_get_attach_cookie_proto_pe = {\n\t.func\t\t= bpf_get_attach_cookie_pe,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
      "static const struct bpf_func_proto bpf_perf_event_output_proto_tp = {\n\t.func\t\t= bpf_perf_event_output_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
      "static const struct bpf_func_proto bpf_perf_prog_read_value_proto = {\n         .func           = bpf_perf_prog_read_value,\n         .gpl_only       = true,\n         .ret_type       = RET_INTEGER,\n         .arg1_type      = ARG_PTR_TO_CTX,\n         .arg2_type      = ARG_PTR_TO_UNINIT_MEM,\n         .arg3_type      = ARG_CONST_SIZE,\n};",
      "static const struct bpf_func_proto bpf_read_branch_records_proto = {\n\t.func           = bpf_read_branch_records,\n\t.gpl_only       = true,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_PTR_TO_CTX,\n\t.arg2_type      = ARG_PTR_TO_MEM_OR_NULL,\n\t.arg3_type      = ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type      = ARG_ANYTHING,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_tracing_func_proto",
          "args": [
            "func_id",
            "prog"
          ],
          "line": 1501
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_tracing_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "1141-1263",
          "snippet": "static const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "const struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};",
            "const struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};",
            "BTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};",
            "static const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
            "static const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nconst struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};\nconst struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\nBTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};\nstatic const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nstatic const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_get_attach_cookie_proto_pe = {\n\t.func\t\t= bpf_get_attach_cookie_pe,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_perf_event_output_proto_tp = {\n\t.func\t\t= bpf_perf_event_output_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_perf_prog_read_value_proto = {\n         .func           = bpf_perf_prog_read_value,\n         .gpl_only       = true,\n         .ret_type       = RET_INTEGER,\n         .arg1_type      = ARG_PTR_TO_CTX,\n         .arg2_type      = ARG_PTR_TO_UNINIT_MEM,\n         .arg3_type      = ARG_CONST_SIZE,\n};\nstatic const struct bpf_func_proto bpf_read_branch_records_proto = {\n\t.func           = bpf_read_branch_records,\n\t.gpl_only       = true,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_PTR_TO_CTX,\n\t.arg2_type      = ARG_PTR_TO_MEM_OR_NULL,\n\t.arg3_type      = ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type      = ARG_ANYTHING,\n};\n\nstatic const struct bpf_func_proto *\npe_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_pe;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_pe;\n\tcase BPF_FUNC_perf_prog_read_value:\n\t\treturn &bpf_perf_prog_read_value_proto;\n\tcase BPF_FUNC_read_branch_records:\n\t\treturn &bpf_read_branch_records_proto;\n\tcase BPF_FUNC_get_attach_cookie:\n\t\treturn &bpf_get_attach_cookie_proto_pe;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}"
  },
  {
    "function_name": "tp_prog_is_valid_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1400-1413",
    "snippet": "static bool tp_prog_is_valid_access(int off, int size, enum bpf_access_type type,\n\t\t\t\t    const struct bpf_prog *prog,\n\t\t\t\t    struct bpf_insn_access_aux *info)\n{\n\tif (off < sizeof(void *) || off >= PERF_MAX_TRACE_SIZE)\n\t\treturn false;\n\tif (type != BPF_READ)\n\t\treturn false;\n\tif (off % size != 0)\n\t\treturn false;\n\n\tBUILD_BUG_ON(PERF_MAX_TRACE_SIZE % sizeof(__u64));\n\treturn true;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "PERF_MAX_TRACE_SIZE % sizeof(__u64)"
          ],
          "line": 1411
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool tp_prog_is_valid_access(int off, int size, enum bpf_access_type type,\n\t\t\t\t    const struct bpf_prog *prog,\n\t\t\t\t    struct bpf_insn_access_aux *info)\n{\n\tif (off < sizeof(void *) || off >= PERF_MAX_TRACE_SIZE)\n\t\treturn false;\n\tif (type != BPF_READ)\n\t\treturn false;\n\tif (off % size != 0)\n\t\treturn false;\n\n\tBUILD_BUG_ON(PERF_MAX_TRACE_SIZE % sizeof(__u64));\n\treturn true;\n}"
  },
  {
    "function_name": "tp_prog_func_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1383-1398",
    "snippet": "static const struct bpf_func_proto *\ntp_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_tp;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_tp;\n\tcase BPF_FUNC_get_attach_cookie:\n\t\treturn &bpf_get_attach_cookie_proto_trace;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_get_attach_cookie_proto_trace = {\n\t.func\t\t= bpf_get_attach_cookie_trace,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
      "static const struct bpf_func_proto bpf_perf_event_output_proto_tp = {\n\t.func\t\t= bpf_perf_event_output_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
      "static const struct bpf_func_proto bpf_get_stackid_proto_tp = {\n\t.func\t\t= bpf_get_stackid_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_get_stack_proto_tp = {\n\t.func\t\t= bpf_get_stack_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_tracing_func_proto",
          "args": [
            "func_id",
            "prog"
          ],
          "line": 1396
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_tracing_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "1141-1263",
          "snippet": "static const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "const struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};",
            "const struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};",
            "BTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};",
            "static const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
            "static const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nconst struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};\nconst struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\nBTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};\nstatic const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nstatic const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_get_attach_cookie_proto_trace = {\n\t.func\t\t= bpf_get_attach_cookie_trace,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_perf_event_output_proto_tp = {\n\t.func\t\t= bpf_perf_event_output_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_get_stackid_proto_tp = {\n\t.func\t\t= bpf_get_stackid_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_stack_proto_tp = {\n\t.func\t\t= bpf_get_stack_tp,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg3_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg4_type\t= ARG_ANYTHING,\n};\n\nstatic const struct bpf_func_proto *\ntp_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto_tp;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto_tp;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto_tp;\n\tcase BPF_FUNC_get_attach_cookie:\n\t\treturn &bpf_get_attach_cookie_proto_trace;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}"
  },
  {
    "function_name": "kprobe_prog_is_valid_access",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1289-1307",
    "snippet": "static bool kprobe_prog_is_valid_access(int off, int size, enum bpf_access_type type,\n\t\t\t\t\tconst struct bpf_prog *prog,\n\t\t\t\t\tstruct bpf_insn_access_aux *info)\n{\n\tif (off < 0 || off >= sizeof(struct pt_regs))\n\t\treturn false;\n\tif (type != BPF_READ)\n\t\treturn false;\n\tif (off % size != 0)\n\t\treturn false;\n\t/*\n\t * Assertion for 32 bit to make sure last 8 byte access\n\t * (BPF_DW) to the last 4 byte member is disallowed.\n\t */\n\tif (off + size > sizeof(struct pt_regs))\n\t\treturn false;\n\n\treturn true;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic bool kprobe_prog_is_valid_access(int off, int size, enum bpf_access_type type,\n\t\t\t\t\tconst struct bpf_prog *prog,\n\t\t\t\t\tstruct bpf_insn_access_aux *info)\n{\n\tif (off < 0 || off >= sizeof(struct pt_regs))\n\t\treturn false;\n\tif (type != BPF_READ)\n\t\treturn false;\n\tif (off % size != 0)\n\t\treturn false;\n\t/*\n\t * Assertion for 32 bit to make sure last 8 byte access\n\t * (BPF_DW) to the last 4 byte member is disallowed.\n\t */\n\tif (off + size > sizeof(struct pt_regs))\n\t\treturn false;\n\n\treturn true;\n}"
  },
  {
    "function_name": "kprobe_prog_func_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1265-1286",
    "snippet": "static const struct bpf_func_proto *\nkprobe_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto;\n#ifdef CONFIG_BPF_KPROBE_OVERRIDE\n\tcase BPF_FUNC_override_return:\n\t\treturn &bpf_override_return_proto;\n#endif\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_kprobe;\n\tcase BPF_FUNC_get_attach_cookie:\n\t\treturn &bpf_get_attach_cookie_proto_trace;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_perf_event_output_proto = {\n\t.func\t\t= bpf_perf_event_output,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
      "static const struct bpf_func_proto bpf_get_func_ip_proto_kprobe = {\n\t.func\t\t= bpf_get_func_ip_kprobe,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
      "static const struct bpf_func_proto bpf_get_attach_cookie_proto_trace = {\n\t.func\t\t= bpf_get_attach_cookie_trace,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_tracing_func_proto",
          "args": [
            "func_id",
            "prog"
          ],
          "line": 1284
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_tracing_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "1141-1263",
          "snippet": "static const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "const struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};",
            "const struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};",
            "BTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};",
            "static const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
            "static const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nconst struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};\nconst struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\nBTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};\nstatic const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nstatic const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_perf_event_output_proto = {\n\t.func\t\t= bpf_perf_event_output,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n\t.arg4_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_get_func_ip_proto_kprobe = {\n\t.func\t\t= bpf_get_func_ip_kprobe,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_get_attach_cookie_proto_trace = {\n\t.func\t\t= bpf_get_attach_cookie_trace,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\n\nstatic const struct bpf_func_proto *\nkprobe_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_perf_event_output:\n\t\treturn &bpf_perf_event_output_proto;\n\tcase BPF_FUNC_get_stackid:\n\t\treturn &bpf_get_stackid_proto;\n\tcase BPF_FUNC_get_stack:\n\t\treturn &bpf_get_stack_proto;\n#ifdef CONFIG_BPF_KPROBE_OVERRIDE\n\tcase BPF_FUNC_override_return:\n\t\treturn &bpf_override_return_proto;\n#endif\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_kprobe;\n\tcase BPF_FUNC_get_attach_cookie:\n\t\treturn &bpf_get_attach_cookie_proto_trace;\n\tdefault:\n\t\treturn bpf_tracing_func_proto(func_id, prog);\n\t}\n}"
  },
  {
    "function_name": "bpf_tracing_func_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "1141-1263",
    "snippet": "static const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "const struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
      "const struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
      "const struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
      "const struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};",
      "const struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};",
      "const struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};",
      "BTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};",
      "static const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};",
      "const struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};",
      "static const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};",
      "static const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_base_func_proto",
          "args": [
            "func_id"
          ],
          "line": 1261
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_base_func_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "1354-1459",
          "snippet": "const struct bpf_func_proto *\nbpf_base_func_proto(enum bpf_func_id func_id)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_raw_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_loop:\n\t\treturn &bpf_loop_proto;\n\tcase BPF_FUNC_strncmp:\n\t\treturn &bpf_strncmp_proto;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (!bpf_capable())\n\t\treturn NULL;\n\n\tswitch (func_id) {\n\tcase BPF_FUNC_spin_lock:\n\t\treturn &bpf_spin_lock_proto;\n\tcase BPF_FUNC_spin_unlock:\n\t\treturn &bpf_spin_unlock_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_timer_init:\n\t\treturn &bpf_timer_init_proto;\n\tcase BPF_FUNC_timer_set_callback:\n\t\treturn &bpf_timer_set_callback_proto;\n\tcase BPF_FUNC_timer_start:\n\t\treturn &bpf_timer_start_proto;\n\tcase BPF_FUNC_timer_cancel:\n\t\treturn &bpf_timer_cancel_proto;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (!perfmon_capable())\n\t\treturn NULL;\n\n\tswitch (func_id) {\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn NULL;\n\t}\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "const struct bpf_func_proto bpf_map_lookup_elem_proto = {\n\t.func\t\t= bpf_map_lookup_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_PTR_TO_MAP_VALUE_OR_NULL,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_KEY,\n};",
            "const struct bpf_func_proto bpf_map_update_elem_proto = {\n\t.func\t\t= bpf_map_update_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_KEY,\n\t.arg3_type\t= ARG_PTR_TO_MAP_VALUE,\n\t.arg4_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_map_delete_elem_proto = {\n\t.func\t\t= bpf_map_delete_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_KEY,\n};",
            "const struct bpf_func_proto bpf_map_push_elem_proto = {\n\t.func\t\t= bpf_map_push_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_VALUE,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_map_pop_elem_proto = {\n\t.func\t\t= bpf_map_pop_elem,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_UNINIT_MAP_VALUE,\n};",
            "const struct bpf_func_proto bpf_map_peek_elem_proto = {\n\t.func\t\t= bpf_map_peek_elem,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_UNINIT_MAP_VALUE,\n};",
            "const struct bpf_func_proto bpf_get_prandom_u32_proto = {\n\t.func\t\t= bpf_user_rnd_u32,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_get_numa_node_id_proto = {\n\t.func\t\t= bpf_get_numa_node_id,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_ktime_get_ns_proto = {\n\t.func\t\t= bpf_ktime_get_ns,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_ktime_get_boot_ns_proto = {\n\t.func\t\t= bpf_ktime_get_boot_ns,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_spin_lock_proto = {\n\t.func\t\t= bpf_spin_lock,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_VOID,\n\t.arg1_type\t= ARG_PTR_TO_SPIN_LOCK,\n};",
            "const struct bpf_func_proto bpf_spin_unlock_proto = {\n\t.func\t\t= bpf_spin_unlock,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_VOID,\n\t.arg1_type\t= ARG_PTR_TO_SPIN_LOCK,\n};",
            "const struct bpf_func_proto bpf_jiffies64_proto = {\n\t.func\t\t= bpf_jiffies64,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_strncmp_proto = {\n\t.func\t\t= bpf_strncmp,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_CONST_STR,\n};",
            "static const struct bpf_func_proto bpf_get_raw_smp_processor_id_proto = {\n\t.func\t\t= bpf_get_raw_cpu_id,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};",
            "const struct bpf_func_proto bpf_per_cpu_ptr_proto = {\n\t.func\t\t= bpf_per_cpu_ptr,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_PTR_TO_MEM_OR_BTF_ID | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg1_type\t= ARG_PTR_TO_PERCPU_BTF_ID,\n\t.arg2_type\t= ARG_ANYTHING,\n};",
            "const struct bpf_func_proto bpf_this_cpu_ptr_proto = {\n\t.func\t\t= bpf_this_cpu_ptr,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_PTR_TO_MEM_OR_BTF_ID | MEM_RDONLY,\n\t.arg1_type\t= ARG_PTR_TO_PERCPU_BTF_ID,\n};",
            "const struct bpf_func_proto bpf_snprintf_proto = {\n\t.func\t\t= bpf_snprintf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM_OR_NULL,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_PTR_TO_CONST_STR,\n\t.arg4_type\t= ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};",
            "static const struct bpf_func_proto bpf_timer_init_proto = {\n\t.func\t\t= bpf_timer_init,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_timer_set_callback_proto = {\n\t.func\t\t= bpf_timer_set_callback,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n\t.arg2_type\t= ARG_PTR_TO_FUNC,\n};",
            "static const struct bpf_func_proto bpf_timer_start_proto = {\n\t.func\t\t= bpf_timer_start,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_ANYTHING,\n};",
            "static const struct bpf_func_proto bpf_timer_cancel_proto = {\n\t.func\t\t= bpf_timer_cancel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nconst struct bpf_func_proto bpf_map_lookup_elem_proto = {\n\t.func\t\t= bpf_map_lookup_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_PTR_TO_MAP_VALUE_OR_NULL,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_KEY,\n};\nconst struct bpf_func_proto bpf_map_update_elem_proto = {\n\t.func\t\t= bpf_map_update_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_KEY,\n\t.arg3_type\t= ARG_PTR_TO_MAP_VALUE,\n\t.arg4_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_map_delete_elem_proto = {\n\t.func\t\t= bpf_map_delete_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_KEY,\n};\nconst struct bpf_func_proto bpf_map_push_elem_proto = {\n\t.func\t\t= bpf_map_push_elem,\n\t.gpl_only\t= false,\n\t.pkt_access\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_MAP_VALUE,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_map_pop_elem_proto = {\n\t.func\t\t= bpf_map_pop_elem,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_UNINIT_MAP_VALUE,\n};\nconst struct bpf_func_proto bpf_map_peek_elem_proto = {\n\t.func\t\t= bpf_map_peek_elem,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_PTR_TO_UNINIT_MAP_VALUE,\n};\nconst struct bpf_func_proto bpf_get_prandom_u32_proto = {\n\t.func\t\t= bpf_user_rnd_u32,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_get_numa_node_id_proto = {\n\t.func\t\t= bpf_get_numa_node_id,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_ktime_get_ns_proto = {\n\t.func\t\t= bpf_ktime_get_ns,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_ktime_get_boot_ns_proto = {\n\t.func\t\t= bpf_ktime_get_boot_ns,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_spin_lock_proto = {\n\t.func\t\t= bpf_spin_lock,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_VOID,\n\t.arg1_type\t= ARG_PTR_TO_SPIN_LOCK,\n};\nconst struct bpf_func_proto bpf_spin_unlock_proto = {\n\t.func\t\t= bpf_spin_unlock,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_VOID,\n\t.arg1_type\t= ARG_PTR_TO_SPIN_LOCK,\n};\nconst struct bpf_func_proto bpf_jiffies64_proto = {\n\t.func\t\t= bpf_jiffies64,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_strncmp_proto = {\n\t.func\t\t= bpf_strncmp,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_CONST_STR,\n};\nstatic const struct bpf_func_proto bpf_get_raw_smp_processor_id_proto = {\n\t.func\t\t= bpf_get_raw_cpu_id,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_per_cpu_ptr_proto = {\n\t.func\t\t= bpf_per_cpu_ptr,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_PTR_TO_MEM_OR_BTF_ID | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg1_type\t= ARG_PTR_TO_PERCPU_BTF_ID,\n\t.arg2_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_this_cpu_ptr_proto = {\n\t.func\t\t= bpf_this_cpu_ptr,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_PTR_TO_MEM_OR_BTF_ID | MEM_RDONLY,\n\t.arg1_type\t= ARG_PTR_TO_PERCPU_BTF_ID,\n};\nconst struct bpf_func_proto bpf_snprintf_proto = {\n\t.func\t\t= bpf_snprintf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM_OR_NULL,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_PTR_TO_CONST_STR,\n\t.arg4_type\t= ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg5_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\nstatic const struct bpf_func_proto bpf_timer_init_proto = {\n\t.func\t\t= bpf_timer_init,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n\t.arg2_type\t= ARG_CONST_MAP_PTR,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_timer_set_callback_proto = {\n\t.func\t\t= bpf_timer_set_callback,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n\t.arg2_type\t= ARG_PTR_TO_FUNC,\n};\nstatic const struct bpf_func_proto bpf_timer_start_proto = {\n\t.func\t\t= bpf_timer_start,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_timer_cancel_proto = {\n\t.func\t\t= bpf_timer_cancel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_TIMER,\n};\n\nconst struct bpf_func_proto *\nbpf_base_func_proto(enum bpf_func_id func_id)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_raw_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_loop:\n\t\treturn &bpf_loop_proto;\n\tcase BPF_FUNC_strncmp:\n\t\treturn &bpf_strncmp_proto;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (!bpf_capable())\n\t\treturn NULL;\n\n\tswitch (func_id) {\n\tcase BPF_FUNC_spin_lock:\n\t\treturn &bpf_spin_lock_proto;\n\tcase BPF_FUNC_spin_unlock:\n\t\treturn &bpf_spin_unlock_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_timer_init:\n\t\treturn &bpf_timer_init_proto;\n\tcase BPF_FUNC_timer_set_callback:\n\t\treturn &bpf_timer_set_callback_proto;\n\tcase BPF_FUNC_timer_start:\n\t\treturn &bpf_timer_start_proto;\n\tcase BPF_FUNC_timer_cancel:\n\t\treturn &bpf_timer_cancel_proto;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tif (!perfmon_capable())\n\t\treturn NULL;\n\n\tswitch (func_id) {\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn NULL;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_get_trace_vprintk_proto",
          "args": [],
          "line": 1259
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_trace_vprintk_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "459-463",
          "snippet": "const struct bpf_func_proto *bpf_get_trace_vprintk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_vprintk_proto;\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static const struct bpf_func_proto bpf_trace_vprintk_proto = {\n\t.func\t\t= bpf_trace_vprintk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_trace_vprintk_proto = {\n\t.func\t\t= bpf_trace_vprintk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nconst struct bpf_func_proto *bpf_get_trace_vprintk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_vprintk_proto;\n}"
        }
      },
      {
        "call_info": {
          "callee": "security_locked_down",
          "args": [
            "LOCKDOWN_BPF_READ_KERNEL"
          ],
          "line": 1205
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "security_locked_down",
          "args": [
            "LOCKDOWN_BPF_READ_KERNEL"
          ],
          "line": 1202
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "security_locked_down",
          "args": [
            "LOCKDOWN_BPF_READ_KERNEL"
          ],
          "line": 1198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "security_locked_down",
          "args": [
            "LOCKDOWN_BPF_READ_KERNEL"
          ],
          "line": 1193
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_get_probe_write_proto",
          "args": [],
          "line": 1189
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_probe_write_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "352-361",
          "snippet": "static const struct bpf_func_proto *bpf_get_probe_write_proto(void)\n{\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn NULL;\n\n\tpr_warn_ratelimited(\"%s[%d] is installing a program with bpf_probe_write_user helper that may corrupt user memory!\",\n\t\t\t    current->comm, task_pid_nr(current));\n\n\treturn &bpf_probe_write_user_proto;\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static const struct bpf_func_proto bpf_probe_write_user_proto = {\n\t.func\t\t= bpf_probe_write_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_probe_write_user_proto = {\n\t.func\t\t= bpf_probe_write_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE,\n};\n\nstatic const struct bpf_func_proto *bpf_get_probe_write_proto(void)\n{\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn NULL;\n\n\tpr_warn_ratelimited(\"%s[%d] is installing a program with bpf_probe_write_user helper that may corrupt user memory!\",\n\t\t\t    current->comm, task_pid_nr(current));\n\n\treturn &bpf_probe_write_user_proto;\n}"
        }
      },
      {
        "call_info": {
          "callee": "security_locked_down",
          "args": [
            "LOCKDOWN_BPF_WRITE_USER"
          ],
          "line": 1188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_get_trace_printk_proto",
          "args": [],
          "line": 1176
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_trace_printk_proto",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "415-419",
          "snippet": "const struct bpf_func_proto *bpf_get_trace_printk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_printk_proto;\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static const struct bpf_func_proto bpf_trace_printk_proto = {\n\t.func\t\t= bpf_trace_printk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_trace_printk_proto = {\n\t.func\t\t= bpf_trace_printk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n};\n\nconst struct bpf_func_proto *bpf_get_trace_printk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_printk_proto;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nconst struct bpf_func_proto bpf_probe_read_user_proto = {\n\t.func\t\t= bpf_probe_read_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_user_str_proto = {\n\t.func\t\t= bpf_probe_read_user_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_proto = {\n\t.func\t\t= bpf_probe_read_kernel,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_probe_read_kernel_str_proto = {\n\t.func\t\t= bpf_probe_read_kernel_str,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n\t.arg3_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_proto = {\n\t.func\t\t= bpf_perf_event_read,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_perf_event_read_value_proto = {\n\t.func\t\t= bpf_perf_event_read_value,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_CONST_MAP_PTR,\n\t.arg2_type\t= ARG_ANYTHING,\n\t.arg3_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg4_type\t= ARG_CONST_SIZE,\n};\nconst struct bpf_func_proto bpf_get_current_task_proto = {\n\t.func\t\t= bpf_get_current_task,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n};\nconst struct bpf_func_proto bpf_get_current_task_btf_proto = {\n\t.func\t\t= bpf_get_current_task_btf,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n};\nBTF_ID_LIST(bpf_task_pt_regs_ids)\nBTF_ID(struct, pt_regs)\n\nconst struct bpf_func_proto bpf_task_pt_regs_proto = {\n\t.func\t\t= bpf_task_pt_regs,\n\t.gpl_only\t= true,\n\t.arg1_type\t= ARG_PTR_TO_BTF_ID,\n\t.arg1_btf_id\t= &btf_tracing_ids[BTF_TRACING_TYPE_TASK],\n\t.ret_type\t= RET_PTR_TO_BTF_ID,\n\t.ret_btf_id\t= &bpf_task_pt_regs_ids[0],\n};\nstatic const struct bpf_func_proto bpf_current_task_under_cgroup_proto = {\n\t.func           = bpf_current_task_under_cgroup,\n\t.gpl_only       = false,\n\t.ret_type       = RET_INTEGER,\n\t.arg1_type      = ARG_CONST_MAP_PTR,\n\t.arg2_type      = ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_proto = {\n\t.func\t\t= bpf_send_signal,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_send_signal_thread_proto = {\n\t.func\t\t= bpf_send_signal_thread,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n};\nconst struct bpf_func_proto bpf_snprintf_btf_proto = {\n\t.func\t\t= bpf_snprintf_btf,\n\t.gpl_only\t= false,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE,\n\t.arg5_type\t= ARG_ANYTHING,\n};\nstatic const struct bpf_func_proto bpf_get_func_ip_proto_tracing = {\n\t.func\t\t= bpf_get_func_ip_tracing,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_CTX,\n};\nstatic const struct bpf_func_proto bpf_get_branch_snapshot_proto = {\n\t.func\t\t= bpf_get_branch_snapshot,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_UNINIT_MEM,\n\t.arg2_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nstatic const struct bpf_func_proto *\nbpf_tracing_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)\n{\n\tswitch (func_id) {\n\tcase BPF_FUNC_map_lookup_elem:\n\t\treturn &bpf_map_lookup_elem_proto;\n\tcase BPF_FUNC_map_update_elem:\n\t\treturn &bpf_map_update_elem_proto;\n\tcase BPF_FUNC_map_delete_elem:\n\t\treturn &bpf_map_delete_elem_proto;\n\tcase BPF_FUNC_map_push_elem:\n\t\treturn &bpf_map_push_elem_proto;\n\tcase BPF_FUNC_map_pop_elem:\n\t\treturn &bpf_map_pop_elem_proto;\n\tcase BPF_FUNC_map_peek_elem:\n\t\treturn &bpf_map_peek_elem_proto;\n\tcase BPF_FUNC_ktime_get_ns:\n\t\treturn &bpf_ktime_get_ns_proto;\n\tcase BPF_FUNC_ktime_get_boot_ns:\n\t\treturn &bpf_ktime_get_boot_ns_proto;\n\tcase BPF_FUNC_tail_call:\n\t\treturn &bpf_tail_call_proto;\n\tcase BPF_FUNC_get_current_pid_tgid:\n\t\treturn &bpf_get_current_pid_tgid_proto;\n\tcase BPF_FUNC_get_current_task:\n\t\treturn &bpf_get_current_task_proto;\n\tcase BPF_FUNC_get_current_task_btf:\n\t\treturn &bpf_get_current_task_btf_proto;\n\tcase BPF_FUNC_task_pt_regs:\n\t\treturn &bpf_task_pt_regs_proto;\n\tcase BPF_FUNC_get_current_uid_gid:\n\t\treturn &bpf_get_current_uid_gid_proto;\n\tcase BPF_FUNC_get_current_comm:\n\t\treturn &bpf_get_current_comm_proto;\n\tcase BPF_FUNC_trace_printk:\n\t\treturn bpf_get_trace_printk_proto();\n\tcase BPF_FUNC_get_smp_processor_id:\n\t\treturn &bpf_get_smp_processor_id_proto;\n\tcase BPF_FUNC_get_numa_node_id:\n\t\treturn &bpf_get_numa_node_id_proto;\n\tcase BPF_FUNC_perf_event_read:\n\t\treturn &bpf_perf_event_read_proto;\n\tcase BPF_FUNC_current_task_under_cgroup:\n\t\treturn &bpf_current_task_under_cgroup_proto;\n\tcase BPF_FUNC_get_prandom_u32:\n\t\treturn &bpf_get_prandom_u32_proto;\n\tcase BPF_FUNC_probe_write_user:\n\t\treturn security_locked_down(LOCKDOWN_BPF_WRITE_USER) < 0 ?\n\t\t       NULL : bpf_get_probe_write_proto();\n\tcase BPF_FUNC_probe_read_user:\n\t\treturn &bpf_probe_read_user_proto;\n\tcase BPF_FUNC_probe_read_kernel:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_proto;\n\tcase BPF_FUNC_probe_read_user_str:\n\t\treturn &bpf_probe_read_user_str_proto;\n\tcase BPF_FUNC_probe_read_kernel_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_kernel_str_proto;\n#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE\n\tcase BPF_FUNC_probe_read:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_proto;\n\tcase BPF_FUNC_probe_read_str:\n\t\treturn security_locked_down(LOCKDOWN_BPF_READ_KERNEL) < 0 ?\n\t\t       NULL : &bpf_probe_read_compat_str_proto;\n#endif\n#ifdef CONFIG_CGROUPS\n\tcase BPF_FUNC_get_current_cgroup_id:\n\t\treturn &bpf_get_current_cgroup_id_proto;\n\tcase BPF_FUNC_get_current_ancestor_cgroup_id:\n\t\treturn &bpf_get_current_ancestor_cgroup_id_proto;\n#endif\n\tcase BPF_FUNC_send_signal:\n\t\treturn &bpf_send_signal_proto;\n\tcase BPF_FUNC_send_signal_thread:\n\t\treturn &bpf_send_signal_thread_proto;\n\tcase BPF_FUNC_perf_event_read_value:\n\t\treturn &bpf_perf_event_read_value_proto;\n\tcase BPF_FUNC_get_ns_current_pid_tgid:\n\t\treturn &bpf_get_ns_current_pid_tgid_proto;\n\tcase BPF_FUNC_ringbuf_output:\n\t\treturn &bpf_ringbuf_output_proto;\n\tcase BPF_FUNC_ringbuf_reserve:\n\t\treturn &bpf_ringbuf_reserve_proto;\n\tcase BPF_FUNC_ringbuf_submit:\n\t\treturn &bpf_ringbuf_submit_proto;\n\tcase BPF_FUNC_ringbuf_discard:\n\t\treturn &bpf_ringbuf_discard_proto;\n\tcase BPF_FUNC_ringbuf_query:\n\t\treturn &bpf_ringbuf_query_proto;\n\tcase BPF_FUNC_jiffies64:\n\t\treturn &bpf_jiffies64_proto;\n\tcase BPF_FUNC_get_task_stack:\n\t\treturn &bpf_get_task_stack_proto;\n\tcase BPF_FUNC_copy_from_user:\n\t\treturn prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;\n\tcase BPF_FUNC_snprintf_btf:\n\t\treturn &bpf_snprintf_btf_proto;\n\tcase BPF_FUNC_per_cpu_ptr:\n\t\treturn &bpf_per_cpu_ptr_proto;\n\tcase BPF_FUNC_this_cpu_ptr:\n\t\treturn &bpf_this_cpu_ptr_proto;\n\tcase BPF_FUNC_task_storage_get:\n\t\treturn &bpf_task_storage_get_proto;\n\tcase BPF_FUNC_task_storage_delete:\n\t\treturn &bpf_task_storage_delete_proto;\n\tcase BPF_FUNC_for_each_map_elem:\n\t\treturn &bpf_for_each_map_elem_proto;\n\tcase BPF_FUNC_snprintf:\n\t\treturn &bpf_snprintf_proto;\n\tcase BPF_FUNC_get_func_ip:\n\t\treturn &bpf_get_func_ip_proto_tracing;\n\tcase BPF_FUNC_get_branch_snapshot:\n\t\treturn &bpf_get_branch_snapshot_proto;\n\tcase BPF_FUNC_find_vma:\n\t\treturn &bpf_find_vma_proto;\n\tcase BPF_FUNC_trace_vprintk:\n\t\treturn bpf_get_trace_vprintk_proto();\n\tdefault:\n\t\treturn bpf_base_func_proto(func_id);\n\t}\n}"
  },
  {
    "function_name": "bpf_btf_printf_prepare",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "956-984",
    "snippet": "static int bpf_btf_printf_prepare(struct btf_ptr *ptr, u32 btf_ptr_size,\n\t\t\t\t  u64 flags, const struct btf **btf,\n\t\t\t\t  s32 *btf_id)\n{\n\tconst struct btf_type *t;\n\n\tif (unlikely(flags & ~(BTF_F_ALL)))\n\t\treturn -EINVAL;\n\n\tif (btf_ptr_size != sizeof(struct btf_ptr))\n\t\treturn -EINVAL;\n\n\t*btf = bpf_get_btf_vmlinux();\n\n\tif (IS_ERR_OR_NULL(*btf))\n\t\treturn IS_ERR(*btf) ? PTR_ERR(*btf) : -EINVAL;\n\n\tif (ptr->type_id > 0)\n\t\t*btf_id = ptr->type_id;\n\telse\n\t\treturn -EINVAL;\n\n\tif (*btf_id > 0)\n\t\tt = btf_type_by_id(*btf, *btf_id);\n\tif (*btf_id <= 0 || !t)\n\t\treturn -ENOENT;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [
      "#define BTF_F_ALL\t(BTF_F_COMPACT  | BTF_F_NONAME | \\\n\t\t\t BTF_F_PTR_RAW | BTF_F_ZERO)"
    ],
    "globals_used": [
      "static int bpf_btf_printf_prepare(struct btf_ptr *ptr, u32 btf_ptr_size,\n\t\t\t\t  u64 flags, const struct btf **btf,\n\t\t\t\t  s32 *btf_id);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "btf_type_by_id",
          "args": [
            "*btf",
            "*btf_id"
          ],
          "line": 979
        },
        "resolved": true,
        "details": {
          "function_name": "btf_type_by_id",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/btf.c",
          "lines": "731-740",
          "snippet": "const struct btf_type *btf_type_by_id(const struct btf *btf, u32 type_id)\n{\n\twhile (type_id < btf->start_id)\n\t\tbtf = btf->base_btf;\n\n\ttype_id -= btf->start_id;\n\tif (type_id >= btf->nr_types)\n\t\treturn NULL;\n\treturn btf->types[type_id];\n}",
          "includes": [
            "#include <linux/bpf_types.h>",
            "#include \"../tools/lib/bpf/relo_core.h\"",
            "#include <net/sock.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/kobject.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/skmsg.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/sort.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/file.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/slab.h>",
            "#include <linux/errno.h>",
            "#include <linux/ctype.h>",
            "#include <linux/compiler.h>",
            "#include <linux/seq_file.h>",
            "#include <uapi/linux/types.h>",
            "#include <uapi/linux/bpf_perf_event.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_types.h>\n#include \"../tools/lib/bpf/relo_core.h\"\n#include <net/sock.h>\n#include <linux/sysfs.h>\n#include <linux/kobject.h>\n#include <linux/bsearch.h>\n#include <linux/perf_event.h>\n#include <linux/skmsg.h>\n#include <linux/btf_ids.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/sort.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/uaccess.h>\n#include <linux/file.h>\n#include <linux/anon_inodes.h>\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/ctype.h>\n#include <linux/compiler.h>\n#include <linux/seq_file.h>\n#include <uapi/linux/types.h>\n#include <uapi/linux/bpf_perf_event.h>\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/btf.h>\n\nstatic int btf_resolve(struct btf_verifier_env *env,\n\t\t       const struct btf_type *t, u32 type_id);\n\nconst struct btf_type *btf_type_by_id(const struct btf *btf, u32 type_id)\n{\n\twhile (type_id < btf->start_id)\n\t\tbtf = btf->base_btf;\n\n\ttype_id -= btf->start_id;\n\tif (type_id >= btf->nr_types)\n\t\treturn NULL;\n\treturn btf->types[type_id];\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "*btf"
          ],
          "line": 971
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "*btf"
          ],
          "line": 971
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR_OR_NULL",
          "args": [
            "*btf"
          ],
          "line": 970
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_get_btf_vmlinux",
          "args": [],
          "line": 968
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_get_btf_vmlinux",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "14201-14210",
          "snippet": "struct btf *bpf_get_btf_vmlinux(void)\n{\n\tif (!btf_vmlinux && IS_ENABLED(CONFIG_DEBUG_INFO_BTF)) {\n\t\tmutex_lock(&bpf_verifier_lock);\n\t\tif (!btf_vmlinux)\n\t\t\tbtf_vmlinux = btf_parse_vmlinux();\n\t\tmutex_unlock(&bpf_verifier_lock);\n\t}\n\treturn btf_vmlinux;\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "struct btf *btf_vmlinux;",
            "static DEFINE_MUTEX(bpf_verifier_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstruct btf *btf_vmlinux;\nstatic DEFINE_MUTEX(bpf_verifier_lock);\n\nstruct btf *bpf_get_btf_vmlinux(void)\n{\n\tif (!btf_vmlinux && IS_ENABLED(CONFIG_DEBUG_INFO_BTF)) {\n\t\tmutex_lock(&bpf_verifier_lock);\n\t\tif (!btf_vmlinux)\n\t\t\tbtf_vmlinux = btf_parse_vmlinux();\n\t\tmutex_unlock(&bpf_verifier_lock);\n\t}\n\treturn btf_vmlinux;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "flags & ~(BTF_F_ALL)"
          ],
          "line": 962
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\n#define BTF_F_ALL\t(BTF_F_COMPACT  | BTF_F_NONAME | \\\n\t\t\t BTF_F_PTR_RAW | BTF_F_ZERO)\n\nstatic int bpf_btf_printf_prepare(struct btf_ptr *ptr, u32 btf_ptr_size,\n\t\t\t\t  u64 flags, const struct btf **btf,\n\t\t\t\t  s32 *btf_id);\n\nstatic int bpf_btf_printf_prepare(struct btf_ptr *ptr, u32 btf_ptr_size,\n\t\t\t\t  u64 flags, const struct btf **btf,\n\t\t\t\t  s32 *btf_id)\n{\n\tconst struct btf_type *t;\n\n\tif (unlikely(flags & ~(BTF_F_ALL)))\n\t\treturn -EINVAL;\n\n\tif (btf_ptr_size != sizeof(struct btf_ptr))\n\t\treturn -EINVAL;\n\n\t*btf = bpf_get_btf_vmlinux();\n\n\tif (IS_ERR_OR_NULL(*btf))\n\t\treturn IS_ERR(*btf) ? PTR_ERR(*btf) : -EINVAL;\n\n\tif (ptr->type_id > 0)\n\t\t*btf_id = ptr->type_id;\n\telse\n\t\treturn -EINVAL;\n\n\tif (*btf_id > 0)\n\t\tt = btf_type_by_id(*btf, *btf_id);\n\tif (*btf_id <= 0 || !t)\n\t\treturn -ENOENT;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_d_path_allowed",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "925-938",
    "snippet": "BTF_SET_END(btf_allowlist_d_path)\n\nstatic bool bpf_d_path_allowed(const struct bpf_prog *prog)\n{\n\tif (prog->type == BPF_PROG_TYPE_TRACING &&\n\t    prog->expected_attach_type == BPF_TRACE_ITER)\n\t\treturn true;\n\n\tif (prog->type == BPF_PROG_TYPE_LSM)\n\t\treturn bpf_lsm_is_sleepable_hook(prog->aux->attach_btf_id);\n\n\treturn btf_id_set_contains(&btf_allowlist_d_path,\n\t\t\t\t   prog->aux->attach_btf_id);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "btf_id_set_contains",
          "args": [
            "&btf_allowlist_d_path",
            "prog->aux->attach_btf_id"
          ],
          "line": 936
        },
        "resolved": true,
        "details": {
          "function_name": "btf_id_set_contains",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/btf.c",
          "lines": "6198-6201",
          "snippet": "bool btf_id_set_contains(const struct btf_id_set *set, u32 id)\n{\n\treturn bsearch(&id, set->ids, set->cnt, sizeof(u32), btf_id_cmp_func) != NULL;\n}",
          "includes": [
            "#include <linux/bpf_types.h>",
            "#include \"../tools/lib/bpf/relo_core.h\"",
            "#include <net/sock.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/kobject.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/skmsg.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/sort.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/file.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/slab.h>",
            "#include <linux/errno.h>",
            "#include <linux/ctype.h>",
            "#include <linux/compiler.h>",
            "#include <linux/seq_file.h>",
            "#include <uapi/linux/types.h>",
            "#include <uapi/linux/bpf_perf_event.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_types.h>\n#include \"../tools/lib/bpf/relo_core.h\"\n#include <net/sock.h>\n#include <linux/sysfs.h>\n#include <linux/kobject.h>\n#include <linux/bsearch.h>\n#include <linux/perf_event.h>\n#include <linux/skmsg.h>\n#include <linux/btf_ids.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/sort.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/uaccess.h>\n#include <linux/file.h>\n#include <linux/anon_inodes.h>\n#include <linux/slab.h>\n#include <linux/errno.h>\n#include <linux/ctype.h>\n#include <linux/compiler.h>\n#include <linux/seq_file.h>\n#include <uapi/linux/types.h>\n#include <uapi/linux/bpf_perf_event.h>\n#include <uapi/linux/bpf.h>\n#include <uapi/linux/btf.h>\n\nbool btf_id_set_contains(const struct btf_id_set *set, u32 id)\n{\n\treturn bsearch(&id, set->ids, set->cnt, sizeof(u32), btf_id_cmp_func) != NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_lsm_is_sleepable_hook",
          "args": [
            "prog->aux->attach_btf_id"
          ],
          "line": 934
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nBTF_SET_END(btf_allowlist_d_path)\n\nstatic bool bpf_d_path_allowed(const struct bpf_prog *prog)\n{\n\tif (prog->type == BPF_PROG_TYPE_TRACING &&\n\t    prog->expected_attach_type == BPF_TRACE_ITER)\n\t\treturn true;\n\n\tif (prog->type == BPF_PROG_TYPE_LSM)\n\t\treturn bpf_lsm_is_sleepable_hook(prog->aux->attach_btf_id);\n\n\treturn btf_id_set_contains(&btf_allowlist_d_path,\n\t\t\t\t   prog->aux->attach_btf_id);\n}"
  },
  {
    "function_name": "bpf_send_signal_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "827-866",
    "snippet": "static int bpf_send_signal_common(u32 sig, enum pid_type type)\n{\n\tstruct send_signal_irq_work *work = NULL;\n\n\t/* Similar to bpf_probe_write_user, task needs to be\n\t * in a sound condition and kernel memory access be\n\t * permitted in order to send signal to the current\n\t * task.\n\t */\n\tif (unlikely(current->flags & (PF_KTHREAD | PF_EXITING)))\n\t\treturn -EPERM;\n\tif (unlikely(uaccess_kernel()))\n\t\treturn -EPERM;\n\tif (unlikely(!nmi_uaccess_okay()))\n\t\treturn -EPERM;\n\n\tif (irqs_disabled()) {\n\t\t/* Do an early check on signal validity. Otherwise,\n\t\t * the error is lost in deferred irq_work.\n\t\t */\n\t\tif (unlikely(!valid_signal(sig)))\n\t\t\treturn -EINVAL;\n\n\t\twork = this_cpu_ptr(&send_signal_work);\n\t\tif (irq_work_is_busy(&work->irq_work))\n\t\t\treturn -EBUSY;\n\n\t\t/* Add the current task, which is the target of sending signal,\n\t\t * to the irq_work. The current task may change when queued\n\t\t * irq works get executed.\n\t\t */\n\t\twork->task = current;\n\t\twork->sig = sig;\n\t\twork->type = type;\n\t\tirq_work_queue(&work->irq_work);\n\t\treturn 0;\n\t}\n\n\treturn group_send_sig_info(sig, SEND_SIG_PRIV, current, type);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct send_signal_irq_work, send_signal_work);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "group_send_sig_info",
          "args": [
            "sig",
            "SEND_SIG_PRIV",
            "current",
            "type"
          ],
          "line": 865
        },
        "resolved": true,
        "details": {
          "function_name": "group_send_sig_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/signal.c",
          "lines": "1434-1447",
          "snippet": "int group_send_sig_info(int sig, struct kernel_siginfo *info,\n\t\t\tstruct task_struct *p, enum pid_type type)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tret = check_kill_permission(sig, info, p);\n\trcu_read_unlock();\n\n\tif (!ret && sig)\n\t\tret = do_send_sig_info(sig, info, p, type);\n\n\treturn ret;\n}",
          "includes": [
            "#include <linux/kdb.h>",
            "#include <asm/syscall.h>\t/* for syscall_get_* */",
            "#include <asm/cacheflush.h>",
            "#include <asm/siginfo.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/param.h>",
            "#include <trace/events/signal.h>",
            "#include <linux/audit.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/compiler.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/compat.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/capability.h>",
            "#include <linux/task_work.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/signal.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/coredump.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/tty.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kdb.h>\n#include <asm/syscall.h>\t/* for syscall_get_* */\n#include <asm/cacheflush.h>\n#include <asm/siginfo.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <asm/param.h>\n#include <trace/events/signal.h>\n#include <linux/audit.h>\n#include <linux/cgroup.h>\n#include <linux/posix-timers.h>\n#include <linux/compiler.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/uprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/pid_namespace.h>\n#include <linux/freezer.h>\n#include <linux/capability.h>\n#include <linux/task_work.h>\n#include <linux/ratelimit.h>\n#include <linux/signalfd.h>\n#include <linux/signal.h>\n#include <linux/ptrace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/coredump.h>\n#include <linux/binfmts.h>\n#include <linux/tty.h>\n#include <linux/proc_fs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/user.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\nint group_send_sig_info(int sig, struct kernel_siginfo *info,\n\t\t\tstruct task_struct *p, enum pid_type type)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tret = check_kill_permission(sig, info, p);\n\trcu_read_unlock();\n\n\tif (!ret && sig)\n\t\tret = do_send_sig_info(sig, info, p, type);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_work_queue",
          "args": [
            "&work->irq_work"
          ],
          "line": 861
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "106-118",
          "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_work_is_busy",
          "args": [
            "&work->irq_work"
          ],
          "line": 851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&send_signal_work"
          ],
          "line": 850
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!valid_signal(sig)"
          ],
          "line": 847
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "valid_signal",
          "args": [
            "sig"
          ],
          "line": 847
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqs_disabled",
          "args": [],
          "line": 843
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!nmi_uaccess_okay()"
          ],
          "line": 840
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "nmi_uaccess_okay",
          "args": [],
          "line": 840
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "uaccess_kernel()"
          ],
          "line": 838
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "uaccess_kernel",
          "args": [],
          "line": 838
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "current->flags & (PF_KTHREAD | PF_EXITING)"
          ],
          "line": 836
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_PER_CPU(struct send_signal_irq_work, send_signal_work);\n\nstatic int bpf_send_signal_common(u32 sig, enum pid_type type)\n{\n\tstruct send_signal_irq_work *work = NULL;\n\n\t/* Similar to bpf_probe_write_user, task needs to be\n\t * in a sound condition and kernel memory access be\n\t * permitted in order to send signal to the current\n\t * task.\n\t */\n\tif (unlikely(current->flags & (PF_KTHREAD | PF_EXITING)))\n\t\treturn -EPERM;\n\tif (unlikely(uaccess_kernel()))\n\t\treturn -EPERM;\n\tif (unlikely(!nmi_uaccess_okay()))\n\t\treturn -EPERM;\n\n\tif (irqs_disabled()) {\n\t\t/* Do an early check on signal validity. Otherwise,\n\t\t * the error is lost in deferred irq_work.\n\t\t */\n\t\tif (unlikely(!valid_signal(sig)))\n\t\t\treturn -EINVAL;\n\n\t\twork = this_cpu_ptr(&send_signal_work);\n\t\tif (irq_work_is_busy(&work->irq_work))\n\t\t\treturn -EBUSY;\n\n\t\t/* Add the current task, which is the target of sending signal,\n\t\t * to the irq_work. The current task may change when queued\n\t\t * irq works get executed.\n\t\t */\n\t\twork->task = current;\n\t\twork->sig = sig;\n\t\twork->type = type;\n\t\tirq_work_queue(&work->irq_work);\n\t\treturn 0;\n\t}\n\n\treturn group_send_sig_info(sig, SEND_SIG_PRIV, current, type);\n}"
  },
  {
    "function_name": "do_bpf_send_signal",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "819-825",
    "snippet": "static void do_bpf_send_signal(struct irq_work *entry)\n{\n\tstruct send_signal_irq_work *work;\n\n\twork = container_of(entry, struct send_signal_irq_work, irq_work);\n\tgroup_send_sig_info(work->sig, SEND_SIG_PRIV, work->task, work->type);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "group_send_sig_info",
          "args": [
            "work->sig",
            "SEND_SIG_PRIV",
            "work->task",
            "work->type"
          ],
          "line": 824
        },
        "resolved": true,
        "details": {
          "function_name": "group_send_sig_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/signal.c",
          "lines": "1434-1447",
          "snippet": "int group_send_sig_info(int sig, struct kernel_siginfo *info,\n\t\t\tstruct task_struct *p, enum pid_type type)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tret = check_kill_permission(sig, info, p);\n\trcu_read_unlock();\n\n\tif (!ret && sig)\n\t\tret = do_send_sig_info(sig, info, p, type);\n\n\treturn ret;\n}",
          "includes": [
            "#include <linux/kdb.h>",
            "#include <asm/syscall.h>\t/* for syscall_get_* */",
            "#include <asm/cacheflush.h>",
            "#include <asm/siginfo.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/param.h>",
            "#include <trace/events/signal.h>",
            "#include <linux/audit.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/compiler.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/compat.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/capability.h>",
            "#include <linux/task_work.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/signal.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/coredump.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/tty.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kdb.h>\n#include <asm/syscall.h>\t/* for syscall_get_* */\n#include <asm/cacheflush.h>\n#include <asm/siginfo.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <asm/param.h>\n#include <trace/events/signal.h>\n#include <linux/audit.h>\n#include <linux/cgroup.h>\n#include <linux/posix-timers.h>\n#include <linux/compiler.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/uprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/pid_namespace.h>\n#include <linux/freezer.h>\n#include <linux/capability.h>\n#include <linux/task_work.h>\n#include <linux/ratelimit.h>\n#include <linux/signalfd.h>\n#include <linux/signal.h>\n#include <linux/ptrace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/coredump.h>\n#include <linux/binfmts.h>\n#include <linux/tty.h>\n#include <linux/proc_fs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/user.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\nint group_send_sig_info(int sig, struct kernel_siginfo *info,\n\t\t\tstruct task_struct *p, enum pid_type type)\n{\n\tint ret;\n\n\trcu_read_lock();\n\tret = check_kill_permission(sig, info, p);\n\trcu_read_unlock();\n\n\tif (!ret && sig)\n\t\tret = do_send_sig_info(sig, info, p, type);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "entry",
            "structsend_signal_irq_work",
            "irq_work"
          ],
          "line": 823
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic void do_bpf_send_signal(struct irq_work *entry)\n{\n\tstruct send_signal_irq_work *work;\n\n\twork = container_of(entry, struct send_signal_irq_work, irq_work);\n\tgroup_send_sig_info(work->sig, SEND_SIG_PRIV, work->task, work->type);\n}"
  },
  {
    "function_name": "bpf_event_output",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "708-745",
    "snippet": "u64 bpf_event_output(struct bpf_map *map, u64 flags, void *meta, u64 meta_size,\n\t\t     void *ctx, u64 ctx_size, bpf_ctx_copy_t ctx_copy)\n{\n\tint nest_level = this_cpu_inc_return(bpf_event_output_nest_level);\n\tstruct perf_raw_frag frag = {\n\t\t.copy\t\t= ctx_copy,\n\t\t.size\t\t= ctx_size,\n\t\t.data\t\t= ctx,\n\t};\n\tstruct perf_raw_record raw = {\n\t\t.frag = {\n\t\t\t{\n\t\t\t\t.next\t= ctx_size ? &frag : NULL,\n\t\t\t},\n\t\t\t.size\t= meta_size,\n\t\t\t.data\t= meta,\n\t\t},\n\t};\n\tstruct perf_sample_data *sd;\n\tstruct pt_regs *regs;\n\tu64 ret;\n\n\tif (WARN_ON_ONCE(nest_level > ARRAY_SIZE(bpf_misc_sds.sds))) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tsd = this_cpu_ptr(&bpf_misc_sds.sds[nest_level - 1]);\n\tregs = this_cpu_ptr(&bpf_pt_regs.regs[nest_level - 1]);\n\n\tperf_fetch_caller_regs(regs);\n\tperf_sample_data_init(sd, 0, 0);\n\tsd->raw = &raw;\n\n\tret = __bpf_perf_event_output(regs, map, flags, sd);\nout:\n\tthis_cpu_dec(bpf_event_output_nest_level);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(int, bpf_event_output_nest_level);",
      "static DEFINE_PER_CPU(struct bpf_nested_pt_regs, bpf_pt_regs);",
      "static DEFINE_PER_CPU(struct bpf_trace_sample_data, bpf_misc_sds);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_dec",
          "args": [
            "bpf_event_output_nest_level"
          ],
          "line": 743
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__bpf_perf_event_output",
          "args": [
            "regs",
            "map",
            "flags",
            "sd"
          ],
          "line": 741
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_perf_event_output",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "614-642",
          "snippet": "static __always_inline u64\n__bpf_perf_event_output(struct pt_regs *regs, struct bpf_map *map,\n\t\t\tu64 flags, struct perf_sample_data *sd)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\tstruct perf_event *event;\n\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\tevent = ee->event;\n\tif (unlikely(event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT))\n\t\treturn -EINVAL;\n\n\tif (unlikely(event->oncpu != cpu))\n\t\treturn -EOPNOTSUPP;\n\n\treturn perf_event_output(event, sd, regs);\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline u64\n__bpf_perf_event_output(struct pt_regs *regs, struct bpf_map *map,\n\t\t\tu64 flags, struct perf_sample_data *sd)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\tstruct perf_event *event;\n\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\tevent = ee->event;\n\tif (unlikely(event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT))\n\t\treturn -EINVAL;\n\n\tif (unlikely(event->oncpu != cpu))\n\t\treturn -EOPNOTSUPP;\n\n\treturn perf_event_output(event, sd, regs);\n}"
        }
      },
      {
        "call_info": {
          "callee": "perf_sample_data_init",
          "args": [
            "sd",
            "0",
            "0"
          ],
          "line": 738
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "perf_fetch_caller_regs",
          "args": [
            "regs"
          ],
          "line": 737
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&bpf_pt_regs.regs[nest_level - 1]"
          ],
          "line": 735
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&bpf_misc_sds.sds[nest_level - 1]"
          ],
          "line": 734
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "nest_level > ARRAY_SIZE(bpf_misc_sds.sds)"
          ],
          "line": 730
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ARRAY_SIZE",
          "args": [
            "bpf_misc_sds.sds"
          ],
          "line": 730
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_inc_return",
          "args": [
            "bpf_event_output_nest_level"
          ],
          "line": 711
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_PER_CPU(int, bpf_event_output_nest_level);\nstatic DEFINE_PER_CPU(struct bpf_nested_pt_regs, bpf_pt_regs);\nstatic DEFINE_PER_CPU(struct bpf_trace_sample_data, bpf_misc_sds);\n\nu64 bpf_event_output(struct bpf_map *map, u64 flags, void *meta, u64 meta_size,\n\t\t     void *ctx, u64 ctx_size, bpf_ctx_copy_t ctx_copy)\n{\n\tint nest_level = this_cpu_inc_return(bpf_event_output_nest_level);\n\tstruct perf_raw_frag frag = {\n\t\t.copy\t\t= ctx_copy,\n\t\t.size\t\t= ctx_size,\n\t\t.data\t\t= ctx,\n\t};\n\tstruct perf_raw_record raw = {\n\t\t.frag = {\n\t\t\t{\n\t\t\t\t.next\t= ctx_size ? &frag : NULL,\n\t\t\t},\n\t\t\t.size\t= meta_size,\n\t\t\t.data\t= meta,\n\t\t},\n\t};\n\tstruct perf_sample_data *sd;\n\tstruct pt_regs *regs;\n\tu64 ret;\n\n\tif (WARN_ON_ONCE(nest_level > ARRAY_SIZE(bpf_misc_sds.sds))) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\tsd = this_cpu_ptr(&bpf_misc_sds.sds[nest_level - 1]);\n\tregs = this_cpu_ptr(&bpf_pt_regs.regs[nest_level - 1]);\n\n\tperf_fetch_caller_regs(regs);\n\tperf_sample_data_init(sd, 0, 0);\n\tsd->raw = &raw;\n\n\tret = __bpf_perf_event_output(regs, map, flags, sd);\nout:\n\tthis_cpu_dec(bpf_event_output_nest_level);\n\treturn ret;\n}"
  },
  {
    "function_name": "BPF_CALL_5",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "653-688",
    "snippet": "static DEFINE_PER_CPU(int, bpf_trace_nest_level);\nBPF_CALL_5(bpf_perf_event_output, struct pt_regs *, regs, struct bpf_map *, map,\n\t   u64, flags, void *, data, u64, size)\n{\n\tstruct bpf_trace_sample_data *sds = this_cpu_ptr(&bpf_trace_sds);\n\tint nest_level = this_cpu_inc_return(bpf_trace_nest_level);\n\tstruct perf_raw_record raw = {\n\t\t.frag = {\n\t\t\t.size = size,\n\t\t\t.data = data,\n\t\t},\n\t};\n\tstruct perf_sample_data *sd;\n\tint err;\n\n\tif (WARN_ON_ONCE(nest_level > ARRAY_SIZE(sds->sds))) {\n\t\terr = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tsd = &sds->sds[nest_level - 1];\n\n\tif (unlikely(flags & ~(BPF_F_INDEX_MASK))) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tperf_sample_data_init(sd, 0, 0);\n\tsd->raw = &raw;\n\n\terr = __bpf_perf_event_output(regs, map, flags, sd);\n\nout:\n\tthis_cpu_dec(bpf_trace_nest_level);\n\treturn err;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct bpf_trace_sample_data, bpf_trace_sds);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_dec",
          "args": [
            "bpf_trace_nest_level"
          ],
          "line": 686
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__bpf_perf_event_output",
          "args": [
            "regs",
            "map",
            "flags",
            "sd"
          ],
          "line": 683
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_perf_event_output",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "614-642",
          "snippet": "static __always_inline u64\n__bpf_perf_event_output(struct pt_regs *regs, struct bpf_map *map,\n\t\t\tu64 flags, struct perf_sample_data *sd)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\tstruct perf_event *event;\n\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\tevent = ee->event;\n\tif (unlikely(event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT))\n\t\treturn -EINVAL;\n\n\tif (unlikely(event->oncpu != cpu))\n\t\treturn -EOPNOTSUPP;\n\n\treturn perf_event_output(event, sd, regs);\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline u64\n__bpf_perf_event_output(struct pt_regs *regs, struct bpf_map *map,\n\t\t\tu64 flags, struct perf_sample_data *sd)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\tstruct perf_event *event;\n\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\tevent = ee->event;\n\tif (unlikely(event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT))\n\t\treturn -EINVAL;\n\n\tif (unlikely(event->oncpu != cpu))\n\t\treturn -EOPNOTSUPP;\n\n\treturn perf_event_output(event, sd, regs);\n}"
        }
      },
      {
        "call_info": {
          "callee": "perf_sample_data_init",
          "args": [
            "sd",
            "0",
            "0"
          ],
          "line": 680
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "flags & ~(BPF_F_INDEX_MASK)"
          ],
          "line": 675
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "nest_level > ARRAY_SIZE(sds->sds)"
          ],
          "line": 668
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ARRAY_SIZE",
          "args": [
            "sds->sds"
          ],
          "line": 668
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_inc_return",
          "args": [
            "bpf_trace_nest_level"
          ],
          "line": 658
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&bpf_trace_sds"
          ],
          "line": 657
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic DEFINE_PER_CPU(struct bpf_trace_sample_data, bpf_trace_sds);\n\nstatic DEFINE_PER_CPU(int, bpf_trace_nest_level);\nBPF_CALL_5(bpf_perf_event_output, struct pt_regs *, regs, struct bpf_map *, map,\n\t   u64, flags, void *, data, u64, size)\n{\n\tstruct bpf_trace_sample_data *sds = this_cpu_ptr(&bpf_trace_sds);\n\tint nest_level = this_cpu_inc_return(bpf_trace_nest_level);\n\tstruct perf_raw_record raw = {\n\t\t.frag = {\n\t\t\t.size = size,\n\t\t\t.data = data,\n\t\t},\n\t};\n\tstruct perf_sample_data *sd;\n\tint err;\n\n\tif (WARN_ON_ONCE(nest_level > ARRAY_SIZE(sds->sds))) {\n\t\terr = -EBUSY;\n\t\tgoto out;\n\t}\n\n\tsd = &sds->sds[nest_level - 1];\n\n\tif (unlikely(flags & ~(BPF_F_INDEX_MASK))) {\n\t\terr = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tperf_sample_data_init(sd, 0, 0);\n\tsd->raw = &raw;\n\n\terr = __bpf_perf_event_output(regs, map, flags, sd);\n\nout:\n\tthis_cpu_dec(bpf_trace_nest_level);\n\treturn err;\n}"
  },
  {
    "function_name": "__bpf_perf_event_output",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "614-642",
    "snippet": "static __always_inline u64\n__bpf_perf_event_output(struct pt_regs *regs, struct bpf_map *map,\n\t\t\tu64 flags, struct perf_sample_data *sd)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\tstruct perf_event *event;\n\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\tevent = ee->event;\n\tif (unlikely(event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT))\n\t\treturn -EINVAL;\n\n\tif (unlikely(event->oncpu != cpu))\n\t\treturn -EOPNOTSUPP;\n\n\treturn perf_event_output(event, sd, regs);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "perf_event_output",
          "args": [
            "event",
            "sd",
            "regs"
          ],
          "line": 641
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_output",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/core.c",
          "lines": "7539-7545",
          "snippet": "int\nperf_event_output(struct perf_event *event,\n\t\t  struct perf_sample_data *data,\n\t\t  struct pt_regs *regs)\n{\n\treturn __perf_event_output(event, data, regs, perf_output_begin);\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/pgtable.h>",
            "#include <linux/highmem.h>",
            "#include <linux/min_heap.h>",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void put_event(struct perf_event *event);",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void perf_remove_from_owner(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/buildid.h>\n#include <linux/pgtable.h>\n#include <linux/highmem.h>\n#include <linux/min_heap.h>\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hugetlb.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void put_event(struct perf_event *event);\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void perf_remove_from_owner(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nint\nperf_event_output(struct perf_event *event,\n\t\t  struct perf_sample_data *data,\n\t\t  struct pt_regs *regs)\n{\n\treturn __perf_event_output(event, data, regs, perf_output_begin);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "event->oncpu != cpu"
          ],
          "line": 638
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT"
          ],
          "line": 634
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "array->ptrs[index]"
          ],
          "line": 629
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "index >= array->map.max_entries"
          ],
          "line": 626
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 619
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_array",
            "map"
          ],
          "line": 618
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline u64\n__bpf_perf_event_output(struct pt_regs *regs, struct bpf_map *map,\n\t\t\tu64 flags, struct perf_sample_data *sd)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\tstruct perf_event *event;\n\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\tevent = ee->event;\n\tif (unlikely(event->attr.type != PERF_TYPE_SOFTWARE ||\n\t\t     event->attr.config != PERF_COUNT_SW_BPF_OUTPUT))\n\t\treturn -EINVAL;\n\n\tif (unlikely(event->oncpu != cpu))\n\t\treturn -EOPNOTSUPP;\n\n\treturn perf_event_output(event, sd, regs);\n}"
  },
  {
    "function_name": "get_map_perf_counter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "541-562",
    "snippet": "static __always_inline int\nget_map_perf_counter(struct bpf_map *map, u64 flags,\n\t\t     u64 *value, u64 *enabled, u64 *running)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\n\tif (unlikely(flags & ~(BPF_F_INDEX_MASK)))\n\t\treturn -EINVAL;\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\treturn perf_event_read_local(ee->event, value, enabled, running);\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "perf_event_read_local",
          "args": [
            "ee->event",
            "value",
            "enabled",
            "running"
          ],
          "line": 561
        },
        "resolved": true,
        "details": {
          "function_name": "perf_event_read_local",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/core.c",
          "lines": "4429-4493",
          "snippet": "int perf_event_read_local(struct perf_event *event, u64 *value,\n\t\t\t  u64 *enabled, u64 *running)\n{\n\tunsigned long flags;\n\tint ret = 0;\n\n\t/*\n\t * Disabling interrupts avoids all counter scheduling (context\n\t * switches, timer based rotation and IPIs).\n\t */\n\tlocal_irq_save(flags);\n\n\t/*\n\t * It must not be an event with inherit set, we cannot read\n\t * all child counters from atomic context.\n\t */\n\tif (event->attr.inherit) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\t/* If this is a per-task event, it must be for current */\n\tif ((event->attach_state & PERF_ATTACH_TASK) &&\n\t    event->hw.target != current) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* If this is a per-CPU event, it must be for this CPU */\n\tif (!(event->attach_state & PERF_ATTACH_TASK) &&\n\t    event->cpu != smp_processor_id()) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* If this is a pinned event it must be running on this CPU */\n\tif (event->attr.pinned && event->oncpu != smp_processor_id()) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If the event is currently on this CPU, its either a per-task event,\n\t * or local to this CPU. Furthermore it means its ACTIVE (otherwise\n\t * oncpu == -1).\n\t */\n\tif (event->oncpu == smp_processor_id())\n\t\tevent->pmu->read(event);\n\n\t*value = local64_read(&event->count);\n\tif (enabled || running) {\n\t\tu64 now = event->shadow_ctx_time + perf_clock();\n\t\tu64 __enabled, __running;\n\n\t\t__perf_update_times(event, now, &__enabled, &__running);\n\t\tif (enabled)\n\t\t\t*enabled = __enabled;\n\t\tif (running)\n\t\t\t*running = __running;\n\t}\nout:\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}",
          "includes": [
            "#include <asm/irq_regs.h>",
            "#include \"internal.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/pgtable.h>",
            "#include <linux/highmem.h>",
            "#include <linux/min_heap.h>",
            "#include <linux/mount.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/parser.h>",
            "#include <linux/namei.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/compat.h>",
            "#include <linux/mman.h>",
            "#include <linux/module.h>",
            "#include <linux/mm_types.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/export.h>",
            "#include <linux/device.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/reboot.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/percpu.h>",
            "#include <linux/dcache.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/tick.h>",
            "#include <linux/hash.h>",
            "#include <linux/slab.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/idr.h>",
            "#include <linux/smp.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void cpu_ctx_sched_in(struct perf_cpu_context *cpuctx,\n\t\t\t     enum event_type_t event_type,\n\t\t\t     struct task_struct *task);",
            "static u64 perf_event_time(struct perf_event *event);",
            "static __must_check struct",
            "static void put_event(struct perf_event *event);",
            "static void perf_log_itrace_start(struct perf_event *event);",
            "static void\nctx_sched_in(struct perf_event_context *ctx,\n\t     struct perf_cpu_context *cpuctx,\n\t     enum event_type_t event_type,\n\t     struct task_struct *task);",
            "static void perf_remove_from_owner(struct perf_event *event);",
            "static void perf_event_free_filter(struct perf_event *event);",
            "static int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);",
            "static void perf_pmu_output_stop(struct perf_event *event);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <asm/irq_regs.h>\n#include \"internal.h\"\n#include <linux/buildid.h>\n#include <linux/pgtable.h>\n#include <linux/highmem.h>\n#include <linux/min_heap.h>\n#include <linux/mount.h>\n#include <linux/proc_ns.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/clock.h>\n#include <linux/parser.h>\n#include <linux/namei.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/compat.h>\n#include <linux/mman.h>\n#include <linux/module.h>\n#include <linux/mm_types.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/trace_events.h>\n#include <linux/perf_event.h>\n#include <linux/cgroup.h>\n#include <linux/kernel_stat.h>\n#include <linux/anon_inodes.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/hugetlb.h>\n#include <linux/hardirq.h>\n#include <linux/vmalloc.h>\n#include <linux/export.h>\n#include <linux/device.h>\n#include <linux/vmstat.h>\n#include <linux/reboot.h>\n#include <linux/ptrace.h>\n#include <linux/percpu.h>\n#include <linux/dcache.h>\n#include <linux/sysfs.h>\n#include <linux/tick.h>\n#include <linux/hash.h>\n#include <linux/slab.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/idr.h>\n#include <linux/smp.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n\nstatic void cpu_ctx_sched_in(struct perf_cpu_context *cpuctx,\n\t\t\t     enum event_type_t event_type,\n\t\t\t     struct task_struct *task);\nstatic u64 perf_event_time(struct perf_event *event);\nstatic __must_check struct;\nstatic void put_event(struct perf_event *event);\nstatic void perf_log_itrace_start(struct perf_event *event);\nstatic void\nctx_sched_in(struct perf_event_context *ctx,\n\t     struct perf_cpu_context *cpuctx,\n\t     enum event_type_t event_type,\n\t     struct task_struct *task);\nstatic void perf_remove_from_owner(struct perf_event *event);\nstatic void perf_event_free_filter(struct perf_event *event);\nstatic int perf_copy_attr(struct perf_event_attr __user *uattr,\n\t\t\t  struct perf_event_attr *attr);\nstatic void perf_pmu_output_stop(struct perf_event *event);\n\nint perf_event_read_local(struct perf_event *event, u64 *value,\n\t\t\t  u64 *enabled, u64 *running)\n{\n\tunsigned long flags;\n\tint ret = 0;\n\n\t/*\n\t * Disabling interrupts avoids all counter scheduling (context\n\t * switches, timer based rotation and IPIs).\n\t */\n\tlocal_irq_save(flags);\n\n\t/*\n\t * It must not be an event with inherit set, we cannot read\n\t * all child counters from atomic context.\n\t */\n\tif (event->attr.inherit) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\t/* If this is a per-task event, it must be for current */\n\tif ((event->attach_state & PERF_ATTACH_TASK) &&\n\t    event->hw.target != current) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* If this is a per-CPU event, it must be for this CPU */\n\tif (!(event->attach_state & PERF_ATTACH_TASK) &&\n\t    event->cpu != smp_processor_id()) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* If this is a pinned event it must be running on this CPU */\n\tif (event->attr.pinned && event->oncpu != smp_processor_id()) {\n\t\tret = -EBUSY;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If the event is currently on this CPU, its either a per-task event,\n\t * or local to this CPU. Furthermore it means its ACTIVE (otherwise\n\t * oncpu == -1).\n\t */\n\tif (event->oncpu == smp_processor_id())\n\t\tevent->pmu->read(event);\n\n\t*value = local64_read(&event->count);\n\tif (enabled || running) {\n\t\tu64 now = event->shadow_ctx_time + perf_clock();\n\t\tu64 __enabled, __running;\n\n\t\t__perf_update_times(event, now, &__enabled, &__running);\n\t\tif (enabled)\n\t\t\t*enabled = __enabled;\n\t\tif (running)\n\t\t\t*running = __running;\n\t}\nout:\n\tlocal_irq_restore(flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "array->ptrs[index]"
          ],
          "line": 557
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "index >= array->map.max_entries"
          ],
          "line": 554
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "flags & ~(BPF_F_INDEX_MASK)"
          ],
          "line": 550
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 546
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_array",
            "map"
          ],
          "line": 545
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline int\nget_map_perf_counter(struct bpf_map *map, u64 flags,\n\t\t     u64 *value, u64 *enabled, u64 *running)\n{\n\tstruct bpf_array *array = container_of(map, struct bpf_array, map);\n\tunsigned int cpu = smp_processor_id();\n\tu64 index = flags & BPF_F_INDEX_MASK;\n\tstruct bpf_event_entry *ee;\n\n\tif (unlikely(flags & ~(BPF_F_INDEX_MASK)))\n\t\treturn -EINVAL;\n\tif (index == BPF_F_CURRENT_CPU)\n\t\tindex = cpu;\n\tif (unlikely(index >= array->map.max_entries))\n\t\treturn -E2BIG;\n\n\tee = READ_ONCE(array->ptrs[index]);\n\tif (!ee)\n\t\treturn -ENOENT;\n\n\treturn perf_event_read_local(ee->event, value, enabled, running);\n}"
  },
  {
    "function_name": "bpf_get_trace_vprintk_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "459-463",
    "snippet": "const struct bpf_func_proto *bpf_get_trace_vprintk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_vprintk_proto;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_trace_vprintk_proto = {\n\t.func\t\t= bpf_trace_vprintk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE_OR_ZERO,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__set_printk_clr_event",
          "args": [],
          "line": 461
        },
        "resolved": true,
        "details": {
          "function_name": "__set_printk_clr_event",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "401-413",
          "snippet": "static void __set_printk_clr_event(void)\n{\n\t/*\n\t * This program might be calling bpf_trace_printk,\n\t * so enable the associated bpf_trace/bpf_trace_printk event.\n\t * Repeat this each time as it is possible a user has\n\t * disabled bpf_trace_printk events.  By loading a program\n\t * calling bpf_trace_printk() however the user has expressed\n\t * the intent to see such events.\n\t */\n\tif (trace_set_clr_event(\"bpf_trace\", \"bpf_trace_printk\", 1))\n\t\tpr_warn_ratelimited(\"could not enable bpf_trace_printk events\");\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic void __set_printk_clr_event(void)\n{\n\t/*\n\t * This program might be calling bpf_trace_printk,\n\t * so enable the associated bpf_trace/bpf_trace_printk event.\n\t * Repeat this each time as it is possible a user has\n\t * disabled bpf_trace_printk events.  By loading a program\n\t * calling bpf_trace_printk() however the user has expressed\n\t * the intent to see such events.\n\t */\n\tif (trace_set_clr_event(\"bpf_trace\", \"bpf_trace_printk\", 1))\n\t\tpr_warn_ratelimited(\"could not enable bpf_trace_printk events\");\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_trace_vprintk_proto = {\n\t.func\t\t= bpf_trace_vprintk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n\t.arg3_type\t= ARG_PTR_TO_MEM | PTR_MAYBE_NULL | MEM_RDONLY,\n\t.arg4_type\t= ARG_CONST_SIZE_OR_ZERO,\n};\n\nconst struct bpf_func_proto *bpf_get_trace_vprintk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_vprintk_proto;\n}"
  },
  {
    "function_name": "bpf_get_trace_printk_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "415-419",
    "snippet": "const struct bpf_func_proto *bpf_get_trace_printk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_printk_proto;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_trace_printk_proto = {\n\t.func\t\t= bpf_trace_printk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__set_printk_clr_event",
          "args": [],
          "line": 417
        },
        "resolved": true,
        "details": {
          "function_name": "__set_printk_clr_event",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
          "lines": "401-413",
          "snippet": "static void __set_printk_clr_event(void)\n{\n\t/*\n\t * This program might be calling bpf_trace_printk,\n\t * so enable the associated bpf_trace/bpf_trace_printk event.\n\t * Repeat this each time as it is possible a user has\n\t * disabled bpf_trace_printk events.  By loading a program\n\t * calling bpf_trace_printk() however the user has expressed\n\t * the intent to see such events.\n\t */\n\tif (trace_set_clr_event(\"bpf_trace\", \"bpf_trace_printk\", 1))\n\t\tpr_warn_ratelimited(\"could not enable bpf_trace_printk events\");\n}",
          "includes": [
            "#include \"bpf_trace.h\"",
            "#include \"trace.h\"",
            "#include \"trace_probe.h\"",
            "#include <asm/tlb.h>",
            "#include <uapi/linux/btf.h>",
            "#include <uapi/linux/bpf.h>",
            "#include <net/bpf_sk_storage.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/ctype.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/filter.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_perf_event.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic void __set_printk_clr_event(void)\n{\n\t/*\n\t * This program might be calling bpf_trace_printk,\n\t * so enable the associated bpf_trace/bpf_trace_printk event.\n\t * Repeat this each time as it is possible a user has\n\t * disabled bpf_trace_printk events.  By loading a program\n\t * calling bpf_trace_printk() however the user has expressed\n\t * the intent to see such events.\n\t */\n\tif (trace_set_clr_event(\"bpf_trace\", \"bpf_trace_printk\", 1))\n\t\tpr_warn_ratelimited(\"could not enable bpf_trace_printk events\");\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_trace_printk_proto = {\n\t.func\t\t= bpf_trace_printk,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg2_type\t= ARG_CONST_SIZE,\n};\n\nconst struct bpf_func_proto *bpf_get_trace_printk_proto(void)\n{\n\t__set_printk_clr_event();\n\treturn &bpf_trace_printk_proto;\n}"
  },
  {
    "function_name": "__set_printk_clr_event",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "401-413",
    "snippet": "static void __set_printk_clr_event(void)\n{\n\t/*\n\t * This program might be calling bpf_trace_printk,\n\t * so enable the associated bpf_trace/bpf_trace_printk event.\n\t * Repeat this each time as it is possible a user has\n\t * disabled bpf_trace_printk events.  By loading a program\n\t * calling bpf_trace_printk() however the user has expressed\n\t * the intent to see such events.\n\t */\n\tif (trace_set_clr_event(\"bpf_trace\", \"bpf_trace_printk\", 1))\n\t\tpr_warn_ratelimited(\"could not enable bpf_trace_printk events\");\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_warn_ratelimited",
          "args": [
            "\"could not enable bpf_trace_printk events\""
          ],
          "line": 412
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_set_clr_event",
          "args": [
            "\"bpf_trace\"",
            "\"bpf_trace_printk\"",
            "1"
          ],
          "line": 411
        },
        "resolved": true,
        "details": {
          "function_name": "trace_set_clr_event",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_events.c",
          "lines": "1099-1107",
          "snippet": "int trace_set_clr_event(const char *system, const char *event, int set)\n{\n\tstruct trace_array *tr = top_trace_array();\n\n\tif (!tr)\n\t\treturn -ENODEV;\n\n\treturn __ftrace_set_clr_event(tr, NULL, system, event, set);\n}",
          "includes": [
            "#include \"trace_output.h\"",
            "#include <asm/setup.h>",
            "#include <trace/syscall.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/delay.h>",
            "#include <linux/slab.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/module.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/kthread.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/security.h>",
            "#include <linux/workqueue.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_output.h\"\n#include <asm/setup.h>\n#include <trace/syscall.h>\n#include <trace/events/sched.h>\n#include <linux/delay.h>\n#include <linux/slab.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/module.h>\n#include <linux/uaccess.h>\n#include <linux/tracefs.h>\n#include <linux/kthread.h>\n#include <linux/spinlock.h>\n#include <linux/security.h>\n#include <linux/workqueue.h>\n\nint trace_set_clr_event(const char *system, const char *event, int set)\n{\n\tstruct trace_array *tr = top_trace_array();\n\n\tif (!tr)\n\t\treturn -ENODEV;\n\n\treturn __ftrace_set_clr_event(tr, NULL, system, event, set);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic void __set_printk_clr_event(void)\n{\n\t/*\n\t * This program might be calling bpf_trace_printk,\n\t * so enable the associated bpf_trace/bpf_trace_printk event.\n\t * Repeat this each time as it is possible a user has\n\t * disabled bpf_trace_printk events.  By loading a program\n\t * calling bpf_trace_printk() however the user has expressed\n\t * the intent to see such events.\n\t */\n\tif (trace_set_clr_event(\"bpf_trace\", \"bpf_trace_printk\", 1))\n\t\tpr_warn_ratelimited(\"could not enable bpf_trace_printk events\");\n}"
  },
  {
    "function_name": "bpf_get_probe_write_proto",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "352-361",
    "snippet": "static const struct bpf_func_proto *bpf_get_probe_write_proto(void)\n{\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn NULL;\n\n\tpr_warn_ratelimited(\"%s[%d] is installing a program with bpf_probe_write_user helper that may corrupt user memory!\",\n\t\t\t    current->comm, task_pid_nr(current));\n\n\treturn &bpf_probe_write_user_proto;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static const struct bpf_func_proto bpf_probe_write_user_proto = {\n\t.func\t\t= bpf_probe_write_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_warn_ratelimited",
          "args": [
            "\"%s[%d] is installing a program with bpf_probe_write_user helper that may corrupt user memory!\"",
            "current->comm",
            "task_pid_nr(current)"
          ],
          "line": 357
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_pid_nr",
          "args": [
            "current"
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_SYS_ADMIN"
          ],
          "line": 354
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/capability.c",
          "lines": "447-450",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic const struct bpf_func_proto bpf_probe_write_user_proto = {\n\t.func\t\t= bpf_probe_write_user,\n\t.gpl_only\t= true,\n\t.ret_type\t= RET_INTEGER,\n\t.arg1_type\t= ARG_ANYTHING,\n\t.arg2_type\t= ARG_PTR_TO_MEM | MEM_RDONLY,\n\t.arg3_type\t= ARG_CONST_SIZE,\n};\n\nstatic const struct bpf_func_proto *bpf_get_probe_write_proto(void)\n{\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn NULL;\n\n\tpr_warn_ratelimited(\"%s[%d] is installing a program with bpf_probe_write_user helper that may corrupt user memory!\",\n\t\t\t    current->comm, task_pid_nr(current));\n\n\treturn &bpf_probe_write_user_proto;\n}"
  },
  {
    "function_name": "bpf_probe_read_kernel_str_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "241-259",
    "snippet": "static __always_inline int\nbpf_probe_read_kernel_str_common(void *dst, u32 size, const void *unsafe_ptr)\n{\n\tint ret;\n\n\t/*\n\t * The strncpy_from_kernel_nofault() call will likely not fill the\n\t * entire buffer, but that's okay in this circumstance as we're probing\n\t * arbitrary memory anyway similar to bpf_probe_read_*() and might\n\t * as well probe the stack. Thus, memory is explicitly cleared\n\t * only in error case, so that improper users ignoring return\n\t * code altogether don't copy garbage; otherwise length of string\n\t * is returned that can be used for bpf_perf_event_output() et al.\n\t */\n\tret = strncpy_from_kernel_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "dst",
            "0",
            "size"
          ],
          "line": 257
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret < 0"
          ],
          "line": 256
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strncpy_from_kernel_nofault",
          "args": [
            "dst",
            "unsafe_ptr",
            "size"
          ],
          "line": 255
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline int\nbpf_probe_read_kernel_str_common(void *dst, u32 size, const void *unsafe_ptr)\n{\n\tint ret;\n\n\t/*\n\t * The strncpy_from_kernel_nofault() call will likely not fill the\n\t * entire buffer, but that's okay in this circumstance as we're probing\n\t * arbitrary memory anyway similar to bpf_probe_read_*() and might\n\t * as well probe the stack. Thus, memory is explicitly cleared\n\t * only in error case, so that improper users ignoring return\n\t * code altogether don't copy garbage; otherwise length of string\n\t * is returned that can be used for bpf_perf_event_output() et al.\n\t */\n\tret = strncpy_from_kernel_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_probe_read_kernel_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "215-224",
    "snippet": "static __always_inline int\nbpf_probe_read_kernel_common(void *dst, u32 size, const void *unsafe_ptr)\n{\n\tint ret;\n\n\tret = copy_from_kernel_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "dst",
            "0",
            "size"
          ],
          "line": 222
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret < 0"
          ],
          "line": 221
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_from_kernel_nofault",
          "args": [
            "dst",
            "unsafe_ptr",
            "size"
          ],
          "line": 220
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline int\nbpf_probe_read_kernel_common(void *dst, u32 size, const void *unsafe_ptr)\n{\n\tint ret;\n\n\tret = copy_from_kernel_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_probe_read_user_str_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "178-198",
    "snippet": "static __always_inline int\nbpf_probe_read_user_str_common(void *dst, u32 size,\n\t\t\t       const void __user *unsafe_ptr)\n{\n\tint ret;\n\n\t/*\n\t * NB: We rely on strncpy_from_user() not copying junk past the NUL\n\t * terminator into `dst`.\n\t *\n\t * strncpy_from_user() does long-sized strides in the fast path. If the\n\t * strncpy does not mask out the bytes after the NUL in `unsafe_ptr`,\n\t * then there could be junk after the NUL in `dst`. If user takes `dst`\n\t * and keys a hash map with it, then semantically identical strings can\n\t * occupy multiple entries in the map.\n\t */\n\tret = strncpy_from_user_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "dst",
            "0",
            "size"
          ],
          "line": 196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret < 0"
          ],
          "line": 195
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "strncpy_from_user_nofault",
          "args": [
            "dst",
            "unsafe_ptr",
            "size"
          ],
          "line": 194
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline int\nbpf_probe_read_user_str_common(void *dst, u32 size,\n\t\t\t       const void __user *unsafe_ptr)\n{\n\tint ret;\n\n\t/*\n\t * NB: We rely on strncpy_from_user() not copying junk past the NUL\n\t * terminator into `dst`.\n\t *\n\t * strncpy_from_user() does long-sized strides in the fast path. If the\n\t * strncpy does not mask out the bytes after the NUL in `unsafe_ptr`,\n\t * then there could be junk after the NUL in `dst`. If user takes `dst`\n\t * and keys a hash map with it, then semantically identical strings can\n\t * occupy multiple entries in the map.\n\t */\n\tret = strncpy_from_user_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_probe_read_user_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "152-161",
    "snippet": "static __always_inline int\nbpf_probe_read_user_common(void *dst, u32 size, const void __user *unsafe_ptr)\n{\n\tint ret;\n\n\tret = copy_from_user_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "dst",
            "0",
            "size"
          ],
          "line": 159
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret < 0"
          ],
          "line": 158
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_from_user_nofault",
          "args": [
            "dst",
            "unsafe_ptr",
            "size"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic __always_inline int\nbpf_probe_read_user_common(void *dst, u32 size, const void __user *unsafe_ptr)\n{\n\tint ret;\n\n\tret = copy_from_user_nofault(dst, unsafe_ptr, size);\n\tif (unlikely(ret < 0))\n\t\tmemset(dst, 0, size);\n\treturn ret;\n}"
  },
  {
    "function_name": "trace_call_bpf",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "95-133",
    "snippet": "unsigned int trace_call_bpf(struct trace_event_call *call, void *ctx)\n{\n\tunsigned int ret;\n\n\tcant_sleep();\n\n\tif (unlikely(__this_cpu_inc_return(bpf_prog_active) != 1)) {\n\t\t/*\n\t\t * since some bpf program is already running on this cpu,\n\t\t * don't call into another bpf program (same or different)\n\t\t * and don't send kprobe event into ring-buffer,\n\t\t * so return zero here\n\t\t */\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Instead of moving rcu_read_lock/rcu_dereference/rcu_read_unlock\n\t * to all call sites, we did a bpf_prog_array_valid() there to check\n\t * whether call->prog_array is empty or not, which is\n\t * a heuristic to speed up execution.\n\t *\n\t * If bpf_prog_array_valid() fetched prog_array was\n\t * non-NULL, we go into trace_call_bpf() and do the actual\n\t * proper rcu_dereference() under RCU lock.\n\t * If it turns out that prog_array is NULL then, we bail out.\n\t * For the opposite, if the bpf_prog_array_valid() fetched pointer\n\t * was NULL, you'll skip the prog_array with the risk of missing\n\t * out of events when it was updated in between this and the\n\t * rcu_dereference() which is accepted risk.\n\t */\n\tret = BPF_PROG_RUN_ARRAY(call->prog_array, ctx, bpf_prog_run);\n\n out:\n\t__this_cpu_dec(bpf_prog_active);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__this_cpu_dec",
          "args": [
            "bpf_prog_active"
          ],
          "line": 130
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BPF_PROG_RUN_ARRAY",
          "args": [
            "call->prog_array",
            "ctx",
            "bpf_prog_run"
          ],
          "line": 127
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "__this_cpu_inc_return(bpf_prog_active) != 1"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_inc_return",
          "args": [
            "bpf_prog_active"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cant_sleep",
          "args": [],
          "line": 99
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nunsigned int trace_call_bpf(struct trace_event_call *call, void *ctx)\n{\n\tunsigned int ret;\n\n\tcant_sleep();\n\n\tif (unlikely(__this_cpu_inc_return(bpf_prog_active) != 1)) {\n\t\t/*\n\t\t * since some bpf program is already running on this cpu,\n\t\t * don't call into another bpf program (same or different)\n\t\t * and don't send kprobe event into ring-buffer,\n\t\t * so return zero here\n\t\t */\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Instead of moving rcu_read_lock/rcu_dereference/rcu_read_unlock\n\t * to all call sites, we did a bpf_prog_array_valid() there to check\n\t * whether call->prog_array is empty or not, which is\n\t * a heuristic to speed up execution.\n\t *\n\t * If bpf_prog_array_valid() fetched prog_array was\n\t * non-NULL, we go into trace_call_bpf() and do the actual\n\t * proper rcu_dereference() under RCU lock.\n\t * If it turns out that prog_array is NULL then, we bail out.\n\t * For the opposite, if the bpf_prog_array_valid() fetched pointer\n\t * was NULL, you'll skip the prog_array with the risk of missing\n\t * out of events when it was updated in between this and the\n\t * rcu_dereference() which is accepted risk.\n\t */\n\tret = BPF_PROG_RUN_ARRAY(call->prog_array, ctx, bpf_prog_run);\n\n out:\n\t__this_cpu_dec(bpf_prog_active);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_get_raw_tracepoint_module",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "68-71",
    "snippet": "static struct bpf_raw_event_map *bpf_get_raw_tracepoint_module(const char *name)\n{\n\treturn NULL;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic struct bpf_raw_event_map *bpf_get_raw_tracepoint_module(const char *name)\n{\n\treturn NULL;\n}"
  },
  {
    "function_name": "bpf_get_raw_tracepoint_module",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/bpf_trace.c",
    "lines": "46-66",
    "snippet": "static struct bpf_raw_event_map *bpf_get_raw_tracepoint_module(const char *name)\n{\n\tstruct bpf_raw_event_map *btp, *ret = NULL;\n\tstruct bpf_trace_module *btm;\n\tunsigned int i;\n\n\tmutex_lock(&bpf_module_mutex);\n\tlist_for_each_entry(btm, &bpf_trace_modules, list) {\n\t\tfor (i = 0; i < btm->module->num_bpf_raw_events; ++i) {\n\t\t\tbtp = &btm->module->bpf_raw_events[i];\n\t\t\tif (!strcmp(btp->tp->name, name)) {\n\t\t\t\tif (try_module_get(btm->module))\n\t\t\t\t\tret = btp;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\nout:\n\tmutex_unlock(&bpf_module_mutex);\n\treturn ret;\n}",
    "includes": [
      "#include \"bpf_trace.h\"",
      "#include \"trace.h\"",
      "#include \"trace_probe.h\"",
      "#include <asm/tlb.h>",
      "#include <uapi/linux/btf.h>",
      "#include <uapi/linux/bpf.h>",
      "#include <net/bpf_sk_storage.h>",
      "#include <linux/bpf_lsm.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/error-injection.h>",
      "#include <linux/syscalls.h>",
      "#include <linux/spinlock.h>",
      "#include <linux/kprobes.h>",
      "#include <linux/ctype.h>",
      "#include <linux/uaccess.h>",
      "#include <linux/filter.h>",
      "#include <linux/btf.h>",
      "#include <linux/bpf_perf_event.h>",
      "#include <linux/bpf.h>",
      "#include <linux/slab.h>",
      "#include <linux/types.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&bpf_module_mutex"
          ],
          "line": 64
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "try_module_get",
          "args": [
            "btm->module"
          ],
          "line": 57
        },
        "resolved": true,
        "details": {
          "function_name": "try_module_get",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/module.c",
          "lines": "1068-1084",
          "snippet": "bool try_module_get(struct module *module)\n{\n\tbool ret = true;\n\n\tif (module) {\n\t\tpreempt_disable();\n\t\t/* Note: here, we can fail to get a reference */\n\t\tif (likely(module_is_live(module) &&\n\t\t\t   atomic_inc_not_zero(&module->refcnt) != 0))\n\t\t\ttrace_module_get(module, _RET_IP_);\n\t\telse\n\t\t\tret = false;\n\n\t\tpreempt_enable();\n\t}\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include \"module-internal.h\"",
            "#include <uapi/linux/module.h>",
            "#include <linux/audit.h>",
            "#include <linux/dynamic_debug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/pfn.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/percpu.h>",
            "#include <linux/async.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/tracepoint.h>",
            "#include <asm/sections.h>",
            "#include <linux/license.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/set_memory.h>",
            "#include <asm/cacheflush.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/mutex.h>",
            "#include <linux/string.h>",
            "#include <linux/device.h>",
            "#include <linux/sched.h>",
            "#include <linux/notifier.h>",
            "#include <linux/vermagic.h>",
            "#include <linux/err.h>",
            "#include <linux/errno.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/elf.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel_read_file.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/buildid.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/module_signature.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/extable.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include \"module-internal.h\"\n#include <uapi/linux/module.h>\n#include <linux/audit.h>\n#include <linux/dynamic_debug.h>\n#include <linux/bsearch.h>\n#include <linux/pfn.h>\n#include <linux/jump_label.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/async.h>\n#include <linux/livepatch.h>\n#include <linux/ftrace.h>\n#include <linux/tracepoint.h>\n#include <asm/sections.h>\n#include <linux/license.h>\n#include <asm/mmu_context.h>\n#include <linux/set_memory.h>\n#include <asm/cacheflush.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/mutex.h>\n#include <linux/string.h>\n#include <linux/device.h>\n#include <linux/sched.h>\n#include <linux/notifier.h>\n#include <linux/vermagic.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/moduleparam.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/rcupdate.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/elf.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/kernel_read_file.h>\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/buildid.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/trace_events.h>\n#include <linux/module_signature.h>\n#include <linux/moduleloader.h>\n#include <linux/extable.h>\n#include <linux/export.h>\n\nbool try_module_get(struct module *module)\n{\n\tbool ret = true;\n\n\tif (module) {\n\t\tpreempt_disable();\n\t\t/* Note: here, we can fail to get a reference */\n\t\tif (likely(module_is_live(module) &&\n\t\t\t   atomic_inc_not_zero(&module->refcnt) != 0))\n\t\t\ttrace_module_get(module, _RET_IP_);\n\t\telse\n\t\t\tret = false;\n\n\t\tpreempt_enable();\n\t}\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "strcmp",
          "args": [
            "btp->tp->name",
            "name"
          ],
          "line": 56
        },
        "resolved": true,
        "details": {
          "function_name": "sym_strcmp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/report.c",
          "lines": "356-365",
          "snippet": "static int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}",
          "includes": [
            "#include \"encoding.h\"",
            "#include \"kcsan.h\"",
            "#include <linux/stacktrace.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/printk.h>",
            "#include <linux/preempt.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/delay.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"encoding.h\"\n#include \"kcsan.h\"\n#include <linux/stacktrace.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/printk.h>\n#include <linux/preempt.h>\n#include <linux/lockdep.h>\n#include <linux/kernel.h>\n#include <linux/kallsyms.h>\n#include <linux/jiffies.h>\n#include <linux/delay.h>\n#include <linux/debug_locks.h>\n\nstatic int sym_strcmp(void *addr1, void *addr2)\n{\n\tchar buf1[64];\n\tchar buf2[64];\n\n\tsnprintf(buf1, sizeof(buf1), \"%pS\", addr1);\n\tsnprintf(buf2, sizeof(buf2), \"%pS\", addr2);\n\n\treturn strncmp(buf1, buf2, sizeof(buf1));\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "btm",
            "&bpf_trace_modules",
            "list"
          ],
          "line": 53
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&bpf_module_mutex"
          ],
          "line": 52
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"bpf_trace.h\"\n#include \"trace.h\"\n#include \"trace_probe.h\"\n#include <asm/tlb.h>\n#include <uapi/linux/btf.h>\n#include <uapi/linux/bpf.h>\n#include <net/bpf_sk_storage.h>\n#include <linux/bpf_lsm.h>\n#include <linux/btf_ids.h>\n#include <linux/error-injection.h>\n#include <linux/syscalls.h>\n#include <linux/spinlock.h>\n#include <linux/kprobes.h>\n#include <linux/ctype.h>\n#include <linux/uaccess.h>\n#include <linux/filter.h>\n#include <linux/btf.h>\n#include <linux/bpf_perf_event.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n\nstatic struct bpf_raw_event_map *bpf_get_raw_tracepoint_module(const char *name)\n{\n\tstruct bpf_raw_event_map *btp, *ret = NULL;\n\tstruct bpf_trace_module *btm;\n\tunsigned int i;\n\n\tmutex_lock(&bpf_module_mutex);\n\tlist_for_each_entry(btm, &bpf_trace_modules, list) {\n\t\tfor (i = 0; i < btm->module->num_bpf_raw_events; ++i) {\n\t\t\tbtp = &btm->module->bpf_raw_events[i];\n\t\t\tif (!strcmp(btp->tp->name, name)) {\n\t\t\t\tif (try_module_get(btm->module))\n\t\t\t\t\tret = btp;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\nout:\n\tmutex_unlock(&bpf_module_mutex);\n\treturn ret;\n}"
  }
]