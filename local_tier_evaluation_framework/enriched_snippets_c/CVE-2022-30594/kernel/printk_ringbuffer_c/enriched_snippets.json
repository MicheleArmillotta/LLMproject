[
  {
    "function_name": "prb_record_text_space",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "2079-2082",
    "snippet": "unsigned int prb_record_text_space(struct prb_reserved_entry *e)\n{\n\treturn e->text_space;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nunsigned int prb_record_text_space(struct prb_reserved_entry *e)\n{\n\treturn e->text_space;\n}"
  },
  {
    "function_name": "prb_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "2034-2061",
    "snippet": "void prb_init(struct printk_ringbuffer *rb,\n\t      char *text_buf, unsigned int textbits,\n\t      struct prb_desc *descs, unsigned int descbits,\n\t      struct printk_info *infos)\n{\n\tmemset(descs, 0, _DESCS_COUNT(descbits) * sizeof(descs[0]));\n\tmemset(infos, 0, _DESCS_COUNT(descbits) * sizeof(infos[0]));\n\n\trb->desc_ring.count_bits = descbits;\n\trb->desc_ring.descs = descs;\n\trb->desc_ring.infos = infos;\n\tatomic_long_set(&rb->desc_ring.head_id, DESC0_ID(descbits));\n\tatomic_long_set(&rb->desc_ring.tail_id, DESC0_ID(descbits));\n\n\trb->text_data_ring.size_bits = textbits;\n\trb->text_data_ring.data = text_buf;\n\tatomic_long_set(&rb->text_data_ring.head_lpos, BLK0_LPOS(textbits));\n\tatomic_long_set(&rb->text_data_ring.tail_lpos, BLK0_LPOS(textbits));\n\n\tatomic_long_set(&rb->fail, 0);\n\n\tatomic_long_set(&(descs[_DESCS_COUNT(descbits) - 1].state_var), DESC0_SV(descbits));\n\tdescs[_DESCS_COUNT(descbits) - 1].text_blk_lpos.begin = FAILED_LPOS;\n\tdescs[_DESCS_COUNT(descbits) - 1].text_blk_lpos.next = FAILED_LPOS;\n\n\tinfos[0].seq = -(u64)_DESCS_COUNT(descbits);\n\tinfos[_DESCS_COUNT(descbits) - 1].seq = 0;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2060
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2059
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2057
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2056
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&(descs[_DESCS_COUNT(descbits) - 1].state_var)",
            "DESC0_SV(descbits)"
          ],
          "line": 2055
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC0_SV",
          "args": [
            "descbits"
          ],
          "line": 2055
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2055
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&rb->fail",
            "0"
          ],
          "line": 2053
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&rb->text_data_ring.tail_lpos",
            "BLK0_LPOS(textbits)"
          ],
          "line": 2051
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BLK0_LPOS",
          "args": [
            "textbits"
          ],
          "line": 2051
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&rb->text_data_ring.head_lpos",
            "BLK0_LPOS(textbits)"
          ],
          "line": 2050
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BLK0_LPOS",
          "args": [
            "textbits"
          ],
          "line": 2050
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&rb->desc_ring.tail_id",
            "DESC0_ID(descbits)"
          ],
          "line": 2046
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC0_ID",
          "args": [
            "descbits"
          ],
          "line": 2046
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&rb->desc_ring.head_id",
            "DESC0_ID(descbits)"
          ],
          "line": 2045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC0_ID",
          "args": [
            "descbits"
          ],
          "line": 2045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "infos",
            "0",
            "_DESCS_COUNT(descbits) * sizeof(infos[0])"
          ],
          "line": 2040
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2040
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "descs",
            "0",
            "_DESCS_COUNT(descbits) * sizeof(descs[0])"
          ],
          "line": 2039
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_DESCS_COUNT",
          "args": [
            "descbits"
          ],
          "line": 2039
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nvoid prb_init(struct printk_ringbuffer *rb,\n\t      char *text_buf, unsigned int textbits,\n\t      struct prb_desc *descs, unsigned int descbits,\n\t      struct printk_info *infos)\n{\n\tmemset(descs, 0, _DESCS_COUNT(descbits) * sizeof(descs[0]));\n\tmemset(infos, 0, _DESCS_COUNT(descbits) * sizeof(infos[0]));\n\n\trb->desc_ring.count_bits = descbits;\n\trb->desc_ring.descs = descs;\n\trb->desc_ring.infos = infos;\n\tatomic_long_set(&rb->desc_ring.head_id, DESC0_ID(descbits));\n\tatomic_long_set(&rb->desc_ring.tail_id, DESC0_ID(descbits));\n\n\trb->text_data_ring.size_bits = textbits;\n\trb->text_data_ring.data = text_buf;\n\tatomic_long_set(&rb->text_data_ring.head_lpos, BLK0_LPOS(textbits));\n\tatomic_long_set(&rb->text_data_ring.tail_lpos, BLK0_LPOS(textbits));\n\n\tatomic_long_set(&rb->fail, 0);\n\n\tatomic_long_set(&(descs[_DESCS_COUNT(descbits) - 1].state_var), DESC0_SV(descbits));\n\tdescs[_DESCS_COUNT(descbits) - 1].text_blk_lpos.begin = FAILED_LPOS;\n\tdescs[_DESCS_COUNT(descbits) - 1].text_blk_lpos.next = FAILED_LPOS;\n\n\tinfos[0].seq = -(u64)_DESCS_COUNT(descbits);\n\tinfos[_DESCS_COUNT(descbits) - 1].seq = 0;\n}"
  },
  {
    "function_name": "prb_next_seq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "2006-2015",
    "snippet": "u64 prb_next_seq(struct printk_ringbuffer *rb)\n{\n\tu64 seq = 0;\n\n\t/* Search forward from the oldest descriptor. */\n\twhile (_prb_read_valid(rb, &seq, NULL, NULL))\n\t\tseq++;\n\n\treturn seq;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_prb_read_valid",
          "args": [
            "rb",
            "&seq",
            "NULL",
            "NULL"
          ],
          "line": 2011
        },
        "resolved": true,
        "details": {
          "function_name": "_prb_read_valid",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1874-1901",
          "snippet": "static bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nu64 prb_next_seq(struct printk_ringbuffer *rb)\n{\n\tu64 seq = 0;\n\n\t/* Search forward from the oldest descriptor. */\n\twhile (_prb_read_valid(rb, &seq, NULL, NULL))\n\t\tseq++;\n\n\treturn seq;\n}"
  },
  {
    "function_name": "prb_first_valid_seq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1981-1989",
    "snippet": "u64 prb_first_valid_seq(struct printk_ringbuffer *rb)\n{\n\tu64 seq = 0;\n\n\tif (!_prb_read_valid(rb, &seq, NULL, NULL))\n\t\treturn 0;\n\n\treturn seq;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_prb_read_valid",
          "args": [
            "rb",
            "&seq",
            "NULL",
            "NULL"
          ],
          "line": 1985
        },
        "resolved": true,
        "details": {
          "function_name": "_prb_read_valid",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1874-1901",
          "snippet": "static bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nu64 prb_first_valid_seq(struct printk_ringbuffer *rb)\n{\n\tu64 seq = 0;\n\n\tif (!_prb_read_valid(rb, &seq, NULL, NULL))\n\t\treturn 0;\n\n\treturn seq;\n}"
  },
  {
    "function_name": "prb_read_valid_info",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1956-1964",
    "snippet": "bool prb_read_valid_info(struct printk_ringbuffer *rb, u64 seq,\n\t\t\t struct printk_info *info, unsigned int *line_count)\n{\n\tstruct printk_record r;\n\n\tprb_rec_init_rd(&r, info, NULL, 0);\n\n\treturn _prb_read_valid(rb, &seq, &r, line_count);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_prb_read_valid",
          "args": [
            "rb",
            "&seq",
            "&r",
            "line_count"
          ],
          "line": 1963
        },
        "resolved": true,
        "details": {
          "function_name": "_prb_read_valid",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1874-1901",
          "snippet": "static bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "prb_rec_init_rd",
          "args": [
            "&r",
            "info",
            "NULL",
            "0"
          ],
          "line": 1961
        },
        "resolved": true,
        "details": {
          "function_name": "prb_rec_init_rd",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.h",
          "lines": "330-337",
          "snippet": "static inline void prb_rec_init_rd(struct printk_record *r,\n\t\t\t\t   struct printk_info *info,\n\t\t\t\t   char *text_buf, unsigned int text_buf_size)\n{\n\tr->info = info;\n\tr->text_buf = text_buf;\n\tr->text_buf_size = text_buf_size;\n}",
          "includes": [
            "#include <linux/dev_printk.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/dev_printk.h>\n#include <linux/atomic.h>\n\nstatic inline void prb_rec_init_rd(struct printk_record *r,\n\t\t\t\t   struct printk_info *info,\n\t\t\t\t   char *text_buf, unsigned int text_buf_size)\n{\n\tr->info = info;\n\tr->text_buf = text_buf;\n\tr->text_buf_size = text_buf_size;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nbool prb_read_valid_info(struct printk_ringbuffer *rb, u64 seq,\n\t\t\t struct printk_info *info, unsigned int *line_count)\n{\n\tstruct printk_record r;\n\n\tprb_rec_init_rd(&r, info, NULL, 0);\n\n\treturn _prb_read_valid(rb, &seq, &r, line_count);\n}"
  },
  {
    "function_name": "prb_read_valid",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1926-1930",
    "snippet": "bool prb_read_valid(struct printk_ringbuffer *rb, u64 seq,\n\t\t    struct printk_record *r)\n{\n\treturn _prb_read_valid(rb, &seq, r, NULL);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_prb_read_valid",
          "args": [
            "rb",
            "&seq",
            "r",
            "NULL"
          ],
          "line": 1929
        },
        "resolved": true,
        "details": {
          "function_name": "_prb_read_valid",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1874-1901",
          "snippet": "static bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nbool prb_read_valid(struct printk_ringbuffer *rb, u64 seq,\n\t\t    struct printk_record *r)\n{\n\treturn _prb_read_valid(rb, &seq, r, NULL);\n}"
  },
  {
    "function_name": "_prb_read_valid",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1874-1901",
    "snippet": "static bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "prb_first_seq",
          "args": [
            "rb"
          ],
          "line": 1881
        },
        "resolved": true,
        "details": {
          "function_name": "prb_first_seq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1824-1865",
          "snippet": "static u64 prb_first_seq(struct printk_ringbuffer *rb)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tunsigned long id;\n\tu64 seq;\n\n\tfor (;;) {\n\t\tid = atomic_long_read(&rb->desc_ring.tail_id); /* LMM(prb_first_seq:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc, &seq, NULL); /* LMM(prb_first_seq:B) */\n\n\t\t/*\n\t\t * This loop will not be infinite because the tail is\n\t\t * _always_ in the finalized or reusable state.\n\t\t */\n\t\tif (d_state == desc_finalized || d_state == desc_reusable)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail in the case\n\t\t * that the descriptor has been recycled. This pairs with\n\t\t * desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If prb_first_seq:B reads from desc_reserve:F, then\n\t\t * prb_first_seq:A reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB prb_first_seq:B to prb_first_seq:A\n\t\t */\n\t\tsmp_rmb(); /* LMM(prb_first_seq:C) */\n\t}\n\n\treturn seq;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic u64 prb_first_seq(struct printk_ringbuffer *rb)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tunsigned long id;\n\tu64 seq;\n\n\tfor (;;) {\n\t\tid = atomic_long_read(&rb->desc_ring.tail_id); /* LMM(prb_first_seq:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc, &seq, NULL); /* LMM(prb_first_seq:B) */\n\n\t\t/*\n\t\t * This loop will not be infinite because the tail is\n\t\t * _always_ in the finalized or reusable state.\n\t\t */\n\t\tif (d_state == desc_finalized || d_state == desc_reusable)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail in the case\n\t\t * that the descriptor has been recycled. This pairs with\n\t\t * desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If prb_first_seq:B reads from desc_reserve:F, then\n\t\t * prb_first_seq:A reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB prb_first_seq:B to prb_first_seq:A\n\t\t */\n\t\tsmp_rmb(); /* LMM(prb_first_seq:C) */\n\t}\n\n\treturn seq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "prb_read",
          "args": [
            "rb",
            "*seq",
            "r",
            "line_count"
          ],
          "line": 1880
        },
        "resolved": true,
        "details": {
          "function_name": "prb_read_valid_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1956-1964",
          "snippet": "bool prb_read_valid_info(struct printk_ringbuffer *rb, u64 seq,\n\t\t\t struct printk_info *info, unsigned int *line_count)\n{\n\tstruct printk_record r;\n\n\tprb_rec_init_rd(&r, info, NULL, 0);\n\n\treturn _prb_read_valid(rb, &seq, &r, line_count);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nbool prb_read_valid_info(struct printk_ringbuffer *rb, u64 seq,\n\t\t\t struct printk_info *info, unsigned int *line_count)\n{\n\tstruct printk_record r;\n\n\tprb_rec_init_rd(&r, info, NULL, 0);\n\n\treturn _prb_read_valid(rb, &seq, &r, line_count);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool _prb_read_valid(struct printk_ringbuffer *rb, u64 *seq,\n\t\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tu64 tail_seq;\n\tint err;\n\n\twhile ((err = prb_read(rb, *seq, r, line_count))) {\n\t\ttail_seq = prb_first_seq(rb);\n\n\t\tif (*seq < tail_seq) {\n\t\t\t/*\n\t\t\t * Behind the tail. Catch up and try again. This\n\t\t\t * can happen for -ENOENT and -EINVAL cases.\n\t\t\t */\n\t\t\t*seq = tail_seq;\n\n\t\t} else if (err == -ENOENT) {\n\t\t\t/* Record exists, but no data available. Skip. */\n\t\t\t(*seq)++;\n\n\t\t} else {\n\t\t\t/* Non-existent/non-finalized record. Must stop. */\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}"
  },
  {
    "function_name": "prb_first_seq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1824-1865",
    "snippet": "static u64 prb_first_seq(struct printk_ringbuffer *rb)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tunsigned long id;\n\tu64 seq;\n\n\tfor (;;) {\n\t\tid = atomic_long_read(&rb->desc_ring.tail_id); /* LMM(prb_first_seq:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc, &seq, NULL); /* LMM(prb_first_seq:B) */\n\n\t\t/*\n\t\t * This loop will not be infinite because the tail is\n\t\t * _always_ in the finalized or reusable state.\n\t\t */\n\t\tif (d_state == desc_finalized || d_state == desc_reusable)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail in the case\n\t\t * that the descriptor has been recycled. This pairs with\n\t\t * desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If prb_first_seq:B reads from desc_reserve:F, then\n\t\t * prb_first_seq:A reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB prb_first_seq:B to prb_first_seq:A\n\t\t */\n\t\tsmp_rmb(); /* LMM(prb_first_seq:C) */\n\t}\n\n\treturn seq;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 1861
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "desc_read",
          "args": [
            "desc_ring",
            "id",
            "&desc",
            "&seq",
            "NULL"
          ],
          "line": 1835
        },
        "resolved": true,
        "details": {
          "function_name": "desc_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "432-533",
          "snippet": "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&rb->desc_ring.tail_id"
          ],
          "line": 1833
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic u64 prb_first_seq(struct printk_ringbuffer *rb)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tunsigned long id;\n\tu64 seq;\n\n\tfor (;;) {\n\t\tid = atomic_long_read(&rb->desc_ring.tail_id); /* LMM(prb_first_seq:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc, &seq, NULL); /* LMM(prb_first_seq:B) */\n\n\t\t/*\n\t\t * This loop will not be infinite because the tail is\n\t\t * _always_ in the finalized or reusable state.\n\t\t */\n\t\tif (d_state == desc_finalized || d_state == desc_reusable)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail in the case\n\t\t * that the descriptor has been recycled. This pairs with\n\t\t * desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If prb_first_seq:B reads from desc_reserve:F, then\n\t\t * prb_first_seq:A reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB prb_first_seq:B to prb_first_seq:A\n\t\t */\n\t\tsmp_rmb(); /* LMM(prb_first_seq:C) */\n\t}\n\n\treturn seq;\n}"
  },
  {
    "function_name": "prb_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1785-1821",
    "snippet": "static int prb_read(struct printk_ringbuffer *rb, u64 seq,\n\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct printk_info *info = to_info(desc_ring, seq);\n\tstruct prb_desc *rdesc = to_desc(desc_ring, seq);\n\tatomic_long_t *state_var = &rdesc->state_var;\n\tstruct prb_desc desc;\n\tunsigned long id;\n\tint err;\n\n\t/* Extract the ID, used to specify the descriptor to read. */\n\tid = DESC_ID(atomic_long_read(state_var));\n\n\t/* Get a local copy of the correct descriptor (if available). */\n\terr = desc_read_finalized_seq(desc_ring, id, seq, &desc);\n\n\t/*\n\t * If @r is NULL, the caller is only interested in the availability\n\t * of the record.\n\t */\n\tif (err || !r)\n\t\treturn err;\n\n\t/* If requested, copy meta data. */\n\tif (r->info)\n\t\tmemcpy(r->info, info, sizeof(*(r->info)));\n\n\t/* Copy text data. If it fails, this is a data-less record. */\n\tif (!copy_data(&rb->text_data_ring, &desc.text_blk_lpos, info->text_len,\n\t\t       r->text_buf, r->text_buf_size, line_count)) {\n\t\treturn -ENOENT;\n\t}\n\n\t/* Ensure the record is still finalized and has the same @seq. */\n\treturn desc_read_finalized_seq(desc_ring, id, seq, &desc);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "desc_read_finalized_seq",
          "args": [
            "desc_ring",
            "id",
            "seq",
            "&desc"
          ],
          "line": 1820
        },
        "resolved": true,
        "details": {
          "function_name": "desc_read_finalized_seq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1744-1777",
          "snippet": "static int desc_read_finalized_seq(struct prb_desc_ring *desc_ring,\n\t\t\t\t   unsigned long id, u64 seq,\n\t\t\t\t   struct prb_desc *desc_out)\n{\n\tstruct prb_data_blk_lpos *blk_lpos = &desc_out->text_blk_lpos;\n\tenum desc_state d_state;\n\tu64 s;\n\n\td_state = desc_read(desc_ring, id, desc_out, &s, NULL);\n\n\t/*\n\t * An unexpected @id (desc_miss) or @seq mismatch means the record\n\t * does not exist. A descriptor in the reserved or committed state\n\t * means the record does not yet exist for the reader.\n\t */\n\tif (d_state == desc_miss ||\n\t    d_state == desc_reserved ||\n\t    d_state == desc_committed ||\n\t    s != seq) {\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * A descriptor in the reusable state may no longer have its data\n\t * available; report it as existing but with lost data. Or the record\n\t * may actually be a record with lost data.\n\t */\n\tif (d_state == desc_reusable ||\n\t    (blk_lpos->begin == FAILED_LPOS && blk_lpos->next == FAILED_LPOS)) {\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic int desc_read_finalized_seq(struct prb_desc_ring *desc_ring,\n\t\t\t\t   unsigned long id, u64 seq,\n\t\t\t\t   struct prb_desc *desc_out)\n{\n\tstruct prb_data_blk_lpos *blk_lpos = &desc_out->text_blk_lpos;\n\tenum desc_state d_state;\n\tu64 s;\n\n\td_state = desc_read(desc_ring, id, desc_out, &s, NULL);\n\n\t/*\n\t * An unexpected @id (desc_miss) or @seq mismatch means the record\n\t * does not exist. A descriptor in the reserved or committed state\n\t * means the record does not yet exist for the reader.\n\t */\n\tif (d_state == desc_miss ||\n\t    d_state == desc_reserved ||\n\t    d_state == desc_committed ||\n\t    s != seq) {\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * A descriptor in the reusable state may no longer have its data\n\t * available; report it as existing but with lost data. Or the record\n\t * may actually be a record with lost data.\n\t */\n\tif (d_state == desc_reusable ||\n\t    (blk_lpos->begin == FAILED_LPOS && blk_lpos->next == FAILED_LPOS)) {\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_data",
          "args": [
            "&rb->text_data_ring",
            "&desc.text_blk_lpos",
            "info->text_len",
            "r->text_buf",
            "r->text_buf_size",
            "line_count"
          ],
          "line": 1814
        },
        "resolved": true,
        "details": {
          "function_name": "copy_data",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1694-1731",
          "snippet": "static bool copy_data(struct prb_data_ring *data_ring,\n\t\t      struct prb_data_blk_lpos *blk_lpos, u16 len, char *buf,\n\t\t      unsigned int buf_size, unsigned int *line_count)\n{\n\tunsigned int data_size;\n\tconst char *data;\n\n\t/* Caller might not want any data. */\n\tif ((!buf || !buf_size) && !line_count)\n\t\treturn true;\n\n\tdata = get_data(data_ring, blk_lpos, &data_size);\n\tif (!data)\n\t\treturn false;\n\n\t/*\n\t * Actual cannot be less than expected. It can be more than expected\n\t * because of the trailing alignment padding.\n\t *\n\t * Note that invalid @len values can occur because the caller loads\n\t * the value during an allowed data race.\n\t */\n\tif (data_size < (unsigned int)len)\n\t\treturn false;\n\n\t/* Caller interested in the line count? */\n\tif (line_count)\n\t\t*line_count = count_lines(data, len);\n\n\t/* Caller interested in the data content? */\n\tif (!buf || !buf_size)\n\t\treturn true;\n\n\tdata_size = min_t(u16, buf_size, len);\n\n\tmemcpy(&buf[0], data, data_size); /* LMM(copy_data:A) */\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool copy_data(struct prb_data_ring *data_ring,\n\t\t      struct prb_data_blk_lpos *blk_lpos, u16 len, char *buf,\n\t\t      unsigned int buf_size, unsigned int *line_count)\n{\n\tunsigned int data_size;\n\tconst char *data;\n\n\t/* Caller might not want any data. */\n\tif ((!buf || !buf_size) && !line_count)\n\t\treturn true;\n\n\tdata = get_data(data_ring, blk_lpos, &data_size);\n\tif (!data)\n\t\treturn false;\n\n\t/*\n\t * Actual cannot be less than expected. It can be more than expected\n\t * because of the trailing alignment padding.\n\t *\n\t * Note that invalid @len values can occur because the caller loads\n\t * the value during an allowed data race.\n\t */\n\tif (data_size < (unsigned int)len)\n\t\treturn false;\n\n\t/* Caller interested in the line count? */\n\tif (line_count)\n\t\t*line_count = count_lines(data, len);\n\n\t/* Caller interested in the data content? */\n\tif (!buf || !buf_size)\n\t\treturn true;\n\n\tdata_size = min_t(u16, buf_size, len);\n\n\tmemcpy(&buf[0], data, data_size); /* LMM(copy_data:A) */\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "r->info",
            "info",
            "sizeof(*(r->info))"
          ],
          "line": 1811
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "atomic_long_read(state_var)"
          ],
          "line": 1797
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "state_var"
          ],
          "line": 1797
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "seq"
          ],
          "line": 1790
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_info",
          "args": [
            "desc_ring",
            "seq"
          ],
          "line": 1789
        },
        "resolved": true,
        "details": {
          "function_name": "to_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "364-367",
          "snippet": "static struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic int prb_read(struct printk_ringbuffer *rb, u64 seq,\n\t\t    struct printk_record *r, unsigned int *line_count)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct printk_info *info = to_info(desc_ring, seq);\n\tstruct prb_desc *rdesc = to_desc(desc_ring, seq);\n\tatomic_long_t *state_var = &rdesc->state_var;\n\tstruct prb_desc desc;\n\tunsigned long id;\n\tint err;\n\n\t/* Extract the ID, used to specify the descriptor to read. */\n\tid = DESC_ID(atomic_long_read(state_var));\n\n\t/* Get a local copy of the correct descriptor (if available). */\n\terr = desc_read_finalized_seq(desc_ring, id, seq, &desc);\n\n\t/*\n\t * If @r is NULL, the caller is only interested in the availability\n\t * of the record.\n\t */\n\tif (err || !r)\n\t\treturn err;\n\n\t/* If requested, copy meta data. */\n\tif (r->info)\n\t\tmemcpy(r->info, info, sizeof(*(r->info)));\n\n\t/* Copy text data. If it fails, this is a data-less record. */\n\tif (!copy_data(&rb->text_data_ring, &desc.text_blk_lpos, info->text_len,\n\t\t       r->text_buf, r->text_buf_size, line_count)) {\n\t\treturn -ENOENT;\n\t}\n\n\t/* Ensure the record is still finalized and has the same @seq. */\n\treturn desc_read_finalized_seq(desc_ring, id, seq, &desc);\n}"
  },
  {
    "function_name": "desc_read_finalized_seq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1744-1777",
    "snippet": "static int desc_read_finalized_seq(struct prb_desc_ring *desc_ring,\n\t\t\t\t   unsigned long id, u64 seq,\n\t\t\t\t   struct prb_desc *desc_out)\n{\n\tstruct prb_data_blk_lpos *blk_lpos = &desc_out->text_blk_lpos;\n\tenum desc_state d_state;\n\tu64 s;\n\n\td_state = desc_read(desc_ring, id, desc_out, &s, NULL);\n\n\t/*\n\t * An unexpected @id (desc_miss) or @seq mismatch means the record\n\t * does not exist. A descriptor in the reserved or committed state\n\t * means the record does not yet exist for the reader.\n\t */\n\tif (d_state == desc_miss ||\n\t    d_state == desc_reserved ||\n\t    d_state == desc_committed ||\n\t    s != seq) {\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * A descriptor in the reusable state may no longer have its data\n\t * available; report it as existing but with lost data. Or the record\n\t * may actually be a record with lost data.\n\t */\n\tif (d_state == desc_reusable ||\n\t    (blk_lpos->begin == FAILED_LPOS && blk_lpos->next == FAILED_LPOS)) {\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "desc_read",
          "args": [
            "desc_ring",
            "id",
            "desc_out",
            "&s",
            "NULL"
          ],
          "line": 1752
        },
        "resolved": true,
        "details": {
          "function_name": "desc_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "432-533",
          "snippet": "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic int desc_read_finalized_seq(struct prb_desc_ring *desc_ring,\n\t\t\t\t   unsigned long id, u64 seq,\n\t\t\t\t   struct prb_desc *desc_out)\n{\n\tstruct prb_data_blk_lpos *blk_lpos = &desc_out->text_blk_lpos;\n\tenum desc_state d_state;\n\tu64 s;\n\n\td_state = desc_read(desc_ring, id, desc_out, &s, NULL);\n\n\t/*\n\t * An unexpected @id (desc_miss) or @seq mismatch means the record\n\t * does not exist. A descriptor in the reserved or committed state\n\t * means the record does not yet exist for the reader.\n\t */\n\tif (d_state == desc_miss ||\n\t    d_state == desc_reserved ||\n\t    d_state == desc_committed ||\n\t    s != seq) {\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * A descriptor in the reusable state may no longer have its data\n\t * available; report it as existing but with lost data. Or the record\n\t * may actually be a record with lost data.\n\t */\n\tif (d_state == desc_reusable ||\n\t    (blk_lpos->begin == FAILED_LPOS && blk_lpos->next == FAILED_LPOS)) {\n\t\treturn -ENOENT;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "copy_data",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1694-1731",
    "snippet": "static bool copy_data(struct prb_data_ring *data_ring,\n\t\t      struct prb_data_blk_lpos *blk_lpos, u16 len, char *buf,\n\t\t      unsigned int buf_size, unsigned int *line_count)\n{\n\tunsigned int data_size;\n\tconst char *data;\n\n\t/* Caller might not want any data. */\n\tif ((!buf || !buf_size) && !line_count)\n\t\treturn true;\n\n\tdata = get_data(data_ring, blk_lpos, &data_size);\n\tif (!data)\n\t\treturn false;\n\n\t/*\n\t * Actual cannot be less than expected. It can be more than expected\n\t * because of the trailing alignment padding.\n\t *\n\t * Note that invalid @len values can occur because the caller loads\n\t * the value during an allowed data race.\n\t */\n\tif (data_size < (unsigned int)len)\n\t\treturn false;\n\n\t/* Caller interested in the line count? */\n\tif (line_count)\n\t\t*line_count = count_lines(data, len);\n\n\t/* Caller interested in the data content? */\n\tif (!buf || !buf_size)\n\t\treturn true;\n\n\tdata_size = min_t(u16, buf_size, len);\n\n\tmemcpy(&buf[0], data, data_size); /* LMM(copy_data:A) */\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "&buf[0]",
            "data",
            "data_size"
          ],
          "line": 1729
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "min_t",
          "args": [
            "u16",
            "buf_size",
            "len"
          ],
          "line": 1727
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "count_lines",
          "args": [
            "data",
            "len"
          ],
          "line": 1721
        },
        "resolved": true,
        "details": {
          "function_name": "count_lines",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1668-1684",
          "snippet": "static unsigned int count_lines(const char *text, unsigned int text_size)\n{\n\tunsigned int next_size = text_size;\n\tunsigned int line_count = 1;\n\tconst char *next = text;\n\n\twhile (next_size) {\n\t\tnext = memchr(next, '\\n', next_size);\n\t\tif (!next)\n\t\t\tbreak;\n\t\tline_count++;\n\t\tnext++;\n\t\tnext_size = text_size - (next - text);\n\t}\n\n\treturn line_count;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int count_lines(const char *text, unsigned int text_size)\n{\n\tunsigned int next_size = text_size;\n\tunsigned int line_count = 1;\n\tconst char *next = text;\n\n\twhile (next_size) {\n\t\tnext = memchr(next, '\\n', next_size);\n\t\tif (!next)\n\t\t\tbreak;\n\t\tline_count++;\n\t\tnext++;\n\t\tnext_size = text_size - (next - text);\n\t}\n\n\treturn line_count;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_data",
          "args": [
            "data_ring",
            "blk_lpos",
            "&data_size"
          ],
          "line": 1705
        },
        "resolved": true,
        "details": {
          "function_name": "get_data",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1202-1249",
          "snippet": "static const char *get_data(struct prb_data_ring *data_ring,\n\t\t\t    struct prb_data_blk_lpos *blk_lpos,\n\t\t\t    unsigned int *data_size)\n{\n\tstruct prb_data_block *db;\n\n\t/* Data-less data block description. */\n\tif (BLK_DATALESS(blk_lpos)) {\n\t\tif (blk_lpos->begin == NO_LPOS && blk_lpos->next == NO_LPOS) {\n\t\t\t*data_size = 0;\n\t\t\treturn \"\";\n\t\t}\n\t\treturn NULL;\n\t}\n\n\t/* Regular data block: @begin less than @next and in same wrap. */\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next) &&\n\t    blk_lpos->begin < blk_lpos->next) {\n\t\tdb = to_block(data_ring, blk_lpos->begin);\n\t\t*data_size = blk_lpos->next - blk_lpos->begin;\n\n\t/* Wrapping data block: @begin is one wrap behind @next. */\n\t} else if (DATA_WRAPS(data_ring, blk_lpos->begin + DATA_SIZE(data_ring)) ==\n\t\t   DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\tdb = to_block(data_ring, 0);\n\t\t*data_size = DATA_INDEX(data_ring, blk_lpos->next);\n\n\t/* Illegal block description. */\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always be aligned to the ID size. */\n\tif (WARN_ON_ONCE(blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))) ||\n\t    WARN_ON_ONCE(blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id)))) {\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always have at least an ID. */\n\tif (WARN_ON_ONCE(*data_size < sizeof(db->id)))\n\t\treturn NULL;\n\n\t/* Subtract block ID space from size to reflect data size. */\n\t*data_size -= sizeof(db->id);\n\n\treturn &db->data[0];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic const char *get_data(struct prb_data_ring *data_ring,\n\t\t\t    struct prb_data_blk_lpos *blk_lpos,\n\t\t\t    unsigned int *data_size)\n{\n\tstruct prb_data_block *db;\n\n\t/* Data-less data block description. */\n\tif (BLK_DATALESS(blk_lpos)) {\n\t\tif (blk_lpos->begin == NO_LPOS && blk_lpos->next == NO_LPOS) {\n\t\t\t*data_size = 0;\n\t\t\treturn \"\";\n\t\t}\n\t\treturn NULL;\n\t}\n\n\t/* Regular data block: @begin less than @next and in same wrap. */\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next) &&\n\t    blk_lpos->begin < blk_lpos->next) {\n\t\tdb = to_block(data_ring, blk_lpos->begin);\n\t\t*data_size = blk_lpos->next - blk_lpos->begin;\n\n\t/* Wrapping data block: @begin is one wrap behind @next. */\n\t} else if (DATA_WRAPS(data_ring, blk_lpos->begin + DATA_SIZE(data_ring)) ==\n\t\t   DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\tdb = to_block(data_ring, 0);\n\t\t*data_size = DATA_INDEX(data_ring, blk_lpos->next);\n\n\t/* Illegal block description. */\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always be aligned to the ID size. */\n\tif (WARN_ON_ONCE(blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))) ||\n\t    WARN_ON_ONCE(blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id)))) {\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always have at least an ID. */\n\tif (WARN_ON_ONCE(*data_size < sizeof(db->id)))\n\t\treturn NULL;\n\n\t/* Subtract block ID space from size to reflect data size. */\n\t*data_size -= sizeof(db->id);\n\n\treturn &db->data[0];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool copy_data(struct prb_data_ring *data_ring,\n\t\t      struct prb_data_blk_lpos *blk_lpos, u16 len, char *buf,\n\t\t      unsigned int buf_size, unsigned int *line_count)\n{\n\tunsigned int data_size;\n\tconst char *data;\n\n\t/* Caller might not want any data. */\n\tif ((!buf || !buf_size) && !line_count)\n\t\treturn true;\n\n\tdata = get_data(data_ring, blk_lpos, &data_size);\n\tif (!data)\n\t\treturn false;\n\n\t/*\n\t * Actual cannot be less than expected. It can be more than expected\n\t * because of the trailing alignment padding.\n\t *\n\t * Note that invalid @len values can occur because the caller loads\n\t * the value during an allowed data race.\n\t */\n\tif (data_size < (unsigned int)len)\n\t\treturn false;\n\n\t/* Caller interested in the line count? */\n\tif (line_count)\n\t\t*line_count = count_lines(data, len);\n\n\t/* Caller interested in the data content? */\n\tif (!buf || !buf_size)\n\t\treturn true;\n\n\tdata_size = min_t(u16, buf_size, len);\n\n\tmemcpy(&buf[0], data, data_size); /* LMM(copy_data:A) */\n\treturn true;\n}"
  },
  {
    "function_name": "count_lines",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1668-1684",
    "snippet": "static unsigned int count_lines(const char *text, unsigned int text_size)\n{\n\tunsigned int next_size = text_size;\n\tunsigned int line_count = 1;\n\tconst char *next = text;\n\n\twhile (next_size) {\n\t\tnext = memchr(next, '\\n', next_size);\n\t\tif (!next)\n\t\t\tbreak;\n\t\tline_count++;\n\t\tnext++;\n\t\tnext_size = text_size - (next - text);\n\t}\n\n\treturn line_count;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memchr",
          "args": [
            "next",
            "'\\n'",
            "next_size"
          ],
          "line": 1675
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int count_lines(const char *text, unsigned int text_size)\n{\n\tunsigned int next_size = text_size;\n\tunsigned int line_count = 1;\n\tconst char *next = text;\n\n\twhile (next_size) {\n\t\tnext = memchr(next, '\\n', next_size);\n\t\tif (!next)\n\t\t\tbreak;\n\t\tline_count++;\n\t\tnext++;\n\t\tnext_size = text_size - (next - text);\n\t}\n\n\treturn line_count;\n}"
  },
  {
    "function_name": "prb_final_commit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1658-1661",
    "snippet": "void prb_final_commit(struct prb_reserved_entry *e)\n{\n\t_prb_commit(e, desc_finalized);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_prb_commit",
          "args": [
            "e",
            "desc_finalized"
          ],
          "line": 1660
        },
        "resolved": true,
        "details": {
          "function_name": "_prb_commit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1570-1608",
          "snippet": "static void _prb_commit(struct prb_reserved_entry *e, unsigned long state_val)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tstruct prb_desc *d = to_desc(desc_ring, e->id);\n\tunsigned long prev_state_val = DESC_SV(e->id, desc_reserved);\n\n\t/* Now the writer has finished all writing: LMM(_prb_commit:A) */\n\n\t/*\n\t * Set the descriptor as committed. See \"ABA Issues\" about why\n\t * cmpxchg() instead of set() is used.\n\t *\n\t * 1  Guarantee all record data is stored before the descriptor state\n\t *    is stored as committed. A write memory barrier is sufficient\n\t *    for this. This pairs with desc_read:B and desc_reopen_last:A.\n\t *\n\t * 2. Guarantee the descriptor state is stored as committed before\n\t *    re-checking the head ID in order to possibly finalize this\n\t *    descriptor. This pairs with desc_reserve:D.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If prb_commit:A reads from desc_reserve:D, then\n\t *    desc_make_final:A reads from _prb_commit:B.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB _prb_commit:B to prb_commit:A\n\t *       matching\n\t *    MB desc_reserve:D to desc_make_final:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(e->id, state_val))) { /* LMM(_prb_commit:B) */\n\t\tWARN_ON_ONCE(1);\n\t}\n\n\t/* Restore interrupts, the reserve/commit window is finished. */\n\tlocal_irq_restore(e->irqflags);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void _prb_commit(struct prb_reserved_entry *e, unsigned long state_val)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tstruct prb_desc *d = to_desc(desc_ring, e->id);\n\tunsigned long prev_state_val = DESC_SV(e->id, desc_reserved);\n\n\t/* Now the writer has finished all writing: LMM(_prb_commit:A) */\n\n\t/*\n\t * Set the descriptor as committed. See \"ABA Issues\" about why\n\t * cmpxchg() instead of set() is used.\n\t *\n\t * 1  Guarantee all record data is stored before the descriptor state\n\t *    is stored as committed. A write memory barrier is sufficient\n\t *    for this. This pairs with desc_read:B and desc_reopen_last:A.\n\t *\n\t * 2. Guarantee the descriptor state is stored as committed before\n\t *    re-checking the head ID in order to possibly finalize this\n\t *    descriptor. This pairs with desc_reserve:D.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If prb_commit:A reads from desc_reserve:D, then\n\t *    desc_make_final:A reads from _prb_commit:B.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB _prb_commit:B to prb_commit:A\n\t *       matching\n\t *    MB desc_reserve:D to desc_make_final:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(e->id, state_val))) { /* LMM(_prb_commit:B) */\n\t\tWARN_ON_ONCE(1);\n\t}\n\n\t/* Restore interrupts, the reserve/commit window is finished. */\n\tlocal_irq_restore(e->irqflags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nvoid prb_final_commit(struct prb_reserved_entry *e)\n{\n\t_prb_commit(e, desc_finalized);\n}"
  },
  {
    "function_name": "prb_commit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1626-1641",
    "snippet": "void prb_commit(struct prb_reserved_entry *e)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tunsigned long head_id;\n\n\t_prb_commit(e, desc_committed);\n\n\t/*\n\t * If this descriptor is no longer the head (i.e. a new record has\n\t * been allocated), extending the data for this record is no longer\n\t * allowed and therefore it must be finalized.\n\t */\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(prb_commit:A) */\n\tif (head_id != e->id)\n\t\tdesc_make_final(desc_ring, e->id);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "desc_make_final",
          "args": [
            "desc_ring",
            "e->id"
          ],
          "line": 1640
        },
        "resolved": true,
        "details": {
          "function_name": "desc_make_final",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1445-1452",
          "snippet": "static void desc_make_final(struct prb_desc_ring *desc_ring, unsigned long id)\n{\n\tunsigned long prev_state_val = DESC_SV(id, desc_committed);\n\tstruct prb_desc *d = to_desc(desc_ring, id);\n\n\tatomic_long_cmpxchg_relaxed(&d->state_var, prev_state_val,\n\t\t\tDESC_SV(id, desc_finalized)); /* LMM(desc_make_final:A) */\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void desc_make_final(struct prb_desc_ring *desc_ring, unsigned long id)\n{\n\tunsigned long prev_state_val = DESC_SV(id, desc_committed);\n\tstruct prb_desc *d = to_desc(desc_ring, id);\n\n\tatomic_long_cmpxchg_relaxed(&d->state_var, prev_state_val,\n\t\t\tDESC_SV(id, desc_finalized)); /* LMM(desc_make_final:A) */\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc_ring->head_id"
          ],
          "line": 1638
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "_prb_commit",
          "args": [
            "e",
            "desc_committed"
          ],
          "line": 1631
        },
        "resolved": true,
        "details": {
          "function_name": "_prb_commit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1570-1608",
          "snippet": "static void _prb_commit(struct prb_reserved_entry *e, unsigned long state_val)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tstruct prb_desc *d = to_desc(desc_ring, e->id);\n\tunsigned long prev_state_val = DESC_SV(e->id, desc_reserved);\n\n\t/* Now the writer has finished all writing: LMM(_prb_commit:A) */\n\n\t/*\n\t * Set the descriptor as committed. See \"ABA Issues\" about why\n\t * cmpxchg() instead of set() is used.\n\t *\n\t * 1  Guarantee all record data is stored before the descriptor state\n\t *    is stored as committed. A write memory barrier is sufficient\n\t *    for this. This pairs with desc_read:B and desc_reopen_last:A.\n\t *\n\t * 2. Guarantee the descriptor state is stored as committed before\n\t *    re-checking the head ID in order to possibly finalize this\n\t *    descriptor. This pairs with desc_reserve:D.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If prb_commit:A reads from desc_reserve:D, then\n\t *    desc_make_final:A reads from _prb_commit:B.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB _prb_commit:B to prb_commit:A\n\t *       matching\n\t *    MB desc_reserve:D to desc_make_final:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(e->id, state_val))) { /* LMM(_prb_commit:B) */\n\t\tWARN_ON_ONCE(1);\n\t}\n\n\t/* Restore interrupts, the reserve/commit window is finished. */\n\tlocal_irq_restore(e->irqflags);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void _prb_commit(struct prb_reserved_entry *e, unsigned long state_val)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tstruct prb_desc *d = to_desc(desc_ring, e->id);\n\tunsigned long prev_state_val = DESC_SV(e->id, desc_reserved);\n\n\t/* Now the writer has finished all writing: LMM(_prb_commit:A) */\n\n\t/*\n\t * Set the descriptor as committed. See \"ABA Issues\" about why\n\t * cmpxchg() instead of set() is used.\n\t *\n\t * 1  Guarantee all record data is stored before the descriptor state\n\t *    is stored as committed. A write memory barrier is sufficient\n\t *    for this. This pairs with desc_read:B and desc_reopen_last:A.\n\t *\n\t * 2. Guarantee the descriptor state is stored as committed before\n\t *    re-checking the head ID in order to possibly finalize this\n\t *    descriptor. This pairs with desc_reserve:D.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If prb_commit:A reads from desc_reserve:D, then\n\t *    desc_make_final:A reads from _prb_commit:B.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB _prb_commit:B to prb_commit:A\n\t *       matching\n\t *    MB desc_reserve:D to desc_make_final:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(e->id, state_val))) { /* LMM(_prb_commit:B) */\n\t\tWARN_ON_ONCE(1);\n\t}\n\n\t/* Restore interrupts, the reserve/commit window is finished. */\n\tlocal_irq_restore(e->irqflags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nvoid prb_commit(struct prb_reserved_entry *e)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tunsigned long head_id;\n\n\t_prb_commit(e, desc_committed);\n\n\t/*\n\t * If this descriptor is no longer the head (i.e. a new record has\n\t * been allocated), extending the data for this record is no longer\n\t * allowed and therefore it must be finalized.\n\t */\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(prb_commit:A) */\n\tif (head_id != e->id)\n\t\tdesc_make_final(desc_ring, e->id);\n}"
  },
  {
    "function_name": "_prb_commit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1570-1608",
    "snippet": "static void _prb_commit(struct prb_reserved_entry *e, unsigned long state_val)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tstruct prb_desc *d = to_desc(desc_ring, e->id);\n\tunsigned long prev_state_val = DESC_SV(e->id, desc_reserved);\n\n\t/* Now the writer has finished all writing: LMM(_prb_commit:A) */\n\n\t/*\n\t * Set the descriptor as committed. See \"ABA Issues\" about why\n\t * cmpxchg() instead of set() is used.\n\t *\n\t * 1  Guarantee all record data is stored before the descriptor state\n\t *    is stored as committed. A write memory barrier is sufficient\n\t *    for this. This pairs with desc_read:B and desc_reopen_last:A.\n\t *\n\t * 2. Guarantee the descriptor state is stored as committed before\n\t *    re-checking the head ID in order to possibly finalize this\n\t *    descriptor. This pairs with desc_reserve:D.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If prb_commit:A reads from desc_reserve:D, then\n\t *    desc_make_final:A reads from _prb_commit:B.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB _prb_commit:B to prb_commit:A\n\t *       matching\n\t *    MB desc_reserve:D to desc_make_final:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(e->id, state_val))) { /* LMM(_prb_commit:B) */\n\t\tWARN_ON_ONCE(1);\n\t}\n\n\t/* Restore interrupts, the reserve/commit window is finished. */\n\tlocal_irq_restore(e->irqflags);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "e->irqflags"
          ],
          "line": 1607
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "1"
          ],
          "line": 1603
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&d->state_var",
            "&prev_state_val",
            "DESC_SV(e->id, state_val)"
          ],
          "line": 1601
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "e->id",
            "state_val"
          ],
          "line": 1602
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "e->id",
            "desc_reserved"
          ],
          "line": 1574
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "e->id"
          ],
          "line": 1573
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void _prb_commit(struct prb_reserved_entry *e, unsigned long state_val)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tstruct prb_desc *d = to_desc(desc_ring, e->id);\n\tunsigned long prev_state_val = DESC_SV(e->id, desc_reserved);\n\n\t/* Now the writer has finished all writing: LMM(_prb_commit:A) */\n\n\t/*\n\t * Set the descriptor as committed. See \"ABA Issues\" about why\n\t * cmpxchg() instead of set() is used.\n\t *\n\t * 1  Guarantee all record data is stored before the descriptor state\n\t *    is stored as committed. A write memory barrier is sufficient\n\t *    for this. This pairs with desc_read:B and desc_reopen_last:A.\n\t *\n\t * 2. Guarantee the descriptor state is stored as committed before\n\t *    re-checking the head ID in order to possibly finalize this\n\t *    descriptor. This pairs with desc_reserve:D.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If prb_commit:A reads from desc_reserve:D, then\n\t *    desc_make_final:A reads from _prb_commit:B.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB _prb_commit:B to prb_commit:A\n\t *       matching\n\t *    MB desc_reserve:D to desc_make_final:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(e->id, state_val))) { /* LMM(_prb_commit:B) */\n\t\tWARN_ON_ONCE(1);\n\t}\n\n\t/* Restore interrupts, the reserve/commit window is finished. */\n\tlocal_irq_restore(e->irqflags);\n}"
  },
  {
    "function_name": "prb_reserve",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1479-1567",
    "snippet": "bool prb_reserve(struct prb_reserved_entry *e, struct printk_ringbuffer *rb,\n\t\t struct printk_record *r)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct printk_info *info;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\tu64 seq;\n\n\tif (!data_check_size(&rb->text_data_ring, r->text_buf_size))\n\t\tgoto fail;\n\n\t/*\n\t * Descriptors in the reserved state act as blockers to all further\n\t * reservations once the desc_ring has fully wrapped. Disable\n\t * interrupts during the reserve/commit window in order to minimize\n\t * the likelihood of this happening.\n\t */\n\tlocal_irq_save(e->irqflags);\n\n\tif (!desc_reserve(rb, &id)) {\n\t\t/* Descriptor reservation failures are tracked. */\n\t\tatomic_long_inc(&rb->fail);\n\t\tlocal_irq_restore(e->irqflags);\n\t\tgoto fail;\n\t}\n\n\td = to_desc(desc_ring, id);\n\tinfo = to_info(desc_ring, id);\n\n\t/*\n\t * All @info fields (except @seq) are cleared and must be filled in\n\t * by the writer. Save @seq before clearing because it is used to\n\t * determine the new sequence number.\n\t */\n\tseq = info->seq;\n\tmemset(info, 0, sizeof(*info));\n\n\t/*\n\t * Set the @e fields here so that prb_commit() can be used if\n\t * text data allocation fails.\n\t */\n\te->rb = rb;\n\te->id = id;\n\n\t/*\n\t * Initialize the sequence number if it has \"never been set\".\n\t * Otherwise just increment it by a full wrap.\n\t *\n\t * @seq is considered \"never been set\" if it has a value of 0,\n\t * _except_ for @infos[0], which was specially setup by the ringbuffer\n\t * initializer and therefore is always considered as set.\n\t *\n\t * See the \"Bootstrap\" comment block in printk_ringbuffer.h for\n\t * details about how the initializer bootstraps the descriptors.\n\t */\n\tif (seq == 0 && DESC_INDEX(desc_ring, id) != 0)\n\t\tinfo->seq = DESC_INDEX(desc_ring, id);\n\telse\n\t\tinfo->seq = seq + DESCS_COUNT(desc_ring);\n\n\t/*\n\t * New data is about to be reserved. Once that happens, previous\n\t * descriptors are no longer able to be extended. Finalize the\n\t * previous descriptor now so that it can be made available to\n\t * readers. (For seq==0 there is no previous descriptor.)\n\t */\n\tif (info->seq > 0)\n\t\tdesc_make_final(desc_ring, DESC_ID(id - 1));\n\n\tr->text_buf = data_alloc(rb, r->text_buf_size, &d->text_blk_lpos, id);\n\t/* If text data allocation fails, a data-less record is committed. */\n\tif (r->text_buf_size && !r->text_buf) {\n\t\tprb_commit(e);\n\t\t/* prb_commit() re-enabled interrupts. */\n\t\tgoto fail;\n\t}\n\n\tr->info = info;\n\n\t/* Record full text space used by record. */\n\te->text_space = space_used(&rb->text_data_ring, &d->text_blk_lpos);\n\n\treturn true;\nfail:\n\t/* Make it clear to the caller that the reserve failed. */\n\tmemset(r, 0, sizeof(*r));\n\treturn false;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "r",
            "0",
            "sizeof(*r)"
          ],
          "line": 1565
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "space_used",
          "args": [
            "&rb->text_data_ring",
            "&d->text_blk_lpos"
          ],
          "line": 1560
        },
        "resolved": true,
        "details": {
          "function_name": "space_used",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1172-1191",
          "snippet": "static unsigned int space_used(struct prb_data_ring *data_ring,\n\t\t\t       struct prb_data_blk_lpos *blk_lpos)\n{\n\t/* Data-less blocks take no space. */\n\tif (BLK_DATALESS(blk_lpos))\n\t\treturn 0;\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\t/* Data block does not wrap. */\n\t\treturn (DATA_INDEX(data_ring, blk_lpos->next) -\n\t\t\tDATA_INDEX(data_ring, blk_lpos->begin));\n\t}\n\n\t/*\n\t * For wrapping data blocks, the trailing (wasted) space is\n\t * also counted.\n\t */\n\treturn (DATA_INDEX(data_ring, blk_lpos->next) +\n\t\tDATA_SIZE(data_ring) - DATA_INDEX(data_ring, blk_lpos->begin));\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int space_used(struct prb_data_ring *data_ring,\n\t\t\t       struct prb_data_blk_lpos *blk_lpos)\n{\n\t/* Data-less blocks take no space. */\n\tif (BLK_DATALESS(blk_lpos))\n\t\treturn 0;\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\t/* Data block does not wrap. */\n\t\treturn (DATA_INDEX(data_ring, blk_lpos->next) -\n\t\t\tDATA_INDEX(data_ring, blk_lpos->begin));\n\t}\n\n\t/*\n\t * For wrapping data blocks, the trailing (wasted) space is\n\t * also counted.\n\t */\n\treturn (DATA_INDEX(data_ring, blk_lpos->next) +\n\t\tDATA_SIZE(data_ring) - DATA_INDEX(data_ring, blk_lpos->begin));\n}"
        }
      },
      {
        "call_info": {
          "callee": "prb_commit",
          "args": [
            "e"
          ],
          "line": 1552
        },
        "resolved": true,
        "details": {
          "function_name": "prb_commit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1626-1641",
          "snippet": "void prb_commit(struct prb_reserved_entry *e)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tunsigned long head_id;\n\n\t_prb_commit(e, desc_committed);\n\n\t/*\n\t * If this descriptor is no longer the head (i.e. a new record has\n\t * been allocated), extending the data for this record is no longer\n\t * allowed and therefore it must be finalized.\n\t */\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(prb_commit:A) */\n\tif (head_id != e->id)\n\t\tdesc_make_final(desc_ring, e->id);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nvoid prb_commit(struct prb_reserved_entry *e)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tunsigned long head_id;\n\n\t_prb_commit(e, desc_committed);\n\n\t/*\n\t * If this descriptor is no longer the head (i.e. a new record has\n\t * been allocated), extending the data for this record is no longer\n\t * allowed and therefore it must be finalized.\n\t */\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(prb_commit:A) */\n\tif (head_id != e->id)\n\t\tdesc_make_final(desc_ring, e->id);\n}"
        }
      },
      {
        "call_info": {
          "callee": "data_alloc",
          "args": [
            "rb",
            "r->text_buf_size",
            "&d->text_blk_lpos",
            "id"
          ],
          "line": 1549
        },
        "resolved": true,
        "details": {
          "function_name": "data_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1021-1088",
          "snippet": "static char *data_alloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\tstruct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tif (size == 0) {\n\t\t/* Specify a data-less block. */\n\t\tblk_lpos->begin = NO_LPOS;\n\t\tblk_lpos->next = NO_LPOS;\n\t\treturn NULL;\n\t}\n\n\tsize = to_blk_size(size);\n\n\tbegin_lpos = atomic_long_read(&data_ring->head_lpos);\n\n\tdo {\n\t\tnext_lpos = get_next_lpos(data_ring, begin_lpos, size);\n\n\t\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring))) {\n\t\t\t/* Failed to allocate, specify a data-less block. */\n\t\t\tblk_lpos->begin = FAILED_LPOS;\n\t\t\tblk_lpos->next = FAILED_LPOS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee any descriptor states that have transitioned\n\t\t *    to reusable are stored before modifying the newly\n\t\t *    allocated data area. A full memory barrier is needed\n\t\t *    since other CPUs may have made the descriptor states\n\t\t *    reusable. See data_push_tail:A about why the reusable\n\t\t *    states are visible. This pairs with desc_read:D.\n\t\t *\n\t\t * 2. Guarantee any updated tail lpos is stored before\n\t\t *    modifying the newly allocated data area. Another CPU may\n\t\t *    be in data_make_reusable() and is reading a block ID\n\t\t *    from this area. data_make_reusable() can handle reading\n\t\t *    a garbage block ID value, but then it must be able to\n\t\t *    load a new tail lpos. A full memory barrier is needed\n\t\t *    since other CPUs may have updated the tail lpos. This\n\t\t *    pairs with data_push_tail:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &begin_lpos,\n\t\t\t\t\t  next_lpos)); /* LMM(data_alloc:A) */\n\n\tblk = to_block(data_ring, begin_lpos);\n\tblk->id = id; /* LMM(data_alloc:B) */\n\n\tif (DATA_WRAPS(data_ring, begin_lpos) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\t}\n\n\tblk_lpos->begin = begin_lpos;\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic char *data_alloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\tstruct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tif (size == 0) {\n\t\t/* Specify a data-less block. */\n\t\tblk_lpos->begin = NO_LPOS;\n\t\tblk_lpos->next = NO_LPOS;\n\t\treturn NULL;\n\t}\n\n\tsize = to_blk_size(size);\n\n\tbegin_lpos = atomic_long_read(&data_ring->head_lpos);\n\n\tdo {\n\t\tnext_lpos = get_next_lpos(data_ring, begin_lpos, size);\n\n\t\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring))) {\n\t\t\t/* Failed to allocate, specify a data-less block. */\n\t\t\tblk_lpos->begin = FAILED_LPOS;\n\t\t\tblk_lpos->next = FAILED_LPOS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee any descriptor states that have transitioned\n\t\t *    to reusable are stored before modifying the newly\n\t\t *    allocated data area. A full memory barrier is needed\n\t\t *    since other CPUs may have made the descriptor states\n\t\t *    reusable. See data_push_tail:A about why the reusable\n\t\t *    states are visible. This pairs with desc_read:D.\n\t\t *\n\t\t * 2. Guarantee any updated tail lpos is stored before\n\t\t *    modifying the newly allocated data area. Another CPU may\n\t\t *    be in data_make_reusable() and is reading a block ID\n\t\t *    from this area. data_make_reusable() can handle reading\n\t\t *    a garbage block ID value, but then it must be able to\n\t\t *    load a new tail lpos. A full memory barrier is needed\n\t\t *    since other CPUs may have updated the tail lpos. This\n\t\t *    pairs with data_push_tail:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &begin_lpos,\n\t\t\t\t\t  next_lpos)); /* LMM(data_alloc:A) */\n\n\tblk = to_block(data_ring, begin_lpos);\n\tblk->id = id; /* LMM(data_alloc:B) */\n\n\tif (DATA_WRAPS(data_ring, begin_lpos) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\t}\n\n\tblk_lpos->begin = begin_lpos;\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}"
        }
      },
      {
        "call_info": {
          "callee": "desc_make_final",
          "args": [
            "desc_ring",
            "DESC_ID(id - 1)"
          ],
          "line": 1547
        },
        "resolved": true,
        "details": {
          "function_name": "desc_make_final",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1445-1452",
          "snippet": "static void desc_make_final(struct prb_desc_ring *desc_ring, unsigned long id)\n{\n\tunsigned long prev_state_val = DESC_SV(id, desc_committed);\n\tstruct prb_desc *d = to_desc(desc_ring, id);\n\n\tatomic_long_cmpxchg_relaxed(&d->state_var, prev_state_val,\n\t\t\tDESC_SV(id, desc_finalized)); /* LMM(desc_make_final:A) */\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void desc_make_final(struct prb_desc_ring *desc_ring, unsigned long id)\n{\n\tunsigned long prev_state_val = DESC_SV(id, desc_committed);\n\tstruct prb_desc *d = to_desc(desc_ring, id);\n\n\tatomic_long_cmpxchg_relaxed(&d->state_var, prev_state_val,\n\t\t\tDESC_SV(id, desc_finalized)); /* LMM(desc_make_final:A) */\n}"
        }
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "id - 1"
          ],
          "line": 1547
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESCS_COUNT",
          "args": [
            "desc_ring"
          ],
          "line": 1538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_INDEX",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1536
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_INDEX",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1535
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "info",
            "0",
            "sizeof(*info)"
          ],
          "line": 1515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_info",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1507
        },
        "resolved": true,
        "details": {
          "function_name": "to_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "364-367",
          "snippet": "static struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1506
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "e->irqflags"
          ],
          "line": 1502
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_inc",
          "args": [
            "&rb->fail"
          ],
          "line": 1501
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "desc_reserve",
          "args": [
            "rb",
            "&id"
          ],
          "line": 1499
        },
        "resolved": true,
        "details": {
          "function_name": "desc_reserve",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "872-996",
          "snippet": "static bool desc_reserve(struct printk_ringbuffer *rb, unsigned long *id_out)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tunsigned long prev_state_val;\n\tunsigned long id_prev_wrap;\n\tstruct prb_desc *desc;\n\tunsigned long head_id;\n\tunsigned long id;\n\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(desc_reserve:A) */\n\n\tdo {\n\t\tid = DESC_ID(head_id + 1);\n\t\tid_prev_wrap = DESC_ID_PREV_WRAP(desc_ring, id);\n\n\t\t/*\n\t\t * Guarantee the head ID is read before reading the tail ID.\n\t\t * Since the tail ID is updated before the head ID, this\n\t\t * guarantees that @id_prev_wrap is never ahead of the tail\n\t\t * ID. This pairs with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_reserve:A reads from desc_reserve:D, then\n\t\t * desc_reserve:C reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:D\n\t\t *    matching\n\t\t * RMB from desc_reserve:A to desc_reserve:C\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:D can be different\n\t\t *       CPUs. However, the desc_reserve:D CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_reserve:B) */\n\n\t\tif (id_prev_wrap == atomic_long_read(&desc_ring->tail_id\n\t\t\t\t\t\t    )) { /* LMM(desc_reserve:C) */\n\t\t\t/*\n\t\t\t * Make space for the new descriptor by\n\t\t\t * advancing the tail.\n\t\t\t */\n\t\t\tif (!desc_push_tail(rb, id_prev_wrap))\n\t\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee the tail ID is read before validating the\n\t\t *    recycled descriptor state. A read memory barrier is\n\t\t *    sufficient for this. This pairs with desc_push_tail:B.\n\t\t *\n\t\t *    Memory barrier involvement:\n\t\t *\n\t\t *    If desc_reserve:C reads from desc_push_tail:B, then\n\t\t *    desc_reserve:E reads from desc_make_reusable:A.\n\t\t *\n\t\t *    Relies on:\n\t\t *\n\t\t *    MB from desc_make_reusable:A to desc_push_tail:B\n\t\t *       matching\n\t\t *    RMB from desc_reserve:C to desc_reserve:E\n\t\t *\n\t\t *    Note: desc_make_reusable:A and desc_push_tail:B can be\n\t\t *          different CPUs. However, the desc_push_tail:B CPU\n\t\t *          (which performs the full memory barrier) must have\n\t\t *          previously seen desc_make_reusable:A.\n\t\t *\n\t\t * 2. Guarantee the tail ID is stored before storing the head\n\t\t *    ID. This pairs with desc_reserve:B.\n\t\t *\n\t\t * 3. Guarantee any data ring tail changes are stored before\n\t\t *    recycling the descriptor. Data ring tail changes can\n\t\t *    happen via desc_push_tail()->data_push_tail(). A full\n\t\t *    memory barrier is needed since another CPU may have\n\t\t *    pushed the data ring tails. This pairs with\n\t\t *    data_push_tail:B.\n\t\t *\n\t\t * 4. Guarantee a new tail ID is stored before recycling the\n\t\t *    descriptor. A full memory barrier is needed since\n\t\t *    another CPU may have pushed the tail ID. This pairs\n\t\t *    with desc_push_tail:C and this also pairs with\n\t\t *    prb_first_seq:C.\n\t\t *\n\t\t * 5. Guarantee the head ID is stored before trying to\n\t\t *    finalize the previous descriptor. This pairs with\n\t\t *    _prb_commit:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&desc_ring->head_id, &head_id,\n\t\t\t\t\t  id)); /* LMM(desc_reserve:D) */\n\n\tdesc = to_desc(desc_ring, id);\n\n\t/*\n\t * If the descriptor has been recycled, verify the old state val.\n\t * See \"ABA Issues\" about why this verification is performed.\n\t */\n\tprev_state_val = atomic_long_read(&desc->state_var); /* LMM(desc_reserve:E) */\n\tif (prev_state_val &&\n\t    get_desc_state(id_prev_wrap, prev_state_val) != desc_reusable) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Assign the descriptor a new ID and set its state to reserved.\n\t * See \"ABA Issues\" about why cmpxchg() instead of set() is used.\n\t *\n\t * Guarantee the new descriptor ID and state is stored before making\n\t * any other changes. A write memory barrier is sufficient for this.\n\t * This pairs with desc_read:D.\n\t */\n\tif (!atomic_long_try_cmpxchg(&desc->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reserve:F) */\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/* Now data in @desc can be modified: LMM(desc_reserve:G) */\n\n\t*id_out = id;\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool desc_reserve(struct printk_ringbuffer *rb, unsigned long *id_out)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tunsigned long prev_state_val;\n\tunsigned long id_prev_wrap;\n\tstruct prb_desc *desc;\n\tunsigned long head_id;\n\tunsigned long id;\n\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(desc_reserve:A) */\n\n\tdo {\n\t\tid = DESC_ID(head_id + 1);\n\t\tid_prev_wrap = DESC_ID_PREV_WRAP(desc_ring, id);\n\n\t\t/*\n\t\t * Guarantee the head ID is read before reading the tail ID.\n\t\t * Since the tail ID is updated before the head ID, this\n\t\t * guarantees that @id_prev_wrap is never ahead of the tail\n\t\t * ID. This pairs with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_reserve:A reads from desc_reserve:D, then\n\t\t * desc_reserve:C reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:D\n\t\t *    matching\n\t\t * RMB from desc_reserve:A to desc_reserve:C\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:D can be different\n\t\t *       CPUs. However, the desc_reserve:D CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_reserve:B) */\n\n\t\tif (id_prev_wrap == atomic_long_read(&desc_ring->tail_id\n\t\t\t\t\t\t    )) { /* LMM(desc_reserve:C) */\n\t\t\t/*\n\t\t\t * Make space for the new descriptor by\n\t\t\t * advancing the tail.\n\t\t\t */\n\t\t\tif (!desc_push_tail(rb, id_prev_wrap))\n\t\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee the tail ID is read before validating the\n\t\t *    recycled descriptor state. A read memory barrier is\n\t\t *    sufficient for this. This pairs with desc_push_tail:B.\n\t\t *\n\t\t *    Memory barrier involvement:\n\t\t *\n\t\t *    If desc_reserve:C reads from desc_push_tail:B, then\n\t\t *    desc_reserve:E reads from desc_make_reusable:A.\n\t\t *\n\t\t *    Relies on:\n\t\t *\n\t\t *    MB from desc_make_reusable:A to desc_push_tail:B\n\t\t *       matching\n\t\t *    RMB from desc_reserve:C to desc_reserve:E\n\t\t *\n\t\t *    Note: desc_make_reusable:A and desc_push_tail:B can be\n\t\t *          different CPUs. However, the desc_push_tail:B CPU\n\t\t *          (which performs the full memory barrier) must have\n\t\t *          previously seen desc_make_reusable:A.\n\t\t *\n\t\t * 2. Guarantee the tail ID is stored before storing the head\n\t\t *    ID. This pairs with desc_reserve:B.\n\t\t *\n\t\t * 3. Guarantee any data ring tail changes are stored before\n\t\t *    recycling the descriptor. Data ring tail changes can\n\t\t *    happen via desc_push_tail()->data_push_tail(). A full\n\t\t *    memory barrier is needed since another CPU may have\n\t\t *    pushed the data ring tails. This pairs with\n\t\t *    data_push_tail:B.\n\t\t *\n\t\t * 4. Guarantee a new tail ID is stored before recycling the\n\t\t *    descriptor. A full memory barrier is needed since\n\t\t *    another CPU may have pushed the tail ID. This pairs\n\t\t *    with desc_push_tail:C and this also pairs with\n\t\t *    prb_first_seq:C.\n\t\t *\n\t\t * 5. Guarantee the head ID is stored before trying to\n\t\t *    finalize the previous descriptor. This pairs with\n\t\t *    _prb_commit:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&desc_ring->head_id, &head_id,\n\t\t\t\t\t  id)); /* LMM(desc_reserve:D) */\n\n\tdesc = to_desc(desc_ring, id);\n\n\t/*\n\t * If the descriptor has been recycled, verify the old state val.\n\t * See \"ABA Issues\" about why this verification is performed.\n\t */\n\tprev_state_val = atomic_long_read(&desc->state_var); /* LMM(desc_reserve:E) */\n\tif (prev_state_val &&\n\t    get_desc_state(id_prev_wrap, prev_state_val) != desc_reusable) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Assign the descriptor a new ID and set its state to reserved.\n\t * See \"ABA Issues\" about why cmpxchg() instead of set() is used.\n\t *\n\t * Guarantee the new descriptor ID and state is stored before making\n\t * any other changes. A write memory barrier is sufficient for this.\n\t * This pairs with desc_read:D.\n\t */\n\tif (!atomic_long_try_cmpxchg(&desc->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reserve:F) */\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/* Now data in @desc can be modified: LMM(desc_reserve:G) */\n\n\t*id_out = id;\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "e->irqflags"
          ],
          "line": 1497
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_check_size",
          "args": [
            "&rb->text_data_ring",
            "r->text_buf_size"
          ],
          "line": 1488
        },
        "resolved": true,
        "details": {
          "function_name": "data_check_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "394-411",
          "snippet": "static bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tif (size == 0)\n\t\treturn true;\n\n\t/*\n\t * Ensure the alignment padded size could possibly fit in the data\n\t * array. The largest possible data block must still leave room for\n\t * at least the ID of the next block.\n\t */\n\tsize = to_blk_size(size);\n\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tif (size == 0)\n\t\treturn true;\n\n\t/*\n\t * Ensure the alignment padded size could possibly fit in the data\n\t * array. The largest possible data block must still leave room for\n\t * at least the ID of the next block.\n\t */\n\tsize = to_blk_size(size);\n\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))\n\t\treturn false;\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nbool prb_reserve(struct prb_reserved_entry *e, struct printk_ringbuffer *rb,\n\t\t struct printk_record *r)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct printk_info *info;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\tu64 seq;\n\n\tif (!data_check_size(&rb->text_data_ring, r->text_buf_size))\n\t\tgoto fail;\n\n\t/*\n\t * Descriptors in the reserved state act as blockers to all further\n\t * reservations once the desc_ring has fully wrapped. Disable\n\t * interrupts during the reserve/commit window in order to minimize\n\t * the likelihood of this happening.\n\t */\n\tlocal_irq_save(e->irqflags);\n\n\tif (!desc_reserve(rb, &id)) {\n\t\t/* Descriptor reservation failures are tracked. */\n\t\tatomic_long_inc(&rb->fail);\n\t\tlocal_irq_restore(e->irqflags);\n\t\tgoto fail;\n\t}\n\n\td = to_desc(desc_ring, id);\n\tinfo = to_info(desc_ring, id);\n\n\t/*\n\t * All @info fields (except @seq) are cleared and must be filled in\n\t * by the writer. Save @seq before clearing because it is used to\n\t * determine the new sequence number.\n\t */\n\tseq = info->seq;\n\tmemset(info, 0, sizeof(*info));\n\n\t/*\n\t * Set the @e fields here so that prb_commit() can be used if\n\t * text data allocation fails.\n\t */\n\te->rb = rb;\n\te->id = id;\n\n\t/*\n\t * Initialize the sequence number if it has \"never been set\".\n\t * Otherwise just increment it by a full wrap.\n\t *\n\t * @seq is considered \"never been set\" if it has a value of 0,\n\t * _except_ for @infos[0], which was specially setup by the ringbuffer\n\t * initializer and therefore is always considered as set.\n\t *\n\t * See the \"Bootstrap\" comment block in printk_ringbuffer.h for\n\t * details about how the initializer bootstraps the descriptors.\n\t */\n\tif (seq == 0 && DESC_INDEX(desc_ring, id) != 0)\n\t\tinfo->seq = DESC_INDEX(desc_ring, id);\n\telse\n\t\tinfo->seq = seq + DESCS_COUNT(desc_ring);\n\n\t/*\n\t * New data is about to be reserved. Once that happens, previous\n\t * descriptors are no longer able to be extended. Finalize the\n\t * previous descriptor now so that it can be made available to\n\t * readers. (For seq==0 there is no previous descriptor.)\n\t */\n\tif (info->seq > 0)\n\t\tdesc_make_final(desc_ring, DESC_ID(id - 1));\n\n\tr->text_buf = data_alloc(rb, r->text_buf_size, &d->text_blk_lpos, id);\n\t/* If text data allocation fails, a data-less record is committed. */\n\tif (r->text_buf_size && !r->text_buf) {\n\t\tprb_commit(e);\n\t\t/* prb_commit() re-enabled interrupts. */\n\t\tgoto fail;\n\t}\n\n\tr->info = info;\n\n\t/* Record full text space used by record. */\n\te->text_space = space_used(&rb->text_data_ring, &d->text_blk_lpos);\n\n\treturn true;\nfail:\n\t/* Make it clear to the caller that the reserve failed. */\n\tmemset(r, 0, sizeof(*r));\n\treturn false;\n}"
  },
  {
    "function_name": "desc_make_final",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1445-1452",
    "snippet": "static void desc_make_final(struct prb_desc_ring *desc_ring, unsigned long id)\n{\n\tunsigned long prev_state_val = DESC_SV(id, desc_committed);\n\tstruct prb_desc *d = to_desc(desc_ring, id);\n\n\tatomic_long_cmpxchg_relaxed(&d->state_var, prev_state_val,\n\t\t\tDESC_SV(id, desc_finalized)); /* LMM(desc_make_final:A) */\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg_relaxed",
          "args": [
            "&d->state_var",
            "prev_state_val",
            "DESC_SV(id, desc_finalized)"
          ],
          "line": 1450
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_finalized"
          ],
          "line": 1451
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1448
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_committed"
          ],
          "line": 1447
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void desc_make_final(struct prb_desc_ring *desc_ring, unsigned long id)\n{\n\tunsigned long prev_state_val = DESC_SV(id, desc_committed);\n\tstruct prb_desc *d = to_desc(desc_ring, id);\n\n\tatomic_long_cmpxchg_relaxed(&d->state_var, prev_state_val,\n\t\t\tDESC_SV(id, desc_finalized)); /* LMM(desc_make_final:A) */\n}"
  },
  {
    "function_name": "prb_reserve_in_last",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1347-1439",
    "snippet": "bool prb_reserve_in_last(struct prb_reserved_entry *e, struct printk_ringbuffer *rb,\n\t\t\t struct printk_record *r, u32 caller_id, unsigned int max_size)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct printk_info *info;\n\tunsigned int data_size;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\n\tlocal_irq_save(e->irqflags);\n\n\t/* Transition the newest descriptor back to the reserved state. */\n\td = desc_reopen_last(desc_ring, caller_id, &id);\n\tif (!d) {\n\t\tlocal_irq_restore(e->irqflags);\n\t\tgoto fail_reopen;\n\t}\n\n\t/* Now the writer has exclusive access: LMM(prb_reserve_in_last:A) */\n\n\tinfo = to_info(desc_ring, id);\n\n\t/*\n\t * Set the @e fields here so that prb_commit() can be used if\n\t * anything fails from now on.\n\t */\n\te->rb = rb;\n\te->id = id;\n\n\t/*\n\t * desc_reopen_last() checked the caller_id, but there was no\n\t * exclusive access at that point. The descriptor may have\n\t * changed since then.\n\t */\n\tif (caller_id != info->caller_id)\n\t\tgoto fail;\n\n\tif (BLK_DATALESS(&d->text_blk_lpos)) {\n\t\tif (WARN_ON_ONCE(info->text_len != 0)) {\n\t\t\tpr_warn_once(\"wrong text_len value (%hu, expecting 0)\\n\",\n\t\t\t\t     info->text_len);\n\t\t\tinfo->text_len = 0;\n\t\t}\n\n\t\tif (!data_check_size(&rb->text_data_ring, r->text_buf_size))\n\t\t\tgoto fail;\n\n\t\tif (r->text_buf_size > max_size)\n\t\t\tgoto fail;\n\n\t\tr->text_buf = data_alloc(rb, r->text_buf_size,\n\t\t\t\t\t &d->text_blk_lpos, id);\n\t} else {\n\t\tif (!get_data(&rb->text_data_ring, &d->text_blk_lpos, &data_size))\n\t\t\tgoto fail;\n\n\t\t/*\n\t\t * Increase the buffer size to include the original size. If\n\t\t * the meta data (@text_len) is not sane, use the full data\n\t\t * block size.\n\t\t */\n\t\tif (WARN_ON_ONCE(info->text_len > data_size)) {\n\t\t\tpr_warn_once(\"wrong text_len value (%hu, expecting <=%u)\\n\",\n\t\t\t\t     info->text_len, data_size);\n\t\t\tinfo->text_len = data_size;\n\t\t}\n\t\tr->text_buf_size += info->text_len;\n\n\t\tif (!data_check_size(&rb->text_data_ring, r->text_buf_size))\n\t\t\tgoto fail;\n\n\t\tif (r->text_buf_size > max_size)\n\t\t\tgoto fail;\n\n\t\tr->text_buf = data_realloc(rb, r->text_buf_size,\n\t\t\t\t\t   &d->text_blk_lpos, id);\n\t}\n\tif (r->text_buf_size && !r->text_buf)\n\t\tgoto fail;\n\n\tr->info = info;\n\n\te->text_space = space_used(&rb->text_data_ring, &d->text_blk_lpos);\n\n\treturn true;\nfail:\n\tprb_commit(e);\n\t/* prb_commit() re-enabled interrupts. */\nfail_reopen:\n\t/* Make it clear to the caller that the re-reserve failed. */\n\tmemset(r, 0, sizeof(*r));\n\treturn false;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "r",
            "0",
            "sizeof(*r)"
          ],
          "line": 1437
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "prb_commit",
          "args": [
            "e"
          ],
          "line": 1433
        },
        "resolved": true,
        "details": {
          "function_name": "prb_commit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1626-1641",
          "snippet": "void prb_commit(struct prb_reserved_entry *e)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tunsigned long head_id;\n\n\t_prb_commit(e, desc_committed);\n\n\t/*\n\t * If this descriptor is no longer the head (i.e. a new record has\n\t * been allocated), extending the data for this record is no longer\n\t * allowed and therefore it must be finalized.\n\t */\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(prb_commit:A) */\n\tif (head_id != e->id)\n\t\tdesc_make_final(desc_ring, e->id);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nvoid prb_commit(struct prb_reserved_entry *e)\n{\n\tstruct prb_desc_ring *desc_ring = &e->rb->desc_ring;\n\tunsigned long head_id;\n\n\t_prb_commit(e, desc_committed);\n\n\t/*\n\t * If this descriptor is no longer the head (i.e. a new record has\n\t * been allocated), extending the data for this record is no longer\n\t * allowed and therefore it must be finalized.\n\t */\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(prb_commit:A) */\n\tif (head_id != e->id)\n\t\tdesc_make_final(desc_ring, e->id);\n}"
        }
      },
      {
        "call_info": {
          "callee": "space_used",
          "args": [
            "&rb->text_data_ring",
            "&d->text_blk_lpos"
          ],
          "line": 1429
        },
        "resolved": true,
        "details": {
          "function_name": "space_used",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1172-1191",
          "snippet": "static unsigned int space_used(struct prb_data_ring *data_ring,\n\t\t\t       struct prb_data_blk_lpos *blk_lpos)\n{\n\t/* Data-less blocks take no space. */\n\tif (BLK_DATALESS(blk_lpos))\n\t\treturn 0;\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\t/* Data block does not wrap. */\n\t\treturn (DATA_INDEX(data_ring, blk_lpos->next) -\n\t\t\tDATA_INDEX(data_ring, blk_lpos->begin));\n\t}\n\n\t/*\n\t * For wrapping data blocks, the trailing (wasted) space is\n\t * also counted.\n\t */\n\treturn (DATA_INDEX(data_ring, blk_lpos->next) +\n\t\tDATA_SIZE(data_ring) - DATA_INDEX(data_ring, blk_lpos->begin));\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int space_used(struct prb_data_ring *data_ring,\n\t\t\t       struct prb_data_blk_lpos *blk_lpos)\n{\n\t/* Data-less blocks take no space. */\n\tif (BLK_DATALESS(blk_lpos))\n\t\treturn 0;\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\t/* Data block does not wrap. */\n\t\treturn (DATA_INDEX(data_ring, blk_lpos->next) -\n\t\t\tDATA_INDEX(data_ring, blk_lpos->begin));\n\t}\n\n\t/*\n\t * For wrapping data blocks, the trailing (wasted) space is\n\t * also counted.\n\t */\n\treturn (DATA_INDEX(data_ring, blk_lpos->next) +\n\t\tDATA_SIZE(data_ring) - DATA_INDEX(data_ring, blk_lpos->begin));\n}"
        }
      },
      {
        "call_info": {
          "callee": "data_realloc",
          "args": [
            "rb",
            "r->text_buf_size",
            "&d->text_blk_lpos",
            "id"
          ],
          "line": 1421
        },
        "resolved": true,
        "details": {
          "function_name": "data_realloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1102-1169",
          "snippet": "static char *data_realloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\t  struct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long head_lpos;\n\tunsigned long next_lpos;\n\tbool wrapped;\n\n\t/* Reallocation only works if @blk_lpos is the newest data block. */\n\thead_lpos = atomic_long_read(&data_ring->head_lpos);\n\tif (head_lpos != blk_lpos->next)\n\t\treturn NULL;\n\n\t/* Keep track if @blk_lpos was a wrapping data block. */\n\twrapped = (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, blk_lpos->next));\n\n\tsize = to_blk_size(size);\n\n\tnext_lpos = get_next_lpos(data_ring, blk_lpos->begin, size);\n\n\t/* If the data block does not increase, there is nothing to do. */\n\tif (head_lpos - next_lpos < DATA_SIZE(data_ring)) {\n\t\tif (wrapped)\n\t\t\tblk = to_block(data_ring, 0);\n\t\telse\n\t\t\tblk = to_block(data_ring, blk_lpos->begin);\n\t\treturn &blk->data[0];\n\t}\n\n\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring)))\n\t\treturn NULL;\n\n\t/* The memory barrier involvement is the same as data_alloc:A. */\n\tif (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &head_lpos,\n\t\t\t\t     next_lpos)) { /* LMM(data_realloc:A) */\n\t\treturn NULL;\n\t}\n\n\tblk = to_block(data_ring, blk_lpos->begin);\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\tstruct prb_data_block *old_blk = blk;\n\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\n\t\tif (!wrapped) {\n\t\t\t/*\n\t\t\t * Since the allocated space is now in the newly\n\t\t\t * created wrapping data block, copy the content\n\t\t\t * from the old data block.\n\t\t\t */\n\t\t\tmemcpy(&blk->data[0], &old_blk->data[0],\n\t\t\t       (blk_lpos->next - blk_lpos->begin) - sizeof(blk->id));\n\t\t}\n\t}\n\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic char *data_realloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\t  struct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long head_lpos;\n\tunsigned long next_lpos;\n\tbool wrapped;\n\n\t/* Reallocation only works if @blk_lpos is the newest data block. */\n\thead_lpos = atomic_long_read(&data_ring->head_lpos);\n\tif (head_lpos != blk_lpos->next)\n\t\treturn NULL;\n\n\t/* Keep track if @blk_lpos was a wrapping data block. */\n\twrapped = (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, blk_lpos->next));\n\n\tsize = to_blk_size(size);\n\n\tnext_lpos = get_next_lpos(data_ring, blk_lpos->begin, size);\n\n\t/* If the data block does not increase, there is nothing to do. */\n\tif (head_lpos - next_lpos < DATA_SIZE(data_ring)) {\n\t\tif (wrapped)\n\t\t\tblk = to_block(data_ring, 0);\n\t\telse\n\t\t\tblk = to_block(data_ring, blk_lpos->begin);\n\t\treturn &blk->data[0];\n\t}\n\n\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring)))\n\t\treturn NULL;\n\n\t/* The memory barrier involvement is the same as data_alloc:A. */\n\tif (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &head_lpos,\n\t\t\t\t     next_lpos)) { /* LMM(data_realloc:A) */\n\t\treturn NULL;\n\t}\n\n\tblk = to_block(data_ring, blk_lpos->begin);\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\tstruct prb_data_block *old_blk = blk;\n\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\n\t\tif (!wrapped) {\n\t\t\t/*\n\t\t\t * Since the allocated space is now in the newly\n\t\t\t * created wrapping data block, copy the content\n\t\t\t * from the old data block.\n\t\t\t */\n\t\t\tmemcpy(&blk->data[0], &old_blk->data[0],\n\t\t\t       (blk_lpos->next - blk_lpos->begin) - sizeof(blk->id));\n\t\t}\n\t}\n\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}"
        }
      },
      {
        "call_info": {
          "callee": "data_check_size",
          "args": [
            "&rb->text_data_ring",
            "r->text_buf_size"
          ],
          "line": 1415
        },
        "resolved": true,
        "details": {
          "function_name": "data_check_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "394-411",
          "snippet": "static bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tif (size == 0)\n\t\treturn true;\n\n\t/*\n\t * Ensure the alignment padded size could possibly fit in the data\n\t * array. The largest possible data block must still leave room for\n\t * at least the ID of the next block.\n\t */\n\tsize = to_blk_size(size);\n\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tif (size == 0)\n\t\treturn true;\n\n\t/*\n\t * Ensure the alignment padded size could possibly fit in the data\n\t * array. The largest possible data block must still leave room for\n\t * at least the ID of the next block.\n\t */\n\tsize = to_blk_size(size);\n\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))\n\t\treturn false;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_warn_once",
          "args": [
            "\"wrong text_len value (%hu, expecting <=%u)\\n\"",
            "info->text_len",
            "data_size"
          ],
          "line": 1409
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "info->text_len > data_size"
          ],
          "line": 1408
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_data",
          "args": [
            "&rb->text_data_ring",
            "&d->text_blk_lpos",
            "&data_size"
          ],
          "line": 1400
        },
        "resolved": true,
        "details": {
          "function_name": "get_data",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1202-1249",
          "snippet": "static const char *get_data(struct prb_data_ring *data_ring,\n\t\t\t    struct prb_data_blk_lpos *blk_lpos,\n\t\t\t    unsigned int *data_size)\n{\n\tstruct prb_data_block *db;\n\n\t/* Data-less data block description. */\n\tif (BLK_DATALESS(blk_lpos)) {\n\t\tif (blk_lpos->begin == NO_LPOS && blk_lpos->next == NO_LPOS) {\n\t\t\t*data_size = 0;\n\t\t\treturn \"\";\n\t\t}\n\t\treturn NULL;\n\t}\n\n\t/* Regular data block: @begin less than @next and in same wrap. */\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next) &&\n\t    blk_lpos->begin < blk_lpos->next) {\n\t\tdb = to_block(data_ring, blk_lpos->begin);\n\t\t*data_size = blk_lpos->next - blk_lpos->begin;\n\n\t/* Wrapping data block: @begin is one wrap behind @next. */\n\t} else if (DATA_WRAPS(data_ring, blk_lpos->begin + DATA_SIZE(data_ring)) ==\n\t\t   DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\tdb = to_block(data_ring, 0);\n\t\t*data_size = DATA_INDEX(data_ring, blk_lpos->next);\n\n\t/* Illegal block description. */\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always be aligned to the ID size. */\n\tif (WARN_ON_ONCE(blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))) ||\n\t    WARN_ON_ONCE(blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id)))) {\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always have at least an ID. */\n\tif (WARN_ON_ONCE(*data_size < sizeof(db->id)))\n\t\treturn NULL;\n\n\t/* Subtract block ID space from size to reflect data size. */\n\t*data_size -= sizeof(db->id);\n\n\treturn &db->data[0];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic const char *get_data(struct prb_data_ring *data_ring,\n\t\t\t    struct prb_data_blk_lpos *blk_lpos,\n\t\t\t    unsigned int *data_size)\n{\n\tstruct prb_data_block *db;\n\n\t/* Data-less data block description. */\n\tif (BLK_DATALESS(blk_lpos)) {\n\t\tif (blk_lpos->begin == NO_LPOS && blk_lpos->next == NO_LPOS) {\n\t\t\t*data_size = 0;\n\t\t\treturn \"\";\n\t\t}\n\t\treturn NULL;\n\t}\n\n\t/* Regular data block: @begin less than @next and in same wrap. */\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next) &&\n\t    blk_lpos->begin < blk_lpos->next) {\n\t\tdb = to_block(data_ring, blk_lpos->begin);\n\t\t*data_size = blk_lpos->next - blk_lpos->begin;\n\n\t/* Wrapping data block: @begin is one wrap behind @next. */\n\t} else if (DATA_WRAPS(data_ring, blk_lpos->begin + DATA_SIZE(data_ring)) ==\n\t\t   DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\tdb = to_block(data_ring, 0);\n\t\t*data_size = DATA_INDEX(data_ring, blk_lpos->next);\n\n\t/* Illegal block description. */\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always be aligned to the ID size. */\n\tif (WARN_ON_ONCE(blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))) ||\n\t    WARN_ON_ONCE(blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id)))) {\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always have at least an ID. */\n\tif (WARN_ON_ONCE(*data_size < sizeof(db->id)))\n\t\treturn NULL;\n\n\t/* Subtract block ID space from size to reflect data size. */\n\t*data_size -= sizeof(db->id);\n\n\treturn &db->data[0];\n}"
        }
      },
      {
        "call_info": {
          "callee": "data_alloc",
          "args": [
            "rb",
            "r->text_buf_size",
            "&d->text_blk_lpos",
            "id"
          ],
          "line": 1397
        },
        "resolved": true,
        "details": {
          "function_name": "data_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1021-1088",
          "snippet": "static char *data_alloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\tstruct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tif (size == 0) {\n\t\t/* Specify a data-less block. */\n\t\tblk_lpos->begin = NO_LPOS;\n\t\tblk_lpos->next = NO_LPOS;\n\t\treturn NULL;\n\t}\n\n\tsize = to_blk_size(size);\n\n\tbegin_lpos = atomic_long_read(&data_ring->head_lpos);\n\n\tdo {\n\t\tnext_lpos = get_next_lpos(data_ring, begin_lpos, size);\n\n\t\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring))) {\n\t\t\t/* Failed to allocate, specify a data-less block. */\n\t\t\tblk_lpos->begin = FAILED_LPOS;\n\t\t\tblk_lpos->next = FAILED_LPOS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee any descriptor states that have transitioned\n\t\t *    to reusable are stored before modifying the newly\n\t\t *    allocated data area. A full memory barrier is needed\n\t\t *    since other CPUs may have made the descriptor states\n\t\t *    reusable. See data_push_tail:A about why the reusable\n\t\t *    states are visible. This pairs with desc_read:D.\n\t\t *\n\t\t * 2. Guarantee any updated tail lpos is stored before\n\t\t *    modifying the newly allocated data area. Another CPU may\n\t\t *    be in data_make_reusable() and is reading a block ID\n\t\t *    from this area. data_make_reusable() can handle reading\n\t\t *    a garbage block ID value, but then it must be able to\n\t\t *    load a new tail lpos. A full memory barrier is needed\n\t\t *    since other CPUs may have updated the tail lpos. This\n\t\t *    pairs with data_push_tail:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &begin_lpos,\n\t\t\t\t\t  next_lpos)); /* LMM(data_alloc:A) */\n\n\tblk = to_block(data_ring, begin_lpos);\n\tblk->id = id; /* LMM(data_alloc:B) */\n\n\tif (DATA_WRAPS(data_ring, begin_lpos) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\t}\n\n\tblk_lpos->begin = begin_lpos;\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic char *data_alloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\tstruct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tif (size == 0) {\n\t\t/* Specify a data-less block. */\n\t\tblk_lpos->begin = NO_LPOS;\n\t\tblk_lpos->next = NO_LPOS;\n\t\treturn NULL;\n\t}\n\n\tsize = to_blk_size(size);\n\n\tbegin_lpos = atomic_long_read(&data_ring->head_lpos);\n\n\tdo {\n\t\tnext_lpos = get_next_lpos(data_ring, begin_lpos, size);\n\n\t\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring))) {\n\t\t\t/* Failed to allocate, specify a data-less block. */\n\t\t\tblk_lpos->begin = FAILED_LPOS;\n\t\t\tblk_lpos->next = FAILED_LPOS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee any descriptor states that have transitioned\n\t\t *    to reusable are stored before modifying the newly\n\t\t *    allocated data area. A full memory barrier is needed\n\t\t *    since other CPUs may have made the descriptor states\n\t\t *    reusable. See data_push_tail:A about why the reusable\n\t\t *    states are visible. This pairs with desc_read:D.\n\t\t *\n\t\t * 2. Guarantee any updated tail lpos is stored before\n\t\t *    modifying the newly allocated data area. Another CPU may\n\t\t *    be in data_make_reusable() and is reading a block ID\n\t\t *    from this area. data_make_reusable() can handle reading\n\t\t *    a garbage block ID value, but then it must be able to\n\t\t *    load a new tail lpos. A full memory barrier is needed\n\t\t *    since other CPUs may have updated the tail lpos. This\n\t\t *    pairs with data_push_tail:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &begin_lpos,\n\t\t\t\t\t  next_lpos)); /* LMM(data_alloc:A) */\n\n\tblk = to_block(data_ring, begin_lpos);\n\tblk->id = id; /* LMM(data_alloc:B) */\n\n\tif (DATA_WRAPS(data_ring, begin_lpos) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\t}\n\n\tblk_lpos->begin = begin_lpos;\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_warn_once",
          "args": [
            "\"wrong text_len value (%hu, expecting 0)\\n\"",
            "info->text_len"
          ],
          "line": 1386
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "info->text_len != 0"
          ],
          "line": 1385
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BLK_DATALESS",
          "args": [
            "&d->text_blk_lpos"
          ],
          "line": 1384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_info",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1367
        },
        "resolved": true,
        "details": {
          "function_name": "to_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "364-367",
          "snippet": "static struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "e->irqflags"
          ],
          "line": 1361
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "desc_reopen_last",
          "args": [
            "desc_ring",
            "caller_id",
            "&id"
          ],
          "line": 1359
        },
        "resolved": true,
        "details": {
          "function_name": "desc_reopen_last",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "1256-1303",
          "snippet": "static struct prb_desc *desc_reopen_last(struct prb_desc_ring *desc_ring,\n\t\t\t\t\t u32 caller_id, unsigned long *id_out)\n{\n\tunsigned long prev_state_val;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\tu32 cid;\n\n\tid = atomic_long_read(&desc_ring->head_id);\n\n\t/*\n\t * To reduce unnecessarily reopening, first check if the descriptor\n\t * state and caller ID are correct.\n\t */\n\td_state = desc_read(desc_ring, id, &desc, NULL, &cid);\n\tif (d_state != desc_committed || cid != caller_id)\n\t\treturn NULL;\n\n\td = to_desc(desc_ring, id);\n\n\tprev_state_val = DESC_SV(id, desc_committed);\n\n\t/*\n\t * Guarantee the reserved state is stored before reading any\n\t * record data. A full memory barrier is needed because @state_var\n\t * modification is followed by reading. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_reopen_last:A reads from _prb_commit:B, then\n\t * prb_reserve_in_last:A reads from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * MB If desc_reopen_last:A to prb_reserve_in_last:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reopen_last:A) */\n\t\treturn NULL;\n\t}\n\n\t*id_out = id;\n\treturn d;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *desc_reopen_last(struct prb_desc_ring *desc_ring,\n\t\t\t\t\t u32 caller_id, unsigned long *id_out)\n{\n\tunsigned long prev_state_val;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\tu32 cid;\n\n\tid = atomic_long_read(&desc_ring->head_id);\n\n\t/*\n\t * To reduce unnecessarily reopening, first check if the descriptor\n\t * state and caller ID are correct.\n\t */\n\td_state = desc_read(desc_ring, id, &desc, NULL, &cid);\n\tif (d_state != desc_committed || cid != caller_id)\n\t\treturn NULL;\n\n\td = to_desc(desc_ring, id);\n\n\tprev_state_val = DESC_SV(id, desc_committed);\n\n\t/*\n\t * Guarantee the reserved state is stored before reading any\n\t * record data. A full memory barrier is needed because @state_var\n\t * modification is followed by reading. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_reopen_last:A reads from _prb_commit:B, then\n\t * prb_reserve_in_last:A reads from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * MB If desc_reopen_last:A to prb_reserve_in_last:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reopen_last:A) */\n\t\treturn NULL;\n\t}\n\n\t*id_out = id;\n\treturn d;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "e->irqflags"
          ],
          "line": 1356
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nbool prb_reserve_in_last(struct prb_reserved_entry *e, struct printk_ringbuffer *rb,\n\t\t\t struct printk_record *r, u32 caller_id, unsigned int max_size)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct printk_info *info;\n\tunsigned int data_size;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\n\tlocal_irq_save(e->irqflags);\n\n\t/* Transition the newest descriptor back to the reserved state. */\n\td = desc_reopen_last(desc_ring, caller_id, &id);\n\tif (!d) {\n\t\tlocal_irq_restore(e->irqflags);\n\t\tgoto fail_reopen;\n\t}\n\n\t/* Now the writer has exclusive access: LMM(prb_reserve_in_last:A) */\n\n\tinfo = to_info(desc_ring, id);\n\n\t/*\n\t * Set the @e fields here so that prb_commit() can be used if\n\t * anything fails from now on.\n\t */\n\te->rb = rb;\n\te->id = id;\n\n\t/*\n\t * desc_reopen_last() checked the caller_id, but there was no\n\t * exclusive access at that point. The descriptor may have\n\t * changed since then.\n\t */\n\tif (caller_id != info->caller_id)\n\t\tgoto fail;\n\n\tif (BLK_DATALESS(&d->text_blk_lpos)) {\n\t\tif (WARN_ON_ONCE(info->text_len != 0)) {\n\t\t\tpr_warn_once(\"wrong text_len value (%hu, expecting 0)\\n\",\n\t\t\t\t     info->text_len);\n\t\t\tinfo->text_len = 0;\n\t\t}\n\n\t\tif (!data_check_size(&rb->text_data_ring, r->text_buf_size))\n\t\t\tgoto fail;\n\n\t\tif (r->text_buf_size > max_size)\n\t\t\tgoto fail;\n\n\t\tr->text_buf = data_alloc(rb, r->text_buf_size,\n\t\t\t\t\t &d->text_blk_lpos, id);\n\t} else {\n\t\tif (!get_data(&rb->text_data_ring, &d->text_blk_lpos, &data_size))\n\t\t\tgoto fail;\n\n\t\t/*\n\t\t * Increase the buffer size to include the original size. If\n\t\t * the meta data (@text_len) is not sane, use the full data\n\t\t * block size.\n\t\t */\n\t\tif (WARN_ON_ONCE(info->text_len > data_size)) {\n\t\t\tpr_warn_once(\"wrong text_len value (%hu, expecting <=%u)\\n\",\n\t\t\t\t     info->text_len, data_size);\n\t\t\tinfo->text_len = data_size;\n\t\t}\n\t\tr->text_buf_size += info->text_len;\n\n\t\tif (!data_check_size(&rb->text_data_ring, r->text_buf_size))\n\t\t\tgoto fail;\n\n\t\tif (r->text_buf_size > max_size)\n\t\t\tgoto fail;\n\n\t\tr->text_buf = data_realloc(rb, r->text_buf_size,\n\t\t\t\t\t   &d->text_blk_lpos, id);\n\t}\n\tif (r->text_buf_size && !r->text_buf)\n\t\tgoto fail;\n\n\tr->info = info;\n\n\te->text_space = space_used(&rb->text_data_ring, &d->text_blk_lpos);\n\n\treturn true;\nfail:\n\tprb_commit(e);\n\t/* prb_commit() re-enabled interrupts. */\nfail_reopen:\n\t/* Make it clear to the caller that the re-reserve failed. */\n\tmemset(r, 0, sizeof(*r));\n\treturn false;\n}"
  },
  {
    "function_name": "desc_reopen_last",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1256-1303",
    "snippet": "static struct prb_desc *desc_reopen_last(struct prb_desc_ring *desc_ring,\n\t\t\t\t\t u32 caller_id, unsigned long *id_out)\n{\n\tunsigned long prev_state_val;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\tu32 cid;\n\n\tid = atomic_long_read(&desc_ring->head_id);\n\n\t/*\n\t * To reduce unnecessarily reopening, first check if the descriptor\n\t * state and caller ID are correct.\n\t */\n\td_state = desc_read(desc_ring, id, &desc, NULL, &cid);\n\tif (d_state != desc_committed || cid != caller_id)\n\t\treturn NULL;\n\n\td = to_desc(desc_ring, id);\n\n\tprev_state_val = DESC_SV(id, desc_committed);\n\n\t/*\n\t * Guarantee the reserved state is stored before reading any\n\t * record data. A full memory barrier is needed because @state_var\n\t * modification is followed by reading. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_reopen_last:A reads from _prb_commit:B, then\n\t * prb_reserve_in_last:A reads from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * MB If desc_reopen_last:A to prb_reserve_in_last:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reopen_last:A) */\n\t\treturn NULL;\n\t}\n\n\t*id_out = id;\n\treturn d;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&d->state_var",
            "&prev_state_val",
            "DESC_SV(id, desc_reserved)"
          ],
          "line": 1296
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_reserved"
          ],
          "line": 1297
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_committed"
          ],
          "line": 1278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 1276
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "desc_read",
          "args": [
            "desc_ring",
            "id",
            "&desc",
            "NULL",
            "&cid"
          ],
          "line": 1272
        },
        "resolved": true,
        "details": {
          "function_name": "desc_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "432-533",
          "snippet": "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc_ring->head_id"
          ],
          "line": 1266
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *desc_reopen_last(struct prb_desc_ring *desc_ring,\n\t\t\t\t\t u32 caller_id, unsigned long *id_out)\n{\n\tunsigned long prev_state_val;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_desc *d;\n\tunsigned long id;\n\tu32 cid;\n\n\tid = atomic_long_read(&desc_ring->head_id);\n\n\t/*\n\t * To reduce unnecessarily reopening, first check if the descriptor\n\t * state and caller ID are correct.\n\t */\n\td_state = desc_read(desc_ring, id, &desc, NULL, &cid);\n\tif (d_state != desc_committed || cid != caller_id)\n\t\treturn NULL;\n\n\td = to_desc(desc_ring, id);\n\n\tprev_state_val = DESC_SV(id, desc_committed);\n\n\t/*\n\t * Guarantee the reserved state is stored before reading any\n\t * record data. A full memory barrier is needed because @state_var\n\t * modification is followed by reading. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_reopen_last:A reads from _prb_commit:B, then\n\t * prb_reserve_in_last:A reads from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * MB If desc_reopen_last:A to prb_reserve_in_last:A\n\t */\n\tif (!atomic_long_try_cmpxchg(&d->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reopen_last:A) */\n\t\treturn NULL;\n\t}\n\n\t*id_out = id;\n\treturn d;\n}"
  },
  {
    "function_name": "get_data",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1202-1249",
    "snippet": "static const char *get_data(struct prb_data_ring *data_ring,\n\t\t\t    struct prb_data_blk_lpos *blk_lpos,\n\t\t\t    unsigned int *data_size)\n{\n\tstruct prb_data_block *db;\n\n\t/* Data-less data block description. */\n\tif (BLK_DATALESS(blk_lpos)) {\n\t\tif (blk_lpos->begin == NO_LPOS && blk_lpos->next == NO_LPOS) {\n\t\t\t*data_size = 0;\n\t\t\treturn \"\";\n\t\t}\n\t\treturn NULL;\n\t}\n\n\t/* Regular data block: @begin less than @next and in same wrap. */\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next) &&\n\t    blk_lpos->begin < blk_lpos->next) {\n\t\tdb = to_block(data_ring, blk_lpos->begin);\n\t\t*data_size = blk_lpos->next - blk_lpos->begin;\n\n\t/* Wrapping data block: @begin is one wrap behind @next. */\n\t} else if (DATA_WRAPS(data_ring, blk_lpos->begin + DATA_SIZE(data_ring)) ==\n\t\t   DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\tdb = to_block(data_ring, 0);\n\t\t*data_size = DATA_INDEX(data_ring, blk_lpos->next);\n\n\t/* Illegal block description. */\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always be aligned to the ID size. */\n\tif (WARN_ON_ONCE(blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))) ||\n\t    WARN_ON_ONCE(blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id)))) {\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always have at least an ID. */\n\tif (WARN_ON_ONCE(*data_size < sizeof(db->id)))\n\t\treturn NULL;\n\n\t/* Subtract block ID space from size to reflect data size. */\n\t*data_size -= sizeof(db->id);\n\n\treturn &db->data[0];\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "*data_size < sizeof(db->id)"
          ],
          "line": 1242
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id))"
          ],
          "line": 1237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "blk_lpos->next",
            "sizeof(db->id)"
          ],
          "line": 1237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))"
          ],
          "line": 1236
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "blk_lpos->begin",
            "sizeof(db->id)"
          ],
          "line": 1236
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "1"
          ],
          "line": 1231
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_INDEX",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1227
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_block",
          "args": [
            "data_ring",
            "0"
          ],
          "line": 1226
        },
        "resolved": true,
        "details": {
          "function_name": "to_block",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "369-373",
          "snippet": "static struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1225
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->begin + DATA_SIZE(data_ring)"
          ],
          "line": 1224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 1224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1218
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->begin"
          ],
          "line": 1218
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BLK_DATALESS",
          "args": [
            "blk_lpos"
          ],
          "line": 1209
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic const char *get_data(struct prb_data_ring *data_ring,\n\t\t\t    struct prb_data_blk_lpos *blk_lpos,\n\t\t\t    unsigned int *data_size)\n{\n\tstruct prb_data_block *db;\n\n\t/* Data-less data block description. */\n\tif (BLK_DATALESS(blk_lpos)) {\n\t\tif (blk_lpos->begin == NO_LPOS && blk_lpos->next == NO_LPOS) {\n\t\t\t*data_size = 0;\n\t\t\treturn \"\";\n\t\t}\n\t\treturn NULL;\n\t}\n\n\t/* Regular data block: @begin less than @next and in same wrap. */\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next) &&\n\t    blk_lpos->begin < blk_lpos->next) {\n\t\tdb = to_block(data_ring, blk_lpos->begin);\n\t\t*data_size = blk_lpos->next - blk_lpos->begin;\n\n\t/* Wrapping data block: @begin is one wrap behind @next. */\n\t} else if (DATA_WRAPS(data_ring, blk_lpos->begin + DATA_SIZE(data_ring)) ==\n\t\t   DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\tdb = to_block(data_ring, 0);\n\t\t*data_size = DATA_INDEX(data_ring, blk_lpos->next);\n\n\t/* Illegal block description. */\n\t} else {\n\t\tWARN_ON_ONCE(1);\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always be aligned to the ID size. */\n\tif (WARN_ON_ONCE(blk_lpos->begin != ALIGN(blk_lpos->begin, sizeof(db->id))) ||\n\t    WARN_ON_ONCE(blk_lpos->next != ALIGN(blk_lpos->next, sizeof(db->id)))) {\n\t\treturn NULL;\n\t}\n\n\t/* A valid data block will always have at least an ID. */\n\tif (WARN_ON_ONCE(*data_size < sizeof(db->id)))\n\t\treturn NULL;\n\n\t/* Subtract block ID space from size to reflect data size. */\n\t*data_size -= sizeof(db->id);\n\n\treturn &db->data[0];\n}"
  },
  {
    "function_name": "space_used",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1172-1191",
    "snippet": "static unsigned int space_used(struct prb_data_ring *data_ring,\n\t\t\t       struct prb_data_blk_lpos *blk_lpos)\n{\n\t/* Data-less blocks take no space. */\n\tif (BLK_DATALESS(blk_lpos))\n\t\treturn 0;\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\t/* Data block does not wrap. */\n\t\treturn (DATA_INDEX(data_ring, blk_lpos->next) -\n\t\t\tDATA_INDEX(data_ring, blk_lpos->begin));\n\t}\n\n\t/*\n\t * For wrapping data blocks, the trailing (wasted) space is\n\t * also counted.\n\t */\n\treturn (DATA_INDEX(data_ring, blk_lpos->next) +\n\t\tDATA_SIZE(data_ring) - DATA_INDEX(data_ring, blk_lpos->begin));\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DATA_INDEX",
          "args": [
            "data_ring",
            "blk_lpos->begin"
          ],
          "line": 1190
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 1190
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_INDEX",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1189
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_INDEX",
          "args": [
            "data_ring",
            "blk_lpos->begin"
          ],
          "line": 1182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_INDEX",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1181
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->begin"
          ],
          "line": 1179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BLK_DATALESS",
          "args": [
            "blk_lpos"
          ],
          "line": 1176
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int space_used(struct prb_data_ring *data_ring,\n\t\t\t       struct prb_data_blk_lpos *blk_lpos)\n{\n\t/* Data-less blocks take no space. */\n\tif (BLK_DATALESS(blk_lpos))\n\t\treturn 0;\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) == DATA_WRAPS(data_ring, blk_lpos->next)) {\n\t\t/* Data block does not wrap. */\n\t\treturn (DATA_INDEX(data_ring, blk_lpos->next) -\n\t\t\tDATA_INDEX(data_ring, blk_lpos->begin));\n\t}\n\n\t/*\n\t * For wrapping data blocks, the trailing (wasted) space is\n\t * also counted.\n\t */\n\treturn (DATA_INDEX(data_ring, blk_lpos->next) +\n\t\tDATA_SIZE(data_ring) - DATA_INDEX(data_ring, blk_lpos->begin));\n}"
  },
  {
    "function_name": "data_realloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1102-1169",
    "snippet": "static char *data_realloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\t  struct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long head_lpos;\n\tunsigned long next_lpos;\n\tbool wrapped;\n\n\t/* Reallocation only works if @blk_lpos is the newest data block. */\n\thead_lpos = atomic_long_read(&data_ring->head_lpos);\n\tif (head_lpos != blk_lpos->next)\n\t\treturn NULL;\n\n\t/* Keep track if @blk_lpos was a wrapping data block. */\n\twrapped = (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, blk_lpos->next));\n\n\tsize = to_blk_size(size);\n\n\tnext_lpos = get_next_lpos(data_ring, blk_lpos->begin, size);\n\n\t/* If the data block does not increase, there is nothing to do. */\n\tif (head_lpos - next_lpos < DATA_SIZE(data_ring)) {\n\t\tif (wrapped)\n\t\t\tblk = to_block(data_ring, 0);\n\t\telse\n\t\t\tblk = to_block(data_ring, blk_lpos->begin);\n\t\treturn &blk->data[0];\n\t}\n\n\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring)))\n\t\treturn NULL;\n\n\t/* The memory barrier involvement is the same as data_alloc:A. */\n\tif (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &head_lpos,\n\t\t\t\t     next_lpos)) { /* LMM(data_realloc:A) */\n\t\treturn NULL;\n\t}\n\n\tblk = to_block(data_ring, blk_lpos->begin);\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\tstruct prb_data_block *old_blk = blk;\n\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\n\t\tif (!wrapped) {\n\t\t\t/*\n\t\t\t * Since the allocated space is now in the newly\n\t\t\t * created wrapping data block, copy the content\n\t\t\t * from the old data block.\n\t\t\t */\n\t\t\tmemcpy(&blk->data[0], &old_blk->data[0],\n\t\t\t       (blk_lpos->next - blk_lpos->begin) - sizeof(blk->id));\n\t\t}\n\t}\n\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "&blk->data[0]",
            "&old_blk->data[0]",
            "(blk_lpos->next - blk_lpos->begin) - sizeof(blk->id)"
          ],
          "line": 1161
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_block",
          "args": [
            "data_ring",
            "0"
          ],
          "line": 1147
        },
        "resolved": true,
        "details": {
          "function_name": "to_block",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "369-373",
          "snippet": "static struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "next_lpos"
          ],
          "line": 1143
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->begin"
          ],
          "line": 1143
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&data_ring->head_lpos",
            "&head_lpos",
            "next_lpos"
          ],
          "line": 1136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_push_tail",
          "args": [
            "rb",
            "next_lpos - DATA_SIZE(data_ring)"
          ],
          "line": 1132
        },
        "resolved": true,
        "details": {
          "function_name": "data_push_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "629-754",
          "snippet": "static bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 1132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 1124
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_next_lpos",
          "args": [
            "data_ring",
            "blk_lpos->begin",
            "size"
          ],
          "line": 1121
        },
        "resolved": true,
        "details": {
          "function_name": "get_next_lpos",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "999-1014",
          "snippet": "static unsigned long get_next_lpos(struct prb_data_ring *data_ring,\n\t\t\t\t   unsigned long lpos, unsigned int size)\n{\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tbegin_lpos = lpos;\n\tnext_lpos = lpos + size;\n\n\t/* First check if the data block does not wrap. */\n\tif (DATA_WRAPS(data_ring, begin_lpos) == DATA_WRAPS(data_ring, next_lpos))\n\t\treturn next_lpos;\n\n\t/* Wrapping data blocks store their data at the beginning. */\n\treturn (DATA_THIS_WRAP_START_LPOS(data_ring, next_lpos) + size);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned long get_next_lpos(struct prb_data_ring *data_ring,\n\t\t\t\t   unsigned long lpos, unsigned int size)\n{\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tbegin_lpos = lpos;\n\tnext_lpos = lpos + size;\n\n\t/* First check if the data block does not wrap. */\n\tif (DATA_WRAPS(data_ring, begin_lpos) == DATA_WRAPS(data_ring, next_lpos))\n\t\treturn next_lpos;\n\n\t/* Wrapping data blocks store their data at the beginning. */\n\treturn (DATA_THIS_WRAP_START_LPOS(data_ring, next_lpos) + size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_blk_size",
          "args": [
            "size"
          ],
          "line": 1119
        },
        "resolved": true,
        "details": {
          "function_name": "to_blk_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "379-386",
          "snippet": "static unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->next"
          ],
          "line": 1117
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "blk_lpos->begin"
          ],
          "line": 1117
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&data_ring->head_lpos"
          ],
          "line": 1112
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic char *data_realloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\t  struct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long head_lpos;\n\tunsigned long next_lpos;\n\tbool wrapped;\n\n\t/* Reallocation only works if @blk_lpos is the newest data block. */\n\thead_lpos = atomic_long_read(&data_ring->head_lpos);\n\tif (head_lpos != blk_lpos->next)\n\t\treturn NULL;\n\n\t/* Keep track if @blk_lpos was a wrapping data block. */\n\twrapped = (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, blk_lpos->next));\n\n\tsize = to_blk_size(size);\n\n\tnext_lpos = get_next_lpos(data_ring, blk_lpos->begin, size);\n\n\t/* If the data block does not increase, there is nothing to do. */\n\tif (head_lpos - next_lpos < DATA_SIZE(data_ring)) {\n\t\tif (wrapped)\n\t\t\tblk = to_block(data_ring, 0);\n\t\telse\n\t\t\tblk = to_block(data_ring, blk_lpos->begin);\n\t\treturn &blk->data[0];\n\t}\n\n\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring)))\n\t\treturn NULL;\n\n\t/* The memory barrier involvement is the same as data_alloc:A. */\n\tif (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &head_lpos,\n\t\t\t\t     next_lpos)) { /* LMM(data_realloc:A) */\n\t\treturn NULL;\n\t}\n\n\tblk = to_block(data_ring, blk_lpos->begin);\n\n\tif (DATA_WRAPS(data_ring, blk_lpos->begin) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\tstruct prb_data_block *old_blk = blk;\n\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\n\t\tif (!wrapped) {\n\t\t\t/*\n\t\t\t * Since the allocated space is now in the newly\n\t\t\t * created wrapping data block, copy the content\n\t\t\t * from the old data block.\n\t\t\t */\n\t\t\tmemcpy(&blk->data[0], &old_blk->data[0],\n\t\t\t       (blk_lpos->next - blk_lpos->begin) - sizeof(blk->id));\n\t\t}\n\t}\n\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}"
  },
  {
    "function_name": "data_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "1021-1088",
    "snippet": "static char *data_alloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\tstruct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tif (size == 0) {\n\t\t/* Specify a data-less block. */\n\t\tblk_lpos->begin = NO_LPOS;\n\t\tblk_lpos->next = NO_LPOS;\n\t\treturn NULL;\n\t}\n\n\tsize = to_blk_size(size);\n\n\tbegin_lpos = atomic_long_read(&data_ring->head_lpos);\n\n\tdo {\n\t\tnext_lpos = get_next_lpos(data_ring, begin_lpos, size);\n\n\t\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring))) {\n\t\t\t/* Failed to allocate, specify a data-less block. */\n\t\t\tblk_lpos->begin = FAILED_LPOS;\n\t\t\tblk_lpos->next = FAILED_LPOS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee any descriptor states that have transitioned\n\t\t *    to reusable are stored before modifying the newly\n\t\t *    allocated data area. A full memory barrier is needed\n\t\t *    since other CPUs may have made the descriptor states\n\t\t *    reusable. See data_push_tail:A about why the reusable\n\t\t *    states are visible. This pairs with desc_read:D.\n\t\t *\n\t\t * 2. Guarantee any updated tail lpos is stored before\n\t\t *    modifying the newly allocated data area. Another CPU may\n\t\t *    be in data_make_reusable() and is reading a block ID\n\t\t *    from this area. data_make_reusable() can handle reading\n\t\t *    a garbage block ID value, but then it must be able to\n\t\t *    load a new tail lpos. A full memory barrier is needed\n\t\t *    since other CPUs may have updated the tail lpos. This\n\t\t *    pairs with data_push_tail:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &begin_lpos,\n\t\t\t\t\t  next_lpos)); /* LMM(data_alloc:A) */\n\n\tblk = to_block(data_ring, begin_lpos);\n\tblk->id = id; /* LMM(data_alloc:B) */\n\n\tif (DATA_WRAPS(data_ring, begin_lpos) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\t}\n\n\tblk_lpos->begin = begin_lpos;\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "to_block",
          "args": [
            "data_ring",
            "0"
          ],
          "line": 1075
        },
        "resolved": true,
        "details": {
          "function_name": "to_block",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "369-373",
          "snippet": "static struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "next_lpos"
          ],
          "line": 1073
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "begin_lpos"
          ],
          "line": 1073
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&data_ring->head_lpos",
            "&begin_lpos",
            "next_lpos"
          ],
          "line": 1067
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_push_tail",
          "args": [
            "rb",
            "next_lpos - DATA_SIZE(data_ring)"
          ],
          "line": 1043
        },
        "resolved": true,
        "details": {
          "function_name": "data_push_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "629-754",
          "snippet": "static bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 1043
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_next_lpos",
          "args": [
            "data_ring",
            "begin_lpos",
            "size"
          ],
          "line": 1041
        },
        "resolved": true,
        "details": {
          "function_name": "get_next_lpos",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "999-1014",
          "snippet": "static unsigned long get_next_lpos(struct prb_data_ring *data_ring,\n\t\t\t\t   unsigned long lpos, unsigned int size)\n{\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tbegin_lpos = lpos;\n\tnext_lpos = lpos + size;\n\n\t/* First check if the data block does not wrap. */\n\tif (DATA_WRAPS(data_ring, begin_lpos) == DATA_WRAPS(data_ring, next_lpos))\n\t\treturn next_lpos;\n\n\t/* Wrapping data blocks store their data at the beginning. */\n\treturn (DATA_THIS_WRAP_START_LPOS(data_ring, next_lpos) + size);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned long get_next_lpos(struct prb_data_ring *data_ring,\n\t\t\t\t   unsigned long lpos, unsigned int size)\n{\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tbegin_lpos = lpos;\n\tnext_lpos = lpos + size;\n\n\t/* First check if the data block does not wrap. */\n\tif (DATA_WRAPS(data_ring, begin_lpos) == DATA_WRAPS(data_ring, next_lpos))\n\t\treturn next_lpos;\n\n\t/* Wrapping data blocks store their data at the beginning. */\n\treturn (DATA_THIS_WRAP_START_LPOS(data_ring, next_lpos) + size);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&data_ring->head_lpos"
          ],
          "line": 1038
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_blk_size",
          "args": [
            "size"
          ],
          "line": 1036
        },
        "resolved": true,
        "details": {
          "function_name": "to_blk_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "379-386",
          "snippet": "static unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic char *data_alloc(struct printk_ringbuffer *rb, unsigned int size,\n\t\t\tstruct prb_data_blk_lpos *blk_lpos, unsigned long id)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_data_block *blk;\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tif (size == 0) {\n\t\t/* Specify a data-less block. */\n\t\tblk_lpos->begin = NO_LPOS;\n\t\tblk_lpos->next = NO_LPOS;\n\t\treturn NULL;\n\t}\n\n\tsize = to_blk_size(size);\n\n\tbegin_lpos = atomic_long_read(&data_ring->head_lpos);\n\n\tdo {\n\t\tnext_lpos = get_next_lpos(data_ring, begin_lpos, size);\n\n\t\tif (!data_push_tail(rb, next_lpos - DATA_SIZE(data_ring))) {\n\t\t\t/* Failed to allocate, specify a data-less block. */\n\t\t\tblk_lpos->begin = FAILED_LPOS;\n\t\t\tblk_lpos->next = FAILED_LPOS;\n\t\t\treturn NULL;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee any descriptor states that have transitioned\n\t\t *    to reusable are stored before modifying the newly\n\t\t *    allocated data area. A full memory barrier is needed\n\t\t *    since other CPUs may have made the descriptor states\n\t\t *    reusable. See data_push_tail:A about why the reusable\n\t\t *    states are visible. This pairs with desc_read:D.\n\t\t *\n\t\t * 2. Guarantee any updated tail lpos is stored before\n\t\t *    modifying the newly allocated data area. Another CPU may\n\t\t *    be in data_make_reusable() and is reading a block ID\n\t\t *    from this area. data_make_reusable() can handle reading\n\t\t *    a garbage block ID value, but then it must be able to\n\t\t *    load a new tail lpos. A full memory barrier is needed\n\t\t *    since other CPUs may have updated the tail lpos. This\n\t\t *    pairs with data_push_tail:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&data_ring->head_lpos, &begin_lpos,\n\t\t\t\t\t  next_lpos)); /* LMM(data_alloc:A) */\n\n\tblk = to_block(data_ring, begin_lpos);\n\tblk->id = id; /* LMM(data_alloc:B) */\n\n\tif (DATA_WRAPS(data_ring, begin_lpos) != DATA_WRAPS(data_ring, next_lpos)) {\n\t\t/* Wrapping data blocks store their data at the beginning. */\n\t\tblk = to_block(data_ring, 0);\n\n\t\t/*\n\t\t * Store the ID on the wrapped block for consistency.\n\t\t * The printk_ringbuffer does not actually use it.\n\t\t */\n\t\tblk->id = id;\n\t}\n\n\tblk_lpos->begin = begin_lpos;\n\tblk_lpos->next = next_lpos;\n\n\treturn &blk->data[0];\n}"
  },
  {
    "function_name": "get_next_lpos",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "999-1014",
    "snippet": "static unsigned long get_next_lpos(struct prb_data_ring *data_ring,\n\t\t\t\t   unsigned long lpos, unsigned int size)\n{\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tbegin_lpos = lpos;\n\tnext_lpos = lpos + size;\n\n\t/* First check if the data block does not wrap. */\n\tif (DATA_WRAPS(data_ring, begin_lpos) == DATA_WRAPS(data_ring, next_lpos))\n\t\treturn next_lpos;\n\n\t/* Wrapping data blocks store their data at the beginning. */\n\treturn (DATA_THIS_WRAP_START_LPOS(data_ring, next_lpos) + size);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DATA_THIS_WRAP_START_LPOS",
          "args": [
            "data_ring",
            "next_lpos"
          ],
          "line": 1013
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "next_lpos"
          ],
          "line": 1009
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DATA_WRAPS",
          "args": [
            "data_ring",
            "begin_lpos"
          ],
          "line": 1009
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned long get_next_lpos(struct prb_data_ring *data_ring,\n\t\t\t\t   unsigned long lpos, unsigned int size)\n{\n\tunsigned long begin_lpos;\n\tunsigned long next_lpos;\n\n\tbegin_lpos = lpos;\n\tnext_lpos = lpos + size;\n\n\t/* First check if the data block does not wrap. */\n\tif (DATA_WRAPS(data_ring, begin_lpos) == DATA_WRAPS(data_ring, next_lpos))\n\t\treturn next_lpos;\n\n\t/* Wrapping data blocks store their data at the beginning. */\n\treturn (DATA_THIS_WRAP_START_LPOS(data_ring, next_lpos) + size);\n}"
  },
  {
    "function_name": "desc_reserve",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "872-996",
    "snippet": "static bool desc_reserve(struct printk_ringbuffer *rb, unsigned long *id_out)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tunsigned long prev_state_val;\n\tunsigned long id_prev_wrap;\n\tstruct prb_desc *desc;\n\tunsigned long head_id;\n\tunsigned long id;\n\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(desc_reserve:A) */\n\n\tdo {\n\t\tid = DESC_ID(head_id + 1);\n\t\tid_prev_wrap = DESC_ID_PREV_WRAP(desc_ring, id);\n\n\t\t/*\n\t\t * Guarantee the head ID is read before reading the tail ID.\n\t\t * Since the tail ID is updated before the head ID, this\n\t\t * guarantees that @id_prev_wrap is never ahead of the tail\n\t\t * ID. This pairs with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_reserve:A reads from desc_reserve:D, then\n\t\t * desc_reserve:C reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:D\n\t\t *    matching\n\t\t * RMB from desc_reserve:A to desc_reserve:C\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:D can be different\n\t\t *       CPUs. However, the desc_reserve:D CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_reserve:B) */\n\n\t\tif (id_prev_wrap == atomic_long_read(&desc_ring->tail_id\n\t\t\t\t\t\t    )) { /* LMM(desc_reserve:C) */\n\t\t\t/*\n\t\t\t * Make space for the new descriptor by\n\t\t\t * advancing the tail.\n\t\t\t */\n\t\t\tif (!desc_push_tail(rb, id_prev_wrap))\n\t\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee the tail ID is read before validating the\n\t\t *    recycled descriptor state. A read memory barrier is\n\t\t *    sufficient for this. This pairs with desc_push_tail:B.\n\t\t *\n\t\t *    Memory barrier involvement:\n\t\t *\n\t\t *    If desc_reserve:C reads from desc_push_tail:B, then\n\t\t *    desc_reserve:E reads from desc_make_reusable:A.\n\t\t *\n\t\t *    Relies on:\n\t\t *\n\t\t *    MB from desc_make_reusable:A to desc_push_tail:B\n\t\t *       matching\n\t\t *    RMB from desc_reserve:C to desc_reserve:E\n\t\t *\n\t\t *    Note: desc_make_reusable:A and desc_push_tail:B can be\n\t\t *          different CPUs. However, the desc_push_tail:B CPU\n\t\t *          (which performs the full memory barrier) must have\n\t\t *          previously seen desc_make_reusable:A.\n\t\t *\n\t\t * 2. Guarantee the tail ID is stored before storing the head\n\t\t *    ID. This pairs with desc_reserve:B.\n\t\t *\n\t\t * 3. Guarantee any data ring tail changes are stored before\n\t\t *    recycling the descriptor. Data ring tail changes can\n\t\t *    happen via desc_push_tail()->data_push_tail(). A full\n\t\t *    memory barrier is needed since another CPU may have\n\t\t *    pushed the data ring tails. This pairs with\n\t\t *    data_push_tail:B.\n\t\t *\n\t\t * 4. Guarantee a new tail ID is stored before recycling the\n\t\t *    descriptor. A full memory barrier is needed since\n\t\t *    another CPU may have pushed the tail ID. This pairs\n\t\t *    with desc_push_tail:C and this also pairs with\n\t\t *    prb_first_seq:C.\n\t\t *\n\t\t * 5. Guarantee the head ID is stored before trying to\n\t\t *    finalize the previous descriptor. This pairs with\n\t\t *    _prb_commit:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&desc_ring->head_id, &head_id,\n\t\t\t\t\t  id)); /* LMM(desc_reserve:D) */\n\n\tdesc = to_desc(desc_ring, id);\n\n\t/*\n\t * If the descriptor has been recycled, verify the old state val.\n\t * See \"ABA Issues\" about why this verification is performed.\n\t */\n\tprev_state_val = atomic_long_read(&desc->state_var); /* LMM(desc_reserve:E) */\n\tif (prev_state_val &&\n\t    get_desc_state(id_prev_wrap, prev_state_val) != desc_reusable) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Assign the descriptor a new ID and set its state to reserved.\n\t * See \"ABA Issues\" about why cmpxchg() instead of set() is used.\n\t *\n\t * Guarantee the new descriptor ID and state is stored before making\n\t * any other changes. A write memory barrier is sufficient for this.\n\t * This pairs with desc_read:D.\n\t */\n\tif (!atomic_long_try_cmpxchg(&desc->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reserve:F) */\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/* Now data in @desc can be modified: LMM(desc_reserve:G) */\n\n\t*id_out = id;\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "1"
          ],
          "line": 988
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&desc->state_var",
            "&prev_state_val",
            "DESC_SV(id, desc_reserved)"
          ],
          "line": 986
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_reserved"
          ],
          "line": 987
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "1"
          ],
          "line": 974
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_desc_state",
          "args": [
            "id_prev_wrap",
            "prev_state_val"
          ],
          "line": 973
        },
        "resolved": true,
        "details": {
          "function_name": "get_desc_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "414-421",
          "snippet": "static enum desc_state get_desc_state(unsigned long id,\n\t\t\t\t      unsigned long state_val)\n{\n\tif (id != DESC_ID(state_val))\n\t\treturn desc_miss;\n\n\treturn DESC_STATE(state_val);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state get_desc_state(unsigned long id,\n\t\t\t\t      unsigned long state_val)\n{\n\tif (id != DESC_ID(state_val))\n\t\treturn desc_miss;\n\n\treturn DESC_STATE(state_val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc->state_var"
          ],
          "line": 971
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 965
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&desc_ring->head_id",
            "&head_id",
            "id"
          ],
          "line": 962
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "desc_push_tail",
          "args": [
            "rb",
            "id_prev_wrap"
          ],
          "line": 917
        },
        "resolved": true,
        "details": {
          "function_name": "desc_push_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "764-869",
          "snippet": "static bool desc_push_tail(struct printk_ringbuffer *rb,\n\t\t\t   unsigned long tail_id)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\n\td_state = desc_read(desc_ring, tail_id, &desc, NULL, NULL);\n\n\tswitch (d_state) {\n\tcase desc_miss:\n\t\t/*\n\t\t * If the ID is exactly 1 wrap behind the expected, it is\n\t\t * in the process of being reserved by another writer and\n\t\t * must be considered reserved.\n\t\t */\n\t\tif (DESC_ID(atomic_long_read(&desc.state_var)) ==\n\t\t    DESC_ID_PREV_WRAP(desc_ring, tail_id)) {\n\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * The ID has changed. Another writer must have pushed the\n\t\t * tail and recycled the descriptor already. Success is\n\t\t * returned because the caller is only interested in the\n\t\t * specified tail being pushed, which it was.\n\t\t */\n\t\treturn true;\n\tcase desc_reserved:\n\tcase desc_committed:\n\t\treturn false;\n\tcase desc_finalized:\n\t\tdesc_make_reusable(desc_ring, tail_id);\n\t\tbreak;\n\tcase desc_reusable:\n\t\tbreak;\n\t}\n\n\t/*\n\t * Data blocks must be invalidated before their associated\n\t * descriptor can be made available for recycling. Invalidating\n\t * them later is not possible because there is no way to trust\n\t * data blocks once their associated descriptor is gone.\n\t */\n\n\tif (!data_push_tail(rb, desc.text_blk_lpos.next))\n\t\treturn false;\n\n\t/*\n\t * Check the next descriptor after @tail_id before pushing the tail\n\t * to it because the tail must always be in a finalized or reusable\n\t * state. The implementation of prb_first_seq() relies on this.\n\t *\n\t * A successful read implies that the next descriptor is less than or\n\t * equal to @head_id so there is no risk of pushing the tail past the\n\t * head.\n\t */\n\td_state = desc_read(desc_ring, DESC_ID(tail_id + 1), &desc,\n\t\t\t    NULL, NULL); /* LMM(desc_push_tail:A) */\n\n\tif (d_state == desc_finalized || d_state == desc_reusable) {\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail ID. This allows\n\t\t * verifying the recycled descriptor state. A full memory\n\t\t * barrier is needed since other CPUs may have made the\n\t\t * descriptor states reusable. This pairs with desc_reserve:D.\n\t\t */\n\t\tatomic_long_cmpxchg(&desc_ring->tail_id, tail_id,\n\t\t\t\t    DESC_ID(tail_id + 1)); /* LMM(desc_push_tail:B) */\n\t} else {\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail ID in the\n\t\t * case that the descriptor has been recycled. This pairs\n\t\t * with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_push_tail:A reads from desc_reserve:F, then\n\t\t * desc_push_tail:D reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB from desc_push_tail:A to desc_push_tail:D\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:F can be different\n\t\t *       CPUs. However, the desc_reserve:F CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_push_tail:C) */\n\n\t\t/*\n\t\t * Re-check the tail ID. The descriptor following @tail_id is\n\t\t * not in an allowed tail state. But if the tail has since\n\t\t * been moved by another CPU, then it does not matter.\n\t\t */\n\t\tif (atomic_long_read(&desc_ring->tail_id) == tail_id) /* LMM(desc_push_tail:D) */\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool desc_push_tail(struct printk_ringbuffer *rb,\n\t\t\t   unsigned long tail_id)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\n\td_state = desc_read(desc_ring, tail_id, &desc, NULL, NULL);\n\n\tswitch (d_state) {\n\tcase desc_miss:\n\t\t/*\n\t\t * If the ID is exactly 1 wrap behind the expected, it is\n\t\t * in the process of being reserved by another writer and\n\t\t * must be considered reserved.\n\t\t */\n\t\tif (DESC_ID(atomic_long_read(&desc.state_var)) ==\n\t\t    DESC_ID_PREV_WRAP(desc_ring, tail_id)) {\n\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * The ID has changed. Another writer must have pushed the\n\t\t * tail and recycled the descriptor already. Success is\n\t\t * returned because the caller is only interested in the\n\t\t * specified tail being pushed, which it was.\n\t\t */\n\t\treturn true;\n\tcase desc_reserved:\n\tcase desc_committed:\n\t\treturn false;\n\tcase desc_finalized:\n\t\tdesc_make_reusable(desc_ring, tail_id);\n\t\tbreak;\n\tcase desc_reusable:\n\t\tbreak;\n\t}\n\n\t/*\n\t * Data blocks must be invalidated before their associated\n\t * descriptor can be made available for recycling. Invalidating\n\t * them later is not possible because there is no way to trust\n\t * data blocks once their associated descriptor is gone.\n\t */\n\n\tif (!data_push_tail(rb, desc.text_blk_lpos.next))\n\t\treturn false;\n\n\t/*\n\t * Check the next descriptor after @tail_id before pushing the tail\n\t * to it because the tail must always be in a finalized or reusable\n\t * state. The implementation of prb_first_seq() relies on this.\n\t *\n\t * A successful read implies that the next descriptor is less than or\n\t * equal to @head_id so there is no risk of pushing the tail past the\n\t * head.\n\t */\n\td_state = desc_read(desc_ring, DESC_ID(tail_id + 1), &desc,\n\t\t\t    NULL, NULL); /* LMM(desc_push_tail:A) */\n\n\tif (d_state == desc_finalized || d_state == desc_reusable) {\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail ID. This allows\n\t\t * verifying the recycled descriptor state. A full memory\n\t\t * barrier is needed since other CPUs may have made the\n\t\t * descriptor states reusable. This pairs with desc_reserve:D.\n\t\t */\n\t\tatomic_long_cmpxchg(&desc_ring->tail_id, tail_id,\n\t\t\t\t    DESC_ID(tail_id + 1)); /* LMM(desc_push_tail:B) */\n\t} else {\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail ID in the\n\t\t * case that the descriptor has been recycled. This pairs\n\t\t * with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_push_tail:A reads from desc_reserve:F, then\n\t\t * desc_push_tail:D reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB from desc_push_tail:A to desc_push_tail:D\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:F can be different\n\t\t *       CPUs. However, the desc_reserve:F CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_push_tail:C) */\n\n\t\t/*\n\t\t * Re-check the tail ID. The descriptor following @tail_id is\n\t\t * not in an allowed tail state. But if the tail has since\n\t\t * been moved by another CPU, then it does not matter.\n\t\t */\n\t\tif (atomic_long_read(&desc_ring->tail_id) == tail_id) /* LMM(desc_push_tail:D) */\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc_ring->tail_id"
          ],
          "line": 911
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 909
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_ID_PREV_WRAP",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 885
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "head_id + 1"
          ],
          "line": 884
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc_ring->head_id"
          ],
          "line": 881
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool desc_reserve(struct printk_ringbuffer *rb, unsigned long *id_out)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tunsigned long prev_state_val;\n\tunsigned long id_prev_wrap;\n\tstruct prb_desc *desc;\n\tunsigned long head_id;\n\tunsigned long id;\n\n\thead_id = atomic_long_read(&desc_ring->head_id); /* LMM(desc_reserve:A) */\n\n\tdo {\n\t\tid = DESC_ID(head_id + 1);\n\t\tid_prev_wrap = DESC_ID_PREV_WRAP(desc_ring, id);\n\n\t\t/*\n\t\t * Guarantee the head ID is read before reading the tail ID.\n\t\t * Since the tail ID is updated before the head ID, this\n\t\t * guarantees that @id_prev_wrap is never ahead of the tail\n\t\t * ID. This pairs with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_reserve:A reads from desc_reserve:D, then\n\t\t * desc_reserve:C reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:D\n\t\t *    matching\n\t\t * RMB from desc_reserve:A to desc_reserve:C\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:D can be different\n\t\t *       CPUs. However, the desc_reserve:D CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_reserve:B) */\n\n\t\tif (id_prev_wrap == atomic_long_read(&desc_ring->tail_id\n\t\t\t\t\t\t    )) { /* LMM(desc_reserve:C) */\n\t\t\t/*\n\t\t\t * Make space for the new descriptor by\n\t\t\t * advancing the tail.\n\t\t\t */\n\t\t\tif (!desc_push_tail(rb, id_prev_wrap))\n\t\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * 1. Guarantee the tail ID is read before validating the\n\t\t *    recycled descriptor state. A read memory barrier is\n\t\t *    sufficient for this. This pairs with desc_push_tail:B.\n\t\t *\n\t\t *    Memory barrier involvement:\n\t\t *\n\t\t *    If desc_reserve:C reads from desc_push_tail:B, then\n\t\t *    desc_reserve:E reads from desc_make_reusable:A.\n\t\t *\n\t\t *    Relies on:\n\t\t *\n\t\t *    MB from desc_make_reusable:A to desc_push_tail:B\n\t\t *       matching\n\t\t *    RMB from desc_reserve:C to desc_reserve:E\n\t\t *\n\t\t *    Note: desc_make_reusable:A and desc_push_tail:B can be\n\t\t *          different CPUs. However, the desc_push_tail:B CPU\n\t\t *          (which performs the full memory barrier) must have\n\t\t *          previously seen desc_make_reusable:A.\n\t\t *\n\t\t * 2. Guarantee the tail ID is stored before storing the head\n\t\t *    ID. This pairs with desc_reserve:B.\n\t\t *\n\t\t * 3. Guarantee any data ring tail changes are stored before\n\t\t *    recycling the descriptor. Data ring tail changes can\n\t\t *    happen via desc_push_tail()->data_push_tail(). A full\n\t\t *    memory barrier is needed since another CPU may have\n\t\t *    pushed the data ring tails. This pairs with\n\t\t *    data_push_tail:B.\n\t\t *\n\t\t * 4. Guarantee a new tail ID is stored before recycling the\n\t\t *    descriptor. A full memory barrier is needed since\n\t\t *    another CPU may have pushed the tail ID. This pairs\n\t\t *    with desc_push_tail:C and this also pairs with\n\t\t *    prb_first_seq:C.\n\t\t *\n\t\t * 5. Guarantee the head ID is stored before trying to\n\t\t *    finalize the previous descriptor. This pairs with\n\t\t *    _prb_commit:B.\n\t\t */\n\t} while (!atomic_long_try_cmpxchg(&desc_ring->head_id, &head_id,\n\t\t\t\t\t  id)); /* LMM(desc_reserve:D) */\n\n\tdesc = to_desc(desc_ring, id);\n\n\t/*\n\t * If the descriptor has been recycled, verify the old state val.\n\t * See \"ABA Issues\" about why this verification is performed.\n\t */\n\tprev_state_val = atomic_long_read(&desc->state_var); /* LMM(desc_reserve:E) */\n\tif (prev_state_val &&\n\t    get_desc_state(id_prev_wrap, prev_state_val) != desc_reusable) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Assign the descriptor a new ID and set its state to reserved.\n\t * See \"ABA Issues\" about why cmpxchg() instead of set() is used.\n\t *\n\t * Guarantee the new descriptor ID and state is stored before making\n\t * any other changes. A write memory barrier is sufficient for this.\n\t * This pairs with desc_read:D.\n\t */\n\tif (!atomic_long_try_cmpxchg(&desc->state_var, &prev_state_val,\n\t\t\tDESC_SV(id, desc_reserved))) { /* LMM(desc_reserve:F) */\n\t\tWARN_ON_ONCE(1);\n\t\treturn false;\n\t}\n\n\t/* Now data in @desc can be modified: LMM(desc_reserve:G) */\n\n\t*id_out = id;\n\treturn true;\n}"
  },
  {
    "function_name": "desc_push_tail",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "764-869",
    "snippet": "static bool desc_push_tail(struct printk_ringbuffer *rb,\n\t\t\t   unsigned long tail_id)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\n\td_state = desc_read(desc_ring, tail_id, &desc, NULL, NULL);\n\n\tswitch (d_state) {\n\tcase desc_miss:\n\t\t/*\n\t\t * If the ID is exactly 1 wrap behind the expected, it is\n\t\t * in the process of being reserved by another writer and\n\t\t * must be considered reserved.\n\t\t */\n\t\tif (DESC_ID(atomic_long_read(&desc.state_var)) ==\n\t\t    DESC_ID_PREV_WRAP(desc_ring, tail_id)) {\n\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * The ID has changed. Another writer must have pushed the\n\t\t * tail and recycled the descriptor already. Success is\n\t\t * returned because the caller is only interested in the\n\t\t * specified tail being pushed, which it was.\n\t\t */\n\t\treturn true;\n\tcase desc_reserved:\n\tcase desc_committed:\n\t\treturn false;\n\tcase desc_finalized:\n\t\tdesc_make_reusable(desc_ring, tail_id);\n\t\tbreak;\n\tcase desc_reusable:\n\t\tbreak;\n\t}\n\n\t/*\n\t * Data blocks must be invalidated before their associated\n\t * descriptor can be made available for recycling. Invalidating\n\t * them later is not possible because there is no way to trust\n\t * data blocks once their associated descriptor is gone.\n\t */\n\n\tif (!data_push_tail(rb, desc.text_blk_lpos.next))\n\t\treturn false;\n\n\t/*\n\t * Check the next descriptor after @tail_id before pushing the tail\n\t * to it because the tail must always be in a finalized or reusable\n\t * state. The implementation of prb_first_seq() relies on this.\n\t *\n\t * A successful read implies that the next descriptor is less than or\n\t * equal to @head_id so there is no risk of pushing the tail past the\n\t * head.\n\t */\n\td_state = desc_read(desc_ring, DESC_ID(tail_id + 1), &desc,\n\t\t\t    NULL, NULL); /* LMM(desc_push_tail:A) */\n\n\tif (d_state == desc_finalized || d_state == desc_reusable) {\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail ID. This allows\n\t\t * verifying the recycled descriptor state. A full memory\n\t\t * barrier is needed since other CPUs may have made the\n\t\t * descriptor states reusable. This pairs with desc_reserve:D.\n\t\t */\n\t\tatomic_long_cmpxchg(&desc_ring->tail_id, tail_id,\n\t\t\t\t    DESC_ID(tail_id + 1)); /* LMM(desc_push_tail:B) */\n\t} else {\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail ID in the\n\t\t * case that the descriptor has been recycled. This pairs\n\t\t * with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_push_tail:A reads from desc_reserve:F, then\n\t\t * desc_push_tail:D reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB from desc_push_tail:A to desc_push_tail:D\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:F can be different\n\t\t *       CPUs. However, the desc_reserve:F CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_push_tail:C) */\n\n\t\t/*\n\t\t * Re-check the tail ID. The descriptor following @tail_id is\n\t\t * not in an allowed tail state. But if the tail has since\n\t\t * been moved by another CPU, then it does not matter.\n\t\t */\n\t\tif (atomic_long_read(&desc_ring->tail_id) == tail_id) /* LMM(desc_push_tail:D) */\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc_ring->tail_id"
          ],
          "line": 864
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 857
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg",
          "args": [
            "&desc_ring->tail_id",
            "tail_id",
            "DESC_ID(tail_id + 1)"
          ],
          "line": 832
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "tail_id + 1"
          ],
          "line": 833
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "desc_read",
          "args": [
            "desc_ring",
            "DESC_ID(tail_id + 1)",
            "&desc",
            "NULL",
            "NULL"
          ],
          "line": 821
        },
        "resolved": true,
        "details": {
          "function_name": "desc_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "432-533",
          "snippet": "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "tail_id + 1"
          ],
          "line": 821
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_push_tail",
          "args": [
            "rb",
            "desc.text_blk_lpos.next"
          ],
          "line": 809
        },
        "resolved": true,
        "details": {
          "function_name": "data_push_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "629-754",
          "snippet": "static bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "desc_make_reusable",
          "args": [
            "desc_ring",
            "tail_id"
          ],
          "line": 796
        },
        "resolved": true,
        "details": {
          "function_name": "desc_make_reusable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "540-550",
          "snippet": "static void desc_make_reusable(struct prb_desc_ring *desc_ring,\n\t\t\t       unsigned long id)\n{\n\tunsigned long val_finalized = DESC_SV(id, desc_finalized);\n\tunsigned long val_reusable = DESC_SV(id, desc_reusable);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\n\tatomic_long_cmpxchg_relaxed(state_var, val_finalized,\n\t\t\t\t    val_reusable); /* LMM(desc_make_reusable:A) */\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void desc_make_reusable(struct prb_desc_ring *desc_ring,\n\t\t\t       unsigned long id)\n{\n\tunsigned long val_finalized = DESC_SV(id, desc_finalized);\n\tunsigned long val_reusable = DESC_SV(id, desc_reusable);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\n\tatomic_long_cmpxchg_relaxed(state_var, val_finalized,\n\t\t\t\t    val_reusable); /* LMM(desc_make_reusable:A) */\n}"
        }
      },
      {
        "call_info": {
          "callee": "DESC_ID_PREV_WRAP",
          "args": [
            "desc_ring",
            "tail_id"
          ],
          "line": 781
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "atomic_long_read(&desc.state_var)"
          ],
          "line": 780
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&desc.state_var"
          ],
          "line": 780
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool desc_push_tail(struct printk_ringbuffer *rb,\n\t\t\t   unsigned long tail_id)\n{\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\n\td_state = desc_read(desc_ring, tail_id, &desc, NULL, NULL);\n\n\tswitch (d_state) {\n\tcase desc_miss:\n\t\t/*\n\t\t * If the ID is exactly 1 wrap behind the expected, it is\n\t\t * in the process of being reserved by another writer and\n\t\t * must be considered reserved.\n\t\t */\n\t\tif (DESC_ID(atomic_long_read(&desc.state_var)) ==\n\t\t    DESC_ID_PREV_WRAP(desc_ring, tail_id)) {\n\t\t\treturn false;\n\t\t}\n\n\t\t/*\n\t\t * The ID has changed. Another writer must have pushed the\n\t\t * tail and recycled the descriptor already. Success is\n\t\t * returned because the caller is only interested in the\n\t\t * specified tail being pushed, which it was.\n\t\t */\n\t\treturn true;\n\tcase desc_reserved:\n\tcase desc_committed:\n\t\treturn false;\n\tcase desc_finalized:\n\t\tdesc_make_reusable(desc_ring, tail_id);\n\t\tbreak;\n\tcase desc_reusable:\n\t\tbreak;\n\t}\n\n\t/*\n\t * Data blocks must be invalidated before their associated\n\t * descriptor can be made available for recycling. Invalidating\n\t * them later is not possible because there is no way to trust\n\t * data blocks once their associated descriptor is gone.\n\t */\n\n\tif (!data_push_tail(rb, desc.text_blk_lpos.next))\n\t\treturn false;\n\n\t/*\n\t * Check the next descriptor after @tail_id before pushing the tail\n\t * to it because the tail must always be in a finalized or reusable\n\t * state. The implementation of prb_first_seq() relies on this.\n\t *\n\t * A successful read implies that the next descriptor is less than or\n\t * equal to @head_id so there is no risk of pushing the tail past the\n\t * head.\n\t */\n\td_state = desc_read(desc_ring, DESC_ID(tail_id + 1), &desc,\n\t\t\t    NULL, NULL); /* LMM(desc_push_tail:A) */\n\n\tif (d_state == desc_finalized || d_state == desc_reusable) {\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail ID. This allows\n\t\t * verifying the recycled descriptor state. A full memory\n\t\t * barrier is needed since other CPUs may have made the\n\t\t * descriptor states reusable. This pairs with desc_reserve:D.\n\t\t */\n\t\tatomic_long_cmpxchg(&desc_ring->tail_id, tail_id,\n\t\t\t\t    DESC_ID(tail_id + 1)); /* LMM(desc_push_tail:B) */\n\t} else {\n\t\t/*\n\t\t * Guarantee the last state load from desc_read() is before\n\t\t * reloading @tail_id in order to see a new tail ID in the\n\t\t * case that the descriptor has been recycled. This pairs\n\t\t * with desc_reserve:D.\n\t\t *\n\t\t * Memory barrier involvement:\n\t\t *\n\t\t * If desc_push_tail:A reads from desc_reserve:F, then\n\t\t * desc_push_tail:D reads from desc_push_tail:B.\n\t\t *\n\t\t * Relies on:\n\t\t *\n\t\t * MB from desc_push_tail:B to desc_reserve:F\n\t\t *    matching\n\t\t * RMB from desc_push_tail:A to desc_push_tail:D\n\t\t *\n\t\t * Note: desc_push_tail:B and desc_reserve:F can be different\n\t\t *       CPUs. However, the desc_reserve:F CPU (which performs\n\t\t *       the full memory barrier) must have previously seen\n\t\t *       desc_push_tail:B.\n\t\t */\n\t\tsmp_rmb(); /* LMM(desc_push_tail:C) */\n\n\t\t/*\n\t\t * Re-check the tail ID. The descriptor following @tail_id is\n\t\t * not in an allowed tail state. But if the tail has since\n\t\t * been moved by another CPU, then it does not matter.\n\t\t */\n\t\tif (atomic_long_read(&desc_ring->tail_id) == tail_id) /* LMM(desc_push_tail:D) */\n\t\t\treturn false;\n\t}\n\n\treturn true;\n}"
  },
  {
    "function_name": "data_push_tail",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "629-754",
    "snippet": "static bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&data_ring->tail_lpos",
            "&tail_lpos",
            "next_lpos"
          ],
          "line": 747
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&data_ring->tail_lpos"
          ],
          "line": 730
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 728
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_make_reusable",
          "args": [
            "rb",
            "tail_lpos",
            "lpos",
            "&next_lpos"
          ],
          "line": 672
        },
        "resolved": true,
        "details": {
          "function_name": "data_make_reusable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "561-622",
          "snippet": "static bool data_make_reusable(struct printk_ringbuffer *rb,\n\t\t\t       unsigned long lpos_begin,\n\t\t\t       unsigned long lpos_end,\n\t\t\t       unsigned long *lpos_out)\n{\n\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct prb_data_block *blk;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_data_blk_lpos *blk_lpos = &desc.text_blk_lpos;\n\tunsigned long id;\n\n\t/* Loop until @lpos_begin has advanced to or beyond @lpos_end. */\n\twhile ((lpos_end - lpos_begin) - 1 < DATA_SIZE(data_ring)) {\n\t\tblk = to_block(data_ring, lpos_begin);\n\n\t\t/*\n\t\t * Load the block ID from the data block. This is a data race\n\t\t * against a writer that may have newly reserved this data\n\t\t * area. If the loaded value matches a valid descriptor ID,\n\t\t * the blk_lpos of that descriptor will be checked to make\n\t\t * sure it points back to this data block. If the check fails,\n\t\t * the data area has been recycled by another writer.\n\t\t */\n\t\tid = blk->id; /* LMM(data_make_reusable:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc,\n\t\t\t\t    NULL, NULL); /* LMM(data_make_reusable:B) */\n\n\t\tswitch (d_state) {\n\t\tcase desc_miss:\n\t\tcase desc_reserved:\n\t\tcase desc_committed:\n\t\t\treturn false;\n\t\tcase desc_finalized:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tdesc_make_reusable(desc_ring, id);\n\t\t\tbreak;\n\t\tcase desc_reusable:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Advance @lpos_begin to the next data block. */\n\t\tlpos_begin = blk_lpos->next;\n\t}\n\n\t*lpos_out = lpos_begin;\n\treturn true;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_make_reusable(struct printk_ringbuffer *rb,\n\t\t\t       unsigned long lpos_begin,\n\t\t\t       unsigned long lpos_end,\n\t\t\t       unsigned long *lpos_out)\n{\n\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct prb_data_block *blk;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_data_blk_lpos *blk_lpos = &desc.text_blk_lpos;\n\tunsigned long id;\n\n\t/* Loop until @lpos_begin has advanced to or beyond @lpos_end. */\n\twhile ((lpos_end - lpos_begin) - 1 < DATA_SIZE(data_ring)) {\n\t\tblk = to_block(data_ring, lpos_begin);\n\n\t\t/*\n\t\t * Load the block ID from the data block. This is a data race\n\t\t * against a writer that may have newly reserved this data\n\t\t * area. If the loaded value matches a valid descriptor ID,\n\t\t * the blk_lpos of that descriptor will be checked to make\n\t\t * sure it points back to this data block. If the check fails,\n\t\t * the data area has been recycled by another writer.\n\t\t */\n\t\tid = blk->id; /* LMM(data_make_reusable:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc,\n\t\t\t\t    NULL, NULL); /* LMM(data_make_reusable:B) */\n\n\t\tswitch (d_state) {\n\t\tcase desc_miss:\n\t\tcase desc_reserved:\n\t\tcase desc_committed:\n\t\t\treturn false;\n\t\tcase desc_finalized:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tdesc_make_reusable(desc_ring, id);\n\t\t\tbreak;\n\t\tcase desc_reusable:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Advance @lpos_begin to the next data block. */\n\t\tlpos_begin = blk_lpos->next;\n\t}\n\n\t*lpos_out = lpos_begin;\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 667
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&data_ring->tail_lpos"
          ],
          "line": 658
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LPOS_DATALESS",
          "args": [
            "lpos"
          ],
          "line": 637
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_push_tail(struct printk_ringbuffer *rb, unsigned long lpos)\n{\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tunsigned long tail_lpos_new;\n\tunsigned long tail_lpos;\n\tunsigned long next_lpos;\n\n\t/* If @lpos is from a data-less block, there is nothing to do. */\n\tif (LPOS_DATALESS(lpos))\n\t\treturn true;\n\n\t/*\n\t * Any descriptor states that have transitioned to reusable due to the\n\t * data tail being pushed to this loaded value will be visible to this\n\t * CPU. This pairs with data_push_tail:D.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If data_push_tail:A reads from data_push_tail:D, then this CPU can\n\t * see desc_make_reusable:A.\n\t *\n\t * Relies on:\n\t *\n\t * MB from desc_make_reusable:A to data_push_tail:D\n\t *    matches\n\t * READFROM from data_push_tail:D to data_push_tail:A\n\t *    thus\n\t * READFROM from desc_make_reusable:A to this CPU\n\t */\n\ttail_lpos = atomic_long_read(&data_ring->tail_lpos); /* LMM(data_push_tail:A) */\n\n\t/*\n\t * Loop until the tail lpos is at or beyond @lpos. This condition\n\t * may already be satisfied, resulting in no full memory barrier\n\t * from data_push_tail:D being performed. However, since this CPU\n\t * sees the new tail lpos, any descriptor states that transitioned to\n\t * the reusable state must already be visible.\n\t */\n\twhile ((lpos - tail_lpos) - 1 < DATA_SIZE(data_ring)) {\n\t\t/*\n\t\t * Make all descriptors reusable that are associated with\n\t\t * data blocks before @lpos.\n\t\t */\n\t\tif (!data_make_reusable(rb, tail_lpos, lpos, &next_lpos)) {\n\t\t\t/*\n\t\t\t * 1. Guarantee the block ID loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled data area causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    data_alloc:A and data_realloc:A.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:A reads from data_alloc:B,\n\t\t\t *    then data_push_tail:C reads from\n\t\t\t *    data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to data_alloc:B\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:A to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and data_alloc:B can be\n\t\t\t *          different CPUs. However, the data_alloc:B\n\t\t\t *          CPU (which performs the full memory\n\t\t\t *          barrier) must have previously seen\n\t\t\t *          data_push_tail:D.\n\t\t\t *\n\t\t\t * 2. Guarantee the descriptor state loaded in\n\t\t\t *    data_make_reusable() is performed before\n\t\t\t *    reloading the tail lpos. The failed\n\t\t\t *    data_make_reusable() may be due to a newly\n\t\t\t *    recycled descriptor causing the tail lpos to\n\t\t\t *    have been previously pushed. This pairs with\n\t\t\t *    desc_reserve:D.\n\t\t\t *\n\t\t\t *    Memory barrier involvement:\n\t\t\t *\n\t\t\t *    If data_make_reusable:B reads from\n\t\t\t *    desc_reserve:F, then data_push_tail:C reads\n\t\t\t *    from data_push_tail:D.\n\t\t\t *\n\t\t\t *    Relies on:\n\t\t\t *\n\t\t\t *    MB from data_push_tail:D to desc_reserve:F\n\t\t\t *       matching\n\t\t\t *    RMB from data_make_reusable:B to\n\t\t\t *    data_push_tail:C\n\t\t\t *\n\t\t\t *    Note: data_push_tail:D and desc_reserve:F can\n\t\t\t *          be different CPUs. However, the\n\t\t\t *          desc_reserve:F CPU (which performs the\n\t\t\t *          full memory barrier) must have previously\n\t\t\t *          seen data_push_tail:D.\n\t\t\t */\n\t\t\tsmp_rmb(); /* LMM(data_push_tail:B) */\n\n\t\t\ttail_lpos_new = atomic_long_read(&data_ring->tail_lpos\n\t\t\t\t\t\t\t); /* LMM(data_push_tail:C) */\n\t\t\tif (tail_lpos_new == tail_lpos)\n\t\t\t\treturn false;\n\n\t\t\t/* Another CPU pushed the tail. Try again. */\n\t\t\ttail_lpos = tail_lpos_new;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/*\n\t\t * Guarantee any descriptor states that have transitioned to\n\t\t * reusable are stored before pushing the tail lpos. A full\n\t\t * memory barrier is needed since other CPUs may have made\n\t\t * the descriptor states reusable. This pairs with\n\t\t * data_push_tail:A.\n\t\t */\n\t\tif (atomic_long_try_cmpxchg(&data_ring->tail_lpos, &tail_lpos,\n\t\t\t\t\t    next_lpos)) { /* LMM(data_push_tail:D) */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn true;\n}"
  },
  {
    "function_name": "data_make_reusable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "561-622",
    "snippet": "static bool data_make_reusable(struct printk_ringbuffer *rb,\n\t\t\t       unsigned long lpos_begin,\n\t\t\t       unsigned long lpos_end,\n\t\t\t       unsigned long *lpos_out)\n{\n\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct prb_data_block *blk;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_data_blk_lpos *blk_lpos = &desc.text_blk_lpos;\n\tunsigned long id;\n\n\t/* Loop until @lpos_begin has advanced to or beyond @lpos_end. */\n\twhile ((lpos_end - lpos_begin) - 1 < DATA_SIZE(data_ring)) {\n\t\tblk = to_block(data_ring, lpos_begin);\n\n\t\t/*\n\t\t * Load the block ID from the data block. This is a data race\n\t\t * against a writer that may have newly reserved this data\n\t\t * area. If the loaded value matches a valid descriptor ID,\n\t\t * the blk_lpos of that descriptor will be checked to make\n\t\t * sure it points back to this data block. If the check fails,\n\t\t * the data area has been recycled by another writer.\n\t\t */\n\t\tid = blk->id; /* LMM(data_make_reusable:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc,\n\t\t\t\t    NULL, NULL); /* LMM(data_make_reusable:B) */\n\n\t\tswitch (d_state) {\n\t\tcase desc_miss:\n\t\tcase desc_reserved:\n\t\tcase desc_committed:\n\t\t\treturn false;\n\t\tcase desc_finalized:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tdesc_make_reusable(desc_ring, id);\n\t\t\tbreak;\n\t\tcase desc_reusable:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Advance @lpos_begin to the next data block. */\n\t\tlpos_begin = blk_lpos->next;\n\t}\n\n\t*lpos_out = lpos_begin;\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "desc_make_reusable",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 604
        },
        "resolved": true,
        "details": {
          "function_name": "desc_make_reusable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "540-550",
          "snippet": "static void desc_make_reusable(struct prb_desc_ring *desc_ring,\n\t\t\t       unsigned long id)\n{\n\tunsigned long val_finalized = DESC_SV(id, desc_finalized);\n\tunsigned long val_reusable = DESC_SV(id, desc_reusable);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\n\tatomic_long_cmpxchg_relaxed(state_var, val_finalized,\n\t\t\t\t    val_reusable); /* LMM(desc_make_reusable:A) */\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void desc_make_reusable(struct prb_desc_ring *desc_ring,\n\t\t\t       unsigned long id)\n{\n\tunsigned long val_finalized = DESC_SV(id, desc_finalized);\n\tunsigned long val_reusable = DESC_SV(id, desc_reusable);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\n\tatomic_long_cmpxchg_relaxed(state_var, val_finalized,\n\t\t\t\t    val_reusable); /* LMM(desc_make_reusable:A) */\n}"
        }
      },
      {
        "call_info": {
          "callee": "desc_read",
          "args": [
            "desc_ring",
            "id",
            "&desc",
            "NULL",
            "NULL"
          ],
          "line": 589
        },
        "resolved": true,
        "details": {
          "function_name": "desc_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "432-533",
          "snippet": "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_block",
          "args": [
            "data_ring",
            "lpos_begin"
          ],
          "line": 577
        },
        "resolved": true,
        "details": {
          "function_name": "to_block",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "369-373",
          "snippet": "static struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 576
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_make_reusable(struct printk_ringbuffer *rb,\n\t\t\t       unsigned long lpos_begin,\n\t\t\t       unsigned long lpos_end,\n\t\t\t       unsigned long *lpos_out)\n{\n\n\tstruct prb_data_ring *data_ring = &rb->text_data_ring;\n\tstruct prb_desc_ring *desc_ring = &rb->desc_ring;\n\tstruct prb_data_block *blk;\n\tenum desc_state d_state;\n\tstruct prb_desc desc;\n\tstruct prb_data_blk_lpos *blk_lpos = &desc.text_blk_lpos;\n\tunsigned long id;\n\n\t/* Loop until @lpos_begin has advanced to or beyond @lpos_end. */\n\twhile ((lpos_end - lpos_begin) - 1 < DATA_SIZE(data_ring)) {\n\t\tblk = to_block(data_ring, lpos_begin);\n\n\t\t/*\n\t\t * Load the block ID from the data block. This is a data race\n\t\t * against a writer that may have newly reserved this data\n\t\t * area. If the loaded value matches a valid descriptor ID,\n\t\t * the blk_lpos of that descriptor will be checked to make\n\t\t * sure it points back to this data block. If the check fails,\n\t\t * the data area has been recycled by another writer.\n\t\t */\n\t\tid = blk->id; /* LMM(data_make_reusable:A) */\n\n\t\td_state = desc_read(desc_ring, id, &desc,\n\t\t\t\t    NULL, NULL); /* LMM(data_make_reusable:B) */\n\n\t\tswitch (d_state) {\n\t\tcase desc_miss:\n\t\tcase desc_reserved:\n\t\tcase desc_committed:\n\t\t\treturn false;\n\t\tcase desc_finalized:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tdesc_make_reusable(desc_ring, id);\n\t\t\tbreak;\n\t\tcase desc_reusable:\n\t\t\t/*\n\t\t\t * This data block is invalid if the descriptor\n\t\t\t * does not point back to it.\n\t\t\t */\n\t\t\tif (blk_lpos->begin != lpos_begin)\n\t\t\t\treturn false;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Advance @lpos_begin to the next data block. */\n\t\tlpos_begin = blk_lpos->next;\n\t}\n\n\t*lpos_out = lpos_begin;\n\treturn true;\n}"
  },
  {
    "function_name": "desc_make_reusable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "540-550",
    "snippet": "static void desc_make_reusable(struct prb_desc_ring *desc_ring,\n\t\t\t       unsigned long id)\n{\n\tunsigned long val_finalized = DESC_SV(id, desc_finalized);\n\tunsigned long val_reusable = DESC_SV(id, desc_reusable);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\n\tatomic_long_cmpxchg_relaxed(state_var, val_finalized,\n\t\t\t\t    val_reusable); /* LMM(desc_make_reusable:A) */\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_cmpxchg_relaxed",
          "args": [
            "state_var",
            "val_finalized",
            "val_reusable"
          ],
          "line": 548
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 545
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_reusable"
          ],
          "line": 544
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_SV",
          "args": [
            "id",
            "desc_finalized"
          ],
          "line": 543
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic void desc_make_reusable(struct prb_desc_ring *desc_ring,\n\t\t\t       unsigned long id)\n{\n\tunsigned long val_finalized = DESC_SV(id, desc_finalized);\n\tunsigned long val_reusable = DESC_SV(id, desc_reusable);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\n\tatomic_long_cmpxchg_relaxed(state_var, val_finalized,\n\t\t\t\t    val_reusable); /* LMM(desc_make_reusable:A) */\n}"
  },
  {
    "function_name": "desc_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "432-533",
    "snippet": "static enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&desc_out->state_var",
            "state_val"
          ],
          "line": 531
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_desc_state",
          "args": [
            "id",
            "state_val"
          ],
          "line": 529
        },
        "resolved": true,
        "details": {
          "function_name": "get_desc_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "414-421",
          "snippet": "static enum desc_state get_desc_state(unsigned long id,\n\t\t\t\t      unsigned long state_val)\n{\n\tif (id != DESC_ID(state_val))\n\t\treturn desc_miss;\n\n\treturn DESC_STATE(state_val);\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state get_desc_state(unsigned long id,\n\t\t\t\t      unsigned long state_val)\n{\n\tif (id != DESC_ID(state_val))\n\t\treturn desc_miss;\n\n\treturn DESC_STATE(state_val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "state_var"
          ],
          "line": 528
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 522
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "&desc_out->text_blk_lpos",
            "&desc->text_blk_lpos",
            "sizeof(desc_out->text_blk_lpos)"
          ],
          "line": 477
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 470
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "state_var"
          ],
          "line": 443
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_desc",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 437
        },
        "resolved": true,
        "details": {
          "function_name": "to_desc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "355-358",
          "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_info",
          "args": [
            "desc_ring",
            "id"
          ],
          "line": 436
        },
        "resolved": true,
        "details": {
          "function_name": "to_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "364-367",
          "snippet": "static struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state desc_read(struct prb_desc_ring *desc_ring,\n\t\t\t\t unsigned long id, struct prb_desc *desc_out,\n\t\t\t\t u64 *seq_out, u32 *caller_id_out)\n{\n\tstruct printk_info *info = to_info(desc_ring, id);\n\tstruct prb_desc *desc = to_desc(desc_ring, id);\n\tatomic_long_t *state_var = &desc->state_var;\n\tenum desc_state d_state;\n\tunsigned long state_val;\n\n\t/* Check the descriptor state. */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:A) */\n\td_state = get_desc_state(id, state_val);\n\tif (d_state == desc_miss || d_state == desc_reserved) {\n\t\t/*\n\t\t * The descriptor is in an inconsistent state. Set at least\n\t\t * @state_var so that the caller can see the details of\n\t\t * the inconsistent state.\n\t\t */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * Guarantee the state is loaded before copying the descriptor\n\t * content. This avoids copying obsolete descriptor content that might\n\t * not apply to the descriptor state. This pairs with _prb_commit:B.\n\t *\n\t * Memory barrier involvement:\n\t *\n\t * If desc_read:A reads from _prb_commit:B, then desc_read:C reads\n\t * from _prb_commit:A.\n\t *\n\t * Relies on:\n\t *\n\t * WMB from _prb_commit:A to _prb_commit:B\n\t *    matching\n\t * RMB from desc_read:A to desc_read:C\n\t */\n\tsmp_rmb(); /* LMM(desc_read:B) */\n\n\t/*\n\t * Copy the descriptor data. The data is not valid until the\n\t * state has been re-checked. A memcpy() for all of @desc\n\t * cannot be used because of the atomic_t @state_var field.\n\t */\n\tmemcpy(&desc_out->text_blk_lpos, &desc->text_blk_lpos,\n\t       sizeof(desc_out->text_blk_lpos)); /* LMM(desc_read:C) */\n\tif (seq_out)\n\t\t*seq_out = info->seq; /* also part of desc_read:C */\n\tif (caller_id_out)\n\t\t*caller_id_out = info->caller_id; /* also part of desc_read:C */\n\n\t/*\n\t * 1. Guarantee the descriptor content is loaded before re-checking\n\t *    the state. This avoids reading an obsolete descriptor state\n\t *    that may not apply to the copied content. This pairs with\n\t *    desc_reserve:F.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If desc_read:C reads from desc_reserve:G, then desc_read:E\n\t *    reads from desc_reserve:F.\n\t *\n\t *    Relies on:\n\t *\n\t *    WMB from desc_reserve:F to desc_reserve:G\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t * 2. Guarantee the record data is loaded before re-checking the\n\t *    state. This avoids reading an obsolete descriptor state that may\n\t *    not apply to the copied data. This pairs with data_alloc:A and\n\t *    data_realloc:A.\n\t *\n\t *    Memory barrier involvement:\n\t *\n\t *    If copy_data:A reads from data_alloc:B, then desc_read:E\n\t *    reads from desc_make_reusable:A.\n\t *\n\t *    Relies on:\n\t *\n\t *    MB from desc_make_reusable:A to data_alloc:B\n\t *       matching\n\t *    RMB from desc_read:C to desc_read:E\n\t *\n\t *    Note: desc_make_reusable:A and data_alloc:B can be different\n\t *          CPUs. However, the data_alloc:B CPU (which performs the\n\t *          full memory barrier) must have previously seen\n\t *          desc_make_reusable:A.\n\t */\n\tsmp_rmb(); /* LMM(desc_read:D) */\n\n\t/*\n\t * The data has been copied. Return the current descriptor state,\n\t * which may have changed since the load above.\n\t */\n\tstate_val = atomic_long_read(state_var); /* LMM(desc_read:E) */\n\td_state = get_desc_state(id, state_val);\nout:\n\tatomic_long_set(&desc_out->state_var, state_val);\n\treturn d_state;\n}"
  },
  {
    "function_name": "get_desc_state",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "414-421",
    "snippet": "static enum desc_state get_desc_state(unsigned long id,\n\t\t\t\t      unsigned long state_val)\n{\n\tif (id != DESC_ID(state_val))\n\t\treturn desc_miss;\n\n\treturn DESC_STATE(state_val);\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DESC_STATE",
          "args": [
            "state_val"
          ],
          "line": 420
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DESC_ID",
          "args": [
            "state_val"
          ],
          "line": 417
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic enum desc_state get_desc_state(unsigned long id,\n\t\t\t\t      unsigned long state_val)\n{\n\tif (id != DESC_ID(state_val))\n\t\treturn desc_miss;\n\n\treturn DESC_STATE(state_val);\n}"
  },
  {
    "function_name": "data_check_size",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "394-411",
    "snippet": "static bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tif (size == 0)\n\t\treturn true;\n\n\t/*\n\t * Ensure the alignment padded size could possibly fit in the data\n\t * array. The largest possible data block must still leave room for\n\t * at least the ID of the next block.\n\t */\n\tsize = to_blk_size(size);\n\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))\n\t\treturn false;\n\n\treturn true;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DATA_SIZE",
          "args": [
            "data_ring"
          ],
          "line": 407
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_blk_size",
          "args": [
            "size"
          ],
          "line": 406
        },
        "resolved": true,
        "details": {
          "function_name": "to_blk_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
          "lines": "379-386",
          "snippet": "static unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}",
          "includes": [
            "#include \"printk_ringbuffer.h\"",
            "#include <linux/bug.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic bool data_check_size(struct prb_data_ring *data_ring, unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tif (size == 0)\n\t\treturn true;\n\n\t/*\n\t * Ensure the alignment padded size could possibly fit in the data\n\t * array. The largest possible data block must still leave room for\n\t * at least the ID of the next block.\n\t */\n\tsize = to_blk_size(size);\n\tif (size > DATA_SIZE(data_ring) - sizeof(db->id))\n\t\treturn false;\n\n\treturn true;\n}"
  },
  {
    "function_name": "to_blk_size",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "379-386",
    "snippet": "static unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ALIGN",
          "args": [
            "size",
            "sizeof(db->id)"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic unsigned int to_blk_size(unsigned int size)\n{\n\tstruct prb_data_block *db = NULL;\n\n\tsize += sizeof(*db);\n\tsize = ALIGN(size, sizeof(db->id));\n\treturn size;\n}"
  },
  {
    "function_name": "to_block",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "369-373",
    "snippet": "static struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DATA_INDEX",
          "args": [
            "data_ring",
            "begin_lpos"
          ],
          "line": 372
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_data_block *to_block(struct prb_data_ring *data_ring,\n\t\t\t\t       unsigned long begin_lpos)\n{\n\treturn (void *)&data_ring->data[DATA_INDEX(data_ring, begin_lpos)];\n}"
  },
  {
    "function_name": "to_info",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "364-367",
    "snippet": "static struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DESC_INDEX",
          "args": [
            "desc_ring",
            "n"
          ],
          "line": 366
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct printk_info *to_info(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->infos[DESC_INDEX(desc_ring, n)];\n}"
  },
  {
    "function_name": "to_desc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/printk/printk_ringbuffer.c",
    "lines": "355-358",
    "snippet": "static struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}",
    "includes": [
      "#include \"printk_ringbuffer.h\"",
      "#include <linux/bug.h>",
      "#include <linux/errno.h>",
      "#include <linux/string.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/kernel.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DESC_INDEX",
          "args": [
            "desc_ring",
            "n"
          ],
          "line": 357
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"printk_ringbuffer.h\"\n#include <linux/bug.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/irqflags.h>\n#include <linux/kernel.h>\n\nstatic struct prb_desc *to_desc(struct prb_desc_ring *desc_ring, u64 n)\n{\n\treturn &desc_ring->descs[DESC_INDEX(desc_ring, n)];\n}"
  }
]