[
  {
    "function_name": "sched_cpufreq_governor_change",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "850-862",
    "snippet": "void sched_cpufreq_governor_change(struct cpufreq_policy *policy,\n\t\t\t\t  struct cpufreq_governor *old_gov)\n{\n\tif (old_gov == &schedutil_gov || policy->governor == &schedutil_gov) {\n\t\t/*\n\t\t * When called from the cpufreq_register_driver() path, the\n\t\t * cpu_hotplug_lock is already held, so use a work item to\n\t\t * avoid nested locking in rebuild_sched_domains().\n\t\t */\n\t\tschedule_work(&rebuild_sd_work);\n\t}\n\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct cpufreq_governor schedutil_gov;",
      "struct cpufreq_governor schedutil_gov = {\n\t.name\t\t\t= \"schedutil\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= CPUFREQ_GOV_DYNAMIC_SWITCHING,\n\t.init\t\t\t= sugov_init,\n\t.exit\t\t\t= sugov_exit,\n\t.start\t\t\t= sugov_start,\n\t.stop\t\t\t= sugov_stop,\n\t.limits\t\t\t= sugov_limits,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_work",
          "args": [
            "&rebuild_sd_work"
          ],
          "line": 859
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstruct cpufreq_governor schedutil_gov;\nstruct cpufreq_governor schedutil_gov = {\n\t.name\t\t\t= \"schedutil\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= CPUFREQ_GOV_DYNAMIC_SWITCHING,\n\t.init\t\t\t= sugov_init,\n\t.exit\t\t\t= sugov_exit,\n\t.start\t\t\t= sugov_start,\n\t.stop\t\t\t= sugov_stop,\n\t.limits\t\t\t= sugov_limits,\n};\n\nvoid sched_cpufreq_governor_change(struct cpufreq_policy *policy,\n\t\t\t\t  struct cpufreq_governor *old_gov)\n{\n\tif (old_gov == &schedutil_gov || policy->governor == &schedutil_gov) {\n\t\t/*\n\t\t * When called from the cpufreq_register_driver() path, the\n\t\t * cpu_hotplug_lock is already held, so use a work item to\n\t\t * avoid nested locking in rebuild_sched_domains().\n\t\t */\n\t\tschedule_work(&rebuild_sd_work);\n\t}\n\n}"
  },
  {
    "function_name": "rebuild_sd_workfn",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "840-843",
    "snippet": "static void rebuild_sd_workfn(struct work_struct *work)\n{\n\trebuild_sched_domains_energy();\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rebuild_sched_domains_energy",
          "args": [],
          "line": 842
        },
        "resolved": true,
        "details": {
          "function_name": "rebuild_sched_domains_energy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/topology.c",
          "lines": "214-221",
          "snippet": "void rebuild_sched_domains_energy(void)\n{\n\tmutex_lock(&sched_energy_mutex);\n\tsched_energy_update = true;\n\trebuild_sched_domains();\n\tsched_energy_update = false;\n\tmutex_unlock(&sched_energy_mutex);\n}",
          "includes": [
            "#include <linux/sched/sd_flags.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/sd_flags.h>\n#include \"sched.h\"\n\nvoid rebuild_sched_domains_energy(void)\n{\n\tmutex_lock(&sched_energy_mutex);\n\tsched_energy_update = true;\n\trebuild_sched_domains();\n\tsched_energy_update = false;\n\tmutex_unlock(&sched_energy_mutex);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void rebuild_sd_workfn(struct work_struct *work)\n{\n\trebuild_sched_domains_energy();\n}"
  },
  {
    "function_name": "cpufreq_default_governor",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "831-834",
    "snippet": "struct cpufreq_governor *cpufreq_default_governor(void)\n{\n\treturn &schedutil_gov;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct cpufreq_governor schedutil_gov;",
      "struct cpufreq_governor schedutil_gov = {\n\t.name\t\t\t= \"schedutil\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= CPUFREQ_GOV_DYNAMIC_SWITCHING,\n\t.init\t\t\t= sugov_init,\n\t.exit\t\t\t= sugov_exit,\n\t.start\t\t\t= sugov_start,\n\t.stop\t\t\t= sugov_stop,\n\t.limits\t\t\t= sugov_limits,\n};"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstruct cpufreq_governor schedutil_gov;\nstruct cpufreq_governor schedutil_gov = {\n\t.name\t\t\t= \"schedutil\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= CPUFREQ_GOV_DYNAMIC_SWITCHING,\n\t.init\t\t\t= sugov_init,\n\t.exit\t\t\t= sugov_exit,\n\t.start\t\t\t= sugov_start,\n\t.stop\t\t\t= sugov_stop,\n\t.limits\t\t\t= sugov_limits,\n};\n\nstruct cpufreq_governor *cpufreq_default_governor(void)\n{\n\treturn &schedutil_gov;\n}"
  },
  {
    "function_name": "sugov_limits",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "806-817",
    "snippet": "static void sugov_limits(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\n\tif (!policy->fast_switch_enabled) {\n\t\tmutex_lock(&sg_policy->work_lock);\n\t\tcpufreq_policy_apply_limits(policy);\n\t\tmutex_unlock(&sg_policy->work_lock);\n\t}\n\n\tsg_policy->limits_changed = true;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&sg_policy->work_lock"
          ],
          "line": 813
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpufreq_policy_apply_limits",
          "args": [
            "policy"
          ],
          "line": 812
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&sg_policy->work_lock"
          ],
          "line": 811
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_limits(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\n\tif (!policy->fast_switch_enabled) {\n\t\tmutex_lock(&sg_policy->work_lock);\n\t\tcpufreq_policy_apply_limits(policy);\n\t\tmutex_unlock(&sg_policy->work_lock);\n\t}\n\n\tsg_policy->limits_changed = true;\n}"
  },
  {
    "function_name": "sugov_stop",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "790-804",
    "snippet": "static void sugov_stop(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\tunsigned int cpu;\n\n\tfor_each_cpu(cpu, policy->cpus)\n\t\tcpufreq_remove_update_util_hook(cpu);\n\n\tsynchronize_rcu();\n\n\tif (!policy->fast_switch_enabled) {\n\t\tirq_work_sync(&sg_policy->irq_work);\n\t\tkthread_cancel_work_sync(&sg_policy->work);\n\t}\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kthread_cancel_work_sync",
          "args": [
            "&sg_policy->work"
          ],
          "line": 802
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_cancel_work_sync",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "1339-1342",
          "snippet": "bool kthread_cancel_work_sync(struct kthread_work *work)\n{\n\treturn __kthread_cancel_work_sync(work, false);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_cancel_work_sync(struct kthread_work *work)\n{\n\treturn __kthread_cancel_work_sync(work, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_work_sync",
          "args": [
            "&sg_policy->irq_work"
          ],
          "line": 801
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_sync",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "276-290",
          "snippet": "void irq_work_sync(struct irq_work *work)\n{\n\tlockdep_assert_irqs_enabled();\n\tmight_sleep();\n\n\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||\n\t    !arch_irq_work_has_interrupt()) {\n\t\trcuwait_wait_event(&work->irqwait, !irq_work_is_busy(work),\n\t\t\t\t   TASK_UNINTERRUPTIBLE);\n\t\treturn;\n\t}\n\n\twhile (irq_work_is_busy(work))\n\t\tcpu_relax();\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nvoid irq_work_sync(struct irq_work *work)\n{\n\tlockdep_assert_irqs_enabled();\n\tmight_sleep();\n\n\tif ((IS_ENABLED(CONFIG_PREEMPT_RT) && !irq_work_is_hard(work)) ||\n\t    !arch_irq_work_has_interrupt()) {\n\t\trcuwait_wait_event(&work->irqwait, !irq_work_is_busy(work),\n\t\t\t\t   TASK_UNINTERRUPTIBLE);\n\t\treturn;\n\t}\n\n\twhile (irq_work_is_busy(work))\n\t\tcpu_relax();\n}"
        }
      },
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 798
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_expedited",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "816-865",
          "snippet": "void synchronize_rcu_expedited(void)\n{\n\tbool boottime = (rcu_scheduler_active == RCU_SCHEDULER_INIT);\n\tstruct rcu_exp_work rew;\n\tstruct rcu_node *rnp;\n\tunsigned long s;\n\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu_expedited() in RCU read-side critical section\");\n\n\t/* Is the state is such that the call is a grace period? */\n\tif (rcu_blocking_is_gp())\n\t\treturn;\n\n\t/* If expedited grace periods are prohibited, fall back to normal. */\n\tif (rcu_gp_is_normal()) {\n\t\twait_rcu_gp(call_rcu);\n\t\treturn;\n\t}\n\n\t/* Take a snapshot of the sequence number.  */\n\ts = rcu_exp_gp_seq_snap();\n\tif (exp_funnel_lock(s))\n\t\treturn;  /* Someone else did our work for us. */\n\n\t/* Ensure that load happens before action based on it. */\n\tif (unlikely(boottime)) {\n\t\t/* Direct call during scheduler init and early_initcalls(). */\n\t\trcu_exp_sel_wait_wake(s);\n\t} else {\n\t\t/* Marshall arguments & schedule the expedited grace period. */\n\t\trew.rew_s = s;\n\t\tINIT_WORK_ONSTACK(&rew.rew_work, wait_rcu_exp_gp);\n\t\tqueue_work(rcu_gp_wq, &rew.rew_work);\n\t}\n\n\t/* Wait for expedited grace period to complete. */\n\trnp = rcu_get_root();\n\twait_event(rnp->exp_wq[rcu_seq_ctr(s) & 0x3],\n\t\t   sync_exp_work_done(s));\n\tsmp_mb(); /* Workqueue actions happen before return. */\n\n\t/* Let the next expedited grace period start. */\n\tmutex_unlock(&rcu_state.exp_mutex);\n\n\tif (likely(!boottime))\n\t\tdestroy_work_on_stack(&rew.rew_work);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int rcu_print_task_exp_stall(struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic int rcu_print_task_exp_stall(struct rcu_node *rnp);\n\nvoid synchronize_rcu_expedited(void)\n{\n\tbool boottime = (rcu_scheduler_active == RCU_SCHEDULER_INIT);\n\tstruct rcu_exp_work rew;\n\tstruct rcu_node *rnp;\n\tunsigned long s;\n\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu_expedited() in RCU read-side critical section\");\n\n\t/* Is the state is such that the call is a grace period? */\n\tif (rcu_blocking_is_gp())\n\t\treturn;\n\n\t/* If expedited grace periods are prohibited, fall back to normal. */\n\tif (rcu_gp_is_normal()) {\n\t\twait_rcu_gp(call_rcu);\n\t\treturn;\n\t}\n\n\t/* Take a snapshot of the sequence number.  */\n\ts = rcu_exp_gp_seq_snap();\n\tif (exp_funnel_lock(s))\n\t\treturn;  /* Someone else did our work for us. */\n\n\t/* Ensure that load happens before action based on it. */\n\tif (unlikely(boottime)) {\n\t\t/* Direct call during scheduler init and early_initcalls(). */\n\t\trcu_exp_sel_wait_wake(s);\n\t} else {\n\t\t/* Marshall arguments & schedule the expedited grace period. */\n\t\trew.rew_s = s;\n\t\tINIT_WORK_ONSTACK(&rew.rew_work, wait_rcu_exp_gp);\n\t\tqueue_work(rcu_gp_wq, &rew.rew_work);\n\t}\n\n\t/* Wait for expedited grace period to complete. */\n\trnp = rcu_get_root();\n\twait_event(rnp->exp_wq[rcu_seq_ctr(s) & 0x3],\n\t\t   sync_exp_work_done(s));\n\tsmp_mb(); /* Workqueue actions happen before return. */\n\n\t/* Let the next expedited grace period start. */\n\tmutex_unlock(&rcu_state.exp_mutex);\n\n\tif (likely(!boottime))\n\t\tdestroy_work_on_stack(&rew.rew_work);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpufreq_remove_update_util_hook",
          "args": [
            "cpu"
          ],
          "line": 796
        },
        "resolved": true,
        "details": {
          "function_name": "cpufreq_remove_update_util_hook",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq.c",
          "lines": "57-60",
          "snippet": "void cpufreq_remove_update_util_hook(int cpu)\n{\n\trcu_assign_pointer(per_cpu(cpufreq_update_util_data, cpu), NULL);\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/cpufreq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/cpufreq.h>\n\nvoid cpufreq_remove_update_util_hook(int cpu)\n{\n\trcu_assign_pointer(per_cpu(cpufreq_update_util_data, cpu), NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "cpu",
            "policy->cpus"
          ],
          "line": 795
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_stop(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\tunsigned int cpu;\n\n\tfor_each_cpu(cpu, policy->cpus)\n\t\tcpufreq_remove_update_util_hook(cpu);\n\n\tsynchronize_rcu();\n\n\tif (!policy->fast_switch_enabled) {\n\t\tirq_work_sync(&sg_policy->irq_work);\n\t\tkthread_cancel_work_sync(&sg_policy->work);\n\t}\n}"
  },
  {
    "function_name": "sugov_start",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "752-788",
    "snippet": "static int sugov_start(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\tvoid (*uu)(struct update_util_data *data, u64 time, unsigned int flags);\n\tunsigned int cpu;\n\n\tsg_policy->freq_update_delay_ns\t= sg_policy->tunables->rate_limit_us * NSEC_PER_USEC;\n\tsg_policy->last_freq_update_time\t= 0;\n\tsg_policy->next_freq\t\t\t= 0;\n\tsg_policy->work_in_progress\t\t= false;\n\tsg_policy->limits_changed\t\t= false;\n\tsg_policy->cached_raw_freq\t\t= 0;\n\n\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\n\tfor_each_cpu(cpu, policy->cpus) {\n\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);\n\n\t\tmemset(sg_cpu, 0, sizeof(*sg_cpu));\n\t\tsg_cpu->cpu\t\t\t= cpu;\n\t\tsg_cpu->sg_policy\t\t= sg_policy;\n\t}\n\n\tif (policy_is_shared(policy))\n\t\tuu = sugov_update_shared;\n\telse if (policy->fast_switch_enabled && cpufreq_driver_has_adjust_perf())\n\t\tuu = sugov_update_single_perf;\n\telse\n\t\tuu = sugov_update_single_freq;\n\n\tfor_each_cpu(cpu, policy->cpus) {\n\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);\n\n\t\tcpufreq_add_update_util_hook(cpu, &sg_cpu->update_util, uu);\n\t}\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);",
      "static struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpufreq_add_update_util_hook",
          "args": [
            "cpu",
            "&sg_cpu->update_util",
            "uu"
          ],
          "line": 785
        },
        "resolved": true,
        "details": {
          "function_name": "cpufreq_add_update_util_hook",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq.c",
          "lines": "32-44",
          "snippet": "void cpufreq_add_update_util_hook(int cpu, struct update_util_data *data,\n\t\t\tvoid (*func)(struct update_util_data *data, u64 time,\n\t\t\t\t     unsigned int flags))\n{\n\tif (WARN_ON(!data || !func))\n\t\treturn;\n\n\tif (WARN_ON(per_cpu(cpufreq_update_util_data, cpu)))\n\t\treturn;\n\n\tdata->func = func;\n\trcu_assign_pointer(per_cpu(cpufreq_update_util_data, cpu), data);\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/cpufreq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/cpufreq.h>\n\nvoid cpufreq_add_update_util_hook(int cpu, struct update_util_data *data,\n\t\t\tvoid (*func)(struct update_util_data *data, u64 time,\n\t\t\t\t     unsigned int flags))\n{\n\tif (WARN_ON(!data || !func))\n\t\treturn;\n\n\tif (WARN_ON(per_cpu(cpufreq_update_util_data, cpu)))\n\t\treturn;\n\n\tdata->func = func;\n\trcu_assign_pointer(per_cpu(cpufreq_update_util_data, cpu), data);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "sugov_cpu",
            "cpu"
          ],
          "line": 783
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_set_per_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "588-603",
          "snippet": "void kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "cpu",
            "policy->cpus"
          ],
          "line": 782
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpufreq_driver_has_adjust_perf",
          "args": [],
          "line": 777
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "policy_is_shared",
          "args": [
            "policy"
          ],
          "line": 775
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "sg_cpu",
            "0",
            "sizeof(*sg_cpu)"
          ],
          "line": 770
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "cpu",
            "policy->cpus"
          ],
          "line": 767
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpufreq_driver_test_flags",
          "args": [
            "CPUFREQ_NEED_UPDATE_LIMITS"
          ],
          "line": 765
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\nstatic struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);\n\nstatic int sugov_start(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\tvoid (*uu)(struct update_util_data *data, u64 time, unsigned int flags);\n\tunsigned int cpu;\n\n\tsg_policy->freq_update_delay_ns\t= sg_policy->tunables->rate_limit_us * NSEC_PER_USEC;\n\tsg_policy->last_freq_update_time\t= 0;\n\tsg_policy->next_freq\t\t\t= 0;\n\tsg_policy->work_in_progress\t\t= false;\n\tsg_policy->limits_changed\t\t= false;\n\tsg_policy->cached_raw_freq\t\t= 0;\n\n\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\n\tfor_each_cpu(cpu, policy->cpus) {\n\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);\n\n\t\tmemset(sg_cpu, 0, sizeof(*sg_cpu));\n\t\tsg_cpu->cpu\t\t\t= cpu;\n\t\tsg_cpu->sg_policy\t\t= sg_policy;\n\t}\n\n\tif (policy_is_shared(policy))\n\t\tuu = sugov_update_shared;\n\telse if (policy->fast_switch_enabled && cpufreq_driver_has_adjust_perf())\n\t\tuu = sugov_update_single_perf;\n\telse\n\t\tuu = sugov_update_single_freq;\n\n\tfor_each_cpu(cpu, policy->cpus) {\n\t\tstruct sugov_cpu *sg_cpu = &per_cpu(sugov_cpu, cpu);\n\n\t\tcpufreq_add_update_util_hook(cpu, &sg_cpu->update_util, uu);\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "sugov_exit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "732-750",
    "snippet": "static void sugov_exit(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\tstruct sugov_tunables *tunables = sg_policy->tunables;\n\tunsigned int count;\n\n\tmutex_lock(&global_tunables_lock);\n\n\tcount = gov_attr_set_put(&tunables->attr_set, &sg_policy->tunables_hook);\n\tpolicy->governor_data = NULL;\n\tif (!count)\n\t\tsugov_clear_global_tunables();\n\n\tmutex_unlock(&global_tunables_lock);\n\n\tsugov_kthread_stop(sg_policy);\n\tsugov_policy_free(sg_policy);\n\tcpufreq_disable_fast_switch(policy);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_MUTEX(global_tunables_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpufreq_disable_fast_switch",
          "args": [
            "policy"
          ],
          "line": 749
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_policy_free",
          "args": [
            "sg_policy"
          ],
          "line": 748
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_policy_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "570-573",
          "snippet": "static void sugov_policy_free(struct sugov_policy *sg_policy)\n{\n\tkfree(sg_policy);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_policy_free(struct sugov_policy *sg_policy)\n{\n\tkfree(sg_policy);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_kthread_stop",
          "args": [
            "sg_policy"
          ],
          "line": 747
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_kthread_stop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "626-635",
          "snippet": "static void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&global_tunables_lock"
          ],
          "line": 745
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_clear_global_tunables",
          "args": [],
          "line": 743
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_clear_global_tunables",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "650-654",
          "snippet": "static void sugov_clear_global_tunables(void)\n{\n\tif (!have_governor_per_policy())\n\t\tglobal_tunables = NULL;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct sugov_tunables *global_tunables;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_tunables *global_tunables;\n\nstatic void sugov_clear_global_tunables(void)\n{\n\tif (!have_governor_per_policy())\n\t\tglobal_tunables = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "gov_attr_set_put",
          "args": [
            "&tunables->attr_set",
            "&sg_policy->tunables_hook"
          ],
          "line": 740
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&global_tunables_lock"
          ],
          "line": 738
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_MUTEX(global_tunables_lock);\n\nstatic void sugov_exit(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy = policy->governor_data;\n\tstruct sugov_tunables *tunables = sg_policy->tunables;\n\tunsigned int count;\n\n\tmutex_lock(&global_tunables_lock);\n\n\tcount = gov_attr_set_put(&tunables->attr_set, &sg_policy->tunables_hook);\n\tpolicy->governor_data = NULL;\n\tif (!count)\n\t\tsugov_clear_global_tunables();\n\n\tmutex_unlock(&global_tunables_lock);\n\n\tsugov_kthread_stop(sg_policy);\n\tsugov_policy_free(sg_policy);\n\tcpufreq_disable_fast_switch(policy);\n}"
  },
  {
    "function_name": "sugov_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "656-730",
    "snippet": "static int sugov_init(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy;\n\tstruct sugov_tunables *tunables;\n\tint ret = 0;\n\n\t/* State should be equivalent to EXIT */\n\tif (policy->governor_data)\n\t\treturn -EBUSY;\n\n\tcpufreq_enable_fast_switch(policy);\n\n\tsg_policy = sugov_policy_alloc(policy);\n\tif (!sg_policy) {\n\t\tret = -ENOMEM;\n\t\tgoto disable_fast_switch;\n\t}\n\n\tret = sugov_kthread_create(sg_policy);\n\tif (ret)\n\t\tgoto free_sg_policy;\n\n\tmutex_lock(&global_tunables_lock);\n\n\tif (global_tunables) {\n\t\tif (WARN_ON(have_governor_per_policy())) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto stop_kthread;\n\t\t}\n\t\tpolicy->governor_data = sg_policy;\n\t\tsg_policy->tunables = global_tunables;\n\n\t\tgov_attr_set_get(&global_tunables->attr_set, &sg_policy->tunables_hook);\n\t\tgoto out;\n\t}\n\n\ttunables = sugov_tunables_alloc(sg_policy);\n\tif (!tunables) {\n\t\tret = -ENOMEM;\n\t\tgoto stop_kthread;\n\t}\n\n\ttunables->rate_limit_us = cpufreq_policy_transition_delay_us(policy);\n\n\tpolicy->governor_data = sg_policy;\n\tsg_policy->tunables = tunables;\n\n\tret = kobject_init_and_add(&tunables->attr_set.kobj, &sugov_tunables_ktype,\n\t\t\t\t   get_governor_parent_kobj(policy), \"%s\",\n\t\t\t\t   schedutil_gov.name);\n\tif (ret)\n\t\tgoto fail;\n\nout:\n\tmutex_unlock(&global_tunables_lock);\n\treturn 0;\n\nfail:\n\tkobject_put(&tunables->attr_set.kobj);\n\tpolicy->governor_data = NULL;\n\tsugov_clear_global_tunables();\n\nstop_kthread:\n\tsugov_kthread_stop(sg_policy);\n\tmutex_unlock(&global_tunables_lock);\n\nfree_sg_policy:\n\tsugov_policy_free(sg_policy);\n\ndisable_fast_switch:\n\tcpufreq_disable_fast_switch(policy);\n\n\tpr_err(\"initialization failed (error %d)\\n\", ret);\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct sugov_tunables *global_tunables;",
      "static DEFINE_MUTEX(global_tunables_lock);",
      "static struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);",
      "static struct kobj_type sugov_tunables_ktype = {\n\t.default_groups = sugov_groups,\n\t.sysfs_ops = &governor_sysfs_ops,\n\t.release = &sugov_tunables_free,\n};",
      "struct cpufreq_governor schedutil_gov;",
      "struct cpufreq_governor schedutil_gov = {\n\t.name\t\t\t= \"schedutil\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= CPUFREQ_GOV_DYNAMIC_SWITCHING,\n\t.init\t\t\t= sugov_init,\n\t.exit\t\t\t= sugov_exit,\n\t.start\t\t\t= sugov_start,\n\t.stop\t\t\t= sugov_stop,\n\t.limits\t\t\t= sugov_limits,\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"initialization failed (error %d)\\n\"",
            "ret"
          ],
          "line": 728
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpufreq_disable_fast_switch",
          "args": [
            "policy"
          ],
          "line": 726
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_policy_free",
          "args": [
            "sg_policy"
          ],
          "line": 723
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_policy_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "570-573",
          "snippet": "static void sugov_policy_free(struct sugov_policy *sg_policy)\n{\n\tkfree(sg_policy);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_policy_free(struct sugov_policy *sg_policy)\n{\n\tkfree(sg_policy);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&global_tunables_lock"
          ],
          "line": 720
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_kthread_stop",
          "args": [
            "sg_policy"
          ],
          "line": 719
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_kthread_stop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "626-635",
          "snippet": "static void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_clear_global_tunables",
          "args": [],
          "line": 716
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_clear_global_tunables",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "650-654",
          "snippet": "static void sugov_clear_global_tunables(void)\n{\n\tif (!have_governor_per_policy())\n\t\tglobal_tunables = NULL;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct sugov_tunables *global_tunables;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_tunables *global_tunables;\n\nstatic void sugov_clear_global_tunables(void)\n{\n\tif (!have_governor_per_policy())\n\t\tglobal_tunables = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kobject_put",
          "args": [
            "&tunables->attr_set.kobj"
          ],
          "line": 714
        },
        "resolved": true,
        "details": {
          "function_name": "mod_kobject_put",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/module.c",
          "lines": "1804-1810",
          "snippet": "static void mod_kobject_put(struct module *mod)\n{\n\tDECLARE_COMPLETION_ONSTACK(c);\n\tmod->mkobj.kobj_completion = &c;\n\tkobject_put(&mod->mkobj.kobj);\n\twait_for_completion(&c);\n}",
          "includes": [
            "#include <trace/events/module.h>",
            "#include \"module-internal.h\"",
            "#include <uapi/linux/module.h>",
            "#include <linux/audit.h>",
            "#include <linux/dynamic_debug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/pfn.h>",
            "#include <linux/jump_label.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/percpu.h>",
            "#include <linux/async.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/tracepoint.h>",
            "#include <asm/sections.h>",
            "#include <linux/license.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/set_memory.h>",
            "#include <asm/cacheflush.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/rculist.h>",
            "#include <linux/mutex.h>",
            "#include <linux/string.h>",
            "#include <linux/device.h>",
            "#include <linux/sched.h>",
            "#include <linux/notifier.h>",
            "#include <linux/vermagic.h>",
            "#include <linux/err.h>",
            "#include <linux/errno.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/elf.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel_read_file.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/buildid.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/module_signature.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/extable.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void cfi_cleanup(struct module *mod);",
            "static void cfi_init(struct module *mod);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/module.h>\n#include \"module-internal.h\"\n#include <uapi/linux/module.h>\n#include <linux/audit.h>\n#include <linux/dynamic_debug.h>\n#include <linux/bsearch.h>\n#include <linux/pfn.h>\n#include <linux/jump_label.h>\n#include <linux/kmemleak.h>\n#include <linux/percpu.h>\n#include <linux/async.h>\n#include <linux/livepatch.h>\n#include <linux/ftrace.h>\n#include <linux/tracepoint.h>\n#include <asm/sections.h>\n#include <linux/license.h>\n#include <asm/mmu_context.h>\n#include <linux/set_memory.h>\n#include <asm/cacheflush.h>\n#include <linux/uaccess.h>\n#include <linux/rculist.h>\n#include <linux/mutex.h>\n#include <linux/string.h>\n#include <linux/device.h>\n#include <linux/sched.h>\n#include <linux/notifier.h>\n#include <linux/vermagic.h>\n#include <linux/err.h>\n#include <linux/errno.h>\n#include <linux/moduleparam.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/rcupdate.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/elf.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/kernel_read_file.h>\n#include <linux/kernel.h>\n#include <linux/sysfs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/buildid.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/trace_events.h>\n#include <linux/module_signature.h>\n#include <linux/moduleloader.h>\n#include <linux/extable.h>\n#include <linux/export.h>\n\nstatic void cfi_cleanup(struct module *mod);\nstatic void cfi_init(struct module *mod);\n\nstatic void mod_kobject_put(struct module *mod)\n{\n\tDECLARE_COMPLETION_ONSTACK(c);\n\tmod->mkobj.kobj_completion = &c;\n\tkobject_put(&mod->mkobj.kobj);\n\twait_for_completion(&c);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kobject_init_and_add",
          "args": [
            "&tunables->attr_set.kobj",
            "&sugov_tunables_ktype",
            "get_governor_parent_kobj(policy)",
            "\"%s\"",
            "schedutil_gov.name"
          ],
          "line": 703
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_governor_parent_kobj",
          "args": [
            "policy"
          ],
          "line": 704
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpufreq_policy_transition_delay_us",
          "args": [
            "policy"
          ],
          "line": 698
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_tunables_alloc",
          "args": [
            "sg_policy"
          ],
          "line": 692
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_tunables_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "637-648",
          "snippet": "static struct sugov_tunables *sugov_tunables_alloc(struct sugov_policy *sg_policy)\n{\n\tstruct sugov_tunables *tunables;\n\n\ttunables = kzalloc(sizeof(*tunables), GFP_KERNEL);\n\tif (tunables) {\n\t\tgov_attr_set_init(&tunables->attr_set, &sg_policy->tunables_hook);\n\t\tif (!have_governor_per_policy())\n\t\t\tglobal_tunables = tunables;\n\t}\n\treturn tunables;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct sugov_tunables *global_tunables;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_tunables *global_tunables;\n\nstatic struct sugov_tunables *sugov_tunables_alloc(struct sugov_policy *sg_policy)\n{\n\tstruct sugov_tunables *tunables;\n\n\ttunables = kzalloc(sizeof(*tunables), GFP_KERNEL);\n\tif (tunables) {\n\t\tgov_attr_set_init(&tunables->attr_set, &sg_policy->tunables_hook);\n\t\tif (!have_governor_per_policy())\n\t\t\tglobal_tunables = tunables;\n\t}\n\treturn tunables;\n}"
        }
      },
      {
        "call_info": {
          "callee": "gov_attr_set_get",
          "args": [
            "&global_tunables->attr_set",
            "&sg_policy->tunables_hook"
          ],
          "line": 688
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "have_governor_per_policy()"
          ],
          "line": 681
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "have_governor_per_policy",
          "args": [],
          "line": 681
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&global_tunables_lock"
          ],
          "line": 678
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_kthread_create",
          "args": [
            "sg_policy"
          ],
          "line": 674
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_kthread_create",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "575-624",
          "snippet": "static int sugov_kthread_create(struct sugov_policy *sg_policy)\n{\n\tstruct task_struct *thread;\n\tstruct sched_attr attr = {\n\t\t.size\t\t= sizeof(struct sched_attr),\n\t\t.sched_policy\t= SCHED_DEADLINE,\n\t\t.sched_flags\t= SCHED_FLAG_SUGOV,\n\t\t.sched_nice\t= 0,\n\t\t.sched_priority\t= 0,\n\t\t/*\n\t\t * Fake (unused) bandwidth; workaround to \"fix\"\n\t\t * priority inheritance.\n\t\t */\n\t\t.sched_runtime\t=  1000000,\n\t\t.sched_deadline = 10000000,\n\t\t.sched_period\t= 10000000,\n\t};\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tint ret;\n\n\t/* kthread only required for slow path */\n\tif (policy->fast_switch_enabled)\n\t\treturn 0;\n\n\tkthread_init_work(&sg_policy->work, sugov_work);\n\tkthread_init_worker(&sg_policy->worker);\n\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,\n\t\t\t\t\"sugov:%d\",\n\t\t\t\tcpumask_first(policy->related_cpus));\n\tif (IS_ERR(thread)) {\n\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));\n\t\treturn PTR_ERR(thread);\n\t}\n\n\tret = sched_setattr_nocheck(thread, &attr);\n\tif (ret) {\n\t\tkthread_stop(thread);\n\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);\n\t\treturn ret;\n\t}\n\n\tsg_policy->thread = thread;\n\tkthread_bind_mask(thread, policy->related_cpus);\n\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);\n\tmutex_init(&sg_policy->work_lock);\n\n\twake_up_process(thread);\n\n\treturn 0;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic int sugov_kthread_create(struct sugov_policy *sg_policy)\n{\n\tstruct task_struct *thread;\n\tstruct sched_attr attr = {\n\t\t.size\t\t= sizeof(struct sched_attr),\n\t\t.sched_policy\t= SCHED_DEADLINE,\n\t\t.sched_flags\t= SCHED_FLAG_SUGOV,\n\t\t.sched_nice\t= 0,\n\t\t.sched_priority\t= 0,\n\t\t/*\n\t\t * Fake (unused) bandwidth; workaround to \"fix\"\n\t\t * priority inheritance.\n\t\t */\n\t\t.sched_runtime\t=  1000000,\n\t\t.sched_deadline = 10000000,\n\t\t.sched_period\t= 10000000,\n\t};\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tint ret;\n\n\t/* kthread only required for slow path */\n\tif (policy->fast_switch_enabled)\n\t\treturn 0;\n\n\tkthread_init_work(&sg_policy->work, sugov_work);\n\tkthread_init_worker(&sg_policy->worker);\n\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,\n\t\t\t\t\"sugov:%d\",\n\t\t\t\tcpumask_first(policy->related_cpus));\n\tif (IS_ERR(thread)) {\n\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));\n\t\treturn PTR_ERR(thread);\n\t}\n\n\tret = sched_setattr_nocheck(thread, &attr);\n\tif (ret) {\n\t\tkthread_stop(thread);\n\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);\n\t\treturn ret;\n\t}\n\n\tsg_policy->thread = thread;\n\tkthread_bind_mask(thread, policy->related_cpus);\n\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);\n\tmutex_init(&sg_policy->work_lock);\n\n\twake_up_process(thread);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_policy_alloc",
          "args": [
            "policy"
          ],
          "line": 668
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_policy_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "557-568",
          "snippet": "static struct sugov_policy *sugov_policy_alloc(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy;\n\n\tsg_policy = kzalloc(sizeof(*sg_policy), GFP_KERNEL);\n\tif (!sg_policy)\n\t\treturn NULL;\n\n\tsg_policy->policy = policy;\n\traw_spin_lock_init(&sg_policy->update_lock);\n\treturn sg_policy;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_policy *sugov_policy_alloc(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy;\n\n\tsg_policy = kzalloc(sizeof(*sg_policy), GFP_KERNEL);\n\tif (!sg_policy)\n\t\treturn NULL;\n\n\tsg_policy->policy = policy;\n\traw_spin_lock_init(&sg_policy->update_lock);\n\treturn sg_policy;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpufreq_enable_fast_switch",
          "args": [
            "policy"
          ],
          "line": 666
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_tunables *global_tunables;\nstatic DEFINE_MUTEX(global_tunables_lock);\nstatic struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);\nstatic struct kobj_type sugov_tunables_ktype = {\n\t.default_groups = sugov_groups,\n\t.sysfs_ops = &governor_sysfs_ops,\n\t.release = &sugov_tunables_free,\n};\nstruct cpufreq_governor schedutil_gov;\nstruct cpufreq_governor schedutil_gov = {\n\t.name\t\t\t= \"schedutil\",\n\t.owner\t\t\t= THIS_MODULE,\n\t.flags\t\t\t= CPUFREQ_GOV_DYNAMIC_SWITCHING,\n\t.init\t\t\t= sugov_init,\n\t.exit\t\t\t= sugov_exit,\n\t.start\t\t\t= sugov_start,\n\t.stop\t\t\t= sugov_stop,\n\t.limits\t\t\t= sugov_limits,\n};\n\nstatic int sugov_init(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy;\n\tstruct sugov_tunables *tunables;\n\tint ret = 0;\n\n\t/* State should be equivalent to EXIT */\n\tif (policy->governor_data)\n\t\treturn -EBUSY;\n\n\tcpufreq_enable_fast_switch(policy);\n\n\tsg_policy = sugov_policy_alloc(policy);\n\tif (!sg_policy) {\n\t\tret = -ENOMEM;\n\t\tgoto disable_fast_switch;\n\t}\n\n\tret = sugov_kthread_create(sg_policy);\n\tif (ret)\n\t\tgoto free_sg_policy;\n\n\tmutex_lock(&global_tunables_lock);\n\n\tif (global_tunables) {\n\t\tif (WARN_ON(have_governor_per_policy())) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto stop_kthread;\n\t\t}\n\t\tpolicy->governor_data = sg_policy;\n\t\tsg_policy->tunables = global_tunables;\n\n\t\tgov_attr_set_get(&global_tunables->attr_set, &sg_policy->tunables_hook);\n\t\tgoto out;\n\t}\n\n\ttunables = sugov_tunables_alloc(sg_policy);\n\tif (!tunables) {\n\t\tret = -ENOMEM;\n\t\tgoto stop_kthread;\n\t}\n\n\ttunables->rate_limit_us = cpufreq_policy_transition_delay_us(policy);\n\n\tpolicy->governor_data = sg_policy;\n\tsg_policy->tunables = tunables;\n\n\tret = kobject_init_and_add(&tunables->attr_set.kobj, &sugov_tunables_ktype,\n\t\t\t\t   get_governor_parent_kobj(policy), \"%s\",\n\t\t\t\t   schedutil_gov.name);\n\tif (ret)\n\t\tgoto fail;\n\nout:\n\tmutex_unlock(&global_tunables_lock);\n\treturn 0;\n\nfail:\n\tkobject_put(&tunables->attr_set.kobj);\n\tpolicy->governor_data = NULL;\n\tsugov_clear_global_tunables();\n\nstop_kthread:\n\tsugov_kthread_stop(sg_policy);\n\tmutex_unlock(&global_tunables_lock);\n\nfree_sg_policy:\n\tsugov_policy_free(sg_policy);\n\ndisable_fast_switch:\n\tcpufreq_disable_fast_switch(policy);\n\n\tpr_err(\"initialization failed (error %d)\\n\", ret);\n\treturn ret;\n}"
  },
  {
    "function_name": "sugov_clear_global_tunables",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "650-654",
    "snippet": "static void sugov_clear_global_tunables(void)\n{\n\tif (!have_governor_per_policy())\n\t\tglobal_tunables = NULL;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct sugov_tunables *global_tunables;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "have_governor_per_policy",
          "args": [],
          "line": 652
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_tunables *global_tunables;\n\nstatic void sugov_clear_global_tunables(void)\n{\n\tif (!have_governor_per_policy())\n\t\tglobal_tunables = NULL;\n}"
  },
  {
    "function_name": "sugov_tunables_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "637-648",
    "snippet": "static struct sugov_tunables *sugov_tunables_alloc(struct sugov_policy *sg_policy)\n{\n\tstruct sugov_tunables *tunables;\n\n\ttunables = kzalloc(sizeof(*tunables), GFP_KERNEL);\n\tif (tunables) {\n\t\tgov_attr_set_init(&tunables->attr_set, &sg_policy->tunables_hook);\n\t\tif (!have_governor_per_policy())\n\t\t\tglobal_tunables = tunables;\n\t}\n\treturn tunables;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct sugov_tunables *global_tunables;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "have_governor_per_policy",
          "args": [],
          "line": 644
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "gov_attr_set_init",
          "args": [
            "&tunables->attr_set",
            "&sg_policy->tunables_hook"
          ],
          "line": 643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*tunables)",
            "GFP_KERNEL"
          ],
          "line": 641
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_tunables *global_tunables;\n\nstatic struct sugov_tunables *sugov_tunables_alloc(struct sugov_policy *sg_policy)\n{\n\tstruct sugov_tunables *tunables;\n\n\ttunables = kzalloc(sizeof(*tunables), GFP_KERNEL);\n\tif (tunables) {\n\t\tgov_attr_set_init(&tunables->attr_set, &sg_policy->tunables_hook);\n\t\tif (!have_governor_per_policy())\n\t\t\tglobal_tunables = tunables;\n\t}\n\treturn tunables;\n}"
  },
  {
    "function_name": "sugov_kthread_stop",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "626-635",
    "snippet": "static void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_destroy",
          "args": [
            "&sg_policy->work_lock"
          ],
          "line": 634
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/mutex-debug.c",
          "lines": "100-104",
          "snippet": "void mutex_destroy(struct mutex *lock)\n{\n\tDEBUG_LOCKS_WARN_ON(mutex_is_locked(lock));\n\tlock->magic = NULL;\n}",
          "includes": [
            "#include \"mutex.h\"",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/poison.h>",
            "#include <linux/export.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mutex.h\"\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/sched.h>\n#include <linux/poison.h>\n#include <linux/export.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n\nvoid mutex_destroy(struct mutex *lock)\n{\n\tDEBUG_LOCKS_WARN_ON(mutex_is_locked(lock));\n\tlock->magic = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "kthread_stop",
          "args": [
            "sg_policy->thread"
          ],
          "line": 633
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_kthread_stop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "626-635",
          "snippet": "static void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "kthread_flush_worker",
          "args": [
            "&sg_policy->worker"
          ],
          "line": 632
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_flush_worker",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "1367-1376",
          "snippet": "void kthread_flush_worker(struct kthread_worker *worker)\n{\n\tstruct kthread_flush_work fwork = {\n\t\tKTHREAD_WORK_INIT(fwork.work, kthread_flush_work_fn),\n\t\tCOMPLETION_INITIALIZER_ONSTACK(fwork.done),\n\t};\n\n\tkthread_queue_work(worker, &fwork.work);\n\twait_for_completion(&fwork.done);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_flush_worker(struct kthread_worker *worker)\n{\n\tstruct kthread_flush_work fwork = {\n\t\tKTHREAD_WORK_INIT(fwork.work, kthread_flush_work_fn),\n\t\tCOMPLETION_INITIALIZER_ONSTACK(fwork.done),\n\t};\n\n\tkthread_queue_work(worker, &fwork.work);\n\twait_for_completion(&fwork.done);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}"
  },
  {
    "function_name": "sugov_kthread_create",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "575-624",
    "snippet": "static int sugov_kthread_create(struct sugov_policy *sg_policy)\n{\n\tstruct task_struct *thread;\n\tstruct sched_attr attr = {\n\t\t.size\t\t= sizeof(struct sched_attr),\n\t\t.sched_policy\t= SCHED_DEADLINE,\n\t\t.sched_flags\t= SCHED_FLAG_SUGOV,\n\t\t.sched_nice\t= 0,\n\t\t.sched_priority\t= 0,\n\t\t/*\n\t\t * Fake (unused) bandwidth; workaround to \"fix\"\n\t\t * priority inheritance.\n\t\t */\n\t\t.sched_runtime\t=  1000000,\n\t\t.sched_deadline = 10000000,\n\t\t.sched_period\t= 10000000,\n\t};\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tint ret;\n\n\t/* kthread only required for slow path */\n\tif (policy->fast_switch_enabled)\n\t\treturn 0;\n\n\tkthread_init_work(&sg_policy->work, sugov_work);\n\tkthread_init_worker(&sg_policy->worker);\n\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,\n\t\t\t\t\"sugov:%d\",\n\t\t\t\tcpumask_first(policy->related_cpus));\n\tif (IS_ERR(thread)) {\n\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));\n\t\treturn PTR_ERR(thread);\n\t}\n\n\tret = sched_setattr_nocheck(thread, &attr);\n\tif (ret) {\n\t\tkthread_stop(thread);\n\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);\n\t\treturn ret;\n\t}\n\n\tsg_policy->thread = thread;\n\tkthread_bind_mask(thread, policy->related_cpus);\n\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);\n\tmutex_init(&sg_policy->work_lock);\n\n\twake_up_process(thread);\n\n\treturn 0;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "thread"
          ],
          "line": 621
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4215-4218",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_init",
          "args": [
            "&sg_policy->work_lock"
          ],
          "line": 619
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_init_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/fork.c",
          "lines": "1700-1708",
          "snippet": "static void rt_mutex_init_task(struct task_struct *p)\n{\n\traw_spin_lock_init(&p->pi_lock);\n#ifdef CONFIG_RT_MUTEXES\n\tp->pi_waiters = RB_ROOT_CACHED;\n\tp->pi_top_task = NULL;\n\tp->pi_blocked_on = NULL;\n#endif\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <linux/bpf.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/scs.h>",
            "#include <linux/kasan.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/anon_inodes.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <linux/bpf.h>\n#include <linux/io_uring.h>\n#include <linux/scs.h>\n#include <linux/kasan.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm_inline.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/seq_file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n\nstatic __latent_entropy struct;\n\nstatic void rt_mutex_init_task(struct task_struct *p)\n{\n\traw_spin_lock_init(&p->pi_lock);\n#ifdef CONFIG_RT_MUTEXES\n\tp->pi_waiters = RB_ROOT_CACHED;\n\tp->pi_top_task = NULL;\n\tp->pi_blocked_on = NULL;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_irq_work",
          "args": [
            "&sg_policy->irq_work",
            "sugov_irq_work"
          ],
          "line": 618
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_bind_mask",
          "args": [
            "thread",
            "policy->related_cpus"
          ],
          "line": 617
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_bind_mask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "541-544",
          "snippet": "void kthread_bind_mask(struct task_struct *p, const struct cpumask *mask)\n{\n\t__kthread_bind_mask(p, mask, TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_bind_mask(struct task_struct *p, const struct cpumask *mask)\n{\n\t__kthread_bind_mask(p, mask, TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_warn",
          "args": [
            "\"%s: failed to set SCHED_DEADLINE\\n\"",
            "__func__"
          ],
          "line": 612
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_stop",
          "args": [
            "thread"
          ],
          "line": 611
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_kthread_stop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "626-635",
          "snippet": "static void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_kthread_stop(struct sugov_policy *sg_policy)\n{\n\t/* kthread only required for slow path */\n\tif (sg_policy->policy->fast_switch_enabled)\n\t\treturn;\n\n\tkthread_flush_worker(&sg_policy->worker);\n\tkthread_stop(sg_policy->thread);\n\tmutex_destroy(&sg_policy->work_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_setattr_nocheck",
          "args": [
            "thread",
            "&attr"
          ],
          "line": 609
        },
        "resolved": true,
        "details": {
          "function_name": "sched_setattr_nocheck",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "7546-7549",
          "snippet": "int sched_setattr_nocheck(struct task_struct *p, const struct sched_attr *attr)\n{\n\treturn __sched_setscheduler(p, attr, false, true);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint sched_setattr_nocheck(struct task_struct *p, const struct sched_attr *attr)\n{\n\treturn __sched_setscheduler(p, attr, false, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "thread"
          ],
          "line": 606
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"failed to create sugov thread: %ld\\n\"",
            "PTR_ERR(thread)"
          ],
          "line": 605
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "thread"
          ],
          "line": 605
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "thread"
          ],
          "line": 604
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_create",
          "args": [
            "kthread_worker_fn",
            "&sg_policy->worker",
            "\"sugov:%d\"",
            "cpumask_first(policy->related_cpus)"
          ],
          "line": 601
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_create_worker",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "882-893",
          "snippet": "struct kthread_worker *\nkthread_create_worker(unsigned int flags, const char namefmt[], ...)\n{\n\tstruct kthread_worker *worker;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\tworker = __kthread_create_worker(-1, flags, namefmt, args);\n\tva_end(args);\n\n\treturn worker;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;",
            "static __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nstatic __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;\nstatic __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;\n\nstruct kthread_worker *\nkthread_create_worker(unsigned int flags, const char namefmt[], ...)\n{\n\tstruct kthread_worker *worker;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\tworker = __kthread_create_worker(-1, flags, namefmt, args);\n\tva_end(args);\n\n\treturn worker;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_first",
          "args": [
            "policy->related_cpus"
          ],
          "line": 603
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_init_worker",
          "args": [
            "&sg_policy->worker"
          ],
          "line": 600
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_init_work",
          "args": [
            "&sg_policy->work",
            "sugov_work"
          ],
          "line": 599
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic int sugov_kthread_create(struct sugov_policy *sg_policy)\n{\n\tstruct task_struct *thread;\n\tstruct sched_attr attr = {\n\t\t.size\t\t= sizeof(struct sched_attr),\n\t\t.sched_policy\t= SCHED_DEADLINE,\n\t\t.sched_flags\t= SCHED_FLAG_SUGOV,\n\t\t.sched_nice\t= 0,\n\t\t.sched_priority\t= 0,\n\t\t/*\n\t\t * Fake (unused) bandwidth; workaround to \"fix\"\n\t\t * priority inheritance.\n\t\t */\n\t\t.sched_runtime\t=  1000000,\n\t\t.sched_deadline = 10000000,\n\t\t.sched_period\t= 10000000,\n\t};\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tint ret;\n\n\t/* kthread only required for slow path */\n\tif (policy->fast_switch_enabled)\n\t\treturn 0;\n\n\tkthread_init_work(&sg_policy->work, sugov_work);\n\tkthread_init_worker(&sg_policy->worker);\n\tthread = kthread_create(kthread_worker_fn, &sg_policy->worker,\n\t\t\t\t\"sugov:%d\",\n\t\t\t\tcpumask_first(policy->related_cpus));\n\tif (IS_ERR(thread)) {\n\t\tpr_err(\"failed to create sugov thread: %ld\\n\", PTR_ERR(thread));\n\t\treturn PTR_ERR(thread);\n\t}\n\n\tret = sched_setattr_nocheck(thread, &attr);\n\tif (ret) {\n\t\tkthread_stop(thread);\n\t\tpr_warn(\"%s: failed to set SCHED_DEADLINE\\n\", __func__);\n\t\treturn ret;\n\t}\n\n\tsg_policy->thread = thread;\n\tkthread_bind_mask(thread, policy->related_cpus);\n\tinit_irq_work(&sg_policy->irq_work, sugov_irq_work);\n\tmutex_init(&sg_policy->work_lock);\n\n\twake_up_process(thread);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "sugov_policy_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "570-573",
    "snippet": "static void sugov_policy_free(struct sugov_policy *sg_policy)\n{\n\tkfree(sg_policy);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "sg_policy"
          ],
          "line": 572
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_policy_free(struct sugov_policy *sg_policy)\n{\n\tkfree(sg_policy);\n}"
  },
  {
    "function_name": "sugov_policy_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "557-568",
    "snippet": "static struct sugov_policy *sugov_policy_alloc(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy;\n\n\tsg_policy = kzalloc(sizeof(*sg_policy), GFP_KERNEL);\n\tif (!sg_policy)\n\t\treturn NULL;\n\n\tsg_policy->policy = policy;\n\traw_spin_lock_init(&sg_policy->update_lock);\n\treturn sg_policy;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&sg_policy->update_lock"
          ],
          "line": 566
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*sg_policy)",
            "GFP_KERNEL"
          ],
          "line": 561
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct sugov_policy *sugov_policy_alloc(struct cpufreq_policy *policy)\n{\n\tstruct sugov_policy *sg_policy;\n\n\tsg_policy = kzalloc(sizeof(*sg_policy), GFP_KERNEL);\n\tif (!sg_policy)\n\t\treturn NULL;\n\n\tsg_policy->policy = policy;\n\traw_spin_lock_init(&sg_policy->update_lock);\n\treturn sg_policy;\n}"
  },
  {
    "function_name": "sugov_tunables_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "540-545",
    "snippet": "static void sugov_tunables_free(struct kobject *kobj)\n{\n\tstruct gov_attr_set *attr_set = container_of(kobj, struct gov_attr_set, kobj);\n\n\tkfree(to_sugov_tunables(attr_set));\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "to_sugov_tunables(attr_set)"
          ],
          "line": 544
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "to_sugov_tunables",
          "args": [
            "attr_set"
          ],
          "line": 544
        },
        "resolved": true,
        "details": {
          "function_name": "to_sugov_tunables",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "502-505",
          "snippet": "static inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "kobj",
            "structgov_attr_set",
            "kobj"
          ],
          "line": 542
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_tunables_free(struct kobject *kobj)\n{\n\tstruct gov_attr_set *attr_set = container_of(kobj, struct gov_attr_set, kobj);\n\n\tkfree(to_sugov_tunables(attr_set));\n}"
  },
  {
    "function_name": "rate_limit_us_store",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "514-530",
    "snippet": "static ssize_t\nrate_limit_us_store(struct gov_attr_set *attr_set, const char *buf, size_t count)\n{\n\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);\n\tstruct sugov_policy *sg_policy;\n\tunsigned int rate_limit_us;\n\n\tif (kstrtouint(buf, 10, &rate_limit_us))\n\t\treturn -EINVAL;\n\n\ttunables->rate_limit_us = rate_limit_us;\n\n\tlist_for_each_entry(sg_policy, &attr_set->policy_list, tunables_hook)\n\t\tsg_policy->freq_update_delay_ns = rate_limit_us * NSEC_PER_USEC;\n\n\treturn count;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "sg_policy",
            "&attr_set->policy_list",
            "tunables_hook"
          ],
          "line": 526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kstrtouint",
          "args": [
            "buf",
            "10",
            "&rate_limit_us"
          ],
          "line": 521
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_sugov_tunables",
          "args": [
            "attr_set"
          ],
          "line": 517
        },
        "resolved": true,
        "details": {
          "function_name": "to_sugov_tunables",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "502-505",
          "snippet": "static inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);\n\nstatic ssize_t\nrate_limit_us_store(struct gov_attr_set *attr_set, const char *buf, size_t count)\n{\n\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);\n\tstruct sugov_policy *sg_policy;\n\tunsigned int rate_limit_us;\n\n\tif (kstrtouint(buf, 10, &rate_limit_us))\n\t\treturn -EINVAL;\n\n\ttunables->rate_limit_us = rate_limit_us;\n\n\tlist_for_each_entry(sg_policy, &attr_set->policy_list, tunables_hook)\n\t\tsg_policy->freq_update_delay_ns = rate_limit_us * NSEC_PER_USEC;\n\n\treturn count;\n}"
  },
  {
    "function_name": "rate_limit_us_show",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "507-512",
    "snippet": "static ssize_t rate_limit_us_show(struct gov_attr_set *attr_set, char *buf)\n{\n\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);\n\n\treturn sprintf(buf, \"%u\\n\", tunables->rate_limit_us);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sprintf",
          "args": [
            "buf",
            "\"%u\\n\"",
            "tunables->rate_limit_us"
          ],
          "line": 511
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "to_sugov_tunables",
          "args": [
            "attr_set"
          ],
          "line": 509
        },
        "resolved": true,
        "details": {
          "function_name": "to_sugov_tunables",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "502-505",
          "snippet": "static inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic struct governor_attr rate_limit_us = __ATTR_RW(rate_limit_us);\n\nstatic ssize_t rate_limit_us_show(struct gov_attr_set *attr_set, char *buf)\n{\n\tstruct sugov_tunables *tunables = to_sugov_tunables(attr_set);\n\n\treturn sprintf(buf, \"%u\\n\", tunables->rate_limit_us);\n}"
  },
  {
    "function_name": "to_sugov_tunables",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "502-505",
    "snippet": "static inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "attr_set",
            "structsugov_tunables",
            "attr_set"
          ],
          "line": 504
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic inline struct sugov_tunables *to_sugov_tunables(struct gov_attr_set *attr_set)\n{\n\treturn container_of(attr_set, struct sugov_tunables, attr_set);\n}"
  },
  {
    "function_name": "sugov_irq_work",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "488-495",
    "snippet": "static void sugov_irq_work(struct irq_work *irq_work)\n{\n\tstruct sugov_policy *sg_policy;\n\n\tsg_policy = container_of(irq_work, struct sugov_policy, irq_work);\n\n\tkthread_queue_work(&sg_policy->worker, &sg_policy->work);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kthread_queue_work",
          "args": [
            "&sg_policy->worker",
            "&sg_policy->work"
          ],
          "line": 494
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_queue_work",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "995-1008",
          "snippet": "bool kthread_queue_work(struct kthread_worker *worker,\n\t\t\tstruct kthread_work *work)\n{\n\tbool ret = false;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&worker->lock, flags);\n\tif (!queuing_blocked(worker, work)) {\n\t\tkthread_insert_work(worker, work, &worker->work_list);\n\t\tret = true;\n\t}\n\traw_spin_unlock_irqrestore(&worker->lock, flags);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_queue_work(struct kthread_worker *worker,\n\t\t\tstruct kthread_work *work)\n{\n\tbool ret = false;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&worker->lock, flags);\n\tif (!queuing_blocked(worker, work)) {\n\t\tkthread_insert_work(worker, work, &worker->work_list);\n\t\tret = true;\n\t}\n\traw_spin_unlock_irqrestore(&worker->lock, flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "irq_work",
            "structsugov_policy",
            "irq_work"
          ],
          "line": 492
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_irq_work(struct irq_work *irq_work)\n{\n\tstruct sugov_policy *sg_policy;\n\n\tsg_policy = container_of(irq_work, struct sugov_policy, irq_work);\n\n\tkthread_queue_work(&sg_policy->worker, &sg_policy->work);\n}"
  },
  {
    "function_name": "sugov_work",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "462-486",
    "snippet": "static void sugov_work(struct kthread_work *work)\n{\n\tstruct sugov_policy *sg_policy = container_of(work, struct sugov_policy, work);\n\tunsigned int freq;\n\tunsigned long flags;\n\n\t/*\n\t * Hold sg_policy->update_lock shortly to handle the case where:\n\t * in case sg_policy->next_freq is read here, and then updated by\n\t * sugov_deferred_update() just before work_in_progress is set to false\n\t * here, we may miss queueing the new update.\n\t *\n\t * Note: If a work was queued after the update_lock is released,\n\t * sugov_work() will just be called again by kthread_work code; and the\n\t * request will be proceed before the sugov thread sleeps.\n\t */\n\traw_spin_lock_irqsave(&sg_policy->update_lock, flags);\n\tfreq = sg_policy->next_freq;\n\tsg_policy->work_in_progress = false;\n\traw_spin_unlock_irqrestore(&sg_policy->update_lock, flags);\n\n\tmutex_lock(&sg_policy->work_lock);\n\t__cpufreq_driver_target(sg_policy->policy, freq, CPUFREQ_RELATION_L);\n\tmutex_unlock(&sg_policy->work_lock);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&sg_policy->work_lock"
          ],
          "line": 485
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpufreq_driver_target",
          "args": [
            "sg_policy->policy",
            "freq",
            "CPUFREQ_RELATION_L"
          ],
          "line": 484
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&sg_policy->work_lock"
          ],
          "line": 483
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&sg_policy->update_lock",
            "flags"
          ],
          "line": 481
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&sg_policy->update_lock",
            "flags"
          ],
          "line": 478
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structsugov_policy",
            "work"
          ],
          "line": 464
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_work(struct kthread_work *work)\n{\n\tstruct sugov_policy *sg_policy = container_of(work, struct sugov_policy, work);\n\tunsigned int freq;\n\tunsigned long flags;\n\n\t/*\n\t * Hold sg_policy->update_lock shortly to handle the case where:\n\t * in case sg_policy->next_freq is read here, and then updated by\n\t * sugov_deferred_update() just before work_in_progress is set to false\n\t * here, we may miss queueing the new update.\n\t *\n\t * Note: If a work was queued after the update_lock is released,\n\t * sugov_work() will just be called again by kthread_work code; and the\n\t * request will be proceed before the sugov thread sleeps.\n\t */\n\traw_spin_lock_irqsave(&sg_policy->update_lock, flags);\n\tfreq = sg_policy->next_freq;\n\tsg_policy->work_in_progress = false;\n\traw_spin_unlock_irqrestore(&sg_policy->update_lock, flags);\n\n\tmutex_lock(&sg_policy->work_lock);\n\t__cpufreq_driver_target(sg_policy->policy, freq, CPUFREQ_RELATION_L);\n\tmutex_unlock(&sg_policy->work_lock);\n}"
  },
  {
    "function_name": "sugov_update_shared",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "433-460",
    "snippet": "static void\nsugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tunsigned int next_f;\n\n\traw_spin_lock(&sg_policy->update_lock);\n\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (sugov_should_update_freq(sg_policy, time)) {\n\t\tnext_f = sugov_next_freq_shared(sg_cpu, time);\n\n\t\tif (!sugov_update_next_freq(sg_policy, time, next_f))\n\t\t\tgoto unlock;\n\n\t\tif (sg_policy->policy->fast_switch_enabled)\n\t\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);\n\t\telse\n\t\t\tsugov_deferred_update(sg_policy);\n\t}\nunlock:\n\traw_spin_unlock(&sg_policy->update_lock);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&sg_policy->update_lock"
          ],
          "line": 459
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_deferred_update",
          "args": [
            "sg_policy"
          ],
          "line": 456
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_deferred_update",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "117-123",
          "snippet": "static void sugov_deferred_update(struct sugov_policy *sg_policy)\n{\n\tif (!sg_policy->work_in_progress) {\n\t\tsg_policy->work_in_progress = true;\n\t\tirq_work_queue(&sg_policy->irq_work);\n\t}\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_deferred_update(struct sugov_policy *sg_policy)\n{\n\tif (!sg_policy->work_in_progress) {\n\t\tsg_policy->work_in_progress = true;\n\t\tirq_work_queue(&sg_policy->irq_work);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpufreq_driver_fast_switch",
          "args": [
            "sg_policy->policy",
            "next_f"
          ],
          "line": 454
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_update_next_freq",
          "args": [
            "sg_policy",
            "time",
            "next_f"
          ],
          "line": 450
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_update_next_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "103-115",
          "snippet": "static bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,\n\t\t\t\t   unsigned int next_freq)\n{\n\tif (sg_policy->need_freq_update)\n\t\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\telse if (sg_policy->next_freq == next_freq)\n\t\treturn false;\n\n\tsg_policy->next_freq = next_freq;\n\tsg_policy->last_freq_update_time = time;\n\n\treturn true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,\n\t\t\t\t   unsigned int next_freq)\n{\n\tif (sg_policy->need_freq_update)\n\t\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\telse if (sg_policy->next_freq == next_freq)\n\t\treturn false;\n\n\tsg_policy->next_freq = next_freq;\n\tsg_policy->last_freq_update_time = time;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_next_freq_shared",
          "args": [
            "sg_cpu",
            "time"
          ],
          "line": 448
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_next_freq_shared",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "408-431",
          "snippet": "static unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned long util = 0, max = 1;\n\tunsigned int j;\n\n\tfor_each_cpu(j, policy->cpus) {\n\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);\n\t\tunsigned long j_util, j_max;\n\n\t\tsugov_get_util(j_sg_cpu);\n\t\tsugov_iowait_apply(j_sg_cpu, time);\n\t\tj_util = j_sg_cpu->util;\n\t\tj_max = j_sg_cpu->max;\n\n\t\tif (j_util * max > j_max * util) {\n\t\t\tutil = j_util;\n\t\t\tmax = j_max;\n\t\t}\n\t}\n\n\treturn get_next_freq(sg_policy, util, max);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned long util = 0, max = 1;\n\tunsigned int j;\n\n\tfor_each_cpu(j, policy->cpus) {\n\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);\n\t\tunsigned long j_util, j_max;\n\n\t\tsugov_get_util(j_sg_cpu);\n\t\tsugov_iowait_apply(j_sg_cpu, time);\n\t\tj_util = j_sg_cpu->util;\n\t\tj_max = j_sg_cpu->max;\n\n\t\tif (j_util * max > j_max * util) {\n\t\t\tutil = j_util;\n\t\t\tmax = j_max;\n\t\t}\n\t}\n\n\treturn get_next_freq(sg_policy, util, max);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_should_update_freq",
          "args": [
            "sg_policy",
            "time"
          ],
          "line": 447
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_should_update_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "70-101",
          "snippet": "static bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)\n{\n\ts64 delta_ns;\n\n\t/*\n\t * Since cpufreq_update_util() is called with rq->lock held for\n\t * the @target_cpu, our per-CPU data is fully serialized.\n\t *\n\t * However, drivers cannot in general deal with cross-CPU\n\t * requests, so while get_next_freq() will work, our\n\t * sugov_update_commit() call may not for the fast switching platforms.\n\t *\n\t * Hence stop here for remote requests if they aren't supported\n\t * by the hardware, as calculating the frequency is pointless if\n\t * we cannot in fact act on it.\n\t *\n\t * This is needed on the slow switching platforms too to prevent CPUs\n\t * going offline from leaving stale IRQ work items behind.\n\t */\n\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))\n\t\treturn false;\n\n\tif (unlikely(sg_policy->limits_changed)) {\n\t\tsg_policy->limits_changed = false;\n\t\tsg_policy->need_freq_update = true;\n\t\treturn true;\n\t}\n\n\tdelta_ns = time - sg_policy->last_freq_update_time;\n\n\treturn delta_ns >= sg_policy->freq_update_delay_ns;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)\n{\n\ts64 delta_ns;\n\n\t/*\n\t * Since cpufreq_update_util() is called with rq->lock held for\n\t * the @target_cpu, our per-CPU data is fully serialized.\n\t *\n\t * However, drivers cannot in general deal with cross-CPU\n\t * requests, so while get_next_freq() will work, our\n\t * sugov_update_commit() call may not for the fast switching platforms.\n\t *\n\t * Hence stop here for remote requests if they aren't supported\n\t * by the hardware, as calculating the frequency is pointless if\n\t * we cannot in fact act on it.\n\t *\n\t * This is needed on the slow switching platforms too to prevent CPUs\n\t * going offline from leaving stale IRQ work items behind.\n\t */\n\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))\n\t\treturn false;\n\n\tif (unlikely(sg_policy->limits_changed)) {\n\t\tsg_policy->limits_changed = false;\n\t\tsg_policy->need_freq_update = true;\n\t\treturn true;\n\t}\n\n\tdelta_ns = time - sg_policy->last_freq_update_time;\n\n\treturn delta_ns >= sg_policy->freq_update_delay_ns;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ignore_dl_rate_limit",
          "args": [
            "sg_cpu"
          ],
          "line": 445
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_dl_rate_limit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "313-317",
          "snippet": "static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)\n{\n\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_dl)\n\t\tsg_cpu->sg_policy->limits_changed = true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)\n{\n\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_dl)\n\t\tsg_cpu->sg_policy->limits_changed = true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_iowait_boost",
          "args": [
            "sg_cpu",
            "time",
            "flags"
          ],
          "line": 442
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_iowait_boost",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "215-243",
          "snippet": "static void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       unsigned int flags)\n{\n\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sg_cpu->iowait_boost &&\n\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))\n\t\treturn;\n\n\t/* Boost only tasks waking up after IO */\n\tif (!set_iowait_boost)\n\t\treturn;\n\n\t/* Ensure boost doubles only one time at each request */\n\tif (sg_cpu->iowait_boost_pending)\n\t\treturn;\n\tsg_cpu->iowait_boost_pending = true;\n\n\t/* Double the boost at each request */\n\tif (sg_cpu->iowait_boost) {\n\t\tsg_cpu->iowait_boost =\n\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);\n\t\treturn;\n\t}\n\n\t/* First wakeup after IO: start with minimum boost */\n\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       unsigned int flags)\n{\n\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sg_cpu->iowait_boost &&\n\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))\n\t\treturn;\n\n\t/* Boost only tasks waking up after IO */\n\tif (!set_iowait_boost)\n\t\treturn;\n\n\t/* Ensure boost doubles only one time at each request */\n\tif (sg_cpu->iowait_boost_pending)\n\t\treturn;\n\tsg_cpu->iowait_boost_pending = true;\n\n\t/* Double the boost at each request */\n\tif (sg_cpu->iowait_boost) {\n\t\tsg_cpu->iowait_boost =\n\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);\n\t\treturn;\n\t}\n\n\t/* First wakeup after IO: start with minimum boost */\n\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&sg_policy->update_lock"
          ],
          "line": 440
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "hook",
            "structsugov_cpu",
            "update_util"
          ],
          "line": 436
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void\nsugov_update_shared(struct update_util_data *hook, u64 time, unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tunsigned int next_f;\n\n\traw_spin_lock(&sg_policy->update_lock);\n\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (sugov_should_update_freq(sg_policy, time)) {\n\t\tnext_f = sugov_next_freq_shared(sg_cpu, time);\n\n\t\tif (!sugov_update_next_freq(sg_policy, time, next_f))\n\t\t\tgoto unlock;\n\n\t\tif (sg_policy->policy->fast_switch_enabled)\n\t\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);\n\t\telse\n\t\t\tsugov_deferred_update(sg_policy);\n\t}\nunlock:\n\traw_spin_unlock(&sg_policy->update_lock);\n}"
  },
  {
    "function_name": "sugov_next_freq_shared",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "408-431",
    "snippet": "static unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned long util = 0, max = 1;\n\tunsigned int j;\n\n\tfor_each_cpu(j, policy->cpus) {\n\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);\n\t\tunsigned long j_util, j_max;\n\n\t\tsugov_get_util(j_sg_cpu);\n\t\tsugov_iowait_apply(j_sg_cpu, time);\n\t\tj_util = j_sg_cpu->util;\n\t\tj_max = j_sg_cpu->max;\n\n\t\tif (j_util * max > j_max * util) {\n\t\t\tutil = j_util;\n\t\t\tmax = j_max;\n\t\t}\n\t}\n\n\treturn get_next_freq(sg_policy, util, max);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "get_next_freq",
          "args": [
            "sg_policy",
            "util",
            "max"
          ],
          "line": 430
        },
        "resolved": true,
        "details": {
          "function_name": "get_next_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "147-162",
          "snippet": "static unsigned int get_next_freq(struct sugov_policy *sg_policy,\n\t\t\t\t  unsigned long util, unsigned long max)\n{\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned int freq = arch_scale_freq_invariant() ?\n\t\t\t\tpolicy->cpuinfo.max_freq : policy->cur;\n\n\tutil = map_util_perf(util);\n\tfreq = map_util_freq(util, freq, max);\n\n\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)\n\t\treturn sg_policy->next_freq;\n\n\tsg_policy->cached_raw_freq = freq;\n\treturn cpufreq_driver_resolve_freq(policy, freq);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic unsigned int get_next_freq(struct sugov_policy *sg_policy,\n\t\t\t\t  unsigned long util, unsigned long max)\n{\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned int freq = arch_scale_freq_invariant() ?\n\t\t\t\tpolicy->cpuinfo.max_freq : policy->cur;\n\n\tutil = map_util_perf(util);\n\tfreq = map_util_freq(util, freq, max);\n\n\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)\n\t\treturn sg_policy->next_freq;\n\n\tsg_policy->cached_raw_freq = freq;\n\treturn cpufreq_driver_resolve_freq(policy, freq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_iowait_apply",
          "args": [
            "j_sg_cpu",
            "time"
          ],
          "line": 420
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_iowait_apply",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "262-294",
          "snippet": "static void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tunsigned long boost;\n\n\t/* No boost currently required */\n\tif (!sg_cpu->iowait_boost)\n\t\treturn;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sugov_iowait_reset(sg_cpu, time, false))\n\t\treturn;\n\n\tif (!sg_cpu->iowait_boost_pending) {\n\t\t/*\n\t\t * No boost pending; reduce the boost value.\n\t\t */\n\t\tsg_cpu->iowait_boost >>= 1;\n\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {\n\t\t\tsg_cpu->iowait_boost = 0;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tsg_cpu->iowait_boost_pending = false;\n\n\t/*\n\t * sg_cpu->util is already in capacity scale; convert iowait_boost\n\t * into the same scale so we can compare.\n\t */\n\tboost = (sg_cpu->iowait_boost * sg_cpu->max) >> SCHED_CAPACITY_SHIFT;\n\tif (sg_cpu->util < boost)\n\t\tsg_cpu->util = boost;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tunsigned long boost;\n\n\t/* No boost currently required */\n\tif (!sg_cpu->iowait_boost)\n\t\treturn;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sugov_iowait_reset(sg_cpu, time, false))\n\t\treturn;\n\n\tif (!sg_cpu->iowait_boost_pending) {\n\t\t/*\n\t\t * No boost pending; reduce the boost value.\n\t\t */\n\t\tsg_cpu->iowait_boost >>= 1;\n\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {\n\t\t\tsg_cpu->iowait_boost = 0;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tsg_cpu->iowait_boost_pending = false;\n\n\t/*\n\t * sg_cpu->util is already in capacity scale; convert iowait_boost\n\t * into the same scale so we can compare.\n\t */\n\tboost = (sg_cpu->iowait_boost * sg_cpu->max) >> SCHED_CAPACITY_SHIFT;\n\tif (sg_cpu->util < boost)\n\t\tsg_cpu->util = boost;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_get_util",
          "args": [
            "j_sg_cpu"
          ],
          "line": 419
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_get_util",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "164-173",
          "snippet": "static void sugov_get_util(struct sugov_cpu *sg_cpu)\n{\n\tstruct rq *rq = cpu_rq(sg_cpu->cpu);\n\tunsigned long max = arch_scale_cpu_capacity(sg_cpu->cpu);\n\n\tsg_cpu->max = max;\n\tsg_cpu->bw_dl = cpu_bw_dl(rq);\n\tsg_cpu->util = effective_cpu_util(sg_cpu->cpu, cpu_util_cfs(sg_cpu->cpu), max,\n\t\t\t\t\t  FREQUENCY_UTIL, NULL);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_get_util(struct sugov_cpu *sg_cpu)\n{\n\tstruct rq *rq = cpu_rq(sg_cpu->cpu);\n\tunsigned long max = arch_scale_cpu_capacity(sg_cpu->cpu);\n\n\tsg_cpu->max = max;\n\tsg_cpu->bw_dl = cpu_bw_dl(rq);\n\tsg_cpu->util = effective_cpu_util(sg_cpu->cpu, cpu_util_cfs(sg_cpu->cpu), max,\n\t\t\t\t\t  FREQUENCY_UTIL, NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "sugov_cpu",
            "j"
          ],
          "line": 416
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_set_per_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "588-603",
          "snippet": "void kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "j",
            "policy->cpus"
          ],
          "line": 415
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic unsigned int sugov_next_freq_shared(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned long util = 0, max = 1;\n\tunsigned int j;\n\n\tfor_each_cpu(j, policy->cpus) {\n\t\tstruct sugov_cpu *j_sg_cpu = &per_cpu(sugov_cpu, j);\n\t\tunsigned long j_util, j_max;\n\n\t\tsugov_get_util(j_sg_cpu);\n\t\tsugov_iowait_apply(j_sg_cpu, time);\n\t\tj_util = j_sg_cpu->util;\n\t\tj_max = j_sg_cpu->max;\n\n\t\tif (j_util * max > j_max * util) {\n\t\t\tutil = j_util;\n\t\t\tmax = j_max;\n\t\t}\n\t}\n\n\treturn get_next_freq(sg_policy, util, max);\n}"
  },
  {
    "function_name": "sugov_update_single_perf",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "376-406",
    "snippet": "static void sugov_update_single_perf(struct update_util_data *hook, u64 time,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tunsigned long prev_util = sg_cpu->util;\n\n\t/*\n\t * Fall back to the \"frequency\" path if frequency invariance is not\n\t * supported, because the direct mapping between the utilization and\n\t * the performance levels depends on the frequency invariance.\n\t */\n\tif (!arch_scale_freq_invariant()) {\n\t\tsugov_update_single_freq(hook, time, flags);\n\t\treturn;\n\t}\n\n\tif (!sugov_update_single_common(sg_cpu, time, flags))\n\t\treturn;\n\n\t/*\n\t * Do not reduce the target performance level if the CPU has not been\n\t * idle recently, as the reduction is likely to be premature then.\n\t */\n\tif (sugov_cpu_is_busy(sg_cpu) && sg_cpu->util < prev_util)\n\t\tsg_cpu->util = prev_util;\n\n\tcpufreq_driver_adjust_perf(sg_cpu->cpu, map_util_perf(sg_cpu->bw_dl),\n\t\t\t\t   map_util_perf(sg_cpu->util), sg_cpu->max);\n\n\tsg_cpu->sg_policy->last_freq_update_time = time;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpufreq_driver_adjust_perf",
          "args": [
            "sg_cpu->cpu",
            "map_util_perf(sg_cpu->bw_dl)",
            "map_util_perf(sg_cpu->util)",
            "sg_cpu->max"
          ],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_util_perf",
          "args": [
            "sg_cpu->util"
          ],
          "line": 403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_util_perf",
          "args": [
            "sg_cpu->bw_dl"
          ],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_cpu_is_busy",
          "args": [
            "sg_cpu"
          ],
          "line": 399
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_cpu_is_busy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "306-306",
          "snippet": "static inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }"
        }
      },
      {
        "call_info": {
          "callee": "sugov_update_single_common",
          "args": [
            "sg_cpu",
            "time",
            "flags"
          ],
          "line": 392
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_update_single_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "319-334",
          "snippet": "static inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,\n\t\t\t\t\t      u64 time, unsigned int flags)\n{\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))\n\t\treturn false;\n\n\tsugov_get_util(sg_cpu);\n\tsugov_iowait_apply(sg_cpu, time);\n\n\treturn true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,\n\t\t\t\t\t      u64 time, unsigned int flags)\n{\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))\n\t\treturn false;\n\n\tsugov_get_util(sg_cpu);\n\tsugov_iowait_apply(sg_cpu, time);\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_update_single_freq",
          "args": [
            "hook",
            "time",
            "flags"
          ],
          "line": 388
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_update_single_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "336-374",
          "snippet": "static void sugov_update_single_freq(struct update_util_data *hook, u64 time,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tunsigned int cached_freq = sg_policy->cached_raw_freq;\n\tunsigned int next_f;\n\n\tif (!sugov_update_single_common(sg_cpu, time, flags))\n\t\treturn;\n\n\tnext_f = get_next_freq(sg_policy, sg_cpu->util, sg_cpu->max);\n\t/*\n\t * Do not reduce the frequency if the CPU has not been idle\n\t * recently, as the reduction is likely to be premature then.\n\t */\n\tif (sugov_cpu_is_busy(sg_cpu) && next_f < sg_policy->next_freq) {\n\t\tnext_f = sg_policy->next_freq;\n\n\t\t/* Restore cached freq as next_freq has changed */\n\t\tsg_policy->cached_raw_freq = cached_freq;\n\t}\n\n\tif (!sugov_update_next_freq(sg_policy, time, next_f))\n\t\treturn;\n\n\t/*\n\t * This code runs under rq->lock for the target CPU, so it won't run\n\t * concurrently on two different CPUs for the same target and it is not\n\t * necessary to acquire the lock in the fast switch case.\n\t */\n\tif (sg_policy->policy->fast_switch_enabled) {\n\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);\n\t} else {\n\t\traw_spin_lock(&sg_policy->update_lock);\n\t\tsugov_deferred_update(sg_policy);\n\t\traw_spin_unlock(&sg_policy->update_lock);\n\t}\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_update_single_freq(struct update_util_data *hook, u64 time,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tunsigned int cached_freq = sg_policy->cached_raw_freq;\n\tunsigned int next_f;\n\n\tif (!sugov_update_single_common(sg_cpu, time, flags))\n\t\treturn;\n\n\tnext_f = get_next_freq(sg_policy, sg_cpu->util, sg_cpu->max);\n\t/*\n\t * Do not reduce the frequency if the CPU has not been idle\n\t * recently, as the reduction is likely to be premature then.\n\t */\n\tif (sugov_cpu_is_busy(sg_cpu) && next_f < sg_policy->next_freq) {\n\t\tnext_f = sg_policy->next_freq;\n\n\t\t/* Restore cached freq as next_freq has changed */\n\t\tsg_policy->cached_raw_freq = cached_freq;\n\t}\n\n\tif (!sugov_update_next_freq(sg_policy, time, next_f))\n\t\treturn;\n\n\t/*\n\t * This code runs under rq->lock for the target CPU, so it won't run\n\t * concurrently on two different CPUs for the same target and it is not\n\t * necessary to acquire the lock in the fast switch case.\n\t */\n\tif (sg_policy->policy->fast_switch_enabled) {\n\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);\n\t} else {\n\t\traw_spin_lock(&sg_policy->update_lock);\n\t\tsugov_deferred_update(sg_policy);\n\t\traw_spin_unlock(&sg_policy->update_lock);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_scale_freq_invariant",
          "args": [],
          "line": 387
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "hook",
            "structsugov_cpu",
            "update_util"
          ],
          "line": 379
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_update_single_perf(struct update_util_data *hook, u64 time,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tunsigned long prev_util = sg_cpu->util;\n\n\t/*\n\t * Fall back to the \"frequency\" path if frequency invariance is not\n\t * supported, because the direct mapping between the utilization and\n\t * the performance levels depends on the frequency invariance.\n\t */\n\tif (!arch_scale_freq_invariant()) {\n\t\tsugov_update_single_freq(hook, time, flags);\n\t\treturn;\n\t}\n\n\tif (!sugov_update_single_common(sg_cpu, time, flags))\n\t\treturn;\n\n\t/*\n\t * Do not reduce the target performance level if the CPU has not been\n\t * idle recently, as the reduction is likely to be premature then.\n\t */\n\tif (sugov_cpu_is_busy(sg_cpu) && sg_cpu->util < prev_util)\n\t\tsg_cpu->util = prev_util;\n\n\tcpufreq_driver_adjust_perf(sg_cpu->cpu, map_util_perf(sg_cpu->bw_dl),\n\t\t\t\t   map_util_perf(sg_cpu->util), sg_cpu->max);\n\n\tsg_cpu->sg_policy->last_freq_update_time = time;\n}"
  },
  {
    "function_name": "sugov_update_single_freq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "336-374",
    "snippet": "static void sugov_update_single_freq(struct update_util_data *hook, u64 time,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tunsigned int cached_freq = sg_policy->cached_raw_freq;\n\tunsigned int next_f;\n\n\tif (!sugov_update_single_common(sg_cpu, time, flags))\n\t\treturn;\n\n\tnext_f = get_next_freq(sg_policy, sg_cpu->util, sg_cpu->max);\n\t/*\n\t * Do not reduce the frequency if the CPU has not been idle\n\t * recently, as the reduction is likely to be premature then.\n\t */\n\tif (sugov_cpu_is_busy(sg_cpu) && next_f < sg_policy->next_freq) {\n\t\tnext_f = sg_policy->next_freq;\n\n\t\t/* Restore cached freq as next_freq has changed */\n\t\tsg_policy->cached_raw_freq = cached_freq;\n\t}\n\n\tif (!sugov_update_next_freq(sg_policy, time, next_f))\n\t\treturn;\n\n\t/*\n\t * This code runs under rq->lock for the target CPU, so it won't run\n\t * concurrently on two different CPUs for the same target and it is not\n\t * necessary to acquire the lock in the fast switch case.\n\t */\n\tif (sg_policy->policy->fast_switch_enabled) {\n\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);\n\t} else {\n\t\traw_spin_lock(&sg_policy->update_lock);\n\t\tsugov_deferred_update(sg_policy);\n\t\traw_spin_unlock(&sg_policy->update_lock);\n\t}\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&sg_policy->update_lock"
          ],
          "line": 372
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_deferred_update",
          "args": [
            "sg_policy"
          ],
          "line": 371
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_deferred_update",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "117-123",
          "snippet": "static void sugov_deferred_update(struct sugov_policy *sg_policy)\n{\n\tif (!sg_policy->work_in_progress) {\n\t\tsg_policy->work_in_progress = true;\n\t\tirq_work_queue(&sg_policy->irq_work);\n\t}\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_deferred_update(struct sugov_policy *sg_policy)\n{\n\tif (!sg_policy->work_in_progress) {\n\t\tsg_policy->work_in_progress = true;\n\t\tirq_work_queue(&sg_policy->irq_work);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&sg_policy->update_lock"
          ],
          "line": 370
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpufreq_driver_fast_switch",
          "args": [
            "sg_policy->policy",
            "next_f"
          ],
          "line": 368
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_update_next_freq",
          "args": [
            "sg_policy",
            "time",
            "next_f"
          ],
          "line": 359
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_update_next_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "103-115",
          "snippet": "static bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,\n\t\t\t\t   unsigned int next_freq)\n{\n\tif (sg_policy->need_freq_update)\n\t\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\telse if (sg_policy->next_freq == next_freq)\n\t\treturn false;\n\n\tsg_policy->next_freq = next_freq;\n\tsg_policy->last_freq_update_time = time;\n\n\treturn true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,\n\t\t\t\t   unsigned int next_freq)\n{\n\tif (sg_policy->need_freq_update)\n\t\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\telse if (sg_policy->next_freq == next_freq)\n\t\treturn false;\n\n\tsg_policy->next_freq = next_freq;\n\tsg_policy->last_freq_update_time = time;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_cpu_is_busy",
          "args": [
            "sg_cpu"
          ],
          "line": 352
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_cpu_is_busy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "306-306",
          "snippet": "static inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }"
        }
      },
      {
        "call_info": {
          "callee": "get_next_freq",
          "args": [
            "sg_policy",
            "sg_cpu->util",
            "sg_cpu->max"
          ],
          "line": 347
        },
        "resolved": true,
        "details": {
          "function_name": "get_next_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "147-162",
          "snippet": "static unsigned int get_next_freq(struct sugov_policy *sg_policy,\n\t\t\t\t  unsigned long util, unsigned long max)\n{\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned int freq = arch_scale_freq_invariant() ?\n\t\t\t\tpolicy->cpuinfo.max_freq : policy->cur;\n\n\tutil = map_util_perf(util);\n\tfreq = map_util_freq(util, freq, max);\n\n\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)\n\t\treturn sg_policy->next_freq;\n\n\tsg_policy->cached_raw_freq = freq;\n\treturn cpufreq_driver_resolve_freq(policy, freq);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic unsigned int get_next_freq(struct sugov_policy *sg_policy,\n\t\t\t\t  unsigned long util, unsigned long max)\n{\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned int freq = arch_scale_freq_invariant() ?\n\t\t\t\tpolicy->cpuinfo.max_freq : policy->cur;\n\n\tutil = map_util_perf(util);\n\tfreq = map_util_freq(util, freq, max);\n\n\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)\n\t\treturn sg_policy->next_freq;\n\n\tsg_policy->cached_raw_freq = freq;\n\treturn cpufreq_driver_resolve_freq(policy, freq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_update_single_common",
          "args": [
            "sg_cpu",
            "time",
            "flags"
          ],
          "line": 344
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_update_single_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "319-334",
          "snippet": "static inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,\n\t\t\t\t\t      u64 time, unsigned int flags)\n{\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))\n\t\treturn false;\n\n\tsugov_get_util(sg_cpu);\n\tsugov_iowait_apply(sg_cpu, time);\n\n\treturn true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,\n\t\t\t\t\t      u64 time, unsigned int flags)\n{\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))\n\t\treturn false;\n\n\tsugov_get_util(sg_cpu);\n\tsugov_iowait_apply(sg_cpu, time);\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "hook",
            "structsugov_cpu",
            "update_util"
          ],
          "line": 339
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_update_single_freq(struct update_util_data *hook, u64 time,\n\t\t\t\t     unsigned int flags)\n{\n\tstruct sugov_cpu *sg_cpu = container_of(hook, struct sugov_cpu, update_util);\n\tstruct sugov_policy *sg_policy = sg_cpu->sg_policy;\n\tunsigned int cached_freq = sg_policy->cached_raw_freq;\n\tunsigned int next_f;\n\n\tif (!sugov_update_single_common(sg_cpu, time, flags))\n\t\treturn;\n\n\tnext_f = get_next_freq(sg_policy, sg_cpu->util, sg_cpu->max);\n\t/*\n\t * Do not reduce the frequency if the CPU has not been idle\n\t * recently, as the reduction is likely to be premature then.\n\t */\n\tif (sugov_cpu_is_busy(sg_cpu) && next_f < sg_policy->next_freq) {\n\t\tnext_f = sg_policy->next_freq;\n\n\t\t/* Restore cached freq as next_freq has changed */\n\t\tsg_policy->cached_raw_freq = cached_freq;\n\t}\n\n\tif (!sugov_update_next_freq(sg_policy, time, next_f))\n\t\treturn;\n\n\t/*\n\t * This code runs under rq->lock for the target CPU, so it won't run\n\t * concurrently on two different CPUs for the same target and it is not\n\t * necessary to acquire the lock in the fast switch case.\n\t */\n\tif (sg_policy->policy->fast_switch_enabled) {\n\t\tcpufreq_driver_fast_switch(sg_policy->policy, next_f);\n\t} else {\n\t\traw_spin_lock(&sg_policy->update_lock);\n\t\tsugov_deferred_update(sg_policy);\n\t\traw_spin_unlock(&sg_policy->update_lock);\n\t}\n}"
  },
  {
    "function_name": "sugov_update_single_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "319-334",
    "snippet": "static inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,\n\t\t\t\t\t      u64 time, unsigned int flags)\n{\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))\n\t\treturn false;\n\n\tsugov_get_util(sg_cpu);\n\tsugov_iowait_apply(sg_cpu, time);\n\n\treturn true;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sugov_iowait_apply",
          "args": [
            "sg_cpu",
            "time"
          ],
          "line": 331
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_iowait_apply",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "262-294",
          "snippet": "static void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tunsigned long boost;\n\n\t/* No boost currently required */\n\tif (!sg_cpu->iowait_boost)\n\t\treturn;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sugov_iowait_reset(sg_cpu, time, false))\n\t\treturn;\n\n\tif (!sg_cpu->iowait_boost_pending) {\n\t\t/*\n\t\t * No boost pending; reduce the boost value.\n\t\t */\n\t\tsg_cpu->iowait_boost >>= 1;\n\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {\n\t\t\tsg_cpu->iowait_boost = 0;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tsg_cpu->iowait_boost_pending = false;\n\n\t/*\n\t * sg_cpu->util is already in capacity scale; convert iowait_boost\n\t * into the same scale so we can compare.\n\t */\n\tboost = (sg_cpu->iowait_boost * sg_cpu->max) >> SCHED_CAPACITY_SHIFT;\n\tif (sg_cpu->util < boost)\n\t\tsg_cpu->util = boost;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tunsigned long boost;\n\n\t/* No boost currently required */\n\tif (!sg_cpu->iowait_boost)\n\t\treturn;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sugov_iowait_reset(sg_cpu, time, false))\n\t\treturn;\n\n\tif (!sg_cpu->iowait_boost_pending) {\n\t\t/*\n\t\t * No boost pending; reduce the boost value.\n\t\t */\n\t\tsg_cpu->iowait_boost >>= 1;\n\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {\n\t\t\tsg_cpu->iowait_boost = 0;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tsg_cpu->iowait_boost_pending = false;\n\n\t/*\n\t * sg_cpu->util is already in capacity scale; convert iowait_boost\n\t * into the same scale so we can compare.\n\t */\n\tboost = (sg_cpu->iowait_boost * sg_cpu->max) >> SCHED_CAPACITY_SHIFT;\n\tif (sg_cpu->util < boost)\n\t\tsg_cpu->util = boost;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_get_util",
          "args": [
            "sg_cpu"
          ],
          "line": 330
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_get_util",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "164-173",
          "snippet": "static void sugov_get_util(struct sugov_cpu *sg_cpu)\n{\n\tstruct rq *rq = cpu_rq(sg_cpu->cpu);\n\tunsigned long max = arch_scale_cpu_capacity(sg_cpu->cpu);\n\n\tsg_cpu->max = max;\n\tsg_cpu->bw_dl = cpu_bw_dl(rq);\n\tsg_cpu->util = effective_cpu_util(sg_cpu->cpu, cpu_util_cfs(sg_cpu->cpu), max,\n\t\t\t\t\t  FREQUENCY_UTIL, NULL);\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_get_util(struct sugov_cpu *sg_cpu)\n{\n\tstruct rq *rq = cpu_rq(sg_cpu->cpu);\n\tunsigned long max = arch_scale_cpu_capacity(sg_cpu->cpu);\n\n\tsg_cpu->max = max;\n\tsg_cpu->bw_dl = cpu_bw_dl(rq);\n\tsg_cpu->util = effective_cpu_util(sg_cpu->cpu, cpu_util_cfs(sg_cpu->cpu), max,\n\t\t\t\t\t  FREQUENCY_UTIL, NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_should_update_freq",
          "args": [
            "sg_cpu->sg_policy",
            "time"
          ],
          "line": 327
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_should_update_freq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "70-101",
          "snippet": "static bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)\n{\n\ts64 delta_ns;\n\n\t/*\n\t * Since cpufreq_update_util() is called with rq->lock held for\n\t * the @target_cpu, our per-CPU data is fully serialized.\n\t *\n\t * However, drivers cannot in general deal with cross-CPU\n\t * requests, so while get_next_freq() will work, our\n\t * sugov_update_commit() call may not for the fast switching platforms.\n\t *\n\t * Hence stop here for remote requests if they aren't supported\n\t * by the hardware, as calculating the frequency is pointless if\n\t * we cannot in fact act on it.\n\t *\n\t * This is needed on the slow switching platforms too to prevent CPUs\n\t * going offline from leaving stale IRQ work items behind.\n\t */\n\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))\n\t\treturn false;\n\n\tif (unlikely(sg_policy->limits_changed)) {\n\t\tsg_policy->limits_changed = false;\n\t\tsg_policy->need_freq_update = true;\n\t\treturn true;\n\t}\n\n\tdelta_ns = time - sg_policy->last_freq_update_time;\n\n\treturn delta_ns >= sg_policy->freq_update_delay_ns;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)\n{\n\ts64 delta_ns;\n\n\t/*\n\t * Since cpufreq_update_util() is called with rq->lock held for\n\t * the @target_cpu, our per-CPU data is fully serialized.\n\t *\n\t * However, drivers cannot in general deal with cross-CPU\n\t * requests, so while get_next_freq() will work, our\n\t * sugov_update_commit() call may not for the fast switching platforms.\n\t *\n\t * Hence stop here for remote requests if they aren't supported\n\t * by the hardware, as calculating the frequency is pointless if\n\t * we cannot in fact act on it.\n\t *\n\t * This is needed on the slow switching platforms too to prevent CPUs\n\t * going offline from leaving stale IRQ work items behind.\n\t */\n\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))\n\t\treturn false;\n\n\tif (unlikely(sg_policy->limits_changed)) {\n\t\tsg_policy->limits_changed = false;\n\t\tsg_policy->need_freq_update = true;\n\t\treturn true;\n\t}\n\n\tdelta_ns = time - sg_policy->last_freq_update_time;\n\n\treturn delta_ns >= sg_policy->freq_update_delay_ns;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ignore_dl_rate_limit",
          "args": [
            "sg_cpu"
          ],
          "line": 325
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_dl_rate_limit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "313-317",
          "snippet": "static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)\n{\n\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_dl)\n\t\tsg_cpu->sg_policy->limits_changed = true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)\n{\n\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_dl)\n\t\tsg_cpu->sg_policy->limits_changed = true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sugov_iowait_boost",
          "args": [
            "sg_cpu",
            "time",
            "flags"
          ],
          "line": 322
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_iowait_boost",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "215-243",
          "snippet": "static void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       unsigned int flags)\n{\n\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sg_cpu->iowait_boost &&\n\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))\n\t\treturn;\n\n\t/* Boost only tasks waking up after IO */\n\tif (!set_iowait_boost)\n\t\treturn;\n\n\t/* Ensure boost doubles only one time at each request */\n\tif (sg_cpu->iowait_boost_pending)\n\t\treturn;\n\tsg_cpu->iowait_boost_pending = true;\n\n\t/* Double the boost at each request */\n\tif (sg_cpu->iowait_boost) {\n\t\tsg_cpu->iowait_boost =\n\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);\n\t\treturn;\n\t}\n\n\t/* First wakeup after IO: start with minimum boost */\n\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       unsigned int flags)\n{\n\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sg_cpu->iowait_boost &&\n\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))\n\t\treturn;\n\n\t/* Boost only tasks waking up after IO */\n\tif (!set_iowait_boost)\n\t\treturn;\n\n\t/* Ensure boost doubles only one time at each request */\n\tif (sg_cpu->iowait_boost_pending)\n\t\treturn;\n\tsg_cpu->iowait_boost_pending = true;\n\n\t/* Double the boost at each request */\n\tif (sg_cpu->iowait_boost) {\n\t\tsg_cpu->iowait_boost =\n\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);\n\t\treturn;\n\t}\n\n\t/* First wakeup after IO: start with minimum boost */\n\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline bool sugov_update_single_common(struct sugov_cpu *sg_cpu,\n\t\t\t\t\t      u64 time, unsigned int flags)\n{\n\tsugov_iowait_boost(sg_cpu, time, flags);\n\tsg_cpu->last_update = time;\n\n\tignore_dl_rate_limit(sg_cpu);\n\n\tif (!sugov_should_update_freq(sg_cpu->sg_policy, time))\n\t\treturn false;\n\n\tsugov_get_util(sg_cpu);\n\tsugov_iowait_apply(sg_cpu, time);\n\n\treturn true;\n}"
  },
  {
    "function_name": "ignore_dl_rate_limit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "313-317",
    "snippet": "static inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)\n{\n\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_dl)\n\t\tsg_cpu->sg_policy->limits_changed = true;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_bw_dl",
          "args": [
            "cpu_rq(sg_cpu->cpu)"
          ],
          "line": 315
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_bw_dl",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2959-2962",
          "snippet": "static inline unsigned long cpu_bw_dl(struct rq *rq)\n{\n\treturn (rq->dl.running_bw * SCHED_CAPACITY_SCALE) >> BW_SHIFT;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define BW_SHIFT\t\t20"
          ],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define BW_SHIFT\t\t20\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline unsigned long cpu_bw_dl(struct rq *rq)\n{\n\treturn (rq->dl.running_bw * SCHED_CAPACITY_SCALE) >> BW_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "sg_cpu->cpu"
          ],
          "line": 315
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline void ignore_dl_rate_limit(struct sugov_cpu *sg_cpu)\n{\n\tif (cpu_bw_dl(cpu_rq(sg_cpu->cpu)) > sg_cpu->bw_dl)\n\t\tsg_cpu->sg_policy->limits_changed = true;\n}"
  },
  {
    "function_name": "sugov_cpu_is_busy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "306-306",
    "snippet": "static inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic inline bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu) { return false; }"
  },
  {
    "function_name": "sugov_cpu_is_busy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "297-304",
    "snippet": "static bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu)\n{\n\tunsigned long idle_calls = tick_nohz_get_idle_calls_cpu(sg_cpu->cpu);\n\tbool ret = idle_calls == sg_cpu->saved_idle_calls;\n\n\tsg_cpu->saved_idle_calls = idle_calls;\n\treturn ret;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "tick_nohz_get_idle_calls_cpu",
          "args": [
            "sg_cpu->cpu"
          ],
          "line": 299
        },
        "resolved": true,
        "details": {
          "function_name": "tick_nohz_get_idle_calls_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/tick-sched.c",
          "lines": "1212-1217",
          "snippet": "unsigned long tick_nohz_get_idle_calls_cpu(int cpu)\n{\n\tstruct tick_sched *ts = tick_get_tick_sched(cpu);\n\n\treturn ts->idle_calls;\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/irq_regs.h>",
            "#include <linux/mm.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/module.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/profile.h>",
            "#include <linux/nmi.h>",
            "#include <linux/percpu.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/err.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/irq_regs.h>\n#include <linux/mm.h>\n#include <linux/context_tracking.h>\n#include <linux/posix-timers.h>\n#include <linux/irq_work.h>\n#include <linux/module.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/profile.h>\n#include <linux/nmi.h>\n#include <linux/percpu.h>\n#include <linux/kernel_stat.h>\n#include <linux/interrupt.h>\n#include <linux/hrtimer.h>\n#include <linux/err.h>\n#include <linux/cpu.h>\n\nunsigned long tick_nohz_get_idle_calls_cpu(int cpu)\n{\n\tstruct tick_sched *ts = tick_get_tick_sched(cpu);\n\n\treturn ts->idle_calls;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic bool sugov_cpu_is_busy(struct sugov_cpu *sg_cpu)\n{\n\tunsigned long idle_calls = tick_nohz_get_idle_calls_cpu(sg_cpu->cpu);\n\tbool ret = idle_calls == sg_cpu->saved_idle_calls;\n\n\tsg_cpu->saved_idle_calls = idle_calls;\n\treturn ret;\n}"
  },
  {
    "function_name": "sugov_iowait_apply",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "262-294",
    "snippet": "static void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tunsigned long boost;\n\n\t/* No boost currently required */\n\tif (!sg_cpu->iowait_boost)\n\t\treturn;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sugov_iowait_reset(sg_cpu, time, false))\n\t\treturn;\n\n\tif (!sg_cpu->iowait_boost_pending) {\n\t\t/*\n\t\t * No boost pending; reduce the boost value.\n\t\t */\n\t\tsg_cpu->iowait_boost >>= 1;\n\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {\n\t\t\tsg_cpu->iowait_boost = 0;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tsg_cpu->iowait_boost_pending = false;\n\n\t/*\n\t * sg_cpu->util is already in capacity scale; convert iowait_boost\n\t * into the same scale so we can compare.\n\t */\n\tboost = (sg_cpu->iowait_boost * sg_cpu->max) >> SCHED_CAPACITY_SHIFT;\n\tif (sg_cpu->util < boost)\n\t\tsg_cpu->util = boost;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [
      "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
    ],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sugov_iowait_reset",
          "args": [
            "sg_cpu",
            "time",
            "false"
          ],
          "line": 271
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_iowait_reset",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "186-199",
          "snippet": "static bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       bool set_iowait_boost)\n{\n\ts64 delta_ns = time - sg_cpu->last_update;\n\n\t/* Reset boost only if a tick has elapsed since last request */\n\tif (delta_ns <= TICK_NSEC)\n\t\treturn false;\n\n\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;\n\tsg_cpu->iowait_boost_pending = set_iowait_boost;\n\n\treturn true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       bool set_iowait_boost)\n{\n\ts64 delta_ns = time - sg_cpu->last_update;\n\n\t/* Reset boost only if a tick has elapsed since last request */\n\tif (delta_ns <= TICK_NSEC)\n\t\treturn false;\n\n\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;\n\tsg_cpu->iowait_boost_pending = set_iowait_boost;\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_iowait_apply(struct sugov_cpu *sg_cpu, u64 time)\n{\n\tunsigned long boost;\n\n\t/* No boost currently required */\n\tif (!sg_cpu->iowait_boost)\n\t\treturn;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sugov_iowait_reset(sg_cpu, time, false))\n\t\treturn;\n\n\tif (!sg_cpu->iowait_boost_pending) {\n\t\t/*\n\t\t * No boost pending; reduce the boost value.\n\t\t */\n\t\tsg_cpu->iowait_boost >>= 1;\n\t\tif (sg_cpu->iowait_boost < IOWAIT_BOOST_MIN) {\n\t\t\tsg_cpu->iowait_boost = 0;\n\t\t\treturn;\n\t\t}\n\t}\n\n\tsg_cpu->iowait_boost_pending = false;\n\n\t/*\n\t * sg_cpu->util is already in capacity scale; convert iowait_boost\n\t * into the same scale so we can compare.\n\t */\n\tboost = (sg_cpu->iowait_boost * sg_cpu->max) >> SCHED_CAPACITY_SHIFT;\n\tif (sg_cpu->util < boost)\n\t\tsg_cpu->util = boost;\n}"
  },
  {
    "function_name": "sugov_iowait_boost",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "215-243",
    "snippet": "static void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       unsigned int flags)\n{\n\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sg_cpu->iowait_boost &&\n\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))\n\t\treturn;\n\n\t/* Boost only tasks waking up after IO */\n\tif (!set_iowait_boost)\n\t\treturn;\n\n\t/* Ensure boost doubles only one time at each request */\n\tif (sg_cpu->iowait_boost_pending)\n\t\treturn;\n\tsg_cpu->iowait_boost_pending = true;\n\n\t/* Double the boost at each request */\n\tif (sg_cpu->iowait_boost) {\n\t\tsg_cpu->iowait_boost =\n\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);\n\t\treturn;\n\t}\n\n\t/* First wakeup after IO: start with minimum boost */\n\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [
      "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
    ],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "min_t",
          "args": [
            "unsignedint",
            "sg_cpu->iowait_boost << 1",
            "SCHED_CAPACITY_SCALE"
          ],
          "line": 237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sugov_iowait_reset",
          "args": [
            "sg_cpu",
            "time",
            "set_iowait_boost"
          ],
          "line": 222
        },
        "resolved": true,
        "details": {
          "function_name": "sugov_iowait_reset",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
          "lines": "186-199",
          "snippet": "static bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       bool set_iowait_boost)\n{\n\ts64 delta_ns = time - sg_cpu->last_update;\n\n\t/* Reset boost only if a tick has elapsed since last request */\n\tif (delta_ns <= TICK_NSEC)\n\t\treturn false;\n\n\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;\n\tsg_cpu->iowait_boost_pending = set_iowait_boost;\n\n\treturn true;\n}",
          "includes": [
            "#include <trace/events/power.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       bool set_iowait_boost)\n{\n\ts64 delta_ns = time - sg_cpu->last_update;\n\n\t/* Reset boost only if a tick has elapsed since last request */\n\tif (delta_ns <= TICK_NSEC)\n\t\treturn false;\n\n\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;\n\tsg_cpu->iowait_boost_pending = set_iowait_boost;\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_iowait_boost(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       unsigned int flags)\n{\n\tbool set_iowait_boost = flags & SCHED_CPUFREQ_IOWAIT;\n\n\t/* Reset boost if the CPU appears to have been idle enough */\n\tif (sg_cpu->iowait_boost &&\n\t    sugov_iowait_reset(sg_cpu, time, set_iowait_boost))\n\t\treturn;\n\n\t/* Boost only tasks waking up after IO */\n\tif (!set_iowait_boost)\n\t\treturn;\n\n\t/* Ensure boost doubles only one time at each request */\n\tif (sg_cpu->iowait_boost_pending)\n\t\treturn;\n\tsg_cpu->iowait_boost_pending = true;\n\n\t/* Double the boost at each request */\n\tif (sg_cpu->iowait_boost) {\n\t\tsg_cpu->iowait_boost =\n\t\t\tmin_t(unsigned int, sg_cpu->iowait_boost << 1, SCHED_CAPACITY_SCALE);\n\t\treturn;\n\t}\n\n\t/* First wakeup after IO: start with minimum boost */\n\tsg_cpu->iowait_boost = IOWAIT_BOOST_MIN;\n}"
  },
  {
    "function_name": "sugov_iowait_reset",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "186-199",
    "snippet": "static bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       bool set_iowait_boost)\n{\n\ts64 delta_ns = time - sg_cpu->last_update;\n\n\t/* Reset boost only if a tick has elapsed since last request */\n\tif (delta_ns <= TICK_NSEC)\n\t\treturn false;\n\n\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;\n\tsg_cpu->iowait_boost_pending = set_iowait_boost;\n\n\treturn true;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [
      "#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)"
    ],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\n#define IOWAIT_BOOST_MIN\t(SCHED_CAPACITY_SCALE / 8)\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic bool sugov_iowait_reset(struct sugov_cpu *sg_cpu, u64 time,\n\t\t\t       bool set_iowait_boost)\n{\n\ts64 delta_ns = time - sg_cpu->last_update;\n\n\t/* Reset boost only if a tick has elapsed since last request */\n\tif (delta_ns <= TICK_NSEC)\n\t\treturn false;\n\n\tsg_cpu->iowait_boost = set_iowait_boost ? IOWAIT_BOOST_MIN : 0;\n\tsg_cpu->iowait_boost_pending = set_iowait_boost;\n\n\treturn true;\n}"
  },
  {
    "function_name": "sugov_get_util",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "164-173",
    "snippet": "static void sugov_get_util(struct sugov_cpu *sg_cpu)\n{\n\tstruct rq *rq = cpu_rq(sg_cpu->cpu);\n\tunsigned long max = arch_scale_cpu_capacity(sg_cpu->cpu);\n\n\tsg_cpu->max = max;\n\tsg_cpu->bw_dl = cpu_bw_dl(rq);\n\tsg_cpu->util = effective_cpu_util(sg_cpu->cpu, cpu_util_cfs(sg_cpu->cpu), max,\n\t\t\t\t\t  FREQUENCY_UTIL, NULL);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "effective_cpu_util",
          "args": [
            "sg_cpu->cpu",
            "cpu_util_cfs(sg_cpu->cpu)",
            "max",
            "FREQUENCY_UTIL",
            "NULL"
          ],
          "line": 171
        },
        "resolved": true,
        "details": {
          "function_name": "effective_cpu_util",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "7084-7168",
          "snippet": "unsigned long effective_cpu_util(int cpu, unsigned long util_cfs,\n\t\t\t\t unsigned long max, enum cpu_util_type type,\n\t\t\t\t struct task_struct *p)\n{\n\tunsigned long dl_util, util, irq;\n\tstruct rq *rq = cpu_rq(cpu);\n\n\tif (!uclamp_is_used() &&\n\t    type == FREQUENCY_UTIL && rt_rq_is_runnable(&rq->rt)) {\n\t\treturn max;\n\t}\n\n\t/*\n\t * Early check to see if IRQ/steal time saturates the CPU, can be\n\t * because of inaccuracies in how we track these -- see\n\t * update_irq_load_avg().\n\t */\n\tirq = cpu_util_irq(rq);\n\tif (unlikely(irq >= max))\n\t\treturn max;\n\n\t/*\n\t * Because the time spend on RT/DL tasks is visible as 'lost' time to\n\t * CFS tasks and we use the same metric to track the effective\n\t * utilization (PELT windows are synchronized) we can directly add them\n\t * to obtain the CPU's actual utilization.\n\t *\n\t * CFS and RT utilization can be boosted or capped, depending on\n\t * utilization clamp constraints requested by currently RUNNABLE\n\t * tasks.\n\t * When there are no CFS RUNNABLE tasks, clamps are released and\n\t * frequency will be gracefully reduced with the utilization decay.\n\t */\n\tutil = util_cfs + cpu_util_rt(rq);\n\tif (type == FREQUENCY_UTIL)\n\t\tutil = uclamp_rq_util_with(rq, util, p);\n\n\tdl_util = cpu_util_dl(rq);\n\n\t/*\n\t * For frequency selection we do not make cpu_util_dl() a permanent part\n\t * of this sum because we want to use cpu_bw_dl() later on, but we need\n\t * to check if the CFS+RT+DL sum is saturated (ie. no idle time) such\n\t * that we select f_max when there is no idle time.\n\t *\n\t * NOTE: numerical errors or stop class might cause us to not quite hit\n\t * saturation when we should -- something for later.\n\t */\n\tif (util + dl_util >= max)\n\t\treturn max;\n\n\t/*\n\t * OTOH, for energy computation we need the estimated running time, so\n\t * include util_dl and ignore dl_bw.\n\t */\n\tif (type == ENERGY_UTIL)\n\t\tutil += dl_util;\n\n\t/*\n\t * There is still idle time; further improve the number by using the\n\t * irq metric. Because IRQ/steal time is hidden from the task clock we\n\t * need to scale the task numbers:\n\t *\n\t *              max - irq\n\t *   U' = irq + --------- * U\n\t *                 max\n\t */\n\tutil = scale_irq_capacity(util, irq, max);\n\tutil += irq;\n\n\t/*\n\t * Bandwidth required by DEADLINE must always be granted while, for\n\t * FAIR and RT, we use blocked utilization of IDLE CPUs as a mechanism\n\t * to gracefully reduce the frequency when no tasks show up for longer\n\t * periods of time.\n\t *\n\t * Ideally we would like to set bw_dl as min/guaranteed freq and util +\n\t * bw_dl as requested freq. However, cpufreq is not yet ready for such\n\t * an interface. So, we only do the latter for now.\n\t */\n\tif (type == FREQUENCY_UTIL)\n\t\tutil += cpu_bw_dl(rq);\n\n\treturn min(max, util);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\nunsigned long long sum = 0;\n\nunsigned long effective_cpu_util(int cpu, unsigned long util_cfs,\n\t\t\t\t unsigned long max, enum cpu_util_type type,\n\t\t\t\t struct task_struct *p)\n{\n\tunsigned long dl_util, util, irq;\n\tstruct rq *rq = cpu_rq(cpu);\n\n\tif (!uclamp_is_used() &&\n\t    type == FREQUENCY_UTIL && rt_rq_is_runnable(&rq->rt)) {\n\t\treturn max;\n\t}\n\n\t/*\n\t * Early check to see if IRQ/steal time saturates the CPU, can be\n\t * because of inaccuracies in how we track these -- see\n\t * update_irq_load_avg().\n\t */\n\tirq = cpu_util_irq(rq);\n\tif (unlikely(irq >= max))\n\t\treturn max;\n\n\t/*\n\t * Because the time spend on RT/DL tasks is visible as 'lost' time to\n\t * CFS tasks and we use the same metric to track the effective\n\t * utilization (PELT windows are synchronized) we can directly add them\n\t * to obtain the CPU's actual utilization.\n\t *\n\t * CFS and RT utilization can be boosted or capped, depending on\n\t * utilization clamp constraints requested by currently RUNNABLE\n\t * tasks.\n\t * When there are no CFS RUNNABLE tasks, clamps are released and\n\t * frequency will be gracefully reduced with the utilization decay.\n\t */\n\tutil = util_cfs + cpu_util_rt(rq);\n\tif (type == FREQUENCY_UTIL)\n\t\tutil = uclamp_rq_util_with(rq, util, p);\n\n\tdl_util = cpu_util_dl(rq);\n\n\t/*\n\t * For frequency selection we do not make cpu_util_dl() a permanent part\n\t * of this sum because we want to use cpu_bw_dl() later on, but we need\n\t * to check if the CFS+RT+DL sum is saturated (ie. no idle time) such\n\t * that we select f_max when there is no idle time.\n\t *\n\t * NOTE: numerical errors or stop class might cause us to not quite hit\n\t * saturation when we should -- something for later.\n\t */\n\tif (util + dl_util >= max)\n\t\treturn max;\n\n\t/*\n\t * OTOH, for energy computation we need the estimated running time, so\n\t * include util_dl and ignore dl_bw.\n\t */\n\tif (type == ENERGY_UTIL)\n\t\tutil += dl_util;\n\n\t/*\n\t * There is still idle time; further improve the number by using the\n\t * irq metric. Because IRQ/steal time is hidden from the task clock we\n\t * need to scale the task numbers:\n\t *\n\t *              max - irq\n\t *   U' = irq + --------- * U\n\t *                 max\n\t */\n\tutil = scale_irq_capacity(util, irq, max);\n\tutil += irq;\n\n\t/*\n\t * Bandwidth required by DEADLINE must always be granted while, for\n\t * FAIR and RT, we use blocked utilization of IDLE CPUs as a mechanism\n\t * to gracefully reduce the frequency when no tasks show up for longer\n\t * periods of time.\n\t *\n\t * Ideally we would like to set bw_dl as min/guaranteed freq and util +\n\t * bw_dl as requested freq. However, cpufreq is not yet ready for such\n\t * an interface. So, we only do the latter for now.\n\t */\n\tif (type == FREQUENCY_UTIL)\n\t\tutil += cpu_bw_dl(rq);\n\n\treturn min(max, util);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_util_cfs",
          "args": [
            "sg_cpu->cpu"
          ],
          "line": 171
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_util_cfs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "3001-3015",
          "snippet": "static inline unsigned long cpu_util_cfs(int cpu)\n{\n\tstruct cfs_rq *cfs_rq;\n\tunsigned long util;\n\n\tcfs_rq = &cpu_rq(cpu)->cfs;\n\tutil = READ_ONCE(cfs_rq->avg.util_avg);\n\n\tif (sched_feat(UTIL_EST)) {\n\t\tutil = max_t(unsigned long, util,\n\t\t\t     READ_ONCE(cfs_rq->avg.util_est.enqueued));\n\t}\n\n\treturn min(util, capacity_orig_of(cpu));\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern void resched_cpu(int cpu);",
            "extern struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq);",
            "extern struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq);",
            "extern void init_cfs_rq(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern void resched_cpu(int cpu);\nextern struct sched_entity *__pick_first_entity(struct cfs_rq *cfs_rq);\nextern struct sched_entity *__pick_last_entity(struct cfs_rq *cfs_rq);\nextern void init_cfs_rq(struct cfs_rq *cfs_rq);\n\nstatic inline unsigned long cpu_util_cfs(int cpu)\n{\n\tstruct cfs_rq *cfs_rq;\n\tunsigned long util;\n\n\tcfs_rq = &cpu_rq(cpu)->cfs;\n\tutil = READ_ONCE(cfs_rq->avg.util_avg);\n\n\tif (sched_feat(UTIL_EST)) {\n\t\tutil = max_t(unsigned long, util,\n\t\t\t     READ_ONCE(cfs_rq->avg.util_est.enqueued));\n\t}\n\n\treturn min(util, capacity_orig_of(cpu));\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_bw_dl",
          "args": [
            "rq"
          ],
          "line": 170
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_bw_dl",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2959-2962",
          "snippet": "static inline unsigned long cpu_bw_dl(struct rq *rq)\n{\n\treturn (rq->dl.running_bw * SCHED_CAPACITY_SCALE) >> BW_SHIFT;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define BW_SHIFT\t\t20"
          ],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define BW_SHIFT\t\t20\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline unsigned long cpu_bw_dl(struct rq *rq)\n{\n\treturn (rq->dl.running_bw * SCHED_CAPACITY_SCALE) >> BW_SHIFT;\n}"
        }
      },
      {
        "call_info": {
          "callee": "arch_scale_cpu_capacity",
          "args": [
            "sg_cpu->cpu"
          ],
          "line": 167
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "sg_cpu->cpu"
          ],
          "line": 166
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic DEFINE_PER_CPU(struct sugov_cpu, sugov_cpu);\n\nstatic void sugov_get_util(struct sugov_cpu *sg_cpu)\n{\n\tstruct rq *rq = cpu_rq(sg_cpu->cpu);\n\tunsigned long max = arch_scale_cpu_capacity(sg_cpu->cpu);\n\n\tsg_cpu->max = max;\n\tsg_cpu->bw_dl = cpu_bw_dl(rq);\n\tsg_cpu->util = effective_cpu_util(sg_cpu->cpu, cpu_util_cfs(sg_cpu->cpu), max,\n\t\t\t\t\t  FREQUENCY_UTIL, NULL);\n}"
  },
  {
    "function_name": "get_next_freq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "147-162",
    "snippet": "static unsigned int get_next_freq(struct sugov_policy *sg_policy,\n\t\t\t\t  unsigned long util, unsigned long max)\n{\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned int freq = arch_scale_freq_invariant() ?\n\t\t\t\tpolicy->cpuinfo.max_freq : policy->cur;\n\n\tutil = map_util_perf(util);\n\tfreq = map_util_freq(util, freq, max);\n\n\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)\n\t\treturn sg_policy->next_freq;\n\n\tsg_policy->cached_raw_freq = freq;\n\treturn cpufreq_driver_resolve_freq(policy, freq);\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpufreq_driver_resolve_freq",
          "args": [
            "policy",
            "freq"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_util_freq",
          "args": [
            "util",
            "freq",
            "max"
          ],
          "line": 155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_util_perf",
          "args": [
            "util"
          ],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_scale_freq_invariant",
          "args": [],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic unsigned int get_next_freq(struct sugov_policy *sg_policy,\n\t\t\t\t  unsigned long util, unsigned long max)\n{\n\tstruct cpufreq_policy *policy = sg_policy->policy;\n\tunsigned int freq = arch_scale_freq_invariant() ?\n\t\t\t\tpolicy->cpuinfo.max_freq : policy->cur;\n\n\tutil = map_util_perf(util);\n\tfreq = map_util_freq(util, freq, max);\n\n\tif (freq == sg_policy->cached_raw_freq && !sg_policy->need_freq_update)\n\t\treturn sg_policy->next_freq;\n\n\tsg_policy->cached_raw_freq = freq;\n\treturn cpufreq_driver_resolve_freq(policy, freq);\n}"
  },
  {
    "function_name": "sugov_deferred_update",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "117-123",
    "snippet": "static void sugov_deferred_update(struct sugov_policy *sg_policy)\n{\n\tif (!sg_policy->work_in_progress) {\n\t\tsg_policy->work_in_progress = true;\n\t\tirq_work_queue(&sg_policy->irq_work);\n\t}\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue",
          "args": [
            "&sg_policy->irq_work"
          ],
          "line": 121
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "106-118",
          "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic void sugov_deferred_update(struct sugov_policy *sg_policy)\n{\n\tif (!sg_policy->work_in_progress) {\n\t\tsg_policy->work_in_progress = true;\n\t\tirq_work_queue(&sg_policy->irq_work);\n\t}\n}"
  },
  {
    "function_name": "sugov_update_next_freq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "103-115",
    "snippet": "static bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,\n\t\t\t\t   unsigned int next_freq)\n{\n\tif (sg_policy->need_freq_update)\n\t\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\telse if (sg_policy->next_freq == next_freq)\n\t\treturn false;\n\n\tsg_policy->next_freq = next_freq;\n\tsg_policy->last_freq_update_time = time;\n\n\treturn true;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpufreq_driver_test_flags",
          "args": [
            "CPUFREQ_NEED_UPDATE_LIMITS"
          ],
          "line": 107
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic bool sugov_update_next_freq(struct sugov_policy *sg_policy, u64 time,\n\t\t\t\t   unsigned int next_freq)\n{\n\tif (sg_policy->need_freq_update)\n\t\tsg_policy->need_freq_update = cpufreq_driver_test_flags(CPUFREQ_NEED_UPDATE_LIMITS);\n\telse if (sg_policy->next_freq == next_freq)\n\t\treturn false;\n\n\tsg_policy->next_freq = next_freq;\n\tsg_policy->last_freq_update_time = time;\n\n\treturn true;\n}"
  },
  {
    "function_name": "sugov_should_update_freq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq_schedutil.c",
    "lines": "70-101",
    "snippet": "static bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)\n{\n\ts64 delta_ns;\n\n\t/*\n\t * Since cpufreq_update_util() is called with rq->lock held for\n\t * the @target_cpu, our per-CPU data is fully serialized.\n\t *\n\t * However, drivers cannot in general deal with cross-CPU\n\t * requests, so while get_next_freq() will work, our\n\t * sugov_update_commit() call may not for the fast switching platforms.\n\t *\n\t * Hence stop here for remote requests if they aren't supported\n\t * by the hardware, as calculating the frequency is pointless if\n\t * we cannot in fact act on it.\n\t *\n\t * This is needed on the slow switching platforms too to prevent CPUs\n\t * going offline from leaving stale IRQ work items behind.\n\t */\n\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))\n\t\treturn false;\n\n\tif (unlikely(sg_policy->limits_changed)) {\n\t\tsg_policy->limits_changed = false;\n\t\tsg_policy->need_freq_update = true;\n\t\treturn true;\n\t}\n\n\tdelta_ns = time - sg_policy->last_freq_update_time;\n\n\treturn delta_ns >= sg_policy->freq_update_delay_ns;\n}",
    "includes": [
      "#include <trace/events/power.h>",
      "#include <linux/sched/cpufreq.h>",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "sg_policy->limits_changed"
          ],
          "line": 92
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpufreq_this_cpu_can_update",
          "args": [
            "sg_policy->policy"
          ],
          "line": 89
        },
        "resolved": true,
        "details": {
          "function_name": "cpufreq_this_cpu_can_update",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpufreq.c",
          "lines": "72-77",
          "snippet": "bool cpufreq_this_cpu_can_update(struct cpufreq_policy *policy)\n{\n\treturn cpumask_test_cpu(smp_processor_id(), policy->cpus) ||\n\t\t(policy->dvfs_possible_from_any_cpu &&\n\t\t rcu_dereference_sched(*this_cpu_ptr(&cpufreq_update_util_data)));\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/cpufreq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/cpufreq.h>\n\nbool cpufreq_this_cpu_can_update(struct cpufreq_policy *policy)\n{\n\treturn cpumask_test_cpu(smp_processor_id(), policy->cpus) ||\n\t\t(policy->dvfs_possible_from_any_cpu &&\n\t\t rcu_dereference_sched(*this_cpu_ptr(&cpufreq_update_util_data)));\n}"
        }
      }
    ],
    "contextual_snippet": "#include <trace/events/power.h>\n#include <linux/sched/cpufreq.h>\n#include \"sched.h\"\n\nstatic bool sugov_should_update_freq(struct sugov_policy *sg_policy, u64 time)\n{\n\ts64 delta_ns;\n\n\t/*\n\t * Since cpufreq_update_util() is called with rq->lock held for\n\t * the @target_cpu, our per-CPU data is fully serialized.\n\t *\n\t * However, drivers cannot in general deal with cross-CPU\n\t * requests, so while get_next_freq() will work, our\n\t * sugov_update_commit() call may not for the fast switching platforms.\n\t *\n\t * Hence stop here for remote requests if they aren't supported\n\t * by the hardware, as calculating the frequency is pointless if\n\t * we cannot in fact act on it.\n\t *\n\t * This is needed on the slow switching platforms too to prevent CPUs\n\t * going offline from leaving stale IRQ work items behind.\n\t */\n\tif (!cpufreq_this_cpu_can_update(sg_policy->policy))\n\t\treturn false;\n\n\tif (unlikely(sg_policy->limits_changed)) {\n\t\tsg_policy->limits_changed = false;\n\t\tsg_policy->need_freq_update = true;\n\t\treturn true;\n\t}\n\n\tdelta_ns = time - sg_policy->last_freq_update_time;\n\n\treturn delta_ns >= sg_policy->freq_update_delay_ns;\n}"
  }
]