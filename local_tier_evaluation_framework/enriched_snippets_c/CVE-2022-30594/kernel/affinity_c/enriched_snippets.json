[
  {
    "function_name": "irq_calc_affinity_vectors",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "496-514",
    "snippet": "unsigned int irq_calc_affinity_vectors(unsigned int minvec, unsigned int maxvec,\n\t\t\t\t       const struct irq_affinity *affd)\n{\n\tunsigned int resv = affd->pre_vectors + affd->post_vectors;\n\tunsigned int set_vecs;\n\n\tif (resv > minvec)\n\t\treturn 0;\n\n\tif (affd->calc_sets) {\n\t\tset_vecs = maxvec - resv;\n\t} else {\n\t\tcpus_read_lock();\n\t\tset_vecs = cpumask_weight(cpu_possible_mask);\n\t\tcpus_read_unlock();\n\t}\n\n\treturn resv + min(set_vecs, maxvec - resv);\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "min",
          "args": [
            "set_vecs",
            "maxvec - resv"
          ],
          "line": 513
        },
        "resolved": true,
        "details": {
          "function_name": "irq_setup_timings",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/internals.h",
          "lines": "388-389",
          "snippet": "static inline void irq_setup_timings(struct irq_desc *desc,\n\t\t\t\t     struct irqaction *act) {}",
          "includes": [
            "#include <linux/debugfs.h>",
            "#include \"settings.h\"",
            "#include \"debug.h\"",
            "#include <linux/sched/clock.h>",
            "#include <linux/pm_runtime.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/irqdesc.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void __disable_irq(struct irq_desc *desc);",
            "extern void __enable_irq(struct irq_desc *desc);",
            "extern int irq_activate(struct irq_desc *desc);",
            "extern void irq_shutdown(struct irq_desc *desc);",
            "extern void irq_shutdown_and_deactivate(struct irq_desc *desc);",
            "extern void irq_enable(struct irq_desc *desc);",
            "extern void irq_disable(struct irq_desc *desc);",
            "extern void mask_irq(struct irq_desc *desc);",
            "extern void unmask_irq(struct irq_desc *desc);",
            "extern void unmask_threaded_irq(struct irq_desc *desc);",
            "irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event_percpu(struct irq_desc *desc);",
            "irqreturn_t handle_irq_event(struct irq_desc *desc);",
            "bool irq_wait_for_poll(struct irq_desc *desc);",
            "extern void irq_set_thread_affinity(struct irq_desc *desc);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/debugfs.h>\n#include \"settings.h\"\n#include \"debug.h\"\n#include <linux/sched/clock.h>\n#include <linux/pm_runtime.h>\n#include <linux/kernel_stat.h>\n#include <linux/irqdesc.h>\n\nextern void __disable_irq(struct irq_desc *desc);\nextern void __enable_irq(struct irq_desc *desc);\nextern int irq_activate(struct irq_desc *desc);\nextern void irq_shutdown(struct irq_desc *desc);\nextern void irq_shutdown_and_deactivate(struct irq_desc *desc);\nextern void irq_enable(struct irq_desc *desc);\nextern void irq_disable(struct irq_desc *desc);\nextern void mask_irq(struct irq_desc *desc);\nextern void unmask_irq(struct irq_desc *desc);\nextern void unmask_threaded_irq(struct irq_desc *desc);\nirqreturn_t __handle_irq_event_percpu(struct irq_desc *desc);\nirqreturn_t handle_irq_event_percpu(struct irq_desc *desc);\nirqreturn_t handle_irq_event(struct irq_desc *desc);\nbool irq_wait_for_poll(struct irq_desc *desc);\nextern void irq_set_thread_affinity(struct irq_desc *desc);\n\nstatic inline void irq_setup_timings(struct irq_desc *desc,\n\t\t\t\t     struct irqaction *act) {}"
        }
      },
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 510
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "cpu_possible_mask"
          ],
          "line": 509
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 508
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nunsigned int irq_calc_affinity_vectors(unsigned int minvec, unsigned int maxvec,\n\t\t\t\t       const struct irq_affinity *affd)\n{\n\tunsigned int resv = affd->pre_vectors + affd->post_vectors;\n\tunsigned int set_vecs;\n\n\tif (resv > minvec)\n\t\treturn 0;\n\n\tif (affd->calc_sets) {\n\t\tset_vecs = maxvec - resv;\n\t} else {\n\t\tcpus_read_lock();\n\t\tset_vecs = cpumask_weight(cpu_possible_mask);\n\t\tcpus_read_unlock();\n\t}\n\n\treturn resv + min(set_vecs, maxvec - resv);\n}"
  },
  {
    "function_name": "irq_create_affinity_masks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "415-488",
    "snippet": "struct irq_affinity_desc *\nirq_create_affinity_masks(unsigned int nvecs, struct irq_affinity *affd)\n{\n\tunsigned int affvecs, curvec, usedvecs, i;\n\tstruct irq_affinity_desc *masks = NULL;\n\n\t/*\n\t * Determine the number of vectors which need interrupt affinities\n\t * assigned. If the pre/post request exhausts the available vectors\n\t * then nothing to do here except for invoking the calc_sets()\n\t * callback so the device driver can adjust to the situation.\n\t */\n\tif (nvecs > affd->pre_vectors + affd->post_vectors)\n\t\taffvecs = nvecs - affd->pre_vectors - affd->post_vectors;\n\telse\n\t\taffvecs = 0;\n\n\t/*\n\t * Simple invocations do not provide a calc_sets() callback. Install\n\t * the generic one.\n\t */\n\tif (!affd->calc_sets)\n\t\taffd->calc_sets = default_calc_sets;\n\n\t/* Recalculate the sets */\n\taffd->calc_sets(affd, affvecs);\n\n\tif (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS))\n\t\treturn NULL;\n\n\t/* Nothing to assign? */\n\tif (!affvecs)\n\t\treturn NULL;\n\n\tmasks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL);\n\tif (!masks)\n\t\treturn NULL;\n\n\t/* Fill out vectors at the beginning that don't need affinity */\n\tfor (curvec = 0; curvec < affd->pre_vectors; curvec++)\n\t\tcpumask_copy(&masks[curvec].mask, irq_default_affinity);\n\n\t/*\n\t * Spread on present CPUs starting from affd->pre_vectors. If we\n\t * have multiple sets, build each sets affinity mask separately.\n\t */\n\tfor (i = 0, usedvecs = 0; i < affd->nr_sets; i++) {\n\t\tunsigned int this_vecs = affd->set_size[i];\n\t\tint ret;\n\n\t\tret = irq_build_affinity_masks(curvec, this_vecs,\n\t\t\t\t\t       curvec, masks);\n\t\tif (ret) {\n\t\t\tkfree(masks);\n\t\t\treturn NULL;\n\t\t}\n\t\tcurvec += this_vecs;\n\t\tusedvecs += this_vecs;\n\t}\n\n\t/* Fill out vectors at the end that don't need affinity */\n\tif (usedvecs >= affvecs)\n\t\tcurvec = affd->pre_vectors + affvecs;\n\telse\n\t\tcurvec = affd->pre_vectors + usedvecs;\n\tfor (; curvec < nvecs; curvec++)\n\t\tcpumask_copy(&masks[curvec].mask, irq_default_affinity);\n\n\t/* Mark the managed interrupts */\n\tfor (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)\n\t\tmasks[i].is_managed = 1;\n\n\treturn masks;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_copy",
          "args": [
            "&masks[curvec].mask",
            "irq_default_affinity"
          ],
          "line": 481
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "masks"
          ],
          "line": 468
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_build_affinity_masks",
          "args": [
            "curvec",
            "this_vecs",
            "curvec",
            "masks"
          ],
          "line": 465
        },
        "resolved": true,
        "details": {
          "function_name": "irq_build_affinity_masks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "338-400",
          "snippet": "static int irq_build_affinity_masks(unsigned int startvec, unsigned int numvecs,\n\t\t\t\t    unsigned int firstvec,\n\t\t\t\t    struct irq_affinity_desc *masks)\n{\n\tunsigned int curvec = startvec, nr_present = 0, nr_others = 0;\n\tcpumask_var_t *node_to_cpumask;\n\tcpumask_var_t nmsk, npresmsk;\n\tint ret = -ENOMEM;\n\n\tif (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))\n\t\treturn ret;\n\n\tif (!zalloc_cpumask_var(&npresmsk, GFP_KERNEL))\n\t\tgoto fail_nmsk;\n\n\tnode_to_cpumask = alloc_node_to_cpumask();\n\tif (!node_to_cpumask)\n\t\tgoto fail_npresmsk;\n\n\t/* Stabilize the cpumasks */\n\tcpus_read_lock();\n\tbuild_node_to_cpumask(node_to_cpumask);\n\n\t/* Spread on present CPUs starting from affd->pre_vectors */\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, cpu_present_mask,\n\t\t\t\t\t nmsk, masks);\n\tif (ret < 0)\n\t\tgoto fail_build_affinity;\n\tnr_present = ret;\n\n\t/*\n\t * Spread on non present CPUs starting from the next vector to be\n\t * handled. If the spreading of present CPUs already exhausted the\n\t * vector space, assign the non present CPUs to the already spread\n\t * out vectors.\n\t */\n\tif (nr_present >= numvecs)\n\t\tcurvec = firstvec;\n\telse\n\t\tcurvec = firstvec + nr_present;\n\tcpumask_andnot(npresmsk, cpu_possible_mask, cpu_present_mask);\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, npresmsk, nmsk,\n\t\t\t\t\t masks);\n\tif (ret >= 0)\n\t\tnr_others = ret;\n\n fail_build_affinity:\n\tcpus_read_unlock();\n\n\tif (ret >= 0)\n\t\tWARN_ON(nr_present + nr_others < numvecs);\n\n\tfree_node_to_cpumask(node_to_cpumask);\n\n fail_npresmsk:\n\tfree_cpumask_var(npresmsk);\n\n fail_nmsk:\n\tfree_cpumask_var(nmsk);\n\treturn ret < 0 ? ret : 0;\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int irq_build_affinity_masks(unsigned int startvec, unsigned int numvecs,\n\t\t\t\t    unsigned int firstvec,\n\t\t\t\t    struct irq_affinity_desc *masks)\n{\n\tunsigned int curvec = startvec, nr_present = 0, nr_others = 0;\n\tcpumask_var_t *node_to_cpumask;\n\tcpumask_var_t nmsk, npresmsk;\n\tint ret = -ENOMEM;\n\n\tif (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))\n\t\treturn ret;\n\n\tif (!zalloc_cpumask_var(&npresmsk, GFP_KERNEL))\n\t\tgoto fail_nmsk;\n\n\tnode_to_cpumask = alloc_node_to_cpumask();\n\tif (!node_to_cpumask)\n\t\tgoto fail_npresmsk;\n\n\t/* Stabilize the cpumasks */\n\tcpus_read_lock();\n\tbuild_node_to_cpumask(node_to_cpumask);\n\n\t/* Spread on present CPUs starting from affd->pre_vectors */\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, cpu_present_mask,\n\t\t\t\t\t nmsk, masks);\n\tif (ret < 0)\n\t\tgoto fail_build_affinity;\n\tnr_present = ret;\n\n\t/*\n\t * Spread on non present CPUs starting from the next vector to be\n\t * handled. If the spreading of present CPUs already exhausted the\n\t * vector space, assign the non present CPUs to the already spread\n\t * out vectors.\n\t */\n\tif (nr_present >= numvecs)\n\t\tcurvec = firstvec;\n\telse\n\t\tcurvec = firstvec + nr_present;\n\tcpumask_andnot(npresmsk, cpu_possible_mask, cpu_present_mask);\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, npresmsk, nmsk,\n\t\t\t\t\t masks);\n\tif (ret >= 0)\n\t\tnr_others = ret;\n\n fail_build_affinity:\n\tcpus_read_unlock();\n\n\tif (ret >= 0)\n\t\tWARN_ON(nr_present + nr_others < numvecs);\n\n\tfree_node_to_cpumask(node_to_cpumask);\n\n fail_npresmsk:\n\tfree_cpumask_var(npresmsk);\n\n fail_nmsk:\n\tfree_cpumask_var(nmsk);\n\treturn ret < 0 ? ret : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_copy",
          "args": [
            "&masks[curvec].mask",
            "irq_default_affinity"
          ],
          "line": 455
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kcalloc",
          "args": [
            "nvecs",
            "sizeof(*masks)",
            "GFP_KERNEL"
          ],
          "line": 449
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "affd->nr_sets > IRQ_AFFINITY_MAX_SETS"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "affd->calc_sets",
          "args": [
            "affd",
            "affvecs"
          ],
          "line": 440
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstruct irq_affinity_desc *\nirq_create_affinity_masks(unsigned int nvecs, struct irq_affinity *affd)\n{\n\tunsigned int affvecs, curvec, usedvecs, i;\n\tstruct irq_affinity_desc *masks = NULL;\n\n\t/*\n\t * Determine the number of vectors which need interrupt affinities\n\t * assigned. If the pre/post request exhausts the available vectors\n\t * then nothing to do here except for invoking the calc_sets()\n\t * callback so the device driver can adjust to the situation.\n\t */\n\tif (nvecs > affd->pre_vectors + affd->post_vectors)\n\t\taffvecs = nvecs - affd->pre_vectors - affd->post_vectors;\n\telse\n\t\taffvecs = 0;\n\n\t/*\n\t * Simple invocations do not provide a calc_sets() callback. Install\n\t * the generic one.\n\t */\n\tif (!affd->calc_sets)\n\t\taffd->calc_sets = default_calc_sets;\n\n\t/* Recalculate the sets */\n\taffd->calc_sets(affd, affvecs);\n\n\tif (WARN_ON_ONCE(affd->nr_sets > IRQ_AFFINITY_MAX_SETS))\n\t\treturn NULL;\n\n\t/* Nothing to assign? */\n\tif (!affvecs)\n\t\treturn NULL;\n\n\tmasks = kcalloc(nvecs, sizeof(*masks), GFP_KERNEL);\n\tif (!masks)\n\t\treturn NULL;\n\n\t/* Fill out vectors at the beginning that don't need affinity */\n\tfor (curvec = 0; curvec < affd->pre_vectors; curvec++)\n\t\tcpumask_copy(&masks[curvec].mask, irq_default_affinity);\n\n\t/*\n\t * Spread on present CPUs starting from affd->pre_vectors. If we\n\t * have multiple sets, build each sets affinity mask separately.\n\t */\n\tfor (i = 0, usedvecs = 0; i < affd->nr_sets; i++) {\n\t\tunsigned int this_vecs = affd->set_size[i];\n\t\tint ret;\n\n\t\tret = irq_build_affinity_masks(curvec, this_vecs,\n\t\t\t\t\t       curvec, masks);\n\t\tif (ret) {\n\t\t\tkfree(masks);\n\t\t\treturn NULL;\n\t\t}\n\t\tcurvec += this_vecs;\n\t\tusedvecs += this_vecs;\n\t}\n\n\t/* Fill out vectors at the end that don't need affinity */\n\tif (usedvecs >= affvecs)\n\t\tcurvec = affd->pre_vectors + affvecs;\n\telse\n\t\tcurvec = affd->pre_vectors + usedvecs;\n\tfor (; curvec < nvecs; curvec++)\n\t\tcpumask_copy(&masks[curvec].mask, irq_default_affinity);\n\n\t/* Mark the managed interrupts */\n\tfor (i = affd->pre_vectors; i < nvecs - affd->post_vectors; i++)\n\t\tmasks[i].is_managed = 1;\n\n\treturn masks;\n}"
  },
  {
    "function_name": "default_calc_sets",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "402-406",
    "snippet": "static void default_calc_sets(struct irq_affinity *affd, unsigned int affvecs)\n{\n\taffd->nr_sets = 1;\n\taffd->set_size[0] = affvecs;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void default_calc_sets(struct irq_affinity *affd, unsigned int affvecs)\n{\n\taffd->nr_sets = 1;\n\taffd->set_size[0] = affvecs;\n}"
  },
  {
    "function_name": "irq_build_affinity_masks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "338-400",
    "snippet": "static int irq_build_affinity_masks(unsigned int startvec, unsigned int numvecs,\n\t\t\t\t    unsigned int firstvec,\n\t\t\t\t    struct irq_affinity_desc *masks)\n{\n\tunsigned int curvec = startvec, nr_present = 0, nr_others = 0;\n\tcpumask_var_t *node_to_cpumask;\n\tcpumask_var_t nmsk, npresmsk;\n\tint ret = -ENOMEM;\n\n\tif (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))\n\t\treturn ret;\n\n\tif (!zalloc_cpumask_var(&npresmsk, GFP_KERNEL))\n\t\tgoto fail_nmsk;\n\n\tnode_to_cpumask = alloc_node_to_cpumask();\n\tif (!node_to_cpumask)\n\t\tgoto fail_npresmsk;\n\n\t/* Stabilize the cpumasks */\n\tcpus_read_lock();\n\tbuild_node_to_cpumask(node_to_cpumask);\n\n\t/* Spread on present CPUs starting from affd->pre_vectors */\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, cpu_present_mask,\n\t\t\t\t\t nmsk, masks);\n\tif (ret < 0)\n\t\tgoto fail_build_affinity;\n\tnr_present = ret;\n\n\t/*\n\t * Spread on non present CPUs starting from the next vector to be\n\t * handled. If the spreading of present CPUs already exhausted the\n\t * vector space, assign the non present CPUs to the already spread\n\t * out vectors.\n\t */\n\tif (nr_present >= numvecs)\n\t\tcurvec = firstvec;\n\telse\n\t\tcurvec = firstvec + nr_present;\n\tcpumask_andnot(npresmsk, cpu_possible_mask, cpu_present_mask);\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, npresmsk, nmsk,\n\t\t\t\t\t masks);\n\tif (ret >= 0)\n\t\tnr_others = ret;\n\n fail_build_affinity:\n\tcpus_read_unlock();\n\n\tif (ret >= 0)\n\t\tWARN_ON(nr_present + nr_others < numvecs);\n\n\tfree_node_to_cpumask(node_to_cpumask);\n\n fail_npresmsk:\n\tfree_cpumask_var(npresmsk);\n\n fail_nmsk:\n\tfree_cpumask_var(nmsk);\n\treturn ret < 0 ? ret : 0;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "nmsk"
          ],
          "line": 398
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "npresmsk"
          ],
          "line": 395
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "free_node_to_cpumask",
          "args": [
            "node_to_cpumask"
          ],
          "line": 392
        },
        "resolved": true,
        "details": {
          "function_name": "free_node_to_cpumask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "66-73",
          "snippet": "static void free_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint node;\n\n\tfor (node = 0; node < nr_node_ids; node++)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void free_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint node;\n\n\tfor (node = 0; node < nr_node_ids; node++)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "nr_present + nr_others < numvecs"
          ],
          "line": 390
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 387
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__irq_build_affinity_masks",
          "args": [
            "curvec",
            "numvecs",
            "firstvec",
            "node_to_cpumask",
            "npresmsk",
            "nmsk",
            "masks"
          ],
          "line": 380
        },
        "resolved": true,
        "details": {
          "function_name": "__irq_build_affinity_masks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "247-331",
          "snippet": "static int __irq_build_affinity_masks(unsigned int startvec,\n\t\t\t\t      unsigned int numvecs,\n\t\t\t\t      unsigned int firstvec,\n\t\t\t\t      cpumask_var_t *node_to_cpumask,\n\t\t\t\t      const struct cpumask *cpu_mask,\n\t\t\t\t      struct cpumask *nmsk,\n\t\t\t\t      struct irq_affinity_desc *masks)\n{\n\tunsigned int i, n, nodes, cpus_per_vec, extra_vecs, done = 0;\n\tunsigned int last_affv = firstvec + numvecs;\n\tunsigned int curvec = startvec;\n\tnodemask_t nodemsk = NODE_MASK_NONE;\n\tstruct node_vectors *node_vectors;\n\n\tif (!cpumask_weight(cpu_mask))\n\t\treturn 0;\n\n\tnodes = get_nodes_in_cpumask(node_to_cpumask, cpu_mask, &nodemsk);\n\n\t/*\n\t * If the number of nodes in the mask is greater than or equal the\n\t * number of vectors we just spread the vectors across the nodes.\n\t */\n\tif (numvecs <= nodes) {\n\t\tfor_each_node_mask(n, nodemsk) {\n\t\t\tcpumask_or(&masks[curvec].mask, &masks[curvec].mask,\n\t\t\t\t   node_to_cpumask[n]);\n\t\t\tif (++curvec == last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t}\n\t\treturn numvecs;\n\t}\n\n\tnode_vectors = kcalloc(nr_node_ids,\n\t\t\t       sizeof(struct node_vectors),\n\t\t\t       GFP_KERNEL);\n\tif (!node_vectors)\n\t\treturn -ENOMEM;\n\n\t/* allocate vector number for each node */\n\talloc_nodes_vectors(numvecs, node_to_cpumask, cpu_mask,\n\t\t\t    nodemsk, nmsk, node_vectors);\n\n\tfor (i = 0; i < nr_node_ids; i++) {\n\t\tunsigned int ncpus, v;\n\t\tstruct node_vectors *nv = &node_vectors[i];\n\n\t\tif (nv->nvectors == UINT_MAX)\n\t\t\tcontinue;\n\n\t\t/* Get the cpus on this node which are in the mask */\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[nv->id]);\n\t\tncpus = cpumask_weight(nmsk);\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(nv->nvectors > ncpus);\n\n\t\t/* Account for rounding errors */\n\t\textra_vecs = ncpus - nv->nvectors * (ncpus / nv->nvectors);\n\n\t\t/* Spread allocated vectors on CPUs of the current node */\n\t\tfor (v = 0; v < nv->nvectors; v++, curvec++) {\n\t\t\tcpus_per_vec = ncpus / nv->nvectors;\n\n\t\t\t/* Account for extra vectors to compensate rounding errors */\n\t\t\tif (extra_vecs) {\n\t\t\t\tcpus_per_vec++;\n\t\t\t\t--extra_vecs;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * wrapping has to be considered given 'startvec'\n\t\t\t * may start anywhere\n\t\t\t */\n\t\t\tif (curvec >= last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t\tirq_spread_init_one(&masks[curvec].mask, nmsk,\n\t\t\t\t\t\tcpus_per_vec);\n\t\t}\n\t\tdone += nv->nvectors;\n\t}\n\tkfree(node_vectors);\n\treturn done;\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int __irq_build_affinity_masks(unsigned int startvec,\n\t\t\t\t      unsigned int numvecs,\n\t\t\t\t      unsigned int firstvec,\n\t\t\t\t      cpumask_var_t *node_to_cpumask,\n\t\t\t\t      const struct cpumask *cpu_mask,\n\t\t\t\t      struct cpumask *nmsk,\n\t\t\t\t      struct irq_affinity_desc *masks)\n{\n\tunsigned int i, n, nodes, cpus_per_vec, extra_vecs, done = 0;\n\tunsigned int last_affv = firstvec + numvecs;\n\tunsigned int curvec = startvec;\n\tnodemask_t nodemsk = NODE_MASK_NONE;\n\tstruct node_vectors *node_vectors;\n\n\tif (!cpumask_weight(cpu_mask))\n\t\treturn 0;\n\n\tnodes = get_nodes_in_cpumask(node_to_cpumask, cpu_mask, &nodemsk);\n\n\t/*\n\t * If the number of nodes in the mask is greater than or equal the\n\t * number of vectors we just spread the vectors across the nodes.\n\t */\n\tif (numvecs <= nodes) {\n\t\tfor_each_node_mask(n, nodemsk) {\n\t\t\tcpumask_or(&masks[curvec].mask, &masks[curvec].mask,\n\t\t\t\t   node_to_cpumask[n]);\n\t\t\tif (++curvec == last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t}\n\t\treturn numvecs;\n\t}\n\n\tnode_vectors = kcalloc(nr_node_ids,\n\t\t\t       sizeof(struct node_vectors),\n\t\t\t       GFP_KERNEL);\n\tif (!node_vectors)\n\t\treturn -ENOMEM;\n\n\t/* allocate vector number for each node */\n\talloc_nodes_vectors(numvecs, node_to_cpumask, cpu_mask,\n\t\t\t    nodemsk, nmsk, node_vectors);\n\n\tfor (i = 0; i < nr_node_ids; i++) {\n\t\tunsigned int ncpus, v;\n\t\tstruct node_vectors *nv = &node_vectors[i];\n\n\t\tif (nv->nvectors == UINT_MAX)\n\t\t\tcontinue;\n\n\t\t/* Get the cpus on this node which are in the mask */\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[nv->id]);\n\t\tncpus = cpumask_weight(nmsk);\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(nv->nvectors > ncpus);\n\n\t\t/* Account for rounding errors */\n\t\textra_vecs = ncpus - nv->nvectors * (ncpus / nv->nvectors);\n\n\t\t/* Spread allocated vectors on CPUs of the current node */\n\t\tfor (v = 0; v < nv->nvectors; v++, curvec++) {\n\t\t\tcpus_per_vec = ncpus / nv->nvectors;\n\n\t\t\t/* Account for extra vectors to compensate rounding errors */\n\t\t\tif (extra_vecs) {\n\t\t\t\tcpus_per_vec++;\n\t\t\t\t--extra_vecs;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * wrapping has to be considered given 'startvec'\n\t\t\t * may start anywhere\n\t\t\t */\n\t\t\tif (curvec >= last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t\tirq_spread_init_one(&masks[curvec].mask, nmsk,\n\t\t\t\t\t\tcpus_per_vec);\n\t\t}\n\t\tdone += nv->nvectors;\n\t}\n\tkfree(node_vectors);\n\treturn done;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_andnot",
          "args": [
            "npresmsk",
            "cpu_possible_mask",
            "cpu_present_mask"
          ],
          "line": 379
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "build_node_to_cpumask",
          "args": [
            "node_to_cpumask"
          ],
          "line": 359
        },
        "resolved": true,
        "details": {
          "function_name": "build_node_to_cpumask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "75-81",
          "snippet": "static void build_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tcpumask_set_cpu(cpu, masks[cpu_to_node(cpu)]);\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void build_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tcpumask_set_cpu(cpu, masks[cpu_to_node(cpu)]);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 358
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "alloc_node_to_cpumask",
          "args": [],
          "line": 353
        },
        "resolved": true,
        "details": {
          "function_name": "alloc_node_to_cpumask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "43-64",
          "snippet": "static cpumask_var_t *alloc_node_to_cpumask(void)\n{\n\tcpumask_var_t *masks;\n\tint node;\n\n\tmasks = kcalloc(nr_node_ids, sizeof(cpumask_var_t), GFP_KERNEL);\n\tif (!masks)\n\t\treturn NULL;\n\n\tfor (node = 0; node < nr_node_ids; node++) {\n\t\tif (!zalloc_cpumask_var(&masks[node], GFP_KERNEL))\n\t\t\tgoto out_unwind;\n\t}\n\n\treturn masks;\n\nout_unwind:\n\twhile (--node >= 0)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic cpumask_var_t *alloc_node_to_cpumask(void)\n{\n\tcpumask_var_t *masks;\n\tint node;\n\n\tmasks = kcalloc(nr_node_ids, sizeof(cpumask_var_t), GFP_KERNEL);\n\tif (!masks)\n\t\treturn NULL;\n\n\tfor (node = 0; node < nr_node_ids; node++) {\n\t\tif (!zalloc_cpumask_var(&masks[node], GFP_KERNEL))\n\t\t\tgoto out_unwind;\n\t}\n\n\treturn masks;\n\nout_unwind:\n\twhile (--node >= 0)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&npresmsk",
            "GFP_KERNEL"
          ],
          "line": 350
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&nmsk",
            "GFP_KERNEL"
          ],
          "line": 347
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int irq_build_affinity_masks(unsigned int startvec, unsigned int numvecs,\n\t\t\t\t    unsigned int firstvec,\n\t\t\t\t    struct irq_affinity_desc *masks)\n{\n\tunsigned int curvec = startvec, nr_present = 0, nr_others = 0;\n\tcpumask_var_t *node_to_cpumask;\n\tcpumask_var_t nmsk, npresmsk;\n\tint ret = -ENOMEM;\n\n\tif (!zalloc_cpumask_var(&nmsk, GFP_KERNEL))\n\t\treturn ret;\n\n\tif (!zalloc_cpumask_var(&npresmsk, GFP_KERNEL))\n\t\tgoto fail_nmsk;\n\n\tnode_to_cpumask = alloc_node_to_cpumask();\n\tif (!node_to_cpumask)\n\t\tgoto fail_npresmsk;\n\n\t/* Stabilize the cpumasks */\n\tcpus_read_lock();\n\tbuild_node_to_cpumask(node_to_cpumask);\n\n\t/* Spread on present CPUs starting from affd->pre_vectors */\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, cpu_present_mask,\n\t\t\t\t\t nmsk, masks);\n\tif (ret < 0)\n\t\tgoto fail_build_affinity;\n\tnr_present = ret;\n\n\t/*\n\t * Spread on non present CPUs starting from the next vector to be\n\t * handled. If the spreading of present CPUs already exhausted the\n\t * vector space, assign the non present CPUs to the already spread\n\t * out vectors.\n\t */\n\tif (nr_present >= numvecs)\n\t\tcurvec = firstvec;\n\telse\n\t\tcurvec = firstvec + nr_present;\n\tcpumask_andnot(npresmsk, cpu_possible_mask, cpu_present_mask);\n\tret = __irq_build_affinity_masks(curvec, numvecs, firstvec,\n\t\t\t\t\t node_to_cpumask, npresmsk, nmsk,\n\t\t\t\t\t masks);\n\tif (ret >= 0)\n\t\tnr_others = ret;\n\n fail_build_affinity:\n\tcpus_read_unlock();\n\n\tif (ret >= 0)\n\t\tWARN_ON(nr_present + nr_others < numvecs);\n\n\tfree_node_to_cpumask(node_to_cpumask);\n\n fail_npresmsk:\n\tfree_cpumask_var(npresmsk);\n\n fail_nmsk:\n\tfree_cpumask_var(nmsk);\n\treturn ret < 0 ? ret : 0;\n}"
  },
  {
    "function_name": "__irq_build_affinity_masks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "247-331",
    "snippet": "static int __irq_build_affinity_masks(unsigned int startvec,\n\t\t\t\t      unsigned int numvecs,\n\t\t\t\t      unsigned int firstvec,\n\t\t\t\t      cpumask_var_t *node_to_cpumask,\n\t\t\t\t      const struct cpumask *cpu_mask,\n\t\t\t\t      struct cpumask *nmsk,\n\t\t\t\t      struct irq_affinity_desc *masks)\n{\n\tunsigned int i, n, nodes, cpus_per_vec, extra_vecs, done = 0;\n\tunsigned int last_affv = firstvec + numvecs;\n\tunsigned int curvec = startvec;\n\tnodemask_t nodemsk = NODE_MASK_NONE;\n\tstruct node_vectors *node_vectors;\n\n\tif (!cpumask_weight(cpu_mask))\n\t\treturn 0;\n\n\tnodes = get_nodes_in_cpumask(node_to_cpumask, cpu_mask, &nodemsk);\n\n\t/*\n\t * If the number of nodes in the mask is greater than or equal the\n\t * number of vectors we just spread the vectors across the nodes.\n\t */\n\tif (numvecs <= nodes) {\n\t\tfor_each_node_mask(n, nodemsk) {\n\t\t\tcpumask_or(&masks[curvec].mask, &masks[curvec].mask,\n\t\t\t\t   node_to_cpumask[n]);\n\t\t\tif (++curvec == last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t}\n\t\treturn numvecs;\n\t}\n\n\tnode_vectors = kcalloc(nr_node_ids,\n\t\t\t       sizeof(struct node_vectors),\n\t\t\t       GFP_KERNEL);\n\tif (!node_vectors)\n\t\treturn -ENOMEM;\n\n\t/* allocate vector number for each node */\n\talloc_nodes_vectors(numvecs, node_to_cpumask, cpu_mask,\n\t\t\t    nodemsk, nmsk, node_vectors);\n\n\tfor (i = 0; i < nr_node_ids; i++) {\n\t\tunsigned int ncpus, v;\n\t\tstruct node_vectors *nv = &node_vectors[i];\n\n\t\tif (nv->nvectors == UINT_MAX)\n\t\t\tcontinue;\n\n\t\t/* Get the cpus on this node which are in the mask */\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[nv->id]);\n\t\tncpus = cpumask_weight(nmsk);\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(nv->nvectors > ncpus);\n\n\t\t/* Account for rounding errors */\n\t\textra_vecs = ncpus - nv->nvectors * (ncpus / nv->nvectors);\n\n\t\t/* Spread allocated vectors on CPUs of the current node */\n\t\tfor (v = 0; v < nv->nvectors; v++, curvec++) {\n\t\t\tcpus_per_vec = ncpus / nv->nvectors;\n\n\t\t\t/* Account for extra vectors to compensate rounding errors */\n\t\t\tif (extra_vecs) {\n\t\t\t\tcpus_per_vec++;\n\t\t\t\t--extra_vecs;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * wrapping has to be considered given 'startvec'\n\t\t\t * may start anywhere\n\t\t\t */\n\t\t\tif (curvec >= last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t\tirq_spread_init_one(&masks[curvec].mask, nmsk,\n\t\t\t\t\t\tcpus_per_vec);\n\t\t}\n\t\tdone += nv->nvectors;\n\t}\n\tkfree(node_vectors);\n\treturn done;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "node_vectors"
          ],
          "line": 329
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "irq_spread_init_one",
          "args": [
            "&masks[curvec].mask",
            "nmsk",
            "cpus_per_vec"
          ],
          "line": 324
        },
        "resolved": true,
        "details": {
          "function_name": "irq_spread_init_one",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "12-41",
          "snippet": "static void irq_spread_init_one(struct cpumask *irqmsk, struct cpumask *nmsk,\n\t\t\t\tunsigned int cpus_per_vec)\n{\n\tconst struct cpumask *siblmsk;\n\tint cpu, sibl;\n\n\tfor ( ; cpus_per_vec > 0; ) {\n\t\tcpu = cpumask_first(nmsk);\n\n\t\t/* Should not happen, but I'm too lazy to think about it */\n\t\tif (cpu >= nr_cpu_ids)\n\t\t\treturn;\n\n\t\tcpumask_clear_cpu(cpu, nmsk);\n\t\tcpumask_set_cpu(cpu, irqmsk);\n\t\tcpus_per_vec--;\n\n\t\t/* If the cpu has siblings, use them first */\n\t\tsiblmsk = topology_sibling_cpumask(cpu);\n\t\tfor (sibl = -1; cpus_per_vec > 0; ) {\n\t\t\tsibl = cpumask_next(sibl, siblmsk);\n\t\t\tif (sibl >= nr_cpu_ids)\n\t\t\t\tbreak;\n\t\t\tif (!cpumask_test_and_clear_cpu(sibl, nmsk))\n\t\t\t\tcontinue;\n\t\t\tcpumask_set_cpu(sibl, irqmsk);\n\t\t\tcpus_per_vec--;\n\t\t}\n\t}\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void irq_spread_init_one(struct cpumask *irqmsk, struct cpumask *nmsk,\n\t\t\t\tunsigned int cpus_per_vec)\n{\n\tconst struct cpumask *siblmsk;\n\tint cpu, sibl;\n\n\tfor ( ; cpus_per_vec > 0; ) {\n\t\tcpu = cpumask_first(nmsk);\n\n\t\t/* Should not happen, but I'm too lazy to think about it */\n\t\tif (cpu >= nr_cpu_ids)\n\t\t\treturn;\n\n\t\tcpumask_clear_cpu(cpu, nmsk);\n\t\tcpumask_set_cpu(cpu, irqmsk);\n\t\tcpus_per_vec--;\n\n\t\t/* If the cpu has siblings, use them first */\n\t\tsiblmsk = topology_sibling_cpumask(cpu);\n\t\tfor (sibl = -1; cpus_per_vec > 0; ) {\n\t\t\tsibl = cpumask_next(sibl, siblmsk);\n\t\t\tif (sibl >= nr_cpu_ids)\n\t\t\t\tbreak;\n\t\t\tif (!cpumask_test_and_clear_cpu(sibl, nmsk))\n\t\t\t\tcontinue;\n\t\t\tcpumask_set_cpu(sibl, irqmsk);\n\t\t\tcpus_per_vec--;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "nv->nvectors > ncpus"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "nmsk"
          ],
          "line": 299
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_and",
          "args": [
            "nmsk",
            "cpu_mask",
            "node_to_cpumask[nv->id]"
          ],
          "line": 298
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_nodes_vectors",
          "args": [
            "numvecs",
            "node_to_cpumask",
            "cpu_mask",
            "nodemsk",
            "nmsk",
            "node_vectors"
          ],
          "line": 287
        },
        "resolved": true,
        "details": {
          "function_name": "alloc_nodes_vectors",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "128-245",
          "snippet": "static void alloc_nodes_vectors(unsigned int numvecs,\n\t\t\t\tcpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *cpu_mask,\n\t\t\t\tconst nodemask_t nodemsk,\n\t\t\t\tstruct cpumask *nmsk,\n\t\t\t\tstruct node_vectors *node_vectors)\n{\n\tunsigned n, remaining_ncpus = 0;\n\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tnode_vectors[n].id = n;\n\t\tnode_vectors[n].ncpus = UINT_MAX;\n\t}\n\n\tfor_each_node_mask(n, nodemsk) {\n\t\tunsigned ncpus;\n\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[n]);\n\t\tncpus = cpumask_weight(nmsk);\n\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\t\tremaining_ncpus += ncpus;\n\t\tnode_vectors[n].ncpus = ncpus;\n\t}\n\n\tnumvecs = min_t(unsigned, remaining_ncpus, numvecs);\n\n\tsort(node_vectors, nr_node_ids, sizeof(node_vectors[0]),\n\t     ncpus_cmp_func, NULL);\n\n\t/*\n\t * Allocate vectors for each node according to the ratio of this\n\t * node's nr_cpus to remaining un-assigned ncpus. 'numvecs' is\n\t * bigger than number of active numa nodes. Always start the\n\t * allocation from the node with minimized nr_cpus.\n\t *\n\t * This way guarantees that each active node gets allocated at\n\t * least one vector, and the theory is simple: over-allocation\n\t * is only done when this node is assigned by one vector, so\n\t * other nodes will be allocated >= 1 vector, since 'numvecs' is\n\t * bigger than number of numa nodes.\n\t *\n\t * One perfect invariant is that number of allocated vectors for\n\t * each node is <= CPU count of this node:\n\t *\n\t * 1) suppose there are two nodes: A and B\n\t * \tncpu(X) is CPU count of node X\n\t * \tvecs(X) is the vector count allocated to node X via this\n\t * \talgorithm\n\t *\n\t * \tncpu(A) <= ncpu(B)\n\t * \tncpu(A) + ncpu(B) = N\n\t * \tvecs(A) + vecs(B) = V\n\t *\n\t * \tvecs(A) = max(1, round_down(V * ncpu(A) / N))\n\t * \tvecs(B) = V - vecs(A)\n\t *\n\t * \tboth N and V are integer, and 2 <= V <= N, suppose\n\t * \tV = N - delta, and 0 <= delta <= N - 2\n\t *\n\t * 2) obviously vecs(A) <= ncpu(A) because:\n\t *\n\t * \tif vecs(A) is 1, then vecs(A) <= ncpu(A) given\n\t * \tncpu(A) >= 1\n\t *\n\t * \totherwise,\n\t * \t\tvecs(A) <= V * ncpu(A) / N <= ncpu(A), given V <= N\n\t *\n\t * 3) prove how vecs(B) <= ncpu(B):\n\t *\n\t * \tif round_down(V * ncpu(A) / N) == 0, vecs(B) won't be\n\t * \tover-allocated, so vecs(B) <= ncpu(B),\n\t *\n\t * \totherwise:\n\t *\n\t * \tvecs(A) =\n\t * \t\tround_down(V * ncpu(A) / N) =\n\t * \t\tround_down((N - delta) * ncpu(A) / N) =\n\t * \t\tround_down((N * ncpu(A) - delta * ncpu(A)) / N)\t >=\n\t * \t\tround_down((N * ncpu(A) - delta * N) / N)\t =\n\t * \t\tcpu(A) - delta\n\t *\n\t * \tthen:\n\t *\n\t * \tvecs(A) - V >= ncpu(A) - delta - V\n\t * \t=>\n\t * \tV - vecs(A) <= V + delta - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= N - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= cpu(B)\n\t *\n\t * For nodes >= 3, it can be thought as one node and another big\n\t * node given that is exactly what this algorithm is implemented,\n\t * and we always re-calculate 'remaining_ncpus' & 'numvecs', and\n\t * finally for each node X: vecs(X) <= ncpu(X).\n\t *\n\t */\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tunsigned nvectors, ncpus;\n\n\t\tif (node_vectors[n].ncpus == UINT_MAX)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(numvecs == 0);\n\n\t\tncpus = node_vectors[n].ncpus;\n\t\tnvectors = max_t(unsigned, 1,\n\t\t\t\t numvecs * ncpus / remaining_ncpus);\n\t\tWARN_ON_ONCE(nvectors > ncpus);\n\n\t\tnode_vectors[n].nvectors = nvectors;\n\n\t\tremaining_ncpus -= ncpus;\n\t\tnumvecs -= nvectors;\n\t}\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void alloc_nodes_vectors(unsigned int numvecs,\n\t\t\t\tcpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *cpu_mask,\n\t\t\t\tconst nodemask_t nodemsk,\n\t\t\t\tstruct cpumask *nmsk,\n\t\t\t\tstruct node_vectors *node_vectors)\n{\n\tunsigned n, remaining_ncpus = 0;\n\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tnode_vectors[n].id = n;\n\t\tnode_vectors[n].ncpus = UINT_MAX;\n\t}\n\n\tfor_each_node_mask(n, nodemsk) {\n\t\tunsigned ncpus;\n\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[n]);\n\t\tncpus = cpumask_weight(nmsk);\n\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\t\tremaining_ncpus += ncpus;\n\t\tnode_vectors[n].ncpus = ncpus;\n\t}\n\n\tnumvecs = min_t(unsigned, remaining_ncpus, numvecs);\n\n\tsort(node_vectors, nr_node_ids, sizeof(node_vectors[0]),\n\t     ncpus_cmp_func, NULL);\n\n\t/*\n\t * Allocate vectors for each node according to the ratio of this\n\t * node's nr_cpus to remaining un-assigned ncpus. 'numvecs' is\n\t * bigger than number of active numa nodes. Always start the\n\t * allocation from the node with minimized nr_cpus.\n\t *\n\t * This way guarantees that each active node gets allocated at\n\t * least one vector, and the theory is simple: over-allocation\n\t * is only done when this node is assigned by one vector, so\n\t * other nodes will be allocated >= 1 vector, since 'numvecs' is\n\t * bigger than number of numa nodes.\n\t *\n\t * One perfect invariant is that number of allocated vectors for\n\t * each node is <= CPU count of this node:\n\t *\n\t * 1) suppose there are two nodes: A and B\n\t * \tncpu(X) is CPU count of node X\n\t * \tvecs(X) is the vector count allocated to node X via this\n\t * \talgorithm\n\t *\n\t * \tncpu(A) <= ncpu(B)\n\t * \tncpu(A) + ncpu(B) = N\n\t * \tvecs(A) + vecs(B) = V\n\t *\n\t * \tvecs(A) = max(1, round_down(V * ncpu(A) / N))\n\t * \tvecs(B) = V - vecs(A)\n\t *\n\t * \tboth N and V are integer, and 2 <= V <= N, suppose\n\t * \tV = N - delta, and 0 <= delta <= N - 2\n\t *\n\t * 2) obviously vecs(A) <= ncpu(A) because:\n\t *\n\t * \tif vecs(A) is 1, then vecs(A) <= ncpu(A) given\n\t * \tncpu(A) >= 1\n\t *\n\t * \totherwise,\n\t * \t\tvecs(A) <= V * ncpu(A) / N <= ncpu(A), given V <= N\n\t *\n\t * 3) prove how vecs(B) <= ncpu(B):\n\t *\n\t * \tif round_down(V * ncpu(A) / N) == 0, vecs(B) won't be\n\t * \tover-allocated, so vecs(B) <= ncpu(B),\n\t *\n\t * \totherwise:\n\t *\n\t * \tvecs(A) =\n\t * \t\tround_down(V * ncpu(A) / N) =\n\t * \t\tround_down((N - delta) * ncpu(A) / N) =\n\t * \t\tround_down((N * ncpu(A) - delta * ncpu(A)) / N)\t >=\n\t * \t\tround_down((N * ncpu(A) - delta * N) / N)\t =\n\t * \t\tcpu(A) - delta\n\t *\n\t * \tthen:\n\t *\n\t * \tvecs(A) - V >= ncpu(A) - delta - V\n\t * \t=>\n\t * \tV - vecs(A) <= V + delta - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= N - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= cpu(B)\n\t *\n\t * For nodes >= 3, it can be thought as one node and another big\n\t * node given that is exactly what this algorithm is implemented,\n\t * and we always re-calculate 'remaining_ncpus' & 'numvecs', and\n\t * finally for each node X: vecs(X) <= ncpu(X).\n\t *\n\t */\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tunsigned nvectors, ncpus;\n\n\t\tif (node_vectors[n].ncpus == UINT_MAX)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(numvecs == 0);\n\n\t\tncpus = node_vectors[n].ncpus;\n\t\tnvectors = max_t(unsigned, 1,\n\t\t\t\t numvecs * ncpus / remaining_ncpus);\n\t\tWARN_ON_ONCE(nvectors > ncpus);\n\n\t\tnode_vectors[n].nvectors = nvectors;\n\n\t\tremaining_ncpus -= ncpus;\n\t\tnumvecs -= nvectors;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "kcalloc",
          "args": [
            "nr_node_ids",
            "sizeof(struct node_vectors)",
            "GFP_KERNEL"
          ],
          "line": 280
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_or",
          "args": [
            "&masks[curvec].mask",
            "&masks[curvec].mask",
            "node_to_cpumask[n]"
          ],
          "line": 272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_node_mask",
          "args": [
            "n",
            "nodemsk"
          ],
          "line": 271
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_nodes_in_cpumask",
          "args": [
            "node_to_cpumask",
            "cpu_mask",
            "&nodemsk"
          ],
          "line": 264
        },
        "resolved": true,
        "details": {
          "function_name": "get_nodes_in_cpumask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
          "lines": "83-96",
          "snippet": "static int get_nodes_in_cpumask(cpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *mask, nodemask_t *nodemsk)\n{\n\tint n, nodes = 0;\n\n\t/* Calculate the number of nodes in the supplied affinity mask */\n\tfor_each_node(n) {\n\t\tif (cpumask_intersects(mask, node_to_cpumask[n])) {\n\t\t\tnode_set(n, *nodemsk);\n\t\t\tnodes++;\n\t\t}\n\t}\n\treturn nodes;\n}",
          "includes": [
            "#include <linux/sort.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int get_nodes_in_cpumask(cpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *mask, nodemask_t *nodemsk)\n{\n\tint n, nodes = 0;\n\n\t/* Calculate the number of nodes in the supplied affinity mask */\n\tfor_each_node(n) {\n\t\tif (cpumask_intersects(mask, node_to_cpumask[n])) {\n\t\t\tnode_set(n, *nodemsk);\n\t\t\tnodes++;\n\t\t}\n\t}\n\treturn nodes;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "cpu_mask"
          ],
          "line": 261
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int __irq_build_affinity_masks(unsigned int startvec,\n\t\t\t\t      unsigned int numvecs,\n\t\t\t\t      unsigned int firstvec,\n\t\t\t\t      cpumask_var_t *node_to_cpumask,\n\t\t\t\t      const struct cpumask *cpu_mask,\n\t\t\t\t      struct cpumask *nmsk,\n\t\t\t\t      struct irq_affinity_desc *masks)\n{\n\tunsigned int i, n, nodes, cpus_per_vec, extra_vecs, done = 0;\n\tunsigned int last_affv = firstvec + numvecs;\n\tunsigned int curvec = startvec;\n\tnodemask_t nodemsk = NODE_MASK_NONE;\n\tstruct node_vectors *node_vectors;\n\n\tif (!cpumask_weight(cpu_mask))\n\t\treturn 0;\n\n\tnodes = get_nodes_in_cpumask(node_to_cpumask, cpu_mask, &nodemsk);\n\n\t/*\n\t * If the number of nodes in the mask is greater than or equal the\n\t * number of vectors we just spread the vectors across the nodes.\n\t */\n\tif (numvecs <= nodes) {\n\t\tfor_each_node_mask(n, nodemsk) {\n\t\t\tcpumask_or(&masks[curvec].mask, &masks[curvec].mask,\n\t\t\t\t   node_to_cpumask[n]);\n\t\t\tif (++curvec == last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t}\n\t\treturn numvecs;\n\t}\n\n\tnode_vectors = kcalloc(nr_node_ids,\n\t\t\t       sizeof(struct node_vectors),\n\t\t\t       GFP_KERNEL);\n\tif (!node_vectors)\n\t\treturn -ENOMEM;\n\n\t/* allocate vector number for each node */\n\talloc_nodes_vectors(numvecs, node_to_cpumask, cpu_mask,\n\t\t\t    nodemsk, nmsk, node_vectors);\n\n\tfor (i = 0; i < nr_node_ids; i++) {\n\t\tunsigned int ncpus, v;\n\t\tstruct node_vectors *nv = &node_vectors[i];\n\n\t\tif (nv->nvectors == UINT_MAX)\n\t\t\tcontinue;\n\n\t\t/* Get the cpus on this node which are in the mask */\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[nv->id]);\n\t\tncpus = cpumask_weight(nmsk);\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(nv->nvectors > ncpus);\n\n\t\t/* Account for rounding errors */\n\t\textra_vecs = ncpus - nv->nvectors * (ncpus / nv->nvectors);\n\n\t\t/* Spread allocated vectors on CPUs of the current node */\n\t\tfor (v = 0; v < nv->nvectors; v++, curvec++) {\n\t\t\tcpus_per_vec = ncpus / nv->nvectors;\n\n\t\t\t/* Account for extra vectors to compensate rounding errors */\n\t\t\tif (extra_vecs) {\n\t\t\t\tcpus_per_vec++;\n\t\t\t\t--extra_vecs;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * wrapping has to be considered given 'startvec'\n\t\t\t * may start anywhere\n\t\t\t */\n\t\t\tif (curvec >= last_affv)\n\t\t\t\tcurvec = firstvec;\n\t\t\tirq_spread_init_one(&masks[curvec].mask, nmsk,\n\t\t\t\t\t\tcpus_per_vec);\n\t\t}\n\t\tdone += nv->nvectors;\n\t}\n\tkfree(node_vectors);\n\treturn done;\n}"
  },
  {
    "function_name": "alloc_nodes_vectors",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "128-245",
    "snippet": "static void alloc_nodes_vectors(unsigned int numvecs,\n\t\t\t\tcpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *cpu_mask,\n\t\t\t\tconst nodemask_t nodemsk,\n\t\t\t\tstruct cpumask *nmsk,\n\t\t\t\tstruct node_vectors *node_vectors)\n{\n\tunsigned n, remaining_ncpus = 0;\n\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tnode_vectors[n].id = n;\n\t\tnode_vectors[n].ncpus = UINT_MAX;\n\t}\n\n\tfor_each_node_mask(n, nodemsk) {\n\t\tunsigned ncpus;\n\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[n]);\n\t\tncpus = cpumask_weight(nmsk);\n\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\t\tremaining_ncpus += ncpus;\n\t\tnode_vectors[n].ncpus = ncpus;\n\t}\n\n\tnumvecs = min_t(unsigned, remaining_ncpus, numvecs);\n\n\tsort(node_vectors, nr_node_ids, sizeof(node_vectors[0]),\n\t     ncpus_cmp_func, NULL);\n\n\t/*\n\t * Allocate vectors for each node according to the ratio of this\n\t * node's nr_cpus to remaining un-assigned ncpus. 'numvecs' is\n\t * bigger than number of active numa nodes. Always start the\n\t * allocation from the node with minimized nr_cpus.\n\t *\n\t * This way guarantees that each active node gets allocated at\n\t * least one vector, and the theory is simple: over-allocation\n\t * is only done when this node is assigned by one vector, so\n\t * other nodes will be allocated >= 1 vector, since 'numvecs' is\n\t * bigger than number of numa nodes.\n\t *\n\t * One perfect invariant is that number of allocated vectors for\n\t * each node is <= CPU count of this node:\n\t *\n\t * 1) suppose there are two nodes: A and B\n\t * \tncpu(X) is CPU count of node X\n\t * \tvecs(X) is the vector count allocated to node X via this\n\t * \talgorithm\n\t *\n\t * \tncpu(A) <= ncpu(B)\n\t * \tncpu(A) + ncpu(B) = N\n\t * \tvecs(A) + vecs(B) = V\n\t *\n\t * \tvecs(A) = max(1, round_down(V * ncpu(A) / N))\n\t * \tvecs(B) = V - vecs(A)\n\t *\n\t * \tboth N and V are integer, and 2 <= V <= N, suppose\n\t * \tV = N - delta, and 0 <= delta <= N - 2\n\t *\n\t * 2) obviously vecs(A) <= ncpu(A) because:\n\t *\n\t * \tif vecs(A) is 1, then vecs(A) <= ncpu(A) given\n\t * \tncpu(A) >= 1\n\t *\n\t * \totherwise,\n\t * \t\tvecs(A) <= V * ncpu(A) / N <= ncpu(A), given V <= N\n\t *\n\t * 3) prove how vecs(B) <= ncpu(B):\n\t *\n\t * \tif round_down(V * ncpu(A) / N) == 0, vecs(B) won't be\n\t * \tover-allocated, so vecs(B) <= ncpu(B),\n\t *\n\t * \totherwise:\n\t *\n\t * \tvecs(A) =\n\t * \t\tround_down(V * ncpu(A) / N) =\n\t * \t\tround_down((N - delta) * ncpu(A) / N) =\n\t * \t\tround_down((N * ncpu(A) - delta * ncpu(A)) / N)\t >=\n\t * \t\tround_down((N * ncpu(A) - delta * N) / N)\t =\n\t * \t\tcpu(A) - delta\n\t *\n\t * \tthen:\n\t *\n\t * \tvecs(A) - V >= ncpu(A) - delta - V\n\t * \t=>\n\t * \tV - vecs(A) <= V + delta - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= N - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= cpu(B)\n\t *\n\t * For nodes >= 3, it can be thought as one node and another big\n\t * node given that is exactly what this algorithm is implemented,\n\t * and we always re-calculate 'remaining_ncpus' & 'numvecs', and\n\t * finally for each node X: vecs(X) <= ncpu(X).\n\t *\n\t */\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tunsigned nvectors, ncpus;\n\n\t\tif (node_vectors[n].ncpus == UINT_MAX)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(numvecs == 0);\n\n\t\tncpus = node_vectors[n].ncpus;\n\t\tnvectors = max_t(unsigned, 1,\n\t\t\t\t numvecs * ncpus / remaining_ncpus);\n\t\tWARN_ON_ONCE(nvectors > ncpus);\n\n\t\tnode_vectors[n].nvectors = nvectors;\n\n\t\tremaining_ncpus -= ncpus;\n\t\tnumvecs -= nvectors;\n\t}\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "nvectors > ncpus"
          ],
          "line": 238
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "max_t",
          "args": [
            "unsigned",
            "1",
            "numvecs * ncpus / remaining_ncpus"
          ],
          "line": 236
        },
        "resolved": true,
        "details": {
          "function_name": "update_max_tr_single",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace.c",
          "lines": "1831-1865",
          "snippet": "void\nupdate_max_tr_single(struct trace_array *tr, struct task_struct *tsk, int cpu)\n{\n\tint ret;\n\n\tif (tr->stop_count)\n\t\treturn;\n\n\tWARN_ON_ONCE(!irqs_disabled());\n\tif (!tr->allocated_snapshot) {\n\t\t/* Only the nop tracer should hit this when disabling */\n\t\tWARN_ON_ONCE(tr->current_trace != &nop_trace);\n\t\treturn;\n\t}\n\n\tarch_spin_lock(&tr->max_lock);\n\n\tret = ring_buffer_swap_cpu(tr->max_buffer.buffer, tr->array_buffer.buffer, cpu);\n\n\tif (ret == -EBUSY) {\n\t\t/*\n\t\t * We failed to swap the buffer due to a commit taking\n\t\t * place on this CPU. We fail to record, but we reset\n\t\t * the max trace buffer (no one writes directly to it)\n\t\t * and flag that it failed.\n\t\t */\n\t\ttrace_array_printk_buf(tr->max_buffer.buffer, _THIS_IP_,\n\t\t\t\"Failed to swap buffers due to commit in progress\\n\");\n\t}\n\n\tWARN_ON_ONCE(ret && ret != -EAGAIN && ret != -EBUSY);\n\n\t__update_max_tr(tr, tsk, cpu);\n\tarch_spin_unlock(&tr->max_lock);\n}",
          "includes": [
            "#include \"trace_selftest.c\"",
            "#include \"trace_output.h\"",
            "#include \"trace.h\"",
            "#include <linux/workqueue.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/fsnotify.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace.h>",
            "#include <linux/fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/poll.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/mount.h>",
            "#include <linux/string.h>",
            "#include <linux/kdebug.h>",
            "#include <linux/splice.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/linkage.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/notifier.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/writeback.h>",
            "#include <linux/stacktrace.h>",
            "#include <generated/utsrelease.h>",
            "#include <linux/ring_buffer.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct",
            "static void\ncreate_trace_option_files(struct trace_array *tr, struct tracer *tracer);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_selftest.c\"\n#include \"trace_output.h\"\n#include \"trace.h\"\n#include <linux/workqueue.h>\n#include <linux/irq_work.h>\n#include <linux/fsnotify.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/clock.h>\n#include <linux/trace.h>\n#include <linux/fs.h>\n#include <linux/nmi.h>\n#include <linux/poll.h>\n#include <linux/panic_notifier.h>\n#include <linux/init.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/rwsem.h>\n#include <linux/mount.h>\n#include <linux/string.h>\n#include <linux/kdebug.h>\n#include <linux/splice.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/ftrace.h>\n#include <linux/vmalloc.h>\n#include <linux/uaccess.h>\n#include <linux/linkage.h>\n#include <linux/hardirq.h>\n#include <linux/pagemap.h>\n#include <linux/tracefs.h>\n#include <linux/debugfs.h>\n#include <linux/irqflags.h>\n#include <linux/notifier.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/writeback.h>\n#include <linux/stacktrace.h>\n#include <generated/utsrelease.h>\n#include <linux/ring_buffer.h>\n\nstatic __always_inline struct;\nstatic void\ncreate_trace_option_files(struct trace_array *tr, struct tracer *tracer);\n\nvoid\nupdate_max_tr_single(struct trace_array *tr, struct task_struct *tsk, int cpu)\n{\n\tint ret;\n\n\tif (tr->stop_count)\n\t\treturn;\n\n\tWARN_ON_ONCE(!irqs_disabled());\n\tif (!tr->allocated_snapshot) {\n\t\t/* Only the nop tracer should hit this when disabling */\n\t\tWARN_ON_ONCE(tr->current_trace != &nop_trace);\n\t\treturn;\n\t}\n\n\tarch_spin_lock(&tr->max_lock);\n\n\tret = ring_buffer_swap_cpu(tr->max_buffer.buffer, tr->array_buffer.buffer, cpu);\n\n\tif (ret == -EBUSY) {\n\t\t/*\n\t\t * We failed to swap the buffer due to a commit taking\n\t\t * place on this CPU. We fail to record, but we reset\n\t\t * the max trace buffer (no one writes directly to it)\n\t\t * and flag that it failed.\n\t\t */\n\t\ttrace_array_printk_buf(tr->max_buffer.buffer, _THIS_IP_,\n\t\t\t\"Failed to swap buffers due to commit in progress\\n\");\n\t}\n\n\tWARN_ON_ONCE(ret && ret != -EAGAIN && ret != -EBUSY);\n\n\t__update_max_tr(tr, tsk, cpu);\n\tarch_spin_unlock(&tr->max_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "numvecs == 0"
          ],
          "line": 233
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sort",
          "args": [
            "node_vectors",
            "nr_node_ids",
            "sizeof(node_vectors[0])",
            "ncpus_cmp_func",
            "NULL"
          ],
          "line": 156
        },
        "resolved": true,
        "details": {
          "function_name": "sort_secondary",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/tracing_map.c",
          "lines": "998-1043",
          "snippet": "static void sort_secondary(struct tracing_map *map,\n\t\t\t   const struct tracing_map_sort_entry **entries,\n\t\t\t   unsigned int n_entries,\n\t\t\t   struct tracing_map_sort_key *primary_key,\n\t\t\t   struct tracing_map_sort_key *secondary_key)\n{\n\tint (*primary_fn)(const void *, const void *);\n\tint (*secondary_fn)(const void *, const void *);\n\tunsigned i, start = 0, n_sub = 1;\n\n\tif (is_key(map, primary_key->field_idx))\n\t\tprimary_fn = cmp_entries_key;\n\telse\n\t\tprimary_fn = cmp_entries_sum;\n\n\tif (is_key(map, secondary_key->field_idx))\n\t\tsecondary_fn = cmp_entries_key;\n\telse\n\t\tsecondary_fn = cmp_entries_sum;\n\n\tfor (i = 0; i < n_entries - 1; i++) {\n\t\tconst struct tracing_map_sort_entry **a = &entries[i];\n\t\tconst struct tracing_map_sort_entry **b = &entries[i + 1];\n\n\t\tif (primary_fn(a, b) == 0) {\n\t\t\tn_sub++;\n\t\t\tif (i < n_entries - 2)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (n_sub < 2) {\n\t\t\tstart = i + 1;\n\t\t\tn_sub = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tset_sort_key(map, secondary_key);\n\t\tsort(&entries[start], n_sub,\n\t\t     sizeof(struct tracing_map_sort_entry *),\n\t\t     (int (*)(const void *, const void *))secondary_fn, NULL);\n\t\tset_sort_key(map, primary_key);\n\n\t\tstart = i + 1;\n\t\tn_sub = 1;\n\t}\n}",
          "includes": [
            "#include \"trace.h\"",
            "#include \"tracing_map.h\"",
            "#include <linux/kmemleak.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/jhash.h>",
            "#include <linux/vmalloc.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace.h\"\n#include \"tracing_map.h\"\n#include <linux/kmemleak.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/jhash.h>\n#include <linux/vmalloc.h>\n\nstatic void sort_secondary(struct tracing_map *map,\n\t\t\t   const struct tracing_map_sort_entry **entries,\n\t\t\t   unsigned int n_entries,\n\t\t\t   struct tracing_map_sort_key *primary_key,\n\t\t\t   struct tracing_map_sort_key *secondary_key)\n{\n\tint (*primary_fn)(const void *, const void *);\n\tint (*secondary_fn)(const void *, const void *);\n\tunsigned i, start = 0, n_sub = 1;\n\n\tif (is_key(map, primary_key->field_idx))\n\t\tprimary_fn = cmp_entries_key;\n\telse\n\t\tprimary_fn = cmp_entries_sum;\n\n\tif (is_key(map, secondary_key->field_idx))\n\t\tsecondary_fn = cmp_entries_key;\n\telse\n\t\tsecondary_fn = cmp_entries_sum;\n\n\tfor (i = 0; i < n_entries - 1; i++) {\n\t\tconst struct tracing_map_sort_entry **a = &entries[i];\n\t\tconst struct tracing_map_sort_entry **b = &entries[i + 1];\n\n\t\tif (primary_fn(a, b) == 0) {\n\t\t\tn_sub++;\n\t\t\tif (i < n_entries - 2)\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (n_sub < 2) {\n\t\t\tstart = i + 1;\n\t\t\tn_sub = 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\tset_sort_key(map, secondary_key);\n\t\tsort(&entries[start], n_sub,\n\t\t     sizeof(struct tracing_map_sort_entry *),\n\t\t     (int (*)(const void *, const void *))secondary_fn, NULL);\n\t\tset_sort_key(map, primary_key);\n\n\t\tstart = i + 1;\n\t\tn_sub = 1;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "min_t",
          "args": [
            "unsigned",
            "remaining_ncpus",
            "numvecs"
          ],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "nmsk"
          ],
          "line": 146
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_and",
          "args": [
            "nmsk",
            "cpu_mask",
            "node_to_cpumask[n]"
          ],
          "line": 145
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_node_mask",
          "args": [
            "n",
            "nodemsk"
          ],
          "line": 142
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void alloc_nodes_vectors(unsigned int numvecs,\n\t\t\t\tcpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *cpu_mask,\n\t\t\t\tconst nodemask_t nodemsk,\n\t\t\t\tstruct cpumask *nmsk,\n\t\t\t\tstruct node_vectors *node_vectors)\n{\n\tunsigned n, remaining_ncpus = 0;\n\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tnode_vectors[n].id = n;\n\t\tnode_vectors[n].ncpus = UINT_MAX;\n\t}\n\n\tfor_each_node_mask(n, nodemsk) {\n\t\tunsigned ncpus;\n\n\t\tcpumask_and(nmsk, cpu_mask, node_to_cpumask[n]);\n\t\tncpus = cpumask_weight(nmsk);\n\n\t\tif (!ncpus)\n\t\t\tcontinue;\n\t\tremaining_ncpus += ncpus;\n\t\tnode_vectors[n].ncpus = ncpus;\n\t}\n\n\tnumvecs = min_t(unsigned, remaining_ncpus, numvecs);\n\n\tsort(node_vectors, nr_node_ids, sizeof(node_vectors[0]),\n\t     ncpus_cmp_func, NULL);\n\n\t/*\n\t * Allocate vectors for each node according to the ratio of this\n\t * node's nr_cpus to remaining un-assigned ncpus. 'numvecs' is\n\t * bigger than number of active numa nodes. Always start the\n\t * allocation from the node with minimized nr_cpus.\n\t *\n\t * This way guarantees that each active node gets allocated at\n\t * least one vector, and the theory is simple: over-allocation\n\t * is only done when this node is assigned by one vector, so\n\t * other nodes will be allocated >= 1 vector, since 'numvecs' is\n\t * bigger than number of numa nodes.\n\t *\n\t * One perfect invariant is that number of allocated vectors for\n\t * each node is <= CPU count of this node:\n\t *\n\t * 1) suppose there are two nodes: A and B\n\t * \tncpu(X) is CPU count of node X\n\t * \tvecs(X) is the vector count allocated to node X via this\n\t * \talgorithm\n\t *\n\t * \tncpu(A) <= ncpu(B)\n\t * \tncpu(A) + ncpu(B) = N\n\t * \tvecs(A) + vecs(B) = V\n\t *\n\t * \tvecs(A) = max(1, round_down(V * ncpu(A) / N))\n\t * \tvecs(B) = V - vecs(A)\n\t *\n\t * \tboth N and V are integer, and 2 <= V <= N, suppose\n\t * \tV = N - delta, and 0 <= delta <= N - 2\n\t *\n\t * 2) obviously vecs(A) <= ncpu(A) because:\n\t *\n\t * \tif vecs(A) is 1, then vecs(A) <= ncpu(A) given\n\t * \tncpu(A) >= 1\n\t *\n\t * \totherwise,\n\t * \t\tvecs(A) <= V * ncpu(A) / N <= ncpu(A), given V <= N\n\t *\n\t * 3) prove how vecs(B) <= ncpu(B):\n\t *\n\t * \tif round_down(V * ncpu(A) / N) == 0, vecs(B) won't be\n\t * \tover-allocated, so vecs(B) <= ncpu(B),\n\t *\n\t * \totherwise:\n\t *\n\t * \tvecs(A) =\n\t * \t\tround_down(V * ncpu(A) / N) =\n\t * \t\tround_down((N - delta) * ncpu(A) / N) =\n\t * \t\tround_down((N * ncpu(A) - delta * ncpu(A)) / N)\t >=\n\t * \t\tround_down((N * ncpu(A) - delta * N) / N)\t =\n\t * \t\tcpu(A) - delta\n\t *\n\t * \tthen:\n\t *\n\t * \tvecs(A) - V >= ncpu(A) - delta - V\n\t * \t=>\n\t * \tV - vecs(A) <= V + delta - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= N - ncpu(A)\n\t * \t=>\n\t * \tvecs(B) <= cpu(B)\n\t *\n\t * For nodes >= 3, it can be thought as one node and another big\n\t * node given that is exactly what this algorithm is implemented,\n\t * and we always re-calculate 'remaining_ncpus' & 'numvecs', and\n\t * finally for each node X: vecs(X) <= ncpu(X).\n\t *\n\t */\n\tfor (n = 0; n < nr_node_ids; n++) {\n\t\tunsigned nvectors, ncpus;\n\n\t\tif (node_vectors[n].ncpus == UINT_MAX)\n\t\t\tcontinue;\n\n\t\tWARN_ON_ONCE(numvecs == 0);\n\n\t\tncpus = node_vectors[n].ncpus;\n\t\tnvectors = max_t(unsigned, 1,\n\t\t\t\t numvecs * ncpus / remaining_ncpus);\n\t\tWARN_ON_ONCE(nvectors > ncpus);\n\n\t\tnode_vectors[n].nvectors = nvectors;\n\n\t\tremaining_ncpus -= ncpus;\n\t\tnumvecs -= nvectors;\n\t}\n}"
  },
  {
    "function_name": "ncpus_cmp_func",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "107-113",
    "snippet": "static int ncpus_cmp_func(const void *l, const void *r)\n{\n\tconst struct node_vectors *ln = l;\n\tconst struct node_vectors *rn = r;\n\n\treturn ln->ncpus - rn->ncpus;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int ncpus_cmp_func(const void *l, const void *r)\n{\n\tconst struct node_vectors *ln = l;\n\tconst struct node_vectors *rn = r;\n\n\treturn ln->ncpus - rn->ncpus;\n}"
  },
  {
    "function_name": "get_nodes_in_cpumask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "83-96",
    "snippet": "static int get_nodes_in_cpumask(cpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *mask, nodemask_t *nodemsk)\n{\n\tint n, nodes = 0;\n\n\t/* Calculate the number of nodes in the supplied affinity mask */\n\tfor_each_node(n) {\n\t\tif (cpumask_intersects(mask, node_to_cpumask[n])) {\n\t\t\tnode_set(n, *nodemsk);\n\t\t\tnodes++;\n\t\t}\n\t}\n\treturn nodes;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "node_set",
          "args": [
            "n",
            "*nodemsk"
          ],
          "line": 91
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_intersects",
          "args": [
            "mask",
            "node_to_cpumask[n]"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic int get_nodes_in_cpumask(cpumask_var_t *node_to_cpumask,\n\t\t\t\tconst struct cpumask *mask, nodemask_t *nodemsk)\n{\n\tint n, nodes = 0;\n\n\t/* Calculate the number of nodes in the supplied affinity mask */\n\tfor_each_node(n) {\n\t\tif (cpumask_intersects(mask, node_to_cpumask[n])) {\n\t\t\tnode_set(n, *nodemsk);\n\t\t\tnodes++;\n\t\t}\n\t}\n\treturn nodes;\n}"
  },
  {
    "function_name": "build_node_to_cpumask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "75-81",
    "snippet": "static void build_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tcpumask_set_cpu(cpu, masks[cpu_to_node(cpu)]);\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 80
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void build_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tcpumask_set_cpu(cpu, masks[cpu_to_node(cpu)]);\n}"
  },
  {
    "function_name": "free_node_to_cpumask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "66-73",
    "snippet": "static void free_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint node;\n\n\tfor (node = 0; node < nr_node_ids; node++)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "masks"
          ],
          "line": 72
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "masks[node]"
          ],
          "line": 71
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void free_node_to_cpumask(cpumask_var_t *masks)\n{\n\tint node;\n\n\tfor (node = 0; node < nr_node_ids; node++)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n}"
  },
  {
    "function_name": "alloc_node_to_cpumask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "43-64",
    "snippet": "static cpumask_var_t *alloc_node_to_cpumask(void)\n{\n\tcpumask_var_t *masks;\n\tint node;\n\n\tmasks = kcalloc(nr_node_ids, sizeof(cpumask_var_t), GFP_KERNEL);\n\tif (!masks)\n\t\treturn NULL;\n\n\tfor (node = 0; node < nr_node_ids; node++) {\n\t\tif (!zalloc_cpumask_var(&masks[node], GFP_KERNEL))\n\t\t\tgoto out_unwind;\n\t}\n\n\treturn masks;\n\nout_unwind:\n\twhile (--node >= 0)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n\treturn NULL;\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "masks"
          ],
          "line": 62
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "masks[node]"
          ],
          "line": 61
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&masks[node]",
            "GFP_KERNEL"
          ],
          "line": 53
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kcalloc",
          "args": [
            "nr_node_ids",
            "sizeof(cpumask_var_t)",
            "GFP_KERNEL"
          ],
          "line": 48
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic cpumask_var_t *alloc_node_to_cpumask(void)\n{\n\tcpumask_var_t *masks;\n\tint node;\n\n\tmasks = kcalloc(nr_node_ids, sizeof(cpumask_var_t), GFP_KERNEL);\n\tif (!masks)\n\t\treturn NULL;\n\n\tfor (node = 0; node < nr_node_ids; node++) {\n\t\tif (!zalloc_cpumask_var(&masks[node], GFP_KERNEL))\n\t\t\tgoto out_unwind;\n\t}\n\n\treturn masks;\n\nout_unwind:\n\twhile (--node >= 0)\n\t\tfree_cpumask_var(masks[node]);\n\tkfree(masks);\n\treturn NULL;\n}"
  },
  {
    "function_name": "irq_spread_init_one",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq/affinity.c",
    "lines": "12-41",
    "snippet": "static void irq_spread_init_one(struct cpumask *irqmsk, struct cpumask *nmsk,\n\t\t\t\tunsigned int cpus_per_vec)\n{\n\tconst struct cpumask *siblmsk;\n\tint cpu, sibl;\n\n\tfor ( ; cpus_per_vec > 0; ) {\n\t\tcpu = cpumask_first(nmsk);\n\n\t\t/* Should not happen, but I'm too lazy to think about it */\n\t\tif (cpu >= nr_cpu_ids)\n\t\t\treturn;\n\n\t\tcpumask_clear_cpu(cpu, nmsk);\n\t\tcpumask_set_cpu(cpu, irqmsk);\n\t\tcpus_per_vec--;\n\n\t\t/* If the cpu has siblings, use them first */\n\t\tsiblmsk = topology_sibling_cpumask(cpu);\n\t\tfor (sibl = -1; cpus_per_vec > 0; ) {\n\t\t\tsibl = cpumask_next(sibl, siblmsk);\n\t\t\tif (sibl >= nr_cpu_ids)\n\t\t\t\tbreak;\n\t\t\tif (!cpumask_test_and_clear_cpu(sibl, nmsk))\n\t\t\t\tcontinue;\n\t\t\tcpumask_set_cpu(sibl, irqmsk);\n\t\t\tcpus_per_vec--;\n\t\t}\n\t}\n}",
    "includes": [
      "#include <linux/sort.h>",
      "#include <linux/cpu.h>",
      "#include <linux/slab.h>",
      "#include <linux/kernel.h>",
      "#include <linux/interrupt.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "sibl",
            "irqmsk"
          ],
          "line": 37
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_and_clear_cpu",
          "args": [
            "sibl",
            "nmsk"
          ],
          "line": 35
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_next",
          "args": [
            "sibl",
            "siblmsk"
          ],
          "line": 32
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "topology_sibling_cpumask",
          "args": [
            "cpu"
          ],
          "line": 30
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "cpu",
            "irqmsk"
          ],
          "line": 26
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_clear_cpu",
          "args": [
            "cpu",
            "nmsk"
          ],
          "line": 25
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_first",
          "args": [
            "nmsk"
          ],
          "line": 19
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/sort.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nstatic void irq_spread_init_one(struct cpumask *irqmsk, struct cpumask *nmsk,\n\t\t\t\tunsigned int cpus_per_vec)\n{\n\tconst struct cpumask *siblmsk;\n\tint cpu, sibl;\n\n\tfor ( ; cpus_per_vec > 0; ) {\n\t\tcpu = cpumask_first(nmsk);\n\n\t\t/* Should not happen, but I'm too lazy to think about it */\n\t\tif (cpu >= nr_cpu_ids)\n\t\t\treturn;\n\n\t\tcpumask_clear_cpu(cpu, nmsk);\n\t\tcpumask_set_cpu(cpu, irqmsk);\n\t\tcpus_per_vec--;\n\n\t\t/* If the cpu has siblings, use them first */\n\t\tsiblmsk = topology_sibling_cpumask(cpu);\n\t\tfor (sibl = -1; cpus_per_vec > 0; ) {\n\t\t\tsibl = cpumask_next(sibl, siblmsk);\n\t\t\tif (sibl >= nr_cpu_ids)\n\t\t\t\tbreak;\n\t\t\tif (!cpumask_test_and_clear_cpu(sibl, nmsk))\n\t\t\t\tcontinue;\n\t\t\tcpumask_set_cpu(sibl, irqmsk);\n\t\t\tcpus_per_vec--;\n\t\t}\n\t}\n}"
  }
]