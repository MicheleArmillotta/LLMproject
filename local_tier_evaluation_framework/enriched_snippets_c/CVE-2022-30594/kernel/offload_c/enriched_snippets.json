[
  {
    "function_name": "bpf_offload_dev_priv",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "708-711",
    "snippet": "void *bpf_offload_dev_priv(struct bpf_offload_dev *offdev)\n{\n\treturn offdev->priv;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nvoid *bpf_offload_dev_priv(struct bpf_offload_dev *offdev)\n{\n\treturn offdev->priv;\n}"
  },
  {
    "function_name": "bpf_offload_dev_destroy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "701-705",
    "snippet": "void bpf_offload_dev_destroy(struct bpf_offload_dev *offdev)\n{\n\tWARN_ON(!list_empty(&offdev->netdevs));\n\tkfree(offdev);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "offdev"
          ],
          "line": 704
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!list_empty(&offdev->netdevs)"
          ],
          "line": 703
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&offdev->netdevs"
          ],
          "line": 703
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nvoid bpf_offload_dev_destroy(struct bpf_offload_dev *offdev)\n{\n\tWARN_ON(!list_empty(&offdev->netdevs));\n\tkfree(offdev);\n}"
  },
  {
    "function_name": "bpf_offload_dev_create",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "672-698",
    "snippet": "struct bpf_offload_dev *\nbpf_offload_dev_create(const struct bpf_prog_offload_ops *ops, void *priv)\n{\n\tstruct bpf_offload_dev *offdev;\n\tint err;\n\n\tdown_write(&bpf_devs_lock);\n\tif (!offdevs_inited) {\n\t\terr = rhashtable_init(&offdevs, &offdevs_params);\n\t\tif (err) {\n\t\t\tup_write(&bpf_devs_lock);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\t\toffdevs_inited = true;\n\t}\n\tup_write(&bpf_devs_lock);\n\n\toffdev = kzalloc(sizeof(*offdev), GFP_KERNEL);\n\tif (!offdev)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\toffdev->ops = ops;\n\toffdev->priv = priv;\n\tINIT_LIST_HEAD(&offdev->netdevs);\n\n\treturn offdev;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);",
      "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
      "static struct rhashtable offdevs;",
      "static bool offdevs_inited;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&offdev->netdevs"
          ],
          "line": 695
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 691
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*offdev)",
            "GFP_KERNEL"
          ],
          "line": 689
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 687
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 683
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rhashtable_init",
          "args": [
            "&offdevs",
            "&offdevs_params"
          ],
          "line": 680
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 678
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\nstatic bool offdevs_inited;\n\nstruct bpf_offload_dev *\nbpf_offload_dev_create(const struct bpf_prog_offload_ops *ops, void *priv)\n{\n\tstruct bpf_offload_dev *offdev;\n\tint err;\n\n\tdown_write(&bpf_devs_lock);\n\tif (!offdevs_inited) {\n\t\terr = rhashtable_init(&offdevs, &offdevs_params);\n\t\tif (err) {\n\t\t\tup_write(&bpf_devs_lock);\n\t\t\treturn ERR_PTR(err);\n\t\t}\n\t\toffdevs_inited = true;\n\t}\n\tup_write(&bpf_devs_lock);\n\n\toffdev = kzalloc(sizeof(*offdev), GFP_KERNEL);\n\tif (!offdev)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\toffdev->ops = ops;\n\toffdev->priv = priv;\n\tINIT_LIST_HEAD(&offdev->netdevs);\n\n\treturn offdev;\n}"
  },
  {
    "function_name": "bpf_offload_dev_netdev_unregister",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "628-669",
    "snippet": "void bpf_offload_dev_netdev_unregister(struct bpf_offload_dev *offdev,\n\t\t\t\t       struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev, *altdev;\n\tstruct bpf_offloaded_map *offmap, *mtmp;\n\tstruct bpf_prog_offload *offload, *ptmp;\n\n\tASSERT_RTNL();\n\n\tdown_write(&bpf_devs_lock);\n\tondev = rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n\tif (WARN_ON(!ondev))\n\t\tgoto unlock;\n\n\tWARN_ON(rhashtable_remove_fast(&offdevs, &ondev->l, offdevs_params));\n\tlist_del(&ondev->offdev_netdevs);\n\n\t/* Try to move the objects to another netdev of the device */\n\taltdev = list_first_entry_or_null(&offdev->netdevs,\n\t\t\t\t\t  struct bpf_offload_netdev,\n\t\t\t\t\t  offdev_netdevs);\n\tif (altdev) {\n\t\tlist_for_each_entry(offload, &ondev->progs, offloads)\n\t\t\toffload->netdev = altdev->netdev;\n\t\tlist_splice_init(&ondev->progs, &altdev->progs);\n\n\t\tlist_for_each_entry(offmap, &ondev->maps, offloads)\n\t\t\toffmap->netdev = altdev->netdev;\n\t\tlist_splice_init(&ondev->maps, &altdev->maps);\n\t} else {\n\t\tlist_for_each_entry_safe(offload, ptmp, &ondev->progs, offloads)\n\t\t\t__bpf_prog_offload_destroy(offload->prog);\n\t\tlist_for_each_entry_safe(offmap, mtmp, &ondev->maps, offloads)\n\t\t\t__bpf_map_offload_destroy(offmap);\n\t}\n\n\tWARN_ON(!list_empty(&ondev->progs));\n\tWARN_ON(!list_empty(&ondev->maps));\n\tkfree(ondev);\nunlock:\n\tup_write(&bpf_devs_lock);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);",
      "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
      "static struct rhashtable offdevs;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 668
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "ondev"
          ],
          "line": 666
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!list_empty(&ondev->maps)"
          ],
          "line": 665
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&ondev->maps"
          ],
          "line": 665
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!list_empty(&ondev->progs)"
          ],
          "line": 664
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__bpf_map_offload_destroy",
          "args": [
            "offmap"
          ],
          "line": 661
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_map_offload_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "411-418",
          "snippet": "static void __bpf_map_offload_destroy(struct bpf_offloaded_map *offmap)\n{\n\tWARN_ON(bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE));\n\t/* Make sure BPF_MAP_GET_NEXT_ID can't find this dead map */\n\tbpf_map_free_id(&offmap->map, true);\n\tlist_del_init(&offmap->offloads);\n\toffmap->netdev = NULL;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic void __bpf_map_offload_destroy(struct bpf_offloaded_map *offmap)\n{\n\tWARN_ON(bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE));\n\t/* Make sure BPF_MAP_GET_NEXT_ID can't find this dead map */\n\tbpf_map_free_id(&offmap->map, true);\n\tlist_del_init(&offmap->offloads);\n\toffmap->netdev = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "offmap",
            "mtmp",
            "&ondev->maps",
            "offloads"
          ],
          "line": 660
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__bpf_prog_offload_destroy",
          "args": [
            "offload->prog"
          ],
          "line": 659
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_prog_offload_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "212-225",
          "snippet": "static void __bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload = prog->aux->offload;\n\n\tif (offload->dev_state)\n\t\toffload->offdev->ops->destroy(prog);\n\n\t/* Make sure BPF_PROG_GET_NEXT_ID can't find this dead program */\n\tbpf_prog_free_id(prog, true);\n\n\tlist_del_init(&offload->offloads);\n\tkfree(offload);\n\tprog->aux->offload = NULL;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic void __bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload = prog->aux->offload;\n\n\tif (offload->dev_state)\n\t\toffload->offdev->ops->destroy(prog);\n\n\t/* Make sure BPF_PROG_GET_NEXT_ID can't find this dead program */\n\tbpf_prog_free_id(prog, true);\n\n\tlist_del_init(&offload->offloads);\n\tkfree(offload);\n\tprog->aux->offload = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "offload",
            "ptmp",
            "&ondev->progs",
            "offloads"
          ],
          "line": 658
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_splice_init",
          "args": [
            "&ondev->maps",
            "&altdev->maps"
          ],
          "line": 656
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "offmap",
            "&ondev->maps",
            "offloads"
          ],
          "line": 654
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_splice_init",
          "args": [
            "&ondev->progs",
            "&altdev->progs"
          ],
          "line": 652
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry",
          "args": [
            "offload",
            "&ondev->progs",
            "offloads"
          ],
          "line": 650
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_first_entry_or_null",
          "args": [
            "&offdev->netdevs",
            "structbpf_offload_netdev",
            "offdev_netdevs"
          ],
          "line": 646
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&ondev->offdev_netdevs"
          ],
          "line": 643
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/fair.c",
          "lines": "475-477",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);",
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "rhashtable_remove_fast(&offdevs, &ondev->l, offdevs_params)"
          ],
          "line": 642
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rhashtable_remove_fast",
          "args": [
            "&offdevs",
            "&ondev->l",
            "offdevs_params"
          ],
          "line": 642
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!ondev"
          ],
          "line": 639
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rhashtable_lookup_fast",
          "args": [
            "&offdevs",
            "&netdev",
            "offdevs_params"
          ],
          "line": 638
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 637
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ASSERT_RTNL",
          "args": [],
          "line": 635
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\n\nvoid bpf_offload_dev_netdev_unregister(struct bpf_offload_dev *offdev,\n\t\t\t\t       struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev, *altdev;\n\tstruct bpf_offloaded_map *offmap, *mtmp;\n\tstruct bpf_prog_offload *offload, *ptmp;\n\n\tASSERT_RTNL();\n\n\tdown_write(&bpf_devs_lock);\n\tondev = rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n\tif (WARN_ON(!ondev))\n\t\tgoto unlock;\n\n\tWARN_ON(rhashtable_remove_fast(&offdevs, &ondev->l, offdevs_params));\n\tlist_del(&ondev->offdev_netdevs);\n\n\t/* Try to move the objects to another netdev of the device */\n\taltdev = list_first_entry_or_null(&offdev->netdevs,\n\t\t\t\t\t  struct bpf_offload_netdev,\n\t\t\t\t\t  offdev_netdevs);\n\tif (altdev) {\n\t\tlist_for_each_entry(offload, &ondev->progs, offloads)\n\t\t\toffload->netdev = altdev->netdev;\n\t\tlist_splice_init(&ondev->progs, &altdev->progs);\n\n\t\tlist_for_each_entry(offmap, &ondev->maps, offloads)\n\t\t\toffmap->netdev = altdev->netdev;\n\t\tlist_splice_init(&ondev->maps, &altdev->maps);\n\t} else {\n\t\tlist_for_each_entry_safe(offload, ptmp, &ondev->progs, offloads)\n\t\t\t__bpf_prog_offload_destroy(offload->prog);\n\t\tlist_for_each_entry_safe(offmap, mtmp, &ondev->maps, offloads)\n\t\t\t__bpf_map_offload_destroy(offmap);\n\t}\n\n\tWARN_ON(!list_empty(&ondev->progs));\n\tWARN_ON(!list_empty(&ondev->maps));\n\tkfree(ondev);\nunlock:\n\tup_write(&bpf_devs_lock);\n}"
  },
  {
    "function_name": "bpf_offload_dev_netdev_register",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "595-625",
    "snippet": "int bpf_offload_dev_netdev_register(struct bpf_offload_dev *offdev,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev;\n\tint err;\n\n\tondev = kzalloc(sizeof(*ondev), GFP_KERNEL);\n\tif (!ondev)\n\t\treturn -ENOMEM;\n\n\tondev->netdev = netdev;\n\tondev->offdev = offdev;\n\tINIT_LIST_HEAD(&ondev->progs);\n\tINIT_LIST_HEAD(&ondev->maps);\n\n\tdown_write(&bpf_devs_lock);\n\terr = rhashtable_insert_fast(&offdevs, &ondev->l, offdevs_params);\n\tif (err) {\n\t\tnetdev_warn(netdev, \"failed to register for BPF offload\\n\");\n\t\tgoto err_unlock_free;\n\t}\n\n\tlist_add(&ondev->offdev_netdevs, &offdev->netdevs);\n\tup_write(&bpf_devs_lock);\n\treturn 0;\n\nerr_unlock_free:\n\tup_write(&bpf_devs_lock);\n\tkfree(ondev);\n\treturn err;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);",
      "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
      "static struct rhashtable offdevs;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "ondev"
          ],
          "line": 623
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 622
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&ondev->offdev_netdevs",
            "&offdev->netdevs"
          ],
          "line": 617
        },
        "resolved": true,
        "details": {
          "function_name": "cmp_filterlist_addrs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/debugfs.c",
          "lines": "95-101",
          "snippet": "static int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}",
          "includes": [
            "#include \"kcsan.h\"",
            "#include <linux/uaccess.h>",
            "#include <linux/string.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/bug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kcsan.h\"\n#include <linux/uaccess.h>\n#include <linux/string.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/sched.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/debugfs.h>\n#include <linux/bug.h>\n#include <linux/bsearch.h>\n#include <linux/atomic.h>\n\nstatic int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "netdev_warn",
          "args": [
            "netdev",
            "\"failed to register for BPF offload\\n\""
          ],
          "line": 613
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rhashtable_insert_fast",
          "args": [
            "&offdevs",
            "&ondev->l",
            "offdevs_params"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 610
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&ondev->maps"
          ],
          "line": 608
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&ondev->progs"
          ],
          "line": 607
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*ondev)",
            "GFP_KERNEL"
          ],
          "line": 601
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\n\nint bpf_offload_dev_netdev_register(struct bpf_offload_dev *offdev,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev;\n\tint err;\n\n\tondev = kzalloc(sizeof(*ondev), GFP_KERNEL);\n\tif (!ondev)\n\t\treturn -ENOMEM;\n\n\tondev->netdev = netdev;\n\tondev->offdev = offdev;\n\tINIT_LIST_HEAD(&ondev->progs);\n\tINIT_LIST_HEAD(&ondev->maps);\n\n\tdown_write(&bpf_devs_lock);\n\terr = rhashtable_insert_fast(&offdevs, &ondev->l, offdevs_params);\n\tif (err) {\n\t\tnetdev_warn(netdev, \"failed to register for BPF offload\\n\");\n\t\tgoto err_unlock_free;\n\t}\n\n\tlist_add(&ondev->offdev_netdevs, &offdev->netdevs);\n\tup_write(&bpf_devs_lock);\n\treturn 0;\n\nerr_unlock_free:\n\tup_write(&bpf_devs_lock);\n\tkfree(ondev);\n\treturn err;\n}"
  },
  {
    "function_name": "bpf_offload_prog_map_match",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "579-593",
    "snippet": "bool bpf_offload_prog_map_match(struct bpf_prog *prog, struct bpf_map *map)\n{\n\tstruct bpf_offloaded_map *offmap;\n\tbool ret;\n\n\tif (!bpf_map_is_dev_bound(map))\n\t\treturn bpf_map_offload_neutral(map);\n\toffmap = map_to_offmap(map);\n\n\tdown_read(&bpf_devs_lock);\n\tret = __bpf_offload_dev_match(prog, offmap->netdev);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 590
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__bpf_offload_dev_match",
          "args": [
            "prog",
            "offmap->netdev"
          ],
          "line": 589
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_offload_dev_match",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "546-565",
          "snippet": "static bool __bpf_offload_dev_match(struct bpf_prog *prog,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev1, *ondev2;\n\tstruct bpf_prog_offload *offload;\n\n\tif (!bpf_prog_is_dev_bound(prog->aux))\n\t\treturn false;\n\n\toffload = prog->aux->offload;\n\tif (!offload)\n\t\treturn false;\n\tif (offload->netdev == netdev)\n\t\treturn true;\n\n\tondev1 = bpf_offload_find_netdev(offload->netdev);\n\tondev2 = bpf_offload_find_netdev(netdev);\n\n\treturn ondev1 && ondev2 && ondev1->offdev == ondev2->offdev;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic bool __bpf_offload_dev_match(struct bpf_prog *prog,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev1, *ondev2;\n\tstruct bpf_prog_offload *offload;\n\n\tif (!bpf_prog_is_dev_bound(prog->aux))\n\t\treturn false;\n\n\toffload = prog->aux->offload;\n\tif (!offload)\n\t\treturn false;\n\tif (offload->netdev == netdev)\n\t\treturn true;\n\n\tondev1 = bpf_offload_find_netdev(offload->netdev);\n\tondev2 = bpf_offload_find_netdev(netdev);\n\n\treturn ondev1 && ondev2 && ondev1->offdev == ondev2->offdev;\n}"
        }
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 588
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 586
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_offload_neutral",
          "args": [
            "map"
          ],
          "line": 585
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_is_dev_bound",
          "args": [
            "map"
          ],
          "line": 584
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nbool bpf_offload_prog_map_match(struct bpf_prog *prog, struct bpf_map *map)\n{\n\tstruct bpf_offloaded_map *offmap;\n\tbool ret;\n\n\tif (!bpf_map_is_dev_bound(map))\n\t\treturn bpf_map_offload_neutral(map);\n\toffmap = map_to_offmap(map);\n\n\tdown_read(&bpf_devs_lock);\n\tret = __bpf_offload_dev_match(prog, offmap->netdev);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_offload_dev_match",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "567-576",
    "snippet": "bool bpf_offload_dev_match(struct bpf_prog *prog, struct net_device *netdev)\n{\n\tbool ret;\n\n\tdown_read(&bpf_devs_lock);\n\tret = __bpf_offload_dev_match(prog, netdev);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 573
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__bpf_offload_dev_match",
          "args": [
            "prog",
            "netdev"
          ],
          "line": 572
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_offload_dev_match",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "546-565",
          "snippet": "static bool __bpf_offload_dev_match(struct bpf_prog *prog,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev1, *ondev2;\n\tstruct bpf_prog_offload *offload;\n\n\tif (!bpf_prog_is_dev_bound(prog->aux))\n\t\treturn false;\n\n\toffload = prog->aux->offload;\n\tif (!offload)\n\t\treturn false;\n\tif (offload->netdev == netdev)\n\t\treturn true;\n\n\tondev1 = bpf_offload_find_netdev(offload->netdev);\n\tondev2 = bpf_offload_find_netdev(netdev);\n\n\treturn ondev1 && ondev2 && ondev1->offdev == ondev2->offdev;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic bool __bpf_offload_dev_match(struct bpf_prog *prog,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev1, *ondev2;\n\tstruct bpf_prog_offload *offload;\n\n\tif (!bpf_prog_is_dev_bound(prog->aux))\n\t\treturn false;\n\n\toffload = prog->aux->offload;\n\tif (!offload)\n\t\treturn false;\n\tif (offload->netdev == netdev)\n\t\treturn true;\n\n\tondev1 = bpf_offload_find_netdev(offload->netdev);\n\tondev2 = bpf_offload_find_netdev(netdev);\n\n\treturn ondev1 && ondev2 && ondev1->offdev == ondev2->offdev;\n}"
        }
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 571
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nbool bpf_offload_dev_match(struct bpf_prog *prog, struct net_device *netdev)\n{\n\tbool ret;\n\n\tdown_read(&bpf_devs_lock);\n\tret = __bpf_offload_dev_match(prog, netdev);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "__bpf_offload_dev_match",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "546-565",
    "snippet": "static bool __bpf_offload_dev_match(struct bpf_prog *prog,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev1, *ondev2;\n\tstruct bpf_prog_offload *offload;\n\n\tif (!bpf_prog_is_dev_bound(prog->aux))\n\t\treturn false;\n\n\toffload = prog->aux->offload;\n\tif (!offload)\n\t\treturn false;\n\tif (offload->netdev == netdev)\n\t\treturn true;\n\n\tondev1 = bpf_offload_find_netdev(offload->netdev);\n\tondev2 = bpf_offload_find_netdev(netdev);\n\n\treturn ondev1 && ondev2 && ondev1->offdev == ondev2->offdev;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_offload_find_netdev",
          "args": [
            "netdev"
          ],
          "line": 562
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_offload_find_netdev",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "70-78",
          "snippet": "static struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DECLARE_RWSEM(bpf_devs_lock);",
            "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
            "static struct rhashtable offdevs;",
            "static bool offdevs_inited;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\nstatic bool offdevs_inited;\n\nstatic struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_is_dev_bound",
          "args": [
            "prog->aux"
          ],
          "line": 552
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic bool __bpf_offload_dev_match(struct bpf_prog *prog,\n\t\t\t\t    struct net_device *netdev)\n{\n\tstruct bpf_offload_netdev *ondev1, *ondev2;\n\tstruct bpf_prog_offload *offload;\n\n\tif (!bpf_prog_is_dev_bound(prog->aux))\n\t\treturn false;\n\n\toffload = prog->aux->offload;\n\tif (!offload)\n\t\treturn false;\n\tif (offload->netdev == netdev)\n\t\treturn true;\n\n\tondev1 = bpf_offload_find_netdev(offload->netdev);\n\tondev2 = bpf_offload_find_netdev(netdev);\n\n\treturn ondev1 && ondev2 && ondev1->offdev == ondev2->offdev;\n}"
  },
  {
    "function_name": "bpf_map_offload_info_fill",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "521-544",
    "snippet": "int bpf_map_offload_info_fill(struct bpf_map_info *info, struct bpf_map *map)\n{\n\tstruct ns_get_path_bpf_map_args args = {\n\t\t.offmap\t= map_to_offmap(map),\n\t\t.info\t= info,\n\t};\n\tstruct inode *ns_inode;\n\tstruct path ns_path;\n\tint res;\n\n\tres = ns_get_path_cb(&ns_path, bpf_map_offload_info_fill_ns, &args);\n\tif (res) {\n\t\tif (!info->ifindex)\n\t\t\treturn -ENODEV;\n\t\treturn res;\n\t}\n\n\tns_inode = ns_path.dentry->d_inode;\n\tinfo->netns_dev = new_encode_dev(ns_inode->i_sb->s_dev);\n\tinfo->netns_ino = ns_inode->i_ino;\n\tpath_put(&ns_path);\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "path_put",
          "args": [
            "&ns_path"
          ],
          "line": 541
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "new_encode_dev",
          "args": [
            "ns_inode->i_sb->s_dev"
          ],
          "line": 539
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ns_get_path_cb",
          "args": [
            "&ns_path",
            "bpf_map_offload_info_fill_ns",
            "&args"
          ],
          "line": 531
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 524
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nint bpf_map_offload_info_fill(struct bpf_map_info *info, struct bpf_map *map)\n{\n\tstruct ns_get_path_bpf_map_args args = {\n\t\t.offmap\t= map_to_offmap(map),\n\t\t.info\t= info,\n\t};\n\tstruct inode *ns_inode;\n\tstruct path ns_path;\n\tint res;\n\n\tres = ns_get_path_cb(&ns_path, bpf_map_offload_info_fill_ns, &args);\n\tif (res) {\n\t\tif (!info->ifindex)\n\t\t\treturn -ENODEV;\n\t\treturn res;\n\t}\n\n\tns_inode = ns_path.dentry->d_inode;\n\tinfo->netns_dev = new_encode_dev(ns_inode->i_sb->s_dev);\n\tinfo->netns_ino = ns_inode->i_ino;\n\tpath_put(&ns_path);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_map_offload_info_fill_ns",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "496-519",
    "snippet": "static struct ns_common *bpf_map_offload_info_fill_ns(void *private_data)\n{\n\tstruct ns_get_path_bpf_map_args *args = private_data;\n\tstruct ns_common *ns;\n\tstruct net *net;\n\n\trtnl_lock();\n\tdown_read(&bpf_devs_lock);\n\n\tif (args->offmap->netdev) {\n\t\targs->info->ifindex = args->offmap->netdev->ifindex;\n\t\tnet = dev_net(args->offmap->netdev);\n\t\tget_net(net);\n\t\tns = &net->ns;\n\t} else {\n\t\targs->info->ifindex = 0;\n\t\tns = NULL;\n\t}\n\n\tup_read(&bpf_devs_lock);\n\trtnl_unlock();\n\n\treturn ns;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rtnl_unlock",
          "args": [],
          "line": 516
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 515
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_net",
          "args": [
            "net"
          ],
          "line": 508
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "dev_net",
          "args": [
            "args->offmap->netdev"
          ],
          "line": 507
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 503
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_lock",
          "args": [],
          "line": 502
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nstatic struct ns_common *bpf_map_offload_info_fill_ns(void *private_data)\n{\n\tstruct ns_get_path_bpf_map_args *args = private_data;\n\tstruct ns_common *ns;\n\tstruct net *net;\n\n\trtnl_lock();\n\tdown_read(&bpf_devs_lock);\n\n\tif (args->offmap->netdev) {\n\t\targs->info->ifindex = args->offmap->netdev->ifindex;\n\t\tnet = dev_net(args->offmap->netdev);\n\t\tget_net(net);\n\t\tns = &net->ns;\n\t} else {\n\t\targs->info->ifindex = 0;\n\t\tns = NULL;\n\t}\n\n\tup_read(&bpf_devs_lock);\n\trtnl_unlock();\n\n\treturn ns;\n}"
  },
  {
    "function_name": "bpf_map_offload_get_next_key",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "478-489",
    "snippet": "int bpf_map_offload_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_get_next_key(offmap, key, next_key);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 486
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offmap->dev_ops->map_get_next_key",
          "args": [
            "offmap",
            "key",
            "next_key"
          ],
          "line": 485
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 483
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 480
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_map_offload_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_get_next_key(offmap, key, next_key);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_map_offload_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "465-476",
    "snippet": "int bpf_map_offload_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_delete_elem(offmap, key);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 473
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offmap->dev_ops->map_delete_elem",
          "args": [
            "offmap",
            "key"
          ],
          "line": 472
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 470
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 467
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_map_offload_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_delete_elem(offmap, key);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_map_offload_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "447-463",
    "snippet": "int bpf_map_offload_update_elem(struct bpf_map *map,\n\t\t\t\tvoid *key, void *value, u64 flags)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tif (unlikely(flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_update_elem(offmap, key, value,\n\t\t\t\t\t\t       flags);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 460
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offmap->dev_ops->map_update_elem",
          "args": [
            "offmap",
            "key",
            "value",
            "flags"
          ],
          "line": 458
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 456
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "flags > BPF_EXIST"
          ],
          "line": 453
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 450
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_map_offload_update_elem(struct bpf_map *map,\n\t\t\t\tvoid *key, void *value, u64 flags)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tif (unlikely(flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_update_elem(offmap, key, value,\n\t\t\t\t\t\t       flags);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_map_offload_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "434-445",
    "snippet": "int bpf_map_offload_lookup_elem(struct bpf_map *map, void *key, void *value)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_lookup_elem(offmap, key, value);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 442
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offmap->dev_ops->map_lookup_elem",
          "args": [
            "offmap",
            "key",
            "value"
          ],
          "line": 441
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 439
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 436
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_map_offload_lookup_elem(struct bpf_map *map, void *key, void *value)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\tret = offmap->dev_ops->map_lookup_elem(offmap, key, value);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_map_offload_map_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "420-432",
    "snippet": "void bpf_map_offload_map_free(struct bpf_map *map)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\n\trtnl_lock();\n\tdown_write(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\t__bpf_map_offload_destroy(offmap);\n\tup_write(&bpf_devs_lock);\n\trtnl_unlock();\n\n\tkfree(offmap);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "offmap"
          ],
          "line": 431
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_unlock",
          "args": [],
          "line": 429
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 428
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__bpf_map_offload_destroy",
          "args": [
            "offmap"
          ],
          "line": 427
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_map_offload_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "411-418",
          "snippet": "static void __bpf_map_offload_destroy(struct bpf_offloaded_map *offmap)\n{\n\tWARN_ON(bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE));\n\t/* Make sure BPF_MAP_GET_NEXT_ID can't find this dead map */\n\tbpf_map_free_id(&offmap->map, true);\n\tlist_del_init(&offmap->offloads);\n\toffmap->netdev = NULL;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic void __bpf_map_offload_destroy(struct bpf_offloaded_map *offmap)\n{\n\tWARN_ON(bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE));\n\t/* Make sure BPF_MAP_GET_NEXT_ID can't find this dead map */\n\tbpf_map_free_id(&offmap->map, true);\n\tlist_del_init(&offmap->offloads);\n\toffmap->netdev = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 425
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_lock",
          "args": [],
          "line": 424
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "map_to_offmap",
          "args": [
            "map"
          ],
          "line": 422
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nvoid bpf_map_offload_map_free(struct bpf_map *map)\n{\n\tstruct bpf_offloaded_map *offmap = map_to_offmap(map);\n\n\trtnl_lock();\n\tdown_write(&bpf_devs_lock);\n\tif (offmap->netdev)\n\t\t__bpf_map_offload_destroy(offmap);\n\tup_write(&bpf_devs_lock);\n\trtnl_unlock();\n\n\tkfree(offmap);\n}"
  },
  {
    "function_name": "__bpf_map_offload_destroy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "411-418",
    "snippet": "static void __bpf_map_offload_destroy(struct bpf_offloaded_map *offmap)\n{\n\tWARN_ON(bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE));\n\t/* Make sure BPF_MAP_GET_NEXT_ID can't find this dead map */\n\tbpf_map_free_id(&offmap->map, true);\n\tlist_del_init(&offmap->offloads);\n\toffmap->netdev = NULL;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&offmap->offloads"
          ],
          "line": 416
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_free_id",
          "args": [
            "&offmap->map",
            "true"
          ],
          "line": 415
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_free_id",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "390-414",
          "snippet": "void bpf_map_free_id(struct bpf_map *map, bool do_idr_lock)\n{\n\tunsigned long flags;\n\n\t/* Offloaded maps are removed from the IDR store when their device\n\t * disappears - even if someone holds an fd to them they are unusable,\n\t * the memory is gone, all ops will fail; they are simply waiting for\n\t * refcnt to drop to be freed.\n\t */\n\tif (!map->id)\n\t\treturn;\n\n\tif (do_idr_lock)\n\t\tspin_lock_irqsave(&map_idr_lock, flags);\n\telse\n\t\t__acquire(&map_idr_lock);\n\n\tidr_remove(&map_idr, map->id);\n\tmap->id = 0;\n\n\tif (do_idr_lock)\n\t\tspin_unlock_irqrestore(&map_idr_lock, flags);\n\telse\n\t\t__release(&map_idr_lock);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_IDR(map_idr);",
            "static DEFINE_SPINLOCK(map_idr_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_IDR(map_idr);\nstatic DEFINE_SPINLOCK(map_idr_lock);\n\nvoid bpf_map_free_id(struct bpf_map *map, bool do_idr_lock)\n{\n\tunsigned long flags;\n\n\t/* Offloaded maps are removed from the IDR store when their device\n\t * disappears - even if someone holds an fd to them they are unusable,\n\t * the memory is gone, all ops will fail; they are simply waiting for\n\t * refcnt to drop to be freed.\n\t */\n\tif (!map->id)\n\t\treturn;\n\n\tif (do_idr_lock)\n\t\tspin_lock_irqsave(&map_idr_lock, flags);\n\telse\n\t\t__acquire(&map_idr_lock);\n\n\tidr_remove(&map_idr, map->id);\n\tmap->id = 0;\n\n\tif (do_idr_lock)\n\t\tspin_unlock_irqrestore(&map_idr_lock, flags);\n\telse\n\t\t__release(&map_idr_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE)"
          ],
          "line": 413
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_offload_ndo",
          "args": [
            "offmap",
            "BPF_OFFLOAD_MAP_FREE"
          ],
          "line": 413
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_offload_ndo",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "346-360",
          "snippet": "static int bpf_map_offload_ndo(struct bpf_offloaded_map *offmap,\n\t\t\t       enum bpf_netdev_command cmd)\n{\n\tstruct netdev_bpf data = {};\n\tstruct net_device *netdev;\n\n\tASSERT_RTNL();\n\n\tdata.command = cmd;\n\tdata.offmap = offmap;\n\t/* Caller must make sure netdev is valid */\n\tnetdev = offmap->netdev;\n\n\treturn netdev->netdev_ops->ndo_bpf(netdev, &data);\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic int bpf_map_offload_ndo(struct bpf_offloaded_map *offmap,\n\t\t\t       enum bpf_netdev_command cmd)\n{\n\tstruct netdev_bpf data = {};\n\tstruct net_device *netdev;\n\n\tASSERT_RTNL();\n\n\tdata.command = cmd;\n\tdata.offmap = offmap;\n\t/* Caller must make sure netdev is valid */\n\tnetdev = offmap->netdev;\n\n\treturn netdev->netdev_ops->ndo_bpf(netdev, &data);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic void __bpf_map_offload_destroy(struct bpf_offloaded_map *offmap)\n{\n\tWARN_ON(bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_FREE));\n\t/* Make sure BPF_MAP_GET_NEXT_ID can't find this dead map */\n\tbpf_map_free_id(&offmap->map, true);\n\tlist_del_init(&offmap->offloads);\n\toffmap->netdev = NULL;\n}"
  },
  {
    "function_name": "bpf_map_offload_map_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "362-409",
    "snippet": "struct bpf_map *bpf_map_offload_map_alloc(union bpf_attr *attr)\n{\n\tstruct net *net = current->nsproxy->net_ns;\n\tstruct bpf_offload_netdev *ondev;\n\tstruct bpf_offloaded_map *offmap;\n\tint err;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\tif (attr->map_type != BPF_MAP_TYPE_ARRAY &&\n\t    attr->map_type != BPF_MAP_TYPE_HASH)\n\t\treturn ERR_PTR(-EINVAL);\n\n\toffmap = kzalloc(sizeof(*offmap), GFP_USER);\n\tif (!offmap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&offmap->map, attr);\n\n\trtnl_lock();\n\tdown_write(&bpf_devs_lock);\n\toffmap->netdev = __dev_get_by_index(net, attr->map_ifindex);\n\terr = bpf_dev_offload_check(offmap->netdev);\n\tif (err)\n\t\tgoto err_unlock;\n\n\tondev = bpf_offload_find_netdev(offmap->netdev);\n\tif (!ondev) {\n\t\terr = -EINVAL;\n\t\tgoto err_unlock;\n\t}\n\n\terr = bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_ALLOC);\n\tif (err)\n\t\tgoto err_unlock;\n\n\tlist_add_tail(&offmap->offloads, &ondev->maps);\n\tup_write(&bpf_devs_lock);\n\trtnl_unlock();\n\n\treturn &offmap->map;\n\nerr_unlock:\n\tup_write(&bpf_devs_lock);\n\trtnl_unlock();\n\tkfree(offmap);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 408
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "offmap"
          ],
          "line": 407
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_unlock",
          "args": [],
          "line": 406
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 405
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_unlock",
          "args": [],
          "line": 400
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&offmap->offloads",
            "&ondev->maps"
          ],
          "line": 398
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_offload_ndo",
          "args": [
            "offmap",
            "BPF_OFFLOAD_MAP_ALLOC"
          ],
          "line": 394
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_offload_ndo",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "346-360",
          "snippet": "static int bpf_map_offload_ndo(struct bpf_offloaded_map *offmap,\n\t\t\t       enum bpf_netdev_command cmd)\n{\n\tstruct netdev_bpf data = {};\n\tstruct net_device *netdev;\n\n\tASSERT_RTNL();\n\n\tdata.command = cmd;\n\tdata.offmap = offmap;\n\t/* Caller must make sure netdev is valid */\n\tnetdev = offmap->netdev;\n\n\treturn netdev->netdev_ops->ndo_bpf(netdev, &data);\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic int bpf_map_offload_ndo(struct bpf_offloaded_map *offmap,\n\t\t\t       enum bpf_netdev_command cmd)\n{\n\tstruct netdev_bpf data = {};\n\tstruct net_device *netdev;\n\n\tASSERT_RTNL();\n\n\tdata.command = cmd;\n\tdata.offmap = offmap;\n\t/* Caller must make sure netdev is valid */\n\tnetdev = offmap->netdev;\n\n\treturn netdev->netdev_ops->ndo_bpf(netdev, &data);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_offload_find_netdev",
          "args": [
            "offmap->netdev"
          ],
          "line": 388
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_offload_find_netdev",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "70-78",
          "snippet": "static struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DECLARE_RWSEM(bpf_devs_lock);",
            "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
            "static struct rhashtable offdevs;",
            "static bool offdevs_inited;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\nstatic bool offdevs_inited;\n\nstatic struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_dev_offload_check",
          "args": [
            "offmap->netdev"
          ],
          "line": 384
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_dev_offload_check",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "61-68",
          "snippet": "static int bpf_dev_offload_check(struct net_device *netdev)\n{\n\tif (!netdev)\n\t\treturn -EINVAL;\n\tif (!netdev->netdev_ops->ndo_bpf)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic int bpf_dev_offload_check(struct net_device *netdev)\n{\n\tif (!netdev)\n\t\treturn -EINVAL;\n\tif (!netdev->netdev_ops->ndo_bpf)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__dev_get_by_index",
          "args": [
            "net",
            "attr->map_ifindex"
          ],
          "line": 383
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 382
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_lock",
          "args": [],
          "line": 381
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&offmap->map",
            "attr"
          ],
          "line": 379
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "361-370",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 377
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*offmap)",
            "GFP_USER"
          ],
          "line": 375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 373
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "capable",
          "args": [
            "CAP_SYS_ADMIN"
          ],
          "line": 369
        },
        "resolved": true,
        "details": {
          "function_name": "capable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/capability.c",
          "lines": "447-450",
          "snippet": "bool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}",
          "includes": [
            "#include <linux/uaccess.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>",
            "#include <linux/capability.h>",
            "#include <linux/audit.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/uaccess.h>\n#include <linux/user_namespace.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n#include <linux/capability.h>\n#include <linux/audit.h>\n\nbool capable(int cap)\n{\n\treturn ns_capable(&init_user_ns, cap);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nstruct bpf_map *bpf_map_offload_map_alloc(union bpf_attr *attr)\n{\n\tstruct net *net = current->nsproxy->net_ns;\n\tstruct bpf_offload_netdev *ondev;\n\tstruct bpf_offloaded_map *offmap;\n\tint err;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn ERR_PTR(-EPERM);\n\tif (attr->map_type != BPF_MAP_TYPE_ARRAY &&\n\t    attr->map_type != BPF_MAP_TYPE_HASH)\n\t\treturn ERR_PTR(-EINVAL);\n\n\toffmap = kzalloc(sizeof(*offmap), GFP_USER);\n\tif (!offmap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&offmap->map, attr);\n\n\trtnl_lock();\n\tdown_write(&bpf_devs_lock);\n\toffmap->netdev = __dev_get_by_index(net, attr->map_ifindex);\n\terr = bpf_dev_offload_check(offmap->netdev);\n\tif (err)\n\t\tgoto err_unlock;\n\n\tondev = bpf_offload_find_netdev(offmap->netdev);\n\tif (!ondev) {\n\t\terr = -EINVAL;\n\t\tgoto err_unlock;\n\t}\n\n\terr = bpf_map_offload_ndo(offmap, BPF_OFFLOAD_MAP_ALLOC);\n\tif (err)\n\t\tgoto err_unlock;\n\n\tlist_add_tail(&offmap->offloads, &ondev->maps);\n\tup_write(&bpf_devs_lock);\n\trtnl_unlock();\n\n\treturn &offmap->map;\n\nerr_unlock:\n\tup_write(&bpf_devs_lock);\n\trtnl_unlock();\n\tkfree(offmap);\n\treturn ERR_PTR(err);\n}"
  },
  {
    "function_name": "bpf_map_offload_ndo",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "346-360",
    "snippet": "static int bpf_map_offload_ndo(struct bpf_offloaded_map *offmap,\n\t\t\t       enum bpf_netdev_command cmd)\n{\n\tstruct netdev_bpf data = {};\n\tstruct net_device *netdev;\n\n\tASSERT_RTNL();\n\n\tdata.command = cmd;\n\tdata.offmap = offmap;\n\t/* Caller must make sure netdev is valid */\n\tnetdev = offmap->netdev;\n\n\treturn netdev->netdev_ops->ndo_bpf(netdev, &data);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "netdev->netdev_ops->ndo_bpf",
          "args": [
            "netdev",
            "&data"
          ],
          "line": 359
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ASSERT_RTNL",
          "args": [],
          "line": 352
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic int bpf_map_offload_ndo(struct bpf_offloaded_map *offmap,\n\t\t\t       enum bpf_netdev_command cmd)\n{\n\tstruct netdev_bpf data = {};\n\tstruct net_device *netdev;\n\n\tASSERT_RTNL();\n\n\tdata.command = cmd;\n\tdata.offmap = offmap;\n\t/* Caller must make sure netdev is valid */\n\tnetdev = offmap->netdev;\n\n\treturn netdev->netdev_ops->ndo_bpf(netdev, &data);\n}"
  },
  {
    "function_name": "bpf_prog_offload_info_fill",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "294-341",
    "snippet": "int bpf_prog_offload_info_fill(struct bpf_prog_info *info,\n\t\t\t       struct bpf_prog *prog)\n{\n\tstruct ns_get_path_bpf_prog_args args = {\n\t\t.prog\t= prog,\n\t\t.info\t= info,\n\t};\n\tstruct bpf_prog_aux *aux = prog->aux;\n\tstruct inode *ns_inode;\n\tstruct path ns_path;\n\tchar __user *uinsns;\n\tint res;\n\tu32 ulen;\n\n\tres = ns_get_path_cb(&ns_path, bpf_prog_offload_info_fill_ns, &args);\n\tif (res) {\n\t\tif (!info->ifindex)\n\t\t\treturn -ENODEV;\n\t\treturn res;\n\t}\n\n\tdown_read(&bpf_devs_lock);\n\n\tif (!aux->offload) {\n\t\tup_read(&bpf_devs_lock);\n\t\treturn -ENODEV;\n\t}\n\n\tulen = info->jited_prog_len;\n\tinfo->jited_prog_len = aux->offload->jited_len;\n\tif (info->jited_prog_len && ulen) {\n\t\tuinsns = u64_to_user_ptr(info->jited_prog_insns);\n\t\tulen = min_t(u32, info->jited_prog_len, ulen);\n\t\tif (copy_to_user(uinsns, aux->offload->jited_image, ulen)) {\n\t\t\tup_read(&bpf_devs_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\tup_read(&bpf_devs_lock);\n\n\tns_inode = ns_path.dentry->d_inode;\n\tinfo->netns_dev = new_encode_dev(ns_inode->i_sb->s_dev);\n\tinfo->netns_ino = ns_inode->i_ino;\n\tpath_put(&ns_path);\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "path_put",
          "args": [
            "&ns_path"
          ],
          "line": 338
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "new_encode_dev",
          "args": [
            "ns_inode->i_sb->s_dev"
          ],
          "line": 336
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 333
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_to_user",
          "args": [
            "uinsns",
            "aux->offload->jited_image",
            "ulen"
          ],
          "line": 327
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_array_copy_to_user",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/core.c",
          "lines": "2043-2067",
          "snippet": "int bpf_prog_array_copy_to_user(struct bpf_prog_array *array,\n\t\t\t\t__u32 __user *prog_ids, u32 cnt)\n{\n\tunsigned long err = 0;\n\tbool nospc;\n\tu32 *ids;\n\n\t/* users of this function are doing:\n\t * cnt = bpf_prog_array_length();\n\t * if (cnt > 0)\n\t *     bpf_prog_array_copy_to_user(..., cnt);\n\t * so below kcalloc doesn't need extra cnt > 0 check.\n\t */\n\tids = kcalloc(cnt, sizeof(u32), GFP_USER | __GFP_NOWARN);\n\tif (!ids)\n\t\treturn -ENOMEM;\n\tnospc = bpf_prog_array_copy_core(array, ids, cnt);\n\terr = copy_to_user(prog_ids, ids, cnt * sizeof(u32));\n\tkfree(ids);\n\tif (err)\n\t\treturn -EFAULT;\n\tif (nospc)\n\t\treturn -ENOSPC;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/bpf_trace.h>",
            "#include <asm/unaligned.h>",
            "#include <asm/barrier.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/log2.h>",
            "#include <linux/extable.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/rbtree_latch.h>",
            "#include <linux/objtool.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/moduleloader.h>",
            "#include <linux/random.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/skbuff.h>",
            "#include <linux/filter.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/bpf_trace.h>\n#include <asm/unaligned.h>\n#include <asm/barrier.h>\n#include <linux/bpf_verifier.h>\n#include <linux/log2.h>\n#include <linux/extable.h>\n#include <linux/perf_event.h>\n#include <linux/rcupdate.h>\n#include <linux/kallsyms.h>\n#include <linux/rbtree_latch.h>\n#include <linux/objtool.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/moduleloader.h>\n#include <linux/random.h>\n#include <linux/vmalloc.h>\n#include <linux/skbuff.h>\n#include <linux/filter.h>\n#include <uapi/linux/btf.h>\n\nint bpf_prog_array_copy_to_user(struct bpf_prog_array *array,\n\t\t\t\t__u32 __user *prog_ids, u32 cnt)\n{\n\tunsigned long err = 0;\n\tbool nospc;\n\tu32 *ids;\n\n\t/* users of this function are doing:\n\t * cnt = bpf_prog_array_length();\n\t * if (cnt > 0)\n\t *     bpf_prog_array_copy_to_user(..., cnt);\n\t * so below kcalloc doesn't need extra cnt > 0 check.\n\t */\n\tids = kcalloc(cnt, sizeof(u32), GFP_USER | __GFP_NOWARN);\n\tif (!ids)\n\t\treturn -ENOMEM;\n\tnospc = bpf_prog_array_copy_core(array, ids, cnt);\n\terr = copy_to_user(prog_ids, ids, cnt * sizeof(u32));\n\tkfree(ids);\n\tif (err)\n\t\treturn -EFAULT;\n\tif (nospc)\n\t\treturn -ENOSPC;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "min_t",
          "args": [
            "u32",
            "info->jited_prog_len",
            "ulen"
          ],
          "line": 326
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "u64_to_user_ptr",
          "args": [
            "info->jited_prog_insns"
          ],
          "line": 325
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 315
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ns_get_path_cb",
          "args": [
            "&ns_path",
            "bpf_prog_offload_info_fill_ns",
            "&args"
          ],
          "line": 308
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_prog_offload_info_fill(struct bpf_prog_info *info,\n\t\t\t       struct bpf_prog *prog)\n{\n\tstruct ns_get_path_bpf_prog_args args = {\n\t\t.prog\t= prog,\n\t\t.info\t= info,\n\t};\n\tstruct bpf_prog_aux *aux = prog->aux;\n\tstruct inode *ns_inode;\n\tstruct path ns_path;\n\tchar __user *uinsns;\n\tint res;\n\tu32 ulen;\n\n\tres = ns_get_path_cb(&ns_path, bpf_prog_offload_info_fill_ns, &args);\n\tif (res) {\n\t\tif (!info->ifindex)\n\t\t\treturn -ENODEV;\n\t\treturn res;\n\t}\n\n\tdown_read(&bpf_devs_lock);\n\n\tif (!aux->offload) {\n\t\tup_read(&bpf_devs_lock);\n\t\treturn -ENODEV;\n\t}\n\n\tulen = info->jited_prog_len;\n\tinfo->jited_prog_len = aux->offload->jited_len;\n\tif (info->jited_prog_len && ulen) {\n\t\tuinsns = u64_to_user_ptr(info->jited_prog_insns);\n\t\tulen = min_t(u32, info->jited_prog_len, ulen);\n\t\tif (copy_to_user(uinsns, aux->offload->jited_image, ulen)) {\n\t\t\tup_read(&bpf_devs_lock);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\n\tup_read(&bpf_devs_lock);\n\n\tns_inode = ns_path.dentry->d_inode;\n\tinfo->netns_dev = new_encode_dev(ns_inode->i_sb->s_dev);\n\tinfo->netns_ino = ns_inode->i_ino;\n\tpath_put(&ns_path);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_prog_offload_info_fill_ns",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "268-292",
    "snippet": "static struct ns_common *bpf_prog_offload_info_fill_ns(void *private_data)\n{\n\tstruct ns_get_path_bpf_prog_args *args = private_data;\n\tstruct bpf_prog_aux *aux = args->prog->aux;\n\tstruct ns_common *ns;\n\tstruct net *net;\n\n\trtnl_lock();\n\tdown_read(&bpf_devs_lock);\n\n\tif (aux->offload) {\n\t\targs->info->ifindex = aux->offload->netdev->ifindex;\n\t\tnet = dev_net(aux->offload->netdev);\n\t\tget_net(net);\n\t\tns = &net->ns;\n\t} else {\n\t\targs->info->ifindex = 0;\n\t\tns = NULL;\n\t}\n\n\tup_read(&bpf_devs_lock);\n\trtnl_unlock();\n\n\treturn ns;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rtnl_unlock",
          "args": [],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 288
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_net",
          "args": [
            "net"
          ],
          "line": 281
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "dev_net",
          "args": [
            "aux->offload->netdev"
          ],
          "line": 280
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 276
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtnl_lock",
          "args": [],
          "line": 275
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nstatic struct ns_common *bpf_prog_offload_info_fill_ns(void *private_data)\n{\n\tstruct ns_get_path_bpf_prog_args *args = private_data;\n\tstruct bpf_prog_aux *aux = args->prog->aux;\n\tstruct ns_common *ns;\n\tstruct net *net;\n\n\trtnl_lock();\n\tdown_read(&bpf_devs_lock);\n\n\tif (aux->offload) {\n\t\targs->info->ifindex = aux->offload->netdev->ifindex;\n\t\tnet = dev_net(aux->offload->netdev);\n\t\tget_net(net);\n\t\tns = &net->ns;\n\t} else {\n\t\targs->info->ifindex = 0;\n\t\tns = NULL;\n\t}\n\n\tup_read(&bpf_devs_lock);\n\trtnl_unlock();\n\n\treturn ns;\n}"
  },
  {
    "function_name": "bpf_prog_offload_compile",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "256-261",
    "snippet": "int bpf_prog_offload_compile(struct bpf_prog *prog)\n{\n\tprog->bpf_func = bpf_prog_warn_on_exec;\n\n\treturn bpf_prog_offload_translate(prog);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_prog_offload_translate",
          "args": [
            "prog"
          ],
          "line": 260
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_offload_translate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "235-247",
          "snippet": "static int bpf_prog_offload_translate(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = prog->aux->offload;\n\tif (offload)\n\t\tret = offload->offdev->ops->translate(prog);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DECLARE_RWSEM(bpf_devs_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nstatic int bpf_prog_offload_translate(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = prog->aux->offload;\n\tif (offload)\n\t\tret = offload->offdev->ops->translate(prog);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nint bpf_prog_offload_compile(struct bpf_prog *prog)\n{\n\tprog->bpf_func = bpf_prog_warn_on_exec;\n\n\treturn bpf_prog_offload_translate(prog);\n}"
  },
  {
    "function_name": "bpf_prog_warn_on_exec",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "249-254",
    "snippet": "static unsigned int bpf_prog_warn_on_exec(const void *ctx,\n\t\t\t\t\t  const struct bpf_insn *insn)\n{\n\tWARN(1, \"attempt to execute device eBPF program on the host!\");\n\treturn 0;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN",
          "args": [
            "1",
            "\"attempt to execute device eBPF program on the host!\""
          ],
          "line": 252
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic unsigned int bpf_prog_warn_on_exec(const void *ctx,\n\t\t\t\t\t  const struct bpf_insn *insn)\n{\n\tWARN(1, \"attempt to execute device eBPF program on the host!\");\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_prog_offload_translate",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "235-247",
    "snippet": "static int bpf_prog_offload_translate(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = prog->aux->offload;\n\tif (offload)\n\t\tret = offload->offdev->ops->translate(prog);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 244
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offload->offdev->ops->translate",
          "args": [
            "prog"
          ],
          "line": 243
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 240
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nstatic int bpf_prog_offload_translate(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = prog->aux->offload;\n\tif (offload)\n\t\tret = offload->offdev->ops->translate(prog);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_prog_offload_destroy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "227-233",
    "snippet": "void bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tdown_write(&bpf_devs_lock);\n\tif (prog->aux->offload)\n\t\t__bpf_prog_offload_destroy(prog);\n\tup_write(&bpf_devs_lock);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 232
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__bpf_prog_offload_destroy",
          "args": [
            "prog"
          ],
          "line": 231
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_prog_offload_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "212-225",
          "snippet": "static void __bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload = prog->aux->offload;\n\n\tif (offload->dev_state)\n\t\toffload->offdev->ops->destroy(prog);\n\n\t/* Make sure BPF_PROG_GET_NEXT_ID can't find this dead program */\n\tbpf_prog_free_id(prog, true);\n\n\tlist_del_init(&offload->offloads);\n\tkfree(offload);\n\tprog->aux->offload = NULL;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic void __bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload = prog->aux->offload;\n\n\tif (offload->dev_state)\n\t\toffload->offdev->ops->destroy(prog);\n\n\t/* Make sure BPF_PROG_GET_NEXT_ID can't find this dead program */\n\tbpf_prog_free_id(prog, true);\n\n\tlist_del_init(&offload->offloads);\n\tkfree(offload);\n\tprog->aux->offload = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 229
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nvoid bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tdown_write(&bpf_devs_lock);\n\tif (prog->aux->offload)\n\t\t__bpf_prog_offload_destroy(prog);\n\tup_write(&bpf_devs_lock);\n}"
  },
  {
    "function_name": "__bpf_prog_offload_destroy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "212-225",
    "snippet": "static void __bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload = prog->aux->offload;\n\n\tif (offload->dev_state)\n\t\toffload->offdev->ops->destroy(prog);\n\n\t/* Make sure BPF_PROG_GET_NEXT_ID can't find this dead program */\n\tbpf_prog_free_id(prog, true);\n\n\tlist_del_init(&offload->offloads);\n\tkfree(offload);\n\tprog->aux->offload = NULL;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "offload"
          ],
          "line": 223
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&offload->offloads"
          ],
          "line": 222
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_free_id",
          "args": [
            "prog",
            "true"
          ],
          "line": 220
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_free_id",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "1742-1766",
          "snippet": "void bpf_prog_free_id(struct bpf_prog *prog, bool do_idr_lock)\n{\n\tunsigned long flags;\n\n\t/* cBPF to eBPF migrations are currently not in the idr store.\n\t * Offloaded programs are removed from the store when their device\n\t * disappears - even if someone grabs an fd to them they are unusable,\n\t * simply waiting for refcnt to drop to be freed.\n\t */\n\tif (!prog->aux->id)\n\t\treturn;\n\n\tif (do_idr_lock)\n\t\tspin_lock_irqsave(&prog_idr_lock, flags);\n\telse\n\t\t__acquire(&prog_idr_lock);\n\n\tidr_remove(&prog_idr, prog->aux->id);\n\tprog->aux->id = 0;\n\n\tif (do_idr_lock)\n\t\tspin_unlock_irqrestore(&prog_idr_lock, flags);\n\telse\n\t\t__release(&prog_idr_lock);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_IDR(prog_idr);",
            "static DEFINE_SPINLOCK(prog_idr_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_IDR(prog_idr);\nstatic DEFINE_SPINLOCK(prog_idr_lock);\n\nvoid bpf_prog_free_id(struct bpf_prog *prog, bool do_idr_lock)\n{\n\tunsigned long flags;\n\n\t/* cBPF to eBPF migrations are currently not in the idr store.\n\t * Offloaded programs are removed from the store when their device\n\t * disappears - even if someone grabs an fd to them they are unusable,\n\t * simply waiting for refcnt to drop to be freed.\n\t */\n\tif (!prog->aux->id)\n\t\treturn;\n\n\tif (do_idr_lock)\n\t\tspin_lock_irqsave(&prog_idr_lock, flags);\n\telse\n\t\t__acquire(&prog_idr_lock);\n\n\tidr_remove(&prog_idr, prog->aux->id);\n\tprog->aux->id = 0;\n\n\tif (do_idr_lock)\n\t\tspin_unlock_irqrestore(&prog_idr_lock, flags);\n\telse\n\t\t__release(&prog_idr_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offload->offdev->ops->destroy",
          "args": [
            "prog"
          ],
          "line": 217
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic void __bpf_prog_offload_destroy(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload = prog->aux->offload;\n\n\tif (offload->dev_state)\n\t\toffload->offdev->ops->destroy(prog);\n\n\t/* Make sure BPF_PROG_GET_NEXT_ID can't find this dead program */\n\tbpf_prog_free_id(prog, true);\n\n\tlist_del_init(&offload->offloads);\n\tkfree(offload);\n\tprog->aux->offload = NULL;\n}"
  },
  {
    "function_name": "bpf_prog_offload_remove_insns",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "196-210",
    "snippet": "void\nbpf_prog_offload_remove_insns(struct bpf_verifier_env *env, u32 off, u32 cnt)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -EOPNOTSUPP;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload) {\n\t\tif (!offload->opt_failed && offload->offdev->ops->remove_insns)\n\t\t\tret = offload->offdev->ops->remove_insns(env, off, cnt);\n\t\toffload->opt_failed |= ret;\n\t}\n\tup_read(&bpf_devs_lock);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 209
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offload->offdev->ops->remove_insns",
          "args": [
            "env",
            "off",
            "cnt"
          ],
          "line": 206
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 202
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nvoid\nbpf_prog_offload_remove_insns(struct bpf_verifier_env *env, u32 off, u32 cnt)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -EOPNOTSUPP;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload) {\n\t\tif (!offload->opt_failed && offload->offdev->ops->remove_insns)\n\t\t\tret = offload->offdev->ops->remove_insns(env, off, cnt);\n\t\toffload->opt_failed |= ret;\n\t}\n\tup_read(&bpf_devs_lock);\n}"
  },
  {
    "function_name": "bpf_prog_offload_replace_insn",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "177-194",
    "snippet": "void\nbpf_prog_offload_replace_insn(struct bpf_verifier_env *env, u32 off,\n\t\t\t      struct bpf_insn *insn)\n{\n\tconst struct bpf_prog_offload_ops *ops;\n\tstruct bpf_prog_offload *offload;\n\tint ret = -EOPNOTSUPP;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload) {\n\t\tops = offload->offdev->ops;\n\t\tif (!offload->opt_failed && ops->replace_insn)\n\t\t\tret = ops->replace_insn(env, off, insn);\n\t\toffload->opt_failed |= ret;\n\t}\n\tup_read(&bpf_devs_lock);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 193
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ops->replace_insn",
          "args": [
            "env",
            "off",
            "insn"
          ],
          "line": 190
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 185
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nvoid\nbpf_prog_offload_replace_insn(struct bpf_verifier_env *env, u32 off,\n\t\t\t      struct bpf_insn *insn)\n{\n\tconst struct bpf_prog_offload_ops *ops;\n\tstruct bpf_prog_offload *offload;\n\tint ret = -EOPNOTSUPP;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload) {\n\t\tops = offload->offdev->ops;\n\t\tif (!offload->opt_failed && ops->replace_insn)\n\t\t\tret = ops->replace_insn(env, off, insn);\n\t\toffload->opt_failed |= ret;\n\t}\n\tup_read(&bpf_devs_lock);\n}"
  },
  {
    "function_name": "bpf_prog_offload_finalize",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "159-175",
    "snippet": "int bpf_prog_offload_finalize(struct bpf_verifier_env *env)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload) {\n\t\tif (offload->offdev->ops->finalize)\n\t\t\tret = offload->offdev->ops->finalize(env);\n\t\telse\n\t\t\tret = 0;\n\t}\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 172
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offload->offdev->ops->finalize",
          "args": [
            "env"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 164
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_prog_offload_finalize(struct bpf_verifier_env *env)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload) {\n\t\tif (offload->offdev->ops->finalize)\n\t\t\tret = offload->offdev->ops->finalize(env);\n\t\telse\n\t\t\tret = 0;\n\t}\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_prog_offload_verify_insn",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "143-157",
    "snippet": "int bpf_prog_offload_verify_insn(struct bpf_verifier_env *env,\n\t\t\t\t int insn_idx, int prev_insn_idx)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload)\n\t\tret = offload->offdev->ops->insn_hook(env, insn_idx,\n\t\t\t\t\t\t      prev_insn_idx);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 154
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offload->offdev->ops->insn_hook",
          "args": [
            "env",
            "insn_idx",
            "prev_insn_idx"
          ],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 149
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_prog_offload_verify_insn(struct bpf_verifier_env *env,\n\t\t\t\t int insn_idx, int prev_insn_idx)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = env->prog->aux->offload;\n\tif (offload)\n\t\tret = offload->offdev->ops->insn_hook(env, insn_idx,\n\t\t\t\t\t\t      prev_insn_idx);\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_prog_offload_verifier_prep",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "127-141",
    "snippet": "int bpf_prog_offload_verifier_prep(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = prog->aux->offload;\n\tif (offload) {\n\t\tret = offload->offdev->ops->prepare(prog);\n\t\toffload->dev_state = !ret;\n\t}\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 138
        },
        "resolved": true,
        "details": {
          "function_name": "wakeup_readers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/relay.c",
          "lines": "271-277",
          "snippet": "static void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}",
          "includes": [
            "#include <linux/splice.h>",
            "#include <linux/cpu.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/relay.h>",
            "#include <linux/string.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>",
            "#include <linux/stddef.h>",
            "#include <linux/errno.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/splice.h>\n#include <linux/cpu.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/relay.h>\n#include <linux/string.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n#include <linux/stddef.h>\n#include <linux/errno.h>\n\nstatic void wakeup_readers(struct irq_work *work)\n{\n\tstruct rchan_buf *buf;\n\n\tbuf = container_of(work, struct rchan_buf, wakeup_work);\n\twake_up_interruptible(&buf->read_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "offload->offdev->ops->prepare",
          "args": [
            "prog"
          ],
          "line": 135
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 132
        },
        "resolved": true,
        "details": {
          "function_name": "__percpu_down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "46-80",
          "snippet": "static bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nstatic bool __percpu_down_read_trylock(struct percpu_rw_semaphore *sem)\n{\n\tthis_cpu_inc(*sem->read_count);\n\n\t/*\n\t * Due to having preemption disabled the decrement happens on\n\t * the same CPU as the increment, avoiding the\n\t * increment-on-one-CPU-and-decrement-on-another problem.\n\t *\n\t * If the reader misses the writer's assignment of sem->block, then the\n\t * writer is guaranteed to see the reader's increment.\n\t *\n\t * Conversely, any readers that increment their sem->read_count after\n\t * the writer looks are guaranteed to see the sem->block value, which\n\t * in turn means that they are guaranteed to immediately decrement\n\t * their sem->read_count, so that it doesn't matter that the writer\n\t * missed them.\n\t */\n\n\tsmp_mb(); /* A matches D */\n\n\t/*\n\t * If !sem->block the critical section starts here, matched by the\n\t * release in percpu_up_write().\n\t */\n\tif (likely(!atomic_read_acquire(&sem->block)))\n\t\treturn true;\n\n\tthis_cpu_dec(*sem->read_count);\n\n\t/* Prod writer to re-evaluate readers_active_check() */\n\trcuwait_wake_up(&sem->writer);\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_prog_offload_verifier_prep(struct bpf_prog *prog)\n{\n\tstruct bpf_prog_offload *offload;\n\tint ret = -ENODEV;\n\n\tdown_read(&bpf_devs_lock);\n\toffload = prog->aux->offload;\n\tif (offload) {\n\t\tret = offload->offdev->ops->prepare(prog);\n\t\toffload->dev_state = !ret;\n\t}\n\tup_read(&bpf_devs_lock);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "bpf_prog_offload_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "80-125",
    "snippet": "int bpf_prog_offload_init(struct bpf_prog *prog, union bpf_attr *attr)\n{\n\tstruct bpf_offload_netdev *ondev;\n\tstruct bpf_prog_offload *offload;\n\tint err;\n\n\tif (attr->prog_type != BPF_PROG_TYPE_SCHED_CLS &&\n\t    attr->prog_type != BPF_PROG_TYPE_XDP)\n\t\treturn -EINVAL;\n\n\tif (attr->prog_flags)\n\t\treturn -EINVAL;\n\n\toffload = kzalloc(sizeof(*offload), GFP_USER);\n\tif (!offload)\n\t\treturn -ENOMEM;\n\n\toffload->prog = prog;\n\n\toffload->netdev = dev_get_by_index(current->nsproxy->net_ns,\n\t\t\t\t\t   attr->prog_ifindex);\n\terr = bpf_dev_offload_check(offload->netdev);\n\tif (err)\n\t\tgoto err_maybe_put;\n\n\tdown_write(&bpf_devs_lock);\n\tondev = bpf_offload_find_netdev(offload->netdev);\n\tif (!ondev) {\n\t\terr = -EINVAL;\n\t\tgoto err_unlock;\n\t}\n\toffload->offdev = ondev->offdev;\n\tprog->aux->offload = offload;\n\tlist_add_tail(&offload->offloads, &ondev->progs);\n\tdev_put(offload->netdev);\n\tup_write(&bpf_devs_lock);\n\n\treturn 0;\nerr_unlock:\n\tup_write(&bpf_devs_lock);\nerr_maybe_put:\n\tif (offload->netdev)\n\t\tdev_put(offload->netdev);\n\tkfree(offload);\n\treturn err;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "offload"
          ],
          "line": 123
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_put",
          "args": [
            "offload->netdev"
          ],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 119
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "242-269",
          "snippet": "void percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_up_write(struct percpu_rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\n\t/*\n\t * Signal the writer is done, no fast path yet.\n\t *\n\t * One reason that we cannot just immediately flip to readers_fast is\n\t * that new readers might fail to see the results of this writer's\n\t * critical section.\n\t *\n\t * Therefore we force it through the slow path which guarantees an\n\t * acquire and thereby guarantees the critical section's consistency.\n\t */\n\tatomic_set_release(&sem->block, 0);\n\n\t/*\n\t * Prod any pending reader/writer to make progress.\n\t */\n\t__wake_up(&sem->waiters, TASK_NORMAL, 1, sem);\n\n\t/*\n\t * Once this completes (at least one RCU-sched grace period hence) the\n\t * reader fast path will be available again. Safe to use outside the\n\t * exclusive write lock because its counting.\n\t */\n\trcu_sync_exit(&sem->rss);\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_put",
          "args": [
            "offload->netdev"
          ],
          "line": 114
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&offload->offloads",
            "&ondev->progs"
          ],
          "line": 113
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_offload_find_netdev",
          "args": [
            "offload->netdev"
          ],
          "line": 106
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_offload_find_netdev",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "70-78",
          "snippet": "static struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DECLARE_RWSEM(bpf_devs_lock);",
            "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
            "static struct rhashtable offdevs;",
            "static bool offdevs_inited;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\nstatic bool offdevs_inited;\n\nstatic struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}"
        }
      },
      {
        "call_info": {
          "callee": "down_write",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 105
        },
        "resolved": true,
        "details": {
          "function_name": "percpu_down_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/percpu-rwsem.c",
          "lines": "214-239",
          "snippet": "void percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <linux/errno.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/wait.h>",
            "#include <linux/percpu.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/errno.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/lockdep.h>\n#include <linux/wait.h>\n#include <linux/percpu.h>\n#include <linux/atomic.h>\n\nvoid percpu_down_write(struct percpu_rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\t/* Notify readers to take the slow path. */\n\trcu_sync_enter(&sem->rss);\n\n\t/*\n\t * Try set sem->block; this provides writer-writer exclusion.\n\t * Having sem->block set makes new readers block.\n\t */\n\tif (!__percpu_down_write_trylock(sem))\n\t\tpercpu_rwsem_wait(sem, /* .reader = */ false);\n\n\t/* smp_mb() implied by __percpu_down_write_trylock() on success -- D matches A */\n\n\t/*\n\t * If they don't see our store of sem->block, then we are guaranteed to\n\t * see their sem->read_count increment, and therefore will wait for\n\t * them.\n\t */\n\n\t/* Wait for all active readers to complete. */\n\trcuwait_wait_event(&sem->writer, readers_active_check(sem), TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_dev_offload_check",
          "args": [
            "offload->netdev"
          ],
          "line": 101
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_dev_offload_check",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
          "lines": "61-68",
          "snippet": "static int bpf_dev_offload_check(struct net_device *netdev)\n{\n\tif (!netdev)\n\t\treturn -EINVAL;\n\tif (!netdev->netdev_ops->ndo_bpf)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}",
          "includes": [
            "#include <linux/rwsem.h>",
            "#include <linux/rtnetlink.h>",
            "#include <linux/rhashtable.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/printk.h>",
            "#include <linux/netdevice.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/list.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/bug.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic int bpf_dev_offload_check(struct net_device *netdev)\n{\n\tif (!netdev)\n\t\treturn -EINVAL;\n\tif (!netdev->netdev_ops->ndo_bpf)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "dev_get_by_index",
          "args": [
            "current->nsproxy->net_ns",
            "attr->prog_ifindex"
          ],
          "line": 99
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*offload)",
            "GFP_USER"
          ],
          "line": 93
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\n\nint bpf_prog_offload_init(struct bpf_prog *prog, union bpf_attr *attr)\n{\n\tstruct bpf_offload_netdev *ondev;\n\tstruct bpf_prog_offload *offload;\n\tint err;\n\n\tif (attr->prog_type != BPF_PROG_TYPE_SCHED_CLS &&\n\t    attr->prog_type != BPF_PROG_TYPE_XDP)\n\t\treturn -EINVAL;\n\n\tif (attr->prog_flags)\n\t\treturn -EINVAL;\n\n\toffload = kzalloc(sizeof(*offload), GFP_USER);\n\tif (!offload)\n\t\treturn -ENOMEM;\n\n\toffload->prog = prog;\n\n\toffload->netdev = dev_get_by_index(current->nsproxy->net_ns,\n\t\t\t\t\t   attr->prog_ifindex);\n\terr = bpf_dev_offload_check(offload->netdev);\n\tif (err)\n\t\tgoto err_maybe_put;\n\n\tdown_write(&bpf_devs_lock);\n\tondev = bpf_offload_find_netdev(offload->netdev);\n\tif (!ondev) {\n\t\terr = -EINVAL;\n\t\tgoto err_unlock;\n\t}\n\toffload->offdev = ondev->offdev;\n\tprog->aux->offload = offload;\n\tlist_add_tail(&offload->offloads, &ondev->progs);\n\tdev_put(offload->netdev);\n\tup_write(&bpf_devs_lock);\n\n\treturn 0;\nerr_unlock:\n\tup_write(&bpf_devs_lock);\nerr_maybe_put:\n\tif (offload->netdev)\n\t\tdev_put(offload->netdev);\n\tkfree(offload);\n\treturn err;\n}"
  },
  {
    "function_name": "bpf_offload_find_netdev",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "70-78",
    "snippet": "static struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DECLARE_RWSEM(bpf_devs_lock);",
      "static const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};",
      "static struct rhashtable offdevs;",
      "static bool offdevs_inited;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rhashtable_lookup_fast",
          "args": [
            "&offdevs",
            "&netdev",
            "offdevs_params"
          ],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&bpf_devs_lock"
          ],
          "line": 73
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic DECLARE_RWSEM(bpf_devs_lock);\nstatic const struct rhashtable_params offdevs_params = {\n\t.nelem_hint\t\t= 4,\n\t.key_len\t\t= sizeof(struct net_device *),\n\t.key_offset\t\t= offsetof(struct bpf_offload_netdev, netdev),\n\t.head_offset\t\t= offsetof(struct bpf_offload_netdev, l),\n\t.automatic_shrinking\t= true,\n};\nstatic struct rhashtable offdevs;\nstatic bool offdevs_inited;\n\nstatic struct bpf_offload_netdev *\nbpf_offload_find_netdev(struct net_device *netdev)\n{\n\tlockdep_assert_held(&bpf_devs_lock);\n\n\tif (!offdevs_inited)\n\t\treturn NULL;\n\treturn rhashtable_lookup_fast(&offdevs, &netdev, offdevs_params);\n}"
  },
  {
    "function_name": "bpf_dev_offload_check",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/offload.c",
    "lines": "61-68",
    "snippet": "static int bpf_dev_offload_check(struct net_device *netdev)\n{\n\tif (!netdev)\n\t\treturn -EINVAL;\n\tif (!netdev->netdev_ops->ndo_bpf)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}",
    "includes": [
      "#include <linux/rwsem.h>",
      "#include <linux/rtnetlink.h>",
      "#include <linux/rhashtable.h>",
      "#include <linux/proc_ns.h>",
      "#include <linux/printk.h>",
      "#include <linux/netdevice.h>",
      "#include <linux/lockdep.h>",
      "#include <linux/list.h>",
      "#include <linux/kdev_t.h>",
      "#include <linux/bug.h>",
      "#include <linux/bpf_verifier.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include <linux/rwsem.h>\n#include <linux/rtnetlink.h>\n#include <linux/rhashtable.h>\n#include <linux/proc_ns.h>\n#include <linux/printk.h>\n#include <linux/netdevice.h>\n#include <linux/lockdep.h>\n#include <linux/list.h>\n#include <linux/kdev_t.h>\n#include <linux/bug.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf.h>\n\nstatic int bpf_dev_offload_check(struct net_device *netdev)\n{\n\tif (!netdev)\n\t\treturn -EINVAL;\n\tif (!netdev->netdev_ops->ndo_bpf)\n\t\treturn -EOPNOTSUPP;\n\treturn 0;\n}"
  }
]