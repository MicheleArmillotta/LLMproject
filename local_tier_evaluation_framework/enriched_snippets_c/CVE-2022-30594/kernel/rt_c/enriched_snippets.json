[
  {
    "function_name": "print_rt_stats",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2993-3002",
    "snippet": "void print_rt_stats(struct seq_file *m, int cpu)\n{\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\trcu_read_lock();\n\tfor_each_rt_rq(rt_rq, iter, cpu_rq(cpu))\n\t\tprint_rt_rq(m, cpu, rt_rq);\n\trcu_read_unlock();\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 3001
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "print_rt_rq",
          "args": [
            "m",
            "cpu",
            "rt_rq"
          ],
          "line": 3000
        },
        "resolved": true,
        "details": {
          "function_name": "print_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/debug.c",
          "lines": "663-691",
          "snippet": "void print_rt_rq(struct seq_file *m, int cpu, struct rt_rq *rt_rq)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tSEQ_printf(m, \"\\n\");\n\tSEQ_printf_task_group_path(m, rt_rq->tg, \"rt_rq[%d]:%s\\n\", cpu);\n#else\n\tSEQ_printf(m, \"\\n\");\n\tSEQ_printf(m, \"rt_rq[%d]:\\n\", cpu);\n#endif\n\n#define P(x) \\\n\tSEQ_printf(m, \"  .%-30s: %Ld\\n\", #x, (long long)(rt_rq->x))\n#define PU(x) \\\n\tSEQ_printf(m, \"  .%-30s: %lu\\n\", #x, (unsigned long)(rt_rq->x))\n#define PN(x) \\\n\tSEQ_printf(m, \"  .%-30s: %Ld.%06ld\\n\", #x, SPLIT_NS(rt_rq->x))\n\n\tPU(rt_nr_running);\n#ifdef CONFIG_SMP\n\tPU(rt_nr_migratory);\n#endif\n\tP(rt_throttled);\n\tPN(rt_time);\n\tPN(rt_runtime);\n\n#undef PN\n#undef PU\n#undef P\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid print_rt_rq(struct seq_file *m, int cpu, struct rt_rq *rt_rq)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tSEQ_printf(m, \"\\n\");\n\tSEQ_printf_task_group_path(m, rt_rq->tg, \"rt_rq[%d]:%s\\n\", cpu);\n#else\n\tSEQ_printf(m, \"\\n\");\n\tSEQ_printf(m, \"rt_rq[%d]:\\n\", cpu);\n#endif\n\n#define P(x) \\\n\tSEQ_printf(m, \"  .%-30s: %Ld\\n\", #x, (long long)(rt_rq->x))\n#define PU(x) \\\n\tSEQ_printf(m, \"  .%-30s: %lu\\n\", #x, (unsigned long)(rt_rq->x))\n#define PN(x) \\\n\tSEQ_printf(m, \"  .%-30s: %Ld.%06ld\\n\", #x, SPLIT_NS(rt_rq->x))\n\n\tPU(rt_nr_running);\n#ifdef CONFIG_SMP\n\tPU(rt_nr_migratory);\n#endif\n\tP(rt_throttled);\n\tPN(rt_time);\n\tPN(rt_runtime);\n\n#undef PN\n#undef PU\n#undef P\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_rt_rq",
          "args": [
            "rt_rq",
            "iter",
            "cpu_rq(cpu)"
          ],
          "line": 2999
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 2999
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2998
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nvoid print_rt_stats(struct seq_file *m, int cpu)\n{\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\trcu_read_lock();\n\tfor_each_rt_rq(rt_rq, iter, cpu_rq(cpu))\n\t\tprint_rt_rq(m, cpu, rt_rq);\n\trcu_read_unlock();\n}"
  },
  {
    "function_name": "sched_rr_handler",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2970-2990",
    "snippet": "int sched_rr_handler(struct ctl_table *table, int write, void *buffer,\n\t\tsize_t *lenp, loff_t *ppos)\n{\n\tint ret;\n\tstatic DEFINE_MUTEX(mutex);\n\n\tmutex_lock(&mutex);\n\tret = proc_dointvec(table, write, buffer, lenp, ppos);\n\t/*\n\t * Make sure that internally we keep jiffies.\n\t * Also, writing zero resets the timeslice to default:\n\t */\n\tif (!ret && write) {\n\t\tsched_rr_timeslice =\n\t\t\tsysctl_sched_rr_timeslice <= 0 ? RR_TIMESLICE :\n\t\t\tmsecs_to_jiffies(sysctl_sched_rr_timeslice);\n\t}\n\tmutex_unlock(&mutex);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "int sched_rr_timeslice = RR_TIMESLICE;",
      "int sysctl_sched_rr_timeslice = (MSEC_PER_SEC / HZ) * RR_TIMESLICE;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&mutex"
          ],
          "line": 2987
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "msecs_to_jiffies",
          "args": [
            "sysctl_sched_rr_timeslice"
          ],
          "line": 2985
        },
        "resolved": true,
        "details": {
          "function_name": "__msecs_to_jiffies",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/time.c",
          "lines": "552-560",
          "snippet": "unsigned long __msecs_to_jiffies(const unsigned int m)\n{\n\t/*\n\t * Negative value, means infinite timeout:\n\t */\n\tif ((int)m < 0)\n\t\treturn MAX_JIFFY_OFFSET;\n\treturn _msecs_to_jiffies(m);\n}",
          "includes": [
            "#include \"timekeeping.h\"",
            "#include <generated/timeconst.h>",
            "#include <asm/unistd.h>",
            "#include <linux/compat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/math64.h>",
            "#include <linux/fs.h>",
            "#include <linux/security.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/errno.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/capability.h>",
            "#include <linux/timex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"timekeeping.h\"\n#include <generated/timeconst.h>\n#include <asm/unistd.h>\n#include <linux/compat.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/math64.h>\n#include <linux/fs.h>\n#include <linux/security.h>\n#include <linux/syscalls.h>\n#include <linux/errno.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/capability.h>\n#include <linux/timex.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nunsigned long __msecs_to_jiffies(const unsigned int m)\n{\n\t/*\n\t * Negative value, means infinite timeout:\n\t */\n\tif ((int)m < 0)\n\t\treturn MAX_JIFFY_OFFSET;\n\treturn _msecs_to_jiffies(m);\n}"
        }
      },
      {
        "call_info": {
          "callee": "proc_dointvec",
          "args": [
            "table",
            "write",
            "buffer",
            "lenp",
            "ppos"
          ],
          "line": 2977
        },
        "resolved": true,
        "details": {
          "function_name": "proc_dointvec_ms_jiffies",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sysctl.c",
          "lines": "1597-1601",
          "snippet": "int proc_dointvec_ms_jiffies(struct ctl_table *table, int write,\n\t\t\t     void *buffer, size_t *lenp, loff_t *ppos)\n{\n\treturn -ENOSYS;\n}",
          "includes": [
            "#include <linux/lockdep.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/acct.h>",
            "#include <asm/setup.h>",
            "#include <asm/io.h>",
            "#include <asm/stacktrace.h>",
            "#include <asm/nmi.h>",
            "#include <asm/processor.h>",
            "#include <linux/uaccess.h>",
            "#include \"../lib/kstrtox.h\"",
            "#include <linux/delayacct.h>",
            "#include <linux/pid.h>",
            "#include <linux/latencytop.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/mount.h>",
            "#include <linux/bpf.h>",
            "#include <linux/kexec.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/capability.h>",
            "#include <linux/kmod.h>",
            "#include <linux/oom.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/reboot.h>",
            "#include <linux/acpi.h>",
            "#include <linux/nfs_fs.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/dcache.h>",
            "#include <linux/limits.h>",
            "#include <linux/times.h>",
            "#include <linux/key.h>",
            "#include <linux/initrd.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/compaction.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/writeback.h>",
            "#include <linux/highuid.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/net.h>",
            "#include <linux/kobject.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init.h>",
            "#include <linux/fs.h>",
            "#include <linux/filter.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/ctype.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/printk.h>",
            "#include <linux/panic.h>",
            "#include <linux/signal.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/slab.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n#include <linux/rtmutex.h>\n#include <linux/acct.h>\n#include <asm/setup.h>\n#include <asm/io.h>\n#include <asm/stacktrace.h>\n#include <asm/nmi.h>\n#include <asm/processor.h>\n#include <linux/uaccess.h>\n#include \"../lib/kstrtox.h\"\n#include <linux/delayacct.h>\n#include <linux/pid.h>\n#include <linux/latencytop.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/mount.h>\n#include <linux/bpf.h>\n#include <linux/kexec.h>\n#include <linux/sched/sysctl.h>\n#include <linux/binfmts.h>\n#include <linux/capability.h>\n#include <linux/kmod.h>\n#include <linux/oom.h>\n#include <linux/perf_event.h>\n#include <linux/ftrace.h>\n#include <linux/reboot.h>\n#include <linux/acpi.h>\n#include <linux/nfs_fs.h>\n#include <linux/vmstat.h>\n#include <linux/syscalls.h>\n#include <linux/dcache.h>\n#include <linux/limits.h>\n#include <linux/times.h>\n#include <linux/key.h>\n#include <linux/initrd.h>\n#include <linux/hugetlb.h>\n#include <linux/compaction.h>\n#include <linux/ratelimit.h>\n#include <linux/writeback.h>\n#include <linux/highuid.h>\n#include <linux/sysrq.h>\n#include <linux/net.h>\n#include <linux/kobject.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n#include <linux/filter.h>\n#include <linux/kmemleak.h>\n#include <linux/ctype.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/printk.h>\n#include <linux/panic.h>\n#include <linux/signal.h>\n#include <linux/bitmap.h>\n#include <linux/sysctl.h>\n#include <linux/slab.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n\nint proc_dointvec_ms_jiffies(struct ctl_table *table, int write,\n\t\t\t     void *buffer, size_t *lenp, loff_t *ppos)\n{\n\treturn -ENOSYS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&mutex"
          ],
          "line": 2976
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_rr_timeslice = RR_TIMESLICE;\nint sysctl_sched_rr_timeslice = (MSEC_PER_SEC / HZ) * RR_TIMESLICE;\n\nint sched_rr_handler(struct ctl_table *table, int write, void *buffer,\n\t\tsize_t *lenp, loff_t *ppos)\n{\n\tint ret;\n\tstatic DEFINE_MUTEX(mutex);\n\n\tmutex_lock(&mutex);\n\tret = proc_dointvec(table, write, buffer, lenp, ppos);\n\t/*\n\t * Make sure that internally we keep jiffies.\n\t * Also, writing zero resets the timeslice to default:\n\t */\n\tif (!ret && write) {\n\t\tsched_rr_timeslice =\n\t\t\tsysctl_sched_rr_timeslice <= 0 ? RR_TIMESLICE :\n\t\t\tmsecs_to_jiffies(sysctl_sched_rr_timeslice);\n\t}\n\tmutex_unlock(&mutex);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "sched_rt_handler",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2931-2968",
    "snippet": "int sched_rt_handler(struct ctl_table *table, int write, void *buffer,\n\t\tsize_t *lenp, loff_t *ppos)\n{\n\tint old_period, old_runtime;\n\tstatic DEFINE_MUTEX(mutex);\n\tint ret;\n\n\tmutex_lock(&mutex);\n\told_period = sysctl_sched_rt_period;\n\told_runtime = sysctl_sched_rt_runtime;\n\n\tret = proc_dointvec(table, write, buffer, lenp, ppos);\n\n\tif (!ret && write) {\n\t\tret = sched_rt_global_validate();\n\t\tif (ret)\n\t\t\tgoto undo;\n\n\t\tret = sched_dl_global_validate();\n\t\tif (ret)\n\t\t\tgoto undo;\n\n\t\tret = sched_rt_global_constraints();\n\t\tif (ret)\n\t\t\tgoto undo;\n\n\t\tsched_rt_do_global();\n\t\tsched_dl_do_global();\n\t}\n\tif (0) {\nundo:\n\t\tsysctl_sched_rt_period = old_period;\n\t\tsysctl_sched_rt_runtime = old_runtime;\n\t}\n\tmutex_unlock(&mutex);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&mutex"
          ],
          "line": 2965
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_dl_do_global",
          "args": [],
          "line": 2958
        },
        "resolved": true,
        "details": {
          "function_name": "sched_dl_do_global",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/deadline.c",
          "lines": "2726-2757",
          "snippet": "void sched_dl_do_global(void)\n{\n\tu64 new_bw = -1;\n\tu64 gen = ++dl_generation;\n\tstruct dl_bw *dl_b;\n\tint cpu;\n\tunsigned long flags;\n\n\tdef_dl_bandwidth.dl_period = global_rt_period();\n\tdef_dl_bandwidth.dl_runtime = global_rt_runtime();\n\n\tif (global_rt_runtime() != RUNTIME_INF)\n\t\tnew_bw = to_ratio(global_rt_period(), global_rt_runtime());\n\n\tfor_each_possible_cpu(cpu) {\n\t\trcu_read_lock_sched();\n\n\t\tif (dl_bw_visited(cpu, gen)) {\n\t\t\trcu_read_unlock_sched();\n\t\t\tcontinue;\n\t\t}\n\n\t\tdl_b = dl_bw_of(cpu);\n\n\t\traw_spin_lock_irqsave(&dl_b->lock, flags);\n\t\tdl_b->bw = new_bw;\n\t\traw_spin_unlock_irqrestore(&dl_b->lock, flags);\n\n\t\trcu_read_unlock_sched();\n\t\tinit_dl_rq_bw_ratio(&cpu_rq(cpu)->dl);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct dl_bandwidth def_dl_bandwidth;",
            "static void enqueue_task_dl(struct rq *rq, struct task_struct *p, int flags);",
            "static void __dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags);",
            "static void check_preempt_curr_dl(struct rq *rq, struct task_struct *p, int flags);",
            "DEFINE_SCHED_CLASS(dl) = {\n\n\t.enqueue_task\t\t= enqueue_task_dl,\n\t.dequeue_task\t\t= dequeue_task_dl,\n\t.yield_task\t\t= yield_task_dl,\n\n\t.check_preempt_curr\t= check_preempt_curr_dl,\n\n\t.pick_next_task\t\t= pick_next_task_dl,\n\t.put_prev_task\t\t= put_prev_task_dl,\n\t.set_next_task\t\t= set_next_task_dl,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_dl,\n\t.pick_task\t\t= pick_task_dl,\n\t.select_task_rq\t\t= select_task_rq_dl,\n\t.migrate_task_rq\t= migrate_task_rq_dl,\n\t.set_cpus_allowed       = set_cpus_allowed_dl,\n\t.rq_online              = rq_online_dl,\n\t.rq_offline             = rq_offline_dl,\n\t.task_woken\t\t= task_woken_dl,\n\t.find_lock_rq\t\t= find_lock_later_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_dl,\n\t.task_fork              = task_fork_dl,\n\n\t.prio_changed           = prio_changed_dl,\n\t.switched_from\t\t= switched_from_dl,\n\t.switched_to\t\t= switched_to_dl,\n\n\t.update_curr\t\t= update_curr_dl,\n};",
            "static u64 dl_generation;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct dl_bandwidth def_dl_bandwidth;\nstatic void enqueue_task_dl(struct rq *rq, struct task_struct *p, int flags);\nstatic void __dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags);\nstatic void check_preempt_curr_dl(struct rq *rq, struct task_struct *p, int flags);\nDEFINE_SCHED_CLASS(dl) = {\n\n\t.enqueue_task\t\t= enqueue_task_dl,\n\t.dequeue_task\t\t= dequeue_task_dl,\n\t.yield_task\t\t= yield_task_dl,\n\n\t.check_preempt_curr\t= check_preempt_curr_dl,\n\n\t.pick_next_task\t\t= pick_next_task_dl,\n\t.put_prev_task\t\t= put_prev_task_dl,\n\t.set_next_task\t\t= set_next_task_dl,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_dl,\n\t.pick_task\t\t= pick_task_dl,\n\t.select_task_rq\t\t= select_task_rq_dl,\n\t.migrate_task_rq\t= migrate_task_rq_dl,\n\t.set_cpus_allowed       = set_cpus_allowed_dl,\n\t.rq_online              = rq_online_dl,\n\t.rq_offline             = rq_offline_dl,\n\t.task_woken\t\t= task_woken_dl,\n\t.find_lock_rq\t\t= find_lock_later_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_dl,\n\t.task_fork              = task_fork_dl,\n\n\t.prio_changed           = prio_changed_dl,\n\t.switched_from\t\t= switched_from_dl,\n\t.switched_to\t\t= switched_to_dl,\n\n\t.update_curr\t\t= update_curr_dl,\n};\nstatic u64 dl_generation;\n\nvoid sched_dl_do_global(void)\n{\n\tu64 new_bw = -1;\n\tu64 gen = ++dl_generation;\n\tstruct dl_bw *dl_b;\n\tint cpu;\n\tunsigned long flags;\n\n\tdef_dl_bandwidth.dl_period = global_rt_period();\n\tdef_dl_bandwidth.dl_runtime = global_rt_runtime();\n\n\tif (global_rt_runtime() != RUNTIME_INF)\n\t\tnew_bw = to_ratio(global_rt_period(), global_rt_runtime());\n\n\tfor_each_possible_cpu(cpu) {\n\t\trcu_read_lock_sched();\n\n\t\tif (dl_bw_visited(cpu, gen)) {\n\t\t\trcu_read_unlock_sched();\n\t\t\tcontinue;\n\t\t}\n\n\t\tdl_b = dl_bw_of(cpu);\n\n\t\traw_spin_lock_irqsave(&dl_b->lock, flags);\n\t\tdl_b->bw = new_bw;\n\t\traw_spin_unlock_irqrestore(&dl_b->lock, flags);\n\n\t\trcu_read_unlock_sched();\n\t\tinit_dl_rq_bw_ratio(&cpu_rq(cpu)->dl);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_do_global",
          "args": [],
          "line": 2957
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_do_global",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2921-2929",
          "snippet": "static void sched_rt_do_global(void)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tdef_rt_bandwidth.rt_runtime = global_rt_runtime();\n\tdef_rt_bandwidth.rt_period = ns_to_ktime(global_rt_period());\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct rt_bandwidth def_rt_bandwidth;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\n\nstatic void sched_rt_do_global(void)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tdef_rt_bandwidth.rt_runtime = global_rt_runtime();\n\tdef_rt_bandwidth.rt_period = ns_to_ktime(global_rt_period());\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_global_constraints",
          "args": [],
          "line": 2953
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_global_constraints",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2888-2904",
          "snippet": "static int sched_rt_global_constraints(void)\n{\n\tunsigned long flags;\n\tint i;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = &cpu_rq(i)->rt;\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = global_rt_runtime();\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct rt_bandwidth def_rt_bandwidth;",
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int sched_rt_global_constraints(void)\n{\n\tunsigned long flags;\n\tint i;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = &cpu_rq(i)->rt;\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = global_rt_runtime();\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_dl_global_validate",
          "args": [],
          "line": 2949
        },
        "resolved": true,
        "details": {
          "function_name": "sched_dl_global_validate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/deadline.c",
          "lines": "2674-2711",
          "snippet": "int sched_dl_global_validate(void)\n{\n\tu64 runtime = global_rt_runtime();\n\tu64 period = global_rt_period();\n\tu64 new_bw = to_ratio(period, runtime);\n\tu64 gen = ++dl_generation;\n\tstruct dl_bw *dl_b;\n\tint cpu, cpus, ret = 0;\n\tunsigned long flags;\n\n\t/*\n\t * Here we want to check the bandwidth not being set to some\n\t * value smaller than the currently allocated bandwidth in\n\t * any of the root_domains.\n\t */\n\tfor_each_possible_cpu(cpu) {\n\t\trcu_read_lock_sched();\n\n\t\tif (dl_bw_visited(cpu, gen))\n\t\t\tgoto next;\n\n\t\tdl_b = dl_bw_of(cpu);\n\t\tcpus = dl_bw_cpus(cpu);\n\n\t\traw_spin_lock_irqsave(&dl_b->lock, flags);\n\t\tif (new_bw * cpus < dl_b->total_bw)\n\t\t\tret = -EBUSY;\n\t\traw_spin_unlock_irqrestore(&dl_b->lock, flags);\n\nnext:\n\t\trcu_read_unlock_sched();\n\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_task_dl(struct rq *rq, struct task_struct *p, int flags);",
            "static void __dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags);",
            "static void check_preempt_curr_dl(struct rq *rq, struct task_struct *p, int flags);",
            "static u64 dl_generation;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_task_dl(struct rq *rq, struct task_struct *p, int flags);\nstatic void __dequeue_task_dl(struct rq *rq, struct task_struct *p, int flags);\nstatic void check_preempt_curr_dl(struct rq *rq, struct task_struct *p, int flags);\nstatic u64 dl_generation;\n\nint sched_dl_global_validate(void)\n{\n\tu64 runtime = global_rt_runtime();\n\tu64 period = global_rt_period();\n\tu64 new_bw = to_ratio(period, runtime);\n\tu64 gen = ++dl_generation;\n\tstruct dl_bw *dl_b;\n\tint cpu, cpus, ret = 0;\n\tunsigned long flags;\n\n\t/*\n\t * Here we want to check the bandwidth not being set to some\n\t * value smaller than the currently allocated bandwidth in\n\t * any of the root_domains.\n\t */\n\tfor_each_possible_cpu(cpu) {\n\t\trcu_read_lock_sched();\n\n\t\tif (dl_bw_visited(cpu, gen))\n\t\t\tgoto next;\n\n\t\tdl_b = dl_bw_of(cpu);\n\t\tcpus = dl_bw_cpus(cpu);\n\n\t\traw_spin_lock_irqsave(&dl_b->lock, flags);\n\t\tif (new_bw * cpus < dl_b->total_bw)\n\t\t\tret = -EBUSY;\n\t\traw_spin_unlock_irqrestore(&dl_b->lock, flags);\n\nnext:\n\t\trcu_read_unlock_sched();\n\n\t\tif (ret)\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_global_validate",
          "args": [],
          "line": 2945
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_global_validate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2907-2919",
          "snippet": "static int sched_rt_global_validate(void)\n{\n\tif (sysctl_sched_rt_period <= 0)\n\t\treturn -EINVAL;\n\n\tif ((sysctl_sched_rt_runtime != RUNTIME_INF) &&\n\t\t((sysctl_sched_rt_runtime > sysctl_sched_rt_period) ||\n\t\t ((u64)sysctl_sched_rt_runtime *\n\t\t\tNSEC_PER_USEC > max_rt_runtime)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static const u64 max_rt_runtime = MAX_BW;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic const u64 max_rt_runtime = MAX_BW;\n\nstatic int sched_rt_global_validate(void)\n{\n\tif (sysctl_sched_rt_period <= 0)\n\t\treturn -EINVAL;\n\n\tif ((sysctl_sched_rt_runtime != RUNTIME_INF) &&\n\t\t((sysctl_sched_rt_runtime > sysctl_sched_rt_period) ||\n\t\t ((u64)sysctl_sched_rt_runtime *\n\t\t\tNSEC_PER_USEC > max_rt_runtime)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "proc_dointvec",
          "args": [
            "table",
            "write",
            "buffer",
            "lenp",
            "ppos"
          ],
          "line": 2942
        },
        "resolved": true,
        "details": {
          "function_name": "proc_dointvec_ms_jiffies",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sysctl.c",
          "lines": "1597-1601",
          "snippet": "int proc_dointvec_ms_jiffies(struct ctl_table *table, int write,\n\t\t\t     void *buffer, size_t *lenp, loff_t *ppos)\n{\n\treturn -ENOSYS;\n}",
          "includes": [
            "#include <linux/lockdep.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/acct.h>",
            "#include <asm/setup.h>",
            "#include <asm/io.h>",
            "#include <asm/stacktrace.h>",
            "#include <asm/nmi.h>",
            "#include <asm/processor.h>",
            "#include <linux/uaccess.h>",
            "#include \"../lib/kstrtox.h\"",
            "#include <linux/delayacct.h>",
            "#include <linux/pid.h>",
            "#include <linux/latencytop.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/mount.h>",
            "#include <linux/bpf.h>",
            "#include <linux/kexec.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/capability.h>",
            "#include <linux/kmod.h>",
            "#include <linux/oom.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/reboot.h>",
            "#include <linux/acpi.h>",
            "#include <linux/nfs_fs.h>",
            "#include <linux/vmstat.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/dcache.h>",
            "#include <linux/limits.h>",
            "#include <linux/times.h>",
            "#include <linux/key.h>",
            "#include <linux/initrd.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/compaction.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/writeback.h>",
            "#include <linux/highuid.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/net.h>",
            "#include <linux/kobject.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init.h>",
            "#include <linux/fs.h>",
            "#include <linux/filter.h>",
            "#include <linux/kmemleak.h>",
            "#include <linux/ctype.h>",
            "#include <linux/security.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/printk.h>",
            "#include <linux/panic.h>",
            "#include <linux/signal.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/slab.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/module.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n#include <linux/rtmutex.h>\n#include <linux/acct.h>\n#include <asm/setup.h>\n#include <asm/io.h>\n#include <asm/stacktrace.h>\n#include <asm/nmi.h>\n#include <asm/processor.h>\n#include <linux/uaccess.h>\n#include \"../lib/kstrtox.h\"\n#include <linux/delayacct.h>\n#include <linux/pid.h>\n#include <linux/latencytop.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/mount.h>\n#include <linux/bpf.h>\n#include <linux/kexec.h>\n#include <linux/sched/sysctl.h>\n#include <linux/binfmts.h>\n#include <linux/capability.h>\n#include <linux/kmod.h>\n#include <linux/oom.h>\n#include <linux/perf_event.h>\n#include <linux/ftrace.h>\n#include <linux/reboot.h>\n#include <linux/acpi.h>\n#include <linux/nfs_fs.h>\n#include <linux/vmstat.h>\n#include <linux/syscalls.h>\n#include <linux/dcache.h>\n#include <linux/limits.h>\n#include <linux/times.h>\n#include <linux/key.h>\n#include <linux/initrd.h>\n#include <linux/hugetlb.h>\n#include <linux/compaction.h>\n#include <linux/ratelimit.h>\n#include <linux/writeback.h>\n#include <linux/highuid.h>\n#include <linux/sysrq.h>\n#include <linux/net.h>\n#include <linux/kobject.h>\n#include <linux/kernel.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n#include <linux/filter.h>\n#include <linux/kmemleak.h>\n#include <linux/ctype.h>\n#include <linux/security.h>\n#include <linux/proc_fs.h>\n#include <linux/printk.h>\n#include <linux/panic.h>\n#include <linux/signal.h>\n#include <linux/bitmap.h>\n#include <linux/sysctl.h>\n#include <linux/slab.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n\nint proc_dointvec_ms_jiffies(struct ctl_table *table, int write,\n\t\t\t     void *buffer, size_t *lenp, loff_t *ppos)\n{\n\treturn -ENOSYS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&mutex"
          ],
          "line": 2938
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_rt_handler(struct ctl_table *table, int write, void *buffer,\n\t\tsize_t *lenp, loff_t *ppos)\n{\n\tint old_period, old_runtime;\n\tstatic DEFINE_MUTEX(mutex);\n\tint ret;\n\n\tmutex_lock(&mutex);\n\told_period = sysctl_sched_rt_period;\n\told_runtime = sysctl_sched_rt_runtime;\n\n\tret = proc_dointvec(table, write, buffer, lenp, ppos);\n\n\tif (!ret && write) {\n\t\tret = sched_rt_global_validate();\n\t\tif (ret)\n\t\t\tgoto undo;\n\n\t\tret = sched_dl_global_validate();\n\t\tif (ret)\n\t\t\tgoto undo;\n\n\t\tret = sched_rt_global_constraints();\n\t\tif (ret)\n\t\t\tgoto undo;\n\n\t\tsched_rt_do_global();\n\t\tsched_dl_do_global();\n\t}\n\tif (0) {\nundo:\n\t\tsysctl_sched_rt_period = old_period;\n\t\tsysctl_sched_rt_runtime = old_runtime;\n\t}\n\tmutex_unlock(&mutex);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "sched_rt_do_global",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2921-2929",
    "snippet": "static void sched_rt_do_global(void)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tdef_rt_bandwidth.rt_runtime = global_rt_runtime();\n\tdef_rt_bandwidth.rt_period = ns_to_ktime(global_rt_period());\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct rt_bandwidth def_rt_bandwidth;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&def_rt_bandwidth.rt_runtime_lock",
            "flags"
          ],
          "line": 2928
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ns_to_ktime",
          "args": [
            "global_rt_period()"
          ],
          "line": 2927
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "global_rt_period",
          "args": [],
          "line": 2927
        },
        "resolved": true,
        "details": {
          "function_name": "global_rt_period",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2017-2020",
          "snippet": "static inline u64 global_rt_period(void)\n{\n\treturn (u64)sysctl_sched_rt_period * NSEC_PER_USEC;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline u64 global_rt_period(void)\n{\n\treturn (u64)sysctl_sched_rt_period * NSEC_PER_USEC;\n}"
        }
      },
      {
        "call_info": {
          "callee": "global_rt_runtime",
          "args": [],
          "line": 2926
        },
        "resolved": true,
        "details": {
          "function_name": "global_rt_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2022-2028",
          "snippet": "static inline u64 global_rt_runtime(void)\n{\n\tif (sysctl_sched_rt_runtime < 0)\n\t\treturn RUNTIME_INF;\n\n\treturn (u64)sysctl_sched_rt_runtime * NSEC_PER_USEC;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define RUNTIME_INF\t\t((u64)~0ULL)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define RUNTIME_INF\t\t((u64)~0ULL)\n\nstatic inline u64 global_rt_runtime(void)\n{\n\tif (sysctl_sched_rt_runtime < 0)\n\t\treturn RUNTIME_INF;\n\n\treturn (u64)sysctl_sched_rt_runtime * NSEC_PER_USEC;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&def_rt_bandwidth.rt_runtime_lock",
            "flags"
          ],
          "line": 2925
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\n\nstatic void sched_rt_do_global(void)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tdef_rt_bandwidth.rt_runtime = global_rt_runtime();\n\tdef_rt_bandwidth.rt_period = ns_to_ktime(global_rt_period());\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n}"
  },
  {
    "function_name": "sched_rt_global_validate",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2907-2919",
    "snippet": "static int sched_rt_global_validate(void)\n{\n\tif (sysctl_sched_rt_period <= 0)\n\t\treturn -EINVAL;\n\n\tif ((sysctl_sched_rt_runtime != RUNTIME_INF) &&\n\t\t((sysctl_sched_rt_runtime > sysctl_sched_rt_period) ||\n\t\t ((u64)sysctl_sched_rt_runtime *\n\t\t\tNSEC_PER_USEC > max_rt_runtime)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static const u64 max_rt_runtime = MAX_BW;"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic const u64 max_rt_runtime = MAX_BW;\n\nstatic int sched_rt_global_validate(void)\n{\n\tif (sysctl_sched_rt_period <= 0)\n\t\treturn -EINVAL;\n\n\tif ((sysctl_sched_rt_runtime != RUNTIME_INF) &&\n\t\t((sysctl_sched_rt_runtime > sysctl_sched_rt_period) ||\n\t\t ((u64)sysctl_sched_rt_runtime *\n\t\t\tNSEC_PER_USEC > max_rt_runtime)))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "sched_rt_global_constraints",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2888-2904",
    "snippet": "static int sched_rt_global_constraints(void)\n{\n\tunsigned long flags;\n\tint i;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = &cpu_rq(i)->rt;\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = global_rt_runtime();\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct rt_bandwidth def_rt_bandwidth;",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&def_rt_bandwidth.rt_runtime_lock",
            "flags"
          ],
          "line": 2901
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 2899
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "global_rt_runtime",
          "args": [],
          "line": 2898
        },
        "resolved": true,
        "details": {
          "function_name": "global_rt_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2022-2028",
          "snippet": "static inline u64 global_rt_runtime(void)\n{\n\tif (sysctl_sched_rt_runtime < 0)\n\t\treturn RUNTIME_INF;\n\n\treturn (u64)sysctl_sched_rt_runtime * NSEC_PER_USEC;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define RUNTIME_INF\t\t((u64)~0ULL)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define RUNTIME_INF\t\t((u64)~0ULL)\n\nstatic inline u64 global_rt_runtime(void)\n{\n\tif (sysctl_sched_rt_runtime < 0)\n\t\treturn RUNTIME_INF;\n\n\treturn (u64)sysctl_sched_rt_runtime * NSEC_PER_USEC;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 2897
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "i"
          ],
          "line": 2895
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&def_rt_bandwidth.rt_runtime_lock",
            "flags"
          ],
          "line": 2893
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int sched_rt_global_constraints(void)\n{\n\tunsigned long flags;\n\tint i;\n\n\traw_spin_lock_irqsave(&def_rt_bandwidth.rt_runtime_lock, flags);\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = &cpu_rq(i)->rt;\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = global_rt_runtime();\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irqrestore(&def_rt_bandwidth.rt_runtime_lock, flags);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "sched_rt_can_attach",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2878-2885",
    "snippet": "int sched_rt_can_attach(struct task_group *tg, struct task_struct *tsk)\n{\n\t/* Don't accept realtime tasks when there is no way for them to run */\n\tif (rt_task(tsk) && tg->rt_bandwidth.rt_runtime == 0)\n\t\treturn 0;\n\n\treturn 1;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "tsk"
          ],
          "line": 2881
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_rt_can_attach(struct task_group *tg, struct task_struct *tsk)\n{\n\t/* Don't accept realtime tasks when there is no way for them to run */\n\tif (rt_task(tsk) && tg->rt_bandwidth.rt_runtime == 0)\n\t\treturn 0;\n\n\treturn 1;\n}"
  },
  {
    "function_name": "sched_rt_global_constraints",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2867-2876",
    "snippet": "static int sched_rt_global_constraints(void)\n{\n\tint ret = 0;\n\n\tmutex_lock(&rt_constraints_mutex);\n\tret = __rt_schedulable(NULL, 0, 0);\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&rt_constraints_mutex"
          ],
          "line": 2873
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__rt_schedulable",
          "args": [
            "NULL",
            "0",
            "0"
          ],
          "line": 2872
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_schedulable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2757-2772",
          "snippet": "static int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)\n{\n\tint ret;\n\n\tstruct rt_schedulable_data data = {\n\t\t.tg = tg,\n\t\t.rt_period = period,\n\t\t.rt_runtime = runtime,\n\t};\n\n\trcu_read_lock();\n\tret = walk_tg_tree(tg_rt_schedulable, tg_nop, &data);\n\trcu_read_unlock();\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)\n{\n\tint ret;\n\n\tstruct rt_schedulable_data data = {\n\t\t.tg = tg,\n\t\t.rt_period = period,\n\t\t.rt_runtime = runtime,\n\t};\n\n\trcu_read_lock();\n\tret = walk_tg_tree(tg_rt_schedulable, tg_nop, &data);\n\trcu_read_unlock();\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&rt_constraints_mutex"
          ],
          "line": 2871
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int sched_rt_global_constraints(void)\n{\n\tint ret = 0;\n\n\tmutex_lock(&rt_constraints_mutex);\n\tret = __rt_schedulable(NULL, 0, 0);\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "sched_group_rt_period",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2858-2865",
    "snippet": "long sched_group_rt_period(struct task_group *tg)\n{\n\tu64 rt_period_us;\n\n\trt_period_us = ktime_to_ns(tg->rt_bandwidth.rt_period);\n\tdo_div(rt_period_us, NSEC_PER_USEC);\n\treturn rt_period_us;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "do_div",
          "args": [
            "rt_period_us",
            "NSEC_PER_USEC"
          ],
          "line": 2863
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "tg->rt_bandwidth.rt_period"
          ],
          "line": 2862
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nlong sched_group_rt_period(struct task_group *tg)\n{\n\tu64 rt_period_us;\n\n\trt_period_us = ktime_to_ns(tg->rt_bandwidth.rt_period);\n\tdo_div(rt_period_us, NSEC_PER_USEC);\n\treturn rt_period_us;\n}"
  },
  {
    "function_name": "sched_group_set_rt_period",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2845-2856",
    "snippet": "int sched_group_set_rt_period(struct task_group *tg, u64 rt_period_us)\n{\n\tu64 rt_runtime, rt_period;\n\n\tif (rt_period_us > U64_MAX / NSEC_PER_USEC)\n\t\treturn -EINVAL;\n\n\trt_period = rt_period_us * NSEC_PER_USEC;\n\trt_runtime = tg->rt_bandwidth.rt_runtime;\n\n\treturn tg_set_rt_bandwidth(tg, rt_period, rt_runtime);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "tg_set_rt_bandwidth",
          "args": [
            "tg",
            "rt_period",
            "rt_runtime"
          ],
          "line": 2855
        },
        "resolved": true,
        "details": {
          "function_name": "tg_set_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2774-2817",
          "snippet": "static int tg_set_rt_bandwidth(struct task_group *tg,\n\t\tu64 rt_period, u64 rt_runtime)\n{\n\tint i, err = 0;\n\n\t/*\n\t * Disallowing the root group RT runtime is BAD, it would disallow the\n\t * kernel creating (and or operating) RT threads.\n\t */\n\tif (tg == &root_task_group && rt_runtime == 0)\n\t\treturn -EINVAL;\n\n\t/* No period doesn't make any sense. */\n\tif (rt_period == 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Bound quota to defend quota against overflow during bandwidth shift.\n\t */\n\tif (rt_runtime != RUNTIME_INF && rt_runtime > max_rt_runtime)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&rt_constraints_mutex);\n\terr = __rt_schedulable(tg, rt_period, rt_runtime);\n\tif (err)\n\t\tgoto unlock;\n\n\traw_spin_lock_irq(&tg->rt_bandwidth.rt_runtime_lock);\n\ttg->rt_bandwidth.rt_period = ns_to_ktime(rt_period);\n\ttg->rt_bandwidth.rt_runtime = rt_runtime;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = tg->rt_rq[i];\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_runtime;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irq(&tg->rt_bandwidth.rt_runtime_lock);\nunlock:\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn err;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static const u64 max_rt_runtime = MAX_BW;",
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic const u64 max_rt_runtime = MAX_BW;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int tg_set_rt_bandwidth(struct task_group *tg,\n\t\tu64 rt_period, u64 rt_runtime)\n{\n\tint i, err = 0;\n\n\t/*\n\t * Disallowing the root group RT runtime is BAD, it would disallow the\n\t * kernel creating (and or operating) RT threads.\n\t */\n\tif (tg == &root_task_group && rt_runtime == 0)\n\t\treturn -EINVAL;\n\n\t/* No period doesn't make any sense. */\n\tif (rt_period == 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Bound quota to defend quota against overflow during bandwidth shift.\n\t */\n\tif (rt_runtime != RUNTIME_INF && rt_runtime > max_rt_runtime)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&rt_constraints_mutex);\n\terr = __rt_schedulable(tg, rt_period, rt_runtime);\n\tif (err)\n\t\tgoto unlock;\n\n\traw_spin_lock_irq(&tg->rt_bandwidth.rt_runtime_lock);\n\ttg->rt_bandwidth.rt_period = ns_to_ktime(rt_period);\n\ttg->rt_bandwidth.rt_runtime = rt_runtime;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = tg->rt_rq[i];\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_runtime;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irq(&tg->rt_bandwidth.rt_runtime_lock);\nunlock:\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn err;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_group_set_rt_period(struct task_group *tg, u64 rt_period_us)\n{\n\tu64 rt_runtime, rt_period;\n\n\tif (rt_period_us > U64_MAX / NSEC_PER_USEC)\n\t\treturn -EINVAL;\n\n\trt_period = rt_period_us * NSEC_PER_USEC;\n\trt_runtime = tg->rt_bandwidth.rt_runtime;\n\n\treturn tg_set_rt_bandwidth(tg, rt_period, rt_runtime);\n}"
  },
  {
    "function_name": "sched_group_rt_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2833-2843",
    "snippet": "long sched_group_rt_runtime(struct task_group *tg)\n{\n\tu64 rt_runtime_us;\n\n\tif (tg->rt_bandwidth.rt_runtime == RUNTIME_INF)\n\t\treturn -1;\n\n\trt_runtime_us = tg->rt_bandwidth.rt_runtime;\n\tdo_div(rt_runtime_us, NSEC_PER_USEC);\n\treturn rt_runtime_us;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "do_div",
          "args": [
            "rt_runtime_us",
            "NSEC_PER_USEC"
          ],
          "line": 2841
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nlong sched_group_rt_runtime(struct task_group *tg)\n{\n\tu64 rt_runtime_us;\n\n\tif (tg->rt_bandwidth.rt_runtime == RUNTIME_INF)\n\t\treturn -1;\n\n\trt_runtime_us = tg->rt_bandwidth.rt_runtime;\n\tdo_div(rt_runtime_us, NSEC_PER_USEC);\n\treturn rt_runtime_us;\n}"
  },
  {
    "function_name": "sched_group_set_rt_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2819-2831",
    "snippet": "int sched_group_set_rt_runtime(struct task_group *tg, long rt_runtime_us)\n{\n\tu64 rt_runtime, rt_period;\n\n\trt_period = ktime_to_ns(tg->rt_bandwidth.rt_period);\n\trt_runtime = (u64)rt_runtime_us * NSEC_PER_USEC;\n\tif (rt_runtime_us < 0)\n\t\trt_runtime = RUNTIME_INF;\n\telse if ((u64)rt_runtime_us > U64_MAX / NSEC_PER_USEC)\n\t\treturn -EINVAL;\n\n\treturn tg_set_rt_bandwidth(tg, rt_period, rt_runtime);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "tg_set_rt_bandwidth",
          "args": [
            "tg",
            "rt_period",
            "rt_runtime"
          ],
          "line": 2830
        },
        "resolved": true,
        "details": {
          "function_name": "tg_set_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2774-2817",
          "snippet": "static int tg_set_rt_bandwidth(struct task_group *tg,\n\t\tu64 rt_period, u64 rt_runtime)\n{\n\tint i, err = 0;\n\n\t/*\n\t * Disallowing the root group RT runtime is BAD, it would disallow the\n\t * kernel creating (and or operating) RT threads.\n\t */\n\tif (tg == &root_task_group && rt_runtime == 0)\n\t\treturn -EINVAL;\n\n\t/* No period doesn't make any sense. */\n\tif (rt_period == 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Bound quota to defend quota against overflow during bandwidth shift.\n\t */\n\tif (rt_runtime != RUNTIME_INF && rt_runtime > max_rt_runtime)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&rt_constraints_mutex);\n\terr = __rt_schedulable(tg, rt_period, rt_runtime);\n\tif (err)\n\t\tgoto unlock;\n\n\traw_spin_lock_irq(&tg->rt_bandwidth.rt_runtime_lock);\n\ttg->rt_bandwidth.rt_period = ns_to_ktime(rt_period);\n\ttg->rt_bandwidth.rt_runtime = rt_runtime;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = tg->rt_rq[i];\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_runtime;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irq(&tg->rt_bandwidth.rt_runtime_lock);\nunlock:\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn err;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static const u64 max_rt_runtime = MAX_BW;",
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic const u64 max_rt_runtime = MAX_BW;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int tg_set_rt_bandwidth(struct task_group *tg,\n\t\tu64 rt_period, u64 rt_runtime)\n{\n\tint i, err = 0;\n\n\t/*\n\t * Disallowing the root group RT runtime is BAD, it would disallow the\n\t * kernel creating (and or operating) RT threads.\n\t */\n\tif (tg == &root_task_group && rt_runtime == 0)\n\t\treturn -EINVAL;\n\n\t/* No period doesn't make any sense. */\n\tif (rt_period == 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Bound quota to defend quota against overflow during bandwidth shift.\n\t */\n\tif (rt_runtime != RUNTIME_INF && rt_runtime > max_rt_runtime)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&rt_constraints_mutex);\n\terr = __rt_schedulable(tg, rt_period, rt_runtime);\n\tif (err)\n\t\tgoto unlock;\n\n\traw_spin_lock_irq(&tg->rt_bandwidth.rt_runtime_lock);\n\ttg->rt_bandwidth.rt_period = ns_to_ktime(rt_period);\n\ttg->rt_bandwidth.rt_runtime = rt_runtime;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = tg->rt_rq[i];\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_runtime;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irq(&tg->rt_bandwidth.rt_runtime_lock);\nunlock:\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "tg->rt_bandwidth.rt_period"
          ],
          "line": 2823
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_group_set_rt_runtime(struct task_group *tg, long rt_runtime_us)\n{\n\tu64 rt_runtime, rt_period;\n\n\trt_period = ktime_to_ns(tg->rt_bandwidth.rt_period);\n\trt_runtime = (u64)rt_runtime_us * NSEC_PER_USEC;\n\tif (rt_runtime_us < 0)\n\t\trt_runtime = RUNTIME_INF;\n\telse if ((u64)rt_runtime_us > U64_MAX / NSEC_PER_USEC)\n\t\treturn -EINVAL;\n\n\treturn tg_set_rt_bandwidth(tg, rt_period, rt_runtime);\n}"
  },
  {
    "function_name": "tg_set_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2774-2817",
    "snippet": "static int tg_set_rt_bandwidth(struct task_group *tg,\n\t\tu64 rt_period, u64 rt_runtime)\n{\n\tint i, err = 0;\n\n\t/*\n\t * Disallowing the root group RT runtime is BAD, it would disallow the\n\t * kernel creating (and or operating) RT threads.\n\t */\n\tif (tg == &root_task_group && rt_runtime == 0)\n\t\treturn -EINVAL;\n\n\t/* No period doesn't make any sense. */\n\tif (rt_period == 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Bound quota to defend quota against overflow during bandwidth shift.\n\t */\n\tif (rt_runtime != RUNTIME_INF && rt_runtime > max_rt_runtime)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&rt_constraints_mutex);\n\terr = __rt_schedulable(tg, rt_period, rt_runtime);\n\tif (err)\n\t\tgoto unlock;\n\n\traw_spin_lock_irq(&tg->rt_bandwidth.rt_runtime_lock);\n\ttg->rt_bandwidth.rt_period = ns_to_ktime(rt_period);\n\ttg->rt_bandwidth.rt_runtime = rt_runtime;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = tg->rt_rq[i];\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_runtime;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irq(&tg->rt_bandwidth.rt_runtime_lock);\nunlock:\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn err;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static const u64 max_rt_runtime = MAX_BW;",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&rt_constraints_mutex"
          ],
          "line": 2814
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irq",
          "args": [
            "&tg->rt_bandwidth.rt_runtime_lock"
          ],
          "line": 2812
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "200-203",
          "snippet": "void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 2810
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 2808
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ns_to_ktime",
          "args": [
            "rt_period"
          ],
          "line": 2802
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irq",
          "args": [
            "&tg->rt_bandwidth.rt_runtime_lock"
          ],
          "line": 2801
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "168-171",
          "snippet": "void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__rt_schedulable",
          "args": [
            "tg",
            "rt_period",
            "rt_runtime"
          ],
          "line": 2797
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_schedulable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2757-2772",
          "snippet": "static int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)\n{\n\tint ret;\n\n\tstruct rt_schedulable_data data = {\n\t\t.tg = tg,\n\t\t.rt_period = period,\n\t\t.rt_runtime = runtime,\n\t};\n\n\trcu_read_lock();\n\tret = walk_tg_tree(tg_rt_schedulable, tg_nop, &data);\n\trcu_read_unlock();\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)\n{\n\tint ret;\n\n\tstruct rt_schedulable_data data = {\n\t\t.tg = tg,\n\t\t.rt_period = period,\n\t\t.rt_runtime = runtime,\n\t};\n\n\trcu_read_lock();\n\tret = walk_tg_tree(tg_rt_schedulable, tg_nop, &data);\n\trcu_read_unlock();\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&rt_constraints_mutex"
          ],
          "line": 2796
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic const u64 max_rt_runtime = MAX_BW;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int tg_set_rt_bandwidth(struct task_group *tg,\n\t\tu64 rt_period, u64 rt_runtime)\n{\n\tint i, err = 0;\n\n\t/*\n\t * Disallowing the root group RT runtime is BAD, it would disallow the\n\t * kernel creating (and or operating) RT threads.\n\t */\n\tif (tg == &root_task_group && rt_runtime == 0)\n\t\treturn -EINVAL;\n\n\t/* No period doesn't make any sense. */\n\tif (rt_period == 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Bound quota to defend quota against overflow during bandwidth shift.\n\t */\n\tif (rt_runtime != RUNTIME_INF && rt_runtime > max_rt_runtime)\n\t\treturn -EINVAL;\n\n\tmutex_lock(&rt_constraints_mutex);\n\terr = __rt_schedulable(tg, rt_period, rt_runtime);\n\tif (err)\n\t\tgoto unlock;\n\n\traw_spin_lock_irq(&tg->rt_bandwidth.rt_runtime_lock);\n\ttg->rt_bandwidth.rt_period = ns_to_ktime(rt_period);\n\ttg->rt_bandwidth.rt_runtime = rt_runtime;\n\n\tfor_each_possible_cpu(i) {\n\t\tstruct rt_rq *rt_rq = tg->rt_rq[i];\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_runtime;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t}\n\traw_spin_unlock_irq(&tg->rt_bandwidth.rt_runtime_lock);\nunlock:\n\tmutex_unlock(&rt_constraints_mutex);\n\n\treturn err;\n}"
  },
  {
    "function_name": "__rt_schedulable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2757-2772",
    "snippet": "static int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)\n{\n\tint ret;\n\n\tstruct rt_schedulable_data data = {\n\t\t.tg = tg,\n\t\t.rt_period = period,\n\t\t.rt_runtime = runtime,\n\t};\n\n\trcu_read_lock();\n\tret = walk_tg_tree(tg_rt_schedulable, tg_nop, &data);\n\trcu_read_unlock();\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 2769
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "walk_tg_tree",
          "args": [
            "tg_rt_schedulable",
            "tg_nop",
            "&data"
          ],
          "line": 2768
        },
        "resolved": true,
        "details": {
          "function_name": "walk_tg_tree",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "471-474",
          "snippet": "static inline int walk_tg_tree(tg_visitor down, tg_visitor up, void *data)\n{\n\treturn walk_tg_tree_from(&root_task_group, down, up, data);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline int walk_tg_tree(tg_visitor down, tg_visitor up, void *data)\n{\n\treturn walk_tg_tree_from(&root_task_group, down, up, data);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 2767
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int __rt_schedulable(struct task_group *tg, u64 period, u64 runtime)\n{\n\tint ret;\n\n\tstruct rt_schedulable_data data = {\n\t\t.tg = tg,\n\t\t.rt_period = period,\n\t\t.rt_runtime = runtime,\n\t};\n\n\trcu_read_lock();\n\tret = walk_tg_tree(tg_rt_schedulable, tg_nop, &data);\n\trcu_read_unlock();\n\n\treturn ret;\n}"
  },
  {
    "function_name": "tg_rt_schedulable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2700-2755",
    "snippet": "static int tg_rt_schedulable(struct task_group *tg, void *data)\n{\n\tstruct rt_schedulable_data *d = data;\n\tstruct task_group *child;\n\tunsigned long total, sum = 0;\n\tu64 period, runtime;\n\n\tperiod = ktime_to_ns(tg->rt_bandwidth.rt_period);\n\truntime = tg->rt_bandwidth.rt_runtime;\n\n\tif (tg == d->tg) {\n\t\tperiod = d->rt_period;\n\t\truntime = d->rt_runtime;\n\t}\n\n\t/*\n\t * Cannot have more runtime than the period.\n\t */\n\tif (runtime > period && runtime != RUNTIME_INF)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Ensure we don't starve existing RT tasks if runtime turns zero.\n\t */\n\tif (rt_bandwidth_enabled() && !runtime &&\n\t    tg->rt_bandwidth.rt_runtime && tg_has_rt_tasks(tg))\n\t\treturn -EBUSY;\n\n\ttotal = to_ratio(period, runtime);\n\n\t/*\n\t * Nobody can have more than the global setting allows.\n\t */\n\tif (total > to_ratio(global_rt_period(), global_rt_runtime()))\n\t\treturn -EINVAL;\n\n\t/*\n\t * The sum of our children's runtime should not exceed our own.\n\t */\n\tlist_for_each_entry_rcu(child, &tg->children, siblings) {\n\t\tperiod = ktime_to_ns(child->rt_bandwidth.rt_period);\n\t\truntime = child->rt_bandwidth.rt_runtime;\n\n\t\tif (child == d->tg) {\n\t\t\tperiod = d->rt_period;\n\t\t\truntime = d->rt_runtime;\n\t\t}\n\n\t\tsum += to_ratio(period, runtime);\n\t}\n\n\tif (sum > total)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "to_ratio",
          "args": [
            "period",
            "runtime"
          ],
          "line": 2748
        },
        "resolved": true,
        "details": {
          "function_name": "to_ratio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4468-4482",
          "snippet": "unsigned long to_ratio(u64 period, u64 runtime)\n{\n\tif (runtime == RUNTIME_INF)\n\t\treturn BW_UNIT;\n\n\t/*\n\t * Doing this here saves a lot of checks in all\n\t * the calling paths, and returning zero seems\n\t * safe for them anyway.\n\t */\n\tif (period == 0)\n\t\treturn 0;\n\n\treturn div64_u64(runtime << BW_SHIFT, period);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nunsigned long to_ratio(u64 period, u64 runtime)\n{\n\tif (runtime == RUNTIME_INF)\n\t\treturn BW_UNIT;\n\n\t/*\n\t * Doing this here saves a lot of checks in all\n\t * the calling paths, and returning zero seems\n\t * safe for them anyway.\n\t */\n\tif (period == 0)\n\t\treturn 0;\n\n\treturn div64_u64(runtime << BW_SHIFT, period);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "child->rt_bandwidth.rt_period"
          ],
          "line": 2740
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_rcu",
          "args": [
            "child",
            "&tg->children",
            "siblings"
          ],
          "line": 2739
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "global_rt_runtime",
          "args": [],
          "line": 2733
        },
        "resolved": true,
        "details": {
          "function_name": "global_rt_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2022-2028",
          "snippet": "static inline u64 global_rt_runtime(void)\n{\n\tif (sysctl_sched_rt_runtime < 0)\n\t\treturn RUNTIME_INF;\n\n\treturn (u64)sysctl_sched_rt_runtime * NSEC_PER_USEC;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define RUNTIME_INF\t\t((u64)~0ULL)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define RUNTIME_INF\t\t((u64)~0ULL)\n\nstatic inline u64 global_rt_runtime(void)\n{\n\tif (sysctl_sched_rt_runtime < 0)\n\t\treturn RUNTIME_INF;\n\n\treturn (u64)sysctl_sched_rt_runtime * NSEC_PER_USEC;\n}"
        }
      },
      {
        "call_info": {
          "callee": "global_rt_period",
          "args": [],
          "line": 2733
        },
        "resolved": true,
        "details": {
          "function_name": "global_rt_period",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2017-2020",
          "snippet": "static inline u64 global_rt_period(void)\n{\n\treturn (u64)sysctl_sched_rt_period * NSEC_PER_USEC;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline u64 global_rt_period(void)\n{\n\treturn (u64)sysctl_sched_rt_period * NSEC_PER_USEC;\n}"
        }
      },
      {
        "call_info": {
          "callee": "tg_has_rt_tasks",
          "args": [
            "tg"
          ],
          "line": 2725
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_bandwidth_enabled",
          "args": [],
          "line": 2724
        },
        "resolved": true,
        "details": {
          "function_name": "rt_bandwidth_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "630-633",
          "snippet": "static inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "tg->rt_bandwidth.rt_period"
          ],
          "line": 2707
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int tg_rt_schedulable(struct task_group *tg, void *data)\n{\n\tstruct rt_schedulable_data *d = data;\n\tstruct task_group *child;\n\tunsigned long total, sum = 0;\n\tu64 period, runtime;\n\n\tperiod = ktime_to_ns(tg->rt_bandwidth.rt_period);\n\truntime = tg->rt_bandwidth.rt_runtime;\n\n\tif (tg == d->tg) {\n\t\tperiod = d->rt_period;\n\t\truntime = d->rt_runtime;\n\t}\n\n\t/*\n\t * Cannot have more runtime than the period.\n\t */\n\tif (runtime > period && runtime != RUNTIME_INF)\n\t\treturn -EINVAL;\n\n\t/*\n\t * Ensure we don't starve existing RT tasks if runtime turns zero.\n\t */\n\tif (rt_bandwidth_enabled() && !runtime &&\n\t    tg->rt_bandwidth.rt_runtime && tg_has_rt_tasks(tg))\n\t\treturn -EBUSY;\n\n\ttotal = to_ratio(period, runtime);\n\n\t/*\n\t * Nobody can have more than the global setting allows.\n\t */\n\tif (total > to_ratio(global_rt_period(), global_rt_runtime()))\n\t\treturn -EINVAL;\n\n\t/*\n\t * The sum of our children's runtime should not exceed our own.\n\t */\n\tlist_for_each_entry_rcu(child, &tg->children, siblings) {\n\t\tperiod = ktime_to_ns(child->rt_bandwidth.rt_period);\n\t\truntime = child->rt_bandwidth.rt_runtime;\n\n\t\tif (child == d->tg) {\n\t\t\tperiod = d->rt_period;\n\t\t\truntime = d->rt_runtime;\n\t\t}\n\n\t\tsum += to_ratio(period, runtime);\n\t}\n\n\tif (sum > total)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "tg_has_rt_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2674-2692",
    "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "css_task_iter_end",
          "args": [
            "&it"
          ],
          "line": 2689
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4761-4775",
          "snippet": "void css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nvoid css_task_iter_end(struct css_task_iter *it)\n{\n\tif (it->cur_cset) {\n\t\tspin_lock_irq(&css_set_lock);\n\t\tlist_del(&it->iters_node);\n\t\tput_css_set_locked(it->cur_cset);\n\t\tspin_unlock_irq(&css_set_lock);\n\t}\n\n\tif (it->cur_dcset)\n\t\tput_css_set(it->cur_dcset);\n\n\tif (it->cur_task)\n\t\tput_task_struct(it->cur_task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "task"
          ],
          "line": 2688
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_next",
          "args": [
            "&it"
          ],
          "line": 2687
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_next",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4730-4753",
          "snippet": "struct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\nstruct task_struct *css_task_iter_next(struct css_task_iter *it)\n{\n\tif (it->cur_task) {\n\t\tput_task_struct(it->cur_task);\n\t\tit->cur_task = NULL;\n\t}\n\n\tspin_lock_irq(&css_set_lock);\n\n\t/* @it may be half-advanced by skips, finish advancing */\n\tif (it->flags & CSS_TASK_ITER_SKIPPED)\n\t\tcss_task_iter_advance(it);\n\n\tif (it->task_pos) {\n\t\tit->cur_task = list_entry(it->task_pos, struct task_struct,\n\t\t\t\t\t  cg_list);\n\t\tget_task_struct(it->cur_task);\n\t\tcss_task_iter_advance(it);\n\t}\n\n\tspin_unlock_irq(&css_set_lock);\n\n\treturn it->cur_task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "css_task_iter_start",
          "args": [
            "&tg->css",
            "0",
            "&it"
          ],
          "line": 2686
        },
        "resolved": true,
        "details": {
          "function_name": "css_task_iter_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/cgroup.c",
          "lines": "4700-4720",
          "snippet": "void css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}",
          "includes": [
            "#include <linux/cgroup_subsys.h>",
            "#include <linux/cgroup_subsys.h>",
            "#include <trace/events/cgroup.h>",
            "#include <net/sock.h>",
            "#include <linux/psi.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/file.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/atomic.h>",
            "#include <linux/kthread.h>",
            "#include <linux/idr.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/string.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mount.h>",
            "#include <linux/mutex.h>",
            "#include <linux/magic.h>",
            "#include <linux/kernel.h>",
            "#include <linux/init_task.h>",
            "#include <linux/errno.h>",
            "#include <linux/cred.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [
            "#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)"
          ],
          "globals_used": [
            "static struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);",
            "static void kill_css(struct cgroup_subsys_state *css);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/cgroup_subsys.h>\n#include <linux/cgroup_subsys.h>\n#include <trace/events/cgroup.h>\n#include <net/sock.h>\n#include <linux/psi.h>\n#include <linux/sched/cputime.h>\n#include <linux/fs_parser.h>\n#include <linux/file.h>\n#include <linux/nsproxy.h>\n#include <linux/proc_ns.h>\n#include <linux/cpuset.h>\n#include <linux/atomic.h>\n#include <linux/kthread.h>\n#include <linux/idr.h>\n#include <linux/hashtable.h>\n#include <linux/string.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/spinlock.h>\n#include <linux/slab.h>\n#include <linux/sched/task.h>\n#include <linux/sched.h>\n#include <linux/rcupdate.h>\n#include <linux/proc_fs.h>\n#include <linux/pagemap.h>\n#include <linux/mount.h>\n#include <linux/mutex.h>\n#include <linux/magic.h>\n#include <linux/kernel.h>\n#include <linux/init_task.h>\n#include <linux/errno.h>\n#include <linux/cred.h>\n#include <linux/bpf-cgroup.h>\n#include \"cgroup-internal.h\"\n\n#define CGROUP_HAS_SUBSYS_CONFIG\t(CGROUP_SUBSYS_COUNT > 0)\n\nstatic struct cgroup_subsys_state *css_create(struct cgroup *cgrp,\n\t\t\t\t\t      struct cgroup_subsys *ss);\nstatic void kill_css(struct cgroup_subsys_state *css);\n\nvoid css_task_iter_start(struct cgroup_subsys_state *css, unsigned int flags,\n\t\t\t struct css_task_iter *it)\n{\n\tmemset(it, 0, sizeof(*it));\n\n\tspin_lock_irq(&css_set_lock);\n\n\tit->ss = css->ss;\n\tit->flags = flags;\n\n\tif (CGROUP_HAS_SUBSYS_CONFIG && it->ss)\n\t\tit->cset_pos = &css->cgroup->e_csets[css->ss->id];\n\telse\n\t\tit->cset_pos = &css->cgroup->cset_links;\n\n\tit->cset_head = it->cset_pos;\n\n\tcss_task_iter_advance(it);\n\n\tspin_unlock_irq(&css_set_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_group_is_autogroup",
          "args": [
            "tg"
          ],
          "line": 2683
        },
        "resolved": true,
        "details": {
          "function_name": "task_group_is_autogroup",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/autogroup.h",
          "lines": "44-47",
          "snippet": "static inline bool task_group_is_autogroup(struct task_group *tg)\n{\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline bool task_group_is_autogroup(struct task_group *tg)\n{\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "get_rr_interval_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2619-2628",
    "snippet": "static unsigned int get_rr_interval_rt(struct rq *rq, struct task_struct *task)\n{\n\t/*\n\t * Time slice is 0 for SCHED_FIFO tasks\n\t */\n\tif (task->policy == SCHED_RR)\n\t\treturn sched_rr_timeslice;\n\telse\n\t\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "int sched_rr_timeslice = RR_TIMESLICE;"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_rr_timeslice = RR_TIMESLICE;\n\nstatic unsigned int get_rr_interval_rt(struct rq *rq, struct task_struct *task)\n{\n\t/*\n\t * Time slice is 0 for SCHED_FIFO tasks\n\t */\n\tif (task->policy == SCHED_RR)\n\t\treturn sched_rr_timeslice;\n\telse\n\t\treturn 0;\n}"
  },
  {
    "function_name": "task_tick_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2585-2617",
    "snippet": "static void task_tick_rt(struct rq *rq, struct task_struct *p, int queued)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\n\tupdate_curr_rt(rq);\n\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 1);\n\n\twatchdog(rq, p);\n\n\t/*\n\t * RR tasks need a special form of timeslice management.\n\t * FIFO tasks have no timeslices.\n\t */\n\tif (p->policy != SCHED_RR)\n\t\treturn;\n\n\tif (--p->rt.time_slice)\n\t\treturn;\n\n\tp->rt.time_slice = sched_rr_timeslice;\n\n\t/*\n\t * Requeue to the end of queue if we (and all of our ancestors) are not\n\t * the only element on the queue\n\t */\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tif (rt_se->run_list.prev != rt_se->run_list.next) {\n\t\t\trequeue_task_rt(rq, p, 0);\n\t\t\tresched_curr(rq);\n\t\t\treturn;\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "int sched_rr_timeslice = RR_TIMESLICE;",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 2613
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "requeue_task_rt",
          "args": [
            "rq",
            "p",
            "0"
          ],
          "line": 2612
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_task_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1543-1552",
          "snippet": "static void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "watchdog",
          "args": [
            "rq",
            "p"
          ],
          "line": 2592
        },
        "resolved": true,
        "details": {
          "function_name": "watchdog",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2574-2574",
          "snippet": "static inline void watchdog(struct rq *rq, struct task_struct *p) { }",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void watchdog(struct rq *rq, struct task_struct *p) { }"
        }
      },
      {
        "call_info": {
          "callee": "update_rt_rq_load_avg",
          "args": [
            "rq_clock_pelt(rq)",
            "rq",
            "1"
          ],
          "line": 2590
        },
        "resolved": true,
        "details": {
          "function_name": "update_rt_rq_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "165-169",
          "snippet": "static inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock_pelt",
          "args": [
            "rq"
          ],
          "line": 2590
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      },
      {
        "call_info": {
          "callee": "update_curr_rt",
          "args": [
            "rq"
          ],
          "line": 2589
        },
        "resolved": true,
        "details": {
          "function_name": "update_curr_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1008-1052",
          "snippet": "static void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint sched_rr_timeslice = RR_TIMESLICE;\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void task_tick_rt(struct rq *rq, struct task_struct *p, int queued)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\n\tupdate_curr_rt(rq);\n\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 1);\n\n\twatchdog(rq, p);\n\n\t/*\n\t * RR tasks need a special form of timeslice management.\n\t * FIFO tasks have no timeslices.\n\t */\n\tif (p->policy != SCHED_RR)\n\t\treturn;\n\n\tif (--p->rt.time_slice)\n\t\treturn;\n\n\tp->rt.time_slice = sched_rr_timeslice;\n\n\t/*\n\t * Requeue to the end of queue if we (and all of our ancestors) are not\n\t * the only element on the queue\n\t */\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tif (rt_se->run_list.prev != rt_se->run_list.next) {\n\t\t\trequeue_task_rt(rq, p, 0);\n\t\t\tresched_curr(rq);\n\t\t\treturn;\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "watchdog",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2574-2574",
    "snippet": "static inline void watchdog(struct rq *rq, struct task_struct *p) { }",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void watchdog(struct rq *rq, struct task_struct *p) { }"
  },
  {
    "function_name": "watchdog",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2550-2572",
    "snippet": "static void watchdog(struct rq *rq, struct task_struct *p)\n{\n\tunsigned long soft, hard;\n\n\t/* max may change after cur was read, this will be fixed next tick */\n\tsoft = task_rlimit(p, RLIMIT_RTTIME);\n\thard = task_rlimit_max(p, RLIMIT_RTTIME);\n\n\tif (soft != RLIM_INFINITY) {\n\t\tunsigned long next;\n\n\t\tif (p->rt.watchdog_stamp != jiffies) {\n\t\t\tp->rt.timeout++;\n\t\t\tp->rt.watchdog_stamp = jiffies;\n\t\t}\n\n\t\tnext = DIV_ROUND_UP(min(soft, hard), USEC_PER_SEC/HZ);\n\t\tif (p->rt.timeout > next) {\n\t\t\tposix_cputimers_rt_watchdog(&p->posix_cputimers,\n\t\t\t\t\t\t    p->se.sum_exec_runtime);\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "posix_cputimers_rt_watchdog",
          "args": [
            "&p->posix_cputimers",
            "p->se.sum_exec_runtime"
          ],
          "line": 2568
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DIV_ROUND_UP",
          "args": [
            "min(soft, hard)",
            "USEC_PER_SEC/HZ"
          ],
          "line": 2566
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "soft",
            "hard"
          ],
          "line": 2566
        },
        "resolved": true,
        "details": {
          "function_name": "wrap_min",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "249-252",
          "snippet": "static inline u64 wrap_min(u64 x, u64 y)\n{\n\treturn (s64)(x - y) < 0 ? x : y;\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic inline u64 wrap_min(u64 x, u64 y)\n{\n\treturn (s64)(x - y) < 0 ? x : y;\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_rlimit_max",
          "args": [
            "p",
            "RLIMIT_RTTIME"
          ],
          "line": 2556
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_rlimit",
          "args": [
            "p",
            "RLIMIT_RTTIME"
          ],
          "line": 2555
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void watchdog(struct rq *rq, struct task_struct *p)\n{\n\tunsigned long soft, hard;\n\n\t/* max may change after cur was read, this will be fixed next tick */\n\tsoft = task_rlimit(p, RLIMIT_RTTIME);\n\thard = task_rlimit_max(p, RLIMIT_RTTIME);\n\n\tif (soft != RLIM_INFINITY) {\n\t\tunsigned long next;\n\n\t\tif (p->rt.watchdog_stamp != jiffies) {\n\t\t\tp->rt.timeout++;\n\t\t\tp->rt.watchdog_stamp = jiffies;\n\t\t}\n\n\t\tnext = DIV_ROUND_UP(min(soft, hard), USEC_PER_SEC/HZ);\n\t\tif (p->rt.timeout > next) {\n\t\t\tposix_cputimers_rt_watchdog(&p->posix_cputimers,\n\t\t\t\t\t\t    p->se.sum_exec_runtime);\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "prio_changed_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2512-2547",
    "snippet": "static void\nprio_changed_rt(struct rq *rq, struct task_struct *p, int oldprio)\n{\n\tif (!task_on_rq_queued(p))\n\t\treturn;\n\n\tif (task_current(rq, p)) {\n#ifdef CONFIG_SMP\n\t\t/*\n\t\t * If our priority decreases while running, we\n\t\t * may need to pull tasks to this runqueue.\n\t\t */\n\t\tif (oldprio < p->prio)\n\t\t\trt_queue_pull_task(rq);\n\n\t\t/*\n\t\t * If there's a higher priority task waiting to run\n\t\t * then reschedule.\n\t\t */\n\t\tif (p->prio > rq->rt.highest_prio.curr)\n\t\t\tresched_curr(rq);\n#else\n\t\t/* For UP simply resched on drop of prio */\n\t\tif (oldprio < p->prio)\n\t\t\tresched_curr(rq);\n#endif /* CONFIG_SMP */\n\t} else {\n\t\t/*\n\t\t * This task is not running, but if it is\n\t\t * greater than the current running task\n\t\t * then reschedule.\n\t\t */\n\t\tif (p->prio < rq->curr->prio)\n\t\t\tresched_curr(rq);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 2545
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_queue_pull_task",
          "args": [
            "rq"
          ],
          "line": 2525
        },
        "resolved": true,
        "details": {
          "function_name": "rt_queue_pull_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "382-385",
          "snippet": "static inline void rt_queue_pull_task(struct rq *rq)\n{\n\tqueue_balance_callback(rq, &per_cpu(rt_pull_head, rq->cpu), pull_rt_task);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_pull_task(struct rq *rq)\n{\n\tqueue_balance_callback(rq, &per_cpu(rt_pull_head, rq->cpu), pull_rt_task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_current",
          "args": [
            "rq",
            "p"
          ],
          "line": 2518
        },
        "resolved": true,
        "details": {
          "function_name": "task_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2030-2033",
          "snippet": "static inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_on_rq_queued",
          "args": [
            "p"
          ],
          "line": 2515
        },
        "resolved": true,
        "details": {
          "function_name": "task_on_rq_queued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2044-2047",
          "snippet": "static inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define TASK_ON_RQ_QUEUED\t1"
          ],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define TASK_ON_RQ_QUEUED\t1\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nprio_changed_rt(struct rq *rq, struct task_struct *p, int oldprio)\n{\n\tif (!task_on_rq_queued(p))\n\t\treturn;\n\n\tif (task_current(rq, p)) {\n#ifdef CONFIG_SMP\n\t\t/*\n\t\t * If our priority decreases while running, we\n\t\t * may need to pull tasks to this runqueue.\n\t\t */\n\t\tif (oldprio < p->prio)\n\t\t\trt_queue_pull_task(rq);\n\n\t\t/*\n\t\t * If there's a higher priority task waiting to run\n\t\t * then reschedule.\n\t\t */\n\t\tif (p->prio > rq->rt.highest_prio.curr)\n\t\t\tresched_curr(rq);\n#else\n\t\t/* For UP simply resched on drop of prio */\n\t\tif (oldprio < p->prio)\n\t\t\tresched_curr(rq);\n#endif /* CONFIG_SMP */\n\t} else {\n\t\t/*\n\t\t * This task is not running, but if it is\n\t\t * greater than the current running task\n\t\t * then reschedule.\n\t\t */\n\t\tif (p->prio < rq->curr->prio)\n\t\t\tresched_curr(rq);\n\t}\n}"
  },
  {
    "function_name": "switched_to_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2482-2506",
    "snippet": "static void switched_to_rt(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * If we are running, update the avg_rt tracking, as the running time\n\t * will now on be accounted into the latter.\n\t */\n\tif (task_current(rq, p)) {\n\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);\n\t\treturn;\n\t}\n\n\t/*\n\t * If we are not running we may need to preempt the current\n\t * running task. If that current running task is also an RT task\n\t * then see if we can move to another run queue.\n\t */\n\tif (task_on_rq_queued(p)) {\n#ifdef CONFIG_SMP\n\t\tif (p->nr_cpus_allowed > 1 && rq->rt.overloaded)\n\t\t\trt_queue_push_tasks(rq);\n#endif /* CONFIG_SMP */\n\t\tif (p->prio < rq->curr->prio && cpu_online(cpu_of(rq)))\n\t\t\tresched_curr(rq);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 2504
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_online",
          "args": [
            "cpu_of(rq)"
          ],
          "line": 2503
        },
        "resolved": true,
        "details": {
          "function_name": "init_cpu_online",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "2616-2619",
          "snippet": "void init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "struct cpumask __cpu_online_mask"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nstruct cpumask __cpu_online_mask;\n\nvoid init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_of",
          "args": [
            "rq"
          ],
          "line": 2503
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1137-1144",
          "snippet": "static inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void resched_cpu(int cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void resched_cpu(int cpu);\n\nstatic inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_queue_push_tasks",
          "args": [
            "rq"
          ],
          "line": 2501
        },
        "resolved": true,
        "details": {
          "function_name": "rt_queue_push_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "441-443",
          "snippet": "static inline void rt_queue_push_tasks(struct rq *rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_push_tasks(struct rq *rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_on_rq_queued",
          "args": [
            "p"
          ],
          "line": 2498
        },
        "resolved": true,
        "details": {
          "function_name": "task_on_rq_queued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2044-2047",
          "snippet": "static inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define TASK_ON_RQ_QUEUED\t1"
          ],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define TASK_ON_RQ_QUEUED\t1\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_rt_rq_load_avg",
          "args": [
            "rq_clock_pelt(rq)",
            "rq",
            "0"
          ],
          "line": 2489
        },
        "resolved": true,
        "details": {
          "function_name": "update_rt_rq_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "165-169",
          "snippet": "static inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock_pelt",
          "args": [
            "rq"
          ],
          "line": 2489
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      },
      {
        "call_info": {
          "callee": "task_current",
          "args": [
            "rq",
            "p"
          ],
          "line": 2488
        },
        "resolved": true,
        "details": {
          "function_name": "task_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2030-2033",
          "snippet": "static inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void switched_to_rt(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * If we are running, update the avg_rt tracking, as the running time\n\t * will now on be accounted into the latter.\n\t */\n\tif (task_current(rq, p)) {\n\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);\n\t\treturn;\n\t}\n\n\t/*\n\t * If we are not running we may need to preempt the current\n\t * running task. If that current running task is also an RT task\n\t * then see if we can move to another run queue.\n\t */\n\tif (task_on_rq_queued(p)) {\n#ifdef CONFIG_SMP\n\t\tif (p->nr_cpus_allowed > 1 && rq->rt.overloaded)\n\t\t\trt_queue_push_tasks(rq);\n#endif /* CONFIG_SMP */\n\t\tif (p->prio < rq->curr->prio && cpu_online(cpu_of(rq)))\n\t\t\tresched_curr(rq);\n\t}\n}"
  },
  {
    "function_name": "init_sched_rt_class",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2466-2474",
    "snippet": "void __init init_sched_rt_class(void)\n{\n\tunsigned int i;\n\n\tfor_each_possible_cpu(i) {\n\t\tzalloc_cpumask_var_node(&per_cpu(local_cpu_mask, i),\n\t\t\t\t\tGFP_KERNEL, cpu_to_node(i));\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "zalloc_cpumask_var_node",
          "args": [
            "&per_cpu(local_cpu_mask, i)",
            "GFP_KERNEL",
            "cpu_to_node(i)"
          ],
          "line": 2471
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "i"
          ],
          "line": 2472
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "local_cpu_mask",
            "i"
          ],
          "line": 2471
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_set_per_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "588-603",
          "snippet": "void kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nvoid __init init_sched_rt_class(void)\n{\n\tunsigned int i;\n\n\tfor_each_possible_cpu(i) {\n\t\tzalloc_cpumask_var_node(&per_cpu(local_cpu_mask, i),\n\t\t\t\t\tGFP_KERNEL, cpu_to_node(i));\n\t}\n}"
  },
  {
    "function_name": "switched_from_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2451-2464",
    "snippet": "static void switched_from_rt(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * If there are other RT tasks then we will reschedule\n\t * and the scheduling of the other RT tasks will handle\n\t * the balancing. But if we are the last RT task\n\t * we may need to handle the pulling of RT tasks\n\t * now.\n\t */\n\tif (!task_on_rq_queued(p) || rq->rt.rt_nr_running)\n\t\treturn;\n\n\trt_queue_pull_task(rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_queue_pull_task",
          "args": [
            "rq"
          ],
          "line": 2463
        },
        "resolved": true,
        "details": {
          "function_name": "rt_queue_pull_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "382-385",
          "snippet": "static inline void rt_queue_pull_task(struct rq *rq)\n{\n\tqueue_balance_callback(rq, &per_cpu(rt_pull_head, rq->cpu), pull_rt_task);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_pull_task(struct rq *rq)\n{\n\tqueue_balance_callback(rq, &per_cpu(rt_pull_head, rq->cpu), pull_rt_task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_on_rq_queued",
          "args": [
            "p"
          ],
          "line": 2460
        },
        "resolved": true,
        "details": {
          "function_name": "task_on_rq_queued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2044-2047",
          "snippet": "static inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define TASK_ON_RQ_QUEUED\t1"
          ],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define TASK_ON_RQ_QUEUED\t1\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void switched_from_rt(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * If there are other RT tasks then we will reschedule\n\t * and the scheduling of the other RT tasks will handle\n\t * the balancing. But if we are the last RT task\n\t * we may need to handle the pulling of RT tasks\n\t * now.\n\t */\n\tif (!task_on_rq_queued(p) || rq->rt.rt_nr_running)\n\t\treturn;\n\n\trt_queue_pull_task(rq);\n}"
  },
  {
    "function_name": "rq_offline_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2437-2445",
    "snippet": "static void rq_offline_rt(struct rq *rq)\n{\n\tif (rq->rt.overloaded)\n\t\trt_clear_overload(rq);\n\n\t__disable_runtime(rq);\n\n\tcpupri_set(&rq->rd->cpupri, rq->cpu, CPUPRI_INVALID);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpupri_set",
          "args": [
            "&rq->rd->cpupri",
            "rq->cpu",
            "CPUPRI_INVALID"
          ],
          "line": 2444
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "210-270",
          "snippet": "void cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__disable_runtime",
          "args": [
            "rq"
          ],
          "line": 2442
        },
        "resolved": true,
        "details": {
          "function_name": "__disable_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "744-824",
          "snippet": "static void __disable_runtime(struct rq *rq)\n{\n\tstruct root_domain *rd = rq->rd;\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\t\ts64 want;\n\t\tint i;\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * Either we're all inf and nobody needs to borrow, or we're\n\t\t * already disabled and thus have nothing to do, or we have\n\t\t * exactly the right amount of runtime to take out.\n\t\t */\n\t\tif (rt_rq->rt_runtime == RUNTIME_INF ||\n\t\t\t\trt_rq->rt_runtime == rt_b->rt_runtime)\n\t\t\tgoto balanced;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\n\t\t/*\n\t\t * Calculate the difference between what we started out with\n\t\t * and what we current have, that's the amount of runtime\n\t\t * we lend and now have to reclaim.\n\t\t */\n\t\twant = rt_b->rt_runtime - rt_rq->rt_runtime;\n\n\t\t/*\n\t\t * Greedy reclaim, take back as much as we can.\n\t\t */\n\t\tfor_each_cpu(i, rd->span) {\n\t\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\t\ts64 diff;\n\n\t\t\t/*\n\t\t\t * Can't reclaim from ourselves or disabled runqueues.\n\t\t\t */\n\t\t\tif (iter == rt_rq || iter->rt_runtime == RUNTIME_INF)\n\t\t\t\tcontinue;\n\n\t\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t\tif (want > 0) {\n\t\t\t\tdiff = min_t(s64, iter->rt_runtime, want);\n\t\t\t\titer->rt_runtime -= diff;\n\t\t\t\twant -= diff;\n\t\t\t} else {\n\t\t\t\titer->rt_runtime -= want;\n\t\t\t\twant -= want;\n\t\t\t}\n\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\n\t\t\tif (!want)\n\t\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * We cannot be left wanting - that would mean some runtime\n\t\t * leaked out of the system.\n\t\t */\n\t\tBUG_ON(want);\nbalanced:\n\t\t/*\n\t\t * Disable all the borrow logic by pretending we have inf\n\t\t * runtime - in which case borrowing doesn't make sense.\n\t\t */\n\t\trt_rq->rt_runtime = RUNTIME_INF;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\n\t\t/* Make rt_rq available for pick_next_task() */\n\t\tsched_rt_rq_enqueue(rt_rq);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __disable_runtime(struct rq *rq)\n{\n\tstruct root_domain *rd = rq->rd;\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\t\ts64 want;\n\t\tint i;\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * Either we're all inf and nobody needs to borrow, or we're\n\t\t * already disabled and thus have nothing to do, or we have\n\t\t * exactly the right amount of runtime to take out.\n\t\t */\n\t\tif (rt_rq->rt_runtime == RUNTIME_INF ||\n\t\t\t\trt_rq->rt_runtime == rt_b->rt_runtime)\n\t\t\tgoto balanced;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\n\t\t/*\n\t\t * Calculate the difference between what we started out with\n\t\t * and what we current have, that's the amount of runtime\n\t\t * we lend and now have to reclaim.\n\t\t */\n\t\twant = rt_b->rt_runtime - rt_rq->rt_runtime;\n\n\t\t/*\n\t\t * Greedy reclaim, take back as much as we can.\n\t\t */\n\t\tfor_each_cpu(i, rd->span) {\n\t\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\t\ts64 diff;\n\n\t\t\t/*\n\t\t\t * Can't reclaim from ourselves or disabled runqueues.\n\t\t\t */\n\t\t\tif (iter == rt_rq || iter->rt_runtime == RUNTIME_INF)\n\t\t\t\tcontinue;\n\n\t\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t\tif (want > 0) {\n\t\t\t\tdiff = min_t(s64, iter->rt_runtime, want);\n\t\t\t\titer->rt_runtime -= diff;\n\t\t\t\twant -= diff;\n\t\t\t} else {\n\t\t\t\titer->rt_runtime -= want;\n\t\t\t\twant -= want;\n\t\t\t}\n\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\n\t\t\tif (!want)\n\t\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * We cannot be left wanting - that would mean some runtime\n\t\t * leaked out of the system.\n\t\t */\n\t\tBUG_ON(want);\nbalanced:\n\t\t/*\n\t\t * Disable all the borrow logic by pretending we have inf\n\t\t * runtime - in which case borrowing doesn't make sense.\n\t\t */\n\t\trt_rq->rt_runtime = RUNTIME_INF;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\n\t\t/* Make rt_rq available for pick_next_task() */\n\t\tsched_rt_rq_enqueue(rt_rq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_clear_overload",
          "args": [
            "rq"
          ],
          "line": 2440
        },
        "resolved": true,
        "details": {
          "function_name": "rt_clear_overload",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "306-314",
          "snippet": "static inline void rt_clear_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\t/* the order here really doesn't matter */\n\tatomic_dec(&rq->rd->rto_count);\n\tcpumask_clear_cpu(rq->cpu, rq->rd->rto_mask);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_clear_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\t/* the order here really doesn't matter */\n\tatomic_dec(&rq->rd->rto_count);\n\tcpumask_clear_cpu(rq->cpu, rq->rd->rto_mask);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void rq_offline_rt(struct rq *rq)\n{\n\tif (rq->rt.overloaded)\n\t\trt_clear_overload(rq);\n\n\t__disable_runtime(rq);\n\n\tcpupri_set(&rq->rd->cpupri, rq->cpu, CPUPRI_INVALID);\n}"
  },
  {
    "function_name": "rq_online_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2426-2434",
    "snippet": "static void rq_online_rt(struct rq *rq)\n{\n\tif (rq->rt.overloaded)\n\t\trt_set_overload(rq);\n\n\t__enable_runtime(rq);\n\n\tcpupri_set(&rq->rd->cpupri, rq->cpu, rq->rt.highest_prio.curr);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpupri_set",
          "args": [
            "&rq->rd->cpupri",
            "rq->cpu",
            "rq->rt.highest_prio.curr"
          ],
          "line": 2433
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "210-270",
          "snippet": "void cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__enable_runtime",
          "args": [
            "rq"
          ],
          "line": 2431
        },
        "resolved": true,
        "details": {
          "function_name": "__enable_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "826-848",
          "snippet": "static void __enable_runtime(struct rq *rq)\n{\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\t/*\n\t * Reset each runqueue's bandwidth settings\n\t */\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\trt_rq->rt_time = 0;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __enable_runtime(struct rq *rq)\n{\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\t/*\n\t * Reset each runqueue's bandwidth settings\n\t */\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\trt_rq->rt_time = 0;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_set_overload",
          "args": [
            "rq"
          ],
          "line": 2429
        },
        "resolved": true,
        "details": {
          "function_name": "rt_set_overload",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "287-304",
          "snippet": "static inline void rt_set_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\tcpumask_set_cpu(rq->cpu, rq->rd->rto_mask);\n\t/*\n\t * Make sure the mask is visible before we set\n\t * the overload count. That is checked to determine\n\t * if we should look at the mask. It would be a shame\n\t * if we looked at the mask, but the mask was not\n\t * updated yet.\n\t *\n\t * Matched by the barrier in pull_rt_task().\n\t */\n\tsmp_wmb();\n\tatomic_inc(&rq->rd->rto_count);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_set_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\tcpumask_set_cpu(rq->cpu, rq->rd->rto_mask);\n\t/*\n\t * Make sure the mask is visible before we set\n\t * the overload count. That is checked to determine\n\t * if we should look at the mask. It would be a shame\n\t * if we looked at the mask, but the mask was not\n\t * updated yet.\n\t *\n\t * Matched by the barrier in pull_rt_task().\n\t */\n\tsmp_wmb();\n\tatomic_inc(&rq->rd->rto_count);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void rq_online_rt(struct rq *rq)\n{\n\tif (rq->rt.overloaded)\n\t\trt_set_overload(rq);\n\n\t__enable_runtime(rq);\n\n\tcpupri_set(&rq->rd->cpupri, rq->cpu, rq->rt.highest_prio.curr);\n}"
  },
  {
    "function_name": "task_woken_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2412-2423",
    "snippet": "static void task_woken_rt(struct rq *rq, struct task_struct *p)\n{\n\tbool need_to_push = !task_running(rq, p) &&\n\t\t\t    !test_tsk_need_resched(rq->curr) &&\n\t\t\t    p->nr_cpus_allowed > 1 &&\n\t\t\t    (dl_task(rq->curr) || rt_task(rq->curr)) &&\n\t\t\t    (rq->curr->nr_cpus_allowed < 2 ||\n\t\t\t     rq->curr->prio <= p->prio);\n\n\tif (need_to_push)\n\t\tpush_rt_tasks(rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "push_rt_tasks",
          "args": [
            "rq"
          ],
          "line": 2422
        },
        "resolved": true,
        "details": {
          "function_name": "push_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2121-2126",
          "snippet": "static void push_rt_tasks(struct rq *rq)\n{\n\t/* push_rt_task will return true if it moved an RT */\n\twhile (push_rt_task(rq, false))\n\t\t;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void push_rt_tasks(struct rq *rq)\n{\n\t/* push_rt_task will return true if it moved an RT */\n\twhile (push_rt_task(rq, false))\n\t\t;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "rq->curr"
          ],
          "line": 2417
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "dl_task",
          "args": [
            "rq->curr"
          ],
          "line": 2417
        },
        "resolved": true,
        "details": {
          "function_name": "pull_dl_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/deadline.c",
          "lines": "2320-2410",
          "snippet": "static void pull_dl_task(struct rq *this_rq)\n{\n\tint this_cpu = this_rq->cpu, cpu;\n\tstruct task_struct *p, *push_task;\n\tbool resched = false;\n\tstruct rq *src_rq;\n\tu64 dmin = LONG_MAX;\n\n\tif (likely(!dl_overloaded(this_rq)))\n\t\treturn;\n\n\t/*\n\t * Match the barrier from dl_set_overloaded; this guarantees that if we\n\t * see overloaded we must also see the dlo_mask bit.\n\t */\n\tsmp_rmb();\n\n\tfor_each_cpu(cpu, this_rq->rd->dlo_mask) {\n\t\tif (this_cpu == cpu)\n\t\t\tcontinue;\n\n\t\tsrc_rq = cpu_rq(cpu);\n\n\t\t/*\n\t\t * It looks racy, abd it is! However, as in sched_rt.c,\n\t\t * we are fine with this.\n\t\t */\n\t\tif (this_rq->dl.dl_nr_running &&\n\t\t    dl_time_before(this_rq->dl.earliest_dl.curr,\n\t\t\t\t   src_rq->dl.earliest_dl.next))\n\t\t\tcontinue;\n\n\t\t/* Might drop this_rq->lock */\n\t\tpush_task = NULL;\n\t\tdouble_lock_balance(this_rq, src_rq);\n\n\t\t/*\n\t\t * If there are no more pullable tasks on the\n\t\t * rq, we're done with it.\n\t\t */\n\t\tif (src_rq->dl.dl_nr_running <= 1)\n\t\t\tgoto skip;\n\n\t\tp = pick_earliest_pushable_dl_task(src_rq, this_cpu);\n\n\t\t/*\n\t\t * We found a task to be pulled if:\n\t\t *  - it preempts our current (if there's one),\n\t\t *  - it will preempt the last one we pulled (if any).\n\t\t */\n\t\tif (p && dl_time_before(p->dl.deadline, dmin) &&\n\t\t    (!this_rq->dl.dl_nr_running ||\n\t\t     dl_time_before(p->dl.deadline,\n\t\t\t\t    this_rq->dl.earliest_dl.curr))) {\n\t\t\tWARN_ON(p == src_rq->curr);\n\t\t\tWARN_ON(!task_on_rq_queued(p));\n\n\t\t\t/*\n\t\t\t * Then we pull iff p has actually an earlier\n\t\t\t * deadline than the current task of its runqueue.\n\t\t\t */\n\t\t\tif (dl_time_before(p->dl.deadline,\n\t\t\t\t\t   src_rq->curr->dl.deadline))\n\t\t\t\tgoto skip;\n\n\t\t\tif (is_migration_disabled(p)) {\n\t\t\t\tpush_task = get_push_task(src_rq);\n\t\t\t} else {\n\t\t\t\tdeactivate_task(src_rq, p, 0);\n\t\t\t\tset_task_cpu(p, this_cpu);\n\t\t\t\tactivate_task(this_rq, p, 0);\n\t\t\t\tdmin = p->dl.deadline;\n\t\t\t\tresched = true;\n\t\t\t}\n\n\t\t\t/* Is there any other task even earlier? */\n\t\t}\nskip:\n\t\tdouble_unlock_balance(this_rq, src_rq);\n\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(this_rq);\n\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &src_rq->push_work);\n\t\t\traw_spin_rq_lock(this_rq);\n\t\t}\n\t}\n\n\tif (resched)\n\t\tresched_curr(this_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(dl) = {\n\n\t.enqueue_task\t\t= enqueue_task_dl,\n\t.dequeue_task\t\t= dequeue_task_dl,\n\t.yield_task\t\t= yield_task_dl,\n\n\t.check_preempt_curr\t= check_preempt_curr_dl,\n\n\t.pick_next_task\t\t= pick_next_task_dl,\n\t.put_prev_task\t\t= put_prev_task_dl,\n\t.set_next_task\t\t= set_next_task_dl,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_dl,\n\t.pick_task\t\t= pick_task_dl,\n\t.select_task_rq\t\t= select_task_rq_dl,\n\t.migrate_task_rq\t= migrate_task_rq_dl,\n\t.set_cpus_allowed       = set_cpus_allowed_dl,\n\t.rq_online              = rq_online_dl,\n\t.rq_offline             = rq_offline_dl,\n\t.task_woken\t\t= task_woken_dl,\n\t.find_lock_rq\t\t= find_lock_later_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_dl,\n\t.task_fork              = task_fork_dl,\n\n\t.prio_changed           = prio_changed_dl,\n\t.switched_from\t\t= switched_from_dl,\n\t.switched_to\t\t= switched_to_dl,\n\n\t.update_curr\t\t= update_curr_dl,\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(dl) = {\n\n\t.enqueue_task\t\t= enqueue_task_dl,\n\t.dequeue_task\t\t= dequeue_task_dl,\n\t.yield_task\t\t= yield_task_dl,\n\n\t.check_preempt_curr\t= check_preempt_curr_dl,\n\n\t.pick_next_task\t\t= pick_next_task_dl,\n\t.put_prev_task\t\t= put_prev_task_dl,\n\t.set_next_task\t\t= set_next_task_dl,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_dl,\n\t.pick_task\t\t= pick_task_dl,\n\t.select_task_rq\t\t= select_task_rq_dl,\n\t.migrate_task_rq\t= migrate_task_rq_dl,\n\t.set_cpus_allowed       = set_cpus_allowed_dl,\n\t.rq_online              = rq_online_dl,\n\t.rq_offline             = rq_offline_dl,\n\t.task_woken\t\t= task_woken_dl,\n\t.find_lock_rq\t\t= find_lock_later_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_dl,\n\t.task_fork              = task_fork_dl,\n\n\t.prio_changed           = prio_changed_dl,\n\t.switched_from\t\t= switched_from_dl,\n\t.switched_to\t\t= switched_to_dl,\n\n\t.update_curr\t\t= update_curr_dl,\n};\n\nstatic void pull_dl_task(struct rq *this_rq)\n{\n\tint this_cpu = this_rq->cpu, cpu;\n\tstruct task_struct *p, *push_task;\n\tbool resched = false;\n\tstruct rq *src_rq;\n\tu64 dmin = LONG_MAX;\n\n\tif (likely(!dl_overloaded(this_rq)))\n\t\treturn;\n\n\t/*\n\t * Match the barrier from dl_set_overloaded; this guarantees that if we\n\t * see overloaded we must also see the dlo_mask bit.\n\t */\n\tsmp_rmb();\n\n\tfor_each_cpu(cpu, this_rq->rd->dlo_mask) {\n\t\tif (this_cpu == cpu)\n\t\t\tcontinue;\n\n\t\tsrc_rq = cpu_rq(cpu);\n\n\t\t/*\n\t\t * It looks racy, abd it is! However, as in sched_rt.c,\n\t\t * we are fine with this.\n\t\t */\n\t\tif (this_rq->dl.dl_nr_running &&\n\t\t    dl_time_before(this_rq->dl.earliest_dl.curr,\n\t\t\t\t   src_rq->dl.earliest_dl.next))\n\t\t\tcontinue;\n\n\t\t/* Might drop this_rq->lock */\n\t\tpush_task = NULL;\n\t\tdouble_lock_balance(this_rq, src_rq);\n\n\t\t/*\n\t\t * If there are no more pullable tasks on the\n\t\t * rq, we're done with it.\n\t\t */\n\t\tif (src_rq->dl.dl_nr_running <= 1)\n\t\t\tgoto skip;\n\n\t\tp = pick_earliest_pushable_dl_task(src_rq, this_cpu);\n\n\t\t/*\n\t\t * We found a task to be pulled if:\n\t\t *  - it preempts our current (if there's one),\n\t\t *  - it will preempt the last one we pulled (if any).\n\t\t */\n\t\tif (p && dl_time_before(p->dl.deadline, dmin) &&\n\t\t    (!this_rq->dl.dl_nr_running ||\n\t\t     dl_time_before(p->dl.deadline,\n\t\t\t\t    this_rq->dl.earliest_dl.curr))) {\n\t\t\tWARN_ON(p == src_rq->curr);\n\t\t\tWARN_ON(!task_on_rq_queued(p));\n\n\t\t\t/*\n\t\t\t * Then we pull iff p has actually an earlier\n\t\t\t * deadline than the current task of its runqueue.\n\t\t\t */\n\t\t\tif (dl_time_before(p->dl.deadline,\n\t\t\t\t\t   src_rq->curr->dl.deadline))\n\t\t\t\tgoto skip;\n\n\t\t\tif (is_migration_disabled(p)) {\n\t\t\t\tpush_task = get_push_task(src_rq);\n\t\t\t} else {\n\t\t\t\tdeactivate_task(src_rq, p, 0);\n\t\t\t\tset_task_cpu(p, this_cpu);\n\t\t\t\tactivate_task(this_rq, p, 0);\n\t\t\t\tdmin = p->dl.deadline;\n\t\t\t\tresched = true;\n\t\t\t}\n\n\t\t\t/* Is there any other task even earlier? */\n\t\t}\nskip:\n\t\tdouble_unlock_balance(this_rq, src_rq);\n\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(this_rq);\n\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &src_rq->push_work);\n\t\t\traw_spin_rq_lock(this_rq);\n\t\t}\n\t}\n\n\tif (resched)\n\t\tresched_curr(this_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "test_tsk_need_resched",
          "args": [
            "rq->curr"
          ],
          "line": 2415
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_running",
          "args": [
            "rq",
            "p"
          ],
          "line": 2414
        },
        "resolved": true,
        "details": {
          "function_name": "task_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2035-2042",
          "snippet": "static inline int task_running(struct rq *rq, struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->on_cpu;\n#else\n\treturn task_current(rq, p);\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_running(struct rq *rq, struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->on_cpu;\n#else\n\treturn task_current(rq, p);\n#endif\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void task_woken_rt(struct rq *rq, struct task_struct *p)\n{\n\tbool need_to_push = !task_running(rq, p) &&\n\t\t\t    !test_tsk_need_resched(rq->curr) &&\n\t\t\t    p->nr_cpus_allowed > 1 &&\n\t\t\t    (dl_task(rq->curr) || rt_task(rq->curr)) &&\n\t\t\t    (rq->curr->nr_cpus_allowed < 2 ||\n\t\t\t     rq->curr->prio <= p->prio);\n\n\tif (need_to_push)\n\t\tpush_rt_tasks(rq);\n}"
  },
  {
    "function_name": "pull_rt_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2299-2406",
    "snippet": "static void pull_rt_task(struct rq *this_rq)\n{\n\tint this_cpu = this_rq->cpu, cpu;\n\tbool resched = false;\n\tstruct task_struct *p, *push_task;\n\tstruct rq *src_rq;\n\tint rt_overload_count = rt_overloaded(this_rq);\n\n\tif (likely(!rt_overload_count))\n\t\treturn;\n\n\t/*\n\t * Match the barrier from rt_set_overloaded; this guarantees that if we\n\t * see overloaded we must also see the rto_mask bit.\n\t */\n\tsmp_rmb();\n\n\t/* If we are the only overloaded CPU do nothing */\n\tif (rt_overload_count == 1 &&\n\t    cpumask_test_cpu(this_rq->cpu, this_rq->rd->rto_mask))\n\t\treturn;\n\n#ifdef HAVE_RT_PUSH_IPI\n\tif (sched_feat(RT_PUSH_IPI)) {\n\t\ttell_cpu_to_push(this_rq);\n\t\treturn;\n\t}\n#endif\n\n\tfor_each_cpu(cpu, this_rq->rd->rto_mask) {\n\t\tif (this_cpu == cpu)\n\t\t\tcontinue;\n\n\t\tsrc_rq = cpu_rq(cpu);\n\n\t\t/*\n\t\t * Don't bother taking the src_rq->lock if the next highest\n\t\t * task is known to be lower-priority than our current task.\n\t\t * This may look racy, but if this value is about to go\n\t\t * logically higher, the src_rq will push this task away.\n\t\t * And if its going logically lower, we do not care\n\t\t */\n\t\tif (src_rq->rt.highest_prio.next >=\n\t\t    this_rq->rt.highest_prio.curr)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We can potentially drop this_rq's lock in\n\t\t * double_lock_balance, and another CPU could\n\t\t * alter this_rq\n\t\t */\n\t\tpush_task = NULL;\n\t\tdouble_lock_balance(this_rq, src_rq);\n\n\t\t/*\n\t\t * We can pull only a task, which is pushable\n\t\t * on its rq, and no others.\n\t\t */\n\t\tp = pick_highest_pushable_task(src_rq, this_cpu);\n\n\t\t/*\n\t\t * Do we have an RT task that preempts\n\t\t * the to-be-scheduled task?\n\t\t */\n\t\tif (p && (p->prio < this_rq->rt.highest_prio.curr)) {\n\t\t\tWARN_ON(p == src_rq->curr);\n\t\t\tWARN_ON(!task_on_rq_queued(p));\n\n\t\t\t/*\n\t\t\t * There's a chance that p is higher in priority\n\t\t\t * than what's currently running on its CPU.\n\t\t\t * This is just that p is waking up and hasn't\n\t\t\t * had a chance to schedule. We only pull\n\t\t\t * p if it is lower in priority than the\n\t\t\t * current task on the run queue\n\t\t\t */\n\t\t\tif (p->prio < src_rq->curr->prio)\n\t\t\t\tgoto skip;\n\n\t\t\tif (is_migration_disabled(p)) {\n\t\t\t\tpush_task = get_push_task(src_rq);\n\t\t\t} else {\n\t\t\t\tdeactivate_task(src_rq, p, 0);\n\t\t\t\tset_task_cpu(p, this_cpu);\n\t\t\t\tactivate_task(this_rq, p, 0);\n\t\t\t\tresched = true;\n\t\t\t}\n\t\t\t/*\n\t\t\t * We continue with the search, just in\n\t\t\t * case there's an even higher prio task\n\t\t\t * in another runqueue. (low likelihood\n\t\t\t * but possible)\n\t\t\t */\n\t\t}\nskip:\n\t\tdouble_unlock_balance(this_rq, src_rq);\n\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(this_rq);\n\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &src_rq->push_work);\n\t\t\traw_spin_rq_lock(this_rq);\n\t\t}\n\t}\n\n\tif (resched)\n\t\tresched_curr(this_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "this_rq"
          ],
          "line": 2405
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_lock",
          "args": [
            "this_rq"
          ],
          "line": 2400
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_rq_lock_irqsave",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1333-1339",
          "snippet": "static inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void activate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void activate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);\n\nstatic inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "stop_one_cpu_nowait",
          "args": [
            "src_rq->cpu",
            "push_cpu_stop",
            "push_task",
            "&src_rq->push_work"
          ],
          "line": 2398
        },
        "resolved": true,
        "details": {
          "function_name": "stop_one_cpu_nowait",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/stop_machine.c",
          "lines": "384-389",
          "snippet": "bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,\n\t\t\tstruct cpu_stop_work *work_buf)\n{\n\t*work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, .caller = _RET_IP_, };\n\treturn cpu_stop_queue_work(cpu, work_buf);\n}",
          "includes": [
            "#include <linux/sched/wake_q.h>",
            "#include <linux/nmi.h>",
            "#include <linux/atomic.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kthread.h>",
            "#include <linux/init.h>",
            "#include <linux/cpu.h>",
            "#include <linux/completion.h>",
            "#include <linux/compiler.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/wake_q.h>\n#include <linux/nmi.h>\n#include <linux/atomic.h>\n#include <linux/smpboot.h>\n#include <linux/kallsyms.h>\n#include <linux/interrupt.h>\n#include <linux/stop_machine.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kthread.h>\n#include <linux/init.h>\n#include <linux/cpu.h>\n#include <linux/completion.h>\n#include <linux/compiler.h>\n\nbool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,\n\t\t\tstruct cpu_stop_work *work_buf)\n{\n\t*work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, .caller = _RET_IP_, };\n\treturn cpu_stop_queue_work(cpu, work_buf);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_unlock",
          "args": [
            "this_rq"
          ],
          "line": 2397
        },
        "resolved": true,
        "details": {
          "function_name": "raw_spin_rq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "531-534",
          "snippet": "void raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}"
        }
      },
      {
        "call_info": {
          "callee": "double_unlock_balance",
          "args": [
            "this_rq",
            "src_rq"
          ],
          "line": 2394
        },
        "resolved": true,
        "details": {
          "function_name": "double_unlock_balance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2597-2603",
          "snippet": "static inline void double_unlock_balance(struct rq *this_rq, struct rq *busiest)\n\t__releases(busiest->lock)\n{\n\tif (__rq_lockp(this_rq) != __rq_lockp(busiest))\n\t\traw_spin_rq_unlock(busiest);\n\tlock_set_subclass(&__rq_lockp(this_rq)->dep_map, 0, _RET_IP_);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void calc_global_load_tick(struct rq *this_rq);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "struct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);",
            "struct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void calc_global_load_tick(struct rq *this_rq);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nstruct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);\nstruct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void double_unlock_balance(struct rq *this_rq, struct rq *busiest)\n\t__releases(busiest->lock)\n{\n\tif (__rq_lockp(this_rq) != __rq_lockp(busiest))\n\t\traw_spin_rq_unlock(busiest);\n\tlock_set_subclass(&__rq_lockp(this_rq)->dep_map, 0, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "activate_task",
          "args": [
            "this_rq",
            "p",
            "0"
          ],
          "line": 2383
        },
        "resolved": true,
        "details": {
          "function_name": "deactivate_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2040-2045",
          "snippet": "void deactivate_task(struct rq *rq, struct task_struct *p, int flags)\n{\n\tp->on_rq = (flags & DEQUEUE_SLEEP) ? 0 : TASK_ON_RQ_MIGRATING;\n\n\tdequeue_task(rq, p, flags);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid deactivate_task(struct rq *rq, struct task_struct *p, int flags)\n{\n\tp->on_rq = (flags & DEQUEUE_SLEEP) ? 0 : TASK_ON_RQ_MIGRATING;\n\n\tdequeue_task(rq, p, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_task_cpu",
          "args": [
            "p",
            "this_cpu"
          ],
          "line": 2382
        },
        "resolved": true,
        "details": {
          "function_name": "set_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "3026-3079",
          "snippet": "void set_task_cpu(struct task_struct *p, unsigned int new_cpu)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tunsigned int state = READ_ONCE(p->__state);\n\n\t/*\n\t * We should never call set_task_cpu() on a blocked task,\n\t * ttwu() will sort out the placement.\n\t */\n\tWARN_ON_ONCE(state != TASK_RUNNING && state != TASK_WAKING && !p->on_rq);\n\n\t/*\n\t * Migrating fair class task must have p->on_rq = TASK_ON_RQ_MIGRATING,\n\t * because schedstat_wait_{start,end} rebase migrating task's wait_start\n\t * time relying on p->on_rq.\n\t */\n\tWARN_ON_ONCE(state == TASK_RUNNING &&\n\t\t     p->sched_class == &fair_sched_class &&\n\t\t     (p->on_rq && !task_on_rq_migrating(p)));\n\n#ifdef CONFIG_LOCKDEP\n\t/*\n\t * The caller should hold either p->pi_lock or rq->lock, when changing\n\t * a task's CPU. ->pi_lock for waking tasks, rq->lock for runnable tasks.\n\t *\n\t * sched_move_task() holds both and thus holding either pins the cgroup,\n\t * see task_group().\n\t *\n\t * Furthermore, all task_rq users should acquire both locks, see\n\t * task_rq_lock().\n\t */\n\tWARN_ON_ONCE(debug_locks && !(lockdep_is_held(&p->pi_lock) ||\n\t\t\t\t      lockdep_is_held(__rq_lockp(task_rq(p)))));\n#endif\n\t/*\n\t * Clearly, migrating tasks to offline CPUs is a fairly daft thing.\n\t */\n\tWARN_ON_ONCE(!cpu_online(new_cpu));\n\n\tWARN_ON_ONCE(is_migration_disabled(p));\n#endif\n\n\ttrace_sched_migrate_task(p, new_cpu);\n\n\tif (task_cpu(p) != new_cpu) {\n\t\tif (p->sched_class->migrate_task_rq)\n\t\t\tp->sched_class->migrate_task_rq(p, new_cpu);\n\t\tp->se.nr_migrations++;\n\t\trseq_migrate(p);\n\t\tperf_event_task_migrate(p);\n\t}\n\n\t__set_task_cpu(p, new_cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid set_task_cpu(struct task_struct *p, unsigned int new_cpu)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tunsigned int state = READ_ONCE(p->__state);\n\n\t/*\n\t * We should never call set_task_cpu() on a blocked task,\n\t * ttwu() will sort out the placement.\n\t */\n\tWARN_ON_ONCE(state != TASK_RUNNING && state != TASK_WAKING && !p->on_rq);\n\n\t/*\n\t * Migrating fair class task must have p->on_rq = TASK_ON_RQ_MIGRATING,\n\t * because schedstat_wait_{start,end} rebase migrating task's wait_start\n\t * time relying on p->on_rq.\n\t */\n\tWARN_ON_ONCE(state == TASK_RUNNING &&\n\t\t     p->sched_class == &fair_sched_class &&\n\t\t     (p->on_rq && !task_on_rq_migrating(p)));\n\n#ifdef CONFIG_LOCKDEP\n\t/*\n\t * The caller should hold either p->pi_lock or rq->lock, when changing\n\t * a task's CPU. ->pi_lock for waking tasks, rq->lock for runnable tasks.\n\t *\n\t * sched_move_task() holds both and thus holding either pins the cgroup,\n\t * see task_group().\n\t *\n\t * Furthermore, all task_rq users should acquire both locks, see\n\t * task_rq_lock().\n\t */\n\tWARN_ON_ONCE(debug_locks && !(lockdep_is_held(&p->pi_lock) ||\n\t\t\t\t      lockdep_is_held(__rq_lockp(task_rq(p)))));\n#endif\n\t/*\n\t * Clearly, migrating tasks to offline CPUs is a fairly daft thing.\n\t */\n\tWARN_ON_ONCE(!cpu_online(new_cpu));\n\n\tWARN_ON_ONCE(is_migration_disabled(p));\n#endif\n\n\ttrace_sched_migrate_task(p, new_cpu);\n\n\tif (task_cpu(p) != new_cpu) {\n\t\tif (p->sched_class->migrate_task_rq)\n\t\t\tp->sched_class->migrate_task_rq(p, new_cpu);\n\t\tp->se.nr_migrations++;\n\t\trseq_migrate(p);\n\t\tperf_event_task_migrate(p);\n\t}\n\n\t__set_task_cpu(p, new_cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_push_task",
          "args": [
            "src_rq"
          ],
          "line": 2379
        },
        "resolved": true,
        "details": {
          "function_name": "get_push_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2268-2285",
          "snippet": "static inline struct task_struct *get_push_task(struct rq *rq)\n{\n\tstruct task_struct *p = rq->curr;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (rq->push_busy)\n\t\treturn NULL;\n\n\tif (p->nr_cpus_allowed == 1)\n\t\treturn NULL;\n\n\tif (p->migration_disabled)\n\t\treturn NULL;\n\n\trq->push_busy = true;\n\treturn get_task_struct(p);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline struct task_struct *get_push_task(struct rq *rq)\n{\n\tstruct task_struct *p = rq->curr;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (rq->push_busy)\n\t\treturn NULL;\n\n\tif (p->nr_cpus_allowed == 1)\n\t\treturn NULL;\n\n\tif (p->migration_disabled)\n\t\treturn NULL;\n\n\trq->push_busy = true;\n\treturn get_task_struct(p);\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_migration_disabled",
          "args": [
            "p"
          ],
          "line": 2378
        },
        "resolved": true,
        "details": {
          "function_name": "is_migration_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1148-1155",
          "snippet": "static inline bool is_migration_disabled(struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->migration_disabled;\n#else\n\treturn false;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline bool is_migration_disabled(struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->migration_disabled;\n#else\n\treturn false;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!task_on_rq_queued(p)"
          ],
          "line": 2365
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_on_rq_queued",
          "args": [
            "p"
          ],
          "line": 2365
        },
        "resolved": true,
        "details": {
          "function_name": "task_on_rq_queued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2044-2047",
          "snippet": "static inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define TASK_ON_RQ_QUEUED\t1"
          ],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define TASK_ON_RQ_QUEUED\t1\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "p == src_rq->curr"
          ],
          "line": 2364
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pick_highest_pushable_task",
          "args": [
            "src_rq",
            "this_cpu"
          ],
          "line": 2357
        },
        "resolved": true,
        "details": {
          "function_name": "pick_highest_pushable_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1824-1838",
          "snippet": "static struct task_struct *pick_highest_pushable_task(struct rq *rq, int cpu)\n{\n\tstruct plist_head *head = &rq->rt.pushable_tasks;\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tplist_for_each_entry(p, head, pushable_tasks) {\n\t\tif (pick_rt_task(rq, p, cpu))\n\t\t\treturn p;\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct task_struct *pick_highest_pushable_task(struct rq *rq, int cpu)\n{\n\tstruct plist_head *head = &rq->rt.pushable_tasks;\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tplist_for_each_entry(p, head, pushable_tasks) {\n\t\tif (pick_rt_task(rq, p, cpu))\n\t\t\treturn p;\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "double_lock_balance",
          "args": [
            "this_rq",
            "src_rq"
          ],
          "line": 2351
        },
        "resolved": true,
        "details": {
          "function_name": "double_lock_balance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2590-2595",
          "snippet": "static inline int double_lock_balance(struct rq *this_rq, struct rq *busiest)\n{\n\tlockdep_assert_irqs_disabled();\n\n\treturn _double_lock_balance(this_rq, busiest);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void calc_global_load_tick(struct rq *this_rq);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void calc_global_load_tick(struct rq *this_rq);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline int double_lock_balance(struct rq *this_rq, struct rq *busiest)\n{\n\tlockdep_assert_irqs_disabled();\n\n\treturn _double_lock_balance(this_rq, busiest);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 2332
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "cpu",
            "this_rq->rd->rto_mask"
          ],
          "line": 2328
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "tell_cpu_to_push",
          "args": [
            "this_rq"
          ],
          "line": 2323
        },
        "resolved": true,
        "details": {
          "function_name": "tell_cpu_to_push",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2228-2259",
          "snippet": "static void tell_cpu_to_push(struct rq *rq)\n{\n\tint cpu = -1;\n\n\t/* Keep the loop going if the IPI is currently active */\n\tatomic_inc(&rq->rd->rto_loop_next);\n\n\t/* Only one CPU can initiate a loop at a time */\n\tif (!rto_start_trylock(&rq->rd->rto_loop_start))\n\t\treturn;\n\n\traw_spin_lock(&rq->rd->rto_lock);\n\n\t/*\n\t * The rto_cpu is updated under the lock, if it has a valid CPU\n\t * then the IPI is still running and will continue due to the\n\t * update to loop_next, and nothing needs to be done here.\n\t * Otherwise it is finishing up and an ipi needs to be sent.\n\t */\n\tif (rq->rd->rto_cpu < 0)\n\t\tcpu = rto_next_cpu(rq->rd);\n\n\traw_spin_unlock(&rq->rd->rto_lock);\n\n\trto_start_unlock(&rq->rd->rto_loop_start);\n\n\tif (cpu >= 0) {\n\t\t/* Make sure the rd does not get freed while pushing */\n\t\tsched_get_rd(rq->rd);\n\t\tirq_work_queue_on(&rq->rd->rto_push_work, cpu);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void tell_cpu_to_push(struct rq *rq)\n{\n\tint cpu = -1;\n\n\t/* Keep the loop going if the IPI is currently active */\n\tatomic_inc(&rq->rd->rto_loop_next);\n\n\t/* Only one CPU can initiate a loop at a time */\n\tif (!rto_start_trylock(&rq->rd->rto_loop_start))\n\t\treturn;\n\n\traw_spin_lock(&rq->rd->rto_lock);\n\n\t/*\n\t * The rto_cpu is updated under the lock, if it has a valid CPU\n\t * then the IPI is still running and will continue due to the\n\t * update to loop_next, and nothing needs to be done here.\n\t * Otherwise it is finishing up and an ipi needs to be sent.\n\t */\n\tif (rq->rd->rto_cpu < 0)\n\t\tcpu = rto_next_cpu(rq->rd);\n\n\traw_spin_unlock(&rq->rd->rto_lock);\n\n\trto_start_unlock(&rq->rd->rto_loop_start);\n\n\tif (cpu >= 0) {\n\t\t/* Make sure the rd does not get freed while pushing */\n\t\tsched_get_rd(rq->rd);\n\t\tirq_work_queue_on(&rq->rd->rto_push_work, cpu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_feat",
          "args": [
            "RT_PUSH_IPI"
          ],
          "line": 2322
        },
        "resolved": true,
        "details": {
          "function_name": "sched_feat_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/debug.c",
          "lines": "99-122",
          "snippet": "static int sched_feat_set(char *cmp)\n{\n\tint i;\n\tint neg = 0;\n\n\tif (strncmp(cmp, \"NO_\", 3) == 0) {\n\t\tneg = 1;\n\t\tcmp += 3;\n\t}\n\n\ti = match_string(sched_feat_names, __SCHED_FEAT_NR, cmp);\n\tif (i < 0)\n\t\treturn i;\n\n\tif (neg) {\n\t\tsysctl_sched_features &= ~(1UL << i);\n\t\tsched_feat_disable(i);\n\t} else {\n\t\tsysctl_sched_features |= (1UL << i);\n\t\tsched_feat_enable(i);\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static const char * const sched_feat_names[] = {\n#include \"features.h\"\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic const char * const sched_feat_names[] = {\n#include \"features.h\"\n};\n\nstatic int sched_feat_set(char *cmp)\n{\n\tint i;\n\tint neg = 0;\n\n\tif (strncmp(cmp, \"NO_\", 3) == 0) {\n\t\tneg = 1;\n\t\tcmp += 3;\n\t}\n\n\ti = match_string(sched_feat_names, __SCHED_FEAT_NR, cmp);\n\tif (i < 0)\n\t\treturn i;\n\n\tif (neg) {\n\t\tsysctl_sched_features &= ~(1UL << i);\n\t\tsched_feat_disable(i);\n\t} else {\n\t\tsysctl_sched_features |= (1UL << i);\n\t\tsched_feat_enable(i);\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "this_rq->cpu",
            "this_rq->rd->rto_mask"
          ],
          "line": 2318
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 2314
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!rt_overload_count"
          ],
          "line": 2307
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_overloaded",
          "args": [
            "this_rq"
          ],
          "line": 2305
        },
        "resolved": true,
        "details": {
          "function_name": "rt_overloaded",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "282-285",
          "snippet": "static inline int rt_overloaded(struct rq *rq)\n{\n\treturn atomic_read(&rq->rd->rto_count);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int rt_overloaded(struct rq *rq)\n{\n\treturn atomic_read(&rq->rd->rto_count);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void pull_rt_task(struct rq *this_rq)\n{\n\tint this_cpu = this_rq->cpu, cpu;\n\tbool resched = false;\n\tstruct task_struct *p, *push_task;\n\tstruct rq *src_rq;\n\tint rt_overload_count = rt_overloaded(this_rq);\n\n\tif (likely(!rt_overload_count))\n\t\treturn;\n\n\t/*\n\t * Match the barrier from rt_set_overloaded; this guarantees that if we\n\t * see overloaded we must also see the rto_mask bit.\n\t */\n\tsmp_rmb();\n\n\t/* If we are the only overloaded CPU do nothing */\n\tif (rt_overload_count == 1 &&\n\t    cpumask_test_cpu(this_rq->cpu, this_rq->rd->rto_mask))\n\t\treturn;\n\n#ifdef HAVE_RT_PUSH_IPI\n\tif (sched_feat(RT_PUSH_IPI)) {\n\t\ttell_cpu_to_push(this_rq);\n\t\treturn;\n\t}\n#endif\n\n\tfor_each_cpu(cpu, this_rq->rd->rto_mask) {\n\t\tif (this_cpu == cpu)\n\t\t\tcontinue;\n\n\t\tsrc_rq = cpu_rq(cpu);\n\n\t\t/*\n\t\t * Don't bother taking the src_rq->lock if the next highest\n\t\t * task is known to be lower-priority than our current task.\n\t\t * This may look racy, but if this value is about to go\n\t\t * logically higher, the src_rq will push this task away.\n\t\t * And if its going logically lower, we do not care\n\t\t */\n\t\tif (src_rq->rt.highest_prio.next >=\n\t\t    this_rq->rt.highest_prio.curr)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We can potentially drop this_rq's lock in\n\t\t * double_lock_balance, and another CPU could\n\t\t * alter this_rq\n\t\t */\n\t\tpush_task = NULL;\n\t\tdouble_lock_balance(this_rq, src_rq);\n\n\t\t/*\n\t\t * We can pull only a task, which is pushable\n\t\t * on its rq, and no others.\n\t\t */\n\t\tp = pick_highest_pushable_task(src_rq, this_cpu);\n\n\t\t/*\n\t\t * Do we have an RT task that preempts\n\t\t * the to-be-scheduled task?\n\t\t */\n\t\tif (p && (p->prio < this_rq->rt.highest_prio.curr)) {\n\t\t\tWARN_ON(p == src_rq->curr);\n\t\t\tWARN_ON(!task_on_rq_queued(p));\n\n\t\t\t/*\n\t\t\t * There's a chance that p is higher in priority\n\t\t\t * than what's currently running on its CPU.\n\t\t\t * This is just that p is waking up and hasn't\n\t\t\t * had a chance to schedule. We only pull\n\t\t\t * p if it is lower in priority than the\n\t\t\t * current task on the run queue\n\t\t\t */\n\t\t\tif (p->prio < src_rq->curr->prio)\n\t\t\t\tgoto skip;\n\n\t\t\tif (is_migration_disabled(p)) {\n\t\t\t\tpush_task = get_push_task(src_rq);\n\t\t\t} else {\n\t\t\t\tdeactivate_task(src_rq, p, 0);\n\t\t\t\tset_task_cpu(p, this_cpu);\n\t\t\t\tactivate_task(this_rq, p, 0);\n\t\t\t\tresched = true;\n\t\t\t}\n\t\t\t/*\n\t\t\t * We continue with the search, just in\n\t\t\t * case there's an even higher prio task\n\t\t\t * in another runqueue. (low likelihood\n\t\t\t * but possible)\n\t\t\t */\n\t\t}\nskip:\n\t\tdouble_unlock_balance(this_rq, src_rq);\n\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(this_rq);\n\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &src_rq->push_work);\n\t\t\traw_spin_rq_lock(this_rq);\n\t\t}\n\t}\n\n\tif (resched)\n\t\tresched_curr(this_rq);\n}"
  },
  {
    "function_name": "rto_push_irq_work_func",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2262-2296",
    "snippet": "void rto_push_irq_work_func(struct irq_work *work)\n{\n\tstruct root_domain *rd =\n\t\tcontainer_of(work, struct root_domain, rto_push_work);\n\tstruct rq *rq;\n\tint cpu;\n\n\trq = this_rq();\n\n\t/*\n\t * We do not need to grab the lock to check for has_pushable_tasks.\n\t * When it gets updated, a check is made if a push is possible.\n\t */\n\tif (has_pushable_tasks(rq)) {\n\t\traw_spin_rq_lock(rq);\n\t\twhile (push_rt_task(rq, true))\n\t\t\t;\n\t\traw_spin_rq_unlock(rq);\n\t}\n\n\traw_spin_lock(&rd->rto_lock);\n\n\t/* Pass the IPI to the next rt overloaded queue */\n\tcpu = rto_next_cpu(rd);\n\n\traw_spin_unlock(&rd->rto_lock);\n\n\tif (cpu < 0) {\n\t\tsched_put_rd(rd);\n\t\treturn;\n\t}\n\n\t/* Try the next RT overloaded CPU */\n\tirq_work_queue_on(&rd->rto_push_work, cpu);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue_on",
          "args": [
            "&rd->rto_push_work",
            "cpu"
          ],
          "line": 2295
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue_on",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "127-172",
          "snippet": "bool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n#ifndef CONFIG_SMP\n\treturn irq_work_queue(work);\n\n#else /* CONFIG_SMP: */\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tkasan_record_aux_stack(work);\n\n\tpreempt_disable();\n\tif (cpu != smp_processor_id()) {\n\t\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\t\tWARN_ON_ONCE(in_nmi());\n\n\t\t/*\n\t\t * On PREEMPT_RT the items which are not marked as\n\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work\n\t\t * item is used on the remote CPU to wake the thread.\n\t\t */\n\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&\n\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {\n\n\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))\n\t\t\t\tgoto out;\n\n\t\t\twork = &per_cpu(irq_work_wakeup, cpu);\n\t\t\tif (!irq_work_claim(work))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t__smp_call_single_queue(cpu, &work->node.llist);\n\t} else {\n\t\t__irq_work_queue_local(work);\n\t}\nout:\n\tpreempt_enable();\n\n\treturn true;\n#endif /* CONFIG_SMP */\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n#ifndef CONFIG_SMP\n\treturn irq_work_queue(work);\n\n#else /* CONFIG_SMP: */\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tkasan_record_aux_stack(work);\n\n\tpreempt_disable();\n\tif (cpu != smp_processor_id()) {\n\t\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\t\tWARN_ON_ONCE(in_nmi());\n\n\t\t/*\n\t\t * On PREEMPT_RT the items which are not marked as\n\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work\n\t\t * item is used on the remote CPU to wake the thread.\n\t\t */\n\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&\n\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {\n\n\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))\n\t\t\t\tgoto out;\n\n\t\t\twork = &per_cpu(irq_work_wakeup, cpu);\n\t\t\tif (!irq_work_claim(work))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t__smp_call_single_queue(cpu, &work->node.llist);\n\t} else {\n\t\t__irq_work_queue_local(work);\n\t}\nout:\n\tpreempt_enable();\n\n\treturn true;\n#endif /* CONFIG_SMP */\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_put_rd",
          "args": [
            "rd"
          ],
          "line": 2290
        },
        "resolved": true,
        "details": {
          "function_name": "sched_put_rd",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/topology.c",
          "lines": "507-513",
          "snippet": "void sched_put_rd(struct root_domain *rd)\n{\n\tif (!atomic_dec_and_test(&rd->refcount))\n\t\treturn;\n\n\tcall_rcu(&rd->rcu, free_rootdomain);\n}",
          "includes": [
            "#include <linux/sched/sd_flags.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/sd_flags.h>\n#include \"sched.h\"\n\nvoid sched_put_rd(struct root_domain *rd)\n{\n\tif (!atomic_dec_and_test(&rd->refcount))\n\t\treturn;\n\n\tcall_rcu(&rd->rcu, free_rootdomain);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rd->rto_lock"
          ],
          "line": 2287
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rto_next_cpu",
          "args": [
            "rd"
          ],
          "line": 2285
        },
        "resolved": true,
        "details": {
          "function_name": "rto_next_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2171-2216",
          "snippet": "static int rto_next_cpu(struct root_domain *rd)\n{\n\tint next;\n\tint cpu;\n\n\t/*\n\t * When starting the IPI RT pushing, the rto_cpu is set to -1,\n\t * rt_next_cpu() will simply return the first CPU found in\n\t * the rto_mask.\n\t *\n\t * If rto_next_cpu() is called with rto_cpu is a valid CPU, it\n\t * will return the next CPU found in the rto_mask.\n\t *\n\t * If there are no more CPUs left in the rto_mask, then a check is made\n\t * against rto_loop and rto_loop_next. rto_loop is only updated with\n\t * the rto_lock held, but any CPU may increment the rto_loop_next\n\t * without any locking.\n\t */\n\tfor (;;) {\n\n\t\t/* When rto_cpu is -1 this acts like cpumask_first() */\n\t\tcpu = cpumask_next(rd->rto_cpu, rd->rto_mask);\n\n\t\trd->rto_cpu = cpu;\n\n\t\tif (cpu < nr_cpu_ids)\n\t\t\treturn cpu;\n\n\t\trd->rto_cpu = -1;\n\n\t\t/*\n\t\t * ACQUIRE ensures we see the @rto_mask changes\n\t\t * made prior to the @next value observed.\n\t\t *\n\t\t * Matches WMB in rt_set_overload().\n\t\t */\n\t\tnext = atomic_read_acquire(&rd->rto_loop_next);\n\n\t\tif (rd->rto_loop == next)\n\t\t\tbreak;\n\n\t\trd->rto_loop = next;\n\t}\n\n\treturn -1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int rto_next_cpu(struct root_domain *rd)\n{\n\tint next;\n\tint cpu;\n\n\t/*\n\t * When starting the IPI RT pushing, the rto_cpu is set to -1,\n\t * rt_next_cpu() will simply return the first CPU found in\n\t * the rto_mask.\n\t *\n\t * If rto_next_cpu() is called with rto_cpu is a valid CPU, it\n\t * will return the next CPU found in the rto_mask.\n\t *\n\t * If there are no more CPUs left in the rto_mask, then a check is made\n\t * against rto_loop and rto_loop_next. rto_loop is only updated with\n\t * the rto_lock held, but any CPU may increment the rto_loop_next\n\t * without any locking.\n\t */\n\tfor (;;) {\n\n\t\t/* When rto_cpu is -1 this acts like cpumask_first() */\n\t\tcpu = cpumask_next(rd->rto_cpu, rd->rto_mask);\n\n\t\trd->rto_cpu = cpu;\n\n\t\tif (cpu < nr_cpu_ids)\n\t\t\treturn cpu;\n\n\t\trd->rto_cpu = -1;\n\n\t\t/*\n\t\t * ACQUIRE ensures we see the @rto_mask changes\n\t\t * made prior to the @next value observed.\n\t\t *\n\t\t * Matches WMB in rt_set_overload().\n\t\t */\n\t\tnext = atomic_read_acquire(&rd->rto_loop_next);\n\n\t\tif (rd->rto_loop == next)\n\t\t\tbreak;\n\n\t\trd->rto_loop = next;\n\t}\n\n\treturn -1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rd->rto_lock"
          ],
          "line": 2282
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_unlock",
          "args": [
            "rq"
          ],
          "line": 2279
        },
        "resolved": true,
        "details": {
          "function_name": "raw_spin_rq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "531-534",
          "snippet": "void raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}"
        }
      },
      {
        "call_info": {
          "callee": "push_rt_task",
          "args": [
            "rq",
            "true"
          ],
          "line": 2277
        },
        "resolved": true,
        "details": {
          "function_name": "push_rt_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2015-2119",
          "snippet": "static int push_rt_task(struct rq *rq, bool pull)\n{\n\tstruct task_struct *next_task;\n\tstruct rq *lowest_rq;\n\tint ret = 0;\n\n\tif (!rq->rt.overloaded)\n\t\treturn 0;\n\n\tnext_task = pick_next_pushable_task(rq);\n\tif (!next_task)\n\t\treturn 0;\n\nretry:\n\tif (is_migration_disabled(next_task)) {\n\t\tstruct task_struct *push_task = NULL;\n\t\tint cpu;\n\n\t\tif (!pull || rq->push_busy)\n\t\t\treturn 0;\n\n\t\tcpu = find_lowest_rq(rq->curr);\n\t\tif (cpu == -1 || cpu == rq->cpu)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Given we found a CPU with lower priority than @next_task,\n\t\t * therefore it should be running. However we cannot migrate it\n\t\t * to this other CPU, instead attempt to push the current\n\t\t * running task on this CPU away.\n\t\t */\n\t\tpush_task = get_push_task(rq);\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(rq);\n\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &rq->push_work);\n\t\t\traw_spin_rq_lock(rq);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (WARN_ON(next_task == rq->curr))\n\t\treturn 0;\n\n\t/*\n\t * It's possible that the next_task slipped in of\n\t * higher priority than current. If that's the case\n\t * just reschedule current.\n\t */\n\tif (unlikely(next_task->prio < rq->curr->prio)) {\n\t\tresched_curr(rq);\n\t\treturn 0;\n\t}\n\n\t/* We might release rq lock */\n\tget_task_struct(next_task);\n\n\t/* find_lock_lowest_rq locks the rq if found */\n\tlowest_rq = find_lock_lowest_rq(next_task, rq);\n\tif (!lowest_rq) {\n\t\tstruct task_struct *task;\n\t\t/*\n\t\t * find_lock_lowest_rq releases rq->lock\n\t\t * so it is possible that next_task has migrated.\n\t\t *\n\t\t * We need to make sure that the task is still on the same\n\t\t * run-queue and is also still the next task eligible for\n\t\t * pushing.\n\t\t */\n\t\ttask = pick_next_pushable_task(rq);\n\t\tif (task == next_task) {\n\t\t\t/*\n\t\t\t * The task hasn't migrated, and is still the next\n\t\t\t * eligible task, but we failed to find a run-queue\n\t\t\t * to push it to.  Do not retry in this case, since\n\t\t\t * other CPUs will pull from us when ready.\n\t\t\t */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!task)\n\t\t\t/* No more tasks, just exit */\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * Something has shifted, try again.\n\t\t */\n\t\tput_task_struct(next_task);\n\t\tnext_task = task;\n\t\tgoto retry;\n\t}\n\n\tdeactivate_task(rq, next_task, 0);\n\tset_task_cpu(next_task, lowest_rq->cpu);\n\tactivate_task(lowest_rq, next_task, 0);\n\tresched_curr(lowest_rq);\n\tret = 1;\n\n\tdouble_unlock_balance(rq, lowest_rq);\nout:\n\tput_task_struct(next_task);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int push_rt_task(struct rq *rq, bool pull)\n{\n\tstruct task_struct *next_task;\n\tstruct rq *lowest_rq;\n\tint ret = 0;\n\n\tif (!rq->rt.overloaded)\n\t\treturn 0;\n\n\tnext_task = pick_next_pushable_task(rq);\n\tif (!next_task)\n\t\treturn 0;\n\nretry:\n\tif (is_migration_disabled(next_task)) {\n\t\tstruct task_struct *push_task = NULL;\n\t\tint cpu;\n\n\t\tif (!pull || rq->push_busy)\n\t\t\treturn 0;\n\n\t\tcpu = find_lowest_rq(rq->curr);\n\t\tif (cpu == -1 || cpu == rq->cpu)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Given we found a CPU with lower priority than @next_task,\n\t\t * therefore it should be running. However we cannot migrate it\n\t\t * to this other CPU, instead attempt to push the current\n\t\t * running task on this CPU away.\n\t\t */\n\t\tpush_task = get_push_task(rq);\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(rq);\n\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &rq->push_work);\n\t\t\traw_spin_rq_lock(rq);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (WARN_ON(next_task == rq->curr))\n\t\treturn 0;\n\n\t/*\n\t * It's possible that the next_task slipped in of\n\t * higher priority than current. If that's the case\n\t * just reschedule current.\n\t */\n\tif (unlikely(next_task->prio < rq->curr->prio)) {\n\t\tresched_curr(rq);\n\t\treturn 0;\n\t}\n\n\t/* We might release rq lock */\n\tget_task_struct(next_task);\n\n\t/* find_lock_lowest_rq locks the rq if found */\n\tlowest_rq = find_lock_lowest_rq(next_task, rq);\n\tif (!lowest_rq) {\n\t\tstruct task_struct *task;\n\t\t/*\n\t\t * find_lock_lowest_rq releases rq->lock\n\t\t * so it is possible that next_task has migrated.\n\t\t *\n\t\t * We need to make sure that the task is still on the same\n\t\t * run-queue and is also still the next task eligible for\n\t\t * pushing.\n\t\t */\n\t\ttask = pick_next_pushable_task(rq);\n\t\tif (task == next_task) {\n\t\t\t/*\n\t\t\t * The task hasn't migrated, and is still the next\n\t\t\t * eligible task, but we failed to find a run-queue\n\t\t\t * to push it to.  Do not retry in this case, since\n\t\t\t * other CPUs will pull from us when ready.\n\t\t\t */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!task)\n\t\t\t/* No more tasks, just exit */\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * Something has shifted, try again.\n\t\t */\n\t\tput_task_struct(next_task);\n\t\tnext_task = task;\n\t\tgoto retry;\n\t}\n\n\tdeactivate_task(rq, next_task, 0);\n\tset_task_cpu(next_task, lowest_rq->cpu);\n\tactivate_task(lowest_rq, next_task, 0);\n\tresched_curr(lowest_rq);\n\tret = 1;\n\n\tdouble_unlock_balance(rq, lowest_rq);\nout:\n\tput_task_struct(next_task);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_lock",
          "args": [
            "rq"
          ],
          "line": 2276
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_rq_lock_irqsave",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1333-1339",
          "snippet": "static inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void activate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void activate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);\n\nstatic inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "has_pushable_tasks",
          "args": [
            "rq"
          ],
          "line": 2275
        },
        "resolved": true,
        "details": {
          "function_name": "has_pushable_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "363-366",
          "snippet": "static inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_rq",
          "args": [],
          "line": 2269
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structroot_domain",
            "rto_push_work"
          ],
          "line": 2265
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nvoid rto_push_irq_work_func(struct irq_work *work)\n{\n\tstruct root_domain *rd =\n\t\tcontainer_of(work, struct root_domain, rto_push_work);\n\tstruct rq *rq;\n\tint cpu;\n\n\trq = this_rq();\n\n\t/*\n\t * We do not need to grab the lock to check for has_pushable_tasks.\n\t * When it gets updated, a check is made if a push is possible.\n\t */\n\tif (has_pushable_tasks(rq)) {\n\t\traw_spin_rq_lock(rq);\n\t\twhile (push_rt_task(rq, true))\n\t\t\t;\n\t\traw_spin_rq_unlock(rq);\n\t}\n\n\traw_spin_lock(&rd->rto_lock);\n\n\t/* Pass the IPI to the next rt overloaded queue */\n\tcpu = rto_next_cpu(rd);\n\n\traw_spin_unlock(&rd->rto_lock);\n\n\tif (cpu < 0) {\n\t\tsched_put_rd(rd);\n\t\treturn;\n\t}\n\n\t/* Try the next RT overloaded CPU */\n\tirq_work_queue_on(&rd->rto_push_work, cpu);\n}"
  },
  {
    "function_name": "tell_cpu_to_push",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2228-2259",
    "snippet": "static void tell_cpu_to_push(struct rq *rq)\n{\n\tint cpu = -1;\n\n\t/* Keep the loop going if the IPI is currently active */\n\tatomic_inc(&rq->rd->rto_loop_next);\n\n\t/* Only one CPU can initiate a loop at a time */\n\tif (!rto_start_trylock(&rq->rd->rto_loop_start))\n\t\treturn;\n\n\traw_spin_lock(&rq->rd->rto_lock);\n\n\t/*\n\t * The rto_cpu is updated under the lock, if it has a valid CPU\n\t * then the IPI is still running and will continue due to the\n\t * update to loop_next, and nothing needs to be done here.\n\t * Otherwise it is finishing up and an ipi needs to be sent.\n\t */\n\tif (rq->rd->rto_cpu < 0)\n\t\tcpu = rto_next_cpu(rq->rd);\n\n\traw_spin_unlock(&rq->rd->rto_lock);\n\n\trto_start_unlock(&rq->rd->rto_loop_start);\n\n\tif (cpu >= 0) {\n\t\t/* Make sure the rd does not get freed while pushing */\n\t\tsched_get_rd(rq->rd);\n\t\tirq_work_queue_on(&rq->rd->rto_push_work, cpu);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue_on",
          "args": [
            "&rq->rd->rto_push_work",
            "cpu"
          ],
          "line": 2257
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue_on",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "127-172",
          "snippet": "bool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n#ifndef CONFIG_SMP\n\treturn irq_work_queue(work);\n\n#else /* CONFIG_SMP: */\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tkasan_record_aux_stack(work);\n\n\tpreempt_disable();\n\tif (cpu != smp_processor_id()) {\n\t\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\t\tWARN_ON_ONCE(in_nmi());\n\n\t\t/*\n\t\t * On PREEMPT_RT the items which are not marked as\n\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work\n\t\t * item is used on the remote CPU to wake the thread.\n\t\t */\n\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&\n\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {\n\n\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))\n\t\t\t\tgoto out;\n\n\t\t\twork = &per_cpu(irq_work_wakeup, cpu);\n\t\t\tif (!irq_work_claim(work))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t__smp_call_single_queue(cpu, &work->node.llist);\n\t} else {\n\t\t__irq_work_queue_local(work);\n\t}\nout:\n\tpreempt_enable();\n\n\treturn true;\n#endif /* CONFIG_SMP */\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n#ifndef CONFIG_SMP\n\treturn irq_work_queue(work);\n\n#else /* CONFIG_SMP: */\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tkasan_record_aux_stack(work);\n\n\tpreempt_disable();\n\tif (cpu != smp_processor_id()) {\n\t\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\t\tWARN_ON_ONCE(in_nmi());\n\n\t\t/*\n\t\t * On PREEMPT_RT the items which are not marked as\n\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work\n\t\t * item is used on the remote CPU to wake the thread.\n\t\t */\n\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&\n\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {\n\n\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))\n\t\t\t\tgoto out;\n\n\t\t\twork = &per_cpu(irq_work_wakeup, cpu);\n\t\t\tif (!irq_work_claim(work))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t__smp_call_single_queue(cpu, &work->node.llist);\n\t} else {\n\t\t__irq_work_queue_local(work);\n\t}\nout:\n\tpreempt_enable();\n\n\treturn true;\n#endif /* CONFIG_SMP */\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_get_rd",
          "args": [
            "rq->rd"
          ],
          "line": 2256
        },
        "resolved": true,
        "details": {
          "function_name": "sched_get_rd",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/topology.c",
          "lines": "502-505",
          "snippet": "void sched_get_rd(struct root_domain *rd)\n{\n\tatomic_inc(&rd->refcount);\n}",
          "includes": [
            "#include <linux/sched/sd_flags.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/sd_flags.h>\n#include \"sched.h\"\n\nvoid sched_get_rd(struct root_domain *rd)\n{\n\tatomic_inc(&rd->refcount);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rto_start_unlock",
          "args": [
            "&rq->rd->rto_loop_start"
          ],
          "line": 2252
        },
        "resolved": true,
        "details": {
          "function_name": "rto_start_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2223-2226",
          "snippet": "static inline void rto_start_unlock(atomic_t *v)\n{\n\tatomic_set_release(v, 0);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rto_start_unlock(atomic_t *v)\n{\n\tatomic_set_release(v, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rq->rd->rto_lock"
          ],
          "line": 2250
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rto_next_cpu",
          "args": [
            "rq->rd"
          ],
          "line": 2248
        },
        "resolved": true,
        "details": {
          "function_name": "rto_next_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2171-2216",
          "snippet": "static int rto_next_cpu(struct root_domain *rd)\n{\n\tint next;\n\tint cpu;\n\n\t/*\n\t * When starting the IPI RT pushing, the rto_cpu is set to -1,\n\t * rt_next_cpu() will simply return the first CPU found in\n\t * the rto_mask.\n\t *\n\t * If rto_next_cpu() is called with rto_cpu is a valid CPU, it\n\t * will return the next CPU found in the rto_mask.\n\t *\n\t * If there are no more CPUs left in the rto_mask, then a check is made\n\t * against rto_loop and rto_loop_next. rto_loop is only updated with\n\t * the rto_lock held, but any CPU may increment the rto_loop_next\n\t * without any locking.\n\t */\n\tfor (;;) {\n\n\t\t/* When rto_cpu is -1 this acts like cpumask_first() */\n\t\tcpu = cpumask_next(rd->rto_cpu, rd->rto_mask);\n\n\t\trd->rto_cpu = cpu;\n\n\t\tif (cpu < nr_cpu_ids)\n\t\t\treturn cpu;\n\n\t\trd->rto_cpu = -1;\n\n\t\t/*\n\t\t * ACQUIRE ensures we see the @rto_mask changes\n\t\t * made prior to the @next value observed.\n\t\t *\n\t\t * Matches WMB in rt_set_overload().\n\t\t */\n\t\tnext = atomic_read_acquire(&rd->rto_loop_next);\n\n\t\tif (rd->rto_loop == next)\n\t\t\tbreak;\n\n\t\trd->rto_loop = next;\n\t}\n\n\treturn -1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int rto_next_cpu(struct root_domain *rd)\n{\n\tint next;\n\tint cpu;\n\n\t/*\n\t * When starting the IPI RT pushing, the rto_cpu is set to -1,\n\t * rt_next_cpu() will simply return the first CPU found in\n\t * the rto_mask.\n\t *\n\t * If rto_next_cpu() is called with rto_cpu is a valid CPU, it\n\t * will return the next CPU found in the rto_mask.\n\t *\n\t * If there are no more CPUs left in the rto_mask, then a check is made\n\t * against rto_loop and rto_loop_next. rto_loop is only updated with\n\t * the rto_lock held, but any CPU may increment the rto_loop_next\n\t * without any locking.\n\t */\n\tfor (;;) {\n\n\t\t/* When rto_cpu is -1 this acts like cpumask_first() */\n\t\tcpu = cpumask_next(rd->rto_cpu, rd->rto_mask);\n\n\t\trd->rto_cpu = cpu;\n\n\t\tif (cpu < nr_cpu_ids)\n\t\t\treturn cpu;\n\n\t\trd->rto_cpu = -1;\n\n\t\t/*\n\t\t * ACQUIRE ensures we see the @rto_mask changes\n\t\t * made prior to the @next value observed.\n\t\t *\n\t\t * Matches WMB in rt_set_overload().\n\t\t */\n\t\tnext = atomic_read_acquire(&rd->rto_loop_next);\n\n\t\tif (rd->rto_loop == next)\n\t\t\tbreak;\n\n\t\trd->rto_loop = next;\n\t}\n\n\treturn -1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rq->rd->rto_lock"
          ],
          "line": 2239
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rto_start_trylock",
          "args": [
            "&rq->rd->rto_loop_start"
          ],
          "line": 2236
        },
        "resolved": true,
        "details": {
          "function_name": "rto_start_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2218-2221",
          "snippet": "static inline bool rto_start_trylock(atomic_t *v)\n{\n\treturn !atomic_cmpxchg_acquire(v, 0, 1);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool rto_start_trylock(atomic_t *v)\n{\n\treturn !atomic_cmpxchg_acquire(v, 0, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&rq->rd->rto_loop_next"
          ],
          "line": 2233
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void tell_cpu_to_push(struct rq *rq)\n{\n\tint cpu = -1;\n\n\t/* Keep the loop going if the IPI is currently active */\n\tatomic_inc(&rq->rd->rto_loop_next);\n\n\t/* Only one CPU can initiate a loop at a time */\n\tif (!rto_start_trylock(&rq->rd->rto_loop_start))\n\t\treturn;\n\n\traw_spin_lock(&rq->rd->rto_lock);\n\n\t/*\n\t * The rto_cpu is updated under the lock, if it has a valid CPU\n\t * then the IPI is still running and will continue due to the\n\t * update to loop_next, and nothing needs to be done here.\n\t * Otherwise it is finishing up and an ipi needs to be sent.\n\t */\n\tif (rq->rd->rto_cpu < 0)\n\t\tcpu = rto_next_cpu(rq->rd);\n\n\traw_spin_unlock(&rq->rd->rto_lock);\n\n\trto_start_unlock(&rq->rd->rto_loop_start);\n\n\tif (cpu >= 0) {\n\t\t/* Make sure the rd does not get freed while pushing */\n\t\tsched_get_rd(rq->rd);\n\t\tirq_work_queue_on(&rq->rd->rto_push_work, cpu);\n\t}\n}"
  },
  {
    "function_name": "rto_start_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2223-2226",
    "snippet": "static inline void rto_start_unlock(atomic_t *v)\n{\n\tatomic_set_release(v, 0);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_set_release",
          "args": [
            "v",
            "0"
          ],
          "line": 2225
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rto_start_unlock(atomic_t *v)\n{\n\tatomic_set_release(v, 0);\n}"
  },
  {
    "function_name": "rto_start_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2218-2221",
    "snippet": "static inline bool rto_start_trylock(atomic_t *v)\n{\n\treturn !atomic_cmpxchg_acquire(v, 0, 1);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_cmpxchg_acquire",
          "args": [
            "v",
            "0",
            "1"
          ],
          "line": 2220
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool rto_start_trylock(atomic_t *v)\n{\n\treturn !atomic_cmpxchg_acquire(v, 0, 1);\n}"
  },
  {
    "function_name": "rto_next_cpu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2171-2216",
    "snippet": "static int rto_next_cpu(struct root_domain *rd)\n{\n\tint next;\n\tint cpu;\n\n\t/*\n\t * When starting the IPI RT pushing, the rto_cpu is set to -1,\n\t * rt_next_cpu() will simply return the first CPU found in\n\t * the rto_mask.\n\t *\n\t * If rto_next_cpu() is called with rto_cpu is a valid CPU, it\n\t * will return the next CPU found in the rto_mask.\n\t *\n\t * If there are no more CPUs left in the rto_mask, then a check is made\n\t * against rto_loop and rto_loop_next. rto_loop is only updated with\n\t * the rto_lock held, but any CPU may increment the rto_loop_next\n\t * without any locking.\n\t */\n\tfor (;;) {\n\n\t\t/* When rto_cpu is -1 this acts like cpumask_first() */\n\t\tcpu = cpumask_next(rd->rto_cpu, rd->rto_mask);\n\n\t\trd->rto_cpu = cpu;\n\n\t\tif (cpu < nr_cpu_ids)\n\t\t\treturn cpu;\n\n\t\trd->rto_cpu = -1;\n\n\t\t/*\n\t\t * ACQUIRE ensures we see the @rto_mask changes\n\t\t * made prior to the @next value observed.\n\t\t *\n\t\t * Matches WMB in rt_set_overload().\n\t\t */\n\t\tnext = atomic_read_acquire(&rd->rto_loop_next);\n\n\t\tif (rd->rto_loop == next)\n\t\t\tbreak;\n\n\t\trd->rto_loop = next;\n\t}\n\n\treturn -1;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_read_acquire",
          "args": [
            "&rd->rto_loop_next"
          ],
          "line": 2207
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_next",
          "args": [
            "rd->rto_cpu",
            "rd->rto_mask"
          ],
          "line": 2192
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int rto_next_cpu(struct root_domain *rd)\n{\n\tint next;\n\tint cpu;\n\n\t/*\n\t * When starting the IPI RT pushing, the rto_cpu is set to -1,\n\t * rt_next_cpu() will simply return the first CPU found in\n\t * the rto_mask.\n\t *\n\t * If rto_next_cpu() is called with rto_cpu is a valid CPU, it\n\t * will return the next CPU found in the rto_mask.\n\t *\n\t * If there are no more CPUs left in the rto_mask, then a check is made\n\t * against rto_loop and rto_loop_next. rto_loop is only updated with\n\t * the rto_lock held, but any CPU may increment the rto_loop_next\n\t * without any locking.\n\t */\n\tfor (;;) {\n\n\t\t/* When rto_cpu is -1 this acts like cpumask_first() */\n\t\tcpu = cpumask_next(rd->rto_cpu, rd->rto_mask);\n\n\t\trd->rto_cpu = cpu;\n\n\t\tif (cpu < nr_cpu_ids)\n\t\t\treturn cpu;\n\n\t\trd->rto_cpu = -1;\n\n\t\t/*\n\t\t * ACQUIRE ensures we see the @rto_mask changes\n\t\t * made prior to the @next value observed.\n\t\t *\n\t\t * Matches WMB in rt_set_overload().\n\t\t */\n\t\tnext = atomic_read_acquire(&rd->rto_loop_next);\n\n\t\tif (rd->rto_loop == next)\n\t\t\tbreak;\n\n\t\trd->rto_loop = next;\n\t}\n\n\treturn -1;\n}"
  },
  {
    "function_name": "push_rt_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2121-2126",
    "snippet": "static void push_rt_tasks(struct rq *rq)\n{\n\t/* push_rt_task will return true if it moved an RT */\n\twhile (push_rt_task(rq, false))\n\t\t;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "push_rt_task",
          "args": [
            "rq",
            "false"
          ],
          "line": 2124
        },
        "resolved": true,
        "details": {
          "function_name": "push_rt_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2015-2119",
          "snippet": "static int push_rt_task(struct rq *rq, bool pull)\n{\n\tstruct task_struct *next_task;\n\tstruct rq *lowest_rq;\n\tint ret = 0;\n\n\tif (!rq->rt.overloaded)\n\t\treturn 0;\n\n\tnext_task = pick_next_pushable_task(rq);\n\tif (!next_task)\n\t\treturn 0;\n\nretry:\n\tif (is_migration_disabled(next_task)) {\n\t\tstruct task_struct *push_task = NULL;\n\t\tint cpu;\n\n\t\tif (!pull || rq->push_busy)\n\t\t\treturn 0;\n\n\t\tcpu = find_lowest_rq(rq->curr);\n\t\tif (cpu == -1 || cpu == rq->cpu)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Given we found a CPU with lower priority than @next_task,\n\t\t * therefore it should be running. However we cannot migrate it\n\t\t * to this other CPU, instead attempt to push the current\n\t\t * running task on this CPU away.\n\t\t */\n\t\tpush_task = get_push_task(rq);\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(rq);\n\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &rq->push_work);\n\t\t\traw_spin_rq_lock(rq);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (WARN_ON(next_task == rq->curr))\n\t\treturn 0;\n\n\t/*\n\t * It's possible that the next_task slipped in of\n\t * higher priority than current. If that's the case\n\t * just reschedule current.\n\t */\n\tif (unlikely(next_task->prio < rq->curr->prio)) {\n\t\tresched_curr(rq);\n\t\treturn 0;\n\t}\n\n\t/* We might release rq lock */\n\tget_task_struct(next_task);\n\n\t/* find_lock_lowest_rq locks the rq if found */\n\tlowest_rq = find_lock_lowest_rq(next_task, rq);\n\tif (!lowest_rq) {\n\t\tstruct task_struct *task;\n\t\t/*\n\t\t * find_lock_lowest_rq releases rq->lock\n\t\t * so it is possible that next_task has migrated.\n\t\t *\n\t\t * We need to make sure that the task is still on the same\n\t\t * run-queue and is also still the next task eligible for\n\t\t * pushing.\n\t\t */\n\t\ttask = pick_next_pushable_task(rq);\n\t\tif (task == next_task) {\n\t\t\t/*\n\t\t\t * The task hasn't migrated, and is still the next\n\t\t\t * eligible task, but we failed to find a run-queue\n\t\t\t * to push it to.  Do not retry in this case, since\n\t\t\t * other CPUs will pull from us when ready.\n\t\t\t */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!task)\n\t\t\t/* No more tasks, just exit */\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * Something has shifted, try again.\n\t\t */\n\t\tput_task_struct(next_task);\n\t\tnext_task = task;\n\t\tgoto retry;\n\t}\n\n\tdeactivate_task(rq, next_task, 0);\n\tset_task_cpu(next_task, lowest_rq->cpu);\n\tactivate_task(lowest_rq, next_task, 0);\n\tresched_curr(lowest_rq);\n\tret = 1;\n\n\tdouble_unlock_balance(rq, lowest_rq);\nout:\n\tput_task_struct(next_task);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int push_rt_task(struct rq *rq, bool pull)\n{\n\tstruct task_struct *next_task;\n\tstruct rq *lowest_rq;\n\tint ret = 0;\n\n\tif (!rq->rt.overloaded)\n\t\treturn 0;\n\n\tnext_task = pick_next_pushable_task(rq);\n\tif (!next_task)\n\t\treturn 0;\n\nretry:\n\tif (is_migration_disabled(next_task)) {\n\t\tstruct task_struct *push_task = NULL;\n\t\tint cpu;\n\n\t\tif (!pull || rq->push_busy)\n\t\t\treturn 0;\n\n\t\tcpu = find_lowest_rq(rq->curr);\n\t\tif (cpu == -1 || cpu == rq->cpu)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Given we found a CPU with lower priority than @next_task,\n\t\t * therefore it should be running. However we cannot migrate it\n\t\t * to this other CPU, instead attempt to push the current\n\t\t * running task on this CPU away.\n\t\t */\n\t\tpush_task = get_push_task(rq);\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(rq);\n\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &rq->push_work);\n\t\t\traw_spin_rq_lock(rq);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (WARN_ON(next_task == rq->curr))\n\t\treturn 0;\n\n\t/*\n\t * It's possible that the next_task slipped in of\n\t * higher priority than current. If that's the case\n\t * just reschedule current.\n\t */\n\tif (unlikely(next_task->prio < rq->curr->prio)) {\n\t\tresched_curr(rq);\n\t\treturn 0;\n\t}\n\n\t/* We might release rq lock */\n\tget_task_struct(next_task);\n\n\t/* find_lock_lowest_rq locks the rq if found */\n\tlowest_rq = find_lock_lowest_rq(next_task, rq);\n\tif (!lowest_rq) {\n\t\tstruct task_struct *task;\n\t\t/*\n\t\t * find_lock_lowest_rq releases rq->lock\n\t\t * so it is possible that next_task has migrated.\n\t\t *\n\t\t * We need to make sure that the task is still on the same\n\t\t * run-queue and is also still the next task eligible for\n\t\t * pushing.\n\t\t */\n\t\ttask = pick_next_pushable_task(rq);\n\t\tif (task == next_task) {\n\t\t\t/*\n\t\t\t * The task hasn't migrated, and is still the next\n\t\t\t * eligible task, but we failed to find a run-queue\n\t\t\t * to push it to.  Do not retry in this case, since\n\t\t\t * other CPUs will pull from us when ready.\n\t\t\t */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!task)\n\t\t\t/* No more tasks, just exit */\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * Something has shifted, try again.\n\t\t */\n\t\tput_task_struct(next_task);\n\t\tnext_task = task;\n\t\tgoto retry;\n\t}\n\n\tdeactivate_task(rq, next_task, 0);\n\tset_task_cpu(next_task, lowest_rq->cpu);\n\tactivate_task(lowest_rq, next_task, 0);\n\tresched_curr(lowest_rq);\n\tret = 1;\n\n\tdouble_unlock_balance(rq, lowest_rq);\nout:\n\tput_task_struct(next_task);\n\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void push_rt_tasks(struct rq *rq)\n{\n\t/* push_rt_task will return true if it moved an RT */\n\twhile (push_rt_task(rq, false))\n\t\t;\n}"
  },
  {
    "function_name": "push_rt_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "2015-2119",
    "snippet": "static int push_rt_task(struct rq *rq, bool pull)\n{\n\tstruct task_struct *next_task;\n\tstruct rq *lowest_rq;\n\tint ret = 0;\n\n\tif (!rq->rt.overloaded)\n\t\treturn 0;\n\n\tnext_task = pick_next_pushable_task(rq);\n\tif (!next_task)\n\t\treturn 0;\n\nretry:\n\tif (is_migration_disabled(next_task)) {\n\t\tstruct task_struct *push_task = NULL;\n\t\tint cpu;\n\n\t\tif (!pull || rq->push_busy)\n\t\t\treturn 0;\n\n\t\tcpu = find_lowest_rq(rq->curr);\n\t\tif (cpu == -1 || cpu == rq->cpu)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Given we found a CPU with lower priority than @next_task,\n\t\t * therefore it should be running. However we cannot migrate it\n\t\t * to this other CPU, instead attempt to push the current\n\t\t * running task on this CPU away.\n\t\t */\n\t\tpush_task = get_push_task(rq);\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(rq);\n\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &rq->push_work);\n\t\t\traw_spin_rq_lock(rq);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (WARN_ON(next_task == rq->curr))\n\t\treturn 0;\n\n\t/*\n\t * It's possible that the next_task slipped in of\n\t * higher priority than current. If that's the case\n\t * just reschedule current.\n\t */\n\tif (unlikely(next_task->prio < rq->curr->prio)) {\n\t\tresched_curr(rq);\n\t\treturn 0;\n\t}\n\n\t/* We might release rq lock */\n\tget_task_struct(next_task);\n\n\t/* find_lock_lowest_rq locks the rq if found */\n\tlowest_rq = find_lock_lowest_rq(next_task, rq);\n\tif (!lowest_rq) {\n\t\tstruct task_struct *task;\n\t\t/*\n\t\t * find_lock_lowest_rq releases rq->lock\n\t\t * so it is possible that next_task has migrated.\n\t\t *\n\t\t * We need to make sure that the task is still on the same\n\t\t * run-queue and is also still the next task eligible for\n\t\t * pushing.\n\t\t */\n\t\ttask = pick_next_pushable_task(rq);\n\t\tif (task == next_task) {\n\t\t\t/*\n\t\t\t * The task hasn't migrated, and is still the next\n\t\t\t * eligible task, but we failed to find a run-queue\n\t\t\t * to push it to.  Do not retry in this case, since\n\t\t\t * other CPUs will pull from us when ready.\n\t\t\t */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!task)\n\t\t\t/* No more tasks, just exit */\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * Something has shifted, try again.\n\t\t */\n\t\tput_task_struct(next_task);\n\t\tnext_task = task;\n\t\tgoto retry;\n\t}\n\n\tdeactivate_task(rq, next_task, 0);\n\tset_task_cpu(next_task, lowest_rq->cpu);\n\tactivate_task(lowest_rq, next_task, 0);\n\tresched_curr(lowest_rq);\n\tret = 1;\n\n\tdouble_unlock_balance(rq, lowest_rq);\nout:\n\tput_task_struct(next_task);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_task_struct",
          "args": [
            "next_task"
          ],
          "line": 2116
        },
        "resolved": true,
        "details": {
          "function_name": "__put_task_struct",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/fork.c",
          "lines": "745-761",
          "snippet": "void __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <linux/bpf.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/scs.h>",
            "#include <linux/kasan.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/anon_inodes.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <linux/bpf.h>\n#include <linux/io_uring.h>\n#include <linux/scs.h>\n#include <linux/kasan.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm_inline.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/seq_file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n\nstatic __latent_entropy struct;\n\nvoid __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "double_unlock_balance",
          "args": [
            "rq",
            "lowest_rq"
          ],
          "line": 2114
        },
        "resolved": true,
        "details": {
          "function_name": "double_unlock_balance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2597-2603",
          "snippet": "static inline void double_unlock_balance(struct rq *this_rq, struct rq *busiest)\n\t__releases(busiest->lock)\n{\n\tif (__rq_lockp(this_rq) != __rq_lockp(busiest))\n\t\traw_spin_rq_unlock(busiest);\n\tlock_set_subclass(&__rq_lockp(this_rq)->dep_map, 0, _RET_IP_);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void calc_global_load_tick(struct rq *this_rq);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "struct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);",
            "struct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void calc_global_load_tick(struct rq *this_rq);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nstruct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);\nstruct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void double_unlock_balance(struct rq *this_rq, struct rq *busiest)\n\t__releases(busiest->lock)\n{\n\tif (__rq_lockp(this_rq) != __rq_lockp(busiest))\n\t\traw_spin_rq_unlock(busiest);\n\tlock_set_subclass(&__rq_lockp(this_rq)->dep_map, 0, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "lowest_rq"
          ],
          "line": 2111
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "activate_task",
          "args": [
            "lowest_rq",
            "next_task",
            "0"
          ],
          "line": 2110
        },
        "resolved": true,
        "details": {
          "function_name": "deactivate_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2040-2045",
          "snippet": "void deactivate_task(struct rq *rq, struct task_struct *p, int flags)\n{\n\tp->on_rq = (flags & DEQUEUE_SLEEP) ? 0 : TASK_ON_RQ_MIGRATING;\n\n\tdequeue_task(rq, p, flags);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid deactivate_task(struct rq *rq, struct task_struct *p, int flags)\n{\n\tp->on_rq = (flags & DEQUEUE_SLEEP) ? 0 : TASK_ON_RQ_MIGRATING;\n\n\tdequeue_task(rq, p, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_task_cpu",
          "args": [
            "next_task",
            "lowest_rq->cpu"
          ],
          "line": 2109
        },
        "resolved": true,
        "details": {
          "function_name": "set_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "3026-3079",
          "snippet": "void set_task_cpu(struct task_struct *p, unsigned int new_cpu)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tunsigned int state = READ_ONCE(p->__state);\n\n\t/*\n\t * We should never call set_task_cpu() on a blocked task,\n\t * ttwu() will sort out the placement.\n\t */\n\tWARN_ON_ONCE(state != TASK_RUNNING && state != TASK_WAKING && !p->on_rq);\n\n\t/*\n\t * Migrating fair class task must have p->on_rq = TASK_ON_RQ_MIGRATING,\n\t * because schedstat_wait_{start,end} rebase migrating task's wait_start\n\t * time relying on p->on_rq.\n\t */\n\tWARN_ON_ONCE(state == TASK_RUNNING &&\n\t\t     p->sched_class == &fair_sched_class &&\n\t\t     (p->on_rq && !task_on_rq_migrating(p)));\n\n#ifdef CONFIG_LOCKDEP\n\t/*\n\t * The caller should hold either p->pi_lock or rq->lock, when changing\n\t * a task's CPU. ->pi_lock for waking tasks, rq->lock for runnable tasks.\n\t *\n\t * sched_move_task() holds both and thus holding either pins the cgroup,\n\t * see task_group().\n\t *\n\t * Furthermore, all task_rq users should acquire both locks, see\n\t * task_rq_lock().\n\t */\n\tWARN_ON_ONCE(debug_locks && !(lockdep_is_held(&p->pi_lock) ||\n\t\t\t\t      lockdep_is_held(__rq_lockp(task_rq(p)))));\n#endif\n\t/*\n\t * Clearly, migrating tasks to offline CPUs is a fairly daft thing.\n\t */\n\tWARN_ON_ONCE(!cpu_online(new_cpu));\n\n\tWARN_ON_ONCE(is_migration_disabled(p));\n#endif\n\n\ttrace_sched_migrate_task(p, new_cpu);\n\n\tif (task_cpu(p) != new_cpu) {\n\t\tif (p->sched_class->migrate_task_rq)\n\t\t\tp->sched_class->migrate_task_rq(p, new_cpu);\n\t\tp->se.nr_migrations++;\n\t\trseq_migrate(p);\n\t\tperf_event_task_migrate(p);\n\t}\n\n\t__set_task_cpu(p, new_cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid set_task_cpu(struct task_struct *p, unsigned int new_cpu)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tunsigned int state = READ_ONCE(p->__state);\n\n\t/*\n\t * We should never call set_task_cpu() on a blocked task,\n\t * ttwu() will sort out the placement.\n\t */\n\tWARN_ON_ONCE(state != TASK_RUNNING && state != TASK_WAKING && !p->on_rq);\n\n\t/*\n\t * Migrating fair class task must have p->on_rq = TASK_ON_RQ_MIGRATING,\n\t * because schedstat_wait_{start,end} rebase migrating task's wait_start\n\t * time relying on p->on_rq.\n\t */\n\tWARN_ON_ONCE(state == TASK_RUNNING &&\n\t\t     p->sched_class == &fair_sched_class &&\n\t\t     (p->on_rq && !task_on_rq_migrating(p)));\n\n#ifdef CONFIG_LOCKDEP\n\t/*\n\t * The caller should hold either p->pi_lock or rq->lock, when changing\n\t * a task's CPU. ->pi_lock for waking tasks, rq->lock for runnable tasks.\n\t *\n\t * sched_move_task() holds both and thus holding either pins the cgroup,\n\t * see task_group().\n\t *\n\t * Furthermore, all task_rq users should acquire both locks, see\n\t * task_rq_lock().\n\t */\n\tWARN_ON_ONCE(debug_locks && !(lockdep_is_held(&p->pi_lock) ||\n\t\t\t\t      lockdep_is_held(__rq_lockp(task_rq(p)))));\n#endif\n\t/*\n\t * Clearly, migrating tasks to offline CPUs is a fairly daft thing.\n\t */\n\tWARN_ON_ONCE(!cpu_online(new_cpu));\n\n\tWARN_ON_ONCE(is_migration_disabled(p));\n#endif\n\n\ttrace_sched_migrate_task(p, new_cpu);\n\n\tif (task_cpu(p) != new_cpu) {\n\t\tif (p->sched_class->migrate_task_rq)\n\t\t\tp->sched_class->migrate_task_rq(p, new_cpu);\n\t\tp->se.nr_migrations++;\n\t\trseq_migrate(p);\n\t\tperf_event_task_migrate(p);\n\t}\n\n\t__set_task_cpu(p, new_cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pick_next_pushable_task",
          "args": [
            "rq"
          ],
          "line": 2085
        },
        "resolved": true,
        "details": {
          "function_name": "pick_next_pushable_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1990-2008",
          "snippet": "static struct task_struct *pick_next_pushable_task(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tp = plist_first_entry(&rq->rt.pushable_tasks,\n\t\t\t      struct task_struct, pushable_tasks);\n\n\tBUG_ON(rq->cpu != task_cpu(p));\n\tBUG_ON(task_current(rq, p));\n\tBUG_ON(p->nr_cpus_allowed <= 1);\n\n\tBUG_ON(!task_on_rq_queued(p));\n\tBUG_ON(!rt_task(p));\n\n\treturn p;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct task_struct *pick_next_pushable_task(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tp = plist_first_entry(&rq->rt.pushable_tasks,\n\t\t\t      struct task_struct, pushable_tasks);\n\n\tBUG_ON(rq->cpu != task_cpu(p));\n\tBUG_ON(task_current(rq, p));\n\tBUG_ON(p->nr_cpus_allowed <= 1);\n\n\tBUG_ON(!task_on_rq_queued(p));\n\tBUG_ON(!rt_task(p));\n\n\treturn p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "find_lock_lowest_rq",
          "args": [
            "next_task",
            "rq"
          ],
          "line": 2074
        },
        "resolved": true,
        "details": {
          "function_name": "find_lock_lowest_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1934-1988",
          "snippet": "static struct rq *find_lock_lowest_rq(struct task_struct *task, struct rq *rq)\n{\n\tstruct rq *lowest_rq = NULL;\n\tint tries;\n\tint cpu;\n\n\tfor (tries = 0; tries < RT_MAX_TRIES; tries++) {\n\t\tcpu = find_lowest_rq(task);\n\n\t\tif ((cpu == -1) || (cpu == rq->cpu))\n\t\t\tbreak;\n\n\t\tlowest_rq = cpu_rq(cpu);\n\n\t\tif (lowest_rq->rt.highest_prio.curr <= task->prio) {\n\t\t\t/*\n\t\t\t * Target rq has tasks of equal or higher priority,\n\t\t\t * retrying does not release any lock and is unlikely\n\t\t\t * to yield a different result.\n\t\t\t */\n\t\t\tlowest_rq = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* if the prio of this runqueue changed, try again */\n\t\tif (double_lock_balance(rq, lowest_rq)) {\n\t\t\t/*\n\t\t\t * We had to unlock the run queue. In\n\t\t\t * the mean time, task could have\n\t\t\t * migrated already or had its affinity changed.\n\t\t\t * Also make sure that it wasn't scheduled on its rq.\n\t\t\t */\n\t\t\tif (unlikely(task_rq(task) != rq ||\n\t\t\t\t     !cpumask_test_cpu(lowest_rq->cpu, &task->cpus_mask) ||\n\t\t\t\t     task_running(rq, task) ||\n\t\t\t\t     !rt_task(task) ||\n\t\t\t\t     !task_on_rq_queued(task))) {\n\n\t\t\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\t\t\tlowest_rq = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If this rq is still suitable use it. */\n\t\tif (lowest_rq->rt.highest_prio.curr > task->prio)\n\t\t\tbreak;\n\n\t\t/* try again */\n\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\tlowest_rq = NULL;\n\t}\n\n\treturn lowest_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [
            "#define RT_MAX_TRIES 3"
          ],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\n#define RT_MAX_TRIES 3\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct rq *find_lock_lowest_rq(struct task_struct *task, struct rq *rq)\n{\n\tstruct rq *lowest_rq = NULL;\n\tint tries;\n\tint cpu;\n\n\tfor (tries = 0; tries < RT_MAX_TRIES; tries++) {\n\t\tcpu = find_lowest_rq(task);\n\n\t\tif ((cpu == -1) || (cpu == rq->cpu))\n\t\t\tbreak;\n\n\t\tlowest_rq = cpu_rq(cpu);\n\n\t\tif (lowest_rq->rt.highest_prio.curr <= task->prio) {\n\t\t\t/*\n\t\t\t * Target rq has tasks of equal or higher priority,\n\t\t\t * retrying does not release any lock and is unlikely\n\t\t\t * to yield a different result.\n\t\t\t */\n\t\t\tlowest_rq = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* if the prio of this runqueue changed, try again */\n\t\tif (double_lock_balance(rq, lowest_rq)) {\n\t\t\t/*\n\t\t\t * We had to unlock the run queue. In\n\t\t\t * the mean time, task could have\n\t\t\t * migrated already or had its affinity changed.\n\t\t\t * Also make sure that it wasn't scheduled on its rq.\n\t\t\t */\n\t\t\tif (unlikely(task_rq(task) != rq ||\n\t\t\t\t     !cpumask_test_cpu(lowest_rq->cpu, &task->cpus_mask) ||\n\t\t\t\t     task_running(rq, task) ||\n\t\t\t\t     !rt_task(task) ||\n\t\t\t\t     !task_on_rq_queued(task))) {\n\n\t\t\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\t\t\tlowest_rq = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If this rq is still suitable use it. */\n\t\tif (lowest_rq->rt.highest_prio.curr > task->prio)\n\t\t\tbreak;\n\n\t\t/* try again */\n\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\tlowest_rq = NULL;\n\t}\n\n\treturn lowest_rq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_task_struct",
          "args": [
            "next_task"
          ],
          "line": 2071
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "next_task->prio < rq->curr->prio"
          ],
          "line": 2065
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "next_task == rq->curr"
          ],
          "line": 2057
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_lock",
          "args": [
            "rq"
          ],
          "line": 2051
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_rq_lock_irqsave",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1333-1339",
          "snippet": "static inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void activate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void activate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);\n\nstatic inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "stop_one_cpu_nowait",
          "args": [
            "rq->cpu",
            "push_cpu_stop",
            "push_task",
            "&rq->push_work"
          ],
          "line": 2049
        },
        "resolved": true,
        "details": {
          "function_name": "stop_one_cpu_nowait",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/stop_machine.c",
          "lines": "384-389",
          "snippet": "bool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,\n\t\t\tstruct cpu_stop_work *work_buf)\n{\n\t*work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, .caller = _RET_IP_, };\n\treturn cpu_stop_queue_work(cpu, work_buf);\n}",
          "includes": [
            "#include <linux/sched/wake_q.h>",
            "#include <linux/nmi.h>",
            "#include <linux/atomic.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kthread.h>",
            "#include <linux/init.h>",
            "#include <linux/cpu.h>",
            "#include <linux/completion.h>",
            "#include <linux/compiler.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/wake_q.h>\n#include <linux/nmi.h>\n#include <linux/atomic.h>\n#include <linux/smpboot.h>\n#include <linux/kallsyms.h>\n#include <linux/interrupt.h>\n#include <linux/stop_machine.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kthread.h>\n#include <linux/init.h>\n#include <linux/cpu.h>\n#include <linux/completion.h>\n#include <linux/compiler.h>\n\nbool stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,\n\t\t\tstruct cpu_stop_work *work_buf)\n{\n\t*work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, .caller = _RET_IP_, };\n\treturn cpu_stop_queue_work(cpu, work_buf);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_unlock",
          "args": [
            "rq"
          ],
          "line": 2048
        },
        "resolved": true,
        "details": {
          "function_name": "raw_spin_rq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "531-534",
          "snippet": "void raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_push_task",
          "args": [
            "rq"
          ],
          "line": 2046
        },
        "resolved": true,
        "details": {
          "function_name": "get_push_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2268-2285",
          "snippet": "static inline struct task_struct *get_push_task(struct rq *rq)\n{\n\tstruct task_struct *p = rq->curr;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (rq->push_busy)\n\t\treturn NULL;\n\n\tif (p->nr_cpus_allowed == 1)\n\t\treturn NULL;\n\n\tif (p->migration_disabled)\n\t\treturn NULL;\n\n\trq->push_busy = true;\n\treturn get_task_struct(p);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline struct task_struct *get_push_task(struct rq *rq)\n{\n\tstruct task_struct *p = rq->curr;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (rq->push_busy)\n\t\treturn NULL;\n\n\tif (p->nr_cpus_allowed == 1)\n\t\treturn NULL;\n\n\tif (p->migration_disabled)\n\t\treturn NULL;\n\n\trq->push_busy = true;\n\treturn get_task_struct(p);\n}"
        }
      },
      {
        "call_info": {
          "callee": "find_lowest_rq",
          "args": [
            "rq->curr"
          ],
          "line": 2036
        },
        "resolved": true,
        "details": {
          "function_name": "find_lowest_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1842-1931",
          "snippet": "static int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_migration_disabled",
          "args": [
            "next_task"
          ],
          "line": 2029
        },
        "resolved": true,
        "details": {
          "function_name": "is_migration_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1148-1155",
          "snippet": "static inline bool is_migration_disabled(struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->migration_disabled;\n#else\n\treturn false;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline bool is_migration_disabled(struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->migration_disabled;\n#else\n\treturn false;\n#endif\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int push_rt_task(struct rq *rq, bool pull)\n{\n\tstruct task_struct *next_task;\n\tstruct rq *lowest_rq;\n\tint ret = 0;\n\n\tif (!rq->rt.overloaded)\n\t\treturn 0;\n\n\tnext_task = pick_next_pushable_task(rq);\n\tif (!next_task)\n\t\treturn 0;\n\nretry:\n\tif (is_migration_disabled(next_task)) {\n\t\tstruct task_struct *push_task = NULL;\n\t\tint cpu;\n\n\t\tif (!pull || rq->push_busy)\n\t\t\treturn 0;\n\n\t\tcpu = find_lowest_rq(rq->curr);\n\t\tif (cpu == -1 || cpu == rq->cpu)\n\t\t\treturn 0;\n\n\t\t/*\n\t\t * Given we found a CPU with lower priority than @next_task,\n\t\t * therefore it should be running. However we cannot migrate it\n\t\t * to this other CPU, instead attempt to push the current\n\t\t * running task on this CPU away.\n\t\t */\n\t\tpush_task = get_push_task(rq);\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(rq);\n\t\t\tstop_one_cpu_nowait(rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &rq->push_work);\n\t\t\traw_spin_rq_lock(rq);\n\t\t}\n\n\t\treturn 0;\n\t}\n\n\tif (WARN_ON(next_task == rq->curr))\n\t\treturn 0;\n\n\t/*\n\t * It's possible that the next_task slipped in of\n\t * higher priority than current. If that's the case\n\t * just reschedule current.\n\t */\n\tif (unlikely(next_task->prio < rq->curr->prio)) {\n\t\tresched_curr(rq);\n\t\treturn 0;\n\t}\n\n\t/* We might release rq lock */\n\tget_task_struct(next_task);\n\n\t/* find_lock_lowest_rq locks the rq if found */\n\tlowest_rq = find_lock_lowest_rq(next_task, rq);\n\tif (!lowest_rq) {\n\t\tstruct task_struct *task;\n\t\t/*\n\t\t * find_lock_lowest_rq releases rq->lock\n\t\t * so it is possible that next_task has migrated.\n\t\t *\n\t\t * We need to make sure that the task is still on the same\n\t\t * run-queue and is also still the next task eligible for\n\t\t * pushing.\n\t\t */\n\t\ttask = pick_next_pushable_task(rq);\n\t\tif (task == next_task) {\n\t\t\t/*\n\t\t\t * The task hasn't migrated, and is still the next\n\t\t\t * eligible task, but we failed to find a run-queue\n\t\t\t * to push it to.  Do not retry in this case, since\n\t\t\t * other CPUs will pull from us when ready.\n\t\t\t */\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!task)\n\t\t\t/* No more tasks, just exit */\n\t\t\tgoto out;\n\n\t\t/*\n\t\t * Something has shifted, try again.\n\t\t */\n\t\tput_task_struct(next_task);\n\t\tnext_task = task;\n\t\tgoto retry;\n\t}\n\n\tdeactivate_task(rq, next_task, 0);\n\tset_task_cpu(next_task, lowest_rq->cpu);\n\tactivate_task(lowest_rq, next_task, 0);\n\tresched_curr(lowest_rq);\n\tret = 1;\n\n\tdouble_unlock_balance(rq, lowest_rq);\nout:\n\tput_task_struct(next_task);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "pick_next_pushable_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1990-2008",
    "snippet": "static struct task_struct *pick_next_pushable_task(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tp = plist_first_entry(&rq->rt.pushable_tasks,\n\t\t\t      struct task_struct, pushable_tasks);\n\n\tBUG_ON(rq->cpu != task_cpu(p));\n\tBUG_ON(task_current(rq, p));\n\tBUG_ON(p->nr_cpus_allowed <= 1);\n\n\tBUG_ON(!task_on_rq_queued(p));\n\tBUG_ON(!rt_task(p));\n\n\treturn p;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!rt_task(p)"
          ],
          "line": 2005
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "p"
          ],
          "line": 2005
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!task_on_rq_queued(p)"
          ],
          "line": 2004
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_on_rq_queued",
          "args": [
            "p"
          ],
          "line": 2004
        },
        "resolved": true,
        "details": {
          "function_name": "task_on_rq_queued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2044-2047",
          "snippet": "static inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define TASK_ON_RQ_QUEUED\t1"
          ],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define TASK_ON_RQ_QUEUED\t1\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "p->nr_cpus_allowed <= 1"
          ],
          "line": 2002
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "task_current(rq, p)"
          ],
          "line": 2001
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_current",
          "args": [
            "rq",
            "p"
          ],
          "line": 2001
        },
        "resolved": true,
        "details": {
          "function_name": "task_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2030-2033",
          "snippet": "static inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "rq->cpu != task_cpu(p)"
          ],
          "line": 2000
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "p"
          ],
          "line": 2000
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ftrace.c",
          "lines": "7612-7633",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include \"ftrace_internal.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include \"ftrace_internal.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "plist_first_entry",
          "args": [
            "&rq->rt.pushable_tasks",
            "structtask_struct",
            "pushable_tasks"
          ],
          "line": 1997
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "has_pushable_tasks",
          "args": [
            "rq"
          ],
          "line": 1994
        },
        "resolved": true,
        "details": {
          "function_name": "has_pushable_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "363-366",
          "snippet": "static inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct task_struct *pick_next_pushable_task(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tp = plist_first_entry(&rq->rt.pushable_tasks,\n\t\t\t      struct task_struct, pushable_tasks);\n\n\tBUG_ON(rq->cpu != task_cpu(p));\n\tBUG_ON(task_current(rq, p));\n\tBUG_ON(p->nr_cpus_allowed <= 1);\n\n\tBUG_ON(!task_on_rq_queued(p));\n\tBUG_ON(!rt_task(p));\n\n\treturn p;\n}"
  },
  {
    "function_name": "find_lock_lowest_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1934-1988",
    "snippet": "static struct rq *find_lock_lowest_rq(struct task_struct *task, struct rq *rq)\n{\n\tstruct rq *lowest_rq = NULL;\n\tint tries;\n\tint cpu;\n\n\tfor (tries = 0; tries < RT_MAX_TRIES; tries++) {\n\t\tcpu = find_lowest_rq(task);\n\n\t\tif ((cpu == -1) || (cpu == rq->cpu))\n\t\t\tbreak;\n\n\t\tlowest_rq = cpu_rq(cpu);\n\n\t\tif (lowest_rq->rt.highest_prio.curr <= task->prio) {\n\t\t\t/*\n\t\t\t * Target rq has tasks of equal or higher priority,\n\t\t\t * retrying does not release any lock and is unlikely\n\t\t\t * to yield a different result.\n\t\t\t */\n\t\t\tlowest_rq = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* if the prio of this runqueue changed, try again */\n\t\tif (double_lock_balance(rq, lowest_rq)) {\n\t\t\t/*\n\t\t\t * We had to unlock the run queue. In\n\t\t\t * the mean time, task could have\n\t\t\t * migrated already or had its affinity changed.\n\t\t\t * Also make sure that it wasn't scheduled on its rq.\n\t\t\t */\n\t\t\tif (unlikely(task_rq(task) != rq ||\n\t\t\t\t     !cpumask_test_cpu(lowest_rq->cpu, &task->cpus_mask) ||\n\t\t\t\t     task_running(rq, task) ||\n\t\t\t\t     !rt_task(task) ||\n\t\t\t\t     !task_on_rq_queued(task))) {\n\n\t\t\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\t\t\tlowest_rq = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If this rq is still suitable use it. */\n\t\tif (lowest_rq->rt.highest_prio.curr > task->prio)\n\t\t\tbreak;\n\n\t\t/* try again */\n\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\tlowest_rq = NULL;\n\t}\n\n\treturn lowest_rq;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [
      "#define RT_MAX_TRIES 3"
    ],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "double_unlock_balance",
          "args": [
            "rq",
            "lowest_rq"
          ],
          "line": 1983
        },
        "resolved": true,
        "details": {
          "function_name": "double_unlock_balance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2597-2603",
          "snippet": "static inline void double_unlock_balance(struct rq *this_rq, struct rq *busiest)\n\t__releases(busiest->lock)\n{\n\tif (__rq_lockp(this_rq) != __rq_lockp(busiest))\n\t\traw_spin_rq_unlock(busiest);\n\tlock_set_subclass(&__rq_lockp(this_rq)->dep_map, 0, _RET_IP_);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void calc_global_load_tick(struct rq *this_rq);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "struct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);",
            "struct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void calc_global_load_tick(struct rq *this_rq);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nstruct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);\nstruct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void double_unlock_balance(struct rq *this_rq, struct rq *busiest)\n\t__releases(busiest->lock)\n{\n\tif (__rq_lockp(this_rq) != __rq_lockp(busiest))\n\t\traw_spin_rq_unlock(busiest);\n\tlock_set_subclass(&__rq_lockp(this_rq)->dep_map, 0, _RET_IP_);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "task_rq(task) != rq ||\n\t\t\t\t     !cpumask_test_cpu(lowest_rq->cpu, &task->cpus_mask) ||\n\t\t\t\t     task_running(rq, task) ||\n\t\t\t\t     !rt_task(task) ||\n\t\t\t\t     !task_on_rq_queued(task)"
          ],
          "line": 1966
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_on_rq_queued",
          "args": [
            "task"
          ],
          "line": 1970
        },
        "resolved": true,
        "details": {
          "function_name": "task_on_rq_queued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2044-2047",
          "snippet": "static inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define TASK_ON_RQ_QUEUED\t1"
          ],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define TASK_ON_RQ_QUEUED\t1\n\nvoid __dl_clear_params(struct task_struct *p);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_on_rq_queued(struct task_struct *p)\n{\n\treturn p->on_rq == TASK_ON_RQ_QUEUED;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "task"
          ],
          "line": 1969
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_running",
          "args": [
            "rq",
            "task"
          ],
          "line": 1968
        },
        "resolved": true,
        "details": {
          "function_name": "task_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2035-2042",
          "snippet": "static inline int task_running(struct rq *rq, struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->on_cpu;\n#else\n\treturn task_current(rq, p);\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_running(struct rq *rq, struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->on_cpu;\n#else\n\treturn task_current(rq, p);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "lowest_rq->cpu",
            "&task->cpus_mask"
          ],
          "line": 1967
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_rq",
          "args": [
            "task"
          ],
          "line": 1966
        },
        "resolved": true,
        "details": {
          "function_name": "is_task_rq_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5634-5637",
          "snippet": "static inline bool is_task_rq_idle(struct task_struct *t)\n{\n\treturn (task_rq(t)->idle == t);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline bool is_task_rq_idle(struct task_struct *t)\n{\n\treturn (task_rq(t)->idle == t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "double_lock_balance",
          "args": [
            "rq",
            "lowest_rq"
          ],
          "line": 1959
        },
        "resolved": true,
        "details": {
          "function_name": "double_lock_balance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2590-2595",
          "snippet": "static inline int double_lock_balance(struct rq *this_rq, struct rq *busiest)\n{\n\tlockdep_assert_irqs_disabled();\n\n\treturn _double_lock_balance(this_rq, busiest);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void calc_global_load_tick(struct rq *this_rq);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void calc_global_load_tick(struct rq *this_rq);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline int double_lock_balance(struct rq *this_rq, struct rq *busiest)\n{\n\tlockdep_assert_irqs_disabled();\n\n\treturn _double_lock_balance(this_rq, busiest);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 1946
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "find_lowest_rq",
          "args": [
            "task"
          ],
          "line": 1941
        },
        "resolved": true,
        "details": {
          "function_name": "find_lowest_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1842-1931",
          "snippet": "static int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\n#define RT_MAX_TRIES 3\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct rq *find_lock_lowest_rq(struct task_struct *task, struct rq *rq)\n{\n\tstruct rq *lowest_rq = NULL;\n\tint tries;\n\tint cpu;\n\n\tfor (tries = 0; tries < RT_MAX_TRIES; tries++) {\n\t\tcpu = find_lowest_rq(task);\n\n\t\tif ((cpu == -1) || (cpu == rq->cpu))\n\t\t\tbreak;\n\n\t\tlowest_rq = cpu_rq(cpu);\n\n\t\tif (lowest_rq->rt.highest_prio.curr <= task->prio) {\n\t\t\t/*\n\t\t\t * Target rq has tasks of equal or higher priority,\n\t\t\t * retrying does not release any lock and is unlikely\n\t\t\t * to yield a different result.\n\t\t\t */\n\t\t\tlowest_rq = NULL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* if the prio of this runqueue changed, try again */\n\t\tif (double_lock_balance(rq, lowest_rq)) {\n\t\t\t/*\n\t\t\t * We had to unlock the run queue. In\n\t\t\t * the mean time, task could have\n\t\t\t * migrated already or had its affinity changed.\n\t\t\t * Also make sure that it wasn't scheduled on its rq.\n\t\t\t */\n\t\t\tif (unlikely(task_rq(task) != rq ||\n\t\t\t\t     !cpumask_test_cpu(lowest_rq->cpu, &task->cpus_mask) ||\n\t\t\t\t     task_running(rq, task) ||\n\t\t\t\t     !rt_task(task) ||\n\t\t\t\t     !task_on_rq_queued(task))) {\n\n\t\t\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\t\t\tlowest_rq = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* If this rq is still suitable use it. */\n\t\tif (lowest_rq->rt.highest_prio.curr > task->prio)\n\t\t\tbreak;\n\n\t\t/* try again */\n\t\tdouble_unlock_balance(rq, lowest_rq);\n\t\tlowest_rq = NULL;\n\t}\n\n\treturn lowest_rq;\n}"
  },
  {
    "function_name": "find_lowest_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1842-1931",
    "snippet": "static int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_any_distribute",
          "args": [
            "lowest_mask"
          ],
          "line": 1926
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1916
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_any_and_distribute",
          "args": [
            "lowest_mask",
            "sched_domain_span(sd)"
          ],
          "line": 1908
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_domain_span",
          "args": [
            "sd"
          ],
          "line": 1909
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "this_cpu",
            "sched_domain_span(sd)"
          ],
          "line": 1903
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_domain_span",
          "args": [
            "sd"
          ],
          "line": 1903
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_domain",
          "args": [
            "cpu",
            "sd"
          ],
          "line": 1894
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1893
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "this_cpu",
            "lowest_mask"
          ],
          "line": 1890
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "lowest_mask"
          ],
          "line": 1883
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpupri_find",
          "args": [
            "&task_rq(task)->rd->cpupri",
            "task",
            "lowest_mask"
          ],
          "line": 1868
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_find",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "121-125",
          "snippet": "int cpupri_find(struct cpupri *cp, struct task_struct *p,\n\t\tstruct cpumask *lowest_mask)\n{\n\treturn cpupri_find_fitness(cp, p, lowest_mask, NULL);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nint cpupri_find(struct cpupri *cp, struct task_struct *p,\n\t\tstruct cpumask *lowest_mask)\n{\n\treturn cpupri_find_fitness(cp, p, lowest_mask, NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_rq",
          "args": [
            "task"
          ],
          "line": 1868
        },
        "resolved": true,
        "details": {
          "function_name": "is_task_rq_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5634-5637",
          "snippet": "static inline bool is_task_rq_idle(struct task_struct *t)\n{\n\treturn (task_rq(t)->idle == t);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline bool is_task_rq_idle(struct task_struct *t)\n{\n\treturn (task_rq(t)->idle == t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpupri_find_fitness",
          "args": [
            "&task_rq(task)->rd->cpupri",
            "task",
            "lowest_mask",
            "rt_task_fits_capacity"
          ],
          "line": 1863
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_find_fitness",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "144-198",
          "snippet": "int cpupri_find_fitness(struct cpupri *cp, struct task_struct *p,\n\t\tstruct cpumask *lowest_mask,\n\t\tbool (*fitness_fn)(struct task_struct *p, int cpu))\n{\n\tint task_pri = convert_prio(p->prio);\n\tint idx, cpu;\n\n\tBUG_ON(task_pri >= CPUPRI_NR_PRIORITIES);\n\n\tfor (idx = 0; idx < task_pri; idx++) {\n\n\t\tif (!__cpupri_find(cp, p, lowest_mask, idx))\n\t\t\tcontinue;\n\n\t\tif (!lowest_mask || !fitness_fn)\n\t\t\treturn 1;\n\n\t\t/* Ensure the capacity of the CPUs fit the task */\n\t\tfor_each_cpu(cpu, lowest_mask) {\n\t\t\tif (!fitness_fn(p, cpu))\n\t\t\t\tcpumask_clear_cpu(cpu, lowest_mask);\n\t\t}\n\n\t\t/*\n\t\t * If no CPU at the current priority can fit the task\n\t\t * continue looking\n\t\t */\n\t\tif (cpumask_empty(lowest_mask))\n\t\t\tcontinue;\n\n\t\treturn 1;\n\t}\n\n\t/*\n\t * If we failed to find a fitting lowest_mask, kick off a new search\n\t * but without taking into account any fitness criteria this time.\n\t *\n\t * This rule favours honouring priority over fitting the task in the\n\t * correct CPU (Capacity Awareness being the only user now).\n\t * The idea is that if a higher priority task can run, then it should\n\t * run even if this ends up being on unfitting CPU.\n\t *\n\t * The cost of this trade-off is not entirely clear and will probably\n\t * be good for some workloads and bad for others.\n\t *\n\t * The main idea here is that if some CPUs were over-committed, we try\n\t * to spread which is what the scheduler traditionally did. Sys admins\n\t * must do proper RT planning to avoid overloading the system if they\n\t * really care.\n\t */\n\tif (fitness_fn)\n\t\treturn cpupri_find(cp, p, lowest_mask);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nint cpupri_find_fitness(struct cpupri *cp, struct task_struct *p,\n\t\tstruct cpumask *lowest_mask,\n\t\tbool (*fitness_fn)(struct task_struct *p, int cpu))\n{\n\tint task_pri = convert_prio(p->prio);\n\tint idx, cpu;\n\n\tBUG_ON(task_pri >= CPUPRI_NR_PRIORITIES);\n\n\tfor (idx = 0; idx < task_pri; idx++) {\n\n\t\tif (!__cpupri_find(cp, p, lowest_mask, idx))\n\t\t\tcontinue;\n\n\t\tif (!lowest_mask || !fitness_fn)\n\t\t\treturn 1;\n\n\t\t/* Ensure the capacity of the CPUs fit the task */\n\t\tfor_each_cpu(cpu, lowest_mask) {\n\t\t\tif (!fitness_fn(p, cpu))\n\t\t\t\tcpumask_clear_cpu(cpu, lowest_mask);\n\t\t}\n\n\t\t/*\n\t\t * If no CPU at the current priority can fit the task\n\t\t * continue looking\n\t\t */\n\t\tif (cpumask_empty(lowest_mask))\n\t\t\tcontinue;\n\n\t\treturn 1;\n\t}\n\n\t/*\n\t * If we failed to find a fitting lowest_mask, kick off a new search\n\t * but without taking into account any fitness criteria this time.\n\t *\n\t * This rule favours honouring priority over fitting the task in the\n\t * correct CPU (Capacity Awareness being the only user now).\n\t * The idea is that if a higher priority task can run, then it should\n\t * run even if this ends up being on unfitting CPU.\n\t *\n\t * The cost of this trade-off is not entirely clear and will probably\n\t * be good for some workloads and bad for others.\n\t *\n\t * The main idea here is that if some CPUs were over-committed, we try\n\t * to spread which is what the scheduler traditionally did. Sys admins\n\t * must do proper RT planning to avoid overloading the system if they\n\t * really care.\n\t */\n\tif (fitness_fn)\n\t\treturn cpupri_find(cp, p, lowest_mask);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "static_branch_unlikely",
          "args": [
            "&sched_asym_cpucapacity"
          ],
          "line": 1861
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!lowest_mask"
          ],
          "line": 1851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "task"
          ],
          "line": 1847
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ftrace.c",
          "lines": "7612-7633",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include \"ftrace_internal.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include \"ftrace_internal.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 1846
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_cpumask_var_ptr",
          "args": [
            "local_cpu_mask"
          ],
          "line": 1845
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}"
  },
  {
    "function_name": "pick_highest_pushable_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1824-1838",
    "snippet": "static struct task_struct *pick_highest_pushable_task(struct rq *rq, int cpu)\n{\n\tstruct plist_head *head = &rq->rt.pushable_tasks;\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tplist_for_each_entry(p, head, pushable_tasks) {\n\t\tif (pick_rt_task(rq, p, cpu))\n\t\t\treturn p;\n\t}\n\n\treturn NULL;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "pick_rt_task",
          "args": [
            "rq",
            "p",
            "cpu"
          ],
          "line": 1833
        },
        "resolved": true,
        "details": {
          "function_name": "pick_rt_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1811-1818",
          "snippet": "static int pick_rt_task(struct rq *rq, struct task_struct *p, int cpu)\n{\n\tif (!task_running(rq, p) &&\n\t    cpumask_test_cpu(cpu, &p->cpus_mask))\n\t\treturn 1;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int pick_rt_task(struct rq *rq, struct task_struct *p, int cpu)\n{\n\tif (!task_running(rq, p) &&\n\t    cpumask_test_cpu(cpu, &p->cpus_mask))\n\t\treturn 1;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "plist_for_each_entry",
          "args": [
            "p",
            "head",
            "pushable_tasks"
          ],
          "line": 1832
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "has_pushable_tasks",
          "args": [
            "rq"
          ],
          "line": 1829
        },
        "resolved": true,
        "details": {
          "function_name": "has_pushable_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "363-366",
          "snippet": "static inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct task_struct *pick_highest_pushable_task(struct rq *rq, int cpu)\n{\n\tstruct plist_head *head = &rq->rt.pushable_tasks;\n\tstruct task_struct *p;\n\n\tif (!has_pushable_tasks(rq))\n\t\treturn NULL;\n\n\tplist_for_each_entry(p, head, pushable_tasks) {\n\t\tif (pick_rt_task(rq, p, cpu))\n\t\t\treturn p;\n\t}\n\n\treturn NULL;\n}"
  },
  {
    "function_name": "pick_rt_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1811-1818",
    "snippet": "static int pick_rt_task(struct rq *rq, struct task_struct *p, int cpu)\n{\n\tif (!task_running(rq, p) &&\n\t    cpumask_test_cpu(cpu, &p->cpus_mask))\n\t\treturn 1;\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_test_cpu",
          "args": [
            "cpu",
            "&p->cpus_mask"
          ],
          "line": 1814
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_running",
          "args": [
            "rq",
            "p"
          ],
          "line": 1813
        },
        "resolved": true,
        "details": {
          "function_name": "task_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2035-2042",
          "snippet": "static inline int task_running(struct rq *rq, struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->on_cpu;\n#else\n\treturn task_current(rq, p);\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_running(struct rq *rq, struct task_struct *p)\n{\n#ifdef CONFIG_SMP\n\treturn p->on_cpu;\n#else\n\treturn task_current(rq, p);\n#endif\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int pick_rt_task(struct rq *rq, struct task_struct *p, int cpu)\n{\n\tif (!task_running(rq, p) &&\n\t    cpumask_test_cpu(cpu, &p->cpus_mask))\n\t\treturn 1;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "put_prev_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1786-1804",
    "snippet": "static void put_prev_task_rt(struct rq *rq, struct task_struct *p)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq = &rq->rt;\n\n\tif (on_rt_rq(&p->rt))\n\t\tupdate_stats_wait_start_rt(rt_rq, rt_se);\n\n\tupdate_curr_rt(rq);\n\n\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 1);\n\n\t/*\n\t * The previous task needs to be made eligible for pushing\n\t * if it is still active\n\t */\n\tif (on_rt_rq(&p->rt) && p->nr_cpus_allowed > 1)\n\t\tenqueue_pushable_task(rq, p);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "enqueue_pushable_task",
          "args": [
            "rq",
            "p"
          ],
          "line": 1803
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_pushable_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "414-416",
          "snippet": "static inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "&p->rt"
          ],
          "line": 1802
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_rt_rq_load_avg",
          "args": [
            "rq_clock_pelt(rq)",
            "rq",
            "1"
          ],
          "line": 1796
        },
        "resolved": true,
        "details": {
          "function_name": "update_rt_rq_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "165-169",
          "snippet": "static inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock_pelt",
          "args": [
            "rq"
          ],
          "line": 1796
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      },
      {
        "call_info": {
          "callee": "update_curr_rt",
          "args": [
            "rq"
          ],
          "line": 1794
        },
        "resolved": true,
        "details": {
          "function_name": "update_curr_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1008-1052",
          "snippet": "static void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_stats_wait_start_rt",
          "args": [
            "rt_rq",
            "rt_se"
          ],
          "line": 1792
        },
        "resolved": true,
        "details": {
          "function_name": "update_stats_wait_start_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1303-1320",
          "snippet": "static inline void\nupdate_stats_wait_start_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_start(rq_of_rt_rq(rt_rq), p, stats);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_wait_start_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_start(rq_of_rt_rq(rt_rq), p, stats);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void put_prev_task_rt(struct rq *rq, struct task_struct *p)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq = &rq->rt;\n\n\tif (on_rt_rq(&p->rt))\n\t\tupdate_stats_wait_start_rt(rt_rq, rt_se);\n\n\tupdate_curr_rt(rq);\n\n\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 1);\n\n\t/*\n\t * The previous task needs to be made eligible for pushing\n\t * if it is still active\n\t */\n\tif (on_rt_rq(&p->rt) && p->nr_cpus_allowed > 1)\n\t\tenqueue_pushable_task(rq, p);\n}"
  },
  {
    "function_name": "pick_next_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1776-1784",
    "snippet": "static struct task_struct *pick_next_task_rt(struct rq *rq)\n{\n\tstruct task_struct *p = pick_task_rt(rq);\n\n\tif (p)\n\t\tset_next_task_rt(rq, p, true);\n\n\treturn p;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "set_next_task_rt",
          "args": [
            "rq",
            "p",
            "true"
          ],
          "line": 1781
        },
        "resolved": true,
        "details": {
          "function_name": "set_next_task_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1707-1731",
          "snippet": "static inline void set_next_task_rt(struct rq *rq, struct task_struct *p, bool first)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq = &rq->rt;\n\n\tp->se.exec_start = rq_clock_task(rq);\n\tif (on_rt_rq(&p->rt))\n\t\tupdate_stats_wait_end_rt(rt_rq, rt_se);\n\n\t/* The running task is never eligible for pushing */\n\tdequeue_pushable_task(rq, p);\n\n\tif (!first)\n\t\treturn;\n\n\t/*\n\t * If prev task was rt, put_prev_task() has already updated the\n\t * utilization. We only care of the case where we start to schedule a\n\t * rt task\n\t */\n\tif (rq->curr->sched_class != &rt_sched_class)\n\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);\n\n\trt_queue_push_tasks(rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline void set_next_task_rt(struct rq *rq, struct task_struct *p, bool first)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq = &rq->rt;\n\n\tp->se.exec_start = rq_clock_task(rq);\n\tif (on_rt_rq(&p->rt))\n\t\tupdate_stats_wait_end_rt(rt_rq, rt_se);\n\n\t/* The running task is never eligible for pushing */\n\tdequeue_pushable_task(rq, p);\n\n\tif (!first)\n\t\treturn;\n\n\t/*\n\t * If prev task was rt, put_prev_task() has already updated the\n\t * utilization. We only care of the case where we start to schedule a\n\t * rt task\n\t */\n\tif (rq->curr->sched_class != &rt_sched_class)\n\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);\n\n\trt_queue_push_tasks(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pick_task_rt",
          "args": [
            "rq"
          ],
          "line": 1778
        },
        "resolved": true,
        "details": {
          "function_name": "pick_task_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1764-1774",
          "snippet": "static struct task_struct *pick_task_rt(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!sched_rt_runnable(rq))\n\t\treturn NULL;\n\n\tp = _pick_next_task_rt(rq);\n\n\treturn p;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic struct task_struct *pick_task_rt(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!sched_rt_runnable(rq))\n\t\treturn NULL;\n\n\tp = _pick_next_task_rt(rq);\n\n\treturn p;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic struct task_struct *pick_next_task_rt(struct rq *rq)\n{\n\tstruct task_struct *p = pick_task_rt(rq);\n\n\tif (p)\n\t\tset_next_task_rt(rq, p, true);\n\n\treturn p;\n}"
  },
  {
    "function_name": "pick_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1764-1774",
    "snippet": "static struct task_struct *pick_task_rt(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!sched_rt_runnable(rq))\n\t\treturn NULL;\n\n\tp = _pick_next_task_rt(rq);\n\n\treturn p;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "_pick_next_task_rt",
          "args": [
            "rq"
          ],
          "line": 1771
        },
        "resolved": true,
        "details": {
          "function_name": "_pick_next_task_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1750-1762",
          "snippet": "static struct task_struct *_pick_next_task_rt(struct rq *rq)\n{\n\tstruct sched_rt_entity *rt_se;\n\tstruct rt_rq *rt_rq  = &rq->rt;\n\n\tdo {\n\t\trt_se = pick_next_rt_entity(rq, rt_rq);\n\t\tBUG_ON(!rt_se);\n\t\trt_rq = group_rt_rq(rt_se);\n\t} while (rt_rq);\n\n\treturn rt_task_of(rt_se);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct task_struct *_pick_next_task_rt(struct rq *rq)\n{\n\tstruct sched_rt_entity *rt_se;\n\tstruct rt_rq *rt_rq  = &rq->rt;\n\n\tdo {\n\t\trt_se = pick_next_rt_entity(rq, rt_rq);\n\t\tBUG_ON(!rt_se);\n\t\trt_rq = group_rt_rq(rt_se);\n\t} while (rt_rq);\n\n\treturn rt_task_of(rt_se);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_runnable",
          "args": [
            "rq"
          ],
          "line": 1768
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_runnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2242-2245",
          "snippet": "static inline bool sched_rt_runnable(struct rq *rq)\n{\n\treturn rq->rt.rt_queued > 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline bool sched_rt_runnable(struct rq *rq)\n{\n\treturn rq->rt.rt_queued > 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic struct task_struct *pick_task_rt(struct rq *rq)\n{\n\tstruct task_struct *p;\n\n\tif (!sched_rt_runnable(rq))\n\t\treturn NULL;\n\n\tp = _pick_next_task_rt(rq);\n\n\treturn p;\n}"
  },
  {
    "function_name": "_pick_next_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1750-1762",
    "snippet": "static struct task_struct *_pick_next_task_rt(struct rq *rq)\n{\n\tstruct sched_rt_entity *rt_se;\n\tstruct rt_rq *rt_rq  = &rq->rt;\n\n\tdo {\n\t\trt_se = pick_next_rt_entity(rq, rt_rq);\n\t\tBUG_ON(!rt_se);\n\t\trt_rq = group_rt_rq(rt_se);\n\t} while (rt_rq);\n\n\treturn rt_task_of(rt_se);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1761
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1758
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!rt_se"
          ],
          "line": 1757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pick_next_rt_entity",
          "args": [
            "rq",
            "rt_rq"
          ],
          "line": 1756
        },
        "resolved": true,
        "details": {
          "function_name": "pick_next_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1733-1748",
          "snippet": "static struct sched_rt_entity *pick_next_rt_entity(struct rq *rq,\n\t\t\t\t\t\t   struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct sched_rt_entity *next = NULL;\n\tstruct list_head *queue;\n\tint idx;\n\n\tidx = sched_find_first_bit(array->bitmap);\n\tBUG_ON(idx >= MAX_RT_PRIO);\n\n\tqueue = array->queue + idx;\n\tnext = list_entry(queue->next, struct sched_rt_entity, run_list);\n\n\treturn next;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic struct sched_rt_entity *pick_next_rt_entity(struct rq *rq,\n\t\t\t\t\t\t   struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct sched_rt_entity *next = NULL;\n\tstruct list_head *queue;\n\tint idx;\n\n\tidx = sched_find_first_bit(array->bitmap);\n\tBUG_ON(idx >= MAX_RT_PRIO);\n\n\tqueue = array->queue + idx;\n\tnext = list_entry(queue->next, struct sched_rt_entity, run_list);\n\n\treturn next;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic struct task_struct *_pick_next_task_rt(struct rq *rq)\n{\n\tstruct sched_rt_entity *rt_se;\n\tstruct rt_rq *rt_rq  = &rq->rt;\n\n\tdo {\n\t\trt_se = pick_next_rt_entity(rq, rt_rq);\n\t\tBUG_ON(!rt_se);\n\t\trt_rq = group_rt_rq(rt_se);\n\t} while (rt_rq);\n\n\treturn rt_task_of(rt_se);\n}"
  },
  {
    "function_name": "pick_next_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1733-1748",
    "snippet": "static struct sched_rt_entity *pick_next_rt_entity(struct rq *rq,\n\t\t\t\t\t\t   struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct sched_rt_entity *next = NULL;\n\tstruct list_head *queue;\n\tint idx;\n\n\tidx = sched_find_first_bit(array->bitmap);\n\tBUG_ON(idx >= MAX_RT_PRIO);\n\n\tqueue = array->queue + idx;\n\tnext = list_entry(queue->next, struct sched_rt_entity, run_list);\n\n\treturn next;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_entry",
          "args": [
            "queue->next",
            "structsched_rt_entity",
            "run_list"
          ],
          "line": 1745
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "idx >= MAX_RT_PRIO"
          ],
          "line": 1742
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_find_first_bit",
          "args": [
            "array->bitmap"
          ],
          "line": 1741
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic struct sched_rt_entity *pick_next_rt_entity(struct rq *rq,\n\t\t\t\t\t\t   struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct sched_rt_entity *next = NULL;\n\tstruct list_head *queue;\n\tint idx;\n\n\tidx = sched_find_first_bit(array->bitmap);\n\tBUG_ON(idx >= MAX_RT_PRIO);\n\n\tqueue = array->queue + idx;\n\tnext = list_entry(queue->next, struct sched_rt_entity, run_list);\n\n\treturn next;\n}"
  },
  {
    "function_name": "set_next_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1707-1731",
    "snippet": "static inline void set_next_task_rt(struct rq *rq, struct task_struct *p, bool first)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq = &rq->rt;\n\n\tp->se.exec_start = rq_clock_task(rq);\n\tif (on_rt_rq(&p->rt))\n\t\tupdate_stats_wait_end_rt(rt_rq, rt_se);\n\n\t/* The running task is never eligible for pushing */\n\tdequeue_pushable_task(rq, p);\n\n\tif (!first)\n\t\treturn;\n\n\t/*\n\t * If prev task was rt, put_prev_task() has already updated the\n\t * utilization. We only care of the case where we start to schedule a\n\t * rt task\n\t */\n\tif (rq->curr->sched_class != &rt_sched_class)\n\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);\n\n\trt_queue_push_tasks(rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_queue_push_tasks",
          "args": [
            "rq"
          ],
          "line": 1730
        },
        "resolved": true,
        "details": {
          "function_name": "rt_queue_push_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "441-443",
          "snippet": "static inline void rt_queue_push_tasks(struct rq *rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_push_tasks(struct rq *rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_rt_rq_load_avg",
          "args": [
            "rq_clock_pelt(rq)",
            "rq",
            "0"
          ],
          "line": 1728
        },
        "resolved": true,
        "details": {
          "function_name": "update_rt_rq_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "165-169",
          "snippet": "static inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline int\nupdate_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock_pelt",
          "args": [
            "rq"
          ],
          "line": 1728
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      },
      {
        "call_info": {
          "callee": "dequeue_pushable_task",
          "args": [
            "rq",
            "p"
          ],
          "line": 1717
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_pushable_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "418-420",
          "snippet": "static inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_stats_wait_end_rt",
          "args": [
            "rt_rq",
            "rt_se"
          ],
          "line": 1714
        },
        "resolved": true,
        "details": {
          "function_name": "update_stats_wait_end_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1352-1369",
          "snippet": "static inline void\nupdate_stats_wait_end_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_end(rq_of_rt_rq(rt_rq), p, stats);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_wait_end_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_end(rq_of_rt_rq(rt_rq), p, stats);\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "&p->rt"
          ],
          "line": 1713
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock_task",
          "args": [
            "rq"
          ],
          "line": 1712
        },
        "resolved": true,
        "details": {
          "function_name": "rq_clock_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1470-1476",
          "snippet": "static inline u64 rq_clock_task(struct rq *rq)\n{\n\tlockdep_assert_rq_held(rq);\n\tassert_clock_updated(rq);\n\n\treturn rq->clock_task;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline u64 rq_clock_task(struct rq *rq)\n{\n\tlockdep_assert_rq_held(rq);\n\tassert_clock_updated(rq);\n\n\treturn rq->clock_task;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline void set_next_task_rt(struct rq *rq, struct task_struct *p, bool first)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq = &rq->rt;\n\n\tp->se.exec_start = rq_clock_task(rq);\n\tif (on_rt_rq(&p->rt))\n\t\tupdate_stats_wait_end_rt(rt_rq, rt_se);\n\n\t/* The running task is never eligible for pushing */\n\tdequeue_pushable_task(rq, p);\n\n\tif (!first)\n\t\treturn;\n\n\t/*\n\t * If prev task was rt, put_prev_task() has already updated the\n\t * utilization. We only care of the case where we start to schedule a\n\t * rt task\n\t */\n\tif (rq->curr->sched_class != &rt_sched_class)\n\t\tupdate_rt_rq_load_avg(rq_clock_pelt(rq), rq, 0);\n\n\trt_queue_push_tasks(rq);\n}"
  },
  {
    "function_name": "check_preempt_curr_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1682-1705",
    "snippet": "static void check_preempt_curr_rt(struct rq *rq, struct task_struct *p, int flags)\n{\n\tif (p->prio < rq->curr->prio) {\n\t\tresched_curr(rq);\n\t\treturn;\n\t}\n\n#ifdef CONFIG_SMP\n\t/*\n\t * If:\n\t *\n\t * - the newly woken task is of equal priority to the current task\n\t * - the newly woken task is non-migratable while current is migratable\n\t * - current will be preempted on the next reschedule\n\t *\n\t * we should check to see if current can readily move to a different\n\t * cpu.  If so, we will reschedule to allow the push logic to try\n\t * to move current somewhere else, making room for our non-migratable\n\t * task.\n\t */\n\tif (p->prio == rq->curr->prio && !test_tsk_need_resched(rq->curr))\n\t\tcheck_preempt_equal_prio(rq, p);\n#endif\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "check_preempt_equal_prio",
          "args": [
            "rq",
            "p"
          ],
          "line": 1703
        },
        "resolved": true,
        "details": {
          "function_name": "check_preempt_equal_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1634-1659",
          "snippet": "static void check_preempt_equal_prio(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * Current can't be migrated, useless to reschedule,\n\t * let's hope p can move out.\n\t */\n\tif (rq->curr->nr_cpus_allowed == 1 ||\n\t    !cpupri_find(&rq->rd->cpupri, rq->curr, NULL))\n\t\treturn;\n\n\t/*\n\t * p is migratable, so let's not schedule it and\n\t * see if it is pushed or pulled somewhere else.\n\t */\n\tif (p->nr_cpus_allowed != 1 &&\n\t    cpupri_find(&rq->rd->cpupri, p, NULL))\n\t\treturn;\n\n\t/*\n\t * There appear to be other CPUs that can accept\n\t * the current task but none can run 'p', so lets reschedule\n\t * to try and push the current task away:\n\t */\n\trequeue_task_rt(rq, p, 1);\n\tresched_curr(rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void check_preempt_equal_prio(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * Current can't be migrated, useless to reschedule,\n\t * let's hope p can move out.\n\t */\n\tif (rq->curr->nr_cpus_allowed == 1 ||\n\t    !cpupri_find(&rq->rd->cpupri, rq->curr, NULL))\n\t\treturn;\n\n\t/*\n\t * p is migratable, so let's not schedule it and\n\t * see if it is pushed or pulled somewhere else.\n\t */\n\tif (p->nr_cpus_allowed != 1 &&\n\t    cpupri_find(&rq->rd->cpupri, p, NULL))\n\t\treturn;\n\n\t/*\n\t * There appear to be other CPUs that can accept\n\t * the current task but none can run 'p', so lets reschedule\n\t * to try and push the current task away:\n\t */\n\trequeue_task_rt(rq, p, 1);\n\tresched_curr(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "test_tsk_need_resched",
          "args": [
            "rq->curr"
          ],
          "line": 1702
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 1685
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void check_preempt_curr_rt(struct rq *rq, struct task_struct *p, int flags)\n{\n\tif (p->prio < rq->curr->prio) {\n\t\tresched_curr(rq);\n\t\treturn;\n\t}\n\n#ifdef CONFIG_SMP\n\t/*\n\t * If:\n\t *\n\t * - the newly woken task is of equal priority to the current task\n\t * - the newly woken task is non-migratable while current is migratable\n\t * - current will be preempted on the next reschedule\n\t *\n\t * we should check to see if current can readily move to a different\n\t * cpu.  If so, we will reschedule to allow the push logic to try\n\t * to move current somewhere else, making room for our non-migratable\n\t * task.\n\t */\n\tif (p->prio == rq->curr->prio && !test_tsk_need_resched(rq->curr))\n\t\tcheck_preempt_equal_prio(rq, p);\n#endif\n}"
  },
  {
    "function_name": "balance_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1661-1676",
    "snippet": "static int balance_rt(struct rq *rq, struct task_struct *p, struct rq_flags *rf)\n{\n\tif (!on_rt_rq(&p->rt) && need_pull_rt_task(rq, p)) {\n\t\t/*\n\t\t * This is OK, because current is on_cpu, which avoids it being\n\t\t * picked for load-balance and preemption/IRQs are still\n\t\t * disabled avoiding further scheduler activity on it and we've\n\t\t * not yet started the picking loop.\n\t\t */\n\t\trq_unpin_lock(rq, rf);\n\t\tpull_rt_task(rq);\n\t\trq_repin_lock(rq, rf);\n\t}\n\n\treturn sched_stop_runnable(rq) || sched_dl_runnable(rq) || sched_rt_runnable(rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_rt_runnable",
          "args": [
            "rq"
          ],
          "line": 1675
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_runnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2242-2245",
          "snippet": "static inline bool sched_rt_runnable(struct rq *rq)\n{\n\treturn rq->rt.rt_queued > 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline bool sched_rt_runnable(struct rq *rq)\n{\n\treturn rq->rt.rt_queued > 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_dl_runnable",
          "args": [
            "rq"
          ],
          "line": 1675
        },
        "resolved": true,
        "details": {
          "function_name": "sched_dl_runnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2237-2240",
          "snippet": "static inline bool sched_dl_runnable(struct rq *rq)\n{\n\treturn rq->dl.dl_nr_running > 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline bool sched_dl_runnable(struct rq *rq)\n{\n\treturn rq->dl.dl_nr_running > 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_stop_runnable",
          "args": [
            "rq"
          ],
          "line": 1675
        },
        "resolved": true,
        "details": {
          "function_name": "sched_stop_runnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2232-2235",
          "snippet": "static inline bool sched_stop_runnable(struct rq *rq)\n{\n\treturn rq->stop && task_on_rq_queued(rq->stop);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline bool sched_stop_runnable(struct rq *rq)\n{\n\treturn rq->stop && task_on_rq_queued(rq->stop);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_repin_lock",
          "args": [
            "rq",
            "rf"
          ],
          "line": 1672
        },
        "resolved": true,
        "details": {
          "function_name": "rq_repin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1560-1570",
          "snippet": "static inline void rq_repin_lock(struct rq *rq, struct rq_flags *rf)\n{\n\tlockdep_repin_lock(__rq_lockp(rq), rf->cookie);\n\n#ifdef CONFIG_SCHED_DEBUG\n\t/*\n\t * Restore the value we stashed in @rf for this pin context.\n\t */\n\trq->clock_update_flags |= rf->clock_update_flags;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void rq_repin_lock(struct rq *rq, struct rq_flags *rf)\n{\n\tlockdep_repin_lock(__rq_lockp(rq), rf->cookie);\n\n#ifdef CONFIG_SCHED_DEBUG\n\t/*\n\t * Restore the value we stashed in @rf for this pin context.\n\t */\n\trq->clock_update_flags |= rf->clock_update_flags;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "pull_rt_task",
          "args": [
            "rq"
          ],
          "line": 1671
        },
        "resolved": true,
        "details": {
          "function_name": "pull_rt_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2299-2406",
          "snippet": "static void pull_rt_task(struct rq *this_rq)\n{\n\tint this_cpu = this_rq->cpu, cpu;\n\tbool resched = false;\n\tstruct task_struct *p, *push_task;\n\tstruct rq *src_rq;\n\tint rt_overload_count = rt_overloaded(this_rq);\n\n\tif (likely(!rt_overload_count))\n\t\treturn;\n\n\t/*\n\t * Match the barrier from rt_set_overloaded; this guarantees that if we\n\t * see overloaded we must also see the rto_mask bit.\n\t */\n\tsmp_rmb();\n\n\t/* If we are the only overloaded CPU do nothing */\n\tif (rt_overload_count == 1 &&\n\t    cpumask_test_cpu(this_rq->cpu, this_rq->rd->rto_mask))\n\t\treturn;\n\n#ifdef HAVE_RT_PUSH_IPI\n\tif (sched_feat(RT_PUSH_IPI)) {\n\t\ttell_cpu_to_push(this_rq);\n\t\treturn;\n\t}\n#endif\n\n\tfor_each_cpu(cpu, this_rq->rd->rto_mask) {\n\t\tif (this_cpu == cpu)\n\t\t\tcontinue;\n\n\t\tsrc_rq = cpu_rq(cpu);\n\n\t\t/*\n\t\t * Don't bother taking the src_rq->lock if the next highest\n\t\t * task is known to be lower-priority than our current task.\n\t\t * This may look racy, but if this value is about to go\n\t\t * logically higher, the src_rq will push this task away.\n\t\t * And if its going logically lower, we do not care\n\t\t */\n\t\tif (src_rq->rt.highest_prio.next >=\n\t\t    this_rq->rt.highest_prio.curr)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We can potentially drop this_rq's lock in\n\t\t * double_lock_balance, and another CPU could\n\t\t * alter this_rq\n\t\t */\n\t\tpush_task = NULL;\n\t\tdouble_lock_balance(this_rq, src_rq);\n\n\t\t/*\n\t\t * We can pull only a task, which is pushable\n\t\t * on its rq, and no others.\n\t\t */\n\t\tp = pick_highest_pushable_task(src_rq, this_cpu);\n\n\t\t/*\n\t\t * Do we have an RT task that preempts\n\t\t * the to-be-scheduled task?\n\t\t */\n\t\tif (p && (p->prio < this_rq->rt.highest_prio.curr)) {\n\t\t\tWARN_ON(p == src_rq->curr);\n\t\t\tWARN_ON(!task_on_rq_queued(p));\n\n\t\t\t/*\n\t\t\t * There's a chance that p is higher in priority\n\t\t\t * than what's currently running on its CPU.\n\t\t\t * This is just that p is waking up and hasn't\n\t\t\t * had a chance to schedule. We only pull\n\t\t\t * p if it is lower in priority than the\n\t\t\t * current task on the run queue\n\t\t\t */\n\t\t\tif (p->prio < src_rq->curr->prio)\n\t\t\t\tgoto skip;\n\n\t\t\tif (is_migration_disabled(p)) {\n\t\t\t\tpush_task = get_push_task(src_rq);\n\t\t\t} else {\n\t\t\t\tdeactivate_task(src_rq, p, 0);\n\t\t\t\tset_task_cpu(p, this_cpu);\n\t\t\t\tactivate_task(this_rq, p, 0);\n\t\t\t\tresched = true;\n\t\t\t}\n\t\t\t/*\n\t\t\t * We continue with the search, just in\n\t\t\t * case there's an even higher prio task\n\t\t\t * in another runqueue. (low likelihood\n\t\t\t * but possible)\n\t\t\t */\n\t\t}\nskip:\n\t\tdouble_unlock_balance(this_rq, src_rq);\n\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(this_rq);\n\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &src_rq->push_work);\n\t\t\traw_spin_rq_lock(this_rq);\n\t\t}\n\t}\n\n\tif (resched)\n\t\tresched_curr(this_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void pull_rt_task(struct rq *this_rq)\n{\n\tint this_cpu = this_rq->cpu, cpu;\n\tbool resched = false;\n\tstruct task_struct *p, *push_task;\n\tstruct rq *src_rq;\n\tint rt_overload_count = rt_overloaded(this_rq);\n\n\tif (likely(!rt_overload_count))\n\t\treturn;\n\n\t/*\n\t * Match the barrier from rt_set_overloaded; this guarantees that if we\n\t * see overloaded we must also see the rto_mask bit.\n\t */\n\tsmp_rmb();\n\n\t/* If we are the only overloaded CPU do nothing */\n\tif (rt_overload_count == 1 &&\n\t    cpumask_test_cpu(this_rq->cpu, this_rq->rd->rto_mask))\n\t\treturn;\n\n#ifdef HAVE_RT_PUSH_IPI\n\tif (sched_feat(RT_PUSH_IPI)) {\n\t\ttell_cpu_to_push(this_rq);\n\t\treturn;\n\t}\n#endif\n\n\tfor_each_cpu(cpu, this_rq->rd->rto_mask) {\n\t\tif (this_cpu == cpu)\n\t\t\tcontinue;\n\n\t\tsrc_rq = cpu_rq(cpu);\n\n\t\t/*\n\t\t * Don't bother taking the src_rq->lock if the next highest\n\t\t * task is known to be lower-priority than our current task.\n\t\t * This may look racy, but if this value is about to go\n\t\t * logically higher, the src_rq will push this task away.\n\t\t * And if its going logically lower, we do not care\n\t\t */\n\t\tif (src_rq->rt.highest_prio.next >=\n\t\t    this_rq->rt.highest_prio.curr)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * We can potentially drop this_rq's lock in\n\t\t * double_lock_balance, and another CPU could\n\t\t * alter this_rq\n\t\t */\n\t\tpush_task = NULL;\n\t\tdouble_lock_balance(this_rq, src_rq);\n\n\t\t/*\n\t\t * We can pull only a task, which is pushable\n\t\t * on its rq, and no others.\n\t\t */\n\t\tp = pick_highest_pushable_task(src_rq, this_cpu);\n\n\t\t/*\n\t\t * Do we have an RT task that preempts\n\t\t * the to-be-scheduled task?\n\t\t */\n\t\tif (p && (p->prio < this_rq->rt.highest_prio.curr)) {\n\t\t\tWARN_ON(p == src_rq->curr);\n\t\t\tWARN_ON(!task_on_rq_queued(p));\n\n\t\t\t/*\n\t\t\t * There's a chance that p is higher in priority\n\t\t\t * than what's currently running on its CPU.\n\t\t\t * This is just that p is waking up and hasn't\n\t\t\t * had a chance to schedule. We only pull\n\t\t\t * p if it is lower in priority than the\n\t\t\t * current task on the run queue\n\t\t\t */\n\t\t\tif (p->prio < src_rq->curr->prio)\n\t\t\t\tgoto skip;\n\n\t\t\tif (is_migration_disabled(p)) {\n\t\t\t\tpush_task = get_push_task(src_rq);\n\t\t\t} else {\n\t\t\t\tdeactivate_task(src_rq, p, 0);\n\t\t\t\tset_task_cpu(p, this_cpu);\n\t\t\t\tactivate_task(this_rq, p, 0);\n\t\t\t\tresched = true;\n\t\t\t}\n\t\t\t/*\n\t\t\t * We continue with the search, just in\n\t\t\t * case there's an even higher prio task\n\t\t\t * in another runqueue. (low likelihood\n\t\t\t * but possible)\n\t\t\t */\n\t\t}\nskip:\n\t\tdouble_unlock_balance(this_rq, src_rq);\n\n\t\tif (push_task) {\n\t\t\traw_spin_rq_unlock(this_rq);\n\t\t\tstop_one_cpu_nowait(src_rq->cpu, push_cpu_stop,\n\t\t\t\t\t    push_task, &src_rq->push_work);\n\t\t\traw_spin_rq_lock(this_rq);\n\t\t}\n\t}\n\n\tif (resched)\n\t\tresched_curr(this_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_unpin_lock",
          "args": [
            "rq",
            "rf"
          ],
          "line": 1670
        },
        "resolved": true,
        "details": {
          "function_name": "rq_unpin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1550-1558",
          "snippet": "static inline void rq_unpin_lock(struct rq *rq, struct rq_flags *rf)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tif (rq->clock_update_flags > RQCF_ACT_SKIP)\n\t\trf->clock_update_flags = RQCF_UPDATED;\n#endif\n\n\tlockdep_unpin_lock(__rq_lockp(rq), rf->cookie);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define RQCF_UPDATED\t\t0x04",
            "#define RQCF_ACT_SKIP\t\t0x02"
          ],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define RQCF_UPDATED\t\t0x04\n#define RQCF_ACT_SKIP\t\t0x02\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void rq_unpin_lock(struct rq *rq, struct rq_flags *rf)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tif (rq->clock_update_flags > RQCF_ACT_SKIP)\n\t\trf->clock_update_flags = RQCF_UPDATED;\n#endif\n\n\tlockdep_unpin_lock(__rq_lockp(rq), rf->cookie);\n}"
        }
      },
      {
        "call_info": {
          "callee": "need_pull_rt_task",
          "args": [
            "rq",
            "p"
          ],
          "line": 1663
        },
        "resolved": true,
        "details": {
          "function_name": "need_pull_rt_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "432-435",
          "snippet": "static inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "&p->rt"
          ],
          "line": 1663
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int balance_rt(struct rq *rq, struct task_struct *p, struct rq_flags *rf)\n{\n\tif (!on_rt_rq(&p->rt) && need_pull_rt_task(rq, p)) {\n\t\t/*\n\t\t * This is OK, because current is on_cpu, which avoids it being\n\t\t * picked for load-balance and preemption/IRQs are still\n\t\t * disabled avoiding further scheduler activity on it and we've\n\t\t * not yet started the picking loop.\n\t\t */\n\t\trq_unpin_lock(rq, rf);\n\t\tpull_rt_task(rq);\n\t\trq_repin_lock(rq, rf);\n\t}\n\n\treturn sched_stop_runnable(rq) || sched_dl_runnable(rq) || sched_rt_runnable(rq);\n}"
  },
  {
    "function_name": "check_preempt_equal_prio",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1634-1659",
    "snippet": "static void check_preempt_equal_prio(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * Current can't be migrated, useless to reschedule,\n\t * let's hope p can move out.\n\t */\n\tif (rq->curr->nr_cpus_allowed == 1 ||\n\t    !cpupri_find(&rq->rd->cpupri, rq->curr, NULL))\n\t\treturn;\n\n\t/*\n\t * p is migratable, so let's not schedule it and\n\t * see if it is pushed or pulled somewhere else.\n\t */\n\tif (p->nr_cpus_allowed != 1 &&\n\t    cpupri_find(&rq->rd->cpupri, p, NULL))\n\t\treturn;\n\n\t/*\n\t * There appear to be other CPUs that can accept\n\t * the current task but none can run 'p', so lets reschedule\n\t * to try and push the current task away:\n\t */\n\trequeue_task_rt(rq, p, 1);\n\tresched_curr(rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 1658
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "requeue_task_rt",
          "args": [
            "rq",
            "p",
            "1"
          ],
          "line": 1657
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_task_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1543-1552",
          "snippet": "static void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpupri_find",
          "args": [
            "&rq->rd->cpupri",
            "p",
            "NULL"
          ],
          "line": 1649
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_find",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "121-125",
          "snippet": "int cpupri_find(struct cpupri *cp, struct task_struct *p,\n\t\tstruct cpumask *lowest_mask)\n{\n\treturn cpupri_find_fitness(cp, p, lowest_mask, NULL);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nint cpupri_find(struct cpupri *cp, struct task_struct *p,\n\t\tstruct cpumask *lowest_mask)\n{\n\treturn cpupri_find_fitness(cp, p, lowest_mask, NULL);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void check_preempt_equal_prio(struct rq *rq, struct task_struct *p)\n{\n\t/*\n\t * Current can't be migrated, useless to reschedule,\n\t * let's hope p can move out.\n\t */\n\tif (rq->curr->nr_cpus_allowed == 1 ||\n\t    !cpupri_find(&rq->rd->cpupri, rq->curr, NULL))\n\t\treturn;\n\n\t/*\n\t * p is migratable, so let's not schedule it and\n\t * see if it is pushed or pulled somewhere else.\n\t */\n\tif (p->nr_cpus_allowed != 1 &&\n\t    cpupri_find(&rq->rd->cpupri, p, NULL))\n\t\treturn;\n\n\t/*\n\t * There appear to be other CPUs that can accept\n\t * the current task but none can run 'p', so lets reschedule\n\t * to try and push the current task away:\n\t */\n\trequeue_task_rt(rq, p, 1);\n\tresched_curr(rq);\n}"
  },
  {
    "function_name": "select_task_rq_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1562-1632",
    "snippet": "static int\nselect_task_rq_rt(struct task_struct *p, int cpu, int flags)\n{\n\tstruct task_struct *curr;\n\tstruct rq *rq;\n\tbool test;\n\n\t/* For anything but wake ups, just return the task_cpu */\n\tif (!(flags & (WF_TTWU | WF_FORK)))\n\t\tgoto out;\n\n\trq = cpu_rq(cpu);\n\n\trcu_read_lock();\n\tcurr = READ_ONCE(rq->curr); /* unlocked access */\n\n\t/*\n\t * If the current task on @p's runqueue is an RT task, then\n\t * try to see if we can wake this RT task up on another\n\t * runqueue. Otherwise simply start this RT task\n\t * on its current runqueue.\n\t *\n\t * We want to avoid overloading runqueues. If the woken\n\t * task is a higher priority, then it will stay on this CPU\n\t * and the lower prio task should be moved to another CPU.\n\t * Even though this will probably make the lower prio task\n\t * lose its cache, we do not want to bounce a higher task\n\t * around just because it gave up its CPU, perhaps for a\n\t * lock?\n\t *\n\t * For equal prio tasks, we just let the scheduler sort it out.\n\t *\n\t * Otherwise, just let it ride on the affined RQ and the\n\t * post-schedule router will push the preempted task away\n\t *\n\t * This test is optimistic, if we get it wrong the load-balancer\n\t * will have to sort it out.\n\t *\n\t * We take into account the capacity of the CPU to ensure it fits the\n\t * requirement of the task - which is only important on heterogeneous\n\t * systems like big.LITTLE.\n\t */\n\ttest = curr &&\n\t       unlikely(rt_task(curr)) &&\n\t       (curr->nr_cpus_allowed < 2 || curr->prio <= p->prio);\n\n\tif (test || !rt_task_fits_capacity(p, cpu)) {\n\t\tint target = find_lowest_rq(p);\n\n\t\t/*\n\t\t * Bail out if we were forcing a migration to find a better\n\t\t * fitting CPU but our search failed.\n\t\t */\n\t\tif (!test && target != -1 && !rt_task_fits_capacity(p, target))\n\t\t\tgoto out_unlock;\n\n\t\t/*\n\t\t * Don't bother moving it if the destination CPU is\n\t\t * not running a lower priority task.\n\t\t */\n\t\tif (target != -1 &&\n\t\t    p->prio < cpu_rq(target)->rt.highest_prio.curr)\n\t\t\tcpu = target;\n\t}\n\nout_unlock:\n\trcu_read_unlock();\n\nout:\n\treturn cpu;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1628
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "target"
          ],
          "line": 1623
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_fits_capacity",
          "args": [
            "p",
            "target"
          ],
          "line": 1615
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_fits_capacity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "487-490",
          "snippet": "static inline bool rt_task_fits_capacity(struct task_struct *p, int cpu)\n{\n\treturn true;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool rt_task_fits_capacity(struct task_struct *p, int cpu)\n{\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "find_lowest_rq",
          "args": [
            "p"
          ],
          "line": 1609
        },
        "resolved": true,
        "details": {
          "function_name": "find_lowest_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1842-1931",
          "snippet": "static int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int find_lowest_rq(struct task_struct *task)\n{\n\tstruct sched_domain *sd;\n\tstruct cpumask *lowest_mask = this_cpu_cpumask_var_ptr(local_cpu_mask);\n\tint this_cpu = smp_processor_id();\n\tint cpu      = task_cpu(task);\n\tint ret;\n\n\t/* Make sure the mask is initialized first */\n\tif (unlikely(!lowest_mask))\n\t\treturn -1;\n\n\tif (task->nr_cpus_allowed == 1)\n\t\treturn -1; /* No other targets possible */\n\n\t/*\n\t * If we're on asym system ensure we consider the different capacities\n\t * of the CPUs when searching for the lowest_mask.\n\t */\n\tif (static_branch_unlikely(&sched_asym_cpucapacity)) {\n\n\t\tret = cpupri_find_fitness(&task_rq(task)->rd->cpupri,\n\t\t\t\t\t  task, lowest_mask,\n\t\t\t\t\t  rt_task_fits_capacity);\n\t} else {\n\n\t\tret = cpupri_find(&task_rq(task)->rd->cpupri,\n\t\t\t\t  task, lowest_mask);\n\t}\n\n\tif (!ret)\n\t\treturn -1; /* No targets found */\n\n\t/*\n\t * At this point we have built a mask of CPUs representing the\n\t * lowest priority tasks in the system.  Now we want to elect\n\t * the best one based on our affinity and topology.\n\t *\n\t * We prioritize the last CPU that the task executed on since\n\t * it is most likely cache-hot in that location.\n\t */\n\tif (cpumask_test_cpu(cpu, lowest_mask))\n\t\treturn cpu;\n\n\t/*\n\t * Otherwise, we consult the sched_domains span maps to figure\n\t * out which CPU is logically closest to our hot cache data.\n\t */\n\tif (!cpumask_test_cpu(this_cpu, lowest_mask))\n\t\tthis_cpu = -1; /* Skip this_cpu opt if not among lowest */\n\n\trcu_read_lock();\n\tfor_each_domain(cpu, sd) {\n\t\tif (sd->flags & SD_WAKE_AFFINE) {\n\t\t\tint best_cpu;\n\n\t\t\t/*\n\t\t\t * \"this_cpu\" is cheaper to preempt than a\n\t\t\t * remote processor.\n\t\t\t */\n\t\t\tif (this_cpu != -1 &&\n\t\t\t    cpumask_test_cpu(this_cpu, sched_domain_span(sd))) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn this_cpu;\n\t\t\t}\n\n\t\t\tbest_cpu = cpumask_any_and_distribute(lowest_mask,\n\t\t\t\t\t\t\t      sched_domain_span(sd));\n\t\t\tif (best_cpu < nr_cpu_ids) {\n\t\t\t\trcu_read_unlock();\n\t\t\t\treturn best_cpu;\n\t\t\t}\n\t\t}\n\t}\n\trcu_read_unlock();\n\n\t/*\n\t * And finally, if there were no matches within the domains\n\t * just give the caller *something* to work with from the compatible\n\t * locations.\n\t */\n\tif (this_cpu != -1)\n\t\treturn this_cpu;\n\n\tcpu = cpumask_any_distribute(lowest_mask);\n\tif (cpu < nr_cpu_ids)\n\t\treturn cpu;\n\n\treturn -1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "rt_task(curr)"
          ],
          "line": 1605
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "curr"
          ],
          "line": 1605
        },
        "resolved": true,
        "details": {
          "function_name": "tg_has_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "2674-2692",
          "snippet": "static inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int tg_has_rt_tasks(struct task_group *tg)\n{\n\tstruct task_struct *task;\n\tstruct css_task_iter it;\n\tint ret = 0;\n\n\t/*\n\t * Autogroups do not have RT tasks; see autogroup_create().\n\t */\n\tif (task_group_is_autogroup(tg))\n\t\treturn 0;\n\n\tcss_task_iter_start(&tg->css, 0, &it);\n\twhile (!ret && (task = css_task_iter_next(&it)))\n\t\tret |= rt_task(task);\n\tcss_task_iter_end(&it);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rq->curr"
          ],
          "line": 1576
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1575
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int\nselect_task_rq_rt(struct task_struct *p, int cpu, int flags)\n{\n\tstruct task_struct *curr;\n\tstruct rq *rq;\n\tbool test;\n\n\t/* For anything but wake ups, just return the task_cpu */\n\tif (!(flags & (WF_TTWU | WF_FORK)))\n\t\tgoto out;\n\n\trq = cpu_rq(cpu);\n\n\trcu_read_lock();\n\tcurr = READ_ONCE(rq->curr); /* unlocked access */\n\n\t/*\n\t * If the current task on @p's runqueue is an RT task, then\n\t * try to see if we can wake this RT task up on another\n\t * runqueue. Otherwise simply start this RT task\n\t * on its current runqueue.\n\t *\n\t * We want to avoid overloading runqueues. If the woken\n\t * task is a higher priority, then it will stay on this CPU\n\t * and the lower prio task should be moved to another CPU.\n\t * Even though this will probably make the lower prio task\n\t * lose its cache, we do not want to bounce a higher task\n\t * around just because it gave up its CPU, perhaps for a\n\t * lock?\n\t *\n\t * For equal prio tasks, we just let the scheduler sort it out.\n\t *\n\t * Otherwise, just let it ride on the affined RQ and the\n\t * post-schedule router will push the preempted task away\n\t *\n\t * This test is optimistic, if we get it wrong the load-balancer\n\t * will have to sort it out.\n\t *\n\t * We take into account the capacity of the CPU to ensure it fits the\n\t * requirement of the task - which is only important on heterogeneous\n\t * systems like big.LITTLE.\n\t */\n\ttest = curr &&\n\t       unlikely(rt_task(curr)) &&\n\t       (curr->nr_cpus_allowed < 2 || curr->prio <= p->prio);\n\n\tif (test || !rt_task_fits_capacity(p, cpu)) {\n\t\tint target = find_lowest_rq(p);\n\n\t\t/*\n\t\t * Bail out if we were forcing a migration to find a better\n\t\t * fitting CPU but our search failed.\n\t\t */\n\t\tif (!test && target != -1 && !rt_task_fits_capacity(p, target))\n\t\t\tgoto out_unlock;\n\n\t\t/*\n\t\t * Don't bother moving it if the destination CPU is\n\t\t * not running a lower priority task.\n\t\t */\n\t\tif (target != -1 &&\n\t\t    p->prio < cpu_rq(target)->rt.highest_prio.curr)\n\t\t\tcpu = target;\n\t}\n\nout_unlock:\n\trcu_read_unlock();\n\nout:\n\treturn cpu;\n}"
  },
  {
    "function_name": "yield_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1554-1557",
    "snippet": "static void yield_task_rt(struct rq *rq)\n{\n\trequeue_task_rt(rq, rq->curr, 0);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "requeue_task_rt",
          "args": [
            "rq",
            "rq->curr",
            "0"
          ],
          "line": 1556
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_task_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1543-1552",
          "snippet": "static void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void yield_task_rt(struct rq *rq)\n{\n\trequeue_task_rt(rq, rq->curr, 0);\n}"
  },
  {
    "function_name": "requeue_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1543-1552",
    "snippet": "static void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "requeue_rt_entity",
          "args": [
            "rt_rq",
            "rt_se",
            "head"
          ],
          "line": 1550
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1529-1541",
          "snippet": "static void\nrequeue_rt_entity(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se, int head)\n{\n\tif (on_rt_rq(rt_se)) {\n\t\tstruct rt_prio_array *array = &rt_rq->active;\n\t\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t\tif (head)\n\t\t\tlist_move(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_move_tail(&rt_se->run_list, queue);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\nrequeue_rt_entity(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se, int head)\n{\n\tif (on_rt_rq(rt_se)) {\n\t\tstruct rt_prio_array *array = &rt_rq->active;\n\t\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t\tif (head)\n\t\t\tlist_move(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_move_tail(&rt_se->run_list, queue);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1549
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void requeue_task_rt(struct rq *rq, struct task_struct *p, int head)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\tstruct rt_rq *rt_rq;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_rq = rt_rq_of_se(rt_se);\n\t\trequeue_rt_entity(rt_rq, rt_se, head);\n\t}\n}"
  },
  {
    "function_name": "requeue_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1529-1541",
    "snippet": "static void\nrequeue_rt_entity(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se, int head)\n{\n\tif (on_rt_rq(rt_se)) {\n\t\tstruct rt_prio_array *array = &rt_rq->active;\n\t\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t\tif (head)\n\t\t\tlist_move(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_move_tail(&rt_se->run_list, queue);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_move_tail",
          "args": [
            "&rt_se->run_list",
            "queue"
          ],
          "line": 1539
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_move",
          "args": [
            "&rt_se->run_list",
            "queue"
          ],
          "line": 1537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_se_prio",
          "args": [
            "rt_se"
          ],
          "line": 1534
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "949-959",
          "snippet": "static inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1532
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\nrequeue_rt_entity(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se, int head)\n{\n\tif (on_rt_rq(rt_se)) {\n\t\tstruct rt_prio_array *array = &rt_rq->active;\n\t\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t\tif (head)\n\t\t\tlist_move(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_move_tail(&rt_se->run_list, queue);\n\t}\n}"
  },
  {
    "function_name": "dequeue_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1515-1523",
    "snippet": "static void dequeue_task_rt(struct rq *rq, struct task_struct *p, int flags)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\n\tupdate_curr_rt(rq);\n\tdequeue_rt_entity(rt_se, flags);\n\n\tdequeue_pushable_task(rq, p);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "dequeue_pushable_task",
          "args": [
            "rq",
            "p"
          ],
          "line": 1522
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_pushable_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "418-420",
          "snippet": "static inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "dequeue_rt_entity",
          "args": [
            "rt_se",
            "flags"
          ],
          "line": 1520
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1478-1493",
          "snippet": "static void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\t\tif (rt_rq && rt_rq->rt_nr_running)\n\t\t\t__enqueue_rt_entity(rt_se, flags);\n\t}\n\tenqueue_top_rt_rq(&rq->rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\t\tif (rt_rq && rt_rq->rt_nr_running)\n\t\t\t__enqueue_rt_entity(rt_se, flags);\n\t}\n\tenqueue_top_rt_rq(&rq->rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_curr_rt",
          "args": [
            "rq"
          ],
          "line": 1519
        },
        "resolved": true,
        "details": {
          "function_name": "update_curr_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1008-1052",
          "snippet": "static void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void dequeue_task_rt(struct rq *rq, struct task_struct *p, int flags)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\n\tupdate_curr_rt(rq);\n\tdequeue_rt_entity(rt_se, flags);\n\n\tdequeue_pushable_task(rq, p);\n}"
  },
  {
    "function_name": "enqueue_task_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1498-1513",
    "snippet": "static void\nenqueue_task_rt(struct rq *rq, struct task_struct *p, int flags)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\n\tif (flags & ENQUEUE_WAKEUP)\n\t\trt_se->timeout = 0;\n\n\tcheck_schedstat_required();\n\tupdate_stats_wait_start_rt(rt_rq_of_se(rt_se), rt_se);\n\n\tenqueue_rt_entity(rt_se, flags);\n\n\tif (!task_current(rq, p) && p->nr_cpus_allowed > 1)\n\t\tenqueue_pushable_task(rq, p);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "enqueue_pushable_task",
          "args": [
            "rq",
            "p"
          ],
          "line": 1512
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_pushable_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "414-416",
          "snippet": "static inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_current",
          "args": [
            "rq",
            "p"
          ],
          "line": 1511
        },
        "resolved": true,
        "details": {
          "function_name": "task_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2030-2033",
          "snippet": "static inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "void __dl_clear_params(struct task_struct *p);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void post_init_entity_util_avg(struct task_struct *p);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nvoid __dl_clear_params(struct task_struct *p);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void post_init_entity_util_avg(struct task_struct *p);\n\nstatic inline int task_current(struct rq *rq, struct task_struct *p)\n{\n\treturn rq->curr == p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "enqueue_rt_entity",
          "args": [
            "rt_se",
            "flags"
          ],
          "line": 1509
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1466-1476",
          "snippet": "static void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_enqueue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\tfor_each_sched_rt_entity(rt_se)\n\t\t__enqueue_rt_entity(rt_se, flags);\n\tenqueue_top_rt_rq(&rq->rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_enqueue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\tfor_each_sched_rt_entity(rt_se)\n\t\t__enqueue_rt_entity(rt_se, flags);\n\tenqueue_top_rt_rq(&rq->rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_stats_wait_start_rt",
          "args": [
            "rt_rq_of_se(rt_se)",
            "rt_se"
          ],
          "line": 1507
        },
        "resolved": true,
        "details": {
          "function_name": "update_stats_wait_start_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1303-1320",
          "snippet": "static inline void\nupdate_stats_wait_start_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_start(rq_of_rt_rq(rt_rq), p, stats);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_wait_start_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_start(rq_of_rt_rq(rt_rq), p, stats);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1507
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_schedstat_required",
          "args": [],
          "line": 1506
        },
        "resolved": true,
        "details": {
          "function_name": "check_schedstat_required",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "53-66",
          "snippet": "static inline void\ncheck_schedstat_required(void)\n{\n\tif (schedstat_enabled())\n\t\treturn;\n\n\t/* Force schedstat enabled if a dependent tracepoint is active */\n\tif (trace_sched_stat_wait_enabled()    ||\n\t    trace_sched_stat_sleep_enabled()   ||\n\t    trace_sched_stat_iowait_enabled()  ||\n\t    trace_sched_stat_blocked_enabled() ||\n\t    trace_sched_stat_runtime_enabled())\n\t\tprintk_deferred_once(\"Scheduler tracepoints stat_sleep, stat_iowait, stat_blocked and stat_runtime require the kernel parameter schedstats=enable or kernel.sched_schedstats=1\\n\");\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void\ncheck_schedstat_required(void)\n{\n\tif (schedstat_enabled())\n\t\treturn;\n\n\t/* Force schedstat enabled if a dependent tracepoint is active */\n\tif (trace_sched_stat_wait_enabled()    ||\n\t    trace_sched_stat_sleep_enabled()   ||\n\t    trace_sched_stat_iowait_enabled()  ||\n\t    trace_sched_stat_blocked_enabled() ||\n\t    trace_sched_stat_runtime_enabled())\n\t\tprintk_deferred_once(\"Scheduler tracepoints stat_sleep, stat_iowait, stat_blocked and stat_runtime require the kernel parameter schedstats=enable or kernel.sched_schedstats=1\\n\");\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nenqueue_task_rt(struct rq *rq, struct task_struct *p, int flags)\n{\n\tstruct sched_rt_entity *rt_se = &p->rt;\n\n\tif (flags & ENQUEUE_WAKEUP)\n\t\trt_se->timeout = 0;\n\n\tcheck_schedstat_required();\n\tupdate_stats_wait_start_rt(rt_rq_of_se(rt_se), rt_se);\n\n\tenqueue_rt_entity(rt_se, flags);\n\n\tif (!task_current(rq, p) && p->nr_cpus_allowed > 1)\n\t\tenqueue_pushable_task(rq, p);\n}"
  },
  {
    "function_name": "dequeue_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1478-1493",
    "snippet": "static void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\t\tif (rt_rq && rt_rq->rt_nr_running)\n\t\t\t__enqueue_rt_entity(rt_se, flags);\n\t}\n\tenqueue_top_rt_rq(&rq->rt);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "enqueue_top_rt_rq",
          "args": [
            "&rq->rt"
          ],
          "line": 1492
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1071-1091",
          "snippet": "static void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__enqueue_rt_entity",
          "args": [
            "rt_se",
            "flags"
          ],
          "line": 1490
        },
        "resolved": true,
        "details": {
          "function_name": "__enqueue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1397-1429",
          "snippet": "static void __enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t/*\n\t * Don't enqueue the group if its throttled, or when empty.\n\t * The latter is a consequence of the former when a child group\n\t * get throttled and the current group doesn't have any other\n\t * active members.\n\t */\n\tif (group_rq && (rt_rq_throttled(group_rq) || !group_rq->rt_nr_running)) {\n\t\tif (rt_se->on_list)\n\t\t\t__delist_rt_entity(rt_se, array);\n\t\treturn;\n\t}\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(rt_se->on_list);\n\t\tif (flags & ENQUEUE_HEAD)\n\t\t\tlist_add(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_add_tail(&rt_se->run_list, queue);\n\n\t\t__set_bit(rt_se_prio(rt_se), array->bitmap);\n\t\trt_se->on_list = 1;\n\t}\n\trt_se->on_rq = 1;\n\n\tinc_rt_tasks(rt_se, rt_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t/*\n\t * Don't enqueue the group if its throttled, or when empty.\n\t * The latter is a consequence of the former when a child group\n\t * get throttled and the current group doesn't have any other\n\t * active members.\n\t */\n\tif (group_rq && (rt_rq_throttled(group_rq) || !group_rq->rt_nr_running)) {\n\t\tif (rt_se->on_list)\n\t\t\t__delist_rt_entity(rt_se, array);\n\t\treturn;\n\t}\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(rt_se->on_list);\n\t\tif (flags & ENQUEUE_HEAD)\n\t\t\tlist_add(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_add_tail(&rt_se->run_list, queue);\n\n\t\t__set_bit(rt_se_prio(rt_se), array->bitmap);\n\t\trt_se->on_list = 1;\n\t}\n\trt_se->on_rq = 1;\n\n\tinc_rt_tasks(rt_se, rt_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1487
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "dequeue_rt_stack",
          "args": [
            "rt_se",
            "flags"
          ],
          "line": 1484
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_rt_stack",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1449-1464",
          "snippet": "static void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct sched_rt_entity *back = NULL;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_se->back = back;\n\t\tback = rt_se;\n\t}\n\n\tdequeue_top_rt_rq(rt_rq_of_se(back));\n\n\tfor (rt_se = back; rt_se; rt_se = rt_se->back) {\n\t\tif (on_rt_rq(rt_se))\n\t\t\t__dequeue_rt_entity(rt_se, flags);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct sched_rt_entity *back = NULL;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_se->back = back;\n\t\tback = rt_se;\n\t}\n\n\tdequeue_top_rt_rq(rt_rq_of_se(back));\n\n\tfor (rt_se = back; rt_se; rt_se = rt_se->back) {\n\t\tif (on_rt_rq(rt_se))\n\t\t\t__dequeue_rt_entity(rt_se, flags);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_stats_dequeue_rt",
          "args": [
            "rt_rq_of_se(rt_se)",
            "rt_se",
            "flags"
          ],
          "line": 1482
        },
        "resolved": true,
        "details": {
          "function_name": "update_stats_dequeue_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1371-1395",
          "snippet": "static inline void\nupdate_stats_dequeue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tif ((flags & DEQUEUE_SLEEP) && p) {\n\t\tunsigned int state;\n\n\t\tstate = READ_ONCE(p->__state);\n\t\tif (state & TASK_INTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.sleep_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\n\t\tif (state & TASK_UNINTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.block_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_dequeue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tif ((flags & DEQUEUE_SLEEP) && p) {\n\t\tunsigned int state;\n\n\t\tstate = READ_ONCE(p->__state);\n\t\tif (state & TASK_INTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.sleep_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\n\t\tif (state & TASK_UNINTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.block_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1482
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_se",
          "args": [
            "rt_se"
          ],
          "line": 1480
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "248-253",
          "snippet": "static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\t\tif (rt_rq && rt_rq->rt_nr_running)\n\t\t\t__enqueue_rt_entity(rt_se, flags);\n\t}\n\tenqueue_top_rt_rq(&rq->rt);\n}"
  },
  {
    "function_name": "enqueue_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1466-1476",
    "snippet": "static void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_enqueue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\tfor_each_sched_rt_entity(rt_se)\n\t\t__enqueue_rt_entity(rt_se, flags);\n\tenqueue_top_rt_rq(&rq->rt);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "enqueue_top_rt_rq",
          "args": [
            "&rq->rt"
          ],
          "line": 1475
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1071-1091",
          "snippet": "static void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "dequeue_rt_stack",
          "args": [
            "rt_se",
            "flags"
          ],
          "line": 1472
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_rt_stack",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1449-1464",
          "snippet": "static void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct sched_rt_entity *back = NULL;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_se->back = back;\n\t\tback = rt_se;\n\t}\n\n\tdequeue_top_rt_rq(rt_rq_of_se(back));\n\n\tfor (rt_se = back; rt_se; rt_se = rt_se->back) {\n\t\tif (on_rt_rq(rt_se))\n\t\t\t__dequeue_rt_entity(rt_se, flags);\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct sched_rt_entity *back = NULL;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_se->back = back;\n\t\tback = rt_se;\n\t}\n\n\tdequeue_top_rt_rq(rt_rq_of_se(back));\n\n\tfor (rt_se = back; rt_se; rt_se = rt_se->back) {\n\t\tif (on_rt_rq(rt_se))\n\t\t\t__dequeue_rt_entity(rt_se, flags);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_stats_enqueue_rt",
          "args": [
            "rt_rq_of_se(rt_se)",
            "rt_se",
            "flags"
          ],
          "line": 1470
        },
        "resolved": true,
        "details": {
          "function_name": "update_stats_enqueue_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1341-1350",
          "snippet": "static inline void\nupdate_stats_enqueue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (flags & ENQUEUE_WAKEUP)\n\t\tupdate_stats_enqueue_sleeper_rt(rt_rq, rt_se);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_enqueue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (flags & ENQUEUE_WAKEUP)\n\t\tupdate_stats_enqueue_sleeper_rt(rt_rq, rt_se);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1470
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_se",
          "args": [
            "rt_se"
          ],
          "line": 1468
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "248-253",
          "snippet": "static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_enqueue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\tfor_each_sched_rt_entity(rt_se)\n\t\t__enqueue_rt_entity(rt_se, flags);\n\tenqueue_top_rt_rq(&rq->rt);\n}"
  },
  {
    "function_name": "dequeue_rt_stack",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1449-1464",
    "snippet": "static void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct sched_rt_entity *back = NULL;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_se->back = back;\n\t\tback = rt_se;\n\t}\n\n\tdequeue_top_rt_rq(rt_rq_of_se(back));\n\n\tfor (rt_se = back; rt_se; rt_se = rt_se->back) {\n\t\tif (on_rt_rq(rt_se))\n\t\t\t__dequeue_rt_entity(rt_se, flags);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__dequeue_rt_entity",
          "args": [
            "rt_se",
            "flags"
          ],
          "line": 1462
        },
        "resolved": true,
        "details": {
          "function_name": "__dequeue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1431-1443",
          "snippet": "static void __dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(!rt_se->on_list);\n\t\t__delist_rt_entity(rt_se, array);\n\t}\n\trt_se->on_rq = 0;\n\n\tdec_rt_tasks(rt_se, rt_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(!rt_se->on_list);\n\t\t__delist_rt_entity(rt_se, array);\n\t}\n\trt_se->on_rq = 0;\n\n\tdec_rt_tasks(rt_se, rt_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1461
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "dequeue_top_rt_rq",
          "args": [
            "rt_rq_of_se(back)"
          ],
          "line": 1458
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1054-1069",
          "snippet": "static void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "back"
          ],
          "line": 1458
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void dequeue_rt_stack(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct sched_rt_entity *back = NULL;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\trt_se->back = back;\n\t\tback = rt_se;\n\t}\n\n\tdequeue_top_rt_rq(rt_rq_of_se(back));\n\n\tfor (rt_se = back; rt_se; rt_se = rt_se->back) {\n\t\tif (on_rt_rq(rt_se))\n\t\t\t__dequeue_rt_entity(rt_se, flags);\n\t}\n}"
  },
  {
    "function_name": "__dequeue_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1431-1443",
    "snippet": "static void __dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(!rt_se->on_list);\n\t\t__delist_rt_entity(rt_se, array);\n\t}\n\trt_se->on_rq = 0;\n\n\tdec_rt_tasks(rt_se, rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "dec_rt_tasks",
          "args": [
            "rt_se",
            "rt_rq"
          ],
          "line": 1442
        },
        "resolved": true,
        "details": {
          "function_name": "dec_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1255-1266",
          "snippet": "static inline\nvoid dec_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tWARN_ON(!rt_prio(rt_se_prio(rt_se)));\n\tWARN_ON(!rt_rq->rt_nr_running);\n\trt_rq->rt_nr_running -= rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running -= rt_se_rr_nr_running(rt_se);\n\n\tdec_rt_prio(rt_rq, rt_se_prio(rt_se));\n\tdec_rt_migration(rt_se, rt_rq);\n\tdec_rt_group(rt_se, rt_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tWARN_ON(!rt_prio(rt_se_prio(rt_se)));\n\tWARN_ON(!rt_rq->rt_nr_running);\n\trt_rq->rt_nr_running -= rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running -= rt_se_rr_nr_running(rt_se);\n\n\tdec_rt_prio(rt_rq, rt_se_prio(rt_se));\n\tdec_rt_migration(rt_se, rt_rq);\n\tdec_rt_group(rt_se, rt_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__delist_rt_entity",
          "args": [
            "rt_se",
            "array"
          ],
          "line": 1438
        },
        "resolved": true,
        "details": {
          "function_name": "__delist_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1281-1289",
          "snippet": "static void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)\n{\n\tlist_del_init(&rt_se->run_list);\n\n\tif (list_empty(array->queue + rt_se_prio(rt_se)))\n\t\t__clear_bit(rt_se_prio(rt_se), array->bitmap);\n\n\trt_se->on_list = 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)\n{\n\tlist_del_init(&rt_se->run_list);\n\n\tif (list_empty(array->queue + rt_se_prio(rt_se)))\n\t\t__clear_bit(rt_se_prio(rt_se), array->bitmap);\n\n\trt_se->on_list = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rt_se->on_list"
          ],
          "line": 1437
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "move_entity",
          "args": [
            "flags"
          ],
          "line": 1436
        },
        "resolved": true,
        "details": {
          "function_name": "move_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1273-1279",
          "snippet": "static inline bool move_entity(unsigned int flags)\n{\n\tif ((flags & (DEQUEUE_SAVE | DEQUEUE_MOVE)) == DEQUEUE_SAVE)\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool move_entity(unsigned int flags)\n{\n\tif ((flags & (DEQUEUE_SAVE | DEQUEUE_MOVE)) == DEQUEUE_SAVE)\n\t\treturn false;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1433
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(!rt_se->on_list);\n\t\t__delist_rt_entity(rt_se, array);\n\t}\n\trt_se->on_rq = 0;\n\n\tdec_rt_tasks(rt_se, rt_rq);\n}"
  },
  {
    "function_name": "__enqueue_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1397-1429",
    "snippet": "static void __enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t/*\n\t * Don't enqueue the group if its throttled, or when empty.\n\t * The latter is a consequence of the former when a child group\n\t * get throttled and the current group doesn't have any other\n\t * active members.\n\t */\n\tif (group_rq && (rt_rq_throttled(group_rq) || !group_rq->rt_nr_running)) {\n\t\tif (rt_se->on_list)\n\t\t\t__delist_rt_entity(rt_se, array);\n\t\treturn;\n\t}\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(rt_se->on_list);\n\t\tif (flags & ENQUEUE_HEAD)\n\t\t\tlist_add(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_add_tail(&rt_se->run_list, queue);\n\n\t\t__set_bit(rt_se_prio(rt_se), array->bitmap);\n\t\trt_se->on_list = 1;\n\t}\n\trt_se->on_rq = 1;\n\n\tinc_rt_tasks(rt_se, rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "inc_rt_tasks",
          "args": [
            "rt_se",
            "rt_rq"
          ],
          "line": 1428
        },
        "resolved": true,
        "details": {
          "function_name": "inc_rt_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1241-1253",
          "snippet": "static inline\nvoid inc_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tint prio = rt_se_prio(rt_se);\n\n\tWARN_ON(!rt_prio(prio));\n\trt_rq->rt_nr_running += rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running += rt_se_rr_nr_running(rt_se);\n\n\tinc_rt_prio(rt_rq, prio);\n\tinc_rt_migration(rt_se, rt_rq);\n\tinc_rt_group(rt_se, rt_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid inc_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tint prio = rt_se_prio(rt_se);\n\n\tWARN_ON(!rt_prio(prio));\n\trt_rq->rt_nr_running += rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running += rt_se_rr_nr_running(rt_se);\n\n\tinc_rt_prio(rt_rq, prio);\n\tinc_rt_migration(rt_se, rt_rq);\n\tinc_rt_group(rt_se, rt_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_bit",
          "args": [
            "rt_se_prio(rt_se)",
            "array->bitmap"
          ],
          "line": 1423
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_se_prio",
          "args": [
            "rt_se"
          ],
          "line": 1423
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "949-959",
          "snippet": "static inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&rt_se->run_list",
            "queue"
          ],
          "line": 1421
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&rt_se->run_list",
            "queue"
          ],
          "line": 1419
        },
        "resolved": true,
        "details": {
          "function_name": "cmp_filterlist_addrs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/debugfs.c",
          "lines": "95-101",
          "snippet": "static int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}",
          "includes": [
            "#include \"kcsan.h\"",
            "#include <linux/uaccess.h>",
            "#include <linux/string.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/bug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kcsan.h\"\n#include <linux/uaccess.h>\n#include <linux/string.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/sched.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/debugfs.h>\n#include <linux/bug.h>\n#include <linux/bsearch.h>\n#include <linux/atomic.h>\n\nstatic int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rt_se->on_list"
          ],
          "line": 1417
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "move_entity",
          "args": [
            "flags"
          ],
          "line": 1416
        },
        "resolved": true,
        "details": {
          "function_name": "move_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1273-1279",
          "snippet": "static inline bool move_entity(unsigned int flags)\n{\n\tif ((flags & (DEQUEUE_SAVE | DEQUEUE_MOVE)) == DEQUEUE_SAVE)\n\t\treturn false;\n\n\treturn true;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool move_entity(unsigned int flags)\n{\n\tif ((flags & (DEQUEUE_SAVE | DEQUEUE_MOVE)) == DEQUEUE_SAVE)\n\t\treturn false;\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__delist_rt_entity",
          "args": [
            "rt_se",
            "array"
          ],
          "line": 1412
        },
        "resolved": true,
        "details": {
          "function_name": "__delist_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1281-1289",
          "snippet": "static void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)\n{\n\tlist_del_init(&rt_se->run_list);\n\n\tif (list_empty(array->queue + rt_se_prio(rt_se)))\n\t\t__clear_bit(rt_se_prio(rt_se), array->bitmap);\n\n\trt_se->on_list = 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)\n{\n\tlist_del_init(&rt_se->run_list);\n\n\tif (list_empty(array->queue + rt_se_prio(rt_se)))\n\t\t__clear_bit(rt_se_prio(rt_se), array->bitmap);\n\n\trt_se->on_list = 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_throttled",
          "args": [
            "group_rq"
          ],
          "line": 1410
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_throttled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "657-660",
          "snippet": "static inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}"
        }
      },
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1401
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1399
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\tstruct rt_prio_array *array = &rt_rq->active;\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct list_head *queue = array->queue + rt_se_prio(rt_se);\n\n\t/*\n\t * Don't enqueue the group if its throttled, or when empty.\n\t * The latter is a consequence of the former when a child group\n\t * get throttled and the current group doesn't have any other\n\t * active members.\n\t */\n\tif (group_rq && (rt_rq_throttled(group_rq) || !group_rq->rt_nr_running)) {\n\t\tif (rt_se->on_list)\n\t\t\t__delist_rt_entity(rt_se, array);\n\t\treturn;\n\t}\n\n\tif (move_entity(flags)) {\n\t\tWARN_ON_ONCE(rt_se->on_list);\n\t\tif (flags & ENQUEUE_HEAD)\n\t\t\tlist_add(&rt_se->run_list, queue);\n\t\telse\n\t\t\tlist_add_tail(&rt_se->run_list, queue);\n\n\t\t__set_bit(rt_se_prio(rt_se), array->bitmap);\n\t\trt_se->on_list = 1;\n\t}\n\trt_se->on_rq = 1;\n\n\tinc_rt_tasks(rt_se, rt_rq);\n}"
  },
  {
    "function_name": "update_stats_dequeue_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1371-1395",
    "snippet": "static inline void\nupdate_stats_dequeue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tif ((flags & DEQUEUE_SLEEP) && p) {\n\t\tunsigned int state;\n\n\t\tstate = READ_ONCE(p->__state);\n\t\tif (state & TASK_INTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.sleep_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\n\t\tif (state & TASK_UNINTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.block_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__schedstat_set",
          "args": [
            "p->stats.block_start",
            "rq_clock(rq_of_rt_rq(rt_rq))"
          ],
          "line": 1392
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rq_clock",
          "args": [
            "rq_of_rt_rq(rt_rq)"
          ],
          "line": 1393
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1393
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__schedstat_set",
          "args": [
            "p->stats.sleep_start",
            "rq_clock(rq_of_rt_rq(rt_rq))"
          ],
          "line": 1388
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "p->__state"
          ],
          "line": 1386
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1381
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 1380
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedstat_enabled",
          "args": [],
          "line": 1377
        },
        "resolved": true,
        "details": {
          "function_name": "force_schedstat_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4325-4331",
          "snippet": "void force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_dequeue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tif ((flags & DEQUEUE_SLEEP) && p) {\n\t\tunsigned int state;\n\n\t\tstate = READ_ONCE(p->__state);\n\t\tif (state & TASK_INTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.sleep_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\n\t\tif (state & TASK_UNINTERRUPTIBLE)\n\t\t\t__schedstat_set(p->stats.block_start,\n\t\t\t\t\trq_clock(rq_of_rt_rq(rt_rq)));\n\t}\n}"
  },
  {
    "function_name": "update_stats_wait_end_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1352-1369",
    "snippet": "static inline void\nupdate_stats_wait_end_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_end(rq_of_rt_rq(rt_rq), p, stats);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__update_stats_wait_end",
          "args": [
            "rq_of_rt_rq(rt_rq)",
            "p",
            "stats"
          ],
          "line": 1368
        },
        "resolved": true,
        "details": {
          "function_name": "__update_stats_wait_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.c",
          "lines": "21-46",
          "snippet": "void __update_stats_wait_end(struct rq *rq, struct task_struct *p,\n\t\t\t     struct sched_statistics *stats)\n{\n\tu64 delta = rq_clock(rq) - schedstat_val(stats->wait_start);\n\n\tif (p) {\n\t\tif (task_on_rq_migrating(p)) {\n\t\t\t/*\n\t\t\t * Preserve migrating task's wait time so wait_start\n\t\t\t * time stamp can be adjusted to accumulate wait time\n\t\t\t * prior to migration.\n\t\t\t */\n\t\t\t__schedstat_set(stats->wait_start, delta);\n\n\t\t\treturn;\n\t\t}\n\n\t\ttrace_sched_stat_wait(p, delta);\n\t}\n\n\t__schedstat_set(stats->wait_max,\n\t\t\tmax(schedstat_val(stats->wait_max), delta));\n\t__schedstat_inc(stats->wait_count);\n\t__schedstat_add(stats->wait_sum, delta);\n\t__schedstat_set(stats->wait_start, 0);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid __update_stats_wait_end(struct rq *rq, struct task_struct *p,\n\t\t\t     struct sched_statistics *stats)\n{\n\tu64 delta = rq_clock(rq) - schedstat_val(stats->wait_start);\n\n\tif (p) {\n\t\tif (task_on_rq_migrating(p)) {\n\t\t\t/*\n\t\t\t * Preserve migrating task's wait time so wait_start\n\t\t\t * time stamp can be adjusted to accumulate wait time\n\t\t\t * prior to migration.\n\t\t\t */\n\t\t\t__schedstat_set(stats->wait_start, delta);\n\n\t\t\treturn;\n\t\t}\n\n\t\ttrace_sched_stat_wait(p, delta);\n\t}\n\n\t__schedstat_set(stats->wait_max,\n\t\t\tmax(schedstat_val(stats->wait_max), delta));\n\t__schedstat_inc(stats->wait_count);\n\t__schedstat_add(stats->wait_sum, delta);\n\t__schedstat_set(stats->wait_start, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1368
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__schedstats_from_rt_se",
          "args": [
            "rt_se"
          ],
          "line": 1364
        },
        "resolved": true,
        "details": {
          "function_name": "__schedstats_from_rt_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1291-1301",
          "snippet": "static inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1362
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 1361
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedstat_enabled",
          "args": [],
          "line": 1358
        },
        "resolved": true,
        "details": {
          "function_name": "force_schedstat_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4325-4331",
          "snippet": "void force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_wait_end_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_end(rq_of_rt_rq(rt_rq), p, stats);\n}"
  },
  {
    "function_name": "update_stats_enqueue_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1341-1350",
    "snippet": "static inline void\nupdate_stats_enqueue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (flags & ENQUEUE_WAKEUP)\n\t\tupdate_stats_enqueue_sleeper_rt(rt_rq, rt_se);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "update_stats_enqueue_sleeper_rt",
          "args": [
            "rt_rq",
            "rt_se"
          ],
          "line": 1349
        },
        "resolved": true,
        "details": {
          "function_name": "update_stats_enqueue_sleeper_rt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1322-1339",
          "snippet": "static inline void\nupdate_stats_enqueue_sleeper_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_enqueue_sleeper(rq_of_rt_rq(rt_rq), p, stats);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_enqueue_sleeper_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_enqueue_sleeper(rq_of_rt_rq(rt_rq), p, stats);\n}"
        }
      },
      {
        "call_info": {
          "callee": "schedstat_enabled",
          "args": [],
          "line": 1345
        },
        "resolved": true,
        "details": {
          "function_name": "force_schedstat_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4325-4331",
          "snippet": "void force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_enqueue_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se,\n\t\t\tint flags)\n{\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (flags & ENQUEUE_WAKEUP)\n\t\tupdate_stats_enqueue_sleeper_rt(rt_rq, rt_se);\n}"
  },
  {
    "function_name": "update_stats_enqueue_sleeper_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1322-1339",
    "snippet": "static inline void\nupdate_stats_enqueue_sleeper_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_enqueue_sleeper(rq_of_rt_rq(rt_rq), p, stats);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__update_stats_enqueue_sleeper",
          "args": [
            "rq_of_rt_rq(rt_rq)",
            "p",
            "stats"
          ],
          "line": 1338
        },
        "resolved": true,
        "details": {
          "function_name": "__update_stats_enqueue_sleeper",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.c",
          "lines": "48-109",
          "snippet": "void __update_stats_enqueue_sleeper(struct rq *rq, struct task_struct *p,\n\t\t\t\t    struct sched_statistics *stats)\n{\n\tu64 sleep_start, block_start;\n\n\tsleep_start = schedstat_val(stats->sleep_start);\n\tblock_start = schedstat_val(stats->block_start);\n\n\tif (sleep_start) {\n\t\tu64 delta = rq_clock(rq) - sleep_start;\n\n\t\tif ((s64)delta < 0)\n\t\t\tdelta = 0;\n\n\t\tif (unlikely(delta > schedstat_val(stats->sleep_max)))\n\t\t\t__schedstat_set(stats->sleep_max, delta);\n\n\t\t__schedstat_set(stats->sleep_start, 0);\n\t\t__schedstat_add(stats->sum_sleep_runtime, delta);\n\n\t\tif (p) {\n\t\t\taccount_scheduler_latency(p, delta >> 10, 1);\n\t\t\ttrace_sched_stat_sleep(p, delta);\n\t\t}\n\t}\n\n\tif (block_start) {\n\t\tu64 delta = rq_clock(rq) - block_start;\n\n\t\tif ((s64)delta < 0)\n\t\t\tdelta = 0;\n\n\t\tif (unlikely(delta > schedstat_val(stats->block_max)))\n\t\t\t__schedstat_set(stats->block_max, delta);\n\n\t\t__schedstat_set(stats->block_start, 0);\n\t\t__schedstat_add(stats->sum_sleep_runtime, delta);\n\t\t__schedstat_add(stats->sum_block_runtime, delta);\n\n\t\tif (p) {\n\t\t\tif (p->in_iowait) {\n\t\t\t\t__schedstat_add(stats->iowait_sum, delta);\n\t\t\t\t__schedstat_inc(stats->iowait_count);\n\t\t\t\ttrace_sched_stat_iowait(p, delta);\n\t\t\t}\n\n\t\t\ttrace_sched_stat_blocked(p, delta);\n\n\t\t\t/*\n\t\t\t * Blocking time is in units of nanosecs, so shift by\n\t\t\t * 20 to get a milliseconds-range estimation of the\n\t\t\t * amount of time that the task spent sleeping:\n\t\t\t */\n\t\t\tif (unlikely(prof_on == SLEEP_PROFILING)) {\n\t\t\t\tprofile_hits(SLEEP_PROFILING,\n\t\t\t\t\t     (void *)get_wchan(p),\n\t\t\t\t\t     delta >> 20);\n\t\t\t}\n\t\t\taccount_scheduler_latency(p, delta >> 10, 0);\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid __update_stats_enqueue_sleeper(struct rq *rq, struct task_struct *p,\n\t\t\t\t    struct sched_statistics *stats)\n{\n\tu64 sleep_start, block_start;\n\n\tsleep_start = schedstat_val(stats->sleep_start);\n\tblock_start = schedstat_val(stats->block_start);\n\n\tif (sleep_start) {\n\t\tu64 delta = rq_clock(rq) - sleep_start;\n\n\t\tif ((s64)delta < 0)\n\t\t\tdelta = 0;\n\n\t\tif (unlikely(delta > schedstat_val(stats->sleep_max)))\n\t\t\t__schedstat_set(stats->sleep_max, delta);\n\n\t\t__schedstat_set(stats->sleep_start, 0);\n\t\t__schedstat_add(stats->sum_sleep_runtime, delta);\n\n\t\tif (p) {\n\t\t\taccount_scheduler_latency(p, delta >> 10, 1);\n\t\t\ttrace_sched_stat_sleep(p, delta);\n\t\t}\n\t}\n\n\tif (block_start) {\n\t\tu64 delta = rq_clock(rq) - block_start;\n\n\t\tif ((s64)delta < 0)\n\t\t\tdelta = 0;\n\n\t\tif (unlikely(delta > schedstat_val(stats->block_max)))\n\t\t\t__schedstat_set(stats->block_max, delta);\n\n\t\t__schedstat_set(stats->block_start, 0);\n\t\t__schedstat_add(stats->sum_sleep_runtime, delta);\n\t\t__schedstat_add(stats->sum_block_runtime, delta);\n\n\t\tif (p) {\n\t\t\tif (p->in_iowait) {\n\t\t\t\t__schedstat_add(stats->iowait_sum, delta);\n\t\t\t\t__schedstat_inc(stats->iowait_count);\n\t\t\t\ttrace_sched_stat_iowait(p, delta);\n\t\t\t}\n\n\t\t\ttrace_sched_stat_blocked(p, delta);\n\n\t\t\t/*\n\t\t\t * Blocking time is in units of nanosecs, so shift by\n\t\t\t * 20 to get a milliseconds-range estimation of the\n\t\t\t * amount of time that the task spent sleeping:\n\t\t\t */\n\t\t\tif (unlikely(prof_on == SLEEP_PROFILING)) {\n\t\t\t\tprofile_hits(SLEEP_PROFILING,\n\t\t\t\t\t     (void *)get_wchan(p),\n\t\t\t\t\t     delta >> 20);\n\t\t\t}\n\t\t\taccount_scheduler_latency(p, delta >> 10, 0);\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1338
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__schedstats_from_rt_se",
          "args": [
            "rt_se"
          ],
          "line": 1334
        },
        "resolved": true,
        "details": {
          "function_name": "__schedstats_from_rt_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1291-1301",
          "snippet": "static inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1332
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 1331
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedstat_enabled",
          "args": [],
          "line": 1328
        },
        "resolved": true,
        "details": {
          "function_name": "force_schedstat_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4325-4331",
          "snippet": "void force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_enqueue_sleeper_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_enqueue_sleeper(rq_of_rt_rq(rt_rq), p, stats);\n}"
  },
  {
    "function_name": "update_stats_wait_start_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1303-1320",
    "snippet": "static inline void\nupdate_stats_wait_start_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_start(rq_of_rt_rq(rt_rq), p, stats);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "__update_stats_wait_start",
          "args": [
            "rq_of_rt_rq(rt_rq)",
            "p",
            "stats"
          ],
          "line": 1319
        },
        "resolved": true,
        "details": {
          "function_name": "__update_stats_wait_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.c",
          "lines": "7-19",
          "snippet": "void __update_stats_wait_start(struct rq *rq, struct task_struct *p,\n\t\t\t       struct sched_statistics *stats)\n{\n\tu64 wait_start, prev_wait_start;\n\n\twait_start = rq_clock(rq);\n\tprev_wait_start = schedstat_val(stats->wait_start);\n\n\tif (p && likely(wait_start > prev_wait_start))\n\t\twait_start -= prev_wait_start;\n\n\t__schedstat_set(stats->wait_start, wait_start);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid __update_stats_wait_start(struct rq *rq, struct task_struct *p,\n\t\t\t       struct sched_statistics *stats)\n{\n\tu64 wait_start, prev_wait_start;\n\n\twait_start = rq_clock(rq);\n\tprev_wait_start = schedstat_val(stats->wait_start);\n\n\tif (p && likely(wait_start > prev_wait_start))\n\t\twait_start -= prev_wait_start;\n\n\t__schedstat_set(stats->wait_start, wait_start);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1319
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__schedstats_from_rt_se",
          "args": [
            "rt_se"
          ],
          "line": 1315
        },
        "resolved": true,
        "details": {
          "function_name": "__schedstats_from_rt_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1291-1301",
          "snippet": "static inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1313
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 1312
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedstat_enabled",
          "args": [],
          "line": 1309
        },
        "resolved": true,
        "details": {
          "function_name": "force_schedstat_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4325-4331",
          "snippet": "void force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void\nupdate_stats_wait_start_rt(struct rt_rq *rt_rq, struct sched_rt_entity *rt_se)\n{\n\tstruct sched_statistics *stats;\n\tstruct task_struct *p = NULL;\n\n\tif (!schedstat_enabled())\n\t\treturn;\n\n\tif (rt_entity_is_task(rt_se))\n\t\tp = rt_task_of(rt_se);\n\n\tstats = __schedstats_from_rt_se(rt_se);\n\tif (!stats)\n\t\treturn;\n\n\t__update_stats_wait_start(rq_of_rt_rq(rt_rq), p, stats);\n}"
  },
  {
    "function_name": "__schedstats_from_rt_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1291-1301",
    "snippet": "static inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1300
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 1296
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct sched_statistics *\n__schedstats_from_rt_se(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/* schedstats is not supported for rt group. */\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn NULL;\n#endif\n\n\treturn &rt_task_of(rt_se)->stats;\n}"
  },
  {
    "function_name": "__delist_rt_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1281-1289",
    "snippet": "static void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)\n{\n\tlist_del_init(&rt_se->run_list);\n\n\tif (list_empty(array->queue + rt_se_prio(rt_se)))\n\t\t__clear_bit(rt_se_prio(rt_se), array->bitmap);\n\n\trt_se->on_list = 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__clear_bit",
          "args": [
            "rt_se_prio(rt_se)",
            "array->bitmap"
          ],
          "line": 1286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_se_prio",
          "args": [
            "rt_se"
          ],
          "line": 1286
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "949-959",
          "snippet": "static inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "array->queue + rt_se_prio(rt_se)"
          ],
          "line": 1285
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&rt_se->run_list"
          ],
          "line": 1283
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void __delist_rt_entity(struct sched_rt_entity *rt_se, struct rt_prio_array *array)\n{\n\tlist_del_init(&rt_se->run_list);\n\n\tif (list_empty(array->queue + rt_se_prio(rt_se)))\n\t\t__clear_bit(rt_se_prio(rt_se), array->bitmap);\n\n\trt_se->on_list = 0;\n}"
  },
  {
    "function_name": "move_entity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1273-1279",
    "snippet": "static inline bool move_entity(unsigned int flags)\n{\n\tif ((flags & (DEQUEUE_SAVE | DEQUEUE_MOVE)) == DEQUEUE_SAVE)\n\t\treturn false;\n\n\treturn true;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool move_entity(unsigned int flags)\n{\n\tif ((flags & (DEQUEUE_SAVE | DEQUEUE_MOVE)) == DEQUEUE_SAVE)\n\t\treturn false;\n\n\treturn true;\n}"
  },
  {
    "function_name": "dec_rt_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1255-1266",
    "snippet": "static inline\nvoid dec_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tWARN_ON(!rt_prio(rt_se_prio(rt_se)));\n\tWARN_ON(!rt_rq->rt_nr_running);\n\trt_rq->rt_nr_running -= rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running -= rt_se_rr_nr_running(rt_se);\n\n\tdec_rt_prio(rt_rq, rt_se_prio(rt_se));\n\tdec_rt_migration(rt_se, rt_rq);\n\tdec_rt_group(rt_se, rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "dec_rt_group",
          "args": [
            "rt_se",
            "rt_rq"
          ],
          "line": 1265
        },
        "resolved": true,
        "details": {
          "function_name": "dec_rt_group",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1211-1212",
          "snippet": "static inline\nvoid dec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq) {}"
        }
      },
      {
        "call_info": {
          "callee": "dec_rt_migration",
          "args": [
            "rt_se",
            "rt_rq"
          ],
          "line": 1264
        },
        "resolved": true,
        "details": {
          "function_name": "dec_rt_migration",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "427-430",
          "snippet": "static inline\nvoid dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "dec_rt_prio",
          "args": [
            "rt_rq",
            "rt_se_prio(rt_se)"
          ],
          "line": 1263
        },
        "resolved": true,
        "details": {
          "function_name": "dec_rt_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1178-1178",
          "snippet": "static inline void dec_rt_prio(struct rt_rq *rt_rq, int prio) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void dec_rt_prio(struct rt_rq *rt_rq, int prio) {}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_prio",
          "args": [
            "rt_se"
          ],
          "line": 1263
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "949-959",
          "snippet": "static inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_rr_nr_running",
          "args": [
            "rt_se"
          ],
          "line": 1261
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_rr_nr_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1227-1239",
          "snippet": "static inline\nunsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct task_struct *tsk;\n\n\tif (group_rq)\n\t\treturn group_rq->rr_nr_running;\n\n\ttsk = rt_task_of(rt_se);\n\n\treturn (tsk->policy == SCHED_RR) ? 1 : 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nunsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct task_struct *tsk;\n\n\tif (group_rq)\n\t\treturn group_rq->rr_nr_running;\n\n\ttsk = rt_task_of(rt_se);\n\n\treturn (tsk->policy == SCHED_RR) ? 1 : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_nr_running",
          "args": [
            "rt_se"
          ],
          "line": 1260
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_nr_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1216-1225",
          "snippet": "static inline\nunsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\n\tif (group_rq)\n\t\treturn group_rq->rt_nr_running;\n\telse\n\t\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nunsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\n\tif (group_rq)\n\t\treturn group_rq->rt_nr_running;\n\telse\n\t\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!rt_rq->rt_nr_running"
          ],
          "line": 1259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!rt_prio(rt_se_prio(rt_se))"
          ],
          "line": 1258
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_prio",
          "args": [
            "rt_se_prio(rt_se)"
          ],
          "line": 1258
        },
        "resolved": true,
        "details": {
          "function_name": "convert_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "43-66",
          "snippet": "static int convert_prio(int prio)\n{\n\tint cpupri;\n\n\tswitch (prio) {\n\tcase CPUPRI_INVALID:\n\t\tcpupri = CPUPRI_INVALID;\t/* -1 */\n\t\tbreak;\n\n\tcase 0 ... 98:\n\t\tcpupri = MAX_RT_PRIO-1 - prio;\t/* 1 ... 99 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO-1:\n\t\tcpupri = CPUPRI_NORMAL;\t\t/*  0 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO:\n\t\tcpupri = CPUPRI_HIGHER;\t\t/* 100 */\n\t\tbreak;\n\t}\n\n\treturn cpupri;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int convert_prio(int prio)\n{\n\tint cpupri;\n\n\tswitch (prio) {\n\tcase CPUPRI_INVALID:\n\t\tcpupri = CPUPRI_INVALID;\t/* -1 */\n\t\tbreak;\n\n\tcase 0 ... 98:\n\t\tcpupri = MAX_RT_PRIO-1 - prio;\t/* 1 ... 99 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO-1:\n\t\tcpupri = CPUPRI_NORMAL;\t\t/*  0 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO:\n\t\tcpupri = CPUPRI_HIGHER;\t\t/* 100 */\n\t\tbreak;\n\t}\n\n\treturn cpupri;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tWARN_ON(!rt_prio(rt_se_prio(rt_se)));\n\tWARN_ON(!rt_rq->rt_nr_running);\n\trt_rq->rt_nr_running -= rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running -= rt_se_rr_nr_running(rt_se);\n\n\tdec_rt_prio(rt_rq, rt_se_prio(rt_se));\n\tdec_rt_migration(rt_se, rt_rq);\n\tdec_rt_group(rt_se, rt_rq);\n}"
  },
  {
    "function_name": "inc_rt_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1241-1253",
    "snippet": "static inline\nvoid inc_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tint prio = rt_se_prio(rt_se);\n\n\tWARN_ON(!rt_prio(prio));\n\trt_rq->rt_nr_running += rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running += rt_se_rr_nr_running(rt_se);\n\n\tinc_rt_prio(rt_rq, prio);\n\tinc_rt_migration(rt_se, rt_rq);\n\tinc_rt_group(rt_se, rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "inc_rt_group",
          "args": [
            "rt_se",
            "rt_rq"
          ],
          "line": 1252
        },
        "resolved": true,
        "details": {
          "function_name": "inc_rt_group",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1205-1209",
          "snippet": "static void\ninc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstart_rt_bandwidth(&def_rt_bandwidth);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct rt_bandwidth def_rt_bandwidth;",
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\ninc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstart_rt_bandwidth(&def_rt_bandwidth);\n}"
        }
      },
      {
        "call_info": {
          "callee": "inc_rt_migration",
          "args": [
            "rt_se",
            "rt_rq"
          ],
          "line": 1251
        },
        "resolved": true,
        "details": {
          "function_name": "inc_rt_migration",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "422-425",
          "snippet": "static inline\nvoid inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "inc_rt_prio",
          "args": [
            "rt_rq",
            "prio"
          ],
          "line": 1250
        },
        "resolved": true,
        "details": {
          "function_name": "inc_rt_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1177-1177",
          "snippet": "static inline void inc_rt_prio(struct rt_rq *rt_rq, int prio) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void inc_rt_prio(struct rt_rq *rt_rq, int prio) {}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_rr_nr_running",
          "args": [
            "rt_se"
          ],
          "line": 1248
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_rr_nr_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1227-1239",
          "snippet": "static inline\nunsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct task_struct *tsk;\n\n\tif (group_rq)\n\t\treturn group_rq->rr_nr_running;\n\n\ttsk = rt_task_of(rt_se);\n\n\treturn (tsk->policy == SCHED_RR) ? 1 : 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nunsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct task_struct *tsk;\n\n\tif (group_rq)\n\t\treturn group_rq->rr_nr_running;\n\n\ttsk = rt_task_of(rt_se);\n\n\treturn (tsk->policy == SCHED_RR) ? 1 : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_nr_running",
          "args": [
            "rt_se"
          ],
          "line": 1247
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_nr_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1216-1225",
          "snippet": "static inline\nunsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\n\tif (group_rq)\n\t\treturn group_rq->rt_nr_running;\n\telse\n\t\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nunsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\n\tif (group_rq)\n\t\treturn group_rq->rt_nr_running;\n\telse\n\t\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!rt_prio(prio)"
          ],
          "line": 1246
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_prio",
          "args": [
            "prio"
          ],
          "line": 1246
        },
        "resolved": true,
        "details": {
          "function_name": "convert_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "43-66",
          "snippet": "static int convert_prio(int prio)\n{\n\tint cpupri;\n\n\tswitch (prio) {\n\tcase CPUPRI_INVALID:\n\t\tcpupri = CPUPRI_INVALID;\t/* -1 */\n\t\tbreak;\n\n\tcase 0 ... 98:\n\t\tcpupri = MAX_RT_PRIO-1 - prio;\t/* 1 ... 99 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO-1:\n\t\tcpupri = CPUPRI_NORMAL;\t\t/*  0 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO:\n\t\tcpupri = CPUPRI_HIGHER;\t\t/* 100 */\n\t\tbreak;\n\t}\n\n\treturn cpupri;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int convert_prio(int prio)\n{\n\tint cpupri;\n\n\tswitch (prio) {\n\tcase CPUPRI_INVALID:\n\t\tcpupri = CPUPRI_INVALID;\t/* -1 */\n\t\tbreak;\n\n\tcase 0 ... 98:\n\t\tcpupri = MAX_RT_PRIO-1 - prio;\t/* 1 ... 99 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO-1:\n\t\tcpupri = CPUPRI_NORMAL;\t\t/*  0 */\n\t\tbreak;\n\n\tcase MAX_RT_PRIO:\n\t\tcpupri = CPUPRI_HIGHER;\t\t/* 100 */\n\t\tbreak;\n\t}\n\n\treturn cpupri;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_prio",
          "args": [
            "rt_se"
          ],
          "line": 1244
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_prio",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "949-959",
          "snippet": "static inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid inc_rt_tasks(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tint prio = rt_se_prio(rt_se);\n\n\tWARN_ON(!rt_prio(prio));\n\trt_rq->rt_nr_running += rt_se_nr_running(rt_se);\n\trt_rq->rr_nr_running += rt_se_rr_nr_running(rt_se);\n\n\tinc_rt_prio(rt_rq, prio);\n\tinc_rt_migration(rt_se, rt_rq);\n\tinc_rt_group(rt_se, rt_rq);\n}"
  },
  {
    "function_name": "rt_se_rr_nr_running",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1227-1239",
    "snippet": "static inline\nunsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct task_struct *tsk;\n\n\tif (group_rq)\n\t\treturn group_rq->rr_nr_running;\n\n\ttsk = rt_task_of(rt_se);\n\n\treturn (tsk->policy == SCHED_RR) ? 1 : 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 1236
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1230
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nunsigned int rt_se_rr_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\tstruct task_struct *tsk;\n\n\tif (group_rq)\n\t\treturn group_rq->rr_nr_running;\n\n\ttsk = rt_task_of(rt_se);\n\n\treturn (tsk->policy == SCHED_RR) ? 1 : 0;\n}"
  },
  {
    "function_name": "rt_se_nr_running",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1216-1225",
    "snippet": "static inline\nunsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\n\tif (group_rq)\n\t\treturn group_rq->rt_nr_running;\n\telse\n\t\treturn 1;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 1219
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nunsigned int rt_se_nr_running(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *group_rq = group_rt_rq(rt_se);\n\n\tif (group_rq)\n\t\treturn group_rq->rt_nr_running;\n\telse\n\t\treturn 1;\n}"
  },
  {
    "function_name": "dec_rt_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1211-1212",
    "snippet": "static inline\nvoid dec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq) {}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq) {}"
  },
  {
    "function_name": "inc_rt_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1205-1209",
    "snippet": "static void\ninc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstart_rt_bandwidth(&def_rt_bandwidth);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct rt_bandwidth def_rt_bandwidth;",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "start_rt_bandwidth",
          "args": [
            "&def_rt_bandwidth"
          ],
          "line": 1208
        },
        "resolved": true,
        "details": {
          "function_name": "start_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "75-81",
          "snippet": "static void start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\tif (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)\n\t\treturn;\n\n\tdo_start_rt_bandwidth(rt_b);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\tif (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)\n\t\treturn;\n\n\tdo_start_rt_bandwidth(rt_b);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\ninc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstart_rt_bandwidth(&def_rt_bandwidth);\n}"
  },
  {
    "function_name": "dec_rt_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1194-1201",
    "snippet": "static void\ndec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tif (rt_se_boosted(rt_se))\n\t\trt_rq->rt_nr_boosted--;\n\n\tWARN_ON(!rt_rq->rt_nr_running && rt_rq->rt_nr_boosted);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!rt_rq->rt_nr_running && rt_rq->rt_nr_boosted"
          ],
          "line": 1200
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_se_boosted",
          "args": [
            "rt_se"
          ],
          "line": 1197
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_boosted",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "581-591",
          "snippet": "static int rt_se_boosted(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\tstruct task_struct *p;\n\n\tif (rt_rq)\n\t\treturn !!rt_rq->rt_nr_boosted;\n\n\tp = rt_task_of(rt_se);\n\treturn p->prio != p->normal_prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int rt_se_boosted(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\tstruct task_struct *p;\n\n\tif (rt_rq)\n\t\treturn !!rt_rq->rt_nr_boosted;\n\n\tp = rt_task_of(rt_se);\n\treturn p->prio != p->normal_prio;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\ndec_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tif (rt_se_boosted(rt_se))\n\t\trt_rq->rt_nr_boosted--;\n\n\tWARN_ON(!rt_rq->rt_nr_running && rt_rq->rt_nr_boosted);\n}"
  },
  {
    "function_name": "inc_rt_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1184-1192",
    "snippet": "static void\ninc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tif (rt_se_boosted(rt_se))\n\t\trt_rq->rt_nr_boosted++;\n\n\tif (rt_rq->tg)\n\t\tstart_rt_bandwidth(&rt_rq->tg->rt_bandwidth);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "start_rt_bandwidth",
          "args": [
            "&rt_rq->tg->rt_bandwidth"
          ],
          "line": 1191
        },
        "resolved": true,
        "details": {
          "function_name": "start_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "75-81",
          "snippet": "static void start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\tif (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)\n\t\treturn;\n\n\tdo_start_rt_bandwidth(rt_b);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\tif (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)\n\t\treturn;\n\n\tdo_start_rt_bandwidth(rt_b);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_se_boosted",
          "args": [
            "rt_se"
          ],
          "line": 1187
        },
        "resolved": true,
        "details": {
          "function_name": "rt_se_boosted",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "581-591",
          "snippet": "static int rt_se_boosted(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\tstruct task_struct *p;\n\n\tif (rt_rq)\n\t\treturn !!rt_rq->rt_nr_boosted;\n\n\tp = rt_task_of(rt_se);\n\treturn p->prio != p->normal_prio;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int rt_se_boosted(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\tstruct task_struct *p;\n\n\tif (rt_rq)\n\t\treturn !!rt_rq->rt_nr_boosted;\n\n\tp = rt_task_of(rt_se);\n\treturn p->prio != p->normal_prio;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\ninc_rt_group(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tif (rt_se_boosted(rt_se))\n\t\trt_rq->rt_nr_boosted++;\n\n\tif (rt_rq->tg)\n\t\tstart_rt_bandwidth(&rt_rq->tg->rt_bandwidth);\n}"
  },
  {
    "function_name": "dec_rt_prio",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1178-1178",
    "snippet": "static inline void dec_rt_prio(struct rt_rq *rt_rq, int prio) {}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void dec_rt_prio(struct rt_rq *rt_rq, int prio) {}"
  },
  {
    "function_name": "inc_rt_prio",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1177-1177",
    "snippet": "static inline void inc_rt_prio(struct rt_rq *rt_rq, int prio) {}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void inc_rt_prio(struct rt_rq *rt_rq, int prio) {}"
  },
  {
    "function_name": "dec_rt_prio",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1148-1173",
    "snippet": "static void\ndec_rt_prio(struct rt_rq *rt_rq, int prio)\n{\n\tint prev_prio = rt_rq->highest_prio.curr;\n\n\tif (rt_rq->rt_nr_running) {\n\n\t\tWARN_ON(prio < prev_prio);\n\n\t\t/*\n\t\t * This may have been our highest task, and therefore\n\t\t * we may have some recomputation to do\n\t\t */\n\t\tif (prio == prev_prio) {\n\t\t\tstruct rt_prio_array *array = &rt_rq->active;\n\n\t\t\trt_rq->highest_prio.curr =\n\t\t\t\tsched_find_first_bit(array->bitmap);\n\t\t}\n\n\t} else {\n\t\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\t}\n\n\tdec_rt_prio_smp(rt_rq, prio, prev_prio);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "dec_rt_prio_smp",
          "args": [
            "rt_rq",
            "prio",
            "prev_prio"
          ],
          "line": 1172
        },
        "resolved": true,
        "details": {
          "function_name": "dec_rt_prio_smp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1131-1132",
          "snippet": "static inline\nvoid dec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}"
        }
      },
      {
        "call_info": {
          "callee": "sched_find_first_bit",
          "args": [
            "array->bitmap"
          ],
          "line": 1165
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "prio < prev_prio"
          ],
          "line": 1155
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\ndec_rt_prio(struct rt_rq *rt_rq, int prio)\n{\n\tint prev_prio = rt_rq->highest_prio.curr;\n\n\tif (rt_rq->rt_nr_running) {\n\n\t\tWARN_ON(prio < prev_prio);\n\n\t\t/*\n\t\t * This may have been our highest task, and therefore\n\t\t * we may have some recomputation to do\n\t\t */\n\t\tif (prio == prev_prio) {\n\t\t\tstruct rt_prio_array *array = &rt_rq->active;\n\n\t\t\trt_rq->highest_prio.curr =\n\t\t\t\tsched_find_first_bit(array->bitmap);\n\t\t}\n\n\t} else {\n\t\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\t}\n\n\tdec_rt_prio_smp(rt_rq, prio, prev_prio);\n}"
  },
  {
    "function_name": "inc_rt_prio",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1137-1146",
    "snippet": "static void\ninc_rt_prio(struct rt_rq *rt_rq, int prio)\n{\n\tint prev_prio = rt_rq->highest_prio.curr;\n\n\tif (prio < prev_prio)\n\t\trt_rq->highest_prio.curr = prio;\n\n\tinc_rt_prio_smp(rt_rq, prio, prev_prio);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "inc_rt_prio_smp",
          "args": [
            "rt_rq",
            "prio",
            "prev_prio"
          ],
          "line": 1145
        },
        "resolved": true,
        "details": {
          "function_name": "inc_rt_prio_smp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1129-1130",
          "snippet": "static inline\nvoid inc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid inc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void\ninc_rt_prio(struct rt_rq *rt_rq, int prio)\n{\n\tint prev_prio = rt_rq->highest_prio.curr;\n\n\tif (prio < prev_prio)\n\t\trt_rq->highest_prio.curr = prio;\n\n\tinc_rt_prio_smp(rt_rq, prio, prev_prio);\n}"
  },
  {
    "function_name": "dec_rt_prio_smp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1131-1132",
    "snippet": "static inline\nvoid dec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}"
  },
  {
    "function_name": "inc_rt_prio_smp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1129-1130",
    "snippet": "static inline\nvoid inc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid inc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio) {}"
  },
  {
    "function_name": "dec_rt_prio_smp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1111-1125",
    "snippet": "static void\ndec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * Change rq's cpupri only if rt_rq is the top queue.\n\t */\n\tif (&rq->rt != rt_rq)\n\t\treturn;\n#endif\n\tif (rq->online && rt_rq->highest_prio.curr != prev_prio)\n\t\tcpupri_set(&rq->rd->cpupri, rq->cpu, rt_rq->highest_prio.curr);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpupri_set",
          "args": [
            "&rq->rd->cpupri",
            "rq->cpu",
            "rt_rq->highest_prio.curr"
          ],
          "line": 1124
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "210-270",
          "snippet": "void cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1114
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\ndec_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * Change rq's cpupri only if rt_rq is the top queue.\n\t */\n\tif (&rq->rt != rt_rq)\n\t\treturn;\n#endif\n\tif (rq->online && rt_rq->highest_prio.curr != prev_prio)\n\t\tcpupri_set(&rq->rd->cpupri, rq->cpu, rt_rq->highest_prio.curr);\n}"
  },
  {
    "function_name": "inc_rt_prio_smp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1095-1109",
    "snippet": "static void\ninc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * Change rq's cpupri only if rt_rq is the top queue.\n\t */\n\tif (&rq->rt != rt_rq)\n\t\treturn;\n#endif\n\tif (rq->online && prio < prev_prio)\n\t\tcpupri_set(&rq->rd->cpupri, rq->cpu, prio);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpupri_set",
          "args": [
            "&rq->rd->cpupri",
            "rq->cpu",
            "prio"
          ],
          "line": 1108
        },
        "resolved": true,
        "details": {
          "function_name": "cpupri_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/cpupri.c",
          "lines": "210-270",
          "snippet": "void cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nvoid cpupri_set(struct cpupri *cp, int cpu, int newpri)\n{\n\tint *currpri = &cp->cpu_to_pri[cpu];\n\tint oldpri = *currpri;\n\tint do_mb = 0;\n\n\tnewpri = convert_prio(newpri);\n\n\tBUG_ON(newpri >= CPUPRI_NR_PRIORITIES);\n\n\tif (newpri == oldpri)\n\t\treturn;\n\n\t/*\n\t * If the CPU was currently mapped to a different value, we\n\t * need to map it to the new value then remove the old value.\n\t * Note, we must add the new value first, otherwise we risk the\n\t * cpu being missed by the priority loop in cpupri_find.\n\t */\n\tif (likely(newpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec = &cp->pri_to_cpu[newpri];\n\n\t\tcpumask_set_cpu(cpu, vec->mask);\n\t\t/*\n\t\t * When adding a new vector, we update the mask first,\n\t\t * do a write memory barrier, and then update the count, to\n\t\t * make sure the vector is visible when count is set.\n\t\t */\n\t\tsmp_mb__before_atomic();\n\t\tatomic_inc(&(vec)->count);\n\t\tdo_mb = 1;\n\t}\n\tif (likely(oldpri != CPUPRI_INVALID)) {\n\t\tstruct cpupri_vec *vec  = &cp->pri_to_cpu[oldpri];\n\n\t\t/*\n\t\t * Because the order of modification of the vec->count\n\t\t * is important, we must make sure that the update\n\t\t * of the new prio is seen before we decrement the\n\t\t * old prio. This makes sure that the loop sees\n\t\t * one or the other when we raise the priority of\n\t\t * the run queue. We don't care about when we lower the\n\t\t * priority, as that will trigger an rt pull anyway.\n\t\t *\n\t\t * We only need to do a memory barrier if we updated\n\t\t * the new priority vec.\n\t\t */\n\t\tif (do_mb)\n\t\t\tsmp_mb__after_atomic();\n\n\t\t/*\n\t\t * When removing from the vector, we decrement the counter first\n\t\t * do a memory barrier and then clear the mask.\n\t\t */\n\t\tatomic_dec(&(vec)->count);\n\t\tsmp_mb__after_atomic();\n\t\tcpumask_clear_cpu(cpu, vec->mask);\n\t}\n\n\t*currpri = newpri;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1098
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\ninc_rt_prio_smp(struct rt_rq *rt_rq, int prio, int prev_prio)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * Change rq's cpupri only if rt_rq is the top queue.\n\t */\n\tif (&rq->rt != rt_rq)\n\t\treturn;\n#endif\n\tif (rq->online && prio < prev_prio)\n\t\tcpupri_set(&rq->rd->cpupri, rq->cpu, prio);\n}"
  },
  {
    "function_name": "enqueue_top_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1071-1091",
    "snippet": "static void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpufreq_update_util",
          "args": [
            "rq",
            "0"
          ],
          "line": 1090
        },
        "resolved": true,
        "details": {
          "function_name": "cpufreq_update_util",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2841-2841",
          "snippet": "static inline void cpufreq_update_util(struct rq *rq, unsigned int flags) {}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void activate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void activate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);\n\nstatic inline void cpufreq_update_util(struct rq *rq, unsigned int flags) {}"
        }
      },
      {
        "call_info": {
          "callee": "add_nr_running",
          "args": [
            "rq",
            "rt_rq->rt_nr_running"
          ],
          "line": 1085
        },
        "resolved": true,
        "details": {
          "function_name": "add_nr_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2375-2392",
          "snippet": "static inline void add_nr_running(struct rq *rq, unsigned count)\n{\n\tunsigned prev_nr = rq->nr_running;\n\n\trq->nr_running = prev_nr + count;\n\tif (trace_sched_update_nr_running_tp_enabled()) {\n\t\tcall_trace_sched_update_nr_running(rq, count);\n\t}\n\n#ifdef CONFIG_SMP\n\tif (prev_nr < 2 && rq->nr_running >= 2) {\n\t\tif (!READ_ONCE(rq->rd->overload))\n\t\t\tWRITE_ONCE(rq->rd->overload, 1);\n\t}\n#endif\n\n\tsched_update_tick_dependency(rq);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void call_trace_sched_update_nr_running(struct rq *rq, int count);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void call_trace_sched_update_nr_running(struct rq *rq, int count);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void add_nr_running(struct rq *rq, unsigned count)\n{\n\tunsigned prev_nr = rq->nr_running;\n\n\trq->nr_running = prev_nr + count;\n\tif (trace_sched_update_nr_running_tp_enabled()) {\n\t\tcall_trace_sched_update_nr_running(rq, count);\n\t}\n\n#ifdef CONFIG_SMP\n\tif (prev_nr < 2 && rq->nr_running >= 2) {\n\t\tif (!READ_ONCE(rq->rd->overload))\n\t\t\tWRITE_ONCE(rq->rd->overload, 1);\n\t}\n#endif\n\n\tsched_update_tick_dependency(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_throttled",
          "args": [
            "rt_rq"
          ],
          "line": 1081
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_throttled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "657-660",
          "snippet": "static inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "&rq->rt != rt_rq"
          ],
          "line": 1076
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1074
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}"
  },
  {
    "function_name": "dequeue_top_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1054-1069",
    "snippet": "static void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sub_nr_running",
          "args": [
            "rq",
            "rt_rq->rt_nr_running"
          ],
          "line": 1066
        },
        "resolved": true,
        "details": {
          "function_name": "sub_nr_running",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2394-2403",
          "snippet": "static inline void sub_nr_running(struct rq *rq, unsigned count)\n{\n\trq->nr_running -= count;\n\tif (trace_sched_update_nr_running_tp_enabled()) {\n\t\tcall_trace_sched_update_nr_running(rq, -count);\n\t}\n\n\t/* Check if we still need preemption */\n\tsched_update_tick_dependency(rq);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void call_trace_sched_update_nr_running(struct rq *rq, int count);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void call_trace_sched_update_nr_running(struct rq *rq, int count);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void sub_nr_running(struct rq *rq, unsigned count)\n{\n\trq->nr_running -= count;\n\tif (trace_sched_update_nr_running_tp_enabled()) {\n\t\tcall_trace_sched_update_nr_running(rq, -count);\n\t}\n\n\t/* Check if we still need preemption */\n\tsched_update_tick_dependency(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!rq->nr_running"
          ],
          "line": 1064
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "&rq->rt != rt_rq"
          ],
          "line": 1059
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 1057
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}"
  },
  {
    "function_name": "update_curr_rt",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "1008-1052",
    "snippet": "static void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "do_start_rt_bandwidth",
          "args": [
            "sched_rt_bandwidth(rt_rq)"
          ],
          "line": 1049
        },
        "resolved": true,
        "details": {
          "function_name": "do_start_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "55-73",
          "snippet": "static inline void do_start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tif (!rt_b->rt_period_active) {\n\t\trt_b->rt_period_active = 1;\n\t\t/*\n\t\t * SCHED_DEADLINE updates the bandwidth, as a run away\n\t\t * RT task with a DL task could hog a CPU. But DL does\n\t\t * not reset the period. If a deadline task was running\n\t\t * without an RT task running, it can cause RT tasks to\n\t\t * throttle when they start up. Kick the timer right away\n\t\t * to update the period.\n\t\t */\n\t\thrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));\n\t\thrtimer_start_expires(&rt_b->rt_period_timer,\n\t\t\t\t      HRTIMER_MODE_ABS_PINNED_HARD);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void do_start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tif (!rt_b->rt_period_active) {\n\t\trt_b->rt_period_active = 1;\n\t\t/*\n\t\t * SCHED_DEADLINE updates the bandwidth, as a run away\n\t\t * RT task with a DL task could hog a CPU. But DL does\n\t\t * not reset the period. If a deadline task was running\n\t\t * without an RT task running, it can cause RT tasks to\n\t\t * throttle when they start up. Kick the timer right away\n\t\t * to update the period.\n\t\t */\n\t\thrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));\n\t\thrtimer_start_expires(&rt_b->rt_period_timer,\n\t\t\t\t      HRTIMER_MODE_ABS_PINNED_HARD);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_bandwidth",
          "args": [
            "rt_rq"
          ],
          "line": 1049
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_bandwidth_account",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "680-686",
          "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nbool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 1047
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 1046
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_runtime_exceeded",
          "args": [
            "rt_rq"
          ],
          "line": 1044
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_runtime_exceeded",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "961-1002",
          "snippet": "static int sched_rt_runtime_exceeded(struct rt_rq *rt_rq)\n{\n\tu64 runtime = sched_rt_runtime(rt_rq);\n\n\tif (rt_rq->rt_throttled)\n\t\treturn rt_rq_throttled(rt_rq);\n\n\tif (runtime >= sched_rt_period(rt_rq))\n\t\treturn 0;\n\n\tbalance_runtime(rt_rq);\n\truntime = sched_rt_runtime(rt_rq);\n\tif (runtime == RUNTIME_INF)\n\t\treturn 0;\n\n\tif (rt_rq->rt_time > runtime) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\t/*\n\t\t * Don't actually throttle groups that have no runtime assigned\n\t\t * but accrue some time due to boosting.\n\t\t */\n\t\tif (likely(rt_b->rt_runtime)) {\n\t\t\trt_rq->rt_throttled = 1;\n\t\t\tprintk_deferred_once(\"sched: RT throttling activated\\n\");\n\t\t} else {\n\t\t\t/*\n\t\t\t * In case we did anyway, make it go away,\n\t\t\t * replenishment is a joke, since it will replenish us\n\t\t\t * with exactly 0 ns.\n\t\t\t */\n\t\t\trt_rq->rt_time = 0;\n\t\t}\n\n\t\tif (rt_rq_throttled(rt_rq)) {\n\t\t\tsched_rt_rq_dequeue(rt_rq);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int sched_rt_runtime_exceeded(struct rt_rq *rt_rq)\n{\n\tu64 runtime = sched_rt_runtime(rt_rq);\n\n\tif (rt_rq->rt_throttled)\n\t\treturn rt_rq_throttled(rt_rq);\n\n\tif (runtime >= sched_rt_period(rt_rq))\n\t\treturn 0;\n\n\tbalance_runtime(rt_rq);\n\truntime = sched_rt_runtime(rt_rq);\n\tif (runtime == RUNTIME_INF)\n\t\treturn 0;\n\n\tif (rt_rq->rt_time > runtime) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\t/*\n\t\t * Don't actually throttle groups that have no runtime assigned\n\t\t * but accrue some time due to boosting.\n\t\t */\n\t\tif (likely(rt_b->rt_runtime)) {\n\t\t\trt_rq->rt_throttled = 1;\n\t\t\tprintk_deferred_once(\"sched: RT throttling activated\\n\");\n\t\t} else {\n\t\t\t/*\n\t\t\t * In case we did anyway, make it go away,\n\t\t\t * replenishment is a joke, since it will replenish us\n\t\t\t * with exactly 0 ns.\n\t\t\t */\n\t\t\trt_rq->rt_time = 0;\n\t\t}\n\n\t\tif (rt_rq_throttled(rt_rq)) {\n\t\t\tsched_rt_rq_dequeue(rt_rq);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 1042
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_of_se",
          "args": [
            "rt_se"
          ],
          "line": 1038
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_of_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "255-260",
          "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_bandwidth_enabled",
          "args": [],
          "line": 1034
        },
        "resolved": true,
        "details": {
          "function_name": "rt_bandwidth_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "630-633",
          "snippet": "static inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cgroup_account_cputime",
          "args": [
            "curr",
            "delta_exec"
          ],
          "line": 1032
        },
        "resolved": true,
        "details": {
          "function_name": "__cgroup_account_cputime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cgroup/rstat.c",
          "lines": "365-373",
          "snippet": "void __cgroup_account_cputime(struct cgroup *cgrp, u64 delta_exec)\n{\n\tstruct cgroup_rstat_cpu *rstatc;\n\tunsigned long flags;\n\n\trstatc = cgroup_base_stat_cputime_account_begin(cgrp, &flags);\n\trstatc->bstat.cputime.sum_exec_runtime += delta_exec;\n\tcgroup_base_stat_cputime_account_end(cgrp, rstatc, flags);\n}",
          "includes": [
            "#include <linux/sched/cputime.h>",
            "#include \"cgroup-internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/cputime.h>\n#include \"cgroup-internal.h\"\n\nvoid __cgroup_account_cputime(struct cgroup *cgrp, u64 delta_exec)\n{\n\tstruct cgroup_rstat_cpu *rstatc;\n\tunsigned long flags;\n\n\trstatc = cgroup_base_stat_cputime_account_begin(cgrp, &flags);\n\trstatc->bstat.cputime.sum_exec_runtime += delta_exec;\n\tcgroup_base_stat_cputime_account_end(cgrp, rstatc, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "account_group_exec_runtime",
          "args": [
            "curr",
            "delta_exec"
          ],
          "line": 1029
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_sched_stat_runtime",
          "args": [
            "curr",
            "delta_exec",
            "0"
          ],
          "line": 1026
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedstat_set",
          "args": [
            "curr->stats.exec_max",
            "max(curr->stats.exec_max, delta_exec)"
          ],
          "line": 1023
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "max",
          "args": [
            "curr->stats.exec_max",
            "delta_exec"
          ],
          "line": 1024
        },
        "resolved": true,
        "details": {
          "function_name": "wrap_max",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "254-257",
          "snippet": "static inline u64 wrap_max(u64 x, u64 y)\n{\n\treturn (s64)(x - y) > 0 ? x : y;\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic inline u64 wrap_max(u64 x, u64 y)\n{\n\treturn (s64)(x - y) > 0 ? x : y;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "(s64)delta_exec <= 0"
          ],
          "line": 1020
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rq_clock_task",
          "args": [
            "rq"
          ],
          "line": 1018
        },
        "resolved": true,
        "details": {
          "function_name": "rq_clock_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1470-1476",
          "snippet": "static inline u64 rq_clock_task(struct rq *rq)\n{\n\tlockdep_assert_rq_held(rq);\n\tassert_clock_updated(rq);\n\n\treturn rq->clock_task;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline u64 rq_clock_task(struct rq *rq)\n{\n\tlockdep_assert_rq_held(rq);\n\tassert_clock_updated(rq);\n\n\treturn rq->clock_task;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void update_curr_rt(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tstruct sched_rt_entity *rt_se = &curr->rt;\n\tu64 delta_exec;\n\tu64 now;\n\n\tif (curr->sched_class != &rt_sched_class)\n\t\treturn;\n\n\tnow = rq_clock_task(rq);\n\tdelta_exec = now - curr->se.exec_start;\n\tif (unlikely((s64)delta_exec <= 0))\n\t\treturn;\n\n\tschedstat_set(curr->stats.exec_max,\n\t\t      max(curr->stats.exec_max, delta_exec));\n\n\ttrace_sched_stat_runtime(curr, delta_exec, 0);\n\n\tcurr->se.sum_exec_runtime += delta_exec;\n\taccount_group_exec_runtime(curr, delta_exec);\n\n\tcurr->se.exec_start = now;\n\tcgroup_account_cputime(curr, delta_exec);\n\n\tif (!rt_bandwidth_enabled())\n\t\treturn;\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = rt_rq_of_se(rt_se);\n\t\tint exceeded;\n\n\t\tif (sched_rt_runtime(rt_rq) != RUNTIME_INF) {\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\trt_rq->rt_time += delta_exec;\n\t\t\texceeded = sched_rt_runtime_exceeded(rt_rq);\n\t\t\tif (exceeded)\n\t\t\t\tresched_curr(rq);\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t\tif (exceeded)\n\t\t\t\tdo_start_rt_bandwidth(sched_rt_bandwidth(rt_rq));\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "sched_rt_runtime_exceeded",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "961-1002",
    "snippet": "static int sched_rt_runtime_exceeded(struct rt_rq *rt_rq)\n{\n\tu64 runtime = sched_rt_runtime(rt_rq);\n\n\tif (rt_rq->rt_throttled)\n\t\treturn rt_rq_throttled(rt_rq);\n\n\tif (runtime >= sched_rt_period(rt_rq))\n\t\treturn 0;\n\n\tbalance_runtime(rt_rq);\n\truntime = sched_rt_runtime(rt_rq);\n\tif (runtime == RUNTIME_INF)\n\t\treturn 0;\n\n\tif (rt_rq->rt_time > runtime) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\t/*\n\t\t * Don't actually throttle groups that have no runtime assigned\n\t\t * but accrue some time due to boosting.\n\t\t */\n\t\tif (likely(rt_b->rt_runtime)) {\n\t\t\trt_rq->rt_throttled = 1;\n\t\t\tprintk_deferred_once(\"sched: RT throttling activated\\n\");\n\t\t} else {\n\t\t\t/*\n\t\t\t * In case we did anyway, make it go away,\n\t\t\t * replenishment is a joke, since it will replenish us\n\t\t\t * with exactly 0 ns.\n\t\t\t */\n\t\t\trt_rq->rt_time = 0;\n\t\t}\n\n\t\tif (rt_rq_throttled(rt_rq)) {\n\t\t\tsched_rt_rq_dequeue(rt_rq);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_rt_rq_dequeue",
          "args": [
            "rt_rq"
          ],
          "line": 996
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_rq_dequeue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "652-655",
          "snippet": "static inline void sched_rt_rq_dequeue(struct rt_rq *rt_rq)\n{\n\tdequeue_top_rt_rq(rt_rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void sched_rt_rq_dequeue(struct rt_rq *rt_rq)\n{\n\tdequeue_top_rt_rq(rt_rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_throttled",
          "args": [
            "rt_rq"
          ],
          "line": 995
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_throttled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "657-660",
          "snippet": "static inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}"
        }
      },
      {
        "call_info": {
          "callee": "printk_deferred_once",
          "args": [
            "\"sched: RT throttling activated\\n\""
          ],
          "line": 985
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "rt_b->rt_runtime"
          ],
          "line": 983
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_rt_bandwidth",
          "args": [
            "rt_rq"
          ],
          "line": 977
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_bandwidth_account",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "680-686",
          "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nbool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_runtime",
          "args": [
            "rt_rq"
          ],
          "line": 972
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_runtime_exceeded",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "961-1002",
          "snippet": "static int sched_rt_runtime_exceeded(struct rt_rq *rt_rq)\n{\n\tu64 runtime = sched_rt_runtime(rt_rq);\n\n\tif (rt_rq->rt_throttled)\n\t\treturn rt_rq_throttled(rt_rq);\n\n\tif (runtime >= sched_rt_period(rt_rq))\n\t\treturn 0;\n\n\tbalance_runtime(rt_rq);\n\truntime = sched_rt_runtime(rt_rq);\n\tif (runtime == RUNTIME_INF)\n\t\treturn 0;\n\n\tif (rt_rq->rt_time > runtime) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\t/*\n\t\t * Don't actually throttle groups that have no runtime assigned\n\t\t * but accrue some time due to boosting.\n\t\t */\n\t\tif (likely(rt_b->rt_runtime)) {\n\t\t\trt_rq->rt_throttled = 1;\n\t\t\tprintk_deferred_once(\"sched: RT throttling activated\\n\");\n\t\t} else {\n\t\t\t/*\n\t\t\t * In case we did anyway, make it go away,\n\t\t\t * replenishment is a joke, since it will replenish us\n\t\t\t * with exactly 0 ns.\n\t\t\t */\n\t\t\trt_rq->rt_time = 0;\n\t\t}\n\n\t\tif (rt_rq_throttled(rt_rq)) {\n\t\t\tsched_rt_rq_dequeue(rt_rq);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "balance_runtime",
          "args": [
            "rt_rq"
          ],
          "line": 971
        },
        "resolved": true,
        "details": {
          "function_name": "balance_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "862-862",
          "snippet": "static inline void balance_runtime(struct rt_rq *rt_rq) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void balance_runtime(struct rt_rq *rt_rq) {}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_period",
          "args": [
            "rt_rq"
          ],
          "line": 968
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_period",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "623-626",
          "snippet": "static inline u64 sched_rt_period(struct rt_rq *rt_rq)\n{\n\treturn ktime_to_ns(def_rt_bandwidth.rt_period);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "struct rt_bandwidth def_rt_bandwidth;",
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline u64 sched_rt_period(struct rt_rq *rt_rq)\n{\n\treturn ktime_to_ns(def_rt_bandwidth.rt_period);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int sched_rt_runtime_exceeded(struct rt_rq *rt_rq)\n{\n\tu64 runtime = sched_rt_runtime(rt_rq);\n\n\tif (rt_rq->rt_throttled)\n\t\treturn rt_rq_throttled(rt_rq);\n\n\tif (runtime >= sched_rt_period(rt_rq))\n\t\treturn 0;\n\n\tbalance_runtime(rt_rq);\n\truntime = sched_rt_runtime(rt_rq);\n\tif (runtime == RUNTIME_INF)\n\t\treturn 0;\n\n\tif (rt_rq->rt_time > runtime) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\t/*\n\t\t * Don't actually throttle groups that have no runtime assigned\n\t\t * but accrue some time due to boosting.\n\t\t */\n\t\tif (likely(rt_b->rt_runtime)) {\n\t\t\trt_rq->rt_throttled = 1;\n\t\t\tprintk_deferred_once(\"sched: RT throttling activated\\n\");\n\t\t} else {\n\t\t\t/*\n\t\t\t * In case we did anyway, make it go away,\n\t\t\t * replenishment is a joke, since it will replenish us\n\t\t\t * with exactly 0 ns.\n\t\t\t */\n\t\t\trt_rq->rt_time = 0;\n\t\t}\n\n\t\tif (rt_rq_throttled(rt_rq)) {\n\t\t\tsched_rt_rq_dequeue(rt_rq);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "rt_se_prio",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "949-959",
    "snippet": "static inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 958
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 952
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_se_prio(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_RT_GROUP_SCHED\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\tif (rt_rq)\n\t\treturn rt_rq->highest_prio.curr;\n#endif\n\n\treturn rt_task_of(rt_se)->prio;\n}"
  },
  {
    "function_name": "do_sched_rt_period_timer",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "865-947",
    "snippet": "static int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun)\n{\n\tint i, idle = 1, throttled = 0;\n\tconst struct cpumask *span;\n\n\tspan = sched_rt_period_mask();\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * FIXME: isolated CPUs should really leave the root task group,\n\t * whether they are isolcpus or were isolated via cpusets, lest\n\t * the timer run on a CPU which does not service all runqueues,\n\t * potentially leaving other CPUs indefinitely throttled.  If\n\t * isolation is really required, the user will turn the throttle\n\t * off to kill the perturbations it causes anyway.  Meanwhile,\n\t * this maintains functionality for boot and/or troubleshooting.\n\t */\n\tif (rt_b == &root_task_group.rt_bandwidth)\n\t\tspan = cpu_online_mask;\n#endif\n\tfor_each_cpu(i, span) {\n\t\tint enqueue = 0;\n\t\tstruct rt_rq *rt_rq = sched_rt_period_rt_rq(rt_b, i);\n\t\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\t\tint skip;\n\n\t\t/*\n\t\t * When span == cpu_online_mask, taking each rq->lock\n\t\t * can be time-consuming. Try to avoid it when possible.\n\t\t */\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\tif (!sched_feat(RT_RUNTIME_SHARE) && rt_rq->rt_runtime != RUNTIME_INF)\n\t\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\tskip = !rt_rq->rt_time && !rt_rq->rt_nr_running;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\tif (skip)\n\t\t\tcontinue;\n\n\t\traw_spin_rq_lock(rq);\n\t\tupdate_rq_clock(rq);\n\n\t\tif (rt_rq->rt_time) {\n\t\t\tu64 runtime;\n\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\tif (rt_rq->rt_throttled)\n\t\t\t\tbalance_runtime(rt_rq);\n\t\t\truntime = rt_rq->rt_runtime;\n\t\t\trt_rq->rt_time -= min(rt_rq->rt_time, overrun*runtime);\n\t\t\tif (rt_rq->rt_throttled && rt_rq->rt_time < runtime) {\n\t\t\t\trt_rq->rt_throttled = 0;\n\t\t\t\tenqueue = 1;\n\n\t\t\t\t/*\n\t\t\t\t * When we're idle and a woken (rt) task is\n\t\t\t\t * throttled check_preempt_curr() will set\n\t\t\t\t * skip_update and the time between the wakeup\n\t\t\t\t * and this unthrottle will get accounted as\n\t\t\t\t * 'runtime'.\n\t\t\t\t */\n\t\t\t\tif (rt_rq->rt_nr_running && rq->curr == rq->idle)\n\t\t\t\t\trq_clock_cancel_skipupdate(rq);\n\t\t\t}\n\t\t\tif (rt_rq->rt_time || rt_rq->rt_nr_running)\n\t\t\t\tidle = 0;\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t} else if (rt_rq->rt_nr_running) {\n\t\t\tidle = 0;\n\t\t\tif (!rt_rq_throttled(rt_rq))\n\t\t\t\tenqueue = 1;\n\t\t}\n\t\tif (rt_rq->rt_throttled)\n\t\t\tthrottled = 1;\n\n\t\tif (enqueue)\n\t\t\tsched_rt_rq_enqueue(rt_rq);\n\t\traw_spin_rq_unlock(rq);\n\t}\n\n\tif (!throttled && (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF))\n\t\treturn 1;\n\n\treturn idle;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun);",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_bandwidth_enabled",
          "args": [],
          "line": 943
        },
        "resolved": true,
        "details": {
          "function_name": "rt_bandwidth_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "630-633",
          "snippet": "static inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_unlock",
          "args": [
            "rq"
          ],
          "line": 940
        },
        "resolved": true,
        "details": {
          "function_name": "raw_spin_rq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "531-534",
          "snippet": "void raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid raw_spin_rq_unlock(struct rq *rq)\n{\n\traw_spin_unlock(rq_lockp(rq));\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_rq_enqueue",
          "args": [
            "rt_rq"
          ],
          "line": 939
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_rq_enqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "641-650",
          "snippet": "static inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tif (!rt_rq->rt_nr_running)\n\t\treturn;\n\n\tenqueue_top_rt_rq(rt_rq);\n\tresched_curr(rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tif (!rt_rq->rt_nr_running)\n\t\treturn;\n\n\tenqueue_top_rt_rq(rt_rq);\n\tresched_curr(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_rq_throttled",
          "args": [
            "rt_rq"
          ],
          "line": 932
        },
        "resolved": true,
        "details": {
          "function_name": "rt_rq_throttled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "657-660",
          "snippet": "static inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 929
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock_cancel_skipupdate",
          "args": [
            "rq"
          ],
          "line": 925
        },
        "resolved": true,
        "details": {
          "function_name": "rq_clock_cancel_skipupdate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1506-1510",
          "snippet": "static inline void rq_clock_cancel_skipupdate(struct rq *rq)\n{\n\tlockdep_assert_rq_held(rq);\n\trq->clock_update_flags &= ~RQCF_REQ_SKIP;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [
            "#define RQCF_REQ_SKIP\t\t0x01"
          ],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\n#define RQCF_REQ_SKIP\t\t0x01\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void rq_clock_cancel_skipupdate(struct rq *rq)\n{\n\tlockdep_assert_rq_held(rq);\n\trq->clock_update_flags &= ~RQCF_REQ_SKIP;\n}"
        }
      },
      {
        "call_info": {
          "callee": "min",
          "args": [
            "rt_rq->rt_time",
            "overrun*runtime"
          ],
          "line": 912
        },
        "resolved": true,
        "details": {
          "function_name": "wrap_min",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "249-252",
          "snippet": "static inline u64 wrap_min(u64 x, u64 y)\n{\n\treturn (s64)(x - y) < 0 ? x : y;\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic inline u64 wrap_min(u64 x, u64 y)\n{\n\treturn (s64)(x - y) < 0 ? x : y;\n}"
        }
      },
      {
        "call_info": {
          "callee": "balance_runtime",
          "args": [
            "rt_rq"
          ],
          "line": 910
        },
        "resolved": true,
        "details": {
          "function_name": "balance_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "862-862",
          "snippet": "static inline void balance_runtime(struct rt_rq *rt_rq) {}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void balance_runtime(struct rt_rq *rt_rq) {}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 908
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "update_rq_clock",
          "args": [
            "rq"
          ],
          "line": 903
        },
        "resolved": true,
        "details": {
          "function_name": "update_rq_clock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "679-699",
          "snippet": "void update_rq_clock(struct rq *rq)\n{\n\ts64 delta;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (rq->clock_update_flags & RQCF_ACT_SKIP)\n\t\treturn;\n\n#ifdef CONFIG_SCHED_DEBUG\n\tif (sched_feat(WARN_DOUBLE_CLOCK))\n\t\tSCHED_WARN_ON(rq->clock_update_flags & RQCF_UPDATED);\n\trq->clock_update_flags |= RQCF_UPDATED;\n#endif\n\n\tdelta = sched_clock_cpu(cpu_of(rq)) - rq->clock;\n\tif (delta < 0)\n\t\treturn;\n\trq->clock += delta;\n\tupdate_rq_clock_task(rq, delta);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid update_rq_clock(struct rq *rq)\n{\n\ts64 delta;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (rq->clock_update_flags & RQCF_ACT_SKIP)\n\t\treturn;\n\n#ifdef CONFIG_SCHED_DEBUG\n\tif (sched_feat(WARN_DOUBLE_CLOCK))\n\t\tSCHED_WARN_ON(rq->clock_update_flags & RQCF_UPDATED);\n\trq->clock_update_flags |= RQCF_UPDATED;\n#endif\n\n\tdelta = sched_clock_cpu(cpu_of(rq)) - rq->clock;\n\tif (delta < 0)\n\t\treturn;\n\trq->clock += delta;\n\tupdate_rq_clock_task(rq, delta);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_rq_lock",
          "args": [
            "rq"
          ],
          "line": 902
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_rq_lock_irqsave",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1333-1339",
          "snippet": "static inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void activate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void activate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);\n\nstatic inline unsigned long _raw_spin_rq_lock_irqsave(struct rq *rq)\n{\n\tunsigned long flags;\n\tlocal_irq_save(flags);\n\traw_spin_rq_lock(rq);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_feat",
          "args": [
            "RT_RUNTIME_SHARE"
          ],
          "line": 895
        },
        "resolved": true,
        "details": {
          "function_name": "sched_feat_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/debug.c",
          "lines": "99-122",
          "snippet": "static int sched_feat_set(char *cmp)\n{\n\tint i;\n\tint neg = 0;\n\n\tif (strncmp(cmp, \"NO_\", 3) == 0) {\n\t\tneg = 1;\n\t\tcmp += 3;\n\t}\n\n\ti = match_string(sched_feat_names, __SCHED_FEAT_NR, cmp);\n\tif (i < 0)\n\t\treturn i;\n\n\tif (neg) {\n\t\tsysctl_sched_features &= ~(1UL << i);\n\t\tsched_feat_disable(i);\n\t} else {\n\t\tsysctl_sched_features |= (1UL << i);\n\t\tsched_feat_enable(i);\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static const char * const sched_feat_names[] = {\n#include \"features.h\"\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic const char * const sched_feat_names[] = {\n#include \"features.h\"\n};\n\nstatic int sched_feat_set(char *cmp)\n{\n\tint i;\n\tint neg = 0;\n\n\tif (strncmp(cmp, \"NO_\", 3) == 0) {\n\t\tneg = 1;\n\t\tcmp += 3;\n\t}\n\n\ti = match_string(sched_feat_names, __SCHED_FEAT_NR, cmp);\n\tif (i < 0)\n\t\treturn i;\n\n\tif (neg) {\n\t\tsysctl_sched_features &= ~(1UL << i);\n\t\tsched_feat_disable(i);\n\t} else {\n\t\tsysctl_sched_features |= (1UL << i);\n\t\tsched_feat_enable(i);\n\t}\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 887
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_period_rt_rq",
          "args": [
            "rt_b",
            "i"
          ],
          "line": 886
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_period_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "667-671",
          "snippet": "static inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "i",
            "span"
          ],
          "line": 884
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_rt_period_mask",
          "args": [],
          "line": 870
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_period_mask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "662-665",
          "snippet": "static inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn cpu_online_mask;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn cpu_online_mask;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun);\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun)\n{\n\tint i, idle = 1, throttled = 0;\n\tconst struct cpumask *span;\n\n\tspan = sched_rt_period_mask();\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * FIXME: isolated CPUs should really leave the root task group,\n\t * whether they are isolcpus or were isolated via cpusets, lest\n\t * the timer run on a CPU which does not service all runqueues,\n\t * potentially leaving other CPUs indefinitely throttled.  If\n\t * isolation is really required, the user will turn the throttle\n\t * off to kill the perturbations it causes anyway.  Meanwhile,\n\t * this maintains functionality for boot and/or troubleshooting.\n\t */\n\tif (rt_b == &root_task_group.rt_bandwidth)\n\t\tspan = cpu_online_mask;\n#endif\n\tfor_each_cpu(i, span) {\n\t\tint enqueue = 0;\n\t\tstruct rt_rq *rt_rq = sched_rt_period_rt_rq(rt_b, i);\n\t\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\t\tint skip;\n\n\t\t/*\n\t\t * When span == cpu_online_mask, taking each rq->lock\n\t\t * can be time-consuming. Try to avoid it when possible.\n\t\t */\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\tif (!sched_feat(RT_RUNTIME_SHARE) && rt_rq->rt_runtime != RUNTIME_INF)\n\t\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\tskip = !rt_rq->rt_time && !rt_rq->rt_nr_running;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\tif (skip)\n\t\t\tcontinue;\n\n\t\traw_spin_rq_lock(rq);\n\t\tupdate_rq_clock(rq);\n\n\t\tif (rt_rq->rt_time) {\n\t\t\tu64 runtime;\n\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\tif (rt_rq->rt_throttled)\n\t\t\t\tbalance_runtime(rt_rq);\n\t\t\truntime = rt_rq->rt_runtime;\n\t\t\trt_rq->rt_time -= min(rt_rq->rt_time, overrun*runtime);\n\t\t\tif (rt_rq->rt_throttled && rt_rq->rt_time < runtime) {\n\t\t\t\trt_rq->rt_throttled = 0;\n\t\t\t\tenqueue = 1;\n\n\t\t\t\t/*\n\t\t\t\t * When we're idle and a woken (rt) task is\n\t\t\t\t * throttled check_preempt_curr() will set\n\t\t\t\t * skip_update and the time between the wakeup\n\t\t\t\t * and this unthrottle will get accounted as\n\t\t\t\t * 'runtime'.\n\t\t\t\t */\n\t\t\t\tif (rt_rq->rt_nr_running && rq->curr == rq->idle)\n\t\t\t\t\trq_clock_cancel_skipupdate(rq);\n\t\t\t}\n\t\t\tif (rt_rq->rt_time || rt_rq->rt_nr_running)\n\t\t\t\tidle = 0;\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t} else if (rt_rq->rt_nr_running) {\n\t\t\tidle = 0;\n\t\t\tif (!rt_rq_throttled(rt_rq))\n\t\t\t\tenqueue = 1;\n\t\t}\n\t\tif (rt_rq->rt_throttled)\n\t\t\tthrottled = 1;\n\n\t\tif (enqueue)\n\t\t\tsched_rt_rq_enqueue(rt_rq);\n\t\traw_spin_rq_unlock(rq);\n\t}\n\n\tif (!throttled && (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF))\n\t\treturn 1;\n\n\treturn idle;\n}"
  },
  {
    "function_name": "balance_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "862-862",
    "snippet": "static inline void balance_runtime(struct rt_rq *rt_rq) {}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void balance_runtime(struct rt_rq *rt_rq) {}"
  },
  {
    "function_name": "balance_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "850-860",
    "snippet": "static void balance_runtime(struct rt_rq *rt_rq)\n{\n\tif (!sched_feat(RT_RUNTIME_SHARE))\n\t\treturn;\n\n\tif (rt_rq->rt_time > rt_rq->rt_runtime) {\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\tdo_balance_runtime(rt_rq);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 858
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "do_balance_runtime",
          "args": [
            "rt_rq"
          ],
          "line": 857
        },
        "resolved": true,
        "details": {
          "function_name": "do_balance_runtime",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "692-739",
          "snippet": "static void do_balance_runtime(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\tstruct root_domain *rd = rq_of_rt_rq(rt_rq)->rd;\n\tint i, weight;\n\tu64 rt_period;\n\n\tweight = cpumask_weight(rd->span);\n\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\trt_period = ktime_to_ns(rt_b->rt_period);\n\tfor_each_cpu(i, rd->span) {\n\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\ts64 diff;\n\n\t\tif (iter == rt_rq)\n\t\t\tcontinue;\n\n\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t/*\n\t\t * Either all rqs have inf runtime and there's nothing to steal\n\t\t * or __disable_runtime() below sets a specific rq to inf to\n\t\t * indicate its been disabled and disallow stealing.\n\t\t */\n\t\tif (iter->rt_runtime == RUNTIME_INF)\n\t\t\tgoto next;\n\n\t\t/*\n\t\t * From runqueues with spare time, take 1/n part of their\n\t\t * spare time, but no more than our period.\n\t\t */\n\t\tdiff = iter->rt_runtime - iter->rt_time;\n\t\tif (diff > 0) {\n\t\t\tdiff = div_u64((u64)diff, weight);\n\t\t\tif (rt_rq->rt_runtime + diff > rt_period)\n\t\t\t\tdiff = rt_period - rt_rq->rt_runtime;\n\t\t\titer->rt_runtime -= diff;\n\t\t\trt_rq->rt_runtime += diff;\n\t\t\tif (rt_rq->rt_runtime == rt_period) {\n\t\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext:\n\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void do_balance_runtime(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\tstruct root_domain *rd = rq_of_rt_rq(rt_rq)->rd;\n\tint i, weight;\n\tu64 rt_period;\n\n\tweight = cpumask_weight(rd->span);\n\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\trt_period = ktime_to_ns(rt_b->rt_period);\n\tfor_each_cpu(i, rd->span) {\n\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\ts64 diff;\n\n\t\tif (iter == rt_rq)\n\t\t\tcontinue;\n\n\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t/*\n\t\t * Either all rqs have inf runtime and there's nothing to steal\n\t\t * or __disable_runtime() below sets a specific rq to inf to\n\t\t * indicate its been disabled and disallow stealing.\n\t\t */\n\t\tif (iter->rt_runtime == RUNTIME_INF)\n\t\t\tgoto next;\n\n\t\t/*\n\t\t * From runqueues with spare time, take 1/n part of their\n\t\t * spare time, but no more than our period.\n\t\t */\n\t\tdiff = iter->rt_runtime - iter->rt_time;\n\t\tif (diff > 0) {\n\t\t\tdiff = div_u64((u64)diff, weight);\n\t\t\tif (rt_rq->rt_runtime + diff > rt_period)\n\t\t\t\tdiff = rt_period - rt_rq->rt_runtime;\n\t\t\titer->rt_runtime -= diff;\n\t\t\trt_rq->rt_runtime += diff;\n\t\t\tif (rt_rq->rt_runtime == rt_period) {\n\t\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext:\n\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 856
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_feat",
          "args": [
            "RT_RUNTIME_SHARE"
          ],
          "line": 852
        },
        "resolved": true,
        "details": {
          "function_name": "sched_feat_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/debug.c",
          "lines": "99-122",
          "snippet": "static int sched_feat_set(char *cmp)\n{\n\tint i;\n\tint neg = 0;\n\n\tif (strncmp(cmp, \"NO_\", 3) == 0) {\n\t\tneg = 1;\n\t\tcmp += 3;\n\t}\n\n\ti = match_string(sched_feat_names, __SCHED_FEAT_NR, cmp);\n\tif (i < 0)\n\t\treturn i;\n\n\tif (neg) {\n\t\tsysctl_sched_features &= ~(1UL << i);\n\t\tsched_feat_disable(i);\n\t} else {\n\t\tsysctl_sched_features |= (1UL << i);\n\t\tsched_feat_enable(i);\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static const char * const sched_feat_names[] = {\n#include \"features.h\"\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic const char * const sched_feat_names[] = {\n#include \"features.h\"\n};\n\nstatic int sched_feat_set(char *cmp)\n{\n\tint i;\n\tint neg = 0;\n\n\tif (strncmp(cmp, \"NO_\", 3) == 0) {\n\t\tneg = 1;\n\t\tcmp += 3;\n\t}\n\n\ti = match_string(sched_feat_names, __SCHED_FEAT_NR, cmp);\n\tif (i < 0)\n\t\treturn i;\n\n\tif (neg) {\n\t\tsysctl_sched_features &= ~(1UL << i);\n\t\tsched_feat_disable(i);\n\t} else {\n\t\tsysctl_sched_features |= (1UL << i);\n\t\tsched_feat_enable(i);\n\t}\n\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void balance_runtime(struct rt_rq *rt_rq)\n{\n\tif (!sched_feat(RT_RUNTIME_SHARE))\n\t\treturn;\n\n\tif (rt_rq->rt_time > rt_rq->rt_runtime) {\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\tdo_balance_runtime(rt_rq);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t}\n}"
  },
  {
    "function_name": "__enable_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "826-848",
    "snippet": "static void __enable_runtime(struct rq *rq)\n{\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\t/*\n\t * Reset each runqueue's bandwidth settings\n\t */\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\trt_rq->rt_time = 0;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 846
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 841
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_bandwidth",
          "args": [
            "rt_rq"
          ],
          "line": 838
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_bandwidth_account",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "680-686",
          "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nbool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_rt_rq",
          "args": [
            "rt_rq",
            "iter",
            "rq"
          ],
          "line": 837
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!scheduler_running"
          ],
          "line": 831
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __enable_runtime(struct rq *rq)\n{\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\t/*\n\t * Reset each runqueue's bandwidth settings\n\t */\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\trt_rq->rt_time = 0;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\t}\n}"
  },
  {
    "function_name": "__disable_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "744-824",
    "snippet": "static void __disable_runtime(struct rq *rq)\n{\n\tstruct root_domain *rd = rq->rd;\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\t\ts64 want;\n\t\tint i;\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * Either we're all inf and nobody needs to borrow, or we're\n\t\t * already disabled and thus have nothing to do, or we have\n\t\t * exactly the right amount of runtime to take out.\n\t\t */\n\t\tif (rt_rq->rt_runtime == RUNTIME_INF ||\n\t\t\t\trt_rq->rt_runtime == rt_b->rt_runtime)\n\t\t\tgoto balanced;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\n\t\t/*\n\t\t * Calculate the difference between what we started out with\n\t\t * and what we current have, that's the amount of runtime\n\t\t * we lend and now have to reclaim.\n\t\t */\n\t\twant = rt_b->rt_runtime - rt_rq->rt_runtime;\n\n\t\t/*\n\t\t * Greedy reclaim, take back as much as we can.\n\t\t */\n\t\tfor_each_cpu(i, rd->span) {\n\t\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\t\ts64 diff;\n\n\t\t\t/*\n\t\t\t * Can't reclaim from ourselves or disabled runqueues.\n\t\t\t */\n\t\t\tif (iter == rt_rq || iter->rt_runtime == RUNTIME_INF)\n\t\t\t\tcontinue;\n\n\t\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t\tif (want > 0) {\n\t\t\t\tdiff = min_t(s64, iter->rt_runtime, want);\n\t\t\t\titer->rt_runtime -= diff;\n\t\t\t\twant -= diff;\n\t\t\t} else {\n\t\t\t\titer->rt_runtime -= want;\n\t\t\t\twant -= want;\n\t\t\t}\n\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\n\t\t\tif (!want)\n\t\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * We cannot be left wanting - that would mean some runtime\n\t\t * leaked out of the system.\n\t\t */\n\t\tBUG_ON(want);\nbalanced:\n\t\t/*\n\t\t * Disable all the borrow logic by pretending we have inf\n\t\t * runtime - in which case borrowing doesn't make sense.\n\t\t */\n\t\trt_rq->rt_runtime = RUNTIME_INF;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\n\t\t/* Make rt_rq available for pick_next_task() */\n\t\tsched_rt_rq_enqueue(rt_rq);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_rt_rq_enqueue",
          "args": [
            "rt_rq"
          ],
          "line": 822
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_rq_enqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "641-650",
          "snippet": "static inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tif (!rt_rq->rt_nr_running)\n\t\treturn;\n\n\tenqueue_top_rt_rq(rt_rq);\n\tresched_curr(rq);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tif (!rt_rq->rt_nr_running)\n\t\treturn;\n\n\tenqueue_top_rt_rq(rt_rq);\n\tresched_curr(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 819
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "want"
          ],
          "line": 810
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 805
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "min_t",
          "args": [
            "s64",
            "iter->rt_runtime",
            "want"
          ],
          "line": 792
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_rt_period_rt_rq",
          "args": [
            "rt_b",
            "i"
          ],
          "line": 781
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_period_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "667-671",
          "snippet": "static inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "i",
            "rd->span"
          ],
          "line": 780
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_rt_bandwidth",
          "args": [
            "rt_rq"
          ],
          "line": 754
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_bandwidth_account",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "680-686",
          "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nbool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_rt_rq",
          "args": [
            "rt_rq",
            "iter",
            "rq"
          ],
          "line": 753
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!scheduler_running"
          ],
          "line": 750
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void __disable_runtime(struct rq *rq)\n{\n\tstruct root_domain *rd = rq->rd;\n\trt_rq_iter_t iter;\n\tstruct rt_rq *rt_rq;\n\n\tif (unlikely(!scheduler_running))\n\t\treturn;\n\n\tfor_each_rt_rq(rt_rq, iter, rq) {\n\t\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\t\ts64 want;\n\t\tint i;\n\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * Either we're all inf and nobody needs to borrow, or we're\n\t\t * already disabled and thus have nothing to do, or we have\n\t\t * exactly the right amount of runtime to take out.\n\t\t */\n\t\tif (rt_rq->rt_runtime == RUNTIME_INF ||\n\t\t\t\trt_rq->rt_runtime == rt_b->rt_runtime)\n\t\t\tgoto balanced;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\n\t\t/*\n\t\t * Calculate the difference between what we started out with\n\t\t * and what we current have, that's the amount of runtime\n\t\t * we lend and now have to reclaim.\n\t\t */\n\t\twant = rt_b->rt_runtime - rt_rq->rt_runtime;\n\n\t\t/*\n\t\t * Greedy reclaim, take back as much as we can.\n\t\t */\n\t\tfor_each_cpu(i, rd->span) {\n\t\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\t\ts64 diff;\n\n\t\t\t/*\n\t\t\t * Can't reclaim from ourselves or disabled runqueues.\n\t\t\t */\n\t\t\tif (iter == rt_rq || iter->rt_runtime == RUNTIME_INF)\n\t\t\t\tcontinue;\n\n\t\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t\tif (want > 0) {\n\t\t\t\tdiff = min_t(s64, iter->rt_runtime, want);\n\t\t\t\titer->rt_runtime -= diff;\n\t\t\t\twant -= diff;\n\t\t\t} else {\n\t\t\t\titer->rt_runtime -= want;\n\t\t\t\twant -= want;\n\t\t\t}\n\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\n\t\t\tif (!want)\n\t\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t/*\n\t\t * We cannot be left wanting - that would mean some runtime\n\t\t * leaked out of the system.\n\t\t */\n\t\tBUG_ON(want);\nbalanced:\n\t\t/*\n\t\t * Disable all the borrow logic by pretending we have inf\n\t\t * runtime - in which case borrowing doesn't make sense.\n\t\t */\n\t\trt_rq->rt_runtime = RUNTIME_INF;\n\t\trt_rq->rt_throttled = 0;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\n\t\t/* Make rt_rq available for pick_next_task() */\n\t\tsched_rt_rq_enqueue(rt_rq);\n\t}\n}"
  },
  {
    "function_name": "do_balance_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "692-739",
    "snippet": "static void do_balance_runtime(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\tstruct root_domain *rd = rq_of_rt_rq(rt_rq)->rd;\n\tint i, weight;\n\tu64 rt_period;\n\n\tweight = cpumask_weight(rd->span);\n\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\trt_period = ktime_to_ns(rt_b->rt_period);\n\tfor_each_cpu(i, rd->span) {\n\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\ts64 diff;\n\n\t\tif (iter == rt_rq)\n\t\t\tcontinue;\n\n\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t/*\n\t\t * Either all rqs have inf runtime and there's nothing to steal\n\t\t * or __disable_runtime() below sets a specific rq to inf to\n\t\t * indicate its been disabled and disallow stealing.\n\t\t */\n\t\tif (iter->rt_runtime == RUNTIME_INF)\n\t\t\tgoto next;\n\n\t\t/*\n\t\t * From runqueues with spare time, take 1/n part of their\n\t\t * spare time, but no more than our period.\n\t\t */\n\t\tdiff = iter->rt_runtime - iter->rt_time;\n\t\tif (diff > 0) {\n\t\t\tdiff = div_u64((u64)diff, weight);\n\t\t\tif (rt_rq->rt_runtime + diff > rt_period)\n\t\t\t\tdiff = rt_period - rt_rq->rt_runtime;\n\t\t\titer->rt_runtime -= diff;\n\t\t\trt_rq->rt_runtime += diff;\n\t\t\tif (rt_rq->rt_runtime == rt_period) {\n\t\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext:\n\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 738
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "div_u64",
          "args": [
            "(u64)diff",
            "weight"
          ],
          "line": 725
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&iter->rt_runtime_lock"
          ],
          "line": 710
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_period_rt_rq",
          "args": [
            "rt_b",
            "i"
          ],
          "line": 704
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_period_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "667-671",
          "snippet": "static inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_cpu",
          "args": [
            "i",
            "rd->span"
          ],
          "line": 703
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "rt_b->rt_period"
          ],
          "line": 702
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "rd->span"
          ],
          "line": 699
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 695
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_bandwidth",
          "args": [
            "rt_rq"
          ],
          "line": 694
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_bandwidth_account",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "680-686",
          "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nbool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void do_balance_runtime(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\tstruct root_domain *rd = rq_of_rt_rq(rt_rq)->rd;\n\tint i, weight;\n\tu64 rt_period;\n\n\tweight = cpumask_weight(rd->span);\n\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\trt_period = ktime_to_ns(rt_b->rt_period);\n\tfor_each_cpu(i, rd->span) {\n\t\tstruct rt_rq *iter = sched_rt_period_rt_rq(rt_b, i);\n\t\ts64 diff;\n\n\t\tif (iter == rt_rq)\n\t\t\tcontinue;\n\n\t\traw_spin_lock(&iter->rt_runtime_lock);\n\t\t/*\n\t\t * Either all rqs have inf runtime and there's nothing to steal\n\t\t * or __disable_runtime() below sets a specific rq to inf to\n\t\t * indicate its been disabled and disallow stealing.\n\t\t */\n\t\tif (iter->rt_runtime == RUNTIME_INF)\n\t\t\tgoto next;\n\n\t\t/*\n\t\t * From runqueues with spare time, take 1/n part of their\n\t\t * spare time, but no more than our period.\n\t\t */\n\t\tdiff = iter->rt_runtime - iter->rt_time;\n\t\tif (diff > 0) {\n\t\t\tdiff = div_u64((u64)diff, weight);\n\t\t\tif (rt_rq->rt_runtime + diff > rt_period)\n\t\t\t\tdiff = rt_period - rt_rq->rt_runtime;\n\t\t\titer->rt_runtime -= diff;\n\t\t\trt_rq->rt_runtime += diff;\n\t\t\tif (rt_rq->rt_runtime == rt_period) {\n\t\t\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext:\n\t\traw_spin_unlock(&iter->rt_runtime_lock);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}"
  },
  {
    "function_name": "sched_rt_bandwidth_account",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "680-686",
    "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "hrtimer_active",
          "args": [
            "&rt_b->rt_period_timer"
          ],
          "line": 684
        },
        "resolved": true,
        "details": {
          "function_name": "hrtimer_active",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/hrtimer.c",
          "lines": "1604-1621",
          "snippet": "bool hrtimer_active(const struct hrtimer *timer)\n{\n\tstruct hrtimer_clock_base *base;\n\tunsigned int seq;\n\n\tdo {\n\t\tbase = READ_ONCE(timer->base);\n\t\tseq = raw_read_seqcount_begin(&base->seq);\n\n\t\tif (timer->state != HRTIMER_STATE_INACTIVE ||\n\t\t    base->running == timer)\n\t\t\treturn true;\n\n\t} while (read_seqcount_retry(&base->seq, seq) ||\n\t\t base != READ_ONCE(timer->base));\n\n\treturn false;\n}",
          "includes": [
            "#include \"tick-internal.h\"",
            "#include <trace/events/timer.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/freezer.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/debugobjects.h>",
            "#include <linux/err.h>",
            "#include <linux/tick.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/notifier.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tick-internal.h\"\n#include <trace/events/timer.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/freezer.h>\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/debugobjects.h>\n#include <linux/err.h>\n#include <linux/tick.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/notifier.h>\n#include <linux/hrtimer.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n\nbool hrtimer_active(const struct hrtimer *timer)\n{\n\tstruct hrtimer_clock_base *base;\n\tunsigned int seq;\n\n\tdo {\n\t\tbase = READ_ONCE(timer->base);\n\t\tseq = raw_read_seqcount_begin(&base->seq);\n\n\t\tif (timer->state != HRTIMER_STATE_INACTIVE ||\n\t\t    base->running == timer)\n\t\t\treturn true;\n\n\t} while (read_seqcount_retry(&base->seq, seq) ||\n\t\t base != READ_ONCE(timer->base));\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_rt_bandwidth",
          "args": [
            "rt_rq"
          ],
          "line": 682
        },
        "resolved": true,
        "details": {
          "function_name": "sched_rt_bandwidth_account",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "680-686",
          "snippet": "bool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}",
          "note": "cyclic_reference_detected"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nbool sched_rt_bandwidth_account(struct rt_rq *rt_rq)\n{\n\tstruct rt_bandwidth *rt_b = sched_rt_bandwidth(rt_rq);\n\n\treturn (hrtimer_active(&rt_b->rt_period_timer) ||\n\t\trt_rq->rt_time < rt_b->rt_runtime);\n}"
  },
  {
    "function_name": "sched_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "673-676",
    "snippet": "static inline struct rt_bandwidth *sched_rt_bandwidth(struct rt_rq *rt_rq)\n{\n\treturn &def_rt_bandwidth;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct rt_bandwidth def_rt_bandwidth;",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_bandwidth *sched_rt_bandwidth(struct rt_rq *rt_rq)\n{\n\treturn &def_rt_bandwidth;\n}"
  },
  {
    "function_name": "sched_rt_period_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "667-671",
    "snippet": "static inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 670
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn &cpu_rq(cpu)->rt;\n}"
  },
  {
    "function_name": "sched_rt_period_mask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "662-665",
    "snippet": "static inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn cpu_online_mask;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn cpu_online_mask;\n}"
  },
  {
    "function_name": "rt_rq_throttled",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "657-660",
    "snippet": "static inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled;\n}"
  },
  {
    "function_name": "sched_rt_rq_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "652-655",
    "snippet": "static inline void sched_rt_rq_dequeue(struct rt_rq *rt_rq)\n{\n\tdequeue_top_rt_rq(rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "dequeue_top_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 654
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1054-1069",
          "snippet": "static void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void sched_rt_rq_dequeue(struct rt_rq *rt_rq)\n{\n\tdequeue_top_rt_rq(rt_rq);\n}"
  },
  {
    "function_name": "sched_rt_rq_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "641-650",
    "snippet": "static inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tif (!rt_rq->rt_nr_running)\n\t\treturn;\n\n\tenqueue_top_rt_rq(rt_rq);\n\tresched_curr(rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 649
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "enqueue_top_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 648
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1071-1091",
          "snippet": "static void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 643
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tif (!rt_rq->rt_nr_running)\n\t\treturn;\n\n\tenqueue_top_rt_rq(rt_rq);\n\tresched_curr(rq);\n}"
  },
  {
    "function_name": "group_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "636-639",
    "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
  },
  {
    "function_name": "sched_rt_period",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "623-626",
    "snippet": "static inline u64 sched_rt_period(struct rt_rq *rt_rq)\n{\n\treturn ktime_to_ns(def_rt_bandwidth.rt_period);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct rt_bandwidth def_rt_bandwidth;",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "def_rt_bandwidth.rt_period"
          ],
          "line": 625
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline u64 sched_rt_period(struct rt_rq *rt_rq)\n{\n\treturn ktime_to_ns(def_rt_bandwidth.rt_period);\n}"
  },
  {
    "function_name": "sched_rt_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "618-621",
    "snippet": "static inline u64 sched_rt_runtime(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_runtime;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline u64 sched_rt_runtime(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_runtime;\n}"
  },
  {
    "function_name": "sched_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "611-614",
    "snippet": "static inline struct rt_bandwidth *sched_rt_bandwidth(struct rt_rq *rt_rq)\n{\n\treturn &rt_rq->tg->rt_bandwidth;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_bandwidth *sched_rt_bandwidth(struct rt_rq *rt_rq)\n{\n\treturn &rt_rq->tg->rt_bandwidth;\n}"
  },
  {
    "function_name": "sched_rt_period_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "605-609",
    "snippet": "static inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn container_of(rt_b, struct task_group, rt_bandwidth)->rt_rq[cpu];\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rt_b",
            "structtask_group",
            "rt_bandwidth"
          ],
          "line": 608
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nstruct rt_rq *sched_rt_period_rt_rq(struct rt_bandwidth *rt_b, int cpu)\n{\n\treturn container_of(rt_b, struct task_group, rt_bandwidth)->rt_rq[cpu];\n}"
  },
  {
    "function_name": "sched_rt_period_mask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "599-602",
    "snippet": "static inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn cpu_online_mask;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn cpu_online_mask;\n}"
  },
  {
    "function_name": "sched_rt_period_mask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "594-597",
    "snippet": "static inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn this_rq()->rd->span;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_rq",
          "args": [],
          "line": 596
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline const struct cpumask *sched_rt_period_mask(void)\n{\n\treturn this_rq()->rd->span;\n}"
  },
  {
    "function_name": "rt_se_boosted",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "581-591",
    "snippet": "static int rt_se_boosted(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\tstruct task_struct *p;\n\n\tif (rt_rq)\n\t\treturn !!rt_rq->rt_nr_boosted;\n\n\tp = rt_task_of(rt_se);\n\treturn p->prio != p->normal_prio;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 589
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "group_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 583
        },
        "resolved": true,
        "details": {
          "function_name": "group_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "636-639",
          "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn NULL;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic int rt_se_boosted(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\tstruct task_struct *p;\n\n\tif (rt_rq)\n\t\treturn !!rt_rq->rt_nr_boosted;\n\n\tp = rt_task_of(rt_se);\n\treturn p->prio != p->normal_prio;\n}"
  },
  {
    "function_name": "rt_rq_throttled",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "576-579",
    "snippet": "static inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled && !rt_rq->rt_nr_boosted;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline int rt_rq_throttled(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rt_throttled && !rt_rq->rt_nr_boosted;\n}"
  },
  {
    "function_name": "sched_rt_rq_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "560-574",
    "snippet": "static void sched_rt_rq_dequeue(struct rt_rq *rt_rq)\n{\n\tstruct sched_rt_entity *rt_se;\n\tint cpu = cpu_of(rq_of_rt_rq(rt_rq));\n\n\trt_se = rt_rq->tg->rt_se[cpu];\n\n\tif (!rt_se) {\n\t\tdequeue_top_rt_rq(rt_rq);\n\t\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\t\tcpufreq_update_util(rq_of_rt_rq(rt_rq), 0);\n\t}\n\telse if (on_rt_rq(rt_se))\n\t\tdequeue_rt_entity(rt_se, 0);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "dequeue_rt_entity",
          "args": [
            "rt_se",
            "0"
          ],
          "line": 573
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1478-1493",
          "snippet": "static void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\t\tif (rt_rq && rt_rq->rt_nr_running)\n\t\t\t__enqueue_rt_entity(rt_se, flags);\n\t}\n\tenqueue_top_rt_rq(&rq->rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void dequeue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_dequeue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\n\tfor_each_sched_rt_entity(rt_se) {\n\t\tstruct rt_rq *rt_rq = group_rt_rq(rt_se);\n\n\t\tif (rt_rq && rt_rq->rt_nr_running)\n\t\t\t__enqueue_rt_entity(rt_se, flags);\n\t}\n\tenqueue_top_rt_rq(&rq->rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 572
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpufreq_update_util",
          "args": [
            "rq_of_rt_rq(rt_rq)",
            "0"
          ],
          "line": 570
        },
        "resolved": true,
        "details": {
          "function_name": "cpufreq_update_util",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2841-2841",
          "snippet": "static inline void cpufreq_update_util(struct rq *rq, unsigned int flags) {}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void activate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);",
            "extern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void activate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void deactivate_task(struct rq *rq, struct task_struct *p, int flags);\nextern void check_preempt_curr(struct rq *rq, struct task_struct *p, int flags);\n\nstatic inline void cpufreq_update_util(struct rq *rq, unsigned int flags) {}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 570
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "dequeue_top_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 568
        },
        "resolved": true,
        "details": {
          "function_name": "dequeue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1054-1069",
          "snippet": "static void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\ndequeue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (!rt_rq->rt_queued)\n\t\treturn;\n\n\tBUG_ON(!rq->nr_running);\n\n\tsub_nr_running(rq, rt_rq->rt_nr_running);\n\trt_rq->rt_queued = 0;\n\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_of",
          "args": [
            "rq_of_rt_rq(rt_rq)"
          ],
          "line": 563
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1137-1144",
          "snippet": "static inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void resched_cpu(int cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void resched_cpu(int cpu);\n\nstatic inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void sched_rt_rq_dequeue(struct rt_rq *rt_rq)\n{\n\tstruct sched_rt_entity *rt_se;\n\tint cpu = cpu_of(rq_of_rt_rq(rt_rq));\n\n\trt_se = rt_rq->tg->rt_se[cpu];\n\n\tif (!rt_se) {\n\t\tdequeue_top_rt_rq(rt_rq);\n\t\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\t\tcpufreq_update_util(rq_of_rt_rq(rt_rq), 0);\n\t}\n\telse if (on_rt_rq(rt_se))\n\t\tdequeue_rt_entity(rt_se, 0);\n}"
  },
  {
    "function_name": "sched_rt_rq_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "539-558",
    "snippet": "static void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct task_struct *curr = rq_of_rt_rq(rt_rq)->curr;\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\tstruct sched_rt_entity *rt_se;\n\n\tint cpu = cpu_of(rq);\n\n\trt_se = rt_rq->tg->rt_se[cpu];\n\n\tif (rt_rq->rt_nr_running) {\n\t\tif (!rt_se)\n\t\t\tenqueue_top_rt_rq(rt_rq);\n\t\telse if (!on_rt_rq(rt_se))\n\t\t\tenqueue_rt_entity(rt_se, 0);\n\n\t\tif (rt_rq->highest_prio.curr < curr->prio)\n\t\t\tresched_curr(rq);\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "resched_curr",
          "args": [
            "rq"
          ],
          "line": 556
        },
        "resolved": true,
        "details": {
          "function_name": "resched_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "976-998",
          "snippet": "void resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid resched_curr(struct rq *rq)\n{\n\tstruct task_struct *curr = rq->curr;\n\tint cpu;\n\n\tlockdep_assert_rq_held(rq);\n\n\tif (test_tsk_need_resched(curr))\n\t\treturn;\n\n\tcpu = cpu_of(rq);\n\n\tif (cpu == smp_processor_id()) {\n\t\tset_tsk_need_resched(curr);\n\t\tset_preempt_need_resched();\n\t\treturn;\n\t}\n\n\tif (set_nr_and_not_polling(curr))\n\t\tsmp_send_reschedule(cpu);\n\telse\n\t\ttrace_sched_wake_idle_without_ipi(cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "enqueue_rt_entity",
          "args": [
            "rt_se",
            "0"
          ],
          "line": 553
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_rt_entity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1466-1476",
          "snippet": "static void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_enqueue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\tfor_each_sched_rt_entity(rt_se)\n\t\t__enqueue_rt_entity(rt_se, flags);\n\tenqueue_top_rt_rq(&rq->rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void enqueue_rt_entity(struct sched_rt_entity *rt_se, unsigned int flags)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\tupdate_stats_enqueue_rt(rt_rq_of_se(rt_se), rt_se, flags);\n\n\tdequeue_rt_stack(rt_se, flags);\n\tfor_each_sched_rt_entity(rt_se)\n\t\t__enqueue_rt_entity(rt_se, flags);\n\tenqueue_top_rt_rq(&rq->rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "on_rt_rq",
          "args": [
            "rt_se"
          ],
          "line": 552
        },
        "resolved": true,
        "details": {
          "function_name": "on_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "449-452",
          "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
        }
      },
      {
        "call_info": {
          "callee": "enqueue_top_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 551
        },
        "resolved": true,
        "details": {
          "function_name": "enqueue_top_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "1071-1091",
          "snippet": "static void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void\nenqueue_top_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\n\tBUG_ON(&rq->rt != rt_rq);\n\n\tif (rt_rq->rt_queued)\n\t\treturn;\n\n\tif (rt_rq_throttled(rt_rq))\n\t\treturn;\n\n\tif (rt_rq->rt_nr_running) {\n\t\tadd_nr_running(rq, rt_rq->rt_nr_running);\n\t\trt_rq->rt_queued = 1;\n\t}\n\n\t/* Kick cpufreq (see the comment in kernel/sched/sched.h). */\n\tcpufreq_update_util(rq, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_of",
          "args": [
            "rq"
          ],
          "line": 545
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1137-1144",
          "snippet": "static inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void resched_cpu(int cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void resched_cpu(int cpu);\n\nstatic inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 542
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void sched_rt_rq_enqueue(struct rt_rq *rt_rq)\n{\n\tstruct task_struct *curr = rq_of_rt_rq(rt_rq)->curr;\n\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\tstruct sched_rt_entity *rt_se;\n\n\tint cpu = cpu_of(rq);\n\n\trt_se = rt_rq->tg->rt_se[cpu];\n\n\tif (rt_rq->rt_nr_running) {\n\t\tif (!rt_se)\n\t\t\tenqueue_top_rt_rq(rt_rq);\n\t\telse if (!on_rt_rq(rt_se))\n\t\t\tenqueue_rt_entity(rt_se, 0);\n\n\t\tif (rt_rq->highest_prio.curr < curr->prio)\n\t\t\tresched_curr(rq);\n\t}\n}"
  },
  {
    "function_name": "group_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "531-534",
    "snippet": "static inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->my_q;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *group_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->my_q;\n}"
  },
  {
    "function_name": "next_task_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "510-521",
    "snippet": "static inline struct task_group *next_task_group(struct task_group *tg)\n{\n\tdo {\n\t\ttg = list_entry_rcu(tg->list.next,\n\t\t\ttypeof(struct task_group), list);\n\t} while (&tg->list != &task_groups && task_group_is_autogroup(tg));\n\n\tif (&tg->list == &task_groups)\n\t\ttg = NULL;\n\n\treturn tg;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "task_group_is_autogroup",
          "args": [
            "tg"
          ],
          "line": 515
        },
        "resolved": true,
        "details": {
          "function_name": "task_group_is_autogroup",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/autogroup.h",
          "lines": "44-47",
          "snippet": "static inline bool task_group_is_autogroup(struct task_group *tg)\n{\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline bool task_group_is_autogroup(struct task_group *tg)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_entry_rcu",
          "args": [
            "tg->list.next",
            "typeof(struct task_group)",
            "list"
          ],
          "line": 513
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "typeof",
          "args": [
            "structtask_group"
          ],
          "line": 514
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline struct task_group *next_task_group(struct task_group *tg)\n{\n\tdo {\n\t\ttg = list_entry_rcu(tg->list.next,\n\t\t\ttypeof(struct task_group), list);\n\t} while (&tg->list != &task_groups && task_group_is_autogroup(tg));\n\n\tif (&tg->list == &task_groups)\n\t\ttg = NULL;\n\n\treturn tg;\n}"
  },
  {
    "function_name": "sched_rt_period",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "503-506",
    "snippet": "static inline u64 sched_rt_period(struct rt_rq *rt_rq)\n{\n\treturn ktime_to_ns(rt_rq->tg->rt_bandwidth.rt_period);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "rt_rq->tg->rt_bandwidth.rt_period"
          ],
          "line": 505
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline u64 sched_rt_period(struct rt_rq *rt_rq)\n{\n\treturn ktime_to_ns(rt_rq->tg->rt_bandwidth.rt_period);\n}"
  },
  {
    "function_name": "sched_rt_runtime",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "495-501",
    "snippet": "static inline u64 sched_rt_runtime(struct rt_rq *rt_rq)\n{\n\tif (!rt_rq->tg)\n\t\treturn RUNTIME_INF;\n\n\treturn rt_rq->rt_runtime;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline u64 sched_rt_runtime(struct rt_rq *rt_rq)\n{\n\tif (!rt_rq->tg)\n\t\treturn RUNTIME_INF;\n\n\treturn rt_rq->rt_runtime;\n}"
  },
  {
    "function_name": "rt_task_fits_capacity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "487-490",
    "snippet": "static inline bool rt_task_fits_capacity(struct task_struct *p, int cpu)\n{\n\treturn true;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool rt_task_fits_capacity(struct task_struct *p, int cpu)\n{\n\treturn true;\n}"
  },
  {
    "function_name": "rt_task_fits_capacity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "469-485",
    "snippet": "static inline bool rt_task_fits_capacity(struct task_struct *p, int cpu)\n{\n\tunsigned int min_cap;\n\tunsigned int max_cap;\n\tunsigned int cpu_cap;\n\n\t/* Only heterogeneous systems can benefit from this check */\n\tif (!static_branch_unlikely(&sched_asym_cpucapacity))\n\t\treturn true;\n\n\tmin_cap = uclamp_eff_value(p, UCLAMP_MIN);\n\tmax_cap = uclamp_eff_value(p, UCLAMP_MAX);\n\n\tcpu_cap = capacity_orig_of(cpu);\n\n\treturn cpu_cap >= min(min_cap, max_cap);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "min",
          "args": [
            "min_cap",
            "max_cap"
          ],
          "line": 484
        },
        "resolved": true,
        "details": {
          "function_name": "wrap_min",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "249-252",
          "snippet": "static inline u64 wrap_min(u64 x, u64 y)\n{\n\treturn (s64)(x - y) < 0 ? x : y;\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic inline u64 wrap_min(u64 x, u64 y)\n{\n\treturn (s64)(x - y) < 0 ? x : y;\n}"
        }
      },
      {
        "call_info": {
          "callee": "capacity_orig_of",
          "args": [
            "cpu"
          ],
          "line": 482
        },
        "resolved": true,
        "details": {
          "function_name": "capacity_orig_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2935-2938",
          "snippet": "static inline unsigned long capacity_orig_of(int cpu)\n{\n\treturn cpu_rq(cpu)->cpu_capacity_orig;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern void resched_cpu(int cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern void resched_cpu(int cpu);\n\nstatic inline unsigned long capacity_orig_of(int cpu)\n{\n\treturn cpu_rq(cpu)->cpu_capacity_orig;\n}"
        }
      },
      {
        "call_info": {
          "callee": "uclamp_eff_value",
          "args": [
            "p",
            "UCLAMP_MAX"
          ],
          "line": 480
        },
        "resolved": true,
        "details": {
          "function_name": "uclamp_eff_value",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "1482-1493",
          "snippet": "unsigned long uclamp_eff_value(struct task_struct *p, enum uclamp_id clamp_id)\n{\n\tstruct uclamp_se uc_eff;\n\n\t/* Task currently refcounted: use back-annotated (effective) value */\n\tif (p->uclamp[clamp_id].active)\n\t\treturn (unsigned long)p->uclamp[clamp_id].value;\n\n\tuc_eff = uclamp_eff_get(p, clamp_id);\n\n\treturn (unsigned long)uc_eff.value;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nunsigned long uclamp_eff_value(struct task_struct *p, enum uclamp_id clamp_id)\n{\n\tstruct uclamp_se uc_eff;\n\n\t/* Task currently refcounted: use back-annotated (effective) value */\n\tif (p->uclamp[clamp_id].active)\n\t\treturn (unsigned long)p->uclamp[clamp_id].value;\n\n\tuc_eff = uclamp_eff_get(p, clamp_id);\n\n\treturn (unsigned long)uc_eff.value;\n}"
        }
      },
      {
        "call_info": {
          "callee": "static_branch_unlikely",
          "args": [
            "&sched_asym_cpucapacity"
          ],
          "line": 476
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool rt_task_fits_capacity(struct task_struct *p, int cpu)\n{\n\tunsigned int min_cap;\n\tunsigned int max_cap;\n\tunsigned int cpu_cap;\n\n\t/* Only heterogeneous systems can benefit from this check */\n\tif (!static_branch_unlikely(&sched_asym_cpucapacity))\n\t\treturn true;\n\n\tmin_cap = uclamp_eff_value(p, UCLAMP_MIN);\n\tmax_cap = uclamp_eff_value(p, UCLAMP_MAX);\n\n\tcpu_cap = capacity_orig_of(cpu);\n\n\treturn cpu_cap >= min(min_cap, max_cap);\n}"
  },
  {
    "function_name": "on_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "449-452",
    "snippet": "static inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int on_rt_rq(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->on_rq;\n}"
  },
  {
    "function_name": "rt_queue_push_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "441-443",
    "snippet": "static inline void rt_queue_push_tasks(struct rq *rq)\n{\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_push_tasks(struct rq *rq)\n{\n}"
  },
  {
    "function_name": "pull_rt_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "437-439",
    "snippet": "static inline void pull_rt_task(struct rq *this_rq)\n{\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void pull_rt_task(struct rq *this_rq)\n{\n}"
  },
  {
    "function_name": "need_pull_rt_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "432-435",
    "snippet": "static inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "dec_rt_migration",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "427-430",
    "snippet": "static inline\nvoid dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}"
  },
  {
    "function_name": "inc_rt_migration",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "422-425",
    "snippet": "static inline\nvoid inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline\nvoid inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n}"
  },
  {
    "function_name": "dequeue_pushable_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "418-420",
    "snippet": "static inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}"
  },
  {
    "function_name": "enqueue_pushable_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "414-416",
    "snippet": "static inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n}"
  },
  {
    "function_name": "dequeue_pushable_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "398-410",
    "snippet": "static void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n\tplist_del(&p->pushable_tasks, &rq->rt.pushable_tasks);\n\n\t/* Update the new highest prio pushable task */\n\tif (has_pushable_tasks(rq)) {\n\t\tp = plist_first_entry(&rq->rt.pushable_tasks,\n\t\t\t\t      struct task_struct, pushable_tasks);\n\t\trq->rt.highest_prio.next = p->prio;\n\t} else {\n\t\trq->rt.highest_prio.next = MAX_RT_PRIO-1;\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "plist_first_entry",
          "args": [
            "&rq->rt.pushable_tasks",
            "structtask_struct",
            "pushable_tasks"
          ],
          "line": 404
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "has_pushable_tasks",
          "args": [
            "rq"
          ],
          "line": 403
        },
        "resolved": true,
        "details": {
          "function_name": "has_pushable_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "363-366",
          "snippet": "static inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}"
        }
      },
      {
        "call_info": {
          "callee": "plist_del",
          "args": [
            "&p->pushable_tasks",
            "&rq->rt.pushable_tasks"
          ],
          "line": 400
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void dequeue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n\tplist_del(&p->pushable_tasks, &rq->rt.pushable_tasks);\n\n\t/* Update the new highest prio pushable task */\n\tif (has_pushable_tasks(rq)) {\n\t\tp = plist_first_entry(&rq->rt.pushable_tasks,\n\t\t\t\t      struct task_struct, pushable_tasks);\n\t\trq->rt.highest_prio.next = p->prio;\n\t} else {\n\t\trq->rt.highest_prio.next = MAX_RT_PRIO-1;\n\t}\n}"
  },
  {
    "function_name": "enqueue_pushable_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "387-396",
    "snippet": "static void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n\tplist_del(&p->pushable_tasks, &rq->rt.pushable_tasks);\n\tplist_node_init(&p->pushable_tasks, p->prio);\n\tplist_add(&p->pushable_tasks, &rq->rt.pushable_tasks);\n\n\t/* Update the highest prio pushable task */\n\tif (p->prio < rq->rt.highest_prio.next)\n\t\trq->rt.highest_prio.next = p->prio;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "plist_add",
          "args": [
            "&p->pushable_tasks",
            "&rq->rt.pushable_tasks"
          ],
          "line": 391
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "plist_node_init",
          "args": [
            "&p->pushable_tasks",
            "p->prio"
          ],
          "line": 390
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "plist_del",
          "args": [
            "&p->pushable_tasks",
            "&rq->rt.pushable_tasks"
          ],
          "line": 389
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void enqueue_pushable_task(struct rq *rq, struct task_struct *p)\n{\n\tplist_del(&p->pushable_tasks, &rq->rt.pushable_tasks);\n\tplist_node_init(&p->pushable_tasks, p->prio);\n\tplist_add(&p->pushable_tasks, &rq->rt.pushable_tasks);\n\n\t/* Update the highest prio pushable task */\n\tif (p->prio < rq->rt.highest_prio.next)\n\t\trq->rt.highest_prio.next = p->prio;\n}"
  },
  {
    "function_name": "rt_queue_pull_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "382-385",
    "snippet": "static inline void rt_queue_pull_task(struct rq *rq)\n{\n\tqueue_balance_callback(rq, &per_cpu(rt_pull_head, rq->cpu), pull_rt_task);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "queue_balance_callback",
          "args": [
            "rq",
            "&per_cpu(rt_pull_head, rq->cpu)",
            "pull_rt_task"
          ],
          "line": 384
        },
        "resolved": true,
        "details": {
          "function_name": "queue_balance_callback",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1701-1714",
          "snippet": "static inline void\nqueue_balance_callback(struct rq *rq,\n\t\t       struct callback_head *head,\n\t\t       void (*func)(struct rq *rq))\n{\n\tlockdep_assert_rq_held(rq);\n\n\tif (unlikely(head->next || rq->balance_callback == &balance_push_callback))\n\t\treturn;\n\n\thead->func = (void (*)(struct callback_head *))func;\n\thead->next = rq->balance_callback;\n\trq->balance_callback = head;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct callback_head balance_push_callback;",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct callback_head balance_push_callback;\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void\nqueue_balance_callback(struct rq *rq,\n\t\t       struct callback_head *head,\n\t\t       void (*func)(struct rq *rq))\n{\n\tlockdep_assert_rq_held(rq);\n\n\tif (unlikely(head->next || rq->balance_callback == &balance_push_callback))\n\t\treturn;\n\n\thead->func = (void (*)(struct callback_head *))func;\n\thead->next = rq->balance_callback;\n\trq->balance_callback = head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "rt_pull_head",
            "rq->cpu"
          ],
          "line": 384
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_set_per_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "588-603",
          "snippet": "void kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_pull_task(struct rq *rq)\n{\n\tqueue_balance_callback(rq, &per_cpu(rt_pull_head, rq->cpu), pull_rt_task);\n}"
  },
  {
    "function_name": "rt_queue_push_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "374-380",
    "snippet": "static inline void rt_queue_push_tasks(struct rq *rq)\n{\n\tif (!has_pushable_tasks(rq))\n\t\treturn;\n\n\tqueue_balance_callback(rq, &per_cpu(rt_push_head, rq->cpu), push_rt_tasks);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "queue_balance_callback",
          "args": [
            "rq",
            "&per_cpu(rt_push_head, rq->cpu)",
            "push_rt_tasks"
          ],
          "line": 379
        },
        "resolved": true,
        "details": {
          "function_name": "queue_balance_callback",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1701-1714",
          "snippet": "static inline void\nqueue_balance_callback(struct rq *rq,\n\t\t       struct callback_head *head,\n\t\t       void (*func)(struct rq *rq))\n{\n\tlockdep_assert_rq_held(rq);\n\n\tif (unlikely(head->next || rq->balance_callback == &balance_push_callback))\n\t\treturn;\n\n\thead->func = (void (*)(struct callback_head *))func;\n\thead->next = rq->balance_callback;\n\trq->balance_callback = head;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct callback_head balance_push_callback;",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct callback_head balance_push_callback;\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void\nqueue_balance_callback(struct rq *rq,\n\t\t       struct callback_head *head,\n\t\t       void (*func)(struct rq *rq))\n{\n\tlockdep_assert_rq_held(rq);\n\n\tif (unlikely(head->next || rq->balance_callback == &balance_push_callback))\n\t\treturn;\n\n\thead->func = (void (*)(struct callback_head *))func;\n\thead->next = rq->balance_callback;\n\trq->balance_callback = head;\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "rt_push_head",
            "rq->cpu"
          ],
          "line": 379
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_set_per_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "588-603",
          "snippet": "void kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "has_pushable_tasks",
          "args": [
            "rq"
          ],
          "line": 376
        },
        "resolved": true,
        "details": {
          "function_name": "has_pushable_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "363-366",
          "snippet": "static inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_queue_push_tasks(struct rq *rq)\n{\n\tif (!has_pushable_tasks(rq))\n\t\treturn;\n\n\tqueue_balance_callback(rq, &per_cpu(rt_push_head, rq->cpu), push_rt_tasks);\n}"
  },
  {
    "function_name": "has_pushable_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "363-366",
    "snippet": "static inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "plist_head_empty",
          "args": [
            "&rq->rt.pushable_tasks"
          ],
          "line": 365
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline int has_pushable_tasks(struct rq *rq)\n{\n\treturn !plist_head_empty(&rq->rt.pushable_tasks);\n}"
  },
  {
    "function_name": "dec_rt_migration",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "346-361",
    "snippet": "static void dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstruct task_struct *p;\n\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn;\n\n\tp = rt_task_of(rt_se);\n\trt_rq = &rq_of_rt_rq(rt_rq)->rt;\n\n\trt_rq->rt_nr_total--;\n\tif (p->nr_cpus_allowed > 1)\n\t\trt_rq->rt_nr_migratory--;\n\n\tupdate_rt_migration(rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "update_rt_migration",
          "args": [
            "rt_rq"
          ],
          "line": 360
        },
        "resolved": true,
        "details": {
          "function_name": "update_rt_migration",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "316-327",
          "snippet": "static void update_rt_migration(struct rt_rq *rt_rq)\n{\n\tif (rt_rq->rt_nr_migratory && rt_rq->rt_nr_total > 1) {\n\t\tif (!rt_rq->overloaded) {\n\t\t\trt_set_overload(rq_of_rt_rq(rt_rq));\n\t\t\trt_rq->overloaded = 1;\n\t\t}\n\t} else if (rt_rq->overloaded) {\n\t\trt_clear_overload(rq_of_rt_rq(rt_rq));\n\t\trt_rq->overloaded = 0;\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void update_rt_migration(struct rt_rq *rt_rq)\n{\n\tif (rt_rq->rt_nr_migratory && rt_rq->rt_nr_total > 1) {\n\t\tif (!rt_rq->overloaded) {\n\t\t\trt_set_overload(rq_of_rt_rq(rt_rq));\n\t\t\trt_rq->overloaded = 1;\n\t\t}\n\t} else if (rt_rq->overloaded) {\n\t\trt_clear_overload(rq_of_rt_rq(rt_rq));\n\t\trt_rq->overloaded = 0;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 354
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 353
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 350
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void dec_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstruct task_struct *p;\n\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn;\n\n\tp = rt_task_of(rt_se);\n\trt_rq = &rq_of_rt_rq(rt_rq)->rt;\n\n\trt_rq->rt_nr_total--;\n\tif (p->nr_cpus_allowed > 1)\n\t\trt_rq->rt_nr_migratory--;\n\n\tupdate_rt_migration(rt_rq);\n}"
  },
  {
    "function_name": "inc_rt_migration",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "329-344",
    "snippet": "static void inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstruct task_struct *p;\n\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn;\n\n\tp = rt_task_of(rt_se);\n\trt_rq = &rq_of_rt_rq(rt_rq)->rt;\n\n\trt_rq->rt_nr_total++;\n\tif (p->nr_cpus_allowed > 1)\n\t\trt_rq->rt_nr_migratory++;\n\n\tupdate_rt_migration(rt_rq);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "update_rt_migration",
          "args": [
            "rt_rq"
          ],
          "line": 343
        },
        "resolved": true,
        "details": {
          "function_name": "update_rt_migration",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "316-327",
          "snippet": "static void update_rt_migration(struct rt_rq *rt_rq)\n{\n\tif (rt_rq->rt_nr_migratory && rt_rq->rt_nr_total > 1) {\n\t\tif (!rt_rq->overloaded) {\n\t\t\trt_set_overload(rq_of_rt_rq(rt_rq));\n\t\t\trt_rq->overloaded = 1;\n\t\t}\n\t} else if (rt_rq->overloaded) {\n\t\trt_clear_overload(rq_of_rt_rq(rt_rq));\n\t\trt_rq->overloaded = 0;\n\t}\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void update_rt_migration(struct rt_rq *rt_rq)\n{\n\tif (rt_rq->rt_nr_migratory && rt_rq->rt_nr_total > 1) {\n\t\tif (!rt_rq->overloaded) {\n\t\t\trt_set_overload(rq_of_rt_rq(rt_rq));\n\t\t\trt_rq->overloaded = 1;\n\t\t}\n\t} else if (rt_rq->overloaded) {\n\t\trt_clear_overload(rq_of_rt_rq(rt_rq));\n\t\trt_rq->overloaded = 0;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 337
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 336
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 333
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic void inc_rt_migration(struct sched_rt_entity *rt_se, struct rt_rq *rt_rq)\n{\n\tstruct task_struct *p;\n\n\tif (!rt_entity_is_task(rt_se))\n\t\treturn;\n\n\tp = rt_task_of(rt_se);\n\trt_rq = &rq_of_rt_rq(rt_rq)->rt;\n\n\trt_rq->rt_nr_total++;\n\tif (p->nr_cpus_allowed > 1)\n\t\trt_rq->rt_nr_migratory++;\n\n\tupdate_rt_migration(rt_rq);\n}"
  },
  {
    "function_name": "update_rt_migration",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "316-327",
    "snippet": "static void update_rt_migration(struct rt_rq *rt_rq)\n{\n\tif (rt_rq->rt_nr_migratory && rt_rq->rt_nr_total > 1) {\n\t\tif (!rt_rq->overloaded) {\n\t\t\trt_set_overload(rq_of_rt_rq(rt_rq));\n\t\t\trt_rq->overloaded = 1;\n\t\t}\n\t} else if (rt_rq->overloaded) {\n\t\trt_clear_overload(rq_of_rt_rq(rt_rq));\n\t\trt_rq->overloaded = 0;\n\t}\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rt_clear_overload",
          "args": [
            "rq_of_rt_rq(rt_rq)"
          ],
          "line": 324
        },
        "resolved": true,
        "details": {
          "function_name": "rt_clear_overload",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "306-314",
          "snippet": "static inline void rt_clear_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\t/* the order here really doesn't matter */\n\tatomic_dec(&rq->rd->rto_count);\n\tcpumask_clear_cpu(rq->cpu, rq->rd->rto_mask);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_clear_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\t/* the order here really doesn't matter */\n\tatomic_dec(&rq->rd->rto_count);\n\tcpumask_clear_cpu(rq->cpu, rq->rd->rto_mask);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rq_of_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 324
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "243-246",
          "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_set_overload",
          "args": [
            "rq_of_rt_rq(rt_rq)"
          ],
          "line": 320
        },
        "resolved": true,
        "details": {
          "function_name": "rt_set_overload",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "287-304",
          "snippet": "static inline void rt_set_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\tcpumask_set_cpu(rq->cpu, rq->rd->rto_mask);\n\t/*\n\t * Make sure the mask is visible before we set\n\t * the overload count. That is checked to determine\n\t * if we should look at the mask. It would be a shame\n\t * if we looked at the mask, but the mask was not\n\t * updated yet.\n\t *\n\t * Matched by the barrier in pull_rt_task().\n\t */\n\tsmp_wmb();\n\tatomic_inc(&rq->rd->rto_count);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_set_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\tcpumask_set_cpu(rq->cpu, rq->rd->rto_mask);\n\t/*\n\t * Make sure the mask is visible before we set\n\t * the overload count. That is checked to determine\n\t * if we should look at the mask. It would be a shame\n\t * if we looked at the mask, but the mask was not\n\t * updated yet.\n\t *\n\t * Matched by the barrier in pull_rt_task().\n\t */\n\tsmp_wmb();\n\tatomic_inc(&rq->rd->rto_count);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic void update_rt_migration(struct rt_rq *rt_rq)\n{\n\tif (rt_rq->rt_nr_migratory && rt_rq->rt_nr_total > 1) {\n\t\tif (!rt_rq->overloaded) {\n\t\t\trt_set_overload(rq_of_rt_rq(rt_rq));\n\t\t\trt_rq->overloaded = 1;\n\t\t}\n\t} else if (rt_rq->overloaded) {\n\t\trt_clear_overload(rq_of_rt_rq(rt_rq));\n\t\trt_rq->overloaded = 0;\n\t}\n}"
  },
  {
    "function_name": "rt_clear_overload",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "306-314",
    "snippet": "static inline void rt_clear_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\t/* the order here really doesn't matter */\n\tatomic_dec(&rq->rd->rto_count);\n\tcpumask_clear_cpu(rq->cpu, rq->rd->rto_mask);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpumask_clear_cpu",
          "args": [
            "rq->cpu",
            "rq->rd->rto_mask"
          ],
          "line": 313
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&rq->rd->rto_count"
          ],
          "line": 312
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_clear_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\t/* the order here really doesn't matter */\n\tatomic_dec(&rq->rd->rto_count);\n\tcpumask_clear_cpu(rq->cpu, rq->rd->rto_mask);\n}"
  },
  {
    "function_name": "rt_set_overload",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "287-304",
    "snippet": "static inline void rt_set_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\tcpumask_set_cpu(rq->cpu, rq->rd->rto_mask);\n\t/*\n\t * Make sure the mask is visible before we set\n\t * the overload count. That is checked to determine\n\t * if we should look at the mask. It would be a shame\n\t * if we looked at the mask, but the mask was not\n\t * updated yet.\n\t *\n\t * Matched by the barrier in pull_rt_task().\n\t */\n\tsmp_wmb();\n\tatomic_inc(&rq->rd->rto_count);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&rq->rd->rto_count"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_wmb",
          "args": [],
          "line": 302
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "rq->cpu",
            "rq->rd->rto_mask"
          ],
          "line": 292
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void rt_set_overload(struct rq *rq)\n{\n\tif (!rq->online)\n\t\treturn;\n\n\tcpumask_set_cpu(rq->cpu, rq->rd->rto_mask);\n\t/*\n\t * Make sure the mask is visible before we set\n\t * the overload count. That is checked to determine\n\t * if we should look at the mask. It would be a shame\n\t * if we looked at the mask, but the mask was not\n\t * updated yet.\n\t *\n\t * Matched by the barrier in pull_rt_task().\n\t */\n\tsmp_wmb();\n\tatomic_inc(&rq->rd->rto_count);\n}"
  },
  {
    "function_name": "rt_overloaded",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "282-285",
    "snippet": "static inline int rt_overloaded(struct rq *rq)\n{\n\treturn atomic_read(&rq->rd->rto_count);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&rq->rd->rto_count"
          ],
          "line": 284
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline int rt_overloaded(struct rq *rq)\n{\n\treturn atomic_read(&rq->rd->rto_count);\n}"
  },
  {
    "function_name": "need_pull_rt_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "276-280",
    "snippet": "static inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)\n{\n\t/* Try to pull RT tasks here if we lower this rq's prio */\n\treturn rq->online && rq->rt.highest_prio.curr > prev->prio;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline bool need_pull_rt_task(struct rq *rq, struct task_struct *prev)\n{\n\t/* Try to pull RT tasks here if we lower this rq's prio */\n\treturn rq->online && rq->rt.highest_prio.curr > prev->prio;\n}"
  },
  {
    "function_name": "alloc_rt_sched_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "266-269",
    "snippet": "int alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)\n{\n\treturn 1;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nint alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)\n{\n\treturn 1;\n}"
  },
  {
    "function_name": "free_rt_sched_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "264-264",
    "snippet": "void free_rt_sched_group(struct task_group *tg) { }",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nvoid free_rt_sched_group(struct task_group *tg) { }"
  },
  {
    "function_name": "unregister_rt_sched_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "262-262",
    "snippet": "void unregister_rt_sched_group(struct task_group *tg) { }",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nvoid unregister_rt_sched_group(struct task_group *tg) { }"
  },
  {
    "function_name": "rt_rq_of_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "255-260",
    "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "rq_of_rt_se",
          "args": [
            "rt_se"
          ],
          "line": 257
        },
        "resolved": true,
        "details": {
          "function_name": "rq_of_rt_se",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "248-253",
          "snippet": "static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rq *rq = rq_of_rt_se(rt_se);\n\n\treturn &rq->rt;\n}"
  },
  {
    "function_name": "rq_of_rt_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "248-253",
    "snippet": "static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "task_rq",
          "args": [
            "p"
          ],
          "line": 252
        },
        "resolved": true,
        "details": {
          "function_name": "is_task_rq_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5634-5637",
          "snippet": "static inline bool is_task_rq_idle(struct task_struct *t)\n{\n\treturn (task_rq(t)->idle == t);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nstatic inline bool is_task_rq_idle(struct task_struct *t)\n{\n\treturn (task_rq(t)->idle == t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_task_of",
          "args": [
            "rt_se"
          ],
          "line": 250
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct task_struct *p = rt_task_of(rt_se);\n\n\treturn task_rq(p);\n}"
  },
  {
    "function_name": "rq_of_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "243-246",
    "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rt_rq",
            "structrq",
            "rt"
          ],
          "line": 245
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn container_of(rt_rq, struct rq, rt);\n}"
  },
  {
    "function_name": "rt_task_of",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "238-241",
    "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rt_se",
            "structtask_struct",
            "rt"
          ],
          "line": 240
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
  },
  {
    "function_name": "alloc_rt_sched_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "194-232",
    "snippet": "int alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)\n{\n\tstruct rt_rq *rt_rq;\n\tstruct sched_rt_entity *rt_se;\n\tint i;\n\n\ttg->rt_rq = kcalloc(nr_cpu_ids, sizeof(rt_rq), GFP_KERNEL);\n\tif (!tg->rt_rq)\n\t\tgoto err;\n\ttg->rt_se = kcalloc(nr_cpu_ids, sizeof(rt_se), GFP_KERNEL);\n\tif (!tg->rt_se)\n\t\tgoto err;\n\n\tinit_rt_bandwidth(&tg->rt_bandwidth,\n\t\t\tktime_to_ns(def_rt_bandwidth.rt_period), 0);\n\n\tfor_each_possible_cpu(i) {\n\t\trt_rq = kzalloc_node(sizeof(struct rt_rq),\n\t\t\t\t     GFP_KERNEL, cpu_to_node(i));\n\t\tif (!rt_rq)\n\t\t\tgoto err;\n\n\t\trt_se = kzalloc_node(sizeof(struct sched_rt_entity),\n\t\t\t\t     GFP_KERNEL, cpu_to_node(i));\n\t\tif (!rt_se)\n\t\t\tgoto err_free_rq;\n\n\t\tinit_rt_rq(rt_rq);\n\t\trt_rq->rt_runtime = tg->rt_bandwidth.rt_runtime;\n\t\tinit_tg_rt_entry(tg, rt_rq, rt_se, i, parent->rt_se[i]);\n\t}\n\n\treturn 1;\n\nerr_free_rq:\n\tkfree(rt_rq);\nerr:\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "struct rt_bandwidth def_rt_bandwidth;",
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "rt_rq"
          ],
          "line": 229
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_tg_rt_entry",
          "args": [
            "tg",
            "rt_rq",
            "rt_se",
            "i",
            "parent->rt_se[i]"
          ],
          "line": 223
        },
        "resolved": true,
        "details": {
          "function_name": "init_tg_rt_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "167-192",
          "snippet": "void init_tg_rt_entry(struct task_group *tg, struct rt_rq *rt_rq,\n\t\tstruct sched_rt_entity *rt_se, int cpu,\n\t\tstruct sched_rt_entity *parent)\n{\n\tstruct rq *rq = cpu_rq(cpu);\n\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_boosted = 0;\n\trt_rq->rq = rq;\n\trt_rq->tg = tg;\n\n\ttg->rt_rq[cpu] = rt_rq;\n\ttg->rt_se[cpu] = rt_se;\n\n\tif (!rt_se)\n\t\treturn;\n\n\tif (!parent)\n\t\trt_se->rt_rq = &rq->rt;\n\telse\n\t\trt_se->rt_rq = parent->my_q;\n\n\trt_se->my_q = rt_rq;\n\trt_se->parent = parent;\n\tINIT_LIST_HEAD(&rt_se->run_list);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nvoid init_tg_rt_entry(struct task_group *tg, struct rt_rq *rt_rq,\n\t\tstruct sched_rt_entity *rt_se, int cpu,\n\t\tstruct sched_rt_entity *parent)\n{\n\tstruct rq *rq = cpu_rq(cpu);\n\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_boosted = 0;\n\trt_rq->rq = rq;\n\trt_rq->tg = tg;\n\n\ttg->rt_rq[cpu] = rt_rq;\n\ttg->rt_se[cpu] = rt_se;\n\n\tif (!rt_se)\n\t\treturn;\n\n\tif (!parent)\n\t\trt_se->rt_rq = &rq->rt;\n\telse\n\t\trt_se->rt_rq = parent->my_q;\n\n\trt_se->my_q = rt_rq;\n\trt_se->parent = parent;\n\tINIT_LIST_HEAD(&rt_se->run_list);\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_rt_rq",
          "args": [
            "rt_rq"
          ],
          "line": 221
        },
        "resolved": true,
        "details": {
          "function_name": "init_rt_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "83-110",
          "snippet": "void init_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array;\n\tint i;\n\n\tarray = &rt_rq->active;\n\tfor (i = 0; i < MAX_RT_PRIO; i++) {\n\t\tINIT_LIST_HEAD(array->queue + i);\n\t\t__clear_bit(i, array->bitmap);\n\t}\n\t/* delimiter for bitsearch: */\n\t__set_bit(MAX_RT_PRIO, array->bitmap);\n\n#if defined CONFIG_SMP\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->highest_prio.next = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_migratory = 0;\n\trt_rq->overloaded = 0;\n\tplist_head_init(&rt_rq->pushable_tasks);\n#endif /* CONFIG_SMP */\n\t/* We start is dequeued state, because no RT tasks are queued */\n\trt_rq->rt_queued = 0;\n\n\trt_rq->rt_time = 0;\n\trt_rq->rt_throttled = 0;\n\trt_rq->rt_runtime = 0;\n\traw_spin_lock_init(&rt_rq->rt_runtime_lock);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nvoid init_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array;\n\tint i;\n\n\tarray = &rt_rq->active;\n\tfor (i = 0; i < MAX_RT_PRIO; i++) {\n\t\tINIT_LIST_HEAD(array->queue + i);\n\t\t__clear_bit(i, array->bitmap);\n\t}\n\t/* delimiter for bitsearch: */\n\t__set_bit(MAX_RT_PRIO, array->bitmap);\n\n#if defined CONFIG_SMP\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->highest_prio.next = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_migratory = 0;\n\trt_rq->overloaded = 0;\n\tplist_head_init(&rt_rq->pushable_tasks);\n#endif /* CONFIG_SMP */\n\t/* We start is dequeued state, because no RT tasks are queued */\n\trt_rq->rt_queued = 0;\n\n\trt_rq->rt_time = 0;\n\trt_rq->rt_throttled = 0;\n\trt_rq->rt_runtime = 0;\n\traw_spin_lock_init(&rt_rq->rt_runtime_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "sizeof(struct sched_rt_entity)",
            "GFP_KERNEL",
            "cpu_to_node(i)"
          ],
          "line": 216
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "i"
          ],
          "line": 217
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc_node",
          "args": [
            "sizeof(struct rt_rq)",
            "GFP_KERNEL",
            "cpu_to_node(i)"
          ],
          "line": 211
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "i"
          ],
          "line": 212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_rt_bandwidth",
          "args": [
            "&tg->rt_bandwidth",
            "ktime_to_ns(def_rt_bandwidth.rt_period)",
            "0"
          ],
          "line": 207
        },
        "resolved": true,
        "details": {
          "function_name": "init_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "43-53",
          "snippet": "void init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)\n{\n\trt_b->rt_period = ns_to_ktime(period);\n\trt_b->rt_runtime = runtime;\n\n\traw_spin_lock_init(&rt_b->rt_runtime_lock);\n\n\thrtimer_init(&rt_b->rt_period_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL_HARD);\n\trt_b->rt_period_timer.function = sched_rt_period_timer;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nvoid init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)\n{\n\trt_b->rt_period = ns_to_ktime(period);\n\trt_b->rt_runtime = runtime;\n\n\traw_spin_lock_init(&rt_b->rt_runtime_lock);\n\n\thrtimer_init(&rt_b->rt_period_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL_HARD);\n\trt_b->rt_period_timer.function = sched_rt_period_timer;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ktime_to_ns",
          "args": [
            "def_rt_bandwidth.rt_period"
          ],
          "line": 208
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kcalloc",
          "args": [
            "nr_cpu_ids",
            "sizeof(rt_se)",
            "GFP_KERNEL"
          ],
          "line": 203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kcalloc",
          "args": [
            "nr_cpu_ids",
            "sizeof(rt_rq)",
            "GFP_KERNEL"
          ],
          "line": 200
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstruct rt_bandwidth def_rt_bandwidth;\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nint alloc_rt_sched_group(struct task_group *tg, struct task_group *parent)\n{\n\tstruct rt_rq *rt_rq;\n\tstruct sched_rt_entity *rt_se;\n\tint i;\n\n\ttg->rt_rq = kcalloc(nr_cpu_ids, sizeof(rt_rq), GFP_KERNEL);\n\tif (!tg->rt_rq)\n\t\tgoto err;\n\ttg->rt_se = kcalloc(nr_cpu_ids, sizeof(rt_se), GFP_KERNEL);\n\tif (!tg->rt_se)\n\t\tgoto err;\n\n\tinit_rt_bandwidth(&tg->rt_bandwidth,\n\t\t\tktime_to_ns(def_rt_bandwidth.rt_period), 0);\n\n\tfor_each_possible_cpu(i) {\n\t\trt_rq = kzalloc_node(sizeof(struct rt_rq),\n\t\t\t\t     GFP_KERNEL, cpu_to_node(i));\n\t\tif (!rt_rq)\n\t\t\tgoto err;\n\n\t\trt_se = kzalloc_node(sizeof(struct sched_rt_entity),\n\t\t\t\t     GFP_KERNEL, cpu_to_node(i));\n\t\tif (!rt_se)\n\t\t\tgoto err_free_rq;\n\n\t\tinit_rt_rq(rt_rq);\n\t\trt_rq->rt_runtime = tg->rt_bandwidth.rt_runtime;\n\t\tinit_tg_rt_entry(tg, rt_rq, rt_se, i, parent->rt_se[i]);\n\t}\n\n\treturn 1;\n\nerr_free_rq:\n\tkfree(rt_rq);\nerr:\n\treturn 0;\n}"
  },
  {
    "function_name": "init_tg_rt_entry",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "167-192",
    "snippet": "void init_tg_rt_entry(struct task_group *tg, struct rt_rq *rt_rq,\n\t\tstruct sched_rt_entity *rt_se, int cpu,\n\t\tstruct sched_rt_entity *parent)\n{\n\tstruct rq *rq = cpu_rq(cpu);\n\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_boosted = 0;\n\trt_rq->rq = rq;\n\trt_rq->tg = tg;\n\n\ttg->rt_rq[cpu] = rt_rq;\n\ttg->rt_se[cpu] = rt_se;\n\n\tif (!rt_se)\n\t\treturn;\n\n\tif (!parent)\n\t\trt_se->rt_rq = &rq->rt;\n\telse\n\t\trt_se->rt_rq = parent->my_q;\n\n\trt_se->my_q = rt_rq;\n\trt_se->parent = parent;\n\tINIT_LIST_HEAD(&rt_se->run_list);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&rt_se->run_list"
          ],
          "line": 191
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 171
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nvoid init_tg_rt_entry(struct task_group *tg, struct rt_rq *rt_rq,\n\t\tstruct sched_rt_entity *rt_se, int cpu,\n\t\tstruct sched_rt_entity *parent)\n{\n\tstruct rq *rq = cpu_rq(cpu);\n\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_boosted = 0;\n\trt_rq->rq = rq;\n\trt_rq->tg = tg;\n\n\ttg->rt_rq[cpu] = rt_rq;\n\ttg->rt_se[cpu] = rt_se;\n\n\tif (!rt_se)\n\t\treturn;\n\n\tif (!parent)\n\t\trt_se->rt_rq = &rq->rt;\n\telse\n\t\trt_se->rt_rq = parent->my_q;\n\n\trt_se->my_q = rt_rq;\n\trt_se->parent = parent;\n\tINIT_LIST_HEAD(&rt_se->run_list);\n}"
  },
  {
    "function_name": "free_rt_sched_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "152-165",
    "snippet": "void free_rt_sched_group(struct task_group *tg)\n{\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tif (tg->rt_rq)\n\t\t\tkfree(tg->rt_rq[i]);\n\t\tif (tg->rt_se)\n\t\t\tkfree(tg->rt_se[i]);\n\t}\n\n\tkfree(tg->rt_rq);\n\tkfree(tg->rt_se);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "tg->rt_se"
          ],
          "line": 164
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nvoid free_rt_sched_group(struct task_group *tg)\n{\n\tint i;\n\n\tfor_each_possible_cpu(i) {\n\t\tif (tg->rt_rq)\n\t\t\tkfree(tg->rt_rq[i]);\n\t\tif (tg->rt_se)\n\t\t\tkfree(tg->rt_se[i]);\n\t}\n\n\tkfree(tg->rt_rq);\n\tkfree(tg->rt_se);\n}"
  },
  {
    "function_name": "unregister_rt_sched_group",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "145-150",
    "snippet": "void unregister_rt_sched_group(struct task_group *tg)\n{\n\tif (tg->rt_se)\n\t\tdestroy_rt_bandwidth(&tg->rt_bandwidth);\n\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "destroy_rt_bandwidth",
          "args": [
            "&tg->rt_bandwidth"
          ],
          "line": 148
        },
        "resolved": true,
        "details": {
          "function_name": "destroy_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "113-116",
          "snippet": "static void destroy_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\thrtimer_cancel(&rt_b->rt_period_timer);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void destroy_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\thrtimer_cancel(&rt_b->rt_period_timer);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nvoid unregister_rt_sched_group(struct task_group *tg)\n{\n\tif (tg->rt_se)\n\t\tdestroy_rt_bandwidth(&tg->rt_bandwidth);\n\n}"
  },
  {
    "function_name": "rq_of_rt_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "138-143",
    "snippet": "static inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = rt_se->rt_rq;\n\n\treturn rt_rq->rq;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rq *rq_of_rt_se(struct sched_rt_entity *rt_se)\n{\n\tstruct rt_rq *rt_rq = rt_se->rt_rq;\n\n\treturn rt_rq->rq;\n}"
  },
  {
    "function_name": "rt_rq_of_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "133-136",
    "snippet": "static inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->rt_rq;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rt_rq *rt_rq_of_se(struct sched_rt_entity *rt_se)\n{\n\treturn rt_se->rt_rq;\n}"
  },
  {
    "function_name": "rq_of_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "128-131",
    "snippet": "static inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rq;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nstatic inline struct rq *rq_of_rt_rq(struct rt_rq *rt_rq)\n{\n\treturn rt_rq->rq;\n}"
  },
  {
    "function_name": "rt_task_of",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "120-126",
    "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tWARN_ON_ONCE(!rt_entity_is_task(rt_se));\n#endif\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rt_se",
            "structtask_struct",
            "rt"
          ],
          "line": 125
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rt_entity_is_task(rt_se)"
          ],
          "line": 123
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_entity_is_task",
          "args": [
            "rt_se"
          ],
          "line": 123
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n#ifdef CONFIG_SCHED_DEBUG\n\tWARN_ON_ONCE(!rt_entity_is_task(rt_se));\n#endif\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
  },
  {
    "function_name": "destroy_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "113-116",
    "snippet": "static void destroy_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\thrtimer_cancel(&rt_b->rt_period_timer);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "hrtimer_cancel",
          "args": [
            "&rt_b->rt_period_timer"
          ],
          "line": 115
        },
        "resolved": true,
        "details": {
          "function_name": "hrtimer_cancel",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/hrtimer.c",
          "lines": "1438-1449",
          "snippet": "int hrtimer_cancel(struct hrtimer *timer)\n{\n\tint ret;\n\n\tdo {\n\t\tret = hrtimer_try_to_cancel(timer);\n\n\t\tif (ret < 0)\n\t\t\thrtimer_cancel_wait_running(timer);\n\t} while (ret < 0);\n\treturn ret;\n}",
          "includes": [
            "#include \"tick-internal.h\"",
            "#include <trace/events/timer.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/freezer.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/debugobjects.h>",
            "#include <linux/err.h>",
            "#include <linux/tick.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/notifier.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tick-internal.h\"\n#include <trace/events/timer.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/freezer.h>\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/debugobjects.h>\n#include <linux/err.h>\n#include <linux/tick.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/notifier.h>\n#include <linux/hrtimer.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n\nint hrtimer_cancel(struct hrtimer *timer)\n{\n\tint ret;\n\n\tdo {\n\t\tret = hrtimer_try_to_cancel(timer);\n\n\t\tif (ret < 0)\n\t\t\thrtimer_cancel_wait_running(timer);\n\t} while (ret < 0);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void destroy_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\thrtimer_cancel(&rt_b->rt_period_timer);\n}"
  },
  {
    "function_name": "init_rt_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "83-110",
    "snippet": "void init_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array;\n\tint i;\n\n\tarray = &rt_rq->active;\n\tfor (i = 0; i < MAX_RT_PRIO; i++) {\n\t\tINIT_LIST_HEAD(array->queue + i);\n\t\t__clear_bit(i, array->bitmap);\n\t}\n\t/* delimiter for bitsearch: */\n\t__set_bit(MAX_RT_PRIO, array->bitmap);\n\n#if defined CONFIG_SMP\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->highest_prio.next = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_migratory = 0;\n\trt_rq->overloaded = 0;\n\tplist_head_init(&rt_rq->pushable_tasks);\n#endif /* CONFIG_SMP */\n\t/* We start is dequeued state, because no RT tasks are queued */\n\trt_rq->rt_queued = 0;\n\n\trt_rq->rt_time = 0;\n\trt_rq->rt_throttled = 0;\n\trt_rq->rt_runtime = 0;\n\traw_spin_lock_init(&rt_rq->rt_runtime_lock);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
      "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&rt_rq->rt_runtime_lock"
          ],
          "line": 109
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "plist_head_init",
          "args": [
            "&rt_rq->pushable_tasks"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__set_bit",
          "args": [
            "MAX_RT_PRIO",
            "array->bitmap"
          ],
          "line": 94
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__clear_bit",
          "args": [
            "i",
            "array->bitmap"
          ],
          "line": 91
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "array->queue + i"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\n\nvoid init_rt_rq(struct rt_rq *rt_rq)\n{\n\tstruct rt_prio_array *array;\n\tint i;\n\n\tarray = &rt_rq->active;\n\tfor (i = 0; i < MAX_RT_PRIO; i++) {\n\t\tINIT_LIST_HEAD(array->queue + i);\n\t\t__clear_bit(i, array->bitmap);\n\t}\n\t/* delimiter for bitsearch: */\n\t__set_bit(MAX_RT_PRIO, array->bitmap);\n\n#if defined CONFIG_SMP\n\trt_rq->highest_prio.curr = MAX_RT_PRIO-1;\n\trt_rq->highest_prio.next = MAX_RT_PRIO-1;\n\trt_rq->rt_nr_migratory = 0;\n\trt_rq->overloaded = 0;\n\tplist_head_init(&rt_rq->pushable_tasks);\n#endif /* CONFIG_SMP */\n\t/* We start is dequeued state, because no RT tasks are queued */\n\trt_rq->rt_queued = 0;\n\n\trt_rq->rt_time = 0;\n\trt_rq->rt_throttled = 0;\n\trt_rq->rt_runtime = 0;\n\traw_spin_lock_init(&rt_rq->rt_runtime_lock);\n}"
  },
  {
    "function_name": "start_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "75-81",
    "snippet": "static void start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\tif (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)\n\t\treturn;\n\n\tdo_start_rt_bandwidth(rt_b);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "do_start_rt_bandwidth",
          "args": [
            "rt_b"
          ],
          "line": 80
        },
        "resolved": true,
        "details": {
          "function_name": "do_start_rt_bandwidth",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "55-73",
          "snippet": "static inline void do_start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tif (!rt_b->rt_period_active) {\n\t\trt_b->rt_period_active = 1;\n\t\t/*\n\t\t * SCHED_DEADLINE updates the bandwidth, as a run away\n\t\t * RT task with a DL task could hog a CPU. But DL does\n\t\t * not reset the period. If a deadline task was running\n\t\t * without an RT task running, it can cause RT tasks to\n\t\t * throttle when they start up. Kick the timer right away\n\t\t * to update the period.\n\t\t */\n\t\thrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));\n\t\thrtimer_start_expires(&rt_b->rt_period_timer,\n\t\t\t\t      HRTIMER_MODE_ABS_PINNED_HARD);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void do_start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tif (!rt_b->rt_period_active) {\n\t\trt_b->rt_period_active = 1;\n\t\t/*\n\t\t * SCHED_DEADLINE updates the bandwidth, as a run away\n\t\t * RT task with a DL task could hog a CPU. But DL does\n\t\t * not reset the period. If a deadline task was running\n\t\t * without an RT task running, it can cause RT tasks to\n\t\t * throttle when they start up. Kick the timer right away\n\t\t * to update the period.\n\t\t */\n\t\thrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));\n\t\thrtimer_start_expires(&rt_b->rt_period_timer,\n\t\t\t\t      HRTIMER_MODE_ABS_PINNED_HARD);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_bandwidth_enabled",
          "args": [],
          "line": 77
        },
        "resolved": true,
        "details": {
          "function_name": "rt_bandwidth_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "630-633",
          "snippet": "static inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nstatic inline int rt_bandwidth_enabled(void)\n{\n\treturn sysctl_sched_rt_runtime >= 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic void start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\tif (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF)\n\t\treturn;\n\n\tdo_start_rt_bandwidth(rt_b);\n}"
  },
  {
    "function_name": "do_start_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "55-73",
    "snippet": "static inline void do_start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tif (!rt_b->rt_period_active) {\n\t\trt_b->rt_period_active = 1;\n\t\t/*\n\t\t * SCHED_DEADLINE updates the bandwidth, as a run away\n\t\t * RT task with a DL task could hog a CPU. But DL does\n\t\t * not reset the period. If a deadline task was running\n\t\t * without an RT task running, it can cause RT tasks to\n\t\t * throttle when they start up. Kick the timer right away\n\t\t * to update the period.\n\t\t */\n\t\thrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));\n\t\thrtimer_start_expires(&rt_b->rt_period_timer,\n\t\t\t\t      HRTIMER_MODE_ABS_PINNED_HARD);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 72
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hrtimer_start_expires",
          "args": [
            "&rt_b->rt_period_timer",
            "HRTIMER_MODE_ABS_PINNED_HARD"
          ],
          "line": 69
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hrtimer_forward_now",
          "args": [
            "&rt_b->rt_period_timer",
            "ns_to_ktime(0)"
          ],
          "line": 68
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ns_to_ktime",
          "args": [
            "0"
          ],
          "line": 68
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 57
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic inline void do_start_rt_bandwidth(struct rt_bandwidth *rt_b)\n{\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tif (!rt_b->rt_period_active) {\n\t\trt_b->rt_period_active = 1;\n\t\t/*\n\t\t * SCHED_DEADLINE updates the bandwidth, as a run away\n\t\t * RT task with a DL task could hog a CPU. But DL does\n\t\t * not reset the period. If a deadline task was running\n\t\t * without an RT task running, it can cause RT tasks to\n\t\t * throttle when they start up. Kick the timer right away\n\t\t * to update the period.\n\t\t */\n\t\thrtimer_forward_now(&rt_b->rt_period_timer, ns_to_ktime(0));\n\t\thrtimer_start_expires(&rt_b->rt_period_timer,\n\t\t\t\t      HRTIMER_MODE_ABS_PINNED_HARD);\n\t}\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n}"
  },
  {
    "function_name": "init_rt_bandwidth",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "43-53",
    "snippet": "void init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)\n{\n\trt_b->rt_period = ns_to_ktime(period);\n\trt_b->rt_runtime = runtime;\n\n\traw_spin_lock_init(&rt_b->rt_runtime_lock);\n\n\thrtimer_init(&rt_b->rt_period_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL_HARD);\n\trt_b->rt_period_timer.function = sched_rt_period_timer;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "hrtimer_init",
          "args": [
            "&rt_b->rt_period_timer",
            "CLOCK_MONOTONIC",
            "HRTIMER_MODE_REL_HARD"
          ],
          "line": 50
        },
        "resolved": true,
        "details": {
          "function_name": "hrtimer_init_sleeper",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/hrtimer.c",
          "lines": "2007-2013",
          "snippet": "void hrtimer_init_sleeper(struct hrtimer_sleeper *sl, clockid_t clock_id,\n\t\t\t  enum hrtimer_mode mode)\n{\n\tdebug_init(&sl->timer, clock_id, mode);\n\t__hrtimer_init_sleeper(sl, clock_id, mode);\n\n}",
          "includes": [
            "#include \"tick-internal.h\"",
            "#include <trace/events/timer.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/freezer.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/debugobjects.h>",
            "#include <linux/err.h>",
            "#include <linux/tick.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/notifier.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tick-internal.h\"\n#include <trace/events/timer.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/freezer.h>\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/debugobjects.h>\n#include <linux/err.h>\n#include <linux/tick.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/notifier.h>\n#include <linux/hrtimer.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n\nvoid hrtimer_init_sleeper(struct hrtimer_sleeper *sl, clockid_t clock_id,\n\t\t\t  enum hrtimer_mode mode)\n{\n\tdebug_init(&sl->timer, clock_id, mode);\n\t__hrtimer_init_sleeper(sl, clock_id, mode);\n\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 48
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ns_to_ktime",
          "args": [
            "period"
          ],
          "line": 45
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nvoid init_rt_bandwidth(struct rt_bandwidth *rt_b, u64 period, u64 runtime)\n{\n\trt_b->rt_period = ns_to_ktime(period);\n\trt_b->rt_runtime = runtime;\n\n\traw_spin_lock_init(&rt_b->rt_runtime_lock);\n\n\thrtimer_init(&rt_b->rt_period_timer, CLOCK_MONOTONIC,\n\t\t     HRTIMER_MODE_REL_HARD);\n\trt_b->rt_period_timer.function = sched_rt_period_timer;\n}"
  },
  {
    "function_name": "sched_rt_period_timer",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
    "lines": "19-41",
    "snippet": "static enum hrtimer_restart sched_rt_period_timer(struct hrtimer *timer)\n{\n\tstruct rt_bandwidth *rt_b =\n\t\tcontainer_of(timer, struct rt_bandwidth, rt_period_timer);\n\tint idle = 0;\n\tint overrun;\n\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tfor (;;) {\n\t\toverrun = hrtimer_forward_now(timer, rt_b->rt_period);\n\t\tif (!overrun)\n\t\t\tbreak;\n\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\t\tidle = do_sched_rt_period_timer(rt_b, overrun);\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t}\n\tif (idle)\n\t\trt_b->rt_period_active = 0;\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\n\treturn idle ? HRTIMER_NORESTART : HRTIMER_RESTART;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [
      "static int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 38
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "208-211",
          "snippet": "void __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock",
          "args": [
            "&rt_b->rt_runtime_lock"
          ],
          "line": 34
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_bh",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "176-179",
          "snippet": "void __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_bh(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_bh(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "do_sched_rt_period_timer",
          "args": [
            "rt_b",
            "overrun"
          ],
          "line": 33
        },
        "resolved": true,
        "details": {
          "function_name": "do_sched_rt_period_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "865-947",
          "snippet": "static int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun)\n{\n\tint i, idle = 1, throttled = 0;\n\tconst struct cpumask *span;\n\n\tspan = sched_rt_period_mask();\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * FIXME: isolated CPUs should really leave the root task group,\n\t * whether they are isolcpus or were isolated via cpusets, lest\n\t * the timer run on a CPU which does not service all runqueues,\n\t * potentially leaving other CPUs indefinitely throttled.  If\n\t * isolation is really required, the user will turn the throttle\n\t * off to kill the perturbations it causes anyway.  Meanwhile,\n\t * this maintains functionality for boot and/or troubleshooting.\n\t */\n\tif (rt_b == &root_task_group.rt_bandwidth)\n\t\tspan = cpu_online_mask;\n#endif\n\tfor_each_cpu(i, span) {\n\t\tint enqueue = 0;\n\t\tstruct rt_rq *rt_rq = sched_rt_period_rt_rq(rt_b, i);\n\t\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\t\tint skip;\n\n\t\t/*\n\t\t * When span == cpu_online_mask, taking each rq->lock\n\t\t * can be time-consuming. Try to avoid it when possible.\n\t\t */\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\tif (!sched_feat(RT_RUNTIME_SHARE) && rt_rq->rt_runtime != RUNTIME_INF)\n\t\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\tskip = !rt_rq->rt_time && !rt_rq->rt_nr_running;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\tif (skip)\n\t\t\tcontinue;\n\n\t\traw_spin_rq_lock(rq);\n\t\tupdate_rq_clock(rq);\n\n\t\tif (rt_rq->rt_time) {\n\t\t\tu64 runtime;\n\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\tif (rt_rq->rt_throttled)\n\t\t\t\tbalance_runtime(rt_rq);\n\t\t\truntime = rt_rq->rt_runtime;\n\t\t\trt_rq->rt_time -= min(rt_rq->rt_time, overrun*runtime);\n\t\t\tif (rt_rq->rt_throttled && rt_rq->rt_time < runtime) {\n\t\t\t\trt_rq->rt_throttled = 0;\n\t\t\t\tenqueue = 1;\n\n\t\t\t\t/*\n\t\t\t\t * When we're idle and a woken (rt) task is\n\t\t\t\t * throttled check_preempt_curr() will set\n\t\t\t\t * skip_update and the time between the wakeup\n\t\t\t\t * and this unthrottle will get accounted as\n\t\t\t\t * 'runtime'.\n\t\t\t\t */\n\t\t\t\tif (rt_rq->rt_nr_running && rq->curr == rq->idle)\n\t\t\t\t\trq_clock_cancel_skipupdate(rq);\n\t\t\t}\n\t\t\tif (rt_rq->rt_time || rt_rq->rt_nr_running)\n\t\t\t\tidle = 0;\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t} else if (rt_rq->rt_nr_running) {\n\t\t\tidle = 0;\n\t\t\tif (!rt_rq_throttled(rt_rq))\n\t\t\t\tenqueue = 1;\n\t\t}\n\t\tif (rt_rq->rt_throttled)\n\t\t\tthrottled = 1;\n\n\t\tif (enqueue)\n\t\t\tsched_rt_rq_enqueue(rt_rq);\n\t\traw_spin_rq_unlock(rq);\n\t}\n\n\tif (!throttled && (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF))\n\t\treturn 1;\n\n\treturn idle;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun);",
            "static void enqueue_top_rt_rq(struct rt_rq *rt_rq);",
            "static void dequeue_top_rt_rq(struct rt_rq *rt_rq);",
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun);\nstatic void enqueue_top_rt_rq(struct rt_rq *rt_rq);\nstatic void dequeue_top_rt_rq(struct rt_rq *rt_rq);\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun)\n{\n\tint i, idle = 1, throttled = 0;\n\tconst struct cpumask *span;\n\n\tspan = sched_rt_period_mask();\n#ifdef CONFIG_RT_GROUP_SCHED\n\t/*\n\t * FIXME: isolated CPUs should really leave the root task group,\n\t * whether they are isolcpus or were isolated via cpusets, lest\n\t * the timer run on a CPU which does not service all runqueues,\n\t * potentially leaving other CPUs indefinitely throttled.  If\n\t * isolation is really required, the user will turn the throttle\n\t * off to kill the perturbations it causes anyway.  Meanwhile,\n\t * this maintains functionality for boot and/or troubleshooting.\n\t */\n\tif (rt_b == &root_task_group.rt_bandwidth)\n\t\tspan = cpu_online_mask;\n#endif\n\tfor_each_cpu(i, span) {\n\t\tint enqueue = 0;\n\t\tstruct rt_rq *rt_rq = sched_rt_period_rt_rq(rt_b, i);\n\t\tstruct rq *rq = rq_of_rt_rq(rt_rq);\n\t\tint skip;\n\n\t\t/*\n\t\t * When span == cpu_online_mask, taking each rq->lock\n\t\t * can be time-consuming. Try to avoid it when possible.\n\t\t */\n\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\tif (!sched_feat(RT_RUNTIME_SHARE) && rt_rq->rt_runtime != RUNTIME_INF)\n\t\t\trt_rq->rt_runtime = rt_b->rt_runtime;\n\t\tskip = !rt_rq->rt_time && !rt_rq->rt_nr_running;\n\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\tif (skip)\n\t\t\tcontinue;\n\n\t\traw_spin_rq_lock(rq);\n\t\tupdate_rq_clock(rq);\n\n\t\tif (rt_rq->rt_time) {\n\t\t\tu64 runtime;\n\n\t\t\traw_spin_lock(&rt_rq->rt_runtime_lock);\n\t\t\tif (rt_rq->rt_throttled)\n\t\t\t\tbalance_runtime(rt_rq);\n\t\t\truntime = rt_rq->rt_runtime;\n\t\t\trt_rq->rt_time -= min(rt_rq->rt_time, overrun*runtime);\n\t\t\tif (rt_rq->rt_throttled && rt_rq->rt_time < runtime) {\n\t\t\t\trt_rq->rt_throttled = 0;\n\t\t\t\tenqueue = 1;\n\n\t\t\t\t/*\n\t\t\t\t * When we're idle and a woken (rt) task is\n\t\t\t\t * throttled check_preempt_curr() will set\n\t\t\t\t * skip_update and the time between the wakeup\n\t\t\t\t * and this unthrottle will get accounted as\n\t\t\t\t * 'runtime'.\n\t\t\t\t */\n\t\t\t\tif (rt_rq->rt_nr_running && rq->curr == rq->idle)\n\t\t\t\t\trq_clock_cancel_skipupdate(rq);\n\t\t\t}\n\t\t\tif (rt_rq->rt_time || rt_rq->rt_nr_running)\n\t\t\t\tidle = 0;\n\t\t\traw_spin_unlock(&rt_rq->rt_runtime_lock);\n\t\t} else if (rt_rq->rt_nr_running) {\n\t\t\tidle = 0;\n\t\t\tif (!rt_rq_throttled(rt_rq))\n\t\t\t\tenqueue = 1;\n\t\t}\n\t\tif (rt_rq->rt_throttled)\n\t\t\tthrottled = 1;\n\n\t\tif (enqueue)\n\t\t\tsched_rt_rq_enqueue(rt_rq);\n\t\traw_spin_rq_unlock(rq);\n\t}\n\n\tif (!throttled && (!rt_bandwidth_enabled() || rt_b->rt_runtime == RUNTIME_INF))\n\t\treturn 1;\n\n\treturn idle;\n}"
        }
      },
      {
        "call_info": {
          "callee": "hrtimer_forward_now",
          "args": [
            "timer",
            "rt_b->rt_period"
          ],
          "line": 28
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "timer",
            "structrt_bandwidth",
            "rt_period_timer"
          ],
          "line": 22
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic int do_sched_rt_period_timer(struct rt_bandwidth *rt_b, int overrun);\n\nstatic enum hrtimer_restart sched_rt_period_timer(struct hrtimer *timer)\n{\n\tstruct rt_bandwidth *rt_b =\n\t\tcontainer_of(timer, struct rt_bandwidth, rt_period_timer);\n\tint idle = 0;\n\tint overrun;\n\n\traw_spin_lock(&rt_b->rt_runtime_lock);\n\tfor (;;) {\n\t\toverrun = hrtimer_forward_now(timer, rt_b->rt_period);\n\t\tif (!overrun)\n\t\t\tbreak;\n\n\t\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\t\tidle = do_sched_rt_period_timer(rt_b, overrun);\n\t\traw_spin_lock(&rt_b->rt_runtime_lock);\n\t}\n\tif (idle)\n\t\trt_b->rt_period_active = 0;\n\traw_spin_unlock(&rt_b->rt_runtime_lock);\n\n\treturn idle ? HRTIMER_NORESTART : HRTIMER_RESTART;\n}"
  }
]