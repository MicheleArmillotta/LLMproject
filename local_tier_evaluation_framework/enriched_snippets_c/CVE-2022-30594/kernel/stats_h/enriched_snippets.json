[
  {
    "function_name": "sched_info_switch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "281-294",
    "snippet": "static inline void\nsched_info_switch(struct rq *rq, struct task_struct *prev, struct task_struct *next)\n{\n\t/*\n\t * prev now departs the CPU.  It's not interesting to record\n\t * stats about how efficient we were at scheduling the idle\n\t * process, however.\n\t */\n\tif (prev != rq->idle)\n\t\tsched_info_depart(rq, prev);\n\n\tif (next != rq->idle)\n\t\tsched_info_arrive(rq, next);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_info_arrive",
          "args": [
            "rq",
            "next"
          ],
          "line": 293
        },
        "resolved": true,
        "details": {
          "function_name": "sched_info_arrive",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "230-245",
          "snippet": "static void sched_info_arrive(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long now, delta = 0;\n\n\tif (!t->sched_info.last_queued)\n\t\treturn;\n\n\tnow = rq_clock(rq);\n\tdelta = now - t->sched_info.last_queued;\n\tt->sched_info.last_queued = 0;\n\tt->sched_info.run_delay += delta;\n\tt->sched_info.last_arrival = now;\n\tt->sched_info.pcount++;\n\n\trq_sched_info_arrive(rq, delta);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static void sched_info_arrive(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long now, delta = 0;\n\n\tif (!t->sched_info.last_queued)\n\t\treturn;\n\n\tnow = rq_clock(rq);\n\tdelta = now - t->sched_info.last_queued;\n\tt->sched_info.last_queued = 0;\n\tt->sched_info.run_delay += delta;\n\tt->sched_info.last_arrival = now;\n\tt->sched_info.pcount++;\n\n\trq_sched_info_arrive(rq, delta);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_info_depart",
          "args": [
            "rq",
            "prev"
          ],
          "line": 290
        },
        "resolved": true,
        "details": {
          "function_name": "sched_info_depart",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "266-274",
          "snippet": "static inline void sched_info_depart(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long delta = rq_clock(rq) - t->sched_info.last_arrival;\n\n\trq_sched_info_depart(rq, delta);\n\n\tif (task_is_running(t))\n\t\tsched_info_enqueue(rq, t);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void sched_info_depart(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long delta = rq_clock(rq) - t->sched_info.last_arrival;\n\n\trq_sched_info_depart(rq, delta);\n\n\tif (task_is_running(t))\n\t\tsched_info_enqueue(rq, t);\n}"
        }
      }
    ],
    "contextual_snippet": "static inline void\nsched_info_switch(struct rq *rq, struct task_struct *prev, struct task_struct *next)\n{\n\t/*\n\t * prev now departs the CPU.  It's not interesting to record\n\t * stats about how efficient we were at scheduling the idle\n\t * process, however.\n\t */\n\tif (prev != rq->idle)\n\t\tsched_info_depart(rq, prev);\n\n\tif (next != rq->idle)\n\t\tsched_info_arrive(rq, next);\n}"
  },
  {
    "function_name": "sched_info_depart",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "266-274",
    "snippet": "static inline void sched_info_depart(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long delta = rq_clock(rq) - t->sched_info.last_arrival;\n\n\trq_sched_info_depart(rq, delta);\n\n\tif (task_is_running(t))\n\t\tsched_info_enqueue(rq, t);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_info_enqueue",
          "args": [
            "rq",
            "t"
          ],
          "line": 273
        },
        "resolved": true,
        "details": {
          "function_name": "sched_info_enqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "252-256",
          "snippet": "static inline void sched_info_enqueue(struct rq *rq, struct task_struct *t)\n{\n\tif (!t->sched_info.last_queued)\n\t\tt->sched_info.last_queued = rq_clock(rq);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void sched_info_enqueue(struct rq *rq, struct task_struct *t)\n{\n\tif (!t->sched_info.last_queued)\n\t\tt->sched_info.last_queued = rq_clock(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_is_running",
          "args": [
            "t"
          ],
          "line": 272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rq_sched_info_depart",
          "args": [
            "rq",
            "delta"
          ],
          "line": 270
        },
        "resolved": true,
        "details": {
          "function_name": "rq_sched_info_depart",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "72-72",
          "snippet": "static inline void rq_sched_info_depart  (struct rq *rq, unsigned long long delta) { }",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void rq_sched_info_depart  (struct rq *rq, unsigned long long delta) { }"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock",
          "args": [
            "rq"
          ],
          "line": 268
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      }
    ],
    "contextual_snippet": "static inline void sched_info_depart(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long delta = rq_clock(rq) - t->sched_info.last_arrival;\n\n\trq_sched_info_depart(rq, delta);\n\n\tif (task_is_running(t))\n\t\tsched_info_enqueue(rq, t);\n}"
  },
  {
    "function_name": "sched_info_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "252-256",
    "snippet": "static inline void sched_info_enqueue(struct rq *rq, struct task_struct *t)\n{\n\tif (!t->sched_info.last_queued)\n\t\tt->sched_info.last_queued = rq_clock(rq);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rq_clock",
          "args": [
            "rq"
          ],
          "line": 255
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      }
    ],
    "contextual_snippet": "static inline void sched_info_enqueue(struct rq *rq, struct task_struct *t)\n{\n\tif (!t->sched_info.last_queued)\n\t\tt->sched_info.last_queued = rq_clock(rq);\n}"
  },
  {
    "function_name": "sched_info_arrive",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "230-245",
    "snippet": "static void sched_info_arrive(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long now, delta = 0;\n\n\tif (!t->sched_info.last_queued)\n\t\treturn;\n\n\tnow = rq_clock(rq);\n\tdelta = now - t->sched_info.last_queued;\n\tt->sched_info.last_queued = 0;\n\tt->sched_info.run_delay += delta;\n\tt->sched_info.last_arrival = now;\n\tt->sched_info.pcount++;\n\n\trq_sched_info_arrive(rq, delta);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rq_sched_info_arrive",
          "args": [
            "rq",
            "delta"
          ],
          "line": 244
        },
        "resolved": true,
        "details": {
          "function_name": "rq_sched_info_arrive",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "70-70",
          "snippet": "static inline void rq_sched_info_arrive  (struct rq *rq, unsigned long long delta) { }",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void rq_sched_info_arrive  (struct rq *rq, unsigned long long delta) { }"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock",
          "args": [
            "rq"
          ],
          "line": 237
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      }
    ],
    "contextual_snippet": "static void sched_info_arrive(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long now, delta = 0;\n\n\tif (!t->sched_info.last_queued)\n\t\treturn;\n\n\tnow = rq_clock(rq);\n\tdelta = now - t->sched_info.last_queued;\n\tt->sched_info.last_queued = 0;\n\tt->sched_info.run_delay += delta;\n\tt->sched_info.last_arrival = now;\n\tt->sched_info.pcount++;\n\n\trq_sched_info_arrive(rq, delta);\n}"
  },
  {
    "function_name": "sched_info_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "211-223",
    "snippet": "static inline void sched_info_dequeue(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long delta = 0;\n\n\tif (!t->sched_info.last_queued)\n\t\treturn;\n\n\tdelta = rq_clock(rq) - t->sched_info.last_queued;\n\tt->sched_info.last_queued = 0;\n\tt->sched_info.run_delay += delta;\n\n\trq_sched_info_dequeue(rq, delta);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rq_sched_info_dequeue",
          "args": [
            "rq",
            "delta"
          ],
          "line": 222
        },
        "resolved": true,
        "details": {
          "function_name": "rq_sched_info_dequeue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
          "lines": "71-71",
          "snippet": "static inline void rq_sched_info_dequeue(struct rq *rq, unsigned long long delta) { }",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void rq_sched_info_dequeue(struct rq *rq, unsigned long long delta) { }"
        }
      },
      {
        "call_info": {
          "callee": "rq_clock",
          "args": [
            "rq"
          ],
          "line": 218
        },
        "resolved": true,
        "details": {
          "function_name": "update_idle_rq_clock_pelt",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "202-203",
          "snippet": "static inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void\nupdate_idle_rq_clock_pelt(struct rq *rq) { }"
        }
      }
    ],
    "contextual_snippet": "static inline void sched_info_dequeue(struct rq *rq, struct task_struct *t)\n{\n\tunsigned long long delta = 0;\n\n\tif (!t->sched_info.last_queued)\n\t\treturn;\n\n\tdelta = rq_clock(rq) - t->sched_info.last_queued;\n\tt->sched_info.last_queued = 0;\n\tt->sched_info.run_delay += delta;\n\n\trq_sched_info_dequeue(rq, delta);\n}"
  },
  {
    "function_name": "psi_sched_switch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "199-201",
    "snippet": "static inline void psi_sched_switch(struct task_struct *prev,\n\t\t\t\t    struct task_struct *next,\n\t\t\t\t    bool sleep) {}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void psi_sched_switch(struct task_struct *prev,\n\t\t\t\t    struct task_struct *next,\n\t\t\t\t    bool sleep) {}"
  },
  {
    "function_name": "psi_ttwu_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "198-198",
    "snippet": "static inline void psi_ttwu_dequeue(struct task_struct *p) {}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void psi_ttwu_dequeue(struct task_struct *p) {}"
  },
  {
    "function_name": "psi_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "197-197",
    "snippet": "static inline void psi_dequeue(struct task_struct *p, bool sleep) {}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void psi_dequeue(struct task_struct *p, bool sleep) {}"
  },
  {
    "function_name": "psi_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "196-196",
    "snippet": "static inline void psi_enqueue(struct task_struct *p, bool wakeup) {}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void psi_enqueue(struct task_struct *p, bool wakeup) {}"
  },
  {
    "function_name": "psi_sched_switch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "185-193",
    "snippet": "static inline void psi_sched_switch(struct task_struct *prev,\n\t\t\t\t    struct task_struct *next,\n\t\t\t\t    bool sleep)\n{\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\n\tpsi_task_switch(prev, next, sleep);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "psi_task_switch",
          "args": [
            "prev",
            "next",
            "sleep"
          ],
          "line": 192
        },
        "resolved": true,
        "details": {
          "function_name": "psi_task_switch",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/psi.c",
          "lines": "830-894",
          "snippet": "void psi_task_switch(struct task_struct *prev, struct task_struct *next,\n\t\t     bool sleep)\n{\n\tstruct psi_group *group, *common = NULL;\n\tint cpu = task_cpu(prev);\n\tvoid *iter;\n\tu64 now = cpu_clock(cpu);\n\n\tif (next->pid) {\n\t\tbool identical_state;\n\n\t\tpsi_flags_change(next, 0, TSK_ONCPU);\n\t\t/*\n\t\t * When switching between tasks that have an identical\n\t\t * runtime state, the cgroup that contains both tasks\n\t\t * we reach the first common ancestor. Iterate @next's\n\t\t * ancestors only until we encounter @prev's ONCPU.\n\t\t */\n\t\tidentical_state = prev->psi_flags == next->psi_flags;\n\t\titer = NULL;\n\t\twhile ((group = iterate_groups(next, &iter))) {\n\t\t\tif (identical_state &&\n\t\t\t    per_cpu_ptr(group->pcpu, cpu)->tasks[NR_ONCPU]) {\n\t\t\t\tcommon = group;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tpsi_group_change(group, cpu, 0, TSK_ONCPU, now, true);\n\t\t}\n\t}\n\n\tif (prev->pid) {\n\t\tint clear = TSK_ONCPU, set = 0;\n\n\t\t/*\n\t\t * When we're going to sleep, psi_dequeue() lets us\n\t\t * handle TSK_RUNNING, TSK_MEMSTALL_RUNNING and\n\t\t * TSK_IOWAIT here, where we can combine it with\n\t\t * TSK_ONCPU and save walking common ancestors twice.\n\t\t */\n\t\tif (sleep) {\n\t\t\tclear |= TSK_RUNNING;\n\t\t\tif (prev->in_memstall)\n\t\t\t\tclear |= TSK_MEMSTALL_RUNNING;\n\t\t\tif (prev->in_iowait)\n\t\t\t\tset |= TSK_IOWAIT;\n\t\t}\n\n\t\tpsi_flags_change(prev, clear, set);\n\n\t\titer = NULL;\n\t\twhile ((group = iterate_groups(prev, &iter)) && group != common)\n\t\t\tpsi_group_change(group, cpu, clear, set, now, true);\n\n\t\t/*\n\t\t * TSK_ONCPU is handled up to the common ancestor. If we're tasked\n\t\t * with dequeuing too, finish that for the rest of the hierarchy.\n\t\t */\n\t\tif (sleep) {\n\t\t\tclear &= ~TSK_ONCPU;\n\t\t\tfor (; group; group = iterate_groups(prev, &iter))\n\t\t\t\tpsi_group_change(group, cpu, clear, set, now, true);\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/psi.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/ctype.h>",
            "#include <linux/sched.h>",
            "#include <linux/module.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/loadavg.h>",
            "#include \"../workqueue_internal.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/psi.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/ctype.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/cgroup.h>\n#include <linux/uaccess.h>\n#include <linux/seqlock.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/sched/loadavg.h>\n#include \"../workqueue_internal.h\"\n\nvoid psi_task_switch(struct task_struct *prev, struct task_struct *next,\n\t\t     bool sleep)\n{\n\tstruct psi_group *group, *common = NULL;\n\tint cpu = task_cpu(prev);\n\tvoid *iter;\n\tu64 now = cpu_clock(cpu);\n\n\tif (next->pid) {\n\t\tbool identical_state;\n\n\t\tpsi_flags_change(next, 0, TSK_ONCPU);\n\t\t/*\n\t\t * When switching between tasks that have an identical\n\t\t * runtime state, the cgroup that contains both tasks\n\t\t * we reach the first common ancestor. Iterate @next's\n\t\t * ancestors only until we encounter @prev's ONCPU.\n\t\t */\n\t\tidentical_state = prev->psi_flags == next->psi_flags;\n\t\titer = NULL;\n\t\twhile ((group = iterate_groups(next, &iter))) {\n\t\t\tif (identical_state &&\n\t\t\t    per_cpu_ptr(group->pcpu, cpu)->tasks[NR_ONCPU]) {\n\t\t\t\tcommon = group;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tpsi_group_change(group, cpu, 0, TSK_ONCPU, now, true);\n\t\t}\n\t}\n\n\tif (prev->pid) {\n\t\tint clear = TSK_ONCPU, set = 0;\n\n\t\t/*\n\t\t * When we're going to sleep, psi_dequeue() lets us\n\t\t * handle TSK_RUNNING, TSK_MEMSTALL_RUNNING and\n\t\t * TSK_IOWAIT here, where we can combine it with\n\t\t * TSK_ONCPU and save walking common ancestors twice.\n\t\t */\n\t\tif (sleep) {\n\t\t\tclear |= TSK_RUNNING;\n\t\t\tif (prev->in_memstall)\n\t\t\t\tclear |= TSK_MEMSTALL_RUNNING;\n\t\t\tif (prev->in_iowait)\n\t\t\t\tset |= TSK_IOWAIT;\n\t\t}\n\n\t\tpsi_flags_change(prev, clear, set);\n\n\t\titer = NULL;\n\t\twhile ((group = iterate_groups(prev, &iter)) && group != common)\n\t\t\tpsi_group_change(group, cpu, clear, set, now, true);\n\n\t\t/*\n\t\t * TSK_ONCPU is handled up to the common ancestor. If we're tasked\n\t\t * with dequeuing too, finish that for the rest of the hierarchy.\n\t\t */\n\t\tif (sleep) {\n\t\t\tclear &= ~TSK_ONCPU;\n\t\t\tfor (; group; group = iterate_groups(prev, &iter))\n\t\t\t\tpsi_group_change(group, cpu, clear, set, now, true);\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "static_branch_likely",
          "args": [
            "&psi_disabled"
          ],
          "line": 189
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline void psi_sched_switch(struct task_struct *prev,\n\t\t\t\t    struct task_struct *next,\n\t\t\t\t    bool sleep)\n{\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\n\tpsi_task_switch(prev, next, sleep);\n}"
  },
  {
    "function_name": "psi_ttwu_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "159-183",
    "snippet": "static inline void psi_ttwu_dequeue(struct task_struct *p)\n{\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\t/*\n\t * Is the task being migrated during a wakeup? Make sure to\n\t * deregister its sleep-persistent psi states from the old\n\t * queue, and let psi_enqueue() know it has to requeue.\n\t */\n\tif (unlikely(p->in_iowait || p->in_memstall)) {\n\t\tstruct rq_flags rf;\n\t\tstruct rq *rq;\n\t\tint clear = 0;\n\n\t\tif (p->in_iowait)\n\t\t\tclear |= TSK_IOWAIT;\n\t\tif (p->in_memstall)\n\t\t\tclear |= TSK_MEMSTALL;\n\n\t\trq = __task_rq_lock(p, &rf);\n\t\tpsi_task_change(p, clear, 0);\n\t\tp->sched_psi_wake_requeue = 1;\n\t\t__task_rq_unlock(rq, &rf);\n\t}\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__task_rq_unlock",
          "args": [
            "rq",
            "&rf"
          ],
          "line": 181
        },
        "resolved": true,
        "details": {
          "function_name": "__task_rq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1579-1584",
          "snippet": "static inline void __task_rq_unlock(struct rq *rq, struct rq_flags *rf)\n\t__releases(rq->lock)\n{\n\trq_unpin_lock(rq, rf);\n\traw_spin_rq_unlock(rq);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "struct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);",
            "struct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);",
            "extern struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nstruct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock);\nstruct rq *task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(p->pi_lock)\n\t__acquires(rq->lock);\nextern struct task_struct *pick_next_task_fair(struct rq *rq, struct task_struct *prev, struct rq_flags *rf);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\n\nstatic inline void __task_rq_unlock(struct rq *rq, struct rq_flags *rf)\n\t__releases(rq->lock)\n{\n\trq_unpin_lock(rq, rf);\n\traw_spin_rq_unlock(rq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "psi_task_change",
          "args": [
            "p",
            "clear",
            "0"
          ],
          "line": 179
        },
        "resolved": true,
        "details": {
          "function_name": "psi_task_change",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/psi.c",
          "lines": "801-828",
          "snippet": "void psi_task_change(struct task_struct *task, int clear, int set)\n{\n\tint cpu = task_cpu(task);\n\tstruct psi_group *group;\n\tbool wake_clock = true;\n\tvoid *iter = NULL;\n\tu64 now;\n\n\tif (!task->pid)\n\t\treturn;\n\n\tpsi_flags_change(task, clear, set);\n\n\tnow = cpu_clock(cpu);\n\t/*\n\t * Periodic aggregation shuts off if there is a period of no\n\t * task changes, so we wake it back up if necessary. However,\n\t * don't do this if the task change is the aggregation worker\n\t * itself going to sleep, or we'll ping-pong forever.\n\t */\n\tif (unlikely((clear & TSK_RUNNING) &&\n\t\t     (task->flags & PF_WQ_WORKER) &&\n\t\t     wq_worker_last_func(task) == psi_avgs_work))\n\t\twake_clock = false;\n\n\twhile ((group = iterate_groups(task, &iter)))\n\t\tpsi_group_change(group, cpu, clear, set, now, wake_clock);\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/psi.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/ctype.h>",
            "#include <linux/sched.h>",
            "#include <linux/module.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/loadavg.h>",
            "#include \"../workqueue_internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void poll_timer_fn(struct timer_list *t);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/psi.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/ctype.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/cgroup.h>\n#include <linux/uaccess.h>\n#include <linux/seqlock.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/sched/loadavg.h>\n#include \"../workqueue_internal.h\"\n\nstatic void poll_timer_fn(struct timer_list *t);\n\nvoid psi_task_change(struct task_struct *task, int clear, int set)\n{\n\tint cpu = task_cpu(task);\n\tstruct psi_group *group;\n\tbool wake_clock = true;\n\tvoid *iter = NULL;\n\tu64 now;\n\n\tif (!task->pid)\n\t\treturn;\n\n\tpsi_flags_change(task, clear, set);\n\n\tnow = cpu_clock(cpu);\n\t/*\n\t * Periodic aggregation shuts off if there is a period of no\n\t * task changes, so we wake it back up if necessary. However,\n\t * don't do this if the task change is the aggregation worker\n\t * itself going to sleep, or we'll ping-pong forever.\n\t */\n\tif (unlikely((clear & TSK_RUNNING) &&\n\t\t     (task->flags & PF_WQ_WORKER) &&\n\t\t     wq_worker_last_func(task) == psi_avgs_work))\n\t\twake_clock = false;\n\n\twhile ((group = iterate_groups(task, &iter)))\n\t\tpsi_group_change(group, cpu, clear, set, now, wake_clock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__task_rq_lock",
          "args": [
            "p",
            "&rf"
          ],
          "line": 178
        },
        "resolved": true,
        "details": {
          "function_name": "__task_rq_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "558-577",
          "snippet": "struct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock)\n{\n\tstruct rq *rq;\n\n\tlockdep_assert_held(&p->pi_lock);\n\n\tfor (;;) {\n\t\trq = task_rq(p);\n\t\traw_spin_rq_lock(rq);\n\t\tif (likely(rq == task_rq(p) && !task_on_rq_migrating(p))) {\n\t\t\trq_pin_lock(rq, rf);\n\t\t\treturn rq;\n\t\t}\n\t\traw_spin_rq_unlock(rq);\n\n\t\twhile (unlikely(task_on_rq_migrating(p)))\n\t\t\tcpu_relax();\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nstruct rq *__task_rq_lock(struct task_struct *p, struct rq_flags *rf)\n\t__acquires(rq->lock)\n{\n\tstruct rq *rq;\n\n\tlockdep_assert_held(&p->pi_lock);\n\n\tfor (;;) {\n\t\trq = task_rq(p);\n\t\traw_spin_rq_lock(rq);\n\t\tif (likely(rq == task_rq(p) && !task_on_rq_migrating(p))) {\n\t\t\trq_pin_lock(rq, rf);\n\t\t\treturn rq;\n\t\t}\n\t\traw_spin_rq_unlock(rq);\n\n\t\twhile (unlikely(task_on_rq_migrating(p)))\n\t\t\tcpu_relax();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "p->in_iowait || p->in_memstall"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "static_branch_likely",
          "args": [
            "&psi_disabled"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline void psi_ttwu_dequeue(struct task_struct *p)\n{\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\t/*\n\t * Is the task being migrated during a wakeup? Make sure to\n\t * deregister its sleep-persistent psi states from the old\n\t * queue, and let psi_enqueue() know it has to requeue.\n\t */\n\tif (unlikely(p->in_iowait || p->in_memstall)) {\n\t\tstruct rq_flags rf;\n\t\tstruct rq *rq;\n\t\tint clear = 0;\n\n\t\tif (p->in_iowait)\n\t\t\tclear |= TSK_IOWAIT;\n\t\tif (p->in_memstall)\n\t\t\tclear |= TSK_MEMSTALL;\n\n\t\trq = __task_rq_lock(p, &rf);\n\t\tpsi_task_change(p, clear, 0);\n\t\tp->sched_psi_wake_requeue = 1;\n\t\t__task_rq_unlock(rq, &rf);\n\t}\n}"
  },
  {
    "function_name": "psi_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "137-157",
    "snippet": "static inline void psi_dequeue(struct task_struct *p, bool sleep)\n{\n\tint clear = TSK_RUNNING;\n\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\n\t/*\n\t * A voluntary sleep is a dequeue followed by a task switch. To\n\t * avoid walking all ancestors twice, psi_task_switch() handles\n\t * TSK_RUNNING and TSK_IOWAIT for us when it moves TSK_ONCPU.\n\t * Do nothing here.\n\t */\n\tif (sleep)\n\t\treturn;\n\n\tif (p->in_memstall)\n\t\tclear |= (TSK_MEMSTALL | TSK_MEMSTALL_RUNNING);\n\n\tpsi_task_change(p, clear, 0);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "psi_task_change",
          "args": [
            "p",
            "clear",
            "0"
          ],
          "line": 156
        },
        "resolved": true,
        "details": {
          "function_name": "psi_task_change",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/psi.c",
          "lines": "801-828",
          "snippet": "void psi_task_change(struct task_struct *task, int clear, int set)\n{\n\tint cpu = task_cpu(task);\n\tstruct psi_group *group;\n\tbool wake_clock = true;\n\tvoid *iter = NULL;\n\tu64 now;\n\n\tif (!task->pid)\n\t\treturn;\n\n\tpsi_flags_change(task, clear, set);\n\n\tnow = cpu_clock(cpu);\n\t/*\n\t * Periodic aggregation shuts off if there is a period of no\n\t * task changes, so we wake it back up if necessary. However,\n\t * don't do this if the task change is the aggregation worker\n\t * itself going to sleep, or we'll ping-pong forever.\n\t */\n\tif (unlikely((clear & TSK_RUNNING) &&\n\t\t     (task->flags & PF_WQ_WORKER) &&\n\t\t     wq_worker_last_func(task) == psi_avgs_work))\n\t\twake_clock = false;\n\n\twhile ((group = iterate_groups(task, &iter)))\n\t\tpsi_group_change(group, cpu, clear, set, now, wake_clock);\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/psi.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/ctype.h>",
            "#include <linux/sched.h>",
            "#include <linux/module.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/loadavg.h>",
            "#include \"../workqueue_internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void poll_timer_fn(struct timer_list *t);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/psi.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/ctype.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/cgroup.h>\n#include <linux/uaccess.h>\n#include <linux/seqlock.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/sched/loadavg.h>\n#include \"../workqueue_internal.h\"\n\nstatic void poll_timer_fn(struct timer_list *t);\n\nvoid psi_task_change(struct task_struct *task, int clear, int set)\n{\n\tint cpu = task_cpu(task);\n\tstruct psi_group *group;\n\tbool wake_clock = true;\n\tvoid *iter = NULL;\n\tu64 now;\n\n\tif (!task->pid)\n\t\treturn;\n\n\tpsi_flags_change(task, clear, set);\n\n\tnow = cpu_clock(cpu);\n\t/*\n\t * Periodic aggregation shuts off if there is a period of no\n\t * task changes, so we wake it back up if necessary. However,\n\t * don't do this if the task change is the aggregation worker\n\t * itself going to sleep, or we'll ping-pong forever.\n\t */\n\tif (unlikely((clear & TSK_RUNNING) &&\n\t\t     (task->flags & PF_WQ_WORKER) &&\n\t\t     wq_worker_last_func(task) == psi_avgs_work))\n\t\twake_clock = false;\n\n\twhile ((group = iterate_groups(task, &iter)))\n\t\tpsi_group_change(group, cpu, clear, set, now, wake_clock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "static_branch_likely",
          "args": [
            "&psi_disabled"
          ],
          "line": 141
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline void psi_dequeue(struct task_struct *p, bool sleep)\n{\n\tint clear = TSK_RUNNING;\n\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\n\t/*\n\t * A voluntary sleep is a dequeue followed by a task switch. To\n\t * avoid walking all ancestors twice, psi_task_switch() handles\n\t * TSK_RUNNING and TSK_IOWAIT for us when it moves TSK_ONCPU.\n\t * Do nothing here.\n\t */\n\tif (sleep)\n\t\treturn;\n\n\tif (p->in_memstall)\n\t\tclear |= (TSK_MEMSTALL | TSK_MEMSTALL_RUNNING);\n\n\tpsi_task_change(p, clear, 0);\n}"
  },
  {
    "function_name": "psi_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "114-135",
    "snippet": "static inline void psi_enqueue(struct task_struct *p, bool wakeup)\n{\n\tint clear = 0, set = TSK_RUNNING;\n\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\n\tif (p->in_memstall)\n\t\tset |= TSK_MEMSTALL_RUNNING;\n\n\tif (!wakeup || p->sched_psi_wake_requeue) {\n\t\tif (p->in_memstall)\n\t\t\tset |= TSK_MEMSTALL;\n\t\tif (p->sched_psi_wake_requeue)\n\t\t\tp->sched_psi_wake_requeue = 0;\n\t} else {\n\t\tif (p->in_iowait)\n\t\t\tclear |= TSK_IOWAIT;\n\t}\n\n\tpsi_task_change(p, clear, set);\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "psi_task_change",
          "args": [
            "p",
            "clear",
            "set"
          ],
          "line": 134
        },
        "resolved": true,
        "details": {
          "function_name": "psi_task_change",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/psi.c",
          "lines": "801-828",
          "snippet": "void psi_task_change(struct task_struct *task, int clear, int set)\n{\n\tint cpu = task_cpu(task);\n\tstruct psi_group *group;\n\tbool wake_clock = true;\n\tvoid *iter = NULL;\n\tu64 now;\n\n\tif (!task->pid)\n\t\treturn;\n\n\tpsi_flags_change(task, clear, set);\n\n\tnow = cpu_clock(cpu);\n\t/*\n\t * Periodic aggregation shuts off if there is a period of no\n\t * task changes, so we wake it back up if necessary. However,\n\t * don't do this if the task change is the aggregation worker\n\t * itself going to sleep, or we'll ping-pong forever.\n\t */\n\tif (unlikely((clear & TSK_RUNNING) &&\n\t\t     (task->flags & PF_WQ_WORKER) &&\n\t\t     wq_worker_last_func(task) == psi_avgs_work))\n\t\twake_clock = false;\n\n\twhile ((group = iterate_groups(task, &iter)))\n\t\tpsi_group_change(group, cpu, clear, set, now, wake_clock);\n}",
          "includes": [
            "#include \"sched.h\"",
            "#include <linux/psi.h>",
            "#include <linux/poll.h>",
            "#include <linux/file.h>",
            "#include <linux/ctype.h>",
            "#include <linux/sched.h>",
            "#include <linux/module.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/loadavg.h>",
            "#include \"../workqueue_internal.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static void poll_timer_fn(struct timer_list *t);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n#include <linux/psi.h>\n#include <linux/poll.h>\n#include <linux/file.h>\n#include <linux/ctype.h>\n#include <linux/sched.h>\n#include <linux/module.h>\n#include <linux/cgroup.h>\n#include <linux/uaccess.h>\n#include <linux/seqlock.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/sched/loadavg.h>\n#include \"../workqueue_internal.h\"\n\nstatic void poll_timer_fn(struct timer_list *t);\n\nvoid psi_task_change(struct task_struct *task, int clear, int set)\n{\n\tint cpu = task_cpu(task);\n\tstruct psi_group *group;\n\tbool wake_clock = true;\n\tvoid *iter = NULL;\n\tu64 now;\n\n\tif (!task->pid)\n\t\treturn;\n\n\tpsi_flags_change(task, clear, set);\n\n\tnow = cpu_clock(cpu);\n\t/*\n\t * Periodic aggregation shuts off if there is a period of no\n\t * task changes, so we wake it back up if necessary. However,\n\t * don't do this if the task change is the aggregation worker\n\t * itself going to sleep, or we'll ping-pong forever.\n\t */\n\tif (unlikely((clear & TSK_RUNNING) &&\n\t\t     (task->flags & PF_WQ_WORKER) &&\n\t\t     wq_worker_last_func(task) == psi_avgs_work))\n\t\twake_clock = false;\n\n\twhile ((group = iterate_groups(task, &iter)))\n\t\tpsi_group_change(group, cpu, clear, set, now, wake_clock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "static_branch_likely",
          "args": [
            "&psi_disabled"
          ],
          "line": 118
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline void psi_enqueue(struct task_struct *p, bool wakeup)\n{\n\tint clear = 0, set = TSK_RUNNING;\n\n\tif (static_branch_likely(&psi_disabled))\n\t\treturn;\n\n\tif (p->in_memstall)\n\t\tset |= TSK_MEMSTALL_RUNNING;\n\n\tif (!wakeup || p->sched_psi_wake_requeue) {\n\t\tif (p->in_memstall)\n\t\t\tset |= TSK_MEMSTALL;\n\t\tif (p->sched_psi_wake_requeue)\n\t\t\tp->sched_psi_wake_requeue = 0;\n\t} else {\n\t\tif (p->in_iowait)\n\t\t\tclear |= TSK_IOWAIT;\n\t}\n\n\tpsi_task_change(p, clear, set);\n}"
  },
  {
    "function_name": "__schedstats_from_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "97-105",
    "snippet": "static inline struct sched_statistics *\n__schedstats_from_se(struct sched_entity *se)\n{\n#ifdef CONFIG_FAIR_GROUP_SCHED\n\tif (!entity_is_task(se))\n\t\treturn &container_of(se, struct sched_entity_stats, se)->stats;\n#endif\n\treturn &task_of(se)->stats;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "task_of",
          "args": [
            "se"
          ],
          "line": 104
        },
        "resolved": true,
        "details": {
          "function_name": "rt_task_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/rt.c",
          "lines": "238-241",
          "snippet": "static inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "DEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nDEFINE_SCHED_CLASS(rt) = {\n\n\t.enqueue_task\t\t= enqueue_task_rt,\n\t.dequeue_task\t\t= dequeue_task_rt,\n\t.yield_task\t\t= yield_task_rt,\n\n\t.check_preempt_curr\t= check_preempt_curr_rt,\n\n\t.pick_next_task\t\t= pick_next_task_rt,\n\t.put_prev_task\t\t= put_prev_task_rt,\n\t.set_next_task          = set_next_task_rt,\n\n#ifdef CONFIG_SMP\n\t.balance\t\t= balance_rt,\n\t.pick_task\t\t= pick_task_rt,\n\t.select_task_rq\t\t= select_task_rq_rt,\n\t.set_cpus_allowed       = set_cpus_allowed_common,\n\t.rq_online              = rq_online_rt,\n\t.rq_offline             = rq_offline_rt,\n\t.task_woken\t\t= task_woken_rt,\n\t.switched_from\t\t= switched_from_rt,\n\t.find_lock_rq\t\t= find_lock_lowest_rq,\n#endif\n\n\t.task_tick\t\t= task_tick_rt,\n\n\t.get_rr_interval\t= get_rr_interval_rt,\n\n\t.prio_changed\t\t= prio_changed_rt,\n\t.switched_to\t\t= switched_to_rt,\n\n\t.update_curr\t\t= update_curr_rt,\n\n#ifdef CONFIG_UCLAMP_TASK\n\t.uclamp_enabled\t\t= 1,\n#endif\n};\n\nstatic inline struct task_struct *rt_task_of(struct sched_rt_entity *rt_se)\n{\n\treturn container_of(rt_se, struct task_struct, rt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "se",
            "structsched_entity_stats",
            "se"
          ],
          "line": 102
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "entity_is_task",
          "args": [
            "se"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "static inline struct sched_statistics *\n__schedstats_from_se(struct sched_entity *se)\n{\n#ifdef CONFIG_FAIR_GROUP_SCHED\n\tif (!entity_is_task(se))\n\t\treturn &container_of(se, struct sched_entity_stats, se)->stats;\n#endif\n\treturn &task_of(se)->stats;\n}"
  },
  {
    "function_name": "rq_sched_info_depart",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "72-72",
    "snippet": "static inline void rq_sched_info_depart  (struct rq *rq, unsigned long long delta) { }",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void rq_sched_info_depart  (struct rq *rq, unsigned long long delta) { }"
  },
  {
    "function_name": "rq_sched_info_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "71-71",
    "snippet": "static inline void rq_sched_info_dequeue(struct rq *rq, unsigned long long delta) { }",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void rq_sched_info_dequeue(struct rq *rq, unsigned long long delta) { }"
  },
  {
    "function_name": "rq_sched_info_arrive",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "70-70",
    "snippet": "static inline void rq_sched_info_arrive  (struct rq *rq, unsigned long long delta) { }",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void rq_sched_info_arrive  (struct rq *rq, unsigned long long delta) { }"
  },
  {
    "function_name": "check_schedstat_required",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "53-66",
    "snippet": "static inline void\ncheck_schedstat_required(void)\n{\n\tif (schedstat_enabled())\n\t\treturn;\n\n\t/* Force schedstat enabled if a dependent tracepoint is active */\n\tif (trace_sched_stat_wait_enabled()    ||\n\t    trace_sched_stat_sleep_enabled()   ||\n\t    trace_sched_stat_iowait_enabled()  ||\n\t    trace_sched_stat_blocked_enabled() ||\n\t    trace_sched_stat_runtime_enabled())\n\t\tprintk_deferred_once(\"Scheduler tracepoints stat_sleep, stat_iowait, stat_blocked and stat_runtime require the kernel parameter schedstats=enable or kernel.sched_schedstats=1\\n\");\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "printk_deferred_once",
          "args": [
            "\"Scheduler tracepoints stat_sleep, stat_iowait, stat_blocked and stat_runtime require the kernel parameter schedstats=enable or kernel.sched_schedstats=1\\n\""
          ],
          "line": 65
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_sched_stat_runtime_enabled",
          "args": [],
          "line": 64
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_sched_stat_blocked_enabled",
          "args": [],
          "line": 63
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_sched_stat_iowait_enabled",
          "args": [],
          "line": 62
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_sched_stat_sleep_enabled",
          "args": [],
          "line": 61
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_sched_stat_wait_enabled",
          "args": [],
          "line": 60
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedstat_enabled",
          "args": [],
          "line": 56
        },
        "resolved": true,
        "details": {
          "function_name": "force_schedstat_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4325-4331",
          "snippet": "void force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nvoid force_schedstat_enabled(void)\n{\n\tif (!schedstat_enabled()) {\n\t\tpr_info(\"kernel profiling enabled schedstats, disable via kernel.sched_schedstats.\\n\");\n\t\tstatic_branch_enable(&sched_schedstats);\n\t}\n}"
        }
      }
    ],
    "contextual_snippet": "static inline void\ncheck_schedstat_required(void)\n{\n\tif (schedstat_enabled())\n\t\treturn;\n\n\t/* Force schedstat enabled if a dependent tracepoint is active */\n\tif (trace_sched_stat_wait_enabled()    ||\n\t    trace_sched_stat_sleep_enabled()   ||\n\t    trace_sched_stat_iowait_enabled()  ||\n\t    trace_sched_stat_blocked_enabled() ||\n\t    trace_sched_stat_runtime_enabled())\n\t\tprintk_deferred_once(\"Scheduler tracepoints stat_sleep, stat_iowait, stat_blocked and stat_runtime require the kernel parameter schedstats=enable or kernel.sched_schedstats=1\\n\");\n}"
  },
  {
    "function_name": "rq_sched_info_dequeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "29-34",
    "snippet": "static inline void\nrq_sched_info_dequeue(struct rq *rq, unsigned long long delta)\n{\n\tif (rq)\n\t\trq->rq_sched_info.run_delay += delta;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void\nrq_sched_info_dequeue(struct rq *rq, unsigned long long delta)\n{\n\tif (rq)\n\t\trq->rq_sched_info.run_delay += delta;\n}"
  },
  {
    "function_name": "rq_sched_info_depart",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "22-27",
    "snippet": "static inline void\nrq_sched_info_depart(struct rq *rq, unsigned long long delta)\n{\n\tif (rq)\n\t\trq->rq_cpu_time += delta;\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void\nrq_sched_info_depart(struct rq *rq, unsigned long long delta)\n{\n\tif (rq)\n\t\trq->rq_cpu_time += delta;\n}"
  },
  {
    "function_name": "rq_sched_info_arrive",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/stats.h",
    "lines": "10-17",
    "snippet": "static inline void\nrq_sched_info_arrive(struct rq *rq, unsigned long long delta)\n{\n\tif (rq) {\n\t\trq->rq_sched_info.run_delay += delta;\n\t\trq->rq_sched_info.pcount++;\n\t}\n}",
    "includes": [],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "static inline void\nrq_sched_info_arrive(struct rq *rq, unsigned long long delta)\n{\n\tif (rq) {\n\t\trq->rq_sched_info.run_delay += delta;\n\t\trq->rq_sched_info.pcount++;\n\t}\n}"
  }
]