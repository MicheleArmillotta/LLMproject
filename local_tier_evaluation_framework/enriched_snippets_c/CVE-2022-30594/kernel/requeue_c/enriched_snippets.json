[
  {
    "function_name": "futex_wait_requeue_pi",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "762-896",
    "snippet": "int futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,\n\t\t\t  u32 val, ktime_t *abs_time, u32 bitset,\n\t\t\t  u32 __user *uaddr2)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct futex_hash_bucket *hb;\n\tunion futex_key key2 = FUTEX_KEY_INIT;\n\tstruct futex_q q = futex_q_init;\n\tstruct rt_mutex_base *pi_mutex;\n\tint res, ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\n\tif (uaddr == uaddr2)\n\t\treturn -EINVAL;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tto = futex_setup_timer(abs_time, &timeout, flags,\n\t\t\t       current->timer_slack_ns);\n\n\t/*\n\t * The waiter is allocated on our stack, manipulated by the requeue\n\t * code while we sleep on uaddr.\n\t */\n\trt_mutex_init_waiter(&rt_waiter);\n\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\n\tq.bitset = bitset;\n\tq.rt_waiter = &rt_waiter;\n\tq.requeue_pi_key = &key2;\n\n\t/*\n\t * Prepare to wait on uaddr. On success, it holds hb->lock and q\n\t * is initialized.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (futex_match(&q.key, &key2)) {\n\t\tfutex_q_unlock(hb);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */\n\tfutex_wait_queue(hb, &q, to);\n\n\tswitch (futex_requeue_pi_wakeup_sync(&q)) {\n\tcase Q_REQUEUE_PI_IGNORE:\n\t\t/* The waiter is still on uaddr1 */\n\t\tspin_lock(&hb->lock);\n\t\tret = handle_early_requeue_pi_wakeup(hb, &q, to);\n\t\tspin_unlock(&hb->lock);\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_LOCKED:\n\t\t/* The requeue acquired the lock */\n\t\tif (q.pi_state && (q.pi_state->owner != current)) {\n\t\t\tspin_lock(q.lock_ptr);\n\t\t\tret = fixup_pi_owner(uaddr2, &q, true);\n\t\t\t/*\n\t\t\t * Drop the reference to the pi state which the\n\t\t\t * requeue_pi() code acquired for us.\n\t\t\t */\n\t\t\tput_pi_state(q.pi_state);\n\t\t\tspin_unlock(q.lock_ptr);\n\t\t\t/*\n\t\t\t * Adjust the return value. It's either -EFAULT or\n\t\t\t * success (1) but the caller expects 0 for success.\n\t\t\t */\n\t\t\tret = ret < 0 ? ret : 0;\n\t\t}\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_DONE:\n\t\t/* Requeue completed. Current is 'pi_blocked_on' the rtmutex */\n\t\tpi_mutex = &q.pi_state->pi_mutex;\n\t\tret = rt_mutex_wait_proxy_lock(pi_mutex, to, &rt_waiter);\n\n\t\t/* Current is not longer pi_blocked_on */\n\t\tspin_lock(q.lock_ptr);\n\t\tif (ret && !rt_mutex_cleanup_proxy_lock(pi_mutex, &rt_waiter))\n\t\t\tret = 0;\n\n\t\tdebug_rt_mutex_free_waiter(&rt_waiter);\n\t\t/*\n\t\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t\t * haven't already.\n\t\t */\n\t\tres = fixup_pi_owner(uaddr2, &q, !ret);\n\t\t/*\n\t\t * If fixup_pi_owner() returned an error, propagate that.  If it\n\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.\n\t\t */\n\t\tif (res)\n\t\t\tret = (res < 0) ? res : 0;\n\n\t\tfutex_unqueue_pi(&q);\n\t\tspin_unlock(q.lock_ptr);\n\n\t\tif (ret == -EINTR) {\n\t\t\t/*\n\t\t\t * We've already been requeued, but cannot restart\n\t\t\t * by calling futex_lock_pi() directly. We could\n\t\t\t * restart this syscall, but it would detect that\n\t\t\t * the user space \"val\" changed and return\n\t\t\t * -EWOULDBLOCK.  Save the overhead of the restart\n\t\t\t * and return -EWOULDBLOCK directly.\n\t\t\t */\n\t\t\tret = -EWOULDBLOCK;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "const struct futex_q futex_q_init = {\n\t/* list gets initialized in futex_queue()*/\n\t.key\t\t= FUTEX_KEY_INIT,\n\t.bitset\t\t= FUTEX_BITSET_MATCH_ANY,\n\t.requeue_state\t= ATOMIC_INIT(Q_REQUEUE_PI_NONE),\n};"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "destroy_hrtimer_on_stack",
          "args": [
            "&to->timer"
          ],
          "line": 893
        },
        "resolved": true,
        "details": {
          "function_name": "destroy_hrtimer_on_stack",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/hrtimer.c",
          "lines": "450-453",
          "snippet": "void destroy_hrtimer_on_stack(struct hrtimer *timer)\n{\n\tdebug_object_free(timer, &hrtimer_debug_descr);\n}",
          "includes": [
            "#include \"tick-internal.h\"",
            "#include <trace/events/timer.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/freezer.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/debugobjects.h>",
            "#include <linux/err.h>",
            "#include <linux/tick.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/notifier.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tick-internal.h\"\n#include <trace/events/timer.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/freezer.h>\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/debugobjects.h>\n#include <linux/err.h>\n#include <linux/tick.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/notifier.h>\n#include <linux/hrtimer.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n\nvoid destroy_hrtimer_on_stack(struct hrtimer *timer)\n{\n\tdebug_object_free(timer, &hrtimer_debug_descr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "hrtimer_cancel",
          "args": [
            "&to->timer"
          ],
          "line": 892
        },
        "resolved": true,
        "details": {
          "function_name": "hrtimer_cancel",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/hrtimer.c",
          "lines": "1438-1449",
          "snippet": "int hrtimer_cancel(struct hrtimer *timer)\n{\n\tint ret;\n\n\tdo {\n\t\tret = hrtimer_try_to_cancel(timer);\n\n\t\tif (ret < 0)\n\t\t\thrtimer_cancel_wait_running(timer);\n\t} while (ret < 0);\n\treturn ret;\n}",
          "includes": [
            "#include \"tick-internal.h\"",
            "#include <trace/events/timer.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/compat.h>",
            "#include <linux/freezer.h>",
            "#include <linux/timer.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/debugobjects.h>",
            "#include <linux/err.h>",
            "#include <linux/tick.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/notifier.h>",
            "#include <linux/hrtimer.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tick-internal.h\"\n#include <trace/events/timer.h>\n#include <linux/uaccess.h>\n#include <linux/compat.h>\n#include <linux/freezer.h>\n#include <linux/timer.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/debugobjects.h>\n#include <linux/err.h>\n#include <linux/tick.h>\n#include <linux/interrupt.h>\n#include <linux/syscalls.h>\n#include <linux/notifier.h>\n#include <linux/hrtimer.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/cpu.h>\n\nint hrtimer_cancel(struct hrtimer *timer)\n{\n\tint ret;\n\n\tdo {\n\t\tret = hrtimer_try_to_cancel(timer);\n\n\t\tif (ret < 0)\n\t\t\thrtimer_cancel_wait_running(timer);\n\t} while (ret < 0);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG",
          "args": [],
          "line": 887
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "q.lock_ptr"
          ],
          "line": 872
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_unqueue_pi",
          "args": [
            "&q"
          ],
          "line": 871
        },
        "resolved": true,
        "details": {
          "function_name": "futex_unqueue_pi",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "620-627",
          "snippet": "void futex_unqueue_pi(struct futex_q *q)\n{\n\t__futex_unqueue(q);\n\n\tBUG_ON(!q->pi_state);\n\tput_pi_state(q->pi_state);\n\tq->pi_state = NULL;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nvoid futex_unqueue_pi(struct futex_q *q)\n{\n\t__futex_unqueue(q);\n\n\tBUG_ON(!q->pi_state);\n\tput_pi_state(q->pi_state);\n\tq->pi_state = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "fixup_pi_owner",
          "args": [
            "uaddr2",
            "&q",
            "!ret"
          ],
          "line": 863
        },
        "resolved": true,
        "details": {
          "function_name": "fixup_pi_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "884-919",
          "snippet": "int fixup_pi_owner(u32 __user *uaddr, struct futex_q *q, int locked)\n{\n\tif (locked) {\n\t\t/*\n\t\t * Got the lock. We might not be the anticipated owner if we\n\t\t * did a lock-steal - fix up the PI-state in that case:\n\t\t *\n\t\t * Speculative pi_state->owner read (we don't hold wait_lock);\n\t\t * since we own the lock pi_state->owner == current is the\n\t\t * stable state, anything else needs more attention.\n\t\t */\n\t\tif (q->pi_state->owner != current)\n\t\t\treturn fixup_pi_state_owner(uaddr, q, current);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * If we didn't get the lock; check if anybody stole it from us. In\n\t * that case, we need to fix up the uval to point to them instead of\n\t * us, otherwise bad things happen. [10]\n\t *\n\t * Another speculative read; pi_state->owner == current is unstable\n\t * but needs our attention.\n\t */\n\tif (q->pi_state->owner == current)\n\t\treturn fixup_pi_state_owner(uaddr, q, NULL);\n\n\t/*\n\t * Paranoia check. If we did not take the lock, then we should not be\n\t * the owner of the rt_mutex. Warn and establish consistent state.\n\t */\n\tif (WARN_ON_ONCE(rt_mutex_owner(&q->pi_state->pi_mutex) == current))\n\t\treturn fixup_pi_state_owner(uaddr, q, current);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nint fixup_pi_owner(u32 __user *uaddr, struct futex_q *q, int locked)\n{\n\tif (locked) {\n\t\t/*\n\t\t * Got the lock. We might not be the anticipated owner if we\n\t\t * did a lock-steal - fix up the PI-state in that case:\n\t\t *\n\t\t * Speculative pi_state->owner read (we don't hold wait_lock);\n\t\t * since we own the lock pi_state->owner == current is the\n\t\t * stable state, anything else needs more attention.\n\t\t */\n\t\tif (q->pi_state->owner != current)\n\t\t\treturn fixup_pi_state_owner(uaddr, q, current);\n\t\treturn 1;\n\t}\n\n\t/*\n\t * If we didn't get the lock; check if anybody stole it from us. In\n\t * that case, we need to fix up the uval to point to them instead of\n\t * us, otherwise bad things happen. [10]\n\t *\n\t * Another speculative read; pi_state->owner == current is unstable\n\t * but needs our attention.\n\t */\n\tif (q->pi_state->owner == current)\n\t\treturn fixup_pi_state_owner(uaddr, q, NULL);\n\n\t/*\n\t * Paranoia check. If we did not take the lock, then we should not be\n\t * the owner of the rt_mutex. Warn and establish consistent state.\n\t */\n\tif (WARN_ON_ONCE(rt_mutex_owner(&q->pi_state->pi_mutex) == current))\n\t\treturn fixup_pi_state_owner(uaddr, q, current);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "debug_rt_mutex_free_waiter",
          "args": [
            "&rt_waiter"
          ],
          "line": 858
        },
        "resolved": true,
        "details": {
          "function_name": "debug_rt_mutex_free_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_common.h",
          "lines": "184-188",
          "snippet": "static inline void debug_rt_mutex_free_waiter(struct rt_mutex_waiter *waiter)\n{\n\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES))\n\t\tmemset(waiter, 0x22, sizeof(*waiter));\n}",
          "includes": [
            "#include <linux/sched/wake_q.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/wake_q.h>\n#include <linux/rtmutex.h>\n#include <linux/debug_locks.h>\n\nstatic inline void debug_rt_mutex_free_waiter(struct rt_mutex_waiter *waiter)\n{\n\tif (IS_ENABLED(CONFIG_DEBUG_RT_MUTEXES))\n\t\tmemset(waiter, 0x22, sizeof(*waiter));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_mutex_cleanup_proxy_lock",
          "args": [
            "pi_mutex",
            "&rt_waiter"
          ],
          "line": 855
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_cleanup_proxy_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "411-446",
          "snippet": "bool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t\t struct rt_mutex_waiter *waiter)\n{\n\tbool cleanup = false;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\t/*\n\t * Do an unconditional try-lock, this deals with the lock stealing\n\t * state where __rt_mutex_futex_unlock() -> mark_wakeup_next_waiter()\n\t * sets a NULL owner.\n\t *\n\t * We're not interested in the return value, because the subsequent\n\t * test on rt_mutex_owner() will infer that. If the trylock succeeded,\n\t * we will own the lock and it will have removed the waiter. If we\n\t * failed the trylock, we're still not owner and we need to remove\n\t * ourselves.\n\t */\n\ttry_to_take_rt_mutex(lock, current, waiter);\n\t/*\n\t * Unless we're the owner; we're still enqueued on the wait_list.\n\t * So check if we became owner, if not, take us off the wait_list.\n\t */\n\tif (rt_mutex_owner(lock) != current) {\n\t\tremove_waiter(lock, waiter);\n\t\tcleanup = true;\n\t}\n\t/*\n\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might\n\t * have to fix that up.\n\t */\n\tfixup_rt_mutex_waiters(lock);\n\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn cleanup;\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nbool __sched rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t\t struct rt_mutex_waiter *waiter)\n{\n\tbool cleanup = false;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\t/*\n\t * Do an unconditional try-lock, this deals with the lock stealing\n\t * state where __rt_mutex_futex_unlock() -> mark_wakeup_next_waiter()\n\t * sets a NULL owner.\n\t *\n\t * We're not interested in the return value, because the subsequent\n\t * test on rt_mutex_owner() will infer that. If the trylock succeeded,\n\t * we will own the lock and it will have removed the waiter. If we\n\t * failed the trylock, we're still not owner and we need to remove\n\t * ourselves.\n\t */\n\ttry_to_take_rt_mutex(lock, current, waiter);\n\t/*\n\t * Unless we're the owner; we're still enqueued on the wait_list.\n\t * So check if we became owner, if not, take us off the wait_list.\n\t */\n\tif (rt_mutex_owner(lock) != current) {\n\t\tremove_waiter(lock, waiter);\n\t\tcleanup = true;\n\t}\n\t/*\n\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might\n\t * have to fix that up.\n\t */\n\tfixup_rt_mutex_waiters(lock);\n\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn cleanup;\n}"
        }
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "q.lock_ptr"
          ],
          "line": 854
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_mutex_wait_proxy_lock",
          "args": [
            "pi_mutex",
            "to",
            "&rt_waiter"
          ],
          "line": 851
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wait_proxy_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "371-389",
          "snippet": "int __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t     struct hrtimer_sleeper *to,\n\t\t\t\t     struct rt_mutex_waiter *waiter)\n{\n\tint ret;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\t/* sleep on the mutex */\n\tset_current_state(TASK_INTERRUPTIBLE);\n\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);\n\t/*\n\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might\n\t * have to fix that up.\n\t */\n\tfixup_rt_mutex_waiters(lock);\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t     struct hrtimer_sleeper *to,\n\t\t\t\t     struct rt_mutex_waiter *waiter)\n{\n\tint ret;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\t/* sleep on the mutex */\n\tset_current_state(TASK_INTERRUPTIBLE);\n\tret = rt_mutex_slowlock_block(lock, NULL, TASK_INTERRUPTIBLE, to, waiter);\n\t/*\n\t * try_to_take_rt_mutex() sets the waiter bit unconditionally. We might\n\t * have to fix that up.\n\t */\n\tfixup_rt_mutex_waiters(lock);\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_pi_state",
          "args": [
            "q.pi_state"
          ],
          "line": 838
        },
        "resolved": true,
        "details": {
          "function_name": "put_pi_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "77-110",
          "snippet": "void put_pi_state(struct futex_pi_state *pi_state)\n{\n\tif (!pi_state)\n\t\treturn;\n\n\tif (!refcount_dec_and_test(&pi_state->refcount))\n\t\treturn;\n\n\t/*\n\t * If pi_state->owner is NULL, the owner is most probably dying\n\t * and has cleaned up the pi_state already\n\t */\n\tif (pi_state->owner) {\n\t\tunsigned long flags;\n\n\t\traw_spin_lock_irqsave(&pi_state->pi_mutex.wait_lock, flags);\n\t\tpi_state_update_owner(pi_state, NULL);\n\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex);\n\t\traw_spin_unlock_irqrestore(&pi_state->pi_mutex.wait_lock, flags);\n\t}\n\n\tif (current->pi_state_cache) {\n\t\tkfree(pi_state);\n\t} else {\n\t\t/*\n\t\t * pi_state->list is already empty.\n\t\t * clear pi_state->owner.\n\t\t * refcount is at 0 - put it back to 1.\n\t\t */\n\t\tpi_state->owner = NULL;\n\t\trefcount_set(&pi_state->refcount, 1);\n\t\tcurrent->pi_state_cache = pi_state;\n\t}\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nvoid put_pi_state(struct futex_pi_state *pi_state)\n{\n\tif (!pi_state)\n\t\treturn;\n\n\tif (!refcount_dec_and_test(&pi_state->refcount))\n\t\treturn;\n\n\t/*\n\t * If pi_state->owner is NULL, the owner is most probably dying\n\t * and has cleaned up the pi_state already\n\t */\n\tif (pi_state->owner) {\n\t\tunsigned long flags;\n\n\t\traw_spin_lock_irqsave(&pi_state->pi_mutex.wait_lock, flags);\n\t\tpi_state_update_owner(pi_state, NULL);\n\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex);\n\t\traw_spin_unlock_irqrestore(&pi_state->pi_mutex.wait_lock, flags);\n\t}\n\n\tif (current->pi_state_cache) {\n\t\tkfree(pi_state);\n\t} else {\n\t\t/*\n\t\t * pi_state->list is already empty.\n\t\t * clear pi_state->owner.\n\t\t * refcount is at 0 - put it back to 1.\n\t\t */\n\t\tpi_state->owner = NULL;\n\t\trefcount_set(&pi_state->refcount, 1);\n\t\tcurrent->pi_state_cache = pi_state;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "handle_early_requeue_pi_wakeup",
          "args": [
            "hb",
            "&q",
            "to"
          ],
          "line": 825
        },
        "resolved": true,
        "details": {
          "function_name": "handle_early_requeue_pi_wakeup",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "690-720",
          "snippet": "static inline\nint handle_early_requeue_pi_wakeup(struct futex_hash_bucket *hb,\n\t\t\t\t   struct futex_q *q,\n\t\t\t\t   struct hrtimer_sleeper *timeout)\n{\n\tint ret;\n\n\t/*\n\t * With the hb lock held, we avoid races while we process the wakeup.\n\t * We only need to hold hb (and not hb2) to ensure atomicity as the\n\t * wakeup code can't change q.key from uaddr to uaddr2 if we hold hb.\n\t * It can't be requeued from uaddr2 to something else since we don't\n\t * support a PI aware source futex for requeue.\n\t */\n\tWARN_ON_ONCE(&hb->lock != q->lock_ptr);\n\n\t/*\n\t * We were woken prior to requeue by a timeout or a signal.\n\t * Unqueue the futex_q and determine which it was.\n\t */\n\tplist_del(&q->list, &hb->chain);\n\tfutex_hb_waiters_dec(hb);\n\n\t/* Handle spurious wakeups gracefully */\n\tret = -EWOULDBLOCK;\n\tif (timeout && !timeout->task)\n\t\tret = -ETIMEDOUT;\n\telse if (signal_pending(current))\n\t\tret = -ERESTARTNOINTR;\n\treturn ret;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nint handle_early_requeue_pi_wakeup(struct futex_hash_bucket *hb,\n\t\t\t\t   struct futex_q *q,\n\t\t\t\t   struct hrtimer_sleeper *timeout)\n{\n\tint ret;\n\n\t/*\n\t * With the hb lock held, we avoid races while we process the wakeup.\n\t * We only need to hold hb (and not hb2) to ensure atomicity as the\n\t * wakeup code can't change q.key from uaddr to uaddr2 if we hold hb.\n\t * It can't be requeued from uaddr2 to something else since we don't\n\t * support a PI aware source futex for requeue.\n\t */\n\tWARN_ON_ONCE(&hb->lock != q->lock_ptr);\n\n\t/*\n\t * We were woken prior to requeue by a timeout or a signal.\n\t * Unqueue the futex_q and determine which it was.\n\t */\n\tplist_del(&q->list, &hb->chain);\n\tfutex_hb_waiters_dec(hb);\n\n\t/* Handle spurious wakeups gracefully */\n\tret = -EWOULDBLOCK;\n\tif (timeout && !timeout->task)\n\t\tret = -ETIMEDOUT;\n\telse if (signal_pending(current))\n\t\tret = -ERESTARTNOINTR;\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_requeue_pi_wakeup_sync",
          "args": [
            "&q"
          ],
          "line": 821
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue_pi_wakeup_sync",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "156-192",
          "snippet": "static inline int futex_requeue_pi_wakeup_sync(struct futex_q *q)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\t/* Is requeue done already? */\n\t\tif (old >= Q_REQUEUE_PI_DONE)\n\t\t\treturn old;\n\n\t\t/*\n\t\t * If not done, then tell the requeue code to either ignore\n\t\t * the waiter or to wake it up once the requeue is done.\n\t\t */\n\t\tnew = Q_REQUEUE_PI_WAIT;\n\t\tif (old == Q_REQUEUE_PI_NONE)\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\t/* If the requeue was in progress, wait for it to complete */\n\tif (old == Q_REQUEUE_PI_IN_PROGRESS) {\n#ifdef CONFIG_PREEMPT_RT\n\t\trcuwait_wait_event(&q->requeue_wait,\n\t\t\t\t   atomic_read(&q->requeue_state) != Q_REQUEUE_PI_WAIT,\n\t\t\t\t   TASK_UNINTERRUPTIBLE);\n#else\n\t\t(void)atomic_cond_read_relaxed(&q->requeue_state, VAL != Q_REQUEUE_PI_WAIT);\n#endif\n\t}\n\n\t/*\n\t * Requeue is now either prohibited or complete. Reread state\n\t * because during the wait above it might have changed. Nothing\n\t * will modify q->requeue_state after this point.\n\t */\n\treturn atomic_read(&q->requeue_state);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline int futex_requeue_pi_wakeup_sync(struct futex_q *q)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\t/* Is requeue done already? */\n\t\tif (old >= Q_REQUEUE_PI_DONE)\n\t\t\treturn old;\n\n\t\t/*\n\t\t * If not done, then tell the requeue code to either ignore\n\t\t * the waiter or to wake it up once the requeue is done.\n\t\t */\n\t\tnew = Q_REQUEUE_PI_WAIT;\n\t\tif (old == Q_REQUEUE_PI_NONE)\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\t/* If the requeue was in progress, wait for it to complete */\n\tif (old == Q_REQUEUE_PI_IN_PROGRESS) {\n#ifdef CONFIG_PREEMPT_RT\n\t\trcuwait_wait_event(&q->requeue_wait,\n\t\t\t\t   atomic_read(&q->requeue_state) != Q_REQUEUE_PI_WAIT,\n\t\t\t\t   TASK_UNINTERRUPTIBLE);\n#else\n\t\t(void)atomic_cond_read_relaxed(&q->requeue_state, VAL != Q_REQUEUE_PI_WAIT);\n#endif\n\t}\n\n\t/*\n\t * Requeue is now either prohibited or complete. Reread state\n\t * because during the wait above it might have changed. Nothing\n\t * will modify q->requeue_state after this point.\n\t */\n\treturn atomic_read(&q->requeue_state);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wait_queue",
          "args": [
            "hb",
            "&q",
            "to"
          ],
          "line": 819
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wait_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/waitwake.c",
          "lines": "328-358",
          "snippet": "void futex_wait_queue(struct futex_hash_bucket *hb, struct futex_q *q,\n\t\t\t    struct hrtimer_sleeper *timeout)\n{\n\t/*\n\t * The task state is guaranteed to be set before another task can\n\t * wake it. set_current_state() is implemented using smp_store_mb() and\n\t * futex_queue() calls spin_unlock() upon completion, both serializing\n\t * access to the hash list and forcing another memory barrier.\n\t */\n\tset_current_state(TASK_INTERRUPTIBLE);\n\tfutex_queue(q, hb);\n\n\t/* Arm the timer */\n\tif (timeout)\n\t\thrtimer_sleeper_start_expires(timeout, HRTIMER_MODE_ABS);\n\n\t/*\n\t * If we have been removed from the hash list, then another task\n\t * has tried to wake us, and we can skip the call to schedule().\n\t */\n\tif (likely(!plist_node_empty(&q->list))) {\n\t\t/*\n\t\t * If the timer has already expired, current will already be\n\t\t * flagged for rescheduling. Only call schedule if there\n\t\t * is no timeout, or if it has yet to expire.\n\t\t */\n\t\tif (!timeout || timeout->task)\n\t\t\tfreezable_schedule();\n\t}\n\t__set_current_state(TASK_RUNNING);\n}",
          "includes": [
            "#include \"futex.h\"",
            "#include <linux/freezer.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"futex.h\"\n#include <linux/freezer.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n\nvoid futex_wait_queue(struct futex_hash_bucket *hb, struct futex_q *q,\n\t\t\t    struct hrtimer_sleeper *timeout)\n{\n\t/*\n\t * The task state is guaranteed to be set before another task can\n\t * wake it. set_current_state() is implemented using smp_store_mb() and\n\t * futex_queue() calls spin_unlock() upon completion, both serializing\n\t * access to the hash list and forcing another memory barrier.\n\t */\n\tset_current_state(TASK_INTERRUPTIBLE);\n\tfutex_queue(q, hb);\n\n\t/* Arm the timer */\n\tif (timeout)\n\t\thrtimer_sleeper_start_expires(timeout, HRTIMER_MODE_ABS);\n\n\t/*\n\t * If we have been removed from the hash list, then another task\n\t * has tried to wake us, and we can skip the call to schedule().\n\t */\n\tif (likely(!plist_node_empty(&q->list))) {\n\t\t/*\n\t\t * If the timer has already expired, current will already be\n\t\t * flagged for rescheduling. Only call schedule if there\n\t\t * is no timeout, or if it has yet to expire.\n\t\t */\n\t\tif (!timeout || timeout->task)\n\t\t\tfreezable_schedule();\n\t}\n\t__set_current_state(TASK_RUNNING);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_q_unlock",
          "args": [
            "hb"
          ],
          "line": 813
        },
        "resolved": true,
        "details": {
          "function_name": "futex_q_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "536-541",
          "snippet": "void futex_q_unlock(struct futex_hash_bucket *hb)\n\t__releases(&hb->lock)\n{\n\tspin_unlock(&hb->lock);\n\tfutex_hb_waiters_dec(hb);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nvoid futex_q_unlock(struct futex_hash_bucket *hb)\n\t__releases(&hb->lock)\n{\n\tspin_unlock(&hb->lock);\n\tfutex_hb_waiters_dec(hb);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_match",
          "args": [
            "&q.key",
            "&key2"
          ],
          "line": 812
        },
        "resolved": true,
        "details": {
          "function_name": "futex_match",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "134-140",
          "snippet": "static inline int futex_match(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline int futex_match(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wait_setup",
          "args": [
            "uaddr",
            "val",
            "flags",
            "&q",
            "&hb"
          ],
          "line": 804
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wait_setup",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/waitwake.c",
          "lines": "577-630",
          "snippet": "int futex_wait_setup(u32 __user *uaddr, u32 val, unsigned int flags,\n\t\t     struct futex_q *q, struct futex_hash_bucket **hb)\n{\n\tu32 uval;\n\tint ret;\n\n\t/*\n\t * Access the page AFTER the hash-bucket is locked.\n\t * Order is important:\n\t *\n\t *   Userspace waiter: val = var; if (cond(val)) futex_wait(&var, val);\n\t *   Userspace waker:  if (cond(var)) { var = new; futex_wake(&var); }\n\t *\n\t * The basic logical guarantee of a futex is that it blocks ONLY\n\t * if cond(var) is known to be true at the time of blocking, for\n\t * any cond.  If we locked the hash-bucket after testing *uaddr, that\n\t * would open a race condition where we could block indefinitely with\n\t * cond(var) false, which would violate the guarantee.\n\t *\n\t * On the other hand, we insert q and release the hash-bucket only\n\t * after testing *uaddr.  This guarantees that futex_wait() will NOT\n\t * absorb a wakeup if *uaddr does not match the desired values\n\t * while the syscall executes.\n\t */\nretry:\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &q->key, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\nretry_private:\n\t*hb = futex_q_lock(q);\n\n\tret = futex_get_value_locked(&uval, uaddr);\n\n\tif (ret) {\n\t\tfutex_q_unlock(*hb);\n\n\t\tret = get_user(uval, uaddr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!(flags & FLAGS_SHARED))\n\t\t\tgoto retry_private;\n\n\t\tgoto retry;\n\t}\n\n\tif (uval != val) {\n\t\tfutex_q_unlock(*hb);\n\t\tret = -EWOULDBLOCK;\n\t}\n\n\treturn ret;\n}",
          "includes": [
            "#include \"futex.h\"",
            "#include <linux/freezer.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"futex.h\"\n#include <linux/freezer.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n\nint futex_wait_setup(u32 __user *uaddr, u32 val, unsigned int flags,\n\t\t     struct futex_q *q, struct futex_hash_bucket **hb)\n{\n\tu32 uval;\n\tint ret;\n\n\t/*\n\t * Access the page AFTER the hash-bucket is locked.\n\t * Order is important:\n\t *\n\t *   Userspace waiter: val = var; if (cond(val)) futex_wait(&var, val);\n\t *   Userspace waker:  if (cond(var)) { var = new; futex_wake(&var); }\n\t *\n\t * The basic logical guarantee of a futex is that it blocks ONLY\n\t * if cond(var) is known to be true at the time of blocking, for\n\t * any cond.  If we locked the hash-bucket after testing *uaddr, that\n\t * would open a race condition where we could block indefinitely with\n\t * cond(var) false, which would violate the guarantee.\n\t *\n\t * On the other hand, we insert q and release the hash-bucket only\n\t * after testing *uaddr.  This guarantees that futex_wait() will NOT\n\t * absorb a wakeup if *uaddr does not match the desired values\n\t * while the syscall executes.\n\t */\nretry:\n\tret = get_futex_key(uaddr, flags & FLAGS_SHARED, &q->key, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\nretry_private:\n\t*hb = futex_q_lock(q);\n\n\tret = futex_get_value_locked(&uval, uaddr);\n\n\tif (ret) {\n\t\tfutex_q_unlock(*hb);\n\n\t\tret = get_user(uval, uaddr);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tif (!(flags & FLAGS_SHARED))\n\t\t\tgoto retry_private;\n\n\t\tgoto retry;\n\t}\n\n\tif (uval != val) {\n\t\tfutex_q_unlock(*hb);\n\t\tret = -EWOULDBLOCK;\n\t}\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret != 0"
          ],
          "line": 793
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_futex_key",
          "args": [
            "uaddr2",
            "flags & FLAGS_SHARED",
            "&key2",
            "FUTEX_WRITE"
          ],
          "line": 792
        },
        "resolved": true,
        "details": {
          "function_name": "get_futex_key",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "220-395",
          "snippet": "int get_futex_key(u32 __user *uaddr, bool fshared, union futex_key *key,\n\t\t  enum futex_access rw)\n{\n\tunsigned long address = (unsigned long)uaddr;\n\tstruct mm_struct *mm = current->mm;\n\tstruct page *page, *tail;\n\tstruct address_space *mapping;\n\tint err, ro = 0;\n\n\t/*\n\t * The futex address must be \"naturally\" aligned.\n\t */\n\tkey->both.offset = address % PAGE_SIZE;\n\tif (unlikely((address % sizeof(u32)) != 0))\n\t\treturn -EINVAL;\n\taddress -= key->both.offset;\n\n\tif (unlikely(!access_ok(uaddr, sizeof(u32))))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(fshared)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * PROCESS_PRIVATE futexes are fast.\n\t * As the mm cannot disappear under us and the 'key' only needs\n\t * virtual address, we dont even have to find the underlying vma.\n\t * Note : We do have to check 'uaddr' is a valid user address,\n\t *        but access_ok() should be faster than find_vma()\n\t */\n\tif (!fshared) {\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\t\treturn 0;\n\t}\n\nagain:\n\t/* Ignore any VERIFY_READ mapping (futex common case) */\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\terr = get_user_pages_fast(address, 1, FOLL_WRITE, &page);\n\t/*\n\t * If write access is not required (eg. FUTEX_WAIT), try\n\t * and get read-only access.\n\t */\n\tif (err == -EFAULT && rw == FUTEX_READ) {\n\t\terr = get_user_pages_fast(address, 1, 0, &page);\n\t\tro = 1;\n\t}\n\tif (err < 0)\n\t\treturn err;\n\telse\n\t\terr = 0;\n\n\t/*\n\t * The treatment of mapping from this point on is critical. The page\n\t * lock protects many things but in this context the page lock\n\t * stabilizes mapping, prevents inode freeing in the shared\n\t * file-backed region case and guards against movement to swap cache.\n\t *\n\t * Strictly speaking the page lock is not needed in all cases being\n\t * considered here and page lock forces unnecessarily serialization\n\t * From this point on, mapping will be re-verified if necessary and\n\t * page lock will be acquired only if it is unavoidable\n\t *\n\t * Mapping checks require the head page for any compound page so the\n\t * head page and mapping is looked up now. For anonymous pages, it\n\t * does not matter if the page splits in the future as the key is\n\t * based on the address. For filesystem-backed pages, the tail is\n\t * required as the index of the page determines the key. For\n\t * base pages, there is no tail page and tail == page.\n\t */\n\ttail = page;\n\tpage = compound_head(page);\n\tmapping = READ_ONCE(page->mapping);\n\n\t/*\n\t * If page->mapping is NULL, then it cannot be a PageAnon\n\t * page; but it might be the ZERO_PAGE or in the gate area or\n\t * in a special mapping (all cases which we are happy to fail);\n\t * or it may have been a good file page when get_user_pages_fast\n\t * found it, but truncated or holepunched or subjected to\n\t * invalidate_complete_page2 before we got the page lock (also\n\t * cases which we are happy to fail).  And we hold a reference,\n\t * so refcount care in invalidate_complete_page's remove_mapping\n\t * prevents drop_caches from setting mapping to NULL beneath us.\n\t *\n\t * The case we do have to guard against is when memory pressure made\n\t * shmem_writepage move it from filecache to swapcache beneath us:\n\t * an unlikely race, but we do need to retry for page->mapping.\n\t */\n\tif (unlikely(!mapping)) {\n\t\tint shmem_swizzled;\n\n\t\t/*\n\t\t * Page lock is required to identify which special case above\n\t\t * applies. If this is really a shmem page then the page lock\n\t\t * will prevent unexpected transitions.\n\t\t */\n\t\tlock_page(page);\n\t\tshmem_swizzled = PageSwapCache(page) || page->mapping;\n\t\tunlock_page(page);\n\t\tput_page(page);\n\n\t\tif (shmem_swizzled)\n\t\t\tgoto again;\n\n\t\treturn -EFAULT;\n\t}\n\n\t/*\n\t * Private mappings are handled in a simple way.\n\t *\n\t * If the futex key is stored on an anonymous page, then the associated\n\t * object is the mm which is implicitly pinned by the calling process.\n\t *\n\t * NOTE: When userspace waits on a MAP_SHARED mapping, even if\n\t * it's a read-only handle, it's expected that futexes attach to\n\t * the object not the particular process.\n\t */\n\tif (PageAnon(page)) {\n\t\t/*\n\t\t * A RO anonymous page will never change and thus doesn't make\n\t\t * sense for futex operations.\n\t\t */\n\t\tif (unlikely(should_fail_futex(true)) || ro) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_MMSHARED; /* ref taken on mm */\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\n\t} else {\n\t\tstruct inode *inode;\n\n\t\t/*\n\t\t * The associated futex object in this case is the inode and\n\t\t * the page->mapping must be traversed. Ordinarily this should\n\t\t * be stabilised under page lock but it's not strictly\n\t\t * necessary in this case as we just want to pin the inode, not\n\t\t * update the radix tree or anything like that.\n\t\t *\n\t\t * The RCU read lock is taken as the inode is finally freed\n\t\t * under RCU. If the mapping still matches expectations then the\n\t\t * mapping->host can be safely accessed as being a valid inode.\n\t\t */\n\t\trcu_read_lock();\n\n\t\tif (READ_ONCE(page->mapping) != mapping) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tinode = READ_ONCE(mapping->host);\n\t\tif (!inode) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_INODE; /* inode-based key */\n\t\tkey->shared.i_seq = get_inode_sequence_number(inode);\n\t\tkey->shared.pgoff = page_to_pgoff(tail);\n\t\trcu_read_unlock();\n\t}\n\nout:\n\tput_page(page);\n\treturn err;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__read_mostly __aligned(2*sizeof(long));"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\n__read_mostly __aligned(2*sizeof(long));\n\nint get_futex_key(u32 __user *uaddr, bool fshared, union futex_key *key,\n\t\t  enum futex_access rw)\n{\n\tunsigned long address = (unsigned long)uaddr;\n\tstruct mm_struct *mm = current->mm;\n\tstruct page *page, *tail;\n\tstruct address_space *mapping;\n\tint err, ro = 0;\n\n\t/*\n\t * The futex address must be \"naturally\" aligned.\n\t */\n\tkey->both.offset = address % PAGE_SIZE;\n\tif (unlikely((address % sizeof(u32)) != 0))\n\t\treturn -EINVAL;\n\taddress -= key->both.offset;\n\n\tif (unlikely(!access_ok(uaddr, sizeof(u32))))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(fshared)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * PROCESS_PRIVATE futexes are fast.\n\t * As the mm cannot disappear under us and the 'key' only needs\n\t * virtual address, we dont even have to find the underlying vma.\n\t * Note : We do have to check 'uaddr' is a valid user address,\n\t *        but access_ok() should be faster than find_vma()\n\t */\n\tif (!fshared) {\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\t\treturn 0;\n\t}\n\nagain:\n\t/* Ignore any VERIFY_READ mapping (futex common case) */\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\terr = get_user_pages_fast(address, 1, FOLL_WRITE, &page);\n\t/*\n\t * If write access is not required (eg. FUTEX_WAIT), try\n\t * and get read-only access.\n\t */\n\tif (err == -EFAULT && rw == FUTEX_READ) {\n\t\terr = get_user_pages_fast(address, 1, 0, &page);\n\t\tro = 1;\n\t}\n\tif (err < 0)\n\t\treturn err;\n\telse\n\t\terr = 0;\n\n\t/*\n\t * The treatment of mapping from this point on is critical. The page\n\t * lock protects many things but in this context the page lock\n\t * stabilizes mapping, prevents inode freeing in the shared\n\t * file-backed region case and guards against movement to swap cache.\n\t *\n\t * Strictly speaking the page lock is not needed in all cases being\n\t * considered here and page lock forces unnecessarily serialization\n\t * From this point on, mapping will be re-verified if necessary and\n\t * page lock will be acquired only if it is unavoidable\n\t *\n\t * Mapping checks require the head page for any compound page so the\n\t * head page and mapping is looked up now. For anonymous pages, it\n\t * does not matter if the page splits in the future as the key is\n\t * based on the address. For filesystem-backed pages, the tail is\n\t * required as the index of the page determines the key. For\n\t * base pages, there is no tail page and tail == page.\n\t */\n\ttail = page;\n\tpage = compound_head(page);\n\tmapping = READ_ONCE(page->mapping);\n\n\t/*\n\t * If page->mapping is NULL, then it cannot be a PageAnon\n\t * page; but it might be the ZERO_PAGE or in the gate area or\n\t * in a special mapping (all cases which we are happy to fail);\n\t * or it may have been a good file page when get_user_pages_fast\n\t * found it, but truncated or holepunched or subjected to\n\t * invalidate_complete_page2 before we got the page lock (also\n\t * cases which we are happy to fail).  And we hold a reference,\n\t * so refcount care in invalidate_complete_page's remove_mapping\n\t * prevents drop_caches from setting mapping to NULL beneath us.\n\t *\n\t * The case we do have to guard against is when memory pressure made\n\t * shmem_writepage move it from filecache to swapcache beneath us:\n\t * an unlikely race, but we do need to retry for page->mapping.\n\t */\n\tif (unlikely(!mapping)) {\n\t\tint shmem_swizzled;\n\n\t\t/*\n\t\t * Page lock is required to identify which special case above\n\t\t * applies. If this is really a shmem page then the page lock\n\t\t * will prevent unexpected transitions.\n\t\t */\n\t\tlock_page(page);\n\t\tshmem_swizzled = PageSwapCache(page) || page->mapping;\n\t\tunlock_page(page);\n\t\tput_page(page);\n\n\t\tif (shmem_swizzled)\n\t\t\tgoto again;\n\n\t\treturn -EFAULT;\n\t}\n\n\t/*\n\t * Private mappings are handled in a simple way.\n\t *\n\t * If the futex key is stored on an anonymous page, then the associated\n\t * object is the mm which is implicitly pinned by the calling process.\n\t *\n\t * NOTE: When userspace waits on a MAP_SHARED mapping, even if\n\t * it's a read-only handle, it's expected that futexes attach to\n\t * the object not the particular process.\n\t */\n\tif (PageAnon(page)) {\n\t\t/*\n\t\t * A RO anonymous page will never change and thus doesn't make\n\t\t * sense for futex operations.\n\t\t */\n\t\tif (unlikely(should_fail_futex(true)) || ro) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_MMSHARED; /* ref taken on mm */\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\n\t} else {\n\t\tstruct inode *inode;\n\n\t\t/*\n\t\t * The associated futex object in this case is the inode and\n\t\t * the page->mapping must be traversed. Ordinarily this should\n\t\t * be stabilised under page lock but it's not strictly\n\t\t * necessary in this case as we just want to pin the inode, not\n\t\t * update the radix tree or anything like that.\n\t\t *\n\t\t * The RCU read lock is taken as the inode is finally freed\n\t\t * under RCU. If the mapping still matches expectations then the\n\t\t * mapping->host can be safely accessed as being a valid inode.\n\t\t */\n\t\trcu_read_lock();\n\n\t\tif (READ_ONCE(page->mapping) != mapping) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tinode = READ_ONCE(mapping->host);\n\t\tif (!inode) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_INODE; /* inode-based key */\n\t\tkey->shared.i_seq = get_inode_sequence_number(inode);\n\t\tkey->shared.pgoff = page_to_pgoff(tail);\n\t\trcu_read_unlock();\n\t}\n\nout:\n\tput_page(page);\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_mutex_init_waiter",
          "args": [
            "&rt_waiter"
          ],
          "line": 790
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_init_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_common.h",
          "lines": "190-197",
          "snippet": "static inline void rt_mutex_init_waiter(struct rt_mutex_waiter *waiter)\n{\n\tdebug_rt_mutex_init_waiter(waiter);\n\tRB_CLEAR_NODE(&waiter->pi_tree_entry);\n\tRB_CLEAR_NODE(&waiter->tree_entry);\n\twaiter->wake_state = TASK_NORMAL;\n\twaiter->task = NULL;\n}",
          "includes": [
            "#include <linux/sched/wake_q.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/wake_q.h>\n#include <linux/rtmutex.h>\n#include <linux/debug_locks.h>\n\nstatic inline void rt_mutex_init_waiter(struct rt_mutex_waiter *waiter)\n{\n\tdebug_rt_mutex_init_waiter(waiter);\n\tRB_CLEAR_NODE(&waiter->pi_tree_entry);\n\tRB_CLEAR_NODE(&waiter->tree_entry);\n\twaiter->wake_state = TASK_NORMAL;\n\twaiter->task = NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_setup_timer",
          "args": [
            "abs_time",
            "&timeout",
            "flags",
            "current->timer_slack_ns"
          ],
          "line": 783
        },
        "resolved": true,
        "details": {
          "function_name": "futex_setup_timer",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "134-151",
          "snippet": "struct hrtimer_sleeper *\nfutex_setup_timer(ktime_t *time, struct hrtimer_sleeper *timeout,\n\t\t  int flags, u64 range_ns)\n{\n\tif (!time)\n\t\treturn NULL;\n\n\thrtimer_init_sleeper_on_stack(timeout, (flags & FLAGS_CLOCKRT) ?\n\t\t\t\t      CLOCK_REALTIME : CLOCK_MONOTONIC,\n\t\t\t\t      HRTIMER_MODE_ABS);\n\t/*\n\t * If range_ns is 0, calling hrtimer_set_expires_range_ns() is\n\t * effectively the same as calling hrtimer_set_expires().\n\t */\n\thrtimer_set_expires_range_ns(&timeout->timer, *time, range_ns);\n\n\treturn timeout;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nstruct hrtimer_sleeper *\nfutex_setup_timer(ktime_t *time, struct hrtimer_sleeper *timeout,\n\t\t  int flags, u64 range_ns)\n{\n\tif (!time)\n\t\treturn NULL;\n\n\thrtimer_init_sleeper_on_stack(timeout, (flags & FLAGS_CLOCKRT) ?\n\t\t\t\t      CLOCK_REALTIME : CLOCK_MONOTONIC,\n\t\t\t\t      HRTIMER_MODE_ABS);\n\t/*\n\t * If range_ns is 0, calling hrtimer_set_expires_range_ns() is\n\t * effectively the same as calling hrtimer_set_expires().\n\t */\n\thrtimer_set_expires_range_ns(&timeout->timer, *time, range_ns);\n\n\treturn timeout;\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_FUTEX_PI"
          ],
          "line": 774
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nconst struct futex_q futex_q_init = {\n\t/* list gets initialized in futex_queue()*/\n\t.key\t\t= FUTEX_KEY_INIT,\n\t.bitset\t\t= FUTEX_BITSET_MATCH_ANY,\n\t.requeue_state\t= ATOMIC_INIT(Q_REQUEUE_PI_NONE),\n};\n\nint futex_wait_requeue_pi(u32 __user *uaddr, unsigned int flags,\n\t\t\t  u32 val, ktime_t *abs_time, u32 bitset,\n\t\t\t  u32 __user *uaddr2)\n{\n\tstruct hrtimer_sleeper timeout, *to;\n\tstruct rt_mutex_waiter rt_waiter;\n\tstruct futex_hash_bucket *hb;\n\tunion futex_key key2 = FUTEX_KEY_INIT;\n\tstruct futex_q q = futex_q_init;\n\tstruct rt_mutex_base *pi_mutex;\n\tint res, ret;\n\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI))\n\t\treturn -ENOSYS;\n\n\tif (uaddr == uaddr2)\n\t\treturn -EINVAL;\n\n\tif (!bitset)\n\t\treturn -EINVAL;\n\n\tto = futex_setup_timer(abs_time, &timeout, flags,\n\t\t\t       current->timer_slack_ns);\n\n\t/*\n\t * The waiter is allocated on our stack, manipulated by the requeue\n\t * code while we sleep on uaddr.\n\t */\n\trt_mutex_init_waiter(&rt_waiter);\n\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2, FUTEX_WRITE);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\n\tq.bitset = bitset;\n\tq.rt_waiter = &rt_waiter;\n\tq.requeue_pi_key = &key2;\n\n\t/*\n\t * Prepare to wait on uaddr. On success, it holds hb->lock and q\n\t * is initialized.\n\t */\n\tret = futex_wait_setup(uaddr, val, flags, &q, &hb);\n\tif (ret)\n\t\tgoto out;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (futex_match(&q.key, &key2)) {\n\t\tfutex_q_unlock(hb);\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Queue the futex_q, drop the hb lock, wait for wakeup. */\n\tfutex_wait_queue(hb, &q, to);\n\n\tswitch (futex_requeue_pi_wakeup_sync(&q)) {\n\tcase Q_REQUEUE_PI_IGNORE:\n\t\t/* The waiter is still on uaddr1 */\n\t\tspin_lock(&hb->lock);\n\t\tret = handle_early_requeue_pi_wakeup(hb, &q, to);\n\t\tspin_unlock(&hb->lock);\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_LOCKED:\n\t\t/* The requeue acquired the lock */\n\t\tif (q.pi_state && (q.pi_state->owner != current)) {\n\t\t\tspin_lock(q.lock_ptr);\n\t\t\tret = fixup_pi_owner(uaddr2, &q, true);\n\t\t\t/*\n\t\t\t * Drop the reference to the pi state which the\n\t\t\t * requeue_pi() code acquired for us.\n\t\t\t */\n\t\t\tput_pi_state(q.pi_state);\n\t\t\tspin_unlock(q.lock_ptr);\n\t\t\t/*\n\t\t\t * Adjust the return value. It's either -EFAULT or\n\t\t\t * success (1) but the caller expects 0 for success.\n\t\t\t */\n\t\t\tret = ret < 0 ? ret : 0;\n\t\t}\n\t\tbreak;\n\n\tcase Q_REQUEUE_PI_DONE:\n\t\t/* Requeue completed. Current is 'pi_blocked_on' the rtmutex */\n\t\tpi_mutex = &q.pi_state->pi_mutex;\n\t\tret = rt_mutex_wait_proxy_lock(pi_mutex, to, &rt_waiter);\n\n\t\t/* Current is not longer pi_blocked_on */\n\t\tspin_lock(q.lock_ptr);\n\t\tif (ret && !rt_mutex_cleanup_proxy_lock(pi_mutex, &rt_waiter))\n\t\t\tret = 0;\n\n\t\tdebug_rt_mutex_free_waiter(&rt_waiter);\n\t\t/*\n\t\t * Fixup the pi_state owner and possibly acquire the lock if we\n\t\t * haven't already.\n\t\t */\n\t\tres = fixup_pi_owner(uaddr2, &q, !ret);\n\t\t/*\n\t\t * If fixup_pi_owner() returned an error, propagate that.  If it\n\t\t * acquired the lock, clear -ETIMEDOUT or -EINTR.\n\t\t */\n\t\tif (res)\n\t\t\tret = (res < 0) ? res : 0;\n\n\t\tfutex_unqueue_pi(&q);\n\t\tspin_unlock(q.lock_ptr);\n\n\t\tif (ret == -EINTR) {\n\t\t\t/*\n\t\t\t * We've already been requeued, but cannot restart\n\t\t\t * by calling futex_lock_pi() directly. We could\n\t\t\t * restart this syscall, but it would detect that\n\t\t\t * the user space \"val\" changed and return\n\t\t\t * -EWOULDBLOCK.  Save the overhead of the restart\n\t\t\t * and return -EWOULDBLOCK directly.\n\t\t\t */\n\t\t\tret = -EWOULDBLOCK;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\nout:\n\tif (to) {\n\t\thrtimer_cancel(&to->timer);\n\t\tdestroy_hrtimer_on_stack(&to->timer);\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "handle_early_requeue_pi_wakeup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "690-720",
    "snippet": "static inline\nint handle_early_requeue_pi_wakeup(struct futex_hash_bucket *hb,\n\t\t\t\t   struct futex_q *q,\n\t\t\t\t   struct hrtimer_sleeper *timeout)\n{\n\tint ret;\n\n\t/*\n\t * With the hb lock held, we avoid races while we process the wakeup.\n\t * We only need to hold hb (and not hb2) to ensure atomicity as the\n\t * wakeup code can't change q.key from uaddr to uaddr2 if we hold hb.\n\t * It can't be requeued from uaddr2 to something else since we don't\n\t * support a PI aware source futex for requeue.\n\t */\n\tWARN_ON_ONCE(&hb->lock != q->lock_ptr);\n\n\t/*\n\t * We were woken prior to requeue by a timeout or a signal.\n\t * Unqueue the futex_q and determine which it was.\n\t */\n\tplist_del(&q->list, &hb->chain);\n\tfutex_hb_waiters_dec(hb);\n\n\t/* Handle spurious wakeups gracefully */\n\tret = -EWOULDBLOCK;\n\tif (timeout && !timeout->task)\n\t\tret = -ETIMEDOUT;\n\telse if (signal_pending(current))\n\t\tret = -ERESTARTNOINTR;\n\treturn ret;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "signal_pending",
          "args": [
            "current"
          ],
          "line": 717
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "futex_hb_waiters_dec",
          "args": [
            "hb"
          ],
          "line": 711
        },
        "resolved": true,
        "details": {
          "function_name": "futex_hb_waiters_dec",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "198-203",
          "snippet": "static inline void futex_hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void futex_hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "plist_del",
          "args": [
            "&q->list",
            "&hb->chain"
          ],
          "line": 710
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "&hb->lock != q->lock_ptr"
          ],
          "line": 704
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nint handle_early_requeue_pi_wakeup(struct futex_hash_bucket *hb,\n\t\t\t\t   struct futex_q *q,\n\t\t\t\t   struct hrtimer_sleeper *timeout)\n{\n\tint ret;\n\n\t/*\n\t * With the hb lock held, we avoid races while we process the wakeup.\n\t * We only need to hold hb (and not hb2) to ensure atomicity as the\n\t * wakeup code can't change q.key from uaddr to uaddr2 if we hold hb.\n\t * It can't be requeued from uaddr2 to something else since we don't\n\t * support a PI aware source futex for requeue.\n\t */\n\tWARN_ON_ONCE(&hb->lock != q->lock_ptr);\n\n\t/*\n\t * We were woken prior to requeue by a timeout or a signal.\n\t * Unqueue the futex_q and determine which it was.\n\t */\n\tplist_del(&q->list, &hb->chain);\n\tfutex_hb_waiters_dec(hb);\n\n\t/* Handle spurious wakeups gracefully */\n\tret = -EWOULDBLOCK;\n\tif (timeout && !timeout->task)\n\t\tret = -ETIMEDOUT;\n\telse if (signal_pending(current))\n\t\tret = -ERESTARTNOINTR;\n\treturn ret;\n}"
  },
  {
    "function_name": "futex_requeue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "364-677",
    "snippet": "int futex_requeue(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,\n\t\t  int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * futex_requeue() allows the caller to define the number\n\t\t * of waiters to wake up via the @nr_wake argument. With\n\t\t * REQUEUE_PI, waking up more than one waiter is creating\n\t\t * more problems than it solves. Waking up a waiter makes\n\t\t * only sense if the PI futex @uaddr2 is uncontended as\n\t\t * this allows the requeue code to acquire the futex\n\t\t * @uaddr2 before waking the waiter. The waiter can then\n\t\t * return to user space without further action. A secondary\n\t\t * wakeup would just make the futex_wait_requeue_pi()\n\t\t * handling more complex, because that code would have to\n\t\t * look up pi_state and do more or less all the handling\n\t\t * which the requeue code has to do for the to be requeued\n\t\t * waiters. So restrict the number of waiters to wake to\n\t\t * one, and only wake it up when the PI futex is\n\t\t * uncontended. Otherwise requeue it and let the unlock of\n\t\t * the PI futex handle the wakeup.\n\t\t *\n\t\t * All REQUEUE_PI users, e.g. pthread_cond_signal() and\n\t\t * pthread_cond_broadcast() must use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? FUTEX_WRITE : FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && futex_match(&key1, &key2))\n\t\treturn -EINVAL;\n\n\thb1 = futex_hash(&key1);\n\thb2 = futex_hash(&key2);\n\nretry_private:\n\tfutex_hb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = futex_get_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi) {\n\t\tstruct task_struct *exiting = NULL;\n\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t *\n\t\t * Updates topwaiter::requeue_state if a top waiter exists.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state,\n\t\t\t\t\t\t &exiting, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or\n\t\t * is waiting on it. In both cases pi_state has been\n\t\t * established and an initial refcount on it. In case of an\n\t\t * error there's nothing.\n\t\t *\n\t\t * The top waiter's requeue_state is up to date:\n\t\t *\n\t\t *  - If the lock was acquired atomically (ret == 1), then\n\t\t *    the state is Q_REQUEUE_PI_LOCKED.\n\t\t *\n\t\t *    The top waiter has been dequeued and woken up and can\n\t\t *    return to user space immediately. The kernel/user\n\t\t *    space state is consistent. In case that there must be\n\t\t *    more waiters requeued the WAITERS bit in the user\n\t\t *    space futex is set so the top waiter task has to go\n\t\t *    into the syscall slowpath to unlock the futex. This\n\t\t *    will block until this requeue operation has been\n\t\t *    completed and the hash bucket locks have been\n\t\t *    dropped.\n\t\t *\n\t\t *  - If the trylock failed with an error (ret < 0) then\n\t\t *    the state is either Q_REQUEUE_PI_NONE, i.e. \"nothing\n\t\t *    happened\", or Q_REQUEUE_PI_IGNORE when there was an\n\t\t *    interleaved early wakeup.\n\t\t *\n\t\t *  - If the trylock did not succeed (ret == 0) then the\n\t\t *    state is either Q_REQUEUE_PI_IN_PROGRESS or\n\t\t *    Q_REQUEUE_PI_WAIT if an early wakeup interleaved.\n\t\t *    This will be cleaned up in the loop below, which\n\t\t *    cannot fail because futex_proxy_trylock_atomic() did\n\t\t *    the same sanity checks for requeue_pi as the loop\n\t\t *    below does.\n\t\t */\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\tcase 1:\n\t\t\t/*\n\t\t\t * futex_proxy_trylock_atomic() acquired the user space\n\t\t\t * futex. Adjust task_count.\n\t\t\t */\n\t\t\ttask_count++;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If the above failed, then pi_state is NULL and\n\t\t * waiter::requeue_state is correct.\n\t\t */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\treturn ret;\n\t\tcase -EBUSY:\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - EBUSY: Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - EAGAIN: The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\t/*\n\t\t\t * Handle the case where the owner is in the middle of\n\t\t\t * exiting. Wait for the exit to complete otherwise\n\t\t\t * this task might loop forever, aka. live lock.\n\t\t\t */\n\t\t\twait_for_owner_exiting(ret, exiting);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!futex_match(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQUEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Plain futexes just wake or requeue and are done */\n\t\tif (!requeue_pi) {\n\t\t\tif (++task_count <= nr_wake)\n\t\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\telse\n\t\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (!futex_match(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t *\n\t\t * Prepare the waiter to take the rt_mutex. Take a refcount\n\t\t * on the pi_state and store the pointer in the futex_q\n\t\t * object of the waiter.\n\t\t */\n\t\tget_pi_state(pi_state);\n\n\t\t/* Don't requeue when the waiter is already on the way out. */\n\t\tif (!futex_requeue_pi_prepare(this, pi_state)) {\n\t\t\t/*\n\t\t\t * Early woken waiter signaled that it is on the\n\t\t\t * way out. Drop the pi_state reference and try the\n\t\t\t * next waiter. @this->pi_state is still NULL.\n\t\t\t */\n\t\t\tput_pi_state(pi_state);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\tthis->task);\n\n\t\tif (ret == 1) {\n\t\t\t/*\n\t\t\t * We got the lock. We do neither drop the refcount\n\t\t\t * on pi_state nor clear this->pi_state because the\n\t\t\t * waiter needs the pi_state for cleaning up the\n\t\t\t * user space value. It will drop the refcount\n\t\t\t * after doing so. this::requeue_state is updated\n\t\t\t * in the wakeup as well.\n\t\t\t */\n\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\ttask_count++;\n\t\t} else if (!ret) {\n\t\t\t/* Waiter is queued, move it to hb2 */\n\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tfutex_requeue_pi_complete(this, 0);\n\t\t\ttask_count++;\n\t\t} else {\n\t\t\t/*\n\t\t\t * rt_mutex_start_proxy_lock() detected a potential\n\t\t\t * deadlock when we tried to queue that waiter.\n\t\t\t * Drop the pi_state reference which we took above\n\t\t\t * and remove the pointer to the state from the\n\t\t\t * waiters futex_q object.\n\t\t\t */\n\t\t\tthis->pi_state = NULL;\n\t\t\tput_pi_state(pi_state);\n\t\t\tfutex_requeue_pi_complete(this, ret);\n\t\t\t/*\n\t\t\t * We stop queueing more waiters and let user space\n\t\t\t * deal with the mess.\n\t\t\t */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state in\n\t * futex_proxy_trylock_atomic(). We need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\tfutex_hb_waiters_dec(hb2);\n\treturn ret ? ret : task_count;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "futex_hb_waiters_dec",
          "args": [
            "hb2"
          ],
          "line": 675
        },
        "resolved": true,
        "details": {
          "function_name": "futex_hb_waiters_dec",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "198-203",
          "snippet": "static inline void futex_hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void futex_hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 674
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_q",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "948-967",
          "snippet": "void wake_up_q(struct wake_q_head *head)\n{\n\tstruct wake_q_node *node = head->first;\n\n\twhile (node != WAKE_Q_TAIL) {\n\t\tstruct task_struct *task;\n\n\t\ttask = container_of(node, struct task_struct, wake_q);\n\t\t/* Task can safely be re-inserted now: */\n\t\tnode = node->next;\n\t\ttask->wake_q.next = NULL;\n\n\t\t/*\n\t\t * wake_up_process() executes a full barrier, which pairs with\n\t\t * the queueing in wake_q_add() so as not to miss wakeups.\n\t\t */\n\t\twake_up_process(task);\n\t\tput_task_struct(task);\n\t}\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid wake_up_q(struct wake_q_head *head)\n{\n\tstruct wake_q_node *node = head->first;\n\n\twhile (node != WAKE_Q_TAIL) {\n\t\tstruct task_struct *task;\n\n\t\ttask = container_of(node, struct task_struct, wake_q);\n\t\t/* Task can safely be re-inserted now: */\n\t\tnode = node->next;\n\t\ttask->wake_q.next = NULL;\n\n\t\t/*\n\t\t * wake_up_process() executes a full barrier, which pairs with\n\t\t * the queueing in wake_q_add() so as not to miss wakeups.\n\t\t */\n\t\twake_up_process(task);\n\t\tput_task_struct(task);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "double_unlock_hb",
          "args": [
            "hb1",
            "hb2"
          ],
          "line": 673
        },
        "resolved": true,
        "details": {
          "function_name": "double_unlock_hb",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "248-254",
          "snippet": "static inline void\ndouble_unlock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)\n{\n\tspin_unlock(&hb1->lock);\n\tif (hb1 != hb2)\n\t\tspin_unlock(&hb2->lock);\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void\ndouble_unlock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)\n{\n\tspin_unlock(&hb1->lock);\n\tif (hb1 != hb2)\n\t\tspin_unlock(&hb2->lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_pi_state",
          "args": [
            "pi_state"
          ],
          "line": 670
        },
        "resolved": true,
        "details": {
          "function_name": "put_pi_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "77-110",
          "snippet": "void put_pi_state(struct futex_pi_state *pi_state)\n{\n\tif (!pi_state)\n\t\treturn;\n\n\tif (!refcount_dec_and_test(&pi_state->refcount))\n\t\treturn;\n\n\t/*\n\t * If pi_state->owner is NULL, the owner is most probably dying\n\t * and has cleaned up the pi_state already\n\t */\n\tif (pi_state->owner) {\n\t\tunsigned long flags;\n\n\t\traw_spin_lock_irqsave(&pi_state->pi_mutex.wait_lock, flags);\n\t\tpi_state_update_owner(pi_state, NULL);\n\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex);\n\t\traw_spin_unlock_irqrestore(&pi_state->pi_mutex.wait_lock, flags);\n\t}\n\n\tif (current->pi_state_cache) {\n\t\tkfree(pi_state);\n\t} else {\n\t\t/*\n\t\t * pi_state->list is already empty.\n\t\t * clear pi_state->owner.\n\t\t * refcount is at 0 - put it back to 1.\n\t\t */\n\t\tpi_state->owner = NULL;\n\t\trefcount_set(&pi_state->refcount, 1);\n\t\tcurrent->pi_state_cache = pi_state;\n\t}\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nvoid put_pi_state(struct futex_pi_state *pi_state)\n{\n\tif (!pi_state)\n\t\treturn;\n\n\tif (!refcount_dec_and_test(&pi_state->refcount))\n\t\treturn;\n\n\t/*\n\t * If pi_state->owner is NULL, the owner is most probably dying\n\t * and has cleaned up the pi_state already\n\t */\n\tif (pi_state->owner) {\n\t\tunsigned long flags;\n\n\t\traw_spin_lock_irqsave(&pi_state->pi_mutex.wait_lock, flags);\n\t\tpi_state_update_owner(pi_state, NULL);\n\t\trt_mutex_proxy_unlock(&pi_state->pi_mutex);\n\t\traw_spin_unlock_irqrestore(&pi_state->pi_mutex.wait_lock, flags);\n\t}\n\n\tif (current->pi_state_cache) {\n\t\tkfree(pi_state);\n\t} else {\n\t\t/*\n\t\t * pi_state->list is already empty.\n\t\t * clear pi_state->owner.\n\t\t * refcount is at 0 - put it back to 1.\n\t\t */\n\t\tpi_state->owner = NULL;\n\t\trefcount_set(&pi_state->refcount, 1);\n\t\tcurrent->pi_state_cache = pi_state;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_requeue_pi_complete",
          "args": [
            "this",
            "ret"
          ],
          "line": 657
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue_pi_complete",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "125-154",
          "snippet": "static inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "requeue_futex",
          "args": [
            "this",
            "hb1",
            "hb2",
            "&key2"
          ],
          "line": 644
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_futex",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "73-90",
          "snippet": "static inline\nvoid requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,\n\t\t   struct futex_hash_bucket *hb2, union futex_key *key2)\n{\n\n\t/*\n\t * If key1 and key2 hash to the same bucket, no need to\n\t * requeue.\n\t */\n\tif (likely(&hb1->chain != &hb2->chain)) {\n\t\tplist_del(&q->list, &hb1->chain);\n\t\tfutex_hb_waiters_dec(hb1);\n\t\tfutex_hb_waiters_inc(hb2);\n\t\tplist_add(&q->list, &hb2->chain);\n\t\tq->lock_ptr = &hb2->lock;\n\t}\n\tq->key = *key2;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nvoid requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,\n\t\t   struct futex_hash_bucket *hb2, union futex_key *key2)\n{\n\n\t/*\n\t * If key1 and key2 hash to the same bucket, no need to\n\t * requeue.\n\t */\n\tif (likely(&hb1->chain != &hb2->chain)) {\n\t\tplist_del(&q->list, &hb1->chain);\n\t\tfutex_hb_waiters_dec(hb1);\n\t\tfutex_hb_waiters_inc(hb2);\n\t\tplist_add(&q->list, &hb2->chain);\n\t\tq->lock_ptr = &hb2->lock;\n\t}\n\tq->key = *key2;\n}"
        }
      },
      {
        "call_info": {
          "callee": "requeue_pi_wake_futex",
          "args": [
            "this",
            "&key2",
            "hb2"
          ],
          "line": 640
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_pi_wake_futex",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "222-238",
          "snippet": "static inline\nvoid requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,\n\t\t\t   struct futex_hash_bucket *hb)\n{\n\tq->key = *key;\n\n\t__futex_unqueue(q);\n\n\tWARN_ON(!q->rt_waiter);\n\tq->rt_waiter = NULL;\n\n\tq->lock_ptr = &hb->lock;\n\n\t/* Signal locked state to the waiter */\n\tfutex_requeue_pi_complete(q, 1);\n\twake_up_state(q->task, TASK_NORMAL);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nvoid requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,\n\t\t\t   struct futex_hash_bucket *hb)\n{\n\tq->key = *key;\n\n\t__futex_unqueue(q);\n\n\tWARN_ON(!q->rt_waiter);\n\tq->rt_waiter = NULL;\n\n\tq->lock_ptr = &hb->lock;\n\n\t/* Signal locked state to the waiter */\n\tfutex_requeue_pi_complete(q, 1);\n\twake_up_state(q->task, TASK_NORMAL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_mutex_start_proxy_lock",
          "args": [
            "&pi_state->pi_mutex",
            "this->rt_waiter",
            "this->task"
          ],
          "line": 627
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_start_proxy_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "339-352",
          "snippet": "int __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t      struct rt_mutex_waiter *waiter,\n\t\t\t\t      struct task_struct *task)\n{\n\tint ret;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);\n\tif (unlikely(ret))\n\t\tremove_waiter(lock, waiter);\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn ret;\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,\n\t\t\t\t      struct rt_mutex_waiter *waiter,\n\t\t\t\t      struct task_struct *task)\n{\n\tint ret;\n\n\traw_spin_lock_irq(&lock->wait_lock);\n\tret = __rt_mutex_start_proxy_lock(lock, waiter, task);\n\tif (unlikely(ret))\n\t\tremove_waiter(lock, waiter);\n\traw_spin_unlock_irq(&lock->wait_lock);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_requeue_pi_prepare",
          "args": [
            "this",
            "pi_state"
          ],
          "line": 617
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue_pi_prepare",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "92-123",
          "snippet": "static inline bool futex_requeue_pi_prepare(struct futex_q *q,\n\t\t\t\t\t    struct futex_pi_state *pi_state)\n{\n\tint old, new;\n\n\t/*\n\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has\n\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should\n\t * ignore the waiter.\n\t */\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn false;\n\n\t\t/*\n\t\t * futex_proxy_trylock_atomic() might have set it to\n\t\t * IN_PROGRESS and a interleaved early wake to WAIT.\n\t\t *\n\t\t * It was considered to have an extra state for that\n\t\t * trylock, but that would just add more conditionals\n\t\t * all over the place for a dubious value.\n\t\t */\n\t\tif (old != Q_REQUEUE_PI_NONE)\n\t\t\tbreak;\n\n\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\tq->pi_state = pi_state;\n\treturn true;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline bool futex_requeue_pi_prepare(struct futex_q *q,\n\t\t\t\t\t    struct futex_pi_state *pi_state)\n{\n\tint old, new;\n\n\t/*\n\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has\n\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should\n\t * ignore the waiter.\n\t */\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn false;\n\n\t\t/*\n\t\t * futex_proxy_trylock_atomic() might have set it to\n\t\t * IN_PROGRESS and a interleaved early wake to WAIT.\n\t\t *\n\t\t * It was considered to have an extra state for that\n\t\t * trylock, but that would just add more conditionals\n\t\t * all over the place for a dubious value.\n\t\t */\n\t\tif (old != Q_REQUEUE_PI_NONE)\n\t\t\tbreak;\n\n\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\tq->pi_state = pi_state;\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_pi_state",
          "args": [
            "pi_state"
          ],
          "line": 614
        },
        "resolved": true,
        "details": {
          "function_name": "get_pi_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "68-71",
          "snippet": "void get_pi_state(struct futex_pi_state *pi_state)\n{\n\tWARN_ON_ONCE(!refcount_inc_not_zero(&pi_state->refcount));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nvoid get_pi_state(struct futex_pi_state *pi_state)\n{\n\tWARN_ON_ONCE(!refcount_inc_not_zero(&pi_state->refcount));\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_match",
          "args": [
            "this->requeue_pi_key",
            "&key2"
          ],
          "line": 601
        },
        "resolved": true,
        "details": {
          "function_name": "futex_match",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "134-140",
          "snippet": "static inline int futex_match(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline int futex_match(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_wake_mark",
          "args": [
            "&wake_q",
            "this"
          ],
          "line": 594
        },
        "resolved": true,
        "details": {
          "function_name": "futex_wake_mark",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/waitwake.c",
          "lines": "115-138",
          "snippet": "void futex_wake_mark(struct wake_q_head *wake_q, struct futex_q *q)\n{\n\tstruct task_struct *p = q->task;\n\n\tif (WARN(q->pi_state || q->rt_waiter, \"refusing to wake PI futex\\n\"))\n\t\treturn;\n\n\tget_task_struct(p);\n\t__futex_unqueue(q);\n\t/*\n\t * The waiting task can free the futex_q as soon as q->lock_ptr = NULL\n\t * is written, without taking any locks. This is possible in the event\n\t * of a spurious wakeup, for example. A memory barrier is required here\n\t * to prevent the following store to lock_ptr from getting ahead of the\n\t * plist_del in __futex_unqueue().\n\t */\n\tsmp_store_release(&q->lock_ptr, NULL);\n\n\t/*\n\t * Queue the task for later wakeup for after we've released\n\t * the hb->lock.\n\t */\n\twake_q_add_safe(wake_q, p);\n}",
          "includes": [
            "#include \"futex.h\"",
            "#include <linux/freezer.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/task.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"futex.h\"\n#include <linux/freezer.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/task.h>\n\nvoid futex_wake_mark(struct wake_q_head *wake_q, struct futex_q *q)\n{\n\tstruct task_struct *p = q->task;\n\n\tif (WARN(q->pi_state || q->rt_waiter, \"refusing to wake PI futex\\n\"))\n\t\treturn;\n\n\tget_task_struct(p);\n\t__futex_unqueue(q);\n\t/*\n\t * The waiting task can free the futex_q as soon as q->lock_ptr = NULL\n\t * is written, without taking any locks. This is possible in the event\n\t * of a spurious wakeup, for example. A memory barrier is required here\n\t * to prevent the following store to lock_ptr from getting ahead of the\n\t * plist_del in __futex_unqueue().\n\t */\n\tsmp_store_release(&q->lock_ptr, NULL);\n\n\t/*\n\t * Queue the task for later wakeup for after we've released\n\t * the hb->lock.\n\t */\n\twake_q_add_safe(wake_q, p);\n}"
        }
      },
      {
        "call_info": {
          "callee": "plist_for_each_entry_safe",
          "args": [
            "this",
            "next",
            "&hb1->chain",
            "list"
          ],
          "line": 570
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 563
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "wait_for_owner_exiting",
          "args": [
            "ret",
            "exiting"
          ],
          "line": 562
        },
        "resolved": true,
        "details": {
          "function_name": "wait_for_owner_exiting",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "469-491",
          "snippet": "void wait_for_owner_exiting(int ret, struct task_struct *exiting)\n{\n\tif (ret != -EBUSY) {\n\t\tWARN_ON_ONCE(exiting);\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(ret == -EBUSY && !exiting))\n\t\treturn;\n\n\tmutex_lock(&exiting->futex_exit_mutex);\n\t/*\n\t * No point in doing state checking here. If the waiter got here\n\t * while the task was in exec()->exec_futex_release() then it can\n\t * have any FUTEX_STATE_* value when the waiter has acquired the\n\t * mutex. OK, if running, EXITING or DEAD if it reached exit()\n\t * already. Highly unlikely and not a problem. Just one more round\n\t * through the futex maze.\n\t */\n\tmutex_unlock(&exiting->futex_exit_mutex);\n\n\tput_task_struct(exiting);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nvoid wait_for_owner_exiting(int ret, struct task_struct *exiting)\n{\n\tif (ret != -EBUSY) {\n\t\tWARN_ON_ONCE(exiting);\n\t\treturn;\n\t}\n\n\tif (WARN_ON_ONCE(ret == -EBUSY && !exiting))\n\t\treturn;\n\n\tmutex_lock(&exiting->futex_exit_mutex);\n\t/*\n\t * No point in doing state checking here. If the waiter got here\n\t * while the task was in exec()->exec_futex_release() then it can\n\t * have any FUTEX_STATE_* value when the waiter has acquired the\n\t * mutex. OK, if running, EXITING or DEAD if it reached exit()\n\t * already. Highly unlikely and not a problem. Just one more round\n\t * through the futex maze.\n\t */\n\tmutex_unlock(&exiting->futex_exit_mutex);\n\n\tput_task_struct(exiting);\n}"
        }
      },
      {
        "call_info": {
          "callee": "fault_in_user_writeable",
          "args": [
            "uaddr2"
          ],
          "line": 543
        },
        "resolved": true,
        "details": {
          "function_name": "fault_in_user_writeable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "409-420",
          "snippet": "int fault_in_user_writeable(u32 __user *uaddr)\n{\n\tstruct mm_struct *mm = current->mm;\n\tint ret;\n\n\tmmap_read_lock(mm);\n\tret = fixup_user_fault(mm, (unsigned long)uaddr,\n\t\t\t       FAULT_FLAG_WRITE, NULL);\n\tmmap_read_unlock(mm);\n\n\treturn ret < 0 ? ret : 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nint fault_in_user_writeable(u32 __user *uaddr)\n{\n\tstruct mm_struct *mm = current->mm;\n\tint ret;\n\n\tmmap_read_lock(mm);\n\tret = fixup_user_fault(mm, (unsigned long)uaddr,\n\t\t\t       FAULT_FLAG_WRITE, NULL);\n\tmmap_read_unlock(mm);\n\n\treturn ret < 0 ? ret : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_proxy_trylock_atomic",
          "args": [
            "uaddr2",
            "hb1",
            "hb2",
            "&key1",
            "&key2",
            "&pi_state",
            "&exiting",
            "nr_requeue"
          ],
          "line": 484
        },
        "resolved": true,
        "details": {
          "function_name": "futex_proxy_trylock_atomic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "266-344",
          "snippet": "static int\nfutex_proxy_trylock_atomic(u32 __user *pifutex, struct futex_hash_bucket *hb1,\n\t\t\t   struct futex_hash_bucket *hb2, union futex_key *key1,\n\t\t\t   union futex_key *key2, struct futex_pi_state **ps,\n\t\t\t   struct task_struct **exiting, int set_waiters)\n{\n\tstruct futex_q *top_waiter = NULL;\n\tu32 curval;\n\tint ret;\n\n\tif (futex_get_value_locked(&curval, pifutex))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * Find the top_waiter and determine if there are additional waiters.\n\t * If the caller intends to requeue more than 1 waiter to pifutex,\n\t * force futex_lock_pi_atomic() to set the FUTEX_WAITERS bit now,\n\t * as we have means to handle the possible fault.  If not, don't set\n\t * the bit unnecessarily as it will force the subsequent unlock to enter\n\t * the kernel.\n\t */\n\ttop_waiter = futex_top_waiter(hb1, key1);\n\n\t/* There are no waiters, nothing for us to do. */\n\tif (!top_waiter)\n\t\treturn 0;\n\n\t/*\n\t * Ensure that this is a waiter sitting in futex_wait_requeue_pi()\n\t * and waiting on the 'waitqueue' futex which is always !PI.\n\t */\n\tif (!top_waiter->rt_waiter || top_waiter->pi_state)\n\t\treturn -EINVAL;\n\n\t/* Ensure we requeue to the expected futex. */\n\tif (!futex_match(top_waiter->requeue_pi_key, key2))\n\t\treturn -EINVAL;\n\n\t/* Ensure that this does not race against an early wakeup */\n\tif (!futex_requeue_pi_prepare(top_waiter, NULL))\n\t\treturn -EAGAIN;\n\n\t/*\n\t * Try to take the lock for top_waiter and set the FUTEX_WAITERS bit\n\t * in the contended case or if @set_waiters is true.\n\t *\n\t * In the contended case PI state is attached to the lock owner. If\n\t * the user space lock can be acquired then PI state is attached to\n\t * the new owner (@top_waiter->task) when @set_waiters is true.\n\t */\n\tret = futex_lock_pi_atomic(pifutex, hb2, key2, ps, top_waiter->task,\n\t\t\t\t   exiting, set_waiters);\n\tif (ret == 1) {\n\t\t/*\n\t\t * Lock was acquired in user space and PI state was\n\t\t * attached to @top_waiter->task. That means state is fully\n\t\t * consistent and the waiter can return to user space\n\t\t * immediately after the wakeup.\n\t\t */\n\t\trequeue_pi_wake_futex(top_waiter, key2, hb2);\n\t} else if (ret < 0) {\n\t\t/* Rewind top_waiter::requeue_state */\n\t\tfutex_requeue_pi_complete(top_waiter, ret);\n\t} else {\n\t\t/*\n\t\t * futex_lock_pi_atomic() did not acquire the user space\n\t\t * futex, but managed to establish the proxy lock and pi\n\t\t * state. top_waiter::requeue_state cannot be fixed up here\n\t\t * because the waiter is not enqueued on the rtmutex\n\t\t * yet. This is handled at the callsite depending on the\n\t\t * result of rt_mutex_start_proxy_lock() which is\n\t\t * guaranteed to be reached with this function returning 0.\n\t\t */\n\t}\n\treturn ret;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic int\nfutex_proxy_trylock_atomic(u32 __user *pifutex, struct futex_hash_bucket *hb1,\n\t\t\t   struct futex_hash_bucket *hb2, union futex_key *key1,\n\t\t\t   union futex_key *key2, struct futex_pi_state **ps,\n\t\t\t   struct task_struct **exiting, int set_waiters)\n{\n\tstruct futex_q *top_waiter = NULL;\n\tu32 curval;\n\tint ret;\n\n\tif (futex_get_value_locked(&curval, pifutex))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * Find the top_waiter and determine if there are additional waiters.\n\t * If the caller intends to requeue more than 1 waiter to pifutex,\n\t * force futex_lock_pi_atomic() to set the FUTEX_WAITERS bit now,\n\t * as we have means to handle the possible fault.  If not, don't set\n\t * the bit unnecessarily as it will force the subsequent unlock to enter\n\t * the kernel.\n\t */\n\ttop_waiter = futex_top_waiter(hb1, key1);\n\n\t/* There are no waiters, nothing for us to do. */\n\tif (!top_waiter)\n\t\treturn 0;\n\n\t/*\n\t * Ensure that this is a waiter sitting in futex_wait_requeue_pi()\n\t * and waiting on the 'waitqueue' futex which is always !PI.\n\t */\n\tif (!top_waiter->rt_waiter || top_waiter->pi_state)\n\t\treturn -EINVAL;\n\n\t/* Ensure we requeue to the expected futex. */\n\tif (!futex_match(top_waiter->requeue_pi_key, key2))\n\t\treturn -EINVAL;\n\n\t/* Ensure that this does not race against an early wakeup */\n\tif (!futex_requeue_pi_prepare(top_waiter, NULL))\n\t\treturn -EAGAIN;\n\n\t/*\n\t * Try to take the lock for top_waiter and set the FUTEX_WAITERS bit\n\t * in the contended case or if @set_waiters is true.\n\t *\n\t * In the contended case PI state is attached to the lock owner. If\n\t * the user space lock can be acquired then PI state is attached to\n\t * the new owner (@top_waiter->task) when @set_waiters is true.\n\t */\n\tret = futex_lock_pi_atomic(pifutex, hb2, key2, ps, top_waiter->task,\n\t\t\t\t   exiting, set_waiters);\n\tif (ret == 1) {\n\t\t/*\n\t\t * Lock was acquired in user space and PI state was\n\t\t * attached to @top_waiter->task. That means state is fully\n\t\t * consistent and the waiter can return to user space\n\t\t * immediately after the wakeup.\n\t\t */\n\t\trequeue_pi_wake_futex(top_waiter, key2, hb2);\n\t} else if (ret < 0) {\n\t\t/* Rewind top_waiter::requeue_state */\n\t\tfutex_requeue_pi_complete(top_waiter, ret);\n\t} else {\n\t\t/*\n\t\t * futex_lock_pi_atomic() did not acquire the user space\n\t\t * futex, but managed to establish the proxy lock and pi\n\t\t * state. top_waiter::requeue_state cannot be fixed up here\n\t\t * because the waiter is not enqueued on the rtmutex\n\t\t * yet. This is handled at the callsite depending on the\n\t\t * result of rt_mutex_start_proxy_lock() which is\n\t\t * guaranteed to be reached with this function returning 0.\n\t\t */\n\t}\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_user",
          "args": [
            "curval",
            "uaddr1"
          ],
          "line": 458
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_obj_get_user",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/inode.c",
          "lines": "530-557",
          "snippet": "int bpf_obj_get_user(const char __user *pathname, int flags)\n{\n\tenum bpf_type type = BPF_TYPE_UNSPEC;\n\tint f_flags;\n\tvoid *raw;\n\tint ret;\n\n\tf_flags = bpf_get_file_flag(flags);\n\tif (f_flags < 0)\n\t\treturn f_flags;\n\n\traw = bpf_obj_do_get(pathname, &type, f_flags);\n\tif (IS_ERR(raw))\n\t\treturn PTR_ERR(raw);\n\n\tif (type == BPF_TYPE_PROG)\n\t\tret = bpf_prog_new_fd(raw);\n\telse if (type == BPF_TYPE_MAP)\n\t\tret = bpf_map_new_fd(raw, f_flags);\n\telse if (type == BPF_TYPE_LINK)\n\t\tret = (f_flags != O_RDWR) ? -EINVAL : bpf_link_new_fd(raw);\n\telse\n\t\treturn -ENOENT;\n\n\tif (ret < 0)\n\t\tbpf_any_put(raw, type);\n\treturn ret;\n}",
          "includes": [
            "#include \"preload/bpf_preload.h\"",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>",
            "#include <linux/filter.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/fs_context.h>",
            "#include <linux/fs.h>",
            "#include <linux/namei.h>",
            "#include <linux/mount.h>",
            "#include <linux/major.h>",
            "#include <linux/magic.h>",
            "#include <linux/init.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"preload/bpf_preload.h\"\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n#include <linux/filter.h>\n#include <linux/kdev_t.h>\n#include <linux/fs_parser.h>\n#include <linux/fs_context.h>\n#include <linux/fs.h>\n#include <linux/namei.h>\n#include <linux/mount.h>\n#include <linux/major.h>\n#include <linux/magic.h>\n#include <linux/init.h>\n\nint bpf_obj_get_user(const char __user *pathname, int flags)\n{\n\tenum bpf_type type = BPF_TYPE_UNSPEC;\n\tint f_flags;\n\tvoid *raw;\n\tint ret;\n\n\tf_flags = bpf_get_file_flag(flags);\n\tif (f_flags < 0)\n\t\treturn f_flags;\n\n\traw = bpf_obj_do_get(pathname, &type, f_flags);\n\tif (IS_ERR(raw))\n\t\treturn PTR_ERR(raw);\n\n\tif (type == BPF_TYPE_PROG)\n\t\tret = bpf_prog_new_fd(raw);\n\telse if (type == BPF_TYPE_MAP)\n\t\tret = bpf_map_new_fd(raw, f_flags);\n\telse if (type == BPF_TYPE_LINK)\n\t\tret = (f_flags != O_RDWR) ? -EINVAL : bpf_link_new_fd(raw);\n\telse\n\t\treturn -ENOENT;\n\n\tif (ret < 0)\n\t\tbpf_any_put(raw, type);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret"
          ],
          "line": 454
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "futex_get_value_locked",
          "args": [
            "&curval",
            "uaddr1"
          ],
          "line": 452
        },
        "resolved": true,
        "details": {
          "function_name": "futex_get_value_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "451-460",
          "snippet": "int futex_get_value_locked(u32 *dest, u32 __user *from)\n{\n\tint ret;\n\n\tpagefault_disable();\n\tret = __get_user(*dest, from);\n\tpagefault_enable();\n\n\treturn ret ? -EFAULT : 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nint futex_get_value_locked(u32 *dest, u32 __user *from)\n{\n\tint ret;\n\n\tpagefault_disable();\n\tret = __get_user(*dest, from);\n\tpagefault_enable();\n\n\treturn ret ? -EFAULT : 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "cmpval != NULL"
          ],
          "line": 449
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "double_lock_hb",
          "args": [
            "hb1",
            "hb2"
          ],
          "line": 447
        },
        "resolved": true,
        "details": {
          "function_name": "double_lock_hb",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "237-246",
          "snippet": "static inline void\ndouble_lock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)\n{\n\tif (hb1 > hb2)\n\t\tswap(hb1, hb2);\n\n\tspin_lock(&hb1->lock);\n\tif (hb1 != hb2)\n\t\tspin_lock_nested(&hb2->lock, SINGLE_DEPTH_NESTING);\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void\ndouble_lock_hb(struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2)\n{\n\tif (hb1 > hb2)\n\t\tswap(hb1, hb2);\n\n\tspin_lock(&hb1->lock);\n\tif (hb1 != hb2)\n\t\tspin_lock_nested(&hb2->lock, SINGLE_DEPTH_NESTING);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_hb_waiters_inc",
          "args": [
            "hb2"
          ],
          "line": 446
        },
        "resolved": true,
        "details": {
          "function_name": "futex_hb_waiters_inc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "183-192",
          "snippet": "static inline void futex_hb_waiters_inc(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_inc(&hb->waiters);\n\t/*\n\t * Full barrier (A), see the ordering comment above.\n\t */\n\tsmp_mb__after_atomic();\n#endif\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void futex_hb_waiters_inc(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_inc(&hb->waiters);\n\t/*\n\t * Full barrier (A), see the ordering comment above.\n\t */\n\tsmp_mb__after_atomic();\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_hash",
          "args": [
            "&key2"
          ],
          "line": 443
        },
        "resolved": true,
        "details": {
          "function_name": "futex_hash",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "115-121",
          "snippet": "struct futex_hash_bucket *futex_hash(union futex_key *key)\n{\n\tu32 hash = jhash2((u32 *)key, offsetof(typeof(*key), both.offset) / 4,\n\t\t\t  key->both.offset);\n\n\treturn &futex_queues[hash & (futex_hashsize - 1)];\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [
            "#define futex_hashsize (__futex_data.hashsize)",
            "#define futex_queues   (__futex_data.queues)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\n#define futex_hashsize (__futex_data.hashsize)\n#define futex_queues   (__futex_data.queues)\n\nstruct futex_hash_bucket *futex_hash(union futex_key *key)\n{\n\tu32 hash = jhash2((u32 *)key, offsetof(typeof(*key), both.offset) / 4,\n\t\t\t  key->both.offset);\n\n\treturn &futex_queues[hash & (futex_hashsize - 1)];\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret != 0"
          ],
          "line": 432
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_futex_key",
          "args": [
            "uaddr2",
            "flags & FLAGS_SHARED",
            "&key2",
            "requeue_pi ? FUTEX_WRITE : FUTEX_READ"
          ],
          "line": 430
        },
        "resolved": true,
        "details": {
          "function_name": "get_futex_key",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "220-395",
          "snippet": "int get_futex_key(u32 __user *uaddr, bool fshared, union futex_key *key,\n\t\t  enum futex_access rw)\n{\n\tunsigned long address = (unsigned long)uaddr;\n\tstruct mm_struct *mm = current->mm;\n\tstruct page *page, *tail;\n\tstruct address_space *mapping;\n\tint err, ro = 0;\n\n\t/*\n\t * The futex address must be \"naturally\" aligned.\n\t */\n\tkey->both.offset = address % PAGE_SIZE;\n\tif (unlikely((address % sizeof(u32)) != 0))\n\t\treturn -EINVAL;\n\taddress -= key->both.offset;\n\n\tif (unlikely(!access_ok(uaddr, sizeof(u32))))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(fshared)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * PROCESS_PRIVATE futexes are fast.\n\t * As the mm cannot disappear under us and the 'key' only needs\n\t * virtual address, we dont even have to find the underlying vma.\n\t * Note : We do have to check 'uaddr' is a valid user address,\n\t *        but access_ok() should be faster than find_vma()\n\t */\n\tif (!fshared) {\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\t\treturn 0;\n\t}\n\nagain:\n\t/* Ignore any VERIFY_READ mapping (futex common case) */\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\terr = get_user_pages_fast(address, 1, FOLL_WRITE, &page);\n\t/*\n\t * If write access is not required (eg. FUTEX_WAIT), try\n\t * and get read-only access.\n\t */\n\tif (err == -EFAULT && rw == FUTEX_READ) {\n\t\terr = get_user_pages_fast(address, 1, 0, &page);\n\t\tro = 1;\n\t}\n\tif (err < 0)\n\t\treturn err;\n\telse\n\t\terr = 0;\n\n\t/*\n\t * The treatment of mapping from this point on is critical. The page\n\t * lock protects many things but in this context the page lock\n\t * stabilizes mapping, prevents inode freeing in the shared\n\t * file-backed region case and guards against movement to swap cache.\n\t *\n\t * Strictly speaking the page lock is not needed in all cases being\n\t * considered here and page lock forces unnecessarily serialization\n\t * From this point on, mapping will be re-verified if necessary and\n\t * page lock will be acquired only if it is unavoidable\n\t *\n\t * Mapping checks require the head page for any compound page so the\n\t * head page and mapping is looked up now. For anonymous pages, it\n\t * does not matter if the page splits in the future as the key is\n\t * based on the address. For filesystem-backed pages, the tail is\n\t * required as the index of the page determines the key. For\n\t * base pages, there is no tail page and tail == page.\n\t */\n\ttail = page;\n\tpage = compound_head(page);\n\tmapping = READ_ONCE(page->mapping);\n\n\t/*\n\t * If page->mapping is NULL, then it cannot be a PageAnon\n\t * page; but it might be the ZERO_PAGE or in the gate area or\n\t * in a special mapping (all cases which we are happy to fail);\n\t * or it may have been a good file page when get_user_pages_fast\n\t * found it, but truncated or holepunched or subjected to\n\t * invalidate_complete_page2 before we got the page lock (also\n\t * cases which we are happy to fail).  And we hold a reference,\n\t * so refcount care in invalidate_complete_page's remove_mapping\n\t * prevents drop_caches from setting mapping to NULL beneath us.\n\t *\n\t * The case we do have to guard against is when memory pressure made\n\t * shmem_writepage move it from filecache to swapcache beneath us:\n\t * an unlikely race, but we do need to retry for page->mapping.\n\t */\n\tif (unlikely(!mapping)) {\n\t\tint shmem_swizzled;\n\n\t\t/*\n\t\t * Page lock is required to identify which special case above\n\t\t * applies. If this is really a shmem page then the page lock\n\t\t * will prevent unexpected transitions.\n\t\t */\n\t\tlock_page(page);\n\t\tshmem_swizzled = PageSwapCache(page) || page->mapping;\n\t\tunlock_page(page);\n\t\tput_page(page);\n\n\t\tif (shmem_swizzled)\n\t\t\tgoto again;\n\n\t\treturn -EFAULT;\n\t}\n\n\t/*\n\t * Private mappings are handled in a simple way.\n\t *\n\t * If the futex key is stored on an anonymous page, then the associated\n\t * object is the mm which is implicitly pinned by the calling process.\n\t *\n\t * NOTE: When userspace waits on a MAP_SHARED mapping, even if\n\t * it's a read-only handle, it's expected that futexes attach to\n\t * the object not the particular process.\n\t */\n\tif (PageAnon(page)) {\n\t\t/*\n\t\t * A RO anonymous page will never change and thus doesn't make\n\t\t * sense for futex operations.\n\t\t */\n\t\tif (unlikely(should_fail_futex(true)) || ro) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_MMSHARED; /* ref taken on mm */\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\n\t} else {\n\t\tstruct inode *inode;\n\n\t\t/*\n\t\t * The associated futex object in this case is the inode and\n\t\t * the page->mapping must be traversed. Ordinarily this should\n\t\t * be stabilised under page lock but it's not strictly\n\t\t * necessary in this case as we just want to pin the inode, not\n\t\t * update the radix tree or anything like that.\n\t\t *\n\t\t * The RCU read lock is taken as the inode is finally freed\n\t\t * under RCU. If the mapping still matches expectations then the\n\t\t * mapping->host can be safely accessed as being a valid inode.\n\t\t */\n\t\trcu_read_lock();\n\n\t\tif (READ_ONCE(page->mapping) != mapping) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tinode = READ_ONCE(mapping->host);\n\t\tif (!inode) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_INODE; /* inode-based key */\n\t\tkey->shared.i_seq = get_inode_sequence_number(inode);\n\t\tkey->shared.pgoff = page_to_pgoff(tail);\n\t\trcu_read_unlock();\n\t}\n\nout:\n\tput_page(page);\n\treturn err;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__read_mostly __aligned(2*sizeof(long));"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\n__read_mostly __aligned(2*sizeof(long));\n\nint get_futex_key(u32 __user *uaddr, bool fshared, union futex_key *key,\n\t\t  enum futex_access rw)\n{\n\tunsigned long address = (unsigned long)uaddr;\n\tstruct mm_struct *mm = current->mm;\n\tstruct page *page, *tail;\n\tstruct address_space *mapping;\n\tint err, ro = 0;\n\n\t/*\n\t * The futex address must be \"naturally\" aligned.\n\t */\n\tkey->both.offset = address % PAGE_SIZE;\n\tif (unlikely((address % sizeof(u32)) != 0))\n\t\treturn -EINVAL;\n\taddress -= key->both.offset;\n\n\tif (unlikely(!access_ok(uaddr, sizeof(u32))))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(fshared)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * PROCESS_PRIVATE futexes are fast.\n\t * As the mm cannot disappear under us and the 'key' only needs\n\t * virtual address, we dont even have to find the underlying vma.\n\t * Note : We do have to check 'uaddr' is a valid user address,\n\t *        but access_ok() should be faster than find_vma()\n\t */\n\tif (!fshared) {\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\t\treturn 0;\n\t}\n\nagain:\n\t/* Ignore any VERIFY_READ mapping (futex common case) */\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\terr = get_user_pages_fast(address, 1, FOLL_WRITE, &page);\n\t/*\n\t * If write access is not required (eg. FUTEX_WAIT), try\n\t * and get read-only access.\n\t */\n\tif (err == -EFAULT && rw == FUTEX_READ) {\n\t\terr = get_user_pages_fast(address, 1, 0, &page);\n\t\tro = 1;\n\t}\n\tif (err < 0)\n\t\treturn err;\n\telse\n\t\terr = 0;\n\n\t/*\n\t * The treatment of mapping from this point on is critical. The page\n\t * lock protects many things but in this context the page lock\n\t * stabilizes mapping, prevents inode freeing in the shared\n\t * file-backed region case and guards against movement to swap cache.\n\t *\n\t * Strictly speaking the page lock is not needed in all cases being\n\t * considered here and page lock forces unnecessarily serialization\n\t * From this point on, mapping will be re-verified if necessary and\n\t * page lock will be acquired only if it is unavoidable\n\t *\n\t * Mapping checks require the head page for any compound page so the\n\t * head page and mapping is looked up now. For anonymous pages, it\n\t * does not matter if the page splits in the future as the key is\n\t * based on the address. For filesystem-backed pages, the tail is\n\t * required as the index of the page determines the key. For\n\t * base pages, there is no tail page and tail == page.\n\t */\n\ttail = page;\n\tpage = compound_head(page);\n\tmapping = READ_ONCE(page->mapping);\n\n\t/*\n\t * If page->mapping is NULL, then it cannot be a PageAnon\n\t * page; but it might be the ZERO_PAGE or in the gate area or\n\t * in a special mapping (all cases which we are happy to fail);\n\t * or it may have been a good file page when get_user_pages_fast\n\t * found it, but truncated or holepunched or subjected to\n\t * invalidate_complete_page2 before we got the page lock (also\n\t * cases which we are happy to fail).  And we hold a reference,\n\t * so refcount care in invalidate_complete_page's remove_mapping\n\t * prevents drop_caches from setting mapping to NULL beneath us.\n\t *\n\t * The case we do have to guard against is when memory pressure made\n\t * shmem_writepage move it from filecache to swapcache beneath us:\n\t * an unlikely race, but we do need to retry for page->mapping.\n\t */\n\tif (unlikely(!mapping)) {\n\t\tint shmem_swizzled;\n\n\t\t/*\n\t\t * Page lock is required to identify which special case above\n\t\t * applies. If this is really a shmem page then the page lock\n\t\t * will prevent unexpected transitions.\n\t\t */\n\t\tlock_page(page);\n\t\tshmem_swizzled = PageSwapCache(page) || page->mapping;\n\t\tunlock_page(page);\n\t\tput_page(page);\n\n\t\tif (shmem_swizzled)\n\t\t\tgoto again;\n\n\t\treturn -EFAULT;\n\t}\n\n\t/*\n\t * Private mappings are handled in a simple way.\n\t *\n\t * If the futex key is stored on an anonymous page, then the associated\n\t * object is the mm which is implicitly pinned by the calling process.\n\t *\n\t * NOTE: When userspace waits on a MAP_SHARED mapping, even if\n\t * it's a read-only handle, it's expected that futexes attach to\n\t * the object not the particular process.\n\t */\n\tif (PageAnon(page)) {\n\t\t/*\n\t\t * A RO anonymous page will never change and thus doesn't make\n\t\t * sense for futex operations.\n\t\t */\n\t\tif (unlikely(should_fail_futex(true)) || ro) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_MMSHARED; /* ref taken on mm */\n\t\tkey->private.mm = mm;\n\t\tkey->private.address = address;\n\n\t} else {\n\t\tstruct inode *inode;\n\n\t\t/*\n\t\t * The associated futex object in this case is the inode and\n\t\t * the page->mapping must be traversed. Ordinarily this should\n\t\t * be stabilised under page lock but it's not strictly\n\t\t * necessary in this case as we just want to pin the inode, not\n\t\t * update the radix tree or anything like that.\n\t\t *\n\t\t * The RCU read lock is taken as the inode is finally freed\n\t\t * under RCU. If the mapping still matches expectations then the\n\t\t * mapping->host can be safely accessed as being a valid inode.\n\t\t */\n\t\trcu_read_lock();\n\n\t\tif (READ_ONCE(page->mapping) != mapping) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tinode = READ_ONCE(mapping->host);\n\t\tif (!inode) {\n\t\t\trcu_read_unlock();\n\t\t\tput_page(page);\n\n\t\t\tgoto again;\n\t\t}\n\n\t\tkey->both.offset |= FUT_OFF_INODE; /* inode-based key */\n\t\tkey->shared.i_seq = get_inode_sequence_number(inode);\n\t\tkey->shared.pgoff = page_to_pgoff(tail);\n\t\trcu_read_unlock();\n\t}\n\nout:\n\tput_page(page);\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret != 0"
          ],
          "line": 428
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "refill_pi_state_cache",
          "args": [],
          "line": 422
        },
        "resolved": true,
        "details": {
          "function_name": "refill_pi_state_cache",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "12-33",
          "snippet": "int refill_pi_state_cache(void)\n{\n\tstruct futex_pi_state *pi_state;\n\n\tif (likely(current->pi_state_cache))\n\t\treturn 0;\n\n\tpi_state = kzalloc(sizeof(*pi_state), GFP_KERNEL);\n\n\tif (!pi_state)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&pi_state->list);\n\t/* pi_mutex gets initialized later */\n\tpi_state->owner = NULL;\n\trefcount_set(&pi_state->refcount, 1);\n\tpi_state->key = FUTEX_KEY_INIT;\n\n\tcurrent->pi_state_cache = pi_state;\n\n\treturn 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nint refill_pi_state_cache(void)\n{\n\tstruct futex_pi_state *pi_state;\n\n\tif (likely(current->pi_state_cache))\n\t\treturn 0;\n\n\tpi_state = kzalloc(sizeof(*pi_state), GFP_KERNEL);\n\n\tif (!pi_state)\n\t\treturn -ENOMEM;\n\n\tINIT_LIST_HEAD(&pi_state->list);\n\t/* pi_mutex gets initialized later */\n\tpi_state->owner = NULL;\n\trefcount_set(&pi_state->refcount, 1);\n\tpi_state->key = FUTEX_KEY_INIT;\n\n\tcurrent->pi_state_cache = pi_state;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_FUTEX_PI"
          ],
          "line": 383
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 372
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nint futex_requeue(u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2,\n\t\t  int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * futex_requeue() allows the caller to define the number\n\t\t * of waiters to wake up via the @nr_wake argument. With\n\t\t * REQUEUE_PI, waking up more than one waiter is creating\n\t\t * more problems than it solves. Waking up a waiter makes\n\t\t * only sense if the PI futex @uaddr2 is uncontended as\n\t\t * this allows the requeue code to acquire the futex\n\t\t * @uaddr2 before waking the waiter. The waiter can then\n\t\t * return to user space without further action. A secondary\n\t\t * wakeup would just make the futex_wait_requeue_pi()\n\t\t * handling more complex, because that code would have to\n\t\t * look up pi_state and do more or less all the handling\n\t\t * which the requeue code has to do for the to be requeued\n\t\t * waiters. So restrict the number of waiters to wake to\n\t\t * one, and only wake it up when the PI futex is\n\t\t * uncontended. Otherwise requeue it and let the unlock of\n\t\t * the PI futex handle the wakeup.\n\t\t *\n\t\t * All REQUEUE_PI users, e.g. pthread_cond_signal() and\n\t\t * pthread_cond_broadcast() must use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? FUTEX_WRITE : FUTEX_READ);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && futex_match(&key1, &key2))\n\t\treturn -EINVAL;\n\n\thb1 = futex_hash(&key1);\n\thb2 = futex_hash(&key2);\n\nretry_private:\n\tfutex_hb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = futex_get_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi) {\n\t\tstruct task_struct *exiting = NULL;\n\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t *\n\t\t * Updates topwaiter::requeue_state if a top waiter exists.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state,\n\t\t\t\t\t\t &exiting, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or\n\t\t * is waiting on it. In both cases pi_state has been\n\t\t * established and an initial refcount on it. In case of an\n\t\t * error there's nothing.\n\t\t *\n\t\t * The top waiter's requeue_state is up to date:\n\t\t *\n\t\t *  - If the lock was acquired atomically (ret == 1), then\n\t\t *    the state is Q_REQUEUE_PI_LOCKED.\n\t\t *\n\t\t *    The top waiter has been dequeued and woken up and can\n\t\t *    return to user space immediately. The kernel/user\n\t\t *    space state is consistent. In case that there must be\n\t\t *    more waiters requeued the WAITERS bit in the user\n\t\t *    space futex is set so the top waiter task has to go\n\t\t *    into the syscall slowpath to unlock the futex. This\n\t\t *    will block until this requeue operation has been\n\t\t *    completed and the hash bucket locks have been\n\t\t *    dropped.\n\t\t *\n\t\t *  - If the trylock failed with an error (ret < 0) then\n\t\t *    the state is either Q_REQUEUE_PI_NONE, i.e. \"nothing\n\t\t *    happened\", or Q_REQUEUE_PI_IGNORE when there was an\n\t\t *    interleaved early wakeup.\n\t\t *\n\t\t *  - If the trylock did not succeed (ret == 0) then the\n\t\t *    state is either Q_REQUEUE_PI_IN_PROGRESS or\n\t\t *    Q_REQUEUE_PI_WAIT if an early wakeup interleaved.\n\t\t *    This will be cleaned up in the loop below, which\n\t\t *    cannot fail because futex_proxy_trylock_atomic() did\n\t\t *    the same sanity checks for requeue_pi as the loop\n\t\t *    below does.\n\t\t */\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\tcase 1:\n\t\t\t/*\n\t\t\t * futex_proxy_trylock_atomic() acquired the user space\n\t\t\t * futex. Adjust task_count.\n\t\t\t */\n\t\t\ttask_count++;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If the above failed, then pi_state is NULL and\n\t\t * waiter::requeue_state is correct.\n\t\t */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\treturn ret;\n\t\tcase -EBUSY:\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - EBUSY: Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - EAGAIN: The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\tfutex_hb_waiters_dec(hb2);\n\t\t\t/*\n\t\t\t * Handle the case where the owner is in the middle of\n\t\t\t * exiting. Wait for the exit to complete otherwise\n\t\t\t * this task might loop forever, aka. live lock.\n\t\t\t */\n\t\t\twait_for_owner_exiting(ret, exiting);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!futex_match(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQUEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Plain futexes just wake or requeue and are done */\n\t\tif (!requeue_pi) {\n\t\t\tif (++task_count <= nr_wake)\n\t\t\t\tfutex_wake_mark(&wake_q, this);\n\t\t\telse\n\t\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (!futex_match(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t *\n\t\t * Prepare the waiter to take the rt_mutex. Take a refcount\n\t\t * on the pi_state and store the pointer in the futex_q\n\t\t * object of the waiter.\n\t\t */\n\t\tget_pi_state(pi_state);\n\n\t\t/* Don't requeue when the waiter is already on the way out. */\n\t\tif (!futex_requeue_pi_prepare(this, pi_state)) {\n\t\t\t/*\n\t\t\t * Early woken waiter signaled that it is on the\n\t\t\t * way out. Drop the pi_state reference and try the\n\t\t\t * next waiter. @this->pi_state is still NULL.\n\t\t\t */\n\t\t\tput_pi_state(pi_state);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\tthis->task);\n\n\t\tif (ret == 1) {\n\t\t\t/*\n\t\t\t * We got the lock. We do neither drop the refcount\n\t\t\t * on pi_state nor clear this->pi_state because the\n\t\t\t * waiter needs the pi_state for cleaning up the\n\t\t\t * user space value. It will drop the refcount\n\t\t\t * after doing so. this::requeue_state is updated\n\t\t\t * in the wakeup as well.\n\t\t\t */\n\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\ttask_count++;\n\t\t} else if (!ret) {\n\t\t\t/* Waiter is queued, move it to hb2 */\n\t\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\t\tfutex_requeue_pi_complete(this, 0);\n\t\t\ttask_count++;\n\t\t} else {\n\t\t\t/*\n\t\t\t * rt_mutex_start_proxy_lock() detected a potential\n\t\t\t * deadlock when we tried to queue that waiter.\n\t\t\t * Drop the pi_state reference which we took above\n\t\t\t * and remove the pointer to the state from the\n\t\t\t * waiters futex_q object.\n\t\t\t */\n\t\t\tthis->pi_state = NULL;\n\t\t\tput_pi_state(pi_state);\n\t\t\tfutex_requeue_pi_complete(this, ret);\n\t\t\t/*\n\t\t\t * We stop queueing more waiters and let user space\n\t\t\t * deal with the mess.\n\t\t\t */\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state in\n\t * futex_proxy_trylock_atomic(). We need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\tfutex_hb_waiters_dec(hb2);\n\treturn ret ? ret : task_count;\n}"
  },
  {
    "function_name": "futex_proxy_trylock_atomic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "266-344",
    "snippet": "static int\nfutex_proxy_trylock_atomic(u32 __user *pifutex, struct futex_hash_bucket *hb1,\n\t\t\t   struct futex_hash_bucket *hb2, union futex_key *key1,\n\t\t\t   union futex_key *key2, struct futex_pi_state **ps,\n\t\t\t   struct task_struct **exiting, int set_waiters)\n{\n\tstruct futex_q *top_waiter = NULL;\n\tu32 curval;\n\tint ret;\n\n\tif (futex_get_value_locked(&curval, pifutex))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * Find the top_waiter and determine if there are additional waiters.\n\t * If the caller intends to requeue more than 1 waiter to pifutex,\n\t * force futex_lock_pi_atomic() to set the FUTEX_WAITERS bit now,\n\t * as we have means to handle the possible fault.  If not, don't set\n\t * the bit unnecessarily as it will force the subsequent unlock to enter\n\t * the kernel.\n\t */\n\ttop_waiter = futex_top_waiter(hb1, key1);\n\n\t/* There are no waiters, nothing for us to do. */\n\tif (!top_waiter)\n\t\treturn 0;\n\n\t/*\n\t * Ensure that this is a waiter sitting in futex_wait_requeue_pi()\n\t * and waiting on the 'waitqueue' futex which is always !PI.\n\t */\n\tif (!top_waiter->rt_waiter || top_waiter->pi_state)\n\t\treturn -EINVAL;\n\n\t/* Ensure we requeue to the expected futex. */\n\tif (!futex_match(top_waiter->requeue_pi_key, key2))\n\t\treturn -EINVAL;\n\n\t/* Ensure that this does not race against an early wakeup */\n\tif (!futex_requeue_pi_prepare(top_waiter, NULL))\n\t\treturn -EAGAIN;\n\n\t/*\n\t * Try to take the lock for top_waiter and set the FUTEX_WAITERS bit\n\t * in the contended case or if @set_waiters is true.\n\t *\n\t * In the contended case PI state is attached to the lock owner. If\n\t * the user space lock can be acquired then PI state is attached to\n\t * the new owner (@top_waiter->task) when @set_waiters is true.\n\t */\n\tret = futex_lock_pi_atomic(pifutex, hb2, key2, ps, top_waiter->task,\n\t\t\t\t   exiting, set_waiters);\n\tif (ret == 1) {\n\t\t/*\n\t\t * Lock was acquired in user space and PI state was\n\t\t * attached to @top_waiter->task. That means state is fully\n\t\t * consistent and the waiter can return to user space\n\t\t * immediately after the wakeup.\n\t\t */\n\t\trequeue_pi_wake_futex(top_waiter, key2, hb2);\n\t} else if (ret < 0) {\n\t\t/* Rewind top_waiter::requeue_state */\n\t\tfutex_requeue_pi_complete(top_waiter, ret);\n\t} else {\n\t\t/*\n\t\t * futex_lock_pi_atomic() did not acquire the user space\n\t\t * futex, but managed to establish the proxy lock and pi\n\t\t * state. top_waiter::requeue_state cannot be fixed up here\n\t\t * because the waiter is not enqueued on the rtmutex\n\t\t * yet. This is handled at the callsite depending on the\n\t\t * result of rt_mutex_start_proxy_lock() which is\n\t\t * guaranteed to be reached with this function returning 0.\n\t\t */\n\t}\n\treturn ret;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "futex_requeue_pi_complete",
          "args": [
            "top_waiter",
            "ret"
          ],
          "line": 331
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue_pi_complete",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "125-154",
          "snippet": "static inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "requeue_pi_wake_futex",
          "args": [
            "top_waiter",
            "key2",
            "hb2"
          ],
          "line": 328
        },
        "resolved": true,
        "details": {
          "function_name": "requeue_pi_wake_futex",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "222-238",
          "snippet": "static inline\nvoid requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,\n\t\t\t   struct futex_hash_bucket *hb)\n{\n\tq->key = *key;\n\n\t__futex_unqueue(q);\n\n\tWARN_ON(!q->rt_waiter);\n\tq->rt_waiter = NULL;\n\n\tq->lock_ptr = &hb->lock;\n\n\t/* Signal locked state to the waiter */\n\tfutex_requeue_pi_complete(q, 1);\n\twake_up_state(q->task, TASK_NORMAL);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nvoid requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,\n\t\t\t   struct futex_hash_bucket *hb)\n{\n\tq->key = *key;\n\n\t__futex_unqueue(q);\n\n\tWARN_ON(!q->rt_waiter);\n\tq->rt_waiter = NULL;\n\n\tq->lock_ptr = &hb->lock;\n\n\t/* Signal locked state to the waiter */\n\tfutex_requeue_pi_complete(q, 1);\n\twake_up_state(q->task, TASK_NORMAL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_lock_pi_atomic",
          "args": [
            "pifutex",
            "hb2",
            "key2",
            "ps",
            "top_waiter->task",
            "exiting",
            "set_waiters"
          ],
          "line": 319
        },
        "resolved": true,
        "details": {
          "function_name": "futex_lock_pi_atomic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/pi.c",
          "lines": "514-608",
          "snippet": "int futex_lock_pi_atomic(u32 __user *uaddr, struct futex_hash_bucket *hb,\n\t\t\t union futex_key *key,\n\t\t\t struct futex_pi_state **ps,\n\t\t\t struct task_struct *task,\n\t\t\t struct task_struct **exiting,\n\t\t\t int set_waiters)\n{\n\tu32 uval, newval, vpid = task_pid_vnr(task);\n\tstruct futex_q *top_waiter;\n\tint ret;\n\n\t/*\n\t * Read the user space value first so we can validate a few\n\t * things before proceeding further.\n\t */\n\tif (futex_get_value_locked(&uval, uaddr))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * Detect deadlocks.\n\t */\n\tif ((unlikely((uval & FUTEX_TID_MASK) == vpid)))\n\t\treturn -EDEADLK;\n\n\tif ((unlikely(should_fail_futex(true))))\n\t\treturn -EDEADLK;\n\n\t/*\n\t * Lookup existing state first. If it exists, try to attach to\n\t * its pi_state.\n\t */\n\ttop_waiter = futex_top_waiter(hb, key);\n\tif (top_waiter)\n\t\treturn attach_to_pi_state(uaddr, uval, top_waiter->pi_state, ps);\n\n\t/*\n\t * No waiter and user TID is 0. We are here because the\n\t * waiters or the owner died bit is set or called from\n\t * requeue_cmp_pi or for whatever reason something took the\n\t * syscall.\n\t */\n\tif (!(uval & FUTEX_TID_MASK)) {\n\t\t/*\n\t\t * We take over the futex. No other waiters and the user space\n\t\t * TID is 0. We preserve the owner died bit.\n\t\t */\n\t\tnewval = uval & FUTEX_OWNER_DIED;\n\t\tnewval |= vpid;\n\n\t\t/* The futex requeue_pi code can enforce the waiters bit */\n\t\tif (set_waiters)\n\t\t\tnewval |= FUTEX_WAITERS;\n\n\t\tret = lock_pi_update_atomic(uaddr, uval, newval);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t/*\n\t\t * If the waiter bit was requested the caller also needs PI\n\t\t * state attached to the new owner of the user space futex.\n\t\t *\n\t\t * @task is guaranteed to be alive and it cannot be exiting\n\t\t * because it is either sleeping or waiting in\n\t\t * futex_requeue_pi_wakeup_sync().\n\t\t *\n\t\t * No need to do the full attach_to_pi_owner() exercise\n\t\t * because @task is known and valid.\n\t\t */\n\t\tif (set_waiters) {\n\t\t\traw_spin_lock_irq(&task->pi_lock);\n\t\t\t__attach_to_pi_owner(task, key, ps);\n\t\t\traw_spin_unlock_irq(&task->pi_lock);\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/*\n\t * First waiter. Set the waiters bit before attaching ourself to\n\t * the owner. If owner tries to unlock, it will be forced into\n\t * the kernel and blocked on hb->lock.\n\t */\n\tnewval = uval | FUTEX_WAITERS;\n\tret = lock_pi_update_atomic(uaddr, uval, newval);\n\tif (ret)\n\t\treturn ret;\n\t/*\n\t * If the update of the user space value succeeded, we try to\n\t * attach to the owner. If that fails, no harm done, we only\n\t * set the FUTEX_WAITERS bit in the user space variable.\n\t */\n\treturn attach_to_pi_owner(uaddr, newval, key, ps, exiting);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/task.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/task.h>\n#include <linux/slab.h>\n\nint futex_lock_pi_atomic(u32 __user *uaddr, struct futex_hash_bucket *hb,\n\t\t\t union futex_key *key,\n\t\t\t struct futex_pi_state **ps,\n\t\t\t struct task_struct *task,\n\t\t\t struct task_struct **exiting,\n\t\t\t int set_waiters)\n{\n\tu32 uval, newval, vpid = task_pid_vnr(task);\n\tstruct futex_q *top_waiter;\n\tint ret;\n\n\t/*\n\t * Read the user space value first so we can validate a few\n\t * things before proceeding further.\n\t */\n\tif (futex_get_value_locked(&uval, uaddr))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * Detect deadlocks.\n\t */\n\tif ((unlikely((uval & FUTEX_TID_MASK) == vpid)))\n\t\treturn -EDEADLK;\n\n\tif ((unlikely(should_fail_futex(true))))\n\t\treturn -EDEADLK;\n\n\t/*\n\t * Lookup existing state first. If it exists, try to attach to\n\t * its pi_state.\n\t */\n\ttop_waiter = futex_top_waiter(hb, key);\n\tif (top_waiter)\n\t\treturn attach_to_pi_state(uaddr, uval, top_waiter->pi_state, ps);\n\n\t/*\n\t * No waiter and user TID is 0. We are here because the\n\t * waiters or the owner died bit is set or called from\n\t * requeue_cmp_pi or for whatever reason something took the\n\t * syscall.\n\t */\n\tif (!(uval & FUTEX_TID_MASK)) {\n\t\t/*\n\t\t * We take over the futex. No other waiters and the user space\n\t\t * TID is 0. We preserve the owner died bit.\n\t\t */\n\t\tnewval = uval & FUTEX_OWNER_DIED;\n\t\tnewval |= vpid;\n\n\t\t/* The futex requeue_pi code can enforce the waiters bit */\n\t\tif (set_waiters)\n\t\t\tnewval |= FUTEX_WAITERS;\n\n\t\tret = lock_pi_update_atomic(uaddr, uval, newval);\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\t/*\n\t\t * If the waiter bit was requested the caller also needs PI\n\t\t * state attached to the new owner of the user space futex.\n\t\t *\n\t\t * @task is guaranteed to be alive and it cannot be exiting\n\t\t * because it is either sleeping or waiting in\n\t\t * futex_requeue_pi_wakeup_sync().\n\t\t *\n\t\t * No need to do the full attach_to_pi_owner() exercise\n\t\t * because @task is known and valid.\n\t\t */\n\t\tif (set_waiters) {\n\t\t\traw_spin_lock_irq(&task->pi_lock);\n\t\t\t__attach_to_pi_owner(task, key, ps);\n\t\t\traw_spin_unlock_irq(&task->pi_lock);\n\t\t}\n\t\treturn 1;\n\t}\n\n\t/*\n\t * First waiter. Set the waiters bit before attaching ourself to\n\t * the owner. If owner tries to unlock, it will be forced into\n\t * the kernel and blocked on hb->lock.\n\t */\n\tnewval = uval | FUTEX_WAITERS;\n\tret = lock_pi_update_atomic(uaddr, uval, newval);\n\tif (ret)\n\t\treturn ret;\n\t/*\n\t * If the update of the user space value succeeded, we try to\n\t * attach to the owner. If that fails, no harm done, we only\n\t * set the FUTEX_WAITERS bit in the user space variable.\n\t */\n\treturn attach_to_pi_owner(uaddr, newval, key, ps, exiting);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_requeue_pi_prepare",
          "args": [
            "top_waiter",
            "NULL"
          ],
          "line": 308
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue_pi_prepare",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "92-123",
          "snippet": "static inline bool futex_requeue_pi_prepare(struct futex_q *q,\n\t\t\t\t\t    struct futex_pi_state *pi_state)\n{\n\tint old, new;\n\n\t/*\n\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has\n\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should\n\t * ignore the waiter.\n\t */\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn false;\n\n\t\t/*\n\t\t * futex_proxy_trylock_atomic() might have set it to\n\t\t * IN_PROGRESS and a interleaved early wake to WAIT.\n\t\t *\n\t\t * It was considered to have an extra state for that\n\t\t * trylock, but that would just add more conditionals\n\t\t * all over the place for a dubious value.\n\t\t */\n\t\tif (old != Q_REQUEUE_PI_NONE)\n\t\t\tbreak;\n\n\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\tq->pi_state = pi_state;\n\treturn true;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline bool futex_requeue_pi_prepare(struct futex_q *q,\n\t\t\t\t\t    struct futex_pi_state *pi_state)\n{\n\tint old, new;\n\n\t/*\n\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has\n\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should\n\t * ignore the waiter.\n\t */\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn false;\n\n\t\t/*\n\t\t * futex_proxy_trylock_atomic() might have set it to\n\t\t * IN_PROGRESS and a interleaved early wake to WAIT.\n\t\t *\n\t\t * It was considered to have an extra state for that\n\t\t * trylock, but that would just add more conditionals\n\t\t * all over the place for a dubious value.\n\t\t */\n\t\tif (old != Q_REQUEUE_PI_NONE)\n\t\t\tbreak;\n\n\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\tq->pi_state = pi_state;\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_match",
          "args": [
            "top_waiter->requeue_pi_key",
            "key2"
          ],
          "line": 304
        },
        "resolved": true,
        "details": {
          "function_name": "futex_match",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "134-140",
          "snippet": "static inline int futex_match(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline int futex_match(union futex_key *key1, union futex_key *key2)\n{\n\treturn (key1 && key2\n\t\t&& key1->both.word == key2->both.word\n\t\t&& key1->both.ptr == key2->both.ptr\n\t\t&& key1->both.offset == key2->both.offset);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_top_waiter",
          "args": [
            "hb1",
            "key1"
          ],
          "line": 290
        },
        "resolved": true,
        "details": {
          "function_name": "futex_top_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "429-438",
          "snippet": "struct futex_q *futex_top_waiter(struct futex_hash_bucket *hb, union futex_key *key)\n{\n\tstruct futex_q *this;\n\n\tplist_for_each_entry(this, &hb->chain, list) {\n\t\tif (futex_match(&this->key, key))\n\t\t\treturn this;\n\t}\n\treturn NULL;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nstruct futex_q *futex_top_waiter(struct futex_hash_bucket *hb, union futex_key *key)\n{\n\tstruct futex_q *this;\n\n\tplist_for_each_entry(this, &hb->chain, list) {\n\t\tif (futex_match(&this->key, key))\n\t\t\treturn this;\n\t}\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "should_fail_futex(true)"
          ],
          "line": 279
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "should_fail_futex",
          "args": [
            "true"
          ],
          "line": 279
        },
        "resolved": true,
        "details": {
          "function_name": "should_fail_futex",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "77-83",
          "snippet": "bool should_fail_futex(bool fshared)\n{\n\tif (fail_futex.ignore_private && !fshared)\n\t\treturn false;\n\n\treturn should_fail(&fail_futex.attr, 1);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nbool should_fail_futex(bool fshared)\n{\n\tif (fail_futex.ignore_private && !fshared)\n\t\treturn false;\n\n\treturn should_fail(&fail_futex.attr, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_get_value_locked",
          "args": [
            "&curval",
            "pifutex"
          ],
          "line": 276
        },
        "resolved": true,
        "details": {
          "function_name": "futex_get_value_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "451-460",
          "snippet": "int futex_get_value_locked(u32 *dest, u32 __user *from)\n{\n\tint ret;\n\n\tpagefault_disable();\n\tret = __get_user(*dest, from);\n\tpagefault_enable();\n\n\treturn ret ? -EFAULT : 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nint futex_get_value_locked(u32 *dest, u32 __user *from)\n{\n\tint ret;\n\n\tpagefault_disable();\n\tret = __get_user(*dest, from);\n\tpagefault_enable();\n\n\treturn ret ? -EFAULT : 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic int\nfutex_proxy_trylock_atomic(u32 __user *pifutex, struct futex_hash_bucket *hb1,\n\t\t\t   struct futex_hash_bucket *hb2, union futex_key *key1,\n\t\t\t   union futex_key *key2, struct futex_pi_state **ps,\n\t\t\t   struct task_struct **exiting, int set_waiters)\n{\n\tstruct futex_q *top_waiter = NULL;\n\tu32 curval;\n\tint ret;\n\n\tif (futex_get_value_locked(&curval, pifutex))\n\t\treturn -EFAULT;\n\n\tif (unlikely(should_fail_futex(true)))\n\t\treturn -EFAULT;\n\n\t/*\n\t * Find the top_waiter and determine if there are additional waiters.\n\t * If the caller intends to requeue more than 1 waiter to pifutex,\n\t * force futex_lock_pi_atomic() to set the FUTEX_WAITERS bit now,\n\t * as we have means to handle the possible fault.  If not, don't set\n\t * the bit unnecessarily as it will force the subsequent unlock to enter\n\t * the kernel.\n\t */\n\ttop_waiter = futex_top_waiter(hb1, key1);\n\n\t/* There are no waiters, nothing for us to do. */\n\tif (!top_waiter)\n\t\treturn 0;\n\n\t/*\n\t * Ensure that this is a waiter sitting in futex_wait_requeue_pi()\n\t * and waiting on the 'waitqueue' futex which is always !PI.\n\t */\n\tif (!top_waiter->rt_waiter || top_waiter->pi_state)\n\t\treturn -EINVAL;\n\n\t/* Ensure we requeue to the expected futex. */\n\tif (!futex_match(top_waiter->requeue_pi_key, key2))\n\t\treturn -EINVAL;\n\n\t/* Ensure that this does not race against an early wakeup */\n\tif (!futex_requeue_pi_prepare(top_waiter, NULL))\n\t\treturn -EAGAIN;\n\n\t/*\n\t * Try to take the lock for top_waiter and set the FUTEX_WAITERS bit\n\t * in the contended case or if @set_waiters is true.\n\t *\n\t * In the contended case PI state is attached to the lock owner. If\n\t * the user space lock can be acquired then PI state is attached to\n\t * the new owner (@top_waiter->task) when @set_waiters is true.\n\t */\n\tret = futex_lock_pi_atomic(pifutex, hb2, key2, ps, top_waiter->task,\n\t\t\t\t   exiting, set_waiters);\n\tif (ret == 1) {\n\t\t/*\n\t\t * Lock was acquired in user space and PI state was\n\t\t * attached to @top_waiter->task. That means state is fully\n\t\t * consistent and the waiter can return to user space\n\t\t * immediately after the wakeup.\n\t\t */\n\t\trequeue_pi_wake_futex(top_waiter, key2, hb2);\n\t} else if (ret < 0) {\n\t\t/* Rewind top_waiter::requeue_state */\n\t\tfutex_requeue_pi_complete(top_waiter, ret);\n\t} else {\n\t\t/*\n\t\t * futex_lock_pi_atomic() did not acquire the user space\n\t\t * futex, but managed to establish the proxy lock and pi\n\t\t * state. top_waiter::requeue_state cannot be fixed up here\n\t\t * because the waiter is not enqueued on the rtmutex\n\t\t * yet. This is handled at the callsite depending on the\n\t\t * result of rt_mutex_start_proxy_lock() which is\n\t\t * guaranteed to be reached with this function returning 0.\n\t\t */\n\t}\n\treturn ret;\n}"
  },
  {
    "function_name": "requeue_pi_wake_futex",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "222-238",
    "snippet": "static inline\nvoid requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,\n\t\t\t   struct futex_hash_bucket *hb)\n{\n\tq->key = *key;\n\n\t__futex_unqueue(q);\n\n\tWARN_ON(!q->rt_waiter);\n\tq->rt_waiter = NULL;\n\n\tq->lock_ptr = &hb->lock;\n\n\t/* Signal locked state to the waiter */\n\tfutex_requeue_pi_complete(q, 1);\n\twake_up_state(q->task, TASK_NORMAL);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_state",
          "args": [
            "q->task",
            "TASK_NORMAL"
          ],
          "line": 237
        },
        "resolved": true,
        "details": {
          "function_name": "signal_wake_up_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/signal.c",
          "lines": "763-775",
          "snippet": "void signal_wake_up_state(struct task_struct *t, unsigned int state)\n{\n\tset_tsk_thread_flag(t, TIF_SIGPENDING);\n\t/*\n\t * TASK_WAKEKILL also means wake it up in the stopped/traced/killable\n\t * case. We don't check t->state here because there is a race with it\n\t * executing another processor and just now entering stopped state.\n\t * By using wake_up_state, we ensure the process will wake up and\n\t * handle its death signal.\n\t */\n\tif (!wake_up_state(t, state | TASK_INTERRUPTIBLE))\n\t\tkick_process(t);\n}",
          "includes": [
            "#include <linux/kdb.h>",
            "#include <asm/syscall.h>\t/* for syscall_get_* */",
            "#include <asm/cacheflush.h>",
            "#include <asm/siginfo.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/param.h>",
            "#include <trace/events/signal.h>",
            "#include <linux/audit.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/compiler.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/compat.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/capability.h>",
            "#include <linux/task_work.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/signal.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/coredump.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/tty.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kdb.h>\n#include <asm/syscall.h>\t/* for syscall_get_* */\n#include <asm/cacheflush.h>\n#include <asm/siginfo.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <asm/param.h>\n#include <trace/events/signal.h>\n#include <linux/audit.h>\n#include <linux/cgroup.h>\n#include <linux/posix-timers.h>\n#include <linux/compiler.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/uprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/pid_namespace.h>\n#include <linux/freezer.h>\n#include <linux/capability.h>\n#include <linux/task_work.h>\n#include <linux/ratelimit.h>\n#include <linux/signalfd.h>\n#include <linux/signal.h>\n#include <linux/ptrace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/coredump.h>\n#include <linux/binfmts.h>\n#include <linux/tty.h>\n#include <linux/proc_fs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/user.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\nvoid signal_wake_up_state(struct task_struct *t, unsigned int state)\n{\n\tset_tsk_thread_flag(t, TIF_SIGPENDING);\n\t/*\n\t * TASK_WAKEKILL also means wake it up in the stopped/traced/killable\n\t * case. We don't check t->state here because there is a race with it\n\t * executing another processor and just now entering stopped state.\n\t * By using wake_up_state, we ensure the process will wake up and\n\t * handle its death signal.\n\t */\n\tif (!wake_up_state(t, state | TASK_INTERRUPTIBLE))\n\t\tkick_process(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_requeue_pi_complete",
          "args": [
            "q",
            "1"
          ],
          "line": 236
        },
        "resolved": true,
        "details": {
          "function_name": "futex_requeue_pi_complete",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
          "lines": "125-154",
          "snippet": "static inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/sched/signal.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "!q->rt_waiter"
          ],
          "line": 230
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__futex_unqueue",
          "args": [
            "q"
          ],
          "line": 228
        },
        "resolved": true,
        "details": {
          "function_name": "__futex_unqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/core.c",
          "lines": "499-510",
          "snippet": "void __futex_unqueue(struct futex_q *q)\n{\n\tstruct futex_hash_bucket *hb;\n\n\tif (WARN_ON_SMP(!q->lock_ptr) || WARN_ON(plist_node_empty(&q->list)))\n\t\treturn;\n\tlockdep_assert_held(q->lock_ptr);\n\n\thb = container_of(q->lock_ptr, struct futex_hash_bucket, lock);\n\tplist_del(&q->list, &hb->chain);\n\tfutex_hb_waiters_dec(hb);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\"",
            "#include \"futex.h\"",
            "#include <linux/slab.h>",
            "#include <linux/fault-inject.h>",
            "#include <linux/memblock.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/jhash.h>",
            "#include <linux/compat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/slab.h>\n#include <linux/fault-inject.h>\n#include <linux/memblock.h>\n#include <linux/pagemap.h>\n#include <linux/jhash.h>\n#include <linux/compat.h>\n\nvoid __futex_unqueue(struct futex_q *q)\n{\n\tstruct futex_hash_bucket *hb;\n\n\tif (WARN_ON_SMP(!q->lock_ptr) || WARN_ON(plist_node_empty(&q->list)))\n\t\treturn;\n\tlockdep_assert_held(q->lock_ptr);\n\n\thb = container_of(q->lock_ptr, struct futex_hash_bucket, lock);\n\tplist_del(&q->list, &hb->chain);\n\tfutex_hb_waiters_dec(hb);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nvoid requeue_pi_wake_futex(struct futex_q *q, union futex_key *key,\n\t\t\t   struct futex_hash_bucket *hb)\n{\n\tq->key = *key;\n\n\t__futex_unqueue(q);\n\n\tWARN_ON(!q->rt_waiter);\n\tq->rt_waiter = NULL;\n\n\tq->lock_ptr = &hb->lock;\n\n\t/* Signal locked state to the waiter */\n\tfutex_requeue_pi_complete(q, 1);\n\twake_up_state(q->task, TASK_NORMAL);\n}"
  },
  {
    "function_name": "futex_requeue_pi_wakeup_sync",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "156-192",
    "snippet": "static inline int futex_requeue_pi_wakeup_sync(struct futex_q *q)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\t/* Is requeue done already? */\n\t\tif (old >= Q_REQUEUE_PI_DONE)\n\t\t\treturn old;\n\n\t\t/*\n\t\t * If not done, then tell the requeue code to either ignore\n\t\t * the waiter or to wake it up once the requeue is done.\n\t\t */\n\t\tnew = Q_REQUEUE_PI_WAIT;\n\t\tif (old == Q_REQUEUE_PI_NONE)\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\t/* If the requeue was in progress, wait for it to complete */\n\tif (old == Q_REQUEUE_PI_IN_PROGRESS) {\n#ifdef CONFIG_PREEMPT_RT\n\t\trcuwait_wait_event(&q->requeue_wait,\n\t\t\t\t   atomic_read(&q->requeue_state) != Q_REQUEUE_PI_WAIT,\n\t\t\t\t   TASK_UNINTERRUPTIBLE);\n#else\n\t\t(void)atomic_cond_read_relaxed(&q->requeue_state, VAL != Q_REQUEUE_PI_WAIT);\n#endif\n\t}\n\n\t/*\n\t * Requeue is now either prohibited or complete. Reread state\n\t * because during the wait above it might have changed. Nothing\n\t * will modify q->requeue_state after this point.\n\t */\n\treturn atomic_read(&q->requeue_state);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&q->requeue_state"
          ],
          "line": 191
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_cond_read_relaxed",
          "args": [
            "&q->requeue_state",
            "VAL != Q_REQUEUE_PI_WAIT"
          ],
          "line": 182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcuwait_wait_event",
          "args": [
            "&q->requeue_wait",
            "atomic_read(&q->requeue_state) != Q_REQUEUE_PI_WAIT",
            "TASK_UNINTERRUPTIBLE"
          ],
          "line": 178
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&q->requeue_state"
          ],
          "line": 179
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_try_cmpxchg",
          "args": [
            "&q->requeue_state",
            "&old",
            "new"
          ],
          "line": 173
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read_acquire",
          "args": [
            "&q->requeue_state"
          ],
          "line": 160
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline int futex_requeue_pi_wakeup_sync(struct futex_q *q)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\t/* Is requeue done already? */\n\t\tif (old >= Q_REQUEUE_PI_DONE)\n\t\t\treturn old;\n\n\t\t/*\n\t\t * If not done, then tell the requeue code to either ignore\n\t\t * the waiter or to wake it up once the requeue is done.\n\t\t */\n\t\tnew = Q_REQUEUE_PI_WAIT;\n\t\tif (old == Q_REQUEUE_PI_NONE)\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\t/* If the requeue was in progress, wait for it to complete */\n\tif (old == Q_REQUEUE_PI_IN_PROGRESS) {\n#ifdef CONFIG_PREEMPT_RT\n\t\trcuwait_wait_event(&q->requeue_wait,\n\t\t\t\t   atomic_read(&q->requeue_state) != Q_REQUEUE_PI_WAIT,\n\t\t\t\t   TASK_UNINTERRUPTIBLE);\n#else\n\t\t(void)atomic_cond_read_relaxed(&q->requeue_state, VAL != Q_REQUEUE_PI_WAIT);\n#endif\n\t}\n\n\t/*\n\t * Requeue is now either prohibited or complete. Reread state\n\t * because during the wait above it might have changed. Nothing\n\t * will modify q->requeue_state after this point.\n\t */\n\treturn atomic_read(&q->requeue_state);\n}"
  },
  {
    "function_name": "futex_requeue_pi_complete",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "125-154",
    "snippet": "static inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcuwait_wake_up",
          "args": [
            "&q->requeue_wait"
          ],
          "line": 152
        },
        "resolved": true,
        "details": {
          "function_name": "rcuwait_wake_up",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/exit.c",
          "lines": "234-260",
          "snippet": "int rcuwait_wake_up(struct rcuwait *w)\n{\n\tint ret = 0;\n\tstruct task_struct *task;\n\n\trcu_read_lock();\n\n\t/*\n\t * Order condition vs @task, such that everything prior to the load\n\t * of @task is visible. This is the condition as to why the user called\n\t * rcuwait_wake() in the first place. Pairs with set_current_state()\n\t * barrier (A) in rcuwait_wait_event().\n\t *\n\t *    WAIT                WAKE\n\t *    [S] tsk = current\t  [S] cond = true\n\t *        MB (A)\t      MB (B)\n\t *    [L] cond\t\t  [L] tsk\n\t */\n\tsmp_mb(); /* (B) */\n\n\ttask = rcu_dereference(w->task);\n\tif (task)\n\t\tret = wake_up_process(task);\n\trcu_read_unlock();\n\n\treturn ret;\n}",
          "includes": [
            "#include <asm/mmu_context.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/compat.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/random.h>",
            "#include <linux/kcov.h>",
            "#include <linux/shm.h>",
            "#include <linux/writeback.h>",
            "#include <linux/oom.h>",
            "#include <linux/hw_breakpoint.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/init_task.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/task_work.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/resource.h>",
            "#include <linux/audit.h> /* for audit_free() */",
            "#include <linux/pipe_fs_i.h>",
            "#include <linux/futex.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/signal.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/kthread.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/mount.h>",
            "#include <linux/profile.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/freezer.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/acct.h>",
            "#include <linux/cpu.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/tty.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/capability.h>",
            "#include <linux/module.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/mmu_context.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/kprobes.h>\n#include <linux/io_uring.h>\n#include <linux/compat.h>\n#include <linux/rcuwait.h>\n#include <linux/random.h>\n#include <linux/kcov.h>\n#include <linux/shm.h>\n#include <linux/writeback.h>\n#include <linux/oom.h>\n#include <linux/hw_breakpoint.h>\n#include <trace/events/sched.h>\n#include <linux/perf_event.h>\n#include <linux/init_task.h>\n#include <linux/fs_struct.h>\n#include <linux/task_work.h>\n#include <linux/blkdev.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/resource.h>\n#include <linux/audit.h> /* for audit_free() */\n#include <linux/pipe_fs_i.h>\n#include <linux/futex.h>\n#include <linux/mutex.h>\n#include <linux/cn_proc.h>\n#include <linux/posix-timers.h>\n#include <linux/signal.h>\n#include <linux/syscalls.h>\n#include <linux/cgroup.h>\n#include <linux/delayacct.h>\n#include <linux/taskstats_kern.h>\n#include <linux/mempolicy.h>\n#include <linux/kthread.h>\n#include <linux/proc_fs.h>\n#include <linux/mount.h>\n#include <linux/profile.h>\n#include <linux/ptrace.h>\n#include <linux/pid_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/binfmts.h>\n#include <linux/freezer.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/tsacct_kern.h>\n#include <linux/acct.h>\n#include <linux/cpu.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/tty.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/capability.h>\n#include <linux/module.h>\n#include <linux/interrupt.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/mm.h>\n\nint rcuwait_wake_up(struct rcuwait *w)\n{\n\tint ret = 0;\n\tstruct task_struct *task;\n\n\trcu_read_lock();\n\n\t/*\n\t * Order condition vs @task, such that everything prior to the load\n\t * of @task is visible. This is the condition as to why the user called\n\t * rcuwait_wake() in the first place. Pairs with set_current_state()\n\t * barrier (A) in rcuwait_wait_event().\n\t *\n\t *    WAIT                WAKE\n\t *    [S] tsk = current\t  [S] cond = true\n\t *        MB (A)\t      MB (B)\n\t *    [L] cond\t\t  [L] tsk\n\t */\n\tsmp_mb(); /* (B) */\n\n\ttask = rcu_dereference(w->task);\n\tif (task)\n\t\tret = wake_up_process(task);\n\trcu_read_unlock();\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "old == Q_REQUEUE_PI_WAIT"
          ],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_try_cmpxchg",
          "args": [
            "&q->requeue_state",
            "&old",
            "new"
          ],
          "line": 147
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "old != Q_REQUEUE_PI_WAIT"
          ],
          "line": 144
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT"
          ],
          "line": 136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read_acquire",
          "args": [
            "&q->requeue_state"
          ],
          "line": 129
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline void futex_requeue_pi_complete(struct futex_q *q, int locked)\n{\n\tint old, new;\n\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn;\n\n\t\tif (locked >= 0) {\n\t\t\t/* Requeue succeeded. Set DONE or LOCKED */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_IN_PROGRESS &&\n\t\t\t\t     old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_DONE + locked;\n\t\t} else if (old == Q_REQUEUE_PI_IN_PROGRESS) {\n\t\t\t/* Deadlock, no early wakeup interleave */\n\t\t\tnew = Q_REQUEUE_PI_NONE;\n\t\t} else {\n\t\t\t/* Deadlock, early wakeup interleave. */\n\t\t\tWARN_ON_ONCE(old != Q_REQUEUE_PI_WAIT);\n\t\t\tnew = Q_REQUEUE_PI_IGNORE;\n\t\t}\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n#ifdef CONFIG_PREEMPT_RT\n\t/* If the waiter interleaved with the requeue let it know */\n\tif (unlikely(old == Q_REQUEUE_PI_WAIT))\n\t\trcuwait_wake_up(&q->requeue_wait);\n#endif\n}"
  },
  {
    "function_name": "futex_requeue_pi_prepare",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "92-123",
    "snippet": "static inline bool futex_requeue_pi_prepare(struct futex_q *q,\n\t\t\t\t\t    struct futex_pi_state *pi_state)\n{\n\tint old, new;\n\n\t/*\n\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has\n\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should\n\t * ignore the waiter.\n\t */\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn false;\n\n\t\t/*\n\t\t * futex_proxy_trylock_atomic() might have set it to\n\t\t * IN_PROGRESS and a interleaved early wake to WAIT.\n\t\t *\n\t\t * It was considered to have an extra state for that\n\t\t * trylock, but that would just add more conditionals\n\t\t * all over the place for a dubious value.\n\t\t */\n\t\tif (old != Q_REQUEUE_PI_NONE)\n\t\t\tbreak;\n\n\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\tq->pi_state = pi_state;\n\treturn true;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_try_cmpxchg",
          "args": [
            "&q->requeue_state",
            "&old",
            "new"
          ],
          "line": 119
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read_acquire",
          "args": [
            "&q->requeue_state"
          ],
          "line": 102
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline bool futex_requeue_pi_prepare(struct futex_q *q,\n\t\t\t\t\t    struct futex_pi_state *pi_state)\n{\n\tint old, new;\n\n\t/*\n\t * Set state to Q_REQUEUE_PI_IN_PROGRESS unless an early wakeup has\n\t * already set Q_REQUEUE_PI_IGNORE to signal that requeue should\n\t * ignore the waiter.\n\t */\n\told = atomic_read_acquire(&q->requeue_state);\n\tdo {\n\t\tif (old == Q_REQUEUE_PI_IGNORE)\n\t\t\treturn false;\n\n\t\t/*\n\t\t * futex_proxy_trylock_atomic() might have set it to\n\t\t * IN_PROGRESS and a interleaved early wake to WAIT.\n\t\t *\n\t\t * It was considered to have an extra state for that\n\t\t * trylock, but that would just add more conditionals\n\t\t * all over the place for a dubious value.\n\t\t */\n\t\tif (old != Q_REQUEUE_PI_NONE)\n\t\t\tbreak;\n\n\t\tnew = Q_REQUEUE_PI_IN_PROGRESS;\n\t} while (!atomic_try_cmpxchg(&q->requeue_state, &old, new));\n\n\tq->pi_state = pi_state;\n\treturn true;\n}"
  },
  {
    "function_name": "requeue_futex",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/requeue.c",
    "lines": "73-90",
    "snippet": "static inline\nvoid requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,\n\t\t   struct futex_hash_bucket *hb2, union futex_key *key2)\n{\n\n\t/*\n\t * If key1 and key2 hash to the same bucket, no need to\n\t * requeue.\n\t */\n\tif (likely(&hb1->chain != &hb2->chain)) {\n\t\tplist_del(&q->list, &hb1->chain);\n\t\tfutex_hb_waiters_dec(hb1);\n\t\tfutex_hb_waiters_inc(hb2);\n\t\tplist_add(&q->list, &hb2->chain);\n\t\tq->lock_ptr = &hb2->lock;\n\t}\n\tq->key = *key2;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\"",
      "#include \"futex.h\"",
      "#include <linux/sched/signal.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "plist_add",
          "args": [
            "&q->list",
            "&hb2->chain"
          ],
          "line": 86
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "futex_hb_waiters_inc",
          "args": [
            "hb2"
          ],
          "line": 85
        },
        "resolved": true,
        "details": {
          "function_name": "futex_hb_waiters_inc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "183-192",
          "snippet": "static inline void futex_hb_waiters_inc(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_inc(&hb->waiters);\n\t/*\n\t * Full barrier (A), see the ordering comment above.\n\t */\n\tsmp_mb__after_atomic();\n#endif\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void futex_hb_waiters_inc(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_inc(&hb->waiters);\n\t/*\n\t * Full barrier (A), see the ordering comment above.\n\t */\n\tsmp_mb__after_atomic();\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "futex_hb_waiters_dec",
          "args": [
            "hb1"
          ],
          "line": 84
        },
        "resolved": true,
        "details": {
          "function_name": "futex_hb_waiters_dec",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/futex/futex.h",
          "lines": "198-203",
          "snippet": "static inline void futex_hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}",
          "includes": [
            "#include <asm/futex.h>",
            "#include <linux/rcuwait.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/futex.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/futex.h>\n#include <linux/rcuwait.h>\n#include <linux/sched/wake_q.h>\n#include <linux/futex.h>\n\nstatic inline void futex_hb_waiters_dec(struct futex_hash_bucket *hb)\n{\n#ifdef CONFIG_SMP\n\tatomic_dec(&hb->waiters);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "plist_del",
          "args": [
            "&q->list",
            "&hb1->chain"
          ],
          "line": 83
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "&hb1->chain != &hb2->chain"
          ],
          "line": 82
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n#include \"futex.h\"\n#include <linux/sched/signal.h>\n\nstatic inline\nvoid requeue_futex(struct futex_q *q, struct futex_hash_bucket *hb1,\n\t\t   struct futex_hash_bucket *hb2, union futex_key *key2)\n{\n\n\t/*\n\t * If key1 and key2 hash to the same bucket, no need to\n\t * requeue.\n\t */\n\tif (likely(&hb1->chain != &hb2->chain)) {\n\t\tplist_del(&q->list, &hb1->chain);\n\t\tfutex_hb_waiters_dec(hb1);\n\t\tfutex_hb_waiters_inc(hb2);\n\t\tplist_add(&q->list, &hb2->chain);\n\t\tq->lock_ptr = &hb2->lock;\n\t}\n\tq->key = *key2;\n}"
  }
]