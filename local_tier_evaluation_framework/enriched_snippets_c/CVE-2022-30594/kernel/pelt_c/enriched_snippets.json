[
  {
    "function_name": "update_irq_load_avg",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "434-472",
    "snippet": "int update_irq_load_avg(struct rq *rq, u64 running)\n{\n\tint ret = 0;\n\n\t/*\n\t * We can't use clock_pelt because irq time is not accounted in\n\t * clock_task. Instead we directly scale the running time to\n\t * reflect the real amount of computation\n\t */\n\trunning = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));\n\trunning = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));\n\n\t/*\n\t * We know the time that has been used by interrupt since last update\n\t * but we don't when. Let be pessimistic and assume that interrupt has\n\t * happened just before the update. This is not so far from reality\n\t * because interrupt will most probably wake up task and trig an update\n\t * of rq clock during which the metric is updated.\n\t * We start to decay with normal context time and then we add the\n\t * interrupt context time.\n\t * We can safely remove running from rq->clock because\n\t * rq->clock += delta with delta >= running\n\t */\n\tret = ___update_load_sum(rq->clock - running, &rq->avg_irq,\n\t\t\t\t0,\n\t\t\t\t0,\n\t\t\t\t0);\n\tret += ___update_load_sum(rq->clock, &rq->avg_irq,\n\t\t\t\t1,\n\t\t\t\t1,\n\t\t\t\t1);\n\n\tif (ret) {\n\t\t___update_load_avg(&rq->avg_irq, 1);\n\t\ttrace_pelt_irq_tp(rq);\n\t}\n\n\treturn ret;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_irq_tp",
          "args": [
            "rq"
          ],
          "line": 468
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&rq->avg_irq",
            "1"
          ],
          "line": 467
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "rq->clock",
            "&rq->avg_irq",
            "1",
            "1",
            "1"
          ],
          "line": 461
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cap_scale",
          "args": [
            "running",
            "arch_scale_cpu_capacity(cpu_of(rq))"
          ],
          "line": 444
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_scale_cpu_capacity",
          "args": [
            "cpu_of(rq)"
          ],
          "line": 444
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_of",
          "args": [
            "rq"
          ],
          "line": 444
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_of",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "1137-1144",
          "snippet": "static inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern bool raw_spin_rq_trylock(struct rq *rq);",
            "extern void raw_spin_rq_unlock(struct rq *rq);",
            "extern void update_rq_clock(struct rq *rq);",
            "extern struct task_struct *pick_next_task_idle(struct rq *rq);",
            "extern void resched_curr(struct rq *rq);",
            "extern void resched_cpu(int cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern bool raw_spin_rq_trylock(struct rq *rq);\nextern void raw_spin_rq_unlock(struct rq *rq);\nextern void update_rq_clock(struct rq *rq);\nextern struct task_struct *pick_next_task_idle(struct rq *rq);\nextern void resched_curr(struct rq *rq);\nextern void resched_cpu(int cpu);\n\nstatic inline int cpu_of(struct rq *rq)\n{\n#ifdef CONFIG_SMP\n\treturn rq->cpu;\n#else\n\treturn 0;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "cap_scale",
          "args": [
            "running",
            "arch_scale_freq_capacity(cpu_of(rq))"
          ],
          "line": 443
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_scale_freq_capacity",
          "args": [
            "cpu_of(rq)"
          ],
          "line": 443
        },
        "resolved": true,
        "details": {
          "function_name": "arch_scale_freq_capacity",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "2496-2500",
          "snippet": "static __always_inline\nunsigned long arch_scale_freq_capacity(int cpu)\n{\n\treturn SCHED_CAPACITY_SCALE;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern bool dl_cpu_busy(unsigned int cpu);",
            "extern void resched_cpu(int cpu);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern bool dl_cpu_busy(unsigned int cpu);\nextern void resched_cpu(int cpu);\n\nstatic __always_inline\nunsigned long arch_scale_freq_capacity(int cpu)\n{\n\treturn SCHED_CAPACITY_SCALE;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint update_irq_load_avg(struct rq *rq, u64 running)\n{\n\tint ret = 0;\n\n\t/*\n\t * We can't use clock_pelt because irq time is not accounted in\n\t * clock_task. Instead we directly scale the running time to\n\t * reflect the real amount of computation\n\t */\n\trunning = cap_scale(running, arch_scale_freq_capacity(cpu_of(rq)));\n\trunning = cap_scale(running, arch_scale_cpu_capacity(cpu_of(rq)));\n\n\t/*\n\t * We know the time that has been used by interrupt since last update\n\t * but we don't when. Let be pessimistic and assume that interrupt has\n\t * happened just before the update. This is not so far from reality\n\t * because interrupt will most probably wake up task and trig an update\n\t * of rq clock during which the metric is updated.\n\t * We start to decay with normal context time and then we add the\n\t * interrupt context time.\n\t * We can safely remove running from rq->clock because\n\t * rq->clock += delta with delta >= running\n\t */\n\tret = ___update_load_sum(rq->clock - running, &rq->avg_irq,\n\t\t\t\t0,\n\t\t\t\t0,\n\t\t\t\t0);\n\tret += ___update_load_sum(rq->clock, &rq->avg_irq,\n\t\t\t\t1,\n\t\t\t\t1,\n\t\t\t\t1);\n\n\tif (ret) {\n\t\t___update_load_avg(&rq->avg_irq, 1);\n\t\ttrace_pelt_irq_tp(rq);\n\t}\n\n\treturn ret;\n}"
  },
  {
    "function_name": "update_thermal_load_avg",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "407-419",
    "snippet": "int update_thermal_load_avg(u64 now, struct rq *rq, u64 capacity)\n{\n\tif (___update_load_sum(now, &rq->avg_thermal,\n\t\t\t       capacity,\n\t\t\t       capacity,\n\t\t\t       capacity)) {\n\t\t___update_load_avg(&rq->avg_thermal, 1);\n\t\ttrace_pelt_thermal_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_thermal_tp",
          "args": [
            "rq"
          ],
          "line": 414
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&rq->avg_thermal",
            "1"
          ],
          "line": 413
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "now",
            "&rq->avg_thermal",
            "capacity",
            "capacity",
            "capacity"
          ],
          "line": 409
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint update_thermal_load_avg(u64 now, struct rq *rq, u64 capacity)\n{\n\tif (___update_load_sum(now, &rq->avg_thermal,\n\t\t\t       capacity,\n\t\t\t       capacity,\n\t\t\t       capacity)) {\n\t\t___update_load_avg(&rq->avg_thermal, 1);\n\t\ttrace_pelt_thermal_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "update_dl_rq_load_avg",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "376-389",
    "snippet": "int update_dl_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\tif (___update_load_sum(now, &rq->avg_dl,\n\t\t\t\trunning,\n\t\t\t\trunning,\n\t\t\t\trunning)) {\n\n\t\t___update_load_avg(&rq->avg_dl, 1);\n\t\ttrace_pelt_dl_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_dl_tp",
          "args": [
            "rq"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&rq->avg_dl",
            "1"
          ],
          "line": 383
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "now",
            "&rq->avg_dl",
            "running",
            "running",
            "running"
          ],
          "line": 378
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint update_dl_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\tif (___update_load_sum(now, &rq->avg_dl,\n\t\t\t\trunning,\n\t\t\t\trunning,\n\t\t\t\trunning)) {\n\n\t\t___update_load_avg(&rq->avg_dl, 1);\n\t\ttrace_pelt_dl_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "update_rt_rq_load_avg",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "350-363",
    "snippet": "int update_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\tif (___update_load_sum(now, &rq->avg_rt,\n\t\t\t\trunning,\n\t\t\t\trunning,\n\t\t\t\trunning)) {\n\n\t\t___update_load_avg(&rq->avg_rt, 1);\n\t\ttrace_pelt_rt_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_rt_tp",
          "args": [
            "rq"
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&rq->avg_rt",
            "1"
          ],
          "line": 357
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "now",
            "&rq->avg_rt",
            "running",
            "running",
            "running"
          ],
          "line": 352
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint update_rt_rq_load_avg(u64 now, struct rq *rq, int running)\n{\n\tif (___update_load_sum(now, &rq->avg_rt,\n\t\t\t\trunning,\n\t\t\t\trunning,\n\t\t\t\trunning)) {\n\n\t\t___update_load_avg(&rq->avg_rt, 1);\n\t\ttrace_pelt_rt_tp(rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__update_load_avg_cfs_rq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "324-337",
    "snippet": "int __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)\n{\n\tif (___update_load_sum(now, &cfs_rq->avg,\n\t\t\t\tscale_load_down(cfs_rq->load.weight),\n\t\t\t\tcfs_rq->h_nr_running,\n\t\t\t\tcfs_rq->curr != NULL)) {\n\n\t\t___update_load_avg(&cfs_rq->avg, 1);\n\t\ttrace_pelt_cfs_tp(cfs_rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_cfs_tp",
          "args": [
            "cfs_rq"
          ],
          "line": 332
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&cfs_rq->avg",
            "1"
          ],
          "line": 331
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "now",
            "&cfs_rq->avg",
            "scale_load_down(cfs_rq->load.weight)",
            "cfs_rq->h_nr_running",
            "cfs_rq->curr != NULL"
          ],
          "line": 326
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "scale_load_down",
          "args": [
            "cfs_rq->load.weight"
          ],
          "line": 327
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint __update_load_avg_cfs_rq(u64 now, struct cfs_rq *cfs_rq)\n{\n\tif (___update_load_sum(now, &cfs_rq->avg,\n\t\t\t\tscale_load_down(cfs_rq->load.weight),\n\t\t\t\tcfs_rq->h_nr_running,\n\t\t\t\tcfs_rq->curr != NULL)) {\n\n\t\t___update_load_avg(&cfs_rq->avg, 1);\n\t\ttrace_pelt_cfs_tp(cfs_rq);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__update_load_avg_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "310-322",
    "snippet": "int __update_load_avg_se(u64 now, struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\tif (___update_load_sum(now, &se->avg, !!se->on_rq, se_runnable(se),\n\t\t\t\tcfs_rq->curr == se)) {\n\n\t\t___update_load_avg(&se->avg, se_weight(se));\n\t\tcfs_se_util_change(&se->avg);\n\t\ttrace_pelt_se_tp(se);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_se_tp",
          "args": [
            "se"
          ],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cfs_se_util_change",
          "args": [
            "&se->avg"
          ],
          "line": 316
        },
        "resolved": true,
        "details": {
          "function_name": "cfs_se_util_change",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "45-60",
          "snippet": "static inline void cfs_se_util_change(struct sched_avg *avg)\n{\n\tunsigned int enqueued;\n\n\tif (!sched_feat(UTIL_EST))\n\t\treturn;\n\n\t/* Avoid store if the flag has been already reset */\n\tenqueued = avg->util_est.enqueued;\n\tif (!(enqueued & UTIL_AVG_UNCHANGED))\n\t\treturn;\n\n\t/* Reset flag to report util_avg has been updated */\n\tenqueued &= ~UTIL_AVG_UNCHANGED;\n\tWRITE_ONCE(avg->util_est.enqueued, enqueued);\n}",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline void cfs_se_util_change(struct sched_avg *avg)\n{\n\tunsigned int enqueued;\n\n\tif (!sched_feat(UTIL_EST))\n\t\treturn;\n\n\t/* Avoid store if the flag has been already reset */\n\tenqueued = avg->util_est.enqueued;\n\tif (!(enqueued & UTIL_AVG_UNCHANGED))\n\t\treturn;\n\n\t/* Reset flag to report util_avg has been updated */\n\tenqueued &= ~UTIL_AVG_UNCHANGED;\n\tWRITE_ONCE(avg->util_est.enqueued, enqueued);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&se->avg",
            "se_weight(se)"
          ],
          "line": 315
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "se_weight",
          "args": [
            "se"
          ],
          "line": 315
        },
        "resolved": true,
        "details": {
          "function_name": "se_weight",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "771-774",
          "snippet": "static inline long se_weight(struct sched_entity *se)\n{\n\treturn scale_load_down(se->load.weight);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void init_entity_runnable_average(struct sched_entity *se);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void init_entity_runnable_average(struct sched_entity *se);\n\nstatic inline long se_weight(struct sched_entity *se)\n{\n\treturn scale_load_down(se->load.weight);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "now",
            "&se->avg",
            "!!se->on_rq",
            "se_runnable(se)",
            "cfs_rq->curr == se"
          ],
          "line": 312
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "se_runnable",
          "args": [
            "se"
          ],
          "line": 312
        },
        "resolved": true,
        "details": {
          "function_name": "se_runnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "761-764",
          "snippet": "static inline long se_runnable(struct sched_entity *se)\n{\n\treturn !!se->on_rq;\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void init_entity_runnable_average(struct sched_entity *se);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void init_entity_runnable_average(struct sched_entity *se);\n\nstatic inline long se_runnable(struct sched_entity *se)\n{\n\treturn !!se->on_rq;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint __update_load_avg_se(u64 now, struct cfs_rq *cfs_rq, struct sched_entity *se)\n{\n\tif (___update_load_sum(now, &se->avg, !!se->on_rq, se_runnable(se),\n\t\t\t\tcfs_rq->curr == se)) {\n\n\t\t___update_load_avg(&se->avg, se_weight(se));\n\t\tcfs_se_util_change(&se->avg);\n\t\ttrace_pelt_se_tp(se);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__update_load_avg_blocked_se",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "299-308",
    "snippet": "int __update_load_avg_blocked_se(u64 now, struct sched_entity *se)\n{\n\tif (___update_load_sum(now, &se->avg, 0, 0, 0)) {\n\t\t___update_load_avg(&se->avg, se_weight(se));\n\t\ttrace_pelt_se_tp(se);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_pelt_se_tp",
          "args": [
            "se"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "___update_load_avg",
          "args": [
            "&se->avg",
            "se_weight(se)"
          ],
          "line": 302
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_avg",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "260-271",
          "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
        }
      },
      {
        "call_info": {
          "callee": "se_weight",
          "args": [
            "se"
          ],
          "line": 302
        },
        "resolved": true,
        "details": {
          "function_name": "se_weight",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/sched.h",
          "lines": "771-774",
          "snippet": "static inline long se_weight(struct sched_entity *se)\n{\n\treturn scale_load_down(se->load.weight);\n}",
          "includes": [
            "#include \"features.h\"",
            "#include \"features.h\"",
            "# include <linux/static_key.h>",
            "#include \"autogroup.h\"",
            "#include \"stats.h\"",
            "#include <linux/psi.h>",
            "#include <linux/cgroup.h>",
            "#include <trace/events/sched.h>",
            "#include \"cpudeadline.h\"",
            "#include \"cpupri.h\"",
            "# include <asm/paravirt.h>",
            "#include <asm/tlb.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/task_work.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swait.h>",
            "#include <linux/suspend.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/security.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/psi.h>",
            "#include <linux/profile.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/nmi.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/migrate.h>",
            "#include <linux/membarrier.h>",
            "#include <linux/kthread.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/init_task.h>",
            "#include <linux/energy_model.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/ctype.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cpuidle.h>",
            "#include <linux/cpufreq.h>",
            "#include <linux/context_tracking.h>",
            "#include <linux/compat.h>",
            "#include <linux/bitops.h>",
            "#include <linux/binfmts.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/sched/xacct.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/topology.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/prio.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/loadavg.h>",
            "#include <linux/sched/jobctl.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/init.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/cpufreq.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "extern void init_entity_runnable_average(struct sched_entity *se);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"features.h\"\n#include \"features.h\"\n# include <linux/static_key.h>\n#include \"autogroup.h\"\n#include \"stats.h\"\n#include <linux/psi.h>\n#include <linux/cgroup.h>\n#include <trace/events/sched.h>\n#include \"cpudeadline.h\"\n#include \"cpupri.h\"\n# include <asm/paravirt.h>\n#include <asm/tlb.h>\n#include <linux/tsacct_kern.h>\n#include <linux/task_work.h>\n#include <linux/syscalls.h>\n#include <linux/swait.h>\n#include <linux/suspend.h>\n#include <linux/stop_machine.h>\n#include <linux/security.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/ratelimit.h>\n#include <linux/psi.h>\n#include <linux/profile.h>\n#include <linux/prefetch.h>\n#include <linux/proc_fs.h>\n#include <linux/nmi.h>\n#include <linux/mmu_context.h>\n#include <linux/migrate.h>\n#include <linux/membarrier.h>\n#include <linux/kthread.h>\n#include <linux/kprobes.h>\n#include <linux/init_task.h>\n#include <linux/energy_model.h>\n#include <linux/delayacct.h>\n#include <linux/debugfs.h>\n#include <linux/ctype.h>\n#include <linux/cpuset.h>\n#include <linux/cpuidle.h>\n#include <linux/cpufreq.h>\n#include <linux/context_tracking.h>\n#include <linux/compat.h>\n#include <linux/bitops.h>\n#include <linux/binfmts.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/sched/xacct.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/user.h>\n#include <linux/sched/topology.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/prio.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/loadavg.h>\n#include <linux/sched/jobctl.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/init.h>\n#include <linux/sched/idle.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/cpufreq.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/autogroup.h>\n#include <linux/sched.h>\n\nextern void init_entity_runnable_average(struct sched_entity *se);\n\nstatic inline long se_weight(struct sched_entity *se)\n{\n\treturn scale_load_down(se->load.weight);\n}"
        }
      },
      {
        "call_info": {
          "callee": "___update_load_sum",
          "args": [
            "now",
            "&se->avg",
            "0",
            "0",
            "0"
          ],
          "line": 301
        },
        "resolved": true,
        "details": {
          "function_name": "___update_load_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "183-234",
          "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nint __update_load_avg_blocked_se(u64 now, struct sched_entity *se)\n{\n\tif (___update_load_sum(now, &se->avg, 0, 0, 0)) {\n\t\t___update_load_avg(&se->avg, se_weight(se));\n\t\ttrace_pelt_se_tp(se);\n\t\treturn 1;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "___update_load_avg",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "260-271",
    "snippet": "static __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "sa->util_avg",
            "sa->util_sum / divider"
          ],
          "line": 270
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "div_u64",
          "args": [
            "sa->runnable_sum",
            "divider"
          ],
          "line": 269
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "div_u64",
          "args": [
            "load * sa->load_sum",
            "divider"
          ],
          "line": 268
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_pelt_divider",
          "args": [
            "sa"
          ],
          "line": 263
        },
        "resolved": true,
        "details": {
          "function_name": "get_pelt_divider",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.h",
          "lines": "40-43",
          "snippet": "static inline u32 get_pelt_divider(struct sched_avg *avg)\n{\n\treturn LOAD_AVG_MAX - 1024 + avg->period_contrib;\n}",
          "includes": [
            "#include \"sched-pelt.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched-pelt.h\"\n\nstatic inline u32 get_pelt_divider(struct sched_avg *avg)\n{\n\treturn LOAD_AVG_MAX - 1024 + avg->period_contrib;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline void\n___update_load_avg(struct sched_avg *sa, unsigned long load)\n{\n\tu32 divider = get_pelt_divider(sa);\n\n\t/*\n\t * Step 2: update *_avg.\n\t */\n\tsa->load_avg = div_u64(load * sa->load_sum, divider);\n\tsa->runnable_avg = div_u64(sa->runnable_sum, divider);\n\tWRITE_ONCE(sa->util_avg, sa->util_sum / divider);\n}"
  },
  {
    "function_name": "___update_load_sum",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "183-234",
    "snippet": "static __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "accumulate_sum",
          "args": [
            "delta",
            "sa",
            "load",
            "runnable",
            "running"
          ],
          "line": 230
        },
        "resolved": true,
        "details": {
          "function_name": "accumulate_sum",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "105-153",
          "snippet": "static __always_inline u32\naccumulate_sum(u64 delta, struct sched_avg *sa,\n\t       unsigned long load, unsigned long runnable, int running)\n{\n\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */\n\tu64 periods;\n\n\tdelta += sa->period_contrib;\n\tperiods = delta / 1024; /* A period is 1024us (~1ms) */\n\n\t/*\n\t * Step 1: decay old *_sum if we crossed period boundaries.\n\t */\n\tif (periods) {\n\t\tsa->load_sum = decay_load(sa->load_sum, periods);\n\t\tsa->runnable_sum =\n\t\t\tdecay_load(sa->runnable_sum, periods);\n\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);\n\n\t\t/*\n\t\t * Step 2\n\t\t */\n\t\tdelta %= 1024;\n\t\tif (load) {\n\t\t\t/*\n\t\t\t * This relies on the:\n\t\t\t *\n\t\t\t * if (!load)\n\t\t\t *\trunnable = running = 0;\n\t\t\t *\n\t\t\t * clause from ___update_load_sum(); this results in\n\t\t\t * the below usage of @contrib to disappear entirely,\n\t\t\t * so no point in calculating it.\n\t\t\t */\n\t\t\tcontrib = __accumulate_pelt_segments(periods,\n\t\t\t\t\t1024 - sa->period_contrib, delta);\n\t\t}\n\t}\n\tsa->period_contrib = delta;\n\n\tif (load)\n\t\tsa->load_sum += load * contrib;\n\tif (runnable)\n\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;\n\tif (running)\n\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;\n\n\treturn periods;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline u32\naccumulate_sum(u64 delta, struct sched_avg *sa,\n\t       unsigned long load, unsigned long runnable, int running)\n{\n\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */\n\tu64 periods;\n\n\tdelta += sa->period_contrib;\n\tperiods = delta / 1024; /* A period is 1024us (~1ms) */\n\n\t/*\n\t * Step 1: decay old *_sum if we crossed period boundaries.\n\t */\n\tif (periods) {\n\t\tsa->load_sum = decay_load(sa->load_sum, periods);\n\t\tsa->runnable_sum =\n\t\t\tdecay_load(sa->runnable_sum, periods);\n\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);\n\n\t\t/*\n\t\t * Step 2\n\t\t */\n\t\tdelta %= 1024;\n\t\tif (load) {\n\t\t\t/*\n\t\t\t * This relies on the:\n\t\t\t *\n\t\t\t * if (!load)\n\t\t\t *\trunnable = running = 0;\n\t\t\t *\n\t\t\t * clause from ___update_load_sum(); this results in\n\t\t\t * the below usage of @contrib to disappear entirely,\n\t\t\t * so no point in calculating it.\n\t\t\t */\n\t\t\tcontrib = __accumulate_pelt_segments(periods,\n\t\t\t\t\t1024 - sa->period_contrib, delta);\n\t\t}\n\t}\n\tsa->period_contrib = delta;\n\n\tif (load)\n\t\tsa->load_sum += load * contrib;\n\tif (runnable)\n\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;\n\tif (running)\n\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;\n\n\treturn periods;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline int\n___update_load_sum(u64 now, struct sched_avg *sa,\n\t\t  unsigned long load, unsigned long runnable, int running)\n{\n\tu64 delta;\n\n\tdelta = now - sa->last_update_time;\n\t/*\n\t * This should only happen when time goes backwards, which it\n\t * unfortunately does during sched clock init when we swap over to TSC.\n\t */\n\tif ((s64)delta < 0) {\n\t\tsa->last_update_time = now;\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Use 1024ns as the unit of measurement since it's a reasonable\n\t * approximation of 1us and fast to compute.\n\t */\n\tdelta >>= 10;\n\tif (!delta)\n\t\treturn 0;\n\n\tsa->last_update_time += delta << 10;\n\n\t/*\n\t * running is a subset of runnable (weight) so running can't be set if\n\t * runnable is clear. But there are some corner cases where the current\n\t * se has been already dequeued but cfs_rq->curr still points to it.\n\t * This means that weight will be 0 but not running for a sched_entity\n\t * but also for a cfs_rq if the latter becomes idle. As an example,\n\t * this happens during idle_balance() which calls\n\t * update_blocked_averages().\n\t *\n\t * Also see the comment in accumulate_sum().\n\t */\n\tif (!load)\n\t\trunnable = running = 0;\n\n\t/*\n\t * Now we know we crossed measurement unit boundaries. The *_avg\n\t * accrues by two steps:\n\t *\n\t * Step 1: accumulate *_sum since last_update_time. If we haven't\n\t * crossed period boundaries, finish.\n\t */\n\tif (!accumulate_sum(delta, sa, load, runnable, running))\n\t\treturn 0;\n\n\treturn 1;\n}"
  },
  {
    "function_name": "accumulate_sum",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "105-153",
    "snippet": "static __always_inline u32\naccumulate_sum(u64 delta, struct sched_avg *sa,\n\t       unsigned long load, unsigned long runnable, int running)\n{\n\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */\n\tu64 periods;\n\n\tdelta += sa->period_contrib;\n\tperiods = delta / 1024; /* A period is 1024us (~1ms) */\n\n\t/*\n\t * Step 1: decay old *_sum if we crossed period boundaries.\n\t */\n\tif (periods) {\n\t\tsa->load_sum = decay_load(sa->load_sum, periods);\n\t\tsa->runnable_sum =\n\t\t\tdecay_load(sa->runnable_sum, periods);\n\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);\n\n\t\t/*\n\t\t * Step 2\n\t\t */\n\t\tdelta %= 1024;\n\t\tif (load) {\n\t\t\t/*\n\t\t\t * This relies on the:\n\t\t\t *\n\t\t\t * if (!load)\n\t\t\t *\trunnable = running = 0;\n\t\t\t *\n\t\t\t * clause from ___update_load_sum(); this results in\n\t\t\t * the below usage of @contrib to disappear entirely,\n\t\t\t * so no point in calculating it.\n\t\t\t */\n\t\t\tcontrib = __accumulate_pelt_segments(periods,\n\t\t\t\t\t1024 - sa->period_contrib, delta);\n\t\t}\n\t}\n\tsa->period_contrib = delta;\n\n\tif (load)\n\t\tsa->load_sum += load * contrib;\n\tif (runnable)\n\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;\n\tif (running)\n\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;\n\n\treturn periods;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__accumulate_pelt_segments",
          "args": [
            "periods",
            "1024 - sa->period_contrib",
            "delta"
          ],
          "line": 139
        },
        "resolved": true,
        "details": {
          "function_name": "__accumulate_pelt_segments",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "61-82",
          "snippet": "static u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)\n{\n\tu32 c1, c2, c3 = d3; /* y^0 == 1 */\n\n\t/*\n\t * c1 = d1 y^p\n\t */\n\tc1 = decay_load((u64)d1, periods);\n\n\t/*\n\t *            p-1\n\t * c2 = 1024 \\Sum y^n\n\t *            n=1\n\t *\n\t *              inf        inf\n\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )\n\t *              n=0        n=p\n\t */\n\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;\n\n\treturn c1 + c2 + c3;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)\n{\n\tu32 c1, c2, c3 = d3; /* y^0 == 1 */\n\n\t/*\n\t * c1 = d1 y^p\n\t */\n\tc1 = decay_load((u64)d1, periods);\n\n\t/*\n\t *            p-1\n\t * c2 = 1024 \\Sum y^n\n\t *            n=1\n\t *\n\t *              inf        inf\n\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )\n\t *              n=0        n=p\n\t */\n\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;\n\n\treturn c1 + c2 + c3;\n}"
        }
      },
      {
        "call_info": {
          "callee": "decay_load",
          "args": [
            "(u64)(sa->util_sum)",
            "periods"
          ],
          "line": 122
        },
        "resolved": true,
        "details": {
          "function_name": "decay_load",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "35-59",
          "snippet": "static u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t/* after bounds checking we can collapse to 32-bit */\n\tlocal_n = n;\n\n\t/*\n\t * As y^PERIOD = 1/2, we can combine\n\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)\n\t * With a look-up table which covers y^n (n<PERIOD)\n\t *\n\t * To achieve constant time decay_load.\n\t */\n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t/* after bounds checking we can collapse to 32-bit */\n\tlocal_n = n;\n\n\t/*\n\t * As y^PERIOD = 1/2, we can combine\n\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)\n\t * With a look-up table which covers y^n (n<PERIOD)\n\t *\n\t * To achieve constant time decay_load.\n\t */\n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}"
        }
      },
      {
        "call_info": {
          "callee": "",
          "args": [
            "sa->util_sum"
          ],
          "line": 122
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic __always_inline u32\naccumulate_sum(u64 delta, struct sched_avg *sa,\n\t       unsigned long load, unsigned long runnable, int running)\n{\n\tu32 contrib = (u32)delta; /* p == 0 -> delta < 1024 */\n\tu64 periods;\n\n\tdelta += sa->period_contrib;\n\tperiods = delta / 1024; /* A period is 1024us (~1ms) */\n\n\t/*\n\t * Step 1: decay old *_sum if we crossed period boundaries.\n\t */\n\tif (periods) {\n\t\tsa->load_sum = decay_load(sa->load_sum, periods);\n\t\tsa->runnable_sum =\n\t\t\tdecay_load(sa->runnable_sum, periods);\n\t\tsa->util_sum = decay_load((u64)(sa->util_sum), periods);\n\n\t\t/*\n\t\t * Step 2\n\t\t */\n\t\tdelta %= 1024;\n\t\tif (load) {\n\t\t\t/*\n\t\t\t * This relies on the:\n\t\t\t *\n\t\t\t * if (!load)\n\t\t\t *\trunnable = running = 0;\n\t\t\t *\n\t\t\t * clause from ___update_load_sum(); this results in\n\t\t\t * the below usage of @contrib to disappear entirely,\n\t\t\t * so no point in calculating it.\n\t\t\t */\n\t\t\tcontrib = __accumulate_pelt_segments(periods,\n\t\t\t\t\t1024 - sa->period_contrib, delta);\n\t\t}\n\t}\n\tsa->period_contrib = delta;\n\n\tif (load)\n\t\tsa->load_sum += load * contrib;\n\tif (runnable)\n\t\tsa->runnable_sum += runnable * contrib << SCHED_CAPACITY_SHIFT;\n\tif (running)\n\t\tsa->util_sum += contrib << SCHED_CAPACITY_SHIFT;\n\n\treturn periods;\n}"
  },
  {
    "function_name": "__accumulate_pelt_segments",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "61-82",
    "snippet": "static u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)\n{\n\tu32 c1, c2, c3 = d3; /* y^0 == 1 */\n\n\t/*\n\t * c1 = d1 y^p\n\t */\n\tc1 = decay_load((u64)d1, periods);\n\n\t/*\n\t *            p-1\n\t * c2 = 1024 \\Sum y^n\n\t *            n=1\n\t *\n\t *              inf        inf\n\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )\n\t *              n=0        n=p\n\t */\n\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;\n\n\treturn c1 + c2 + c3;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "decay_load",
          "args": [
            "LOAD_AVG_MAX",
            "periods"
          ],
          "line": 79
        },
        "resolved": true,
        "details": {
          "function_name": "decay_load",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
          "lines": "35-59",
          "snippet": "static u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t/* after bounds checking we can collapse to 32-bit */\n\tlocal_n = n;\n\n\t/*\n\t * As y^PERIOD = 1/2, we can combine\n\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)\n\t * With a look-up table which covers y^n (n<PERIOD)\n\t *\n\t * To achieve constant time decay_load.\n\t */\n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\"",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t/* after bounds checking we can collapse to 32-bit */\n\tlocal_n = n;\n\n\t/*\n\t * As y^PERIOD = 1/2, we can combine\n\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)\n\t * With a look-up table which covers y^n (n<PERIOD)\n\t *\n\t * To achieve constant time decay_load.\n\t */\n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic u32 __accumulate_pelt_segments(u64 periods, u32 d1, u32 d3)\n{\n\tu32 c1, c2, c3 = d3; /* y^0 == 1 */\n\n\t/*\n\t * c1 = d1 y^p\n\t */\n\tc1 = decay_load((u64)d1, periods);\n\n\t/*\n\t *            p-1\n\t * c2 = 1024 \\Sum y^n\n\t *            n=1\n\t *\n\t *              inf        inf\n\t *    = 1024 ( \\Sum y^n - \\Sum y^n - y^0 )\n\t *              n=0        n=p\n\t */\n\tc2 = LOAD_AVG_MAX - decay_load(LOAD_AVG_MAX, periods) - 1024;\n\n\treturn c1 + c2 + c3;\n}"
  },
  {
    "function_name": "decay_load",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/pelt.c",
    "lines": "35-59",
    "snippet": "static u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t/* after bounds checking we can collapse to 32-bit */\n\tlocal_n = n;\n\n\t/*\n\t * As y^PERIOD = 1/2, we can combine\n\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)\n\t * With a look-up table which covers y^n (n<PERIOD)\n\t *\n\t * To achieve constant time decay_load.\n\t */\n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}",
    "includes": [
      "#include \"pelt.h\"",
      "#include \"sched.h\"",
      "#include <linux/sched.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mul_u64_u32_shr",
          "args": [
            "val",
            "runnable_avg_yN_inv[local_n]",
            "32"
          ],
          "line": 57
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "local_n >= LOAD_AVG_PERIOD"
          ],
          "line": 52
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "n > LOAD_AVG_PERIOD * 63"
          ],
          "line": 39
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n#include <linux/sched.h>\n\nstatic u64 decay_load(u64 val, u64 n)\n{\n\tunsigned int local_n;\n\n\tif (unlikely(n > LOAD_AVG_PERIOD * 63))\n\t\treturn 0;\n\n\t/* after bounds checking we can collapse to 32-bit */\n\tlocal_n = n;\n\n\t/*\n\t * As y^PERIOD = 1/2, we can combine\n\t *    y^n = 1/2^(n/PERIOD) * y^(n%PERIOD)\n\t * With a look-up table which covers y^n (n<PERIOD)\n\t *\n\t * To achieve constant time decay_load.\n\t */\n\tif (unlikely(local_n >= LOAD_AVG_PERIOD)) {\n\t\tval >>= local_n / LOAD_AVG_PERIOD;\n\t\tlocal_n %= LOAD_AVG_PERIOD;\n\t}\n\n\tval = mul_u64_u32_shr(val, runnable_avg_yN_inv[local_n], 32);\n\treturn val;\n}"
  }
]