[
  {
    "function_name": "membarrier_register_private_expedited",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "501-541",
    "snippet": "static int membarrier_register_private_expedited(int flags)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ready_state = MEMBARRIER_STATE_PRIVATE_EXPEDITED_READY,\n\t    set_state = MEMBARRIER_STATE_PRIVATE_EXPEDITED,\n\t    ret;\n\n\tif (flags == MEMBARRIER_FLAG_SYNC_CORE) {\n\t\tif (!IS_ENABLED(CONFIG_ARCH_HAS_MEMBARRIER_SYNC_CORE))\n\t\t\treturn -EINVAL;\n\t\tready_state =\n\t\t\tMEMBARRIER_STATE_PRIVATE_EXPEDITED_SYNC_CORE_READY;\n\t} else if (flags == MEMBARRIER_FLAG_RSEQ) {\n\t\tif (!IS_ENABLED(CONFIG_RSEQ))\n\t\t\treturn -EINVAL;\n\t\tready_state =\n\t\t\tMEMBARRIER_STATE_PRIVATE_EXPEDITED_RSEQ_READY;\n\t} else {\n\t\tWARN_ON_ONCE(flags);\n\t}\n\n\t/*\n\t * We need to consider threads belonging to different thread\n\t * groups, which use the same mm. (CLONE_VM but not\n\t * CLONE_THREAD).\n\t */\n\tif ((atomic_read(&mm->membarrier_state) & ready_state) == ready_state)\n\t\treturn 0;\n\tif (flags & MEMBARRIER_FLAG_SYNC_CORE)\n\t\tset_state |= MEMBARRIER_STATE_PRIVATE_EXPEDITED_SYNC_CORE;\n\tif (flags & MEMBARRIER_FLAG_RSEQ)\n\t\tset_state |= MEMBARRIER_STATE_PRIVATE_EXPEDITED_RSEQ;\n\tatomic_or(set_state, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(ready_state, &mm->membarrier_state);\n\n\treturn 0;\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_or",
          "args": [
            "ready_state",
            "&mm->membarrier_state"
          ],
          "line": 538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sync_runqueues_membarrier_state",
          "args": [
            "mm"
          ],
          "line": 535
        },
        "resolved": true,
        "details": {
          "function_name": "sync_runqueues_membarrier_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
          "lines": "425-480",
          "snippet": "static int sync_runqueues_membarrier_state(struct mm_struct *mm)\n{\n\tint membarrier_state = atomic_read(&mm->membarrier_state);\n\tcpumask_var_t tmpmask;\n\tint cpu;\n\n\tif (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1) {\n\t\tthis_cpu_write(runqueues.membarrier_state, membarrier_state);\n\n\t\t/*\n\t\t * For single mm user, we can simply issue a memory barrier\n\t\t * after setting MEMBARRIER_STATE_GLOBAL_EXPEDITED in the\n\t\t * mm and in the current runqueue to guarantee that no memory\n\t\t * access following registration is reordered before\n\t\t * registration.\n\t\t */\n\t\tsmp_mb();\n\t\treturn 0;\n\t}\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * For mm with multiple users, we need to ensure all future\n\t * scheduler executions will observe @mm's new membarrier\n\t * state.\n\t */\n\tsynchronize_rcu();\n\n\t/*\n\t * For each cpu runqueue, if the task's mm match @mm, ensure that all\n\t * @mm's membarrier state set bits are also set in the runqueue's\n\t * membarrier state. This ensures that a runqueue scheduling\n\t * between threads which are users of @mm has its membarrier state\n\t * updated.\n\t */\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct rq *rq = cpu_rq(cpu);\n\t\tstruct task_struct *p;\n\n\t\tp = rcu_dereference(rq->curr);\n\t\tif (p && p->mm == mm)\n\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\ton_each_cpu_mask(tmpmask, ipi_sync_rq_state, mm, true);\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int sync_runqueues_membarrier_state(struct mm_struct *mm)\n{\n\tint membarrier_state = atomic_read(&mm->membarrier_state);\n\tcpumask_var_t tmpmask;\n\tint cpu;\n\n\tif (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1) {\n\t\tthis_cpu_write(runqueues.membarrier_state, membarrier_state);\n\n\t\t/*\n\t\t * For single mm user, we can simply issue a memory barrier\n\t\t * after setting MEMBARRIER_STATE_GLOBAL_EXPEDITED in the\n\t\t * mm and in the current runqueue to guarantee that no memory\n\t\t * access following registration is reordered before\n\t\t * registration.\n\t\t */\n\t\tsmp_mb();\n\t\treturn 0;\n\t}\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * For mm with multiple users, we need to ensure all future\n\t * scheduler executions will observe @mm's new membarrier\n\t * state.\n\t */\n\tsynchronize_rcu();\n\n\t/*\n\t * For each cpu runqueue, if the task's mm match @mm, ensure that all\n\t * @mm's membarrier state set bits are also set in the runqueue's\n\t * membarrier state. This ensures that a runqueue scheduling\n\t * between threads which are users of @mm has its membarrier state\n\t * updated.\n\t */\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct rq *rq = cpu_rq(cpu);\n\t\tstruct task_struct *p;\n\n\t\tp = rcu_dereference(rq->curr);\n\t\tif (p && p->mm == mm)\n\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\ton_each_cpu_mask(tmpmask, ipi_sync_rq_state, mm, true);\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_or",
          "args": [
            "set_state",
            "&mm->membarrier_state"
          ],
          "line": 534
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 528
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "flags"
          ],
          "line": 520
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RSEQ"
          ],
          "line": 515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_ARCH_HAS_MEMBARRIER_SYNC_CORE"
          ],
          "line": 510
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_private_expedited(int flags)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ready_state = MEMBARRIER_STATE_PRIVATE_EXPEDITED_READY,\n\t    set_state = MEMBARRIER_STATE_PRIVATE_EXPEDITED,\n\t    ret;\n\n\tif (flags == MEMBARRIER_FLAG_SYNC_CORE) {\n\t\tif (!IS_ENABLED(CONFIG_ARCH_HAS_MEMBARRIER_SYNC_CORE))\n\t\t\treturn -EINVAL;\n\t\tready_state =\n\t\t\tMEMBARRIER_STATE_PRIVATE_EXPEDITED_SYNC_CORE_READY;\n\t} else if (flags == MEMBARRIER_FLAG_RSEQ) {\n\t\tif (!IS_ENABLED(CONFIG_RSEQ))\n\t\t\treturn -EINVAL;\n\t\tready_state =\n\t\t\tMEMBARRIER_STATE_PRIVATE_EXPEDITED_RSEQ_READY;\n\t} else {\n\t\tWARN_ON_ONCE(flags);\n\t}\n\n\t/*\n\t * We need to consider threads belonging to different thread\n\t * groups, which use the same mm. (CLONE_VM but not\n\t * CLONE_THREAD).\n\t */\n\tif ((atomic_read(&mm->membarrier_state) & ready_state) == ready_state)\n\t\treturn 0;\n\tif (flags & MEMBARRIER_FLAG_SYNC_CORE)\n\t\tset_state |= MEMBARRIER_STATE_PRIVATE_EXPEDITED_SYNC_CORE;\n\tif (flags & MEMBARRIER_FLAG_RSEQ)\n\t\tset_state |= MEMBARRIER_STATE_PRIVATE_EXPEDITED_RSEQ;\n\tatomic_or(set_state, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(ready_state, &mm->membarrier_state);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "membarrier_register_global_expedited",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "482-499",
    "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ret;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_or",
          "args": [
            "MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY",
            "&mm->membarrier_state"
          ],
          "line": 495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sync_runqueues_membarrier_state",
          "args": [
            "mm"
          ],
          "line": 492
        },
        "resolved": true,
        "details": {
          "function_name": "sync_runqueues_membarrier_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
          "lines": "425-480",
          "snippet": "static int sync_runqueues_membarrier_state(struct mm_struct *mm)\n{\n\tint membarrier_state = atomic_read(&mm->membarrier_state);\n\tcpumask_var_t tmpmask;\n\tint cpu;\n\n\tif (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1) {\n\t\tthis_cpu_write(runqueues.membarrier_state, membarrier_state);\n\n\t\t/*\n\t\t * For single mm user, we can simply issue a memory barrier\n\t\t * after setting MEMBARRIER_STATE_GLOBAL_EXPEDITED in the\n\t\t * mm and in the current runqueue to guarantee that no memory\n\t\t * access following registration is reordered before\n\t\t * registration.\n\t\t */\n\t\tsmp_mb();\n\t\treturn 0;\n\t}\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * For mm with multiple users, we need to ensure all future\n\t * scheduler executions will observe @mm's new membarrier\n\t * state.\n\t */\n\tsynchronize_rcu();\n\n\t/*\n\t * For each cpu runqueue, if the task's mm match @mm, ensure that all\n\t * @mm's membarrier state set bits are also set in the runqueue's\n\t * membarrier state. This ensures that a runqueue scheduling\n\t * between threads which are users of @mm has its membarrier state\n\t * updated.\n\t */\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct rq *rq = cpu_rq(cpu);\n\t\tstruct task_struct *p;\n\n\t\tp = rcu_dereference(rq->curr);\n\t\tif (p && p->mm == mm)\n\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\ton_each_cpu_mask(tmpmask, ipi_sync_rq_state, mm, true);\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int sync_runqueues_membarrier_state(struct mm_struct *mm)\n{\n\tint membarrier_state = atomic_read(&mm->membarrier_state);\n\tcpumask_var_t tmpmask;\n\tint cpu;\n\n\tif (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1) {\n\t\tthis_cpu_write(runqueues.membarrier_state, membarrier_state);\n\n\t\t/*\n\t\t * For single mm user, we can simply issue a memory barrier\n\t\t * after setting MEMBARRIER_STATE_GLOBAL_EXPEDITED in the\n\t\t * mm and in the current runqueue to guarantee that no memory\n\t\t * access following registration is reordered before\n\t\t * registration.\n\t\t */\n\t\tsmp_mb();\n\t\treturn 0;\n\t}\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * For mm with multiple users, we need to ensure all future\n\t * scheduler executions will observe @mm's new membarrier\n\t * state.\n\t */\n\tsynchronize_rcu();\n\n\t/*\n\t * For each cpu runqueue, if the task's mm match @mm, ensure that all\n\t * @mm's membarrier state set bits are also set in the runqueue's\n\t * membarrier state. This ensures that a runqueue scheduling\n\t * between threads which are users of @mm has its membarrier state\n\t * updated.\n\t */\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct rq *rq = cpu_rq(cpu);\n\t\tstruct task_struct *p;\n\n\t\tp = rcu_dereference(rq->curr);\n\t\tif (p && p->mm == mm)\n\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\ton_each_cpu_mask(tmpmask, ipi_sync_rq_state, mm, true);\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_or",
          "args": [
            "MEMBARRIER_STATE_GLOBAL_EXPEDITED",
            "&mm->membarrier_state"
          ],
          "line": 491
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 488
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ret;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
  },
  {
    "function_name": "sync_runqueues_membarrier_state",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "425-480",
    "snippet": "static int sync_runqueues_membarrier_state(struct mm_struct *mm)\n{\n\tint membarrier_state = atomic_read(&mm->membarrier_state);\n\tcpumask_var_t tmpmask;\n\tint cpu;\n\n\tif (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1) {\n\t\tthis_cpu_write(runqueues.membarrier_state, membarrier_state);\n\n\t\t/*\n\t\t * For single mm user, we can simply issue a memory barrier\n\t\t * after setting MEMBARRIER_STATE_GLOBAL_EXPEDITED in the\n\t\t * mm and in the current runqueue to guarantee that no memory\n\t\t * access following registration is reordered before\n\t\t * registration.\n\t\t */\n\t\tsmp_mb();\n\t\treturn 0;\n\t}\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * For mm with multiple users, we need to ensure all future\n\t * scheduler executions will observe @mm's new membarrier\n\t * state.\n\t */\n\tsynchronize_rcu();\n\n\t/*\n\t * For each cpu runqueue, if the task's mm match @mm, ensure that all\n\t * @mm's membarrier state set bits are also set in the runqueue's\n\t * membarrier state. This ensures that a runqueue scheduling\n\t * between threads which are users of @mm has its membarrier state\n\t * updated.\n\t */\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct rq *rq = cpu_rq(cpu);\n\t\tstruct task_struct *p;\n\n\t\tp = rcu_dereference(rq->curr);\n\t\tif (p && p->mm == mm)\n\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\ton_each_cpu_mask(tmpmask, ipi_sync_rq_state, mm, true);\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\treturn 0;\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 477
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "tmpmask"
          ],
          "line": 476
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "on_each_cpu_mask",
          "args": [
            "tmpmask",
            "ipi_sync_rq_state",
            "mm",
            "true"
          ],
          "line": 474
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 472
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpumask_set_cpu",
          "args": [
            "cpu",
            "tmpmask"
          ],
          "line": 470
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "rq->curr"
          ],
          "line": 468
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 465
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 463
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 462
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 453
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_expedited",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "816-865",
          "snippet": "void synchronize_rcu_expedited(void)\n{\n\tbool boottime = (rcu_scheduler_active == RCU_SCHEDULER_INIT);\n\tstruct rcu_exp_work rew;\n\tstruct rcu_node *rnp;\n\tunsigned long s;\n\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu_expedited() in RCU read-side critical section\");\n\n\t/* Is the state is such that the call is a grace period? */\n\tif (rcu_blocking_is_gp())\n\t\treturn;\n\n\t/* If expedited grace periods are prohibited, fall back to normal. */\n\tif (rcu_gp_is_normal()) {\n\t\twait_rcu_gp(call_rcu);\n\t\treturn;\n\t}\n\n\t/* Take a snapshot of the sequence number.  */\n\ts = rcu_exp_gp_seq_snap();\n\tif (exp_funnel_lock(s))\n\t\treturn;  /* Someone else did our work for us. */\n\n\t/* Ensure that load happens before action based on it. */\n\tif (unlikely(boottime)) {\n\t\t/* Direct call during scheduler init and early_initcalls(). */\n\t\trcu_exp_sel_wait_wake(s);\n\t} else {\n\t\t/* Marshall arguments & schedule the expedited grace period. */\n\t\trew.rew_s = s;\n\t\tINIT_WORK_ONSTACK(&rew.rew_work, wait_rcu_exp_gp);\n\t\tqueue_work(rcu_gp_wq, &rew.rew_work);\n\t}\n\n\t/* Wait for expedited grace period to complete. */\n\trnp = rcu_get_root();\n\twait_event(rnp->exp_wq[rcu_seq_ctr(s) & 0x3],\n\t\t   sync_exp_work_done(s));\n\tsmp_mb(); /* Workqueue actions happen before return. */\n\n\t/* Let the next expedited grace period start. */\n\tmutex_unlock(&rcu_state.exp_mutex);\n\n\tif (likely(!boottime))\n\t\tdestroy_work_on_stack(&rew.rew_work);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int rcu_print_task_exp_stall(struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic int rcu_print_task_exp_stall(struct rcu_node *rnp);\n\nvoid synchronize_rcu_expedited(void)\n{\n\tbool boottime = (rcu_scheduler_active == RCU_SCHEDULER_INIT);\n\tstruct rcu_exp_work rew;\n\tstruct rcu_node *rnp;\n\tunsigned long s;\n\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu_expedited() in RCU read-side critical section\");\n\n\t/* Is the state is such that the call is a grace period? */\n\tif (rcu_blocking_is_gp())\n\t\treturn;\n\n\t/* If expedited grace periods are prohibited, fall back to normal. */\n\tif (rcu_gp_is_normal()) {\n\t\twait_rcu_gp(call_rcu);\n\t\treturn;\n\t}\n\n\t/* Take a snapshot of the sequence number.  */\n\ts = rcu_exp_gp_seq_snap();\n\tif (exp_funnel_lock(s))\n\t\treturn;  /* Someone else did our work for us. */\n\n\t/* Ensure that load happens before action based on it. */\n\tif (unlikely(boottime)) {\n\t\t/* Direct call during scheduler init and early_initcalls(). */\n\t\trcu_exp_sel_wait_wake(s);\n\t} else {\n\t\t/* Marshall arguments & schedule the expedited grace period. */\n\t\trew.rew_s = s;\n\t\tINIT_WORK_ONSTACK(&rew.rew_work, wait_rcu_exp_gp);\n\t\tqueue_work(rcu_gp_wq, &rew.rew_work);\n\t}\n\n\t/* Wait for expedited grace period to complete. */\n\trnp = rcu_get_root();\n\twait_event(rnp->exp_wq[rcu_seq_ctr(s) & 0x3],\n\t\t   sync_exp_work_done(s));\n\tsmp_mb(); /* Workqueue actions happen before return. */\n\n\t/* Let the next expedited grace period start. */\n\tmutex_unlock(&rcu_state.exp_mutex);\n\n\tif (likely(!boottime))\n\t\tdestroy_work_on_stack(&rew.rew_work);\n}"
        }
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&tmpmask",
            "GFP_KERNEL"
          ],
          "line": 445
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 441
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "runqueues.membarrier_state",
            "membarrier_state"
          ],
          "line": 432
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_online_cpus",
          "args": [],
          "line": 431
        },
        "resolved": true,
        "details": {
          "function_name": "torture_num_online_cpus",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/torture.c",
          "lines": "185-188",
          "snippet": "int torture_num_online_cpus(void)\n{\n\treturn READ_ONCE(torture_online_cpus);\n}",
          "includes": [
            "#include \"rcu/rcu.h\"",
            "#include <linux/torture.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/ktime.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/slab.h>",
            "#include <linux/stat.h>",
            "#include <linux/delay.h>",
            "#include <linux/cpu.h>",
            "#include <linux/freezer.h>",
            "#include <linux/reboot.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/err.h>",
            "#include <linux/kthread.h>",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu/rcu.h\"\n#include <linux/torture.h>\n#include <asm/byteorder.h>\n#include <linux/ktime.h>\n#include <linux/trace_clock.h>\n#include <linux/slab.h>\n#include <linux/stat.h>\n#include <linux/delay.h>\n#include <linux/cpu.h>\n#include <linux/freezer.h>\n#include <linux/reboot.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/err.h>\n#include <linux/kthread.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint torture_num_online_cpus(void)\n{\n\treturn READ_ONCE(torture_online_cpus);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->mm_users"
          ],
          "line": 431
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 427
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic int sync_runqueues_membarrier_state(struct mm_struct *mm)\n{\n\tint membarrier_state = atomic_read(&mm->membarrier_state);\n\tcpumask_var_t tmpmask;\n\tint cpu;\n\n\tif (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1) {\n\t\tthis_cpu_write(runqueues.membarrier_state, membarrier_state);\n\n\t\t/*\n\t\t * For single mm user, we can simply issue a memory barrier\n\t\t * after setting MEMBARRIER_STATE_GLOBAL_EXPEDITED in the\n\t\t * mm and in the current runqueue to guarantee that no memory\n\t\t * access following registration is reordered before\n\t\t * registration.\n\t\t */\n\t\tsmp_mb();\n\t\treturn 0;\n\t}\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\t/*\n\t * For mm with multiple users, we need to ensure all future\n\t * scheduler executions will observe @mm's new membarrier\n\t * state.\n\t */\n\tsynchronize_rcu();\n\n\t/*\n\t * For each cpu runqueue, if the task's mm match @mm, ensure that all\n\t * @mm's membarrier state set bits are also set in the runqueue's\n\t * membarrier state. This ensures that a runqueue scheduling\n\t * between threads which are users of @mm has its membarrier state\n\t * updated.\n\t */\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct rq *rq = cpu_rq(cpu);\n\t\tstruct task_struct *p;\n\n\t\tp = rcu_dereference(rq->curr);\n\t\tif (p && p->mm == mm)\n\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\ton_each_cpu_mask(tmpmask, ipi_sync_rq_state, mm, true);\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\treturn 0;\n}"
  },
  {
    "function_name": "membarrier_private_expedited",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "309-423",
    "snippet": "static int membarrier_private_expedited(int flags, int cpu_id)\n{\n\tcpumask_var_t tmpmask;\n\tstruct mm_struct *mm = current->mm;\n\tsmp_call_func_t ipi_func = ipi_mb;\n\n\tif (flags == MEMBARRIER_FLAG_SYNC_CORE) {\n\t\tif (!IS_ENABLED(CONFIG_ARCH_HAS_MEMBARRIER_SYNC_CORE))\n\t\t\treturn -EINVAL;\n\t\tif (!(atomic_read(&mm->membarrier_state) &\n\t\t      MEMBARRIER_STATE_PRIVATE_EXPEDITED_SYNC_CORE_READY))\n\t\t\treturn -EPERM;\n\t\tipi_func = ipi_sync_core;\n\t} else if (flags == MEMBARRIER_FLAG_RSEQ) {\n\t\tif (!IS_ENABLED(CONFIG_RSEQ))\n\t\t\treturn -EINVAL;\n\t\tif (!(atomic_read(&mm->membarrier_state) &\n\t\t      MEMBARRIER_STATE_PRIVATE_EXPEDITED_RSEQ_READY))\n\t\t\treturn -EPERM;\n\t\tipi_func = ipi_rseq;\n\t} else {\n\t\tWARN_ON_ONCE(flags);\n\t\tif (!(atomic_read(&mm->membarrier_state) &\n\t\t      MEMBARRIER_STATE_PRIVATE_EXPEDITED_READY))\n\t\t\treturn -EPERM;\n\t}\n\n\tif (flags != MEMBARRIER_FLAG_SYNC_CORE &&\n\t    (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1))\n\t\treturn 0;\n\n\t/*\n\t * Matches memory barriers around rq->curr modification in\n\t * scheduler.\n\t */\n\tsmp_mb();\t/* system call entry is not a mb. */\n\n\tif (cpu_id < 0 && !zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tcpus_read_lock();\n\n\tif (cpu_id >= 0) {\n\t\tstruct task_struct *p;\n\n\t\tif (cpu_id >= nr_cpu_ids || !cpu_online(cpu_id))\n\t\t\tgoto out;\n\t\trcu_read_lock();\n\t\tp = rcu_dereference(cpu_rq(cpu_id)->curr);\n\t\tif (!p || p->mm != mm) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto out;\n\t\t}\n\t\trcu_read_unlock();\n\t} else {\n\t\tint cpu;\n\n\t\trcu_read_lock();\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tstruct task_struct *p;\n\n\t\t\tp = rcu_dereference(cpu_rq(cpu)->curr);\n\t\t\tif (p && p->mm == mm)\n\t\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tif (cpu_id >= 0) {\n\t\t/*\n\t\t * smp_call_function_single() will call ipi_func() if cpu_id\n\t\t * is the calling CPU.\n\t\t */\n\t\tsmp_call_function_single(cpu_id, ipi_func, NULL, 1);\n\t} else {\n\t\t/*\n\t\t * For regular membarrier, we can save a few cycles by\n\t\t * skipping the current cpu -- we're about to do smp_mb()\n\t\t * below, and if we migrate to a different cpu, this cpu\n\t\t * and the new cpu will execute a full barrier in the\n\t\t * scheduler.\n\t\t *\n\t\t * For SYNC_CORE, we do need a barrier on the current cpu --\n\t\t * otherwise, if we are migrated and replaced by a different\n\t\t * task in the same mm just before, during, or after\n\t\t * membarrier, we will end up with some thread in the mm\n\t\t * running without a core sync.\n\t\t *\n\t\t * For RSEQ, don't rseq_preempt() the caller.  User code\n\t\t * is not supposed to issue syscalls at all from inside an\n\t\t * rseq critical section.\n\t\t */\n\t\tif (flags != MEMBARRIER_FLAG_SYNC_CORE) {\n\t\t\tpreempt_disable();\n\t\t\tsmp_call_function_many(tmpmask, ipi_func, NULL, true);\n\t\t\tpreempt_enable();\n\t\t} else {\n\t\t\ton_each_cpu_mask(tmpmask, ipi_func, NULL, true);\n\t\t}\n\t}\n\nout:\n\tif (cpu_id < 0)\n\t\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\t/*\n\t * Memory barrier on the caller thread _after_ we finished\n\t * waiting for the last IPI. Matches memory barriers around\n\t * rq->curr modification in scheduler.\n\t */\n\tsmp_mb();\t/* exit from system call is not a mb */\n\n\treturn 0;\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 420
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 413
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "tmpmask"
          ],
          "line": 412
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "on_each_cpu_mask",
          "args": [
            "tmpmask",
            "ipi_func",
            "NULL",
            "true"
          ],
          "line": 406
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 404
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_call_function_many",
          "args": [
            "tmpmask",
            "ipi_func",
            "NULL",
            "true"
          ],
          "line": 403
        },
        "resolved": true,
        "details": {
          "function_name": "smp_call_function_many",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/smp.c",
          "lines": "990-994",
          "snippet": "void smp_call_function_many(const struct cpumask *mask,\n\t\t\t    smp_call_func_t func, void *info, bool wait)\n{\n\tsmp_call_function_many_cond(mask, func, info, wait * SCF_WAIT, NULL);\n}",
          "includes": [
            "#include \"sched/smp.h\"",
            "#include \"smpboot.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [
            "#define SCF_WAIT\t(1U << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched/smp.h\"\n#include \"smpboot.h\"\n#include <linux/jump_label.h>\n#include <linux/sched/debug.h>\n#include <linux/nmi.h>\n#include <linux/sched/clock.h>\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/interrupt.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\n#define SCF_WAIT\t(1U << 0)\n\nvoid smp_call_function_many(const struct cpumask *mask,\n\t\t\t    smp_call_func_t func, void *info, bool wait)\n{\n\tsmp_call_function_many_cond(mask, func, info, wait * SCF_WAIT, NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 402
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_call_function_single",
          "args": [
            "cpu_id",
            "ipi_func",
            "NULL",
            "1"
          ],
          "line": 382
        },
        "resolved": true,
        "details": {
          "function_name": "smp_call_function_single",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
          "lines": "12-25",
          "snippet": "int smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/hypervisor.h>",
            "#include <linux/smp.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 374
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpumask_set_cpu",
          "args": [
            "cpu",
            "tmpmask"
          ],
          "line": 372
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "cpu_rq(cpu)->curr"
          ],
          "line": 370
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 370
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 366
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "cpu_rq(cpu_id)->curr"
          ],
          "line": 357
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_online",
          "args": [
            "cpu_id"
          ],
          "line": 354
        },
        "resolved": true,
        "details": {
          "function_name": "init_cpu_online",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "2616-2619",
          "snippet": "void init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "struct cpumask __cpu_online_mask"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nstruct cpumask __cpu_online_mask;\n\nvoid init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 349
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&tmpmask",
            "GFP_KERNEL"
          ],
          "line": 346
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 344
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_online_cpus",
          "args": [],
          "line": 337
        },
        "resolved": true,
        "details": {
          "function_name": "torture_num_online_cpus",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/torture.c",
          "lines": "185-188",
          "snippet": "int torture_num_online_cpus(void)\n{\n\treturn READ_ONCE(torture_online_cpus);\n}",
          "includes": [
            "#include \"rcu/rcu.h\"",
            "#include <linux/torture.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/ktime.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/slab.h>",
            "#include <linux/stat.h>",
            "#include <linux/delay.h>",
            "#include <linux/cpu.h>",
            "#include <linux/freezer.h>",
            "#include <linux/reboot.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/err.h>",
            "#include <linux/kthread.h>",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu/rcu.h\"\n#include <linux/torture.h>\n#include <asm/byteorder.h>\n#include <linux/ktime.h>\n#include <linux/trace_clock.h>\n#include <linux/slab.h>\n#include <linux/stat.h>\n#include <linux/delay.h>\n#include <linux/cpu.h>\n#include <linux/freezer.h>\n#include <linux/reboot.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/err.h>\n#include <linux/kthread.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint torture_num_online_cpus(void)\n{\n\treturn READ_ONCE(torture_online_cpus);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->mm_users"
          ],
          "line": 337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 331
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "flags"
          ],
          "line": 330
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 325
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RSEQ"
          ],
          "line": 323
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 318
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_ARCH_HAS_MEMBARRIER_SYNC_CORE"
          ],
          "line": 316
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_private_expedited(int flags, int cpu_id)\n{\n\tcpumask_var_t tmpmask;\n\tstruct mm_struct *mm = current->mm;\n\tsmp_call_func_t ipi_func = ipi_mb;\n\n\tif (flags == MEMBARRIER_FLAG_SYNC_CORE) {\n\t\tif (!IS_ENABLED(CONFIG_ARCH_HAS_MEMBARRIER_SYNC_CORE))\n\t\t\treturn -EINVAL;\n\t\tif (!(atomic_read(&mm->membarrier_state) &\n\t\t      MEMBARRIER_STATE_PRIVATE_EXPEDITED_SYNC_CORE_READY))\n\t\t\treturn -EPERM;\n\t\tipi_func = ipi_sync_core;\n\t} else if (flags == MEMBARRIER_FLAG_RSEQ) {\n\t\tif (!IS_ENABLED(CONFIG_RSEQ))\n\t\t\treturn -EINVAL;\n\t\tif (!(atomic_read(&mm->membarrier_state) &\n\t\t      MEMBARRIER_STATE_PRIVATE_EXPEDITED_RSEQ_READY))\n\t\t\treturn -EPERM;\n\t\tipi_func = ipi_rseq;\n\t} else {\n\t\tWARN_ON_ONCE(flags);\n\t\tif (!(atomic_read(&mm->membarrier_state) &\n\t\t      MEMBARRIER_STATE_PRIVATE_EXPEDITED_READY))\n\t\t\treturn -EPERM;\n\t}\n\n\tif (flags != MEMBARRIER_FLAG_SYNC_CORE &&\n\t    (atomic_read(&mm->mm_users) == 1 || num_online_cpus() == 1))\n\t\treturn 0;\n\n\t/*\n\t * Matches memory barriers around rq->curr modification in\n\t * scheduler.\n\t */\n\tsmp_mb();\t/* system call entry is not a mb. */\n\n\tif (cpu_id < 0 && !zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tcpus_read_lock();\n\n\tif (cpu_id >= 0) {\n\t\tstruct task_struct *p;\n\n\t\tif (cpu_id >= nr_cpu_ids || !cpu_online(cpu_id))\n\t\t\tgoto out;\n\t\trcu_read_lock();\n\t\tp = rcu_dereference(cpu_rq(cpu_id)->curr);\n\t\tif (!p || p->mm != mm) {\n\t\t\trcu_read_unlock();\n\t\t\tgoto out;\n\t\t}\n\t\trcu_read_unlock();\n\t} else {\n\t\tint cpu;\n\n\t\trcu_read_lock();\n\t\tfor_each_online_cpu(cpu) {\n\t\t\tstruct task_struct *p;\n\n\t\t\tp = rcu_dereference(cpu_rq(cpu)->curr);\n\t\t\tif (p && p->mm == mm)\n\t\t\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t\t}\n\t\trcu_read_unlock();\n\t}\n\n\tif (cpu_id >= 0) {\n\t\t/*\n\t\t * smp_call_function_single() will call ipi_func() if cpu_id\n\t\t * is the calling CPU.\n\t\t */\n\t\tsmp_call_function_single(cpu_id, ipi_func, NULL, 1);\n\t} else {\n\t\t/*\n\t\t * For regular membarrier, we can save a few cycles by\n\t\t * skipping the current cpu -- we're about to do smp_mb()\n\t\t * below, and if we migrate to a different cpu, this cpu\n\t\t * and the new cpu will execute a full barrier in the\n\t\t * scheduler.\n\t\t *\n\t\t * For SYNC_CORE, we do need a barrier on the current cpu --\n\t\t * otherwise, if we are migrated and replaced by a different\n\t\t * task in the same mm just before, during, or after\n\t\t * membarrier, we will end up with some thread in the mm\n\t\t * running without a core sync.\n\t\t *\n\t\t * For RSEQ, don't rseq_preempt() the caller.  User code\n\t\t * is not supposed to issue syscalls at all from inside an\n\t\t * rseq critical section.\n\t\t */\n\t\tif (flags != MEMBARRIER_FLAG_SYNC_CORE) {\n\t\t\tpreempt_disable();\n\t\t\tsmp_call_function_many(tmpmask, ipi_func, NULL, true);\n\t\t\tpreempt_enable();\n\t\t} else {\n\t\t\ton_each_cpu_mask(tmpmask, ipi_func, NULL, true);\n\t\t}\n\t}\n\nout:\n\tif (cpu_id < 0)\n\t\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\t/*\n\t * Memory barrier on the caller thread _after_ we finished\n\t * waiting for the last IPI. Matches memory barriers around\n\t * rq->curr modification in scheduler.\n\t */\n\tsmp_mb();\t/* exit from system call is not a mb */\n\n\treturn 0;\n}"
  },
  {
    "function_name": "membarrier_global_expedited",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "244-307",
    "snippet": "static int membarrier_global_expedited(void)\n{\n\tint cpu;\n\tcpumask_var_t tmpmask;\n\n\tif (num_online_cpus() == 1)\n\t\treturn 0;\n\n\t/*\n\t * Matches memory barriers around rq->curr modification in\n\t * scheduler.\n\t */\n\tsmp_mb();\t/* system call entry is not a mb. */\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct task_struct *p;\n\n\t\t/*\n\t\t * Skipping the current CPU is OK even through we can be\n\t\t * migrated at any point. The current CPU, at the point\n\t\t * where we read raw_smp_processor_id(), is ensured to\n\t\t * be in program order with respect to the caller\n\t\t * thread. Therefore, we can skip this CPU from the\n\t\t * iteration.\n\t\t */\n\t\tif (cpu == raw_smp_processor_id())\n\t\t\tcontinue;\n\n\t\tif (!(READ_ONCE(cpu_rq(cpu)->membarrier_state) &\n\t\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Skip the CPU if it runs a kernel thread which is not using\n\t\t * a task mm.\n\t\t */\n\t\tp = rcu_dereference(cpu_rq(cpu)->curr);\n\t\tif (!p->mm)\n\t\t\tcontinue;\n\n\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\tpreempt_disable();\n\tsmp_call_function_many(tmpmask, ipi_mb, NULL, 1);\n\tpreempt_enable();\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\t/*\n\t * Memory barrier on the caller thread _after_ we finished\n\t * waiting for the last IPI. Matches memory barriers around\n\t * rq->curr modification in scheduler.\n\t */\n\tsmp_mb();\t/* exit from system call is not a mb */\n\treturn 0;\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 305
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 298
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "tmpmask"
          ],
          "line": 297
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 295
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_call_function_many",
          "args": [
            "tmpmask",
            "ipi_mb",
            "NULL",
            "1"
          ],
          "line": 294
        },
        "resolved": true,
        "details": {
          "function_name": "smp_call_function_many",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/smp.c",
          "lines": "990-994",
          "snippet": "void smp_call_function_many(const struct cpumask *mask,\n\t\t\t    smp_call_func_t func, void *info, bool wait)\n{\n\tsmp_call_function_many_cond(mask, func, info, wait * SCF_WAIT, NULL);\n}",
          "includes": [
            "#include \"sched/smp.h\"",
            "#include \"smpboot.h\"",
            "#include <linux/jump_label.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/hypervisor.h>",
            "#include <linux/sched/idle.h>",
            "#include <linux/sched.h>",
            "#include <linux/cpu.h>",
            "#include <linux/smp.h>",
            "#include <linux/gfp.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/rculist.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [
            "#define SCF_WAIT\t(1U << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched/smp.h\"\n#include \"smpboot.h\"\n#include <linux/jump_label.h>\n#include <linux/sched/debug.h>\n#include <linux/nmi.h>\n#include <linux/sched/clock.h>\n#include <linux/hypervisor.h>\n#include <linux/sched/idle.h>\n#include <linux/sched.h>\n#include <linux/cpu.h>\n#include <linux/smp.h>\n#include <linux/gfp.h>\n#include <linux/interrupt.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/rculist.h>\n#include <linux/rcupdate.h>\n#include <linux/irq_work.h>\n\n#define SCF_WAIT\t(1U << 0)\n\nvoid smp_call_function_many(const struct cpumask *mask,\n\t\t\t    smp_call_func_t func, void *info, bool wait)\n{\n\tsmp_call_function_many_cond(mask, func, info, wait * SCF_WAIT, NULL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 293
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 291
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpumask_set_cpu",
          "args": [
            "cpu",
            "tmpmask"
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dereference",
          "args": [
            "cpu_rq(cpu)->curr"
          ],
          "line": 285
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_rq",
          "args": [
            "cpu"
          ],
          "line": 285
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "5032-5048",
          "snippet": "for_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int i;",
            "unsigned long long sum = 0;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nint i;\nunsigned long long sum = 0;\n\nfor_each_possible_cpu(i)\n\t\tsum += cpu_rq(i)->nr_switches;\n\n\treturn sum;\n}\n\n/*\n * Consumers of these two interfaces, like for example the cpuidle menu\n * governor, are using nonsensical data. Preferring shallow idle state selection\n * for a CPU that has IO-wait which might not even end up running the task when\n * it does become runnable.\n */\n\nunsigned int nr_iowait_cpu(int cpu)\n{\n\treturn atomic_read(&cpu_rq(cpu)->nr_iowait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "cpu_rq(cpu)->membarrier_state"
          ],
          "line": 277
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 274
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 262
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 261
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&tmpmask",
            "GFP_KERNEL"
          ],
          "line": 258
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 256
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "num_online_cpus",
          "args": [],
          "line": 249
        },
        "resolved": true,
        "details": {
          "function_name": "torture_num_online_cpus",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/torture.c",
          "lines": "185-188",
          "snippet": "int torture_num_online_cpus(void)\n{\n\treturn READ_ONCE(torture_online_cpus);\n}",
          "includes": [
            "#include \"rcu/rcu.h\"",
            "#include <linux/torture.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/ktime.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/slab.h>",
            "#include <linux/stat.h>",
            "#include <linux/delay.h>",
            "#include <linux/cpu.h>",
            "#include <linux/freezer.h>",
            "#include <linux/reboot.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/err.h>",
            "#include <linux/kthread.h>",
            "#include <linux/module.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu/rcu.h\"\n#include <linux/torture.h>\n#include <asm/byteorder.h>\n#include <linux/ktime.h>\n#include <linux/trace_clock.h>\n#include <linux/slab.h>\n#include <linux/stat.h>\n#include <linux/delay.h>\n#include <linux/cpu.h>\n#include <linux/freezer.h>\n#include <linux/reboot.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/err.h>\n#include <linux/kthread.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint torture_num_online_cpus(void)\n{\n\treturn READ_ONCE(torture_online_cpus);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_global_expedited(void)\n{\n\tint cpu;\n\tcpumask_var_t tmpmask;\n\n\tif (num_online_cpus() == 1)\n\t\treturn 0;\n\n\t/*\n\t * Matches memory barriers around rq->curr modification in\n\t * scheduler.\n\t */\n\tsmp_mb();\t/* system call entry is not a mb. */\n\n\tif (!zalloc_cpumask_var(&tmpmask, GFP_KERNEL))\n\t\treturn -ENOMEM;\n\n\tcpus_read_lock();\n\trcu_read_lock();\n\tfor_each_online_cpu(cpu) {\n\t\tstruct task_struct *p;\n\n\t\t/*\n\t\t * Skipping the current CPU is OK even through we can be\n\t\t * migrated at any point. The current CPU, at the point\n\t\t * where we read raw_smp_processor_id(), is ensured to\n\t\t * be in program order with respect to the caller\n\t\t * thread. Therefore, we can skip this CPU from the\n\t\t * iteration.\n\t\t */\n\t\tif (cpu == raw_smp_processor_id())\n\t\t\tcontinue;\n\n\t\tif (!(READ_ONCE(cpu_rq(cpu)->membarrier_state) &\n\t\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * Skip the CPU if it runs a kernel thread which is not using\n\t\t * a task mm.\n\t\t */\n\t\tp = rcu_dereference(cpu_rq(cpu)->curr);\n\t\tif (!p->mm)\n\t\t\tcontinue;\n\n\t\t__cpumask_set_cpu(cpu, tmpmask);\n\t}\n\trcu_read_unlock();\n\n\tpreempt_disable();\n\tsmp_call_function_many(tmpmask, ipi_mb, NULL, 1);\n\tpreempt_enable();\n\n\tfree_cpumask_var(tmpmask);\n\tcpus_read_unlock();\n\n\t/*\n\t * Memory barrier on the caller thread _after_ we finished\n\t * waiting for the last IPI. Matches memory barriers around\n\t * rq->curr modification in scheduler.\n\t */\n\tsmp_mb();\t/* exit from system call is not a mb */\n\treturn 0;\n}"
  },
  {
    "function_name": "membarrier_update_current_mm",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "232-242",
    "snippet": "void membarrier_update_current_mm(struct mm_struct *next_mm)\n{\n\tstruct rq *rq = this_rq();\n\tint membarrier_state = 0;\n\n\tif (next_mm)\n\t\tmembarrier_state = atomic_read(&next_mm->membarrier_state);\n\tif (READ_ONCE(rq->membarrier_state) == membarrier_state)\n\t\treturn;\n\tWRITE_ONCE(rq->membarrier_state, membarrier_state);\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rq->membarrier_state",
            "membarrier_state"
          ],
          "line": 241
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rq->membarrier_state"
          ],
          "line": 239
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&next_mm->membarrier_state"
          ],
          "line": 238
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_rq",
          "args": [],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nvoid membarrier_update_current_mm(struct mm_struct *next_mm)\n{\n\tstruct rq *rq = this_rq();\n\tint membarrier_state = 0;\n\n\tif (next_mm)\n\t\tmembarrier_state = atomic_read(&next_mm->membarrier_state);\n\tif (READ_ONCE(rq->membarrier_state) == membarrier_state)\n\t\treturn;\n\tWRITE_ONCE(rq->membarrier_state, membarrier_state);\n}"
  },
  {
    "function_name": "membarrier_exec_mmap",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "216-230",
    "snippet": "void membarrier_exec_mmap(struct mm_struct *mm)\n{\n\t/*\n\t * Issue a memory barrier before clearing membarrier_state to\n\t * guarantee that no memory access prior to exec is reordered after\n\t * clearing this state.\n\t */\n\tsmp_mb();\n\tatomic_set(&mm->membarrier_state, 0);\n\t/*\n\t * Keep the runqueue membarrier_state in sync with this mm\n\t * membarrier_state.\n\t */\n\tthis_cpu_write(runqueues.membarrier_state, 0);\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "runqueues.membarrier_state",
            "0"
          ],
          "line": 229
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_set",
          "args": [
            "&mm->membarrier_state",
            "0"
          ],
          "line": 224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 223
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nvoid membarrier_exec_mmap(struct mm_struct *mm)\n{\n\t/*\n\t * Issue a memory barrier before clearing membarrier_state to\n\t * guarantee that no memory access prior to exec is reordered after\n\t * clearing this state.\n\t */\n\tsmp_mb();\n\tatomic_set(&mm->membarrier_state, 0);\n\t/*\n\t * Keep the runqueue membarrier_state in sync with this mm\n\t * membarrier_state.\n\t */\n\tthis_cpu_write(runqueues.membarrier_state, 0);\n}"
  },
  {
    "function_name": "ipi_sync_rq_state",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "199-214",
    "snippet": "static void ipi_sync_rq_state(void *info)\n{\n\tstruct mm_struct *mm = (struct mm_struct *) info;\n\n\tif (current->mm != mm)\n\t\treturn;\n\tthis_cpu_write(runqueues.membarrier_state,\n\t\t       atomic_read(&mm->membarrier_state));\n\t/*\n\t * Issue a memory barrier after setting\n\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED in the current runqueue to\n\t * guarantee that no memory access following registration is reordered\n\t * before registration.\n\t */\n\tsmp_mb();\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 213
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "runqueues.membarrier_state",
            "atomic_read(&mm->membarrier_state)"
          ],
          "line": 205
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&mm->membarrier_state"
          ],
          "line": 206
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic void ipi_sync_rq_state(void *info)\n{\n\tstruct mm_struct *mm = (struct mm_struct *) info;\n\n\tif (current->mm != mm)\n\t\treturn;\n\tthis_cpu_write(runqueues.membarrier_state,\n\t\t       atomic_read(&mm->membarrier_state));\n\t/*\n\t * Issue a memory barrier after setting\n\t * MEMBARRIER_STATE_GLOBAL_EXPEDITED in the current runqueue to\n\t * guarantee that no memory access following registration is reordered\n\t * before registration.\n\t */\n\tsmp_mb();\n}"
  },
  {
    "function_name": "ipi_rseq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "186-197",
    "snippet": "static void ipi_rseq(void *info)\n{\n\t/*\n\t * Ensure that all stores done by the calling thread are visible\n\t * to the current task before the current task resumes.  We could\n\t * probably optimize this away on most architectures, but by the\n\t * time we've already sent an IPI, the cost of the extra smp_mb()\n\t * is negligible.\n\t */\n\tsmp_mb();\n\trseq_preempt(current);\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rseq_preempt",
          "args": [
            "current"
          ],
          "line": 196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 195
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic void ipi_rseq(void *info)\n{\n\t/*\n\t * Ensure that all stores done by the calling thread are visible\n\t * to the current task before the current task resumes.  We could\n\t * probably optimize this away on most architectures, but by the\n\t * time we've already sent an IPI, the cost of the extra smp_mb()\n\t * is negligible.\n\t */\n\tsmp_mb();\n\trseq_preempt(current);\n}"
  },
  {
    "function_name": "ipi_sync_core",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "169-184",
    "snippet": "static void ipi_sync_core(void *info)\n{\n\t/*\n\t * The smp_mb() in membarrier after all the IPIs is supposed to\n\t * ensure that memory on remote CPUs that occur before the IPI\n\t * become visible to membarrier()'s caller -- see scenario B in\n\t * the big comment at the top of this file.\n\t *\n\t * A sync_core() would provide this guarantee, but\n\t * sync_core_before_usermode() might end up being deferred until\n\t * after membarrier()'s smp_mb().\n\t */\n\tsmp_mb();\t/* IPIs should be serializing but paranoid. */\n\n\tsync_core_before_usermode();\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sync_core_before_usermode",
          "args": [],
          "line": 183
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 181
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic void ipi_sync_core(void *info)\n{\n\t/*\n\t * The smp_mb() in membarrier after all the IPIs is supposed to\n\t * ensure that memory on remote CPUs that occur before the IPI\n\t * become visible to membarrier()'s caller -- see scenario B in\n\t * the big comment at the top of this file.\n\t *\n\t * A sync_core() would provide this guarantee, but\n\t * sync_core_before_usermode() might end up being deferred until\n\t * after membarrier()'s smp_mb().\n\t */\n\tsmp_mb();\t/* IPIs should be serializing but paranoid. */\n\n\tsync_core_before_usermode();\n}"
  },
  {
    "function_name": "ipi_mb",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "164-167",
    "snippet": "static void ipi_mb(void *info)\n{\n\tsmp_mb();\t/* IPIs should be serializing but paranoid. */\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 166
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"sched.h\"\n\nstatic void ipi_mb(void *info)\n{\n\tsmp_mb();\t/* IPIs should be serializing but paranoid. */\n}"
  },
  {
    "function_name": "membarrier",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
    "lines": "579-629",
    "snippet": "SYSCALL_DEFINE3(membarrier, int, cmd, unsigned int, flags, int, cpu_id)\n{\n\tswitch (cmd) {\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED_RSEQ:\n\t\tif (unlikely(flags && flags != MEMBARRIER_CMD_FLAG_CPU))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tif (unlikely(flags))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!(flags & MEMBARRIER_CMD_FLAG_CPU))\n\t\tcpu_id = -1;\n\n\tswitch (cmd) {\n\tcase MEMBARRIER_CMD_QUERY:\n\t{\n\t\tint cmd_mask = MEMBARRIER_CMD_BITMASK;\n\n\t\tif (tick_nohz_full_enabled())\n\t\t\tcmd_mask &= ~MEMBARRIER_CMD_GLOBAL;\n\t\treturn cmd_mask;\n\t}\n\tcase MEMBARRIER_CMD_GLOBAL:\n\t\t/* MEMBARRIER_CMD_GLOBAL is not compatible with nohz_full. */\n\t\tif (tick_nohz_full_enabled())\n\t\t\treturn -EINVAL;\n\t\tif (num_online_cpus() > 1)\n\t\t\tsynchronize_rcu();\n\t\treturn 0;\n\tcase MEMBARRIER_CMD_GLOBAL_EXPEDITED:\n\t\treturn membarrier_global_expedited();\n\tcase MEMBARRIER_CMD_REGISTER_GLOBAL_EXPEDITED:\n\t\treturn membarrier_register_global_expedited();\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED:\n\t\treturn membarrier_private_expedited(0, cpu_id);\n\tcase MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED:\n\t\treturn membarrier_register_private_expedited(0);\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED_SYNC_CORE:\n\t\treturn membarrier_private_expedited(MEMBARRIER_FLAG_SYNC_CORE, cpu_id);\n\tcase MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_SYNC_CORE:\n\t\treturn membarrier_register_private_expedited(MEMBARRIER_FLAG_SYNC_CORE);\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED_RSEQ:\n\t\treturn membarrier_private_expedited(MEMBARRIER_FLAG_RSEQ, cpu_id);\n\tcase MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_RSEQ:\n\t\treturn membarrier_register_private_expedited(MEMBARRIER_FLAG_RSEQ);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}",
    "includes": [
      "#include \"sched.h\""
    ],
    "macros_used": [
      "#define MEMBARRIER_CMD_BITMASK\t\t\t\t\t\t\\\n\t(MEMBARRIER_CMD_GLOBAL | MEMBARRIER_CMD_GLOBAL_EXPEDITED\t\\\n\t| MEMBARRIER_CMD_REGISTER_GLOBAL_EXPEDITED\t\t\t\\\n\t| MEMBARRIER_CMD_PRIVATE_EXPEDITED\t\t\t\t\\\n\t| MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED\t\t\t\\\n\t| MEMBARRIER_PRIVATE_EXPEDITED_SYNC_CORE_BITMASK)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"sched.h\"\n\n#define MEMBARRIER_CMD_BITMASK\t\t\t\t\t\t\\\n\t(MEMBARRIER_CMD_GLOBAL | MEMBARRIER_CMD_GLOBAL_EXPEDITED\t\\\n\t| MEMBARRIER_CMD_REGISTER_GLOBAL_EXPEDITED\t\t\t\\\n\t| MEMBARRIER_CMD_PRIVATE_EXPEDITED\t\t\t\t\\\n\t| MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED\t\t\t\\\n\t| MEMBARRIER_PRIVATE_EXPEDITED_SYNC_CORE_BITMASK)\n\nSYSCALL_DEFINE3(membarrier, int, cmd, unsigned int, flags, int, cpu_id)\n{\n\tswitch (cmd) {\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED_RSEQ:\n\t\tif (unlikely(flags && flags != MEMBARRIER_CMD_FLAG_CPU))\n\t\t\treturn -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\tif (unlikely(flags))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!(flags & MEMBARRIER_CMD_FLAG_CPU))\n\t\tcpu_id = -1;\n\n\tswitch (cmd) {\n\tcase MEMBARRIER_CMD_QUERY:\n\t{\n\t\tint cmd_mask = MEMBARRIER_CMD_BITMASK;\n\n\t\tif (tick_nohz_full_enabled())\n\t\t\tcmd_mask &= ~MEMBARRIER_CMD_GLOBAL;\n\t\treturn cmd_mask;\n\t}\n\tcase MEMBARRIER_CMD_GLOBAL:\n\t\t/* MEMBARRIER_CMD_GLOBAL is not compatible with nohz_full. */\n\t\tif (tick_nohz_full_enabled())\n\t\t\treturn -EINVAL;\n\t\tif (num_online_cpus() > 1)\n\t\t\tsynchronize_rcu();\n\t\treturn 0;\n\tcase MEMBARRIER_CMD_GLOBAL_EXPEDITED:\n\t\treturn membarrier_global_expedited();\n\tcase MEMBARRIER_CMD_REGISTER_GLOBAL_EXPEDITED:\n\t\treturn membarrier_register_global_expedited();\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED:\n\t\treturn membarrier_private_expedited(0, cpu_id);\n\tcase MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED:\n\t\treturn membarrier_register_private_expedited(0);\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED_SYNC_CORE:\n\t\treturn membarrier_private_expedited(MEMBARRIER_FLAG_SYNC_CORE, cpu_id);\n\tcase MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_SYNC_CORE:\n\t\treturn membarrier_register_private_expedited(MEMBARRIER_FLAG_SYNC_CORE);\n\tcase MEMBARRIER_CMD_PRIVATE_EXPEDITED_RSEQ:\n\t\treturn membarrier_private_expedited(MEMBARRIER_FLAG_RSEQ, cpu_id);\n\tcase MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_RSEQ:\n\t\treturn membarrier_register_private_expedited(MEMBARRIER_FLAG_RSEQ);\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n}"
  }
]