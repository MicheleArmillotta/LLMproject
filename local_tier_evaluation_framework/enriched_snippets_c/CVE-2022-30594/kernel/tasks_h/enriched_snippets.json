[
  {
    "function_name": "rcu_tasks_bootup_oddness",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1720-1720",
    "snippet": "static inline void rcu_tasks_bootup_oddness(void) {}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic inline void rcu_tasks_bootup_oddness(void) {}"
  },
  {
    "function_name": "rcu_init_tasks_generic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1701-1717",
    "snippet": "void __init rcu_init_tasks_generic(void)\n{\n#ifdef CONFIG_TASKS_RCU\n\trcu_spawn_tasks_kthread();\n#endif\n\n#ifdef CONFIG_TASKS_RUDE_RCU\n\trcu_spawn_tasks_rude_kthread();\n#endif\n\n#ifdef CONFIG_TASKS_TRACE_RCU\n\trcu_spawn_tasks_trace_kthread();\n#endif\n\n\t// Run the self-tests.\n\trcu_tasks_initiate_self_tests();\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_tasks_initiate_self_tests",
          "args": [],
          "line": 1716
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_tasks_initiate_self_tests",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1698-1698",
          "snippet": "static void rcu_tasks_initiate_self_tests(void) { }",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_initiate_self_tests(void) { }"
        }
      },
      {
        "call_info": {
          "callee": "rcu_spawn_tasks_trace_kthread",
          "args": [],
          "line": 1712
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_tasks_trace_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1575-1596",
          "snippet": "static int __init rcu_spawn_tasks_trace_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_trace);\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB)) {\n\t\trcu_tasks_trace.gp_sleep = HZ / 10;\n\t\trcu_tasks_trace.init_fract = HZ / 10;\n\t} else {\n\t\trcu_tasks_trace.gp_sleep = HZ / 200;\n\t\tif (rcu_tasks_trace.gp_sleep <= 0)\n\t\t\trcu_tasks_trace.gp_sleep = 1;\n\t\trcu_tasks_trace.init_fract = HZ / 200;\n\t\tif (rcu_tasks_trace.init_fract <= 0)\n\t\t\trcu_tasks_trace.init_fract = 1;\n\t}\n\trcu_tasks_trace.pregp_func = rcu_tasks_trace_pregp_step;\n\trcu_tasks_trace.pertask_func = rcu_tasks_trace_pertask;\n\trcu_tasks_trace.postscan_func = rcu_tasks_trace_postscan;\n\trcu_tasks_trace.holdouts_func = check_all_holdout_tasks_trace;\n\trcu_tasks_trace.postgp_func = rcu_tasks_trace_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_trace);\n\treturn 0;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int __init rcu_spawn_tasks_trace_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_trace);\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB)) {\n\t\trcu_tasks_trace.gp_sleep = HZ / 10;\n\t\trcu_tasks_trace.init_fract = HZ / 10;\n\t} else {\n\t\trcu_tasks_trace.gp_sleep = HZ / 200;\n\t\tif (rcu_tasks_trace.gp_sleep <= 0)\n\t\t\trcu_tasks_trace.gp_sleep = 1;\n\t\trcu_tasks_trace.init_fract = HZ / 200;\n\t\tif (rcu_tasks_trace.init_fract <= 0)\n\t\t\trcu_tasks_trace.init_fract = 1;\n\t}\n\trcu_tasks_trace.pregp_func = rcu_tasks_trace_pregp_step;\n\trcu_tasks_trace.pertask_func = rcu_tasks_trace_pertask;\n\trcu_tasks_trace.postscan_func = rcu_tasks_trace_postscan;\n\trcu_tasks_trace.holdouts_func = check_all_holdout_tasks_trace;\n\trcu_tasks_trace.postgp_func = rcu_tasks_trace_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_trace);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_spawn_tasks_rude_kthread",
          "args": [],
          "line": 1708
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_tasks_rude_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1017-1023",
          "snippet": "static int __init rcu_spawn_tasks_rude_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_rude);\n\trcu_tasks_rude.gp_sleep = HZ / 10;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_rude);\n\treturn 0;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int __init rcu_spawn_tasks_rude_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_rude);\n\trcu_tasks_rude.gp_sleep = HZ / 10;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_rude);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_spawn_tasks_kthread",
          "args": [],
          "line": 1704
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_tasks_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "879-891",
          "snippet": "static int __init rcu_spawn_tasks_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks);\n\trcu_tasks.gp_sleep = HZ / 10;\n\trcu_tasks.init_fract = HZ / 10;\n\trcu_tasks.pregp_func = rcu_tasks_pregp_step;\n\trcu_tasks.pertask_func = rcu_tasks_pertask;\n\trcu_tasks.postscan_func = rcu_tasks_postscan;\n\trcu_tasks.holdouts_func = check_all_holdout_tasks;\n\trcu_tasks.postgp_func = rcu_tasks_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks);\n\treturn 0;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int __init rcu_spawn_tasks_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks);\n\trcu_tasks.gp_sleep = HZ / 10;\n\trcu_tasks.init_fract = HZ / 10;\n\trcu_tasks.pregp_func = rcu_tasks_pregp_step;\n\trcu_tasks.pertask_func = rcu_tasks_pertask;\n\trcu_tasks.postscan_func = rcu_tasks_postscan;\n\trcu_tasks.holdouts_func = check_all_holdout_tasks;\n\trcu_tasks.postgp_func = rcu_tasks_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid __init rcu_init_tasks_generic(void)\n{\n#ifdef CONFIG_TASKS_RCU\n\trcu_spawn_tasks_kthread();\n#endif\n\n#ifdef CONFIG_TASKS_RUDE_RCU\n\trcu_spawn_tasks_rude_kthread();\n#endif\n\n#ifdef CONFIG_TASKS_TRACE_RCU\n\trcu_spawn_tasks_trace_kthread();\n#endif\n\n\t// Run the self-tests.\n\trcu_tasks_initiate_self_tests();\n}"
  },
  {
    "function_name": "rcu_tasks_initiate_self_tests",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1698-1698",
    "snippet": "static void rcu_tasks_initiate_self_tests(void) { }",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_initiate_self_tests(void) { }"
  },
  {
    "function_name": "rcu_tasks_verify_self_tests",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1679-1695",
    "snippet": "static int rcu_tasks_verify_self_tests(void)\n{\n\tint ret = 0;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(tests); i++) {\n\t\tif (!tests[i].notrun) {\t\t// still hanging.\n\t\t\tpr_err(\"%s has been failed.\\n\", tests[i].name);\n\t\t\tret = -1;\n\t\t}\n\t}\n\n\tif (ret)\n\t\tWARN_ON(1);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "1"
          ],
          "line": 1692
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"%s has been failed.\\n\"",
            "tests[i].name"
          ],
          "line": 1686
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ARRAY_SIZE",
          "args": [
            "tests"
          ],
          "line": 1684
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int rcu_tasks_verify_self_tests(void)\n{\n\tint ret = 0;\n\tint i;\n\n\tfor (i = 0; i < ARRAY_SIZE(tests); i++) {\n\t\tif (!tests[i].notrun) {\t\t// still hanging.\n\t\t\tpr_err(\"%s has been failed.\\n\", tests[i].name);\n\t\t\tret = -1;\n\t\t}\n\t}\n\n\tif (ret)\n\t\tWARN_ON(1);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "rcu_tasks_initiate_self_tests",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1660-1677",
    "snippet": "static void rcu_tasks_initiate_self_tests(void)\n{\n\tpr_info(\"Running RCU-tasks wait API self tests\\n\");\n#ifdef CONFIG_TASKS_RCU\n\tsynchronize_rcu_tasks();\n\tcall_rcu_tasks(&tests[0].rh, test_rcu_tasks_callback);\n#endif\n\n#ifdef CONFIG_TASKS_RUDE_RCU\n\tsynchronize_rcu_tasks_rude();\n\tcall_rcu_tasks_rude(&tests[1].rh, test_rcu_tasks_callback);\n#endif\n\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tsynchronize_rcu_tasks_trace();\n\tcall_rcu_tasks_trace(&tests[2].rh, test_rcu_tasks_callback);\n#endif\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu_tasks_trace",
          "args": [
            "&tests[2].rh",
            "test_rcu_tasks_callback"
          ],
          "line": 1675
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1533-1536",
          "snippet": "void call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "synchronize_rcu_tasks_trace",
          "args": [],
          "line": 1674
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1556-1560",
          "snippet": "void synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "call_rcu_tasks_rude",
          "args": [
            "&tests[1].rh",
            "test_rcu_tasks_callback"
          ],
          "line": 1670
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_rude",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "975-978",
          "snippet": "void call_rcu_tasks_rude(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_rude);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks_rude(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_rude);\n}"
        }
      },
      {
        "call_info": {
          "callee": "synchronize_rcu_tasks_rude",
          "args": [],
          "line": 1669
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_rude",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "999-1002",
          "snippet": "void synchronize_rcu_tasks_rude(void)\n{\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_rude);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_rude(void)\n{\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_rude);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Running RCU-tasks wait API self tests\\n\""
          ],
          "line": 1662
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_initiate_self_tests(void)\n{\n\tpr_info(\"Running RCU-tasks wait API self tests\\n\");\n#ifdef CONFIG_TASKS_RCU\n\tsynchronize_rcu_tasks();\n\tcall_rcu_tasks(&tests[0].rh, test_rcu_tasks_callback);\n#endif\n\n#ifdef CONFIG_TASKS_RUDE_RCU\n\tsynchronize_rcu_tasks_rude();\n\tcall_rcu_tasks_rude(&tests[1].rh, test_rcu_tasks_callback);\n#endif\n\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tsynchronize_rcu_tasks_trace();\n\tcall_rcu_tasks_trace(&tests[2].rh, test_rcu_tasks_callback);\n#endif\n}"
  },
  {
    "function_name": "test_rcu_tasks_callback",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1650-1658",
    "snippet": "static void test_rcu_tasks_callback(struct rcu_head *rhp)\n{\n\tstruct rcu_tasks_test_desc *rttd =\n\t\tcontainer_of(rhp, struct rcu_tasks_test_desc, rh);\n\n\tpr_info(\"Callback from %s invoked.\\n\", rttd->name);\n\n\trttd->notrun = true;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Callback from %s invoked.\\n\"",
            "rttd->name"
          ],
          "line": 1655
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rhp",
            "structrcu_tasks_test_desc",
            "rh"
          ],
          "line": 1653
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void test_rcu_tasks_callback(struct rcu_head *rhp)\n{\n\tstruct rcu_tasks_test_desc *rttd =\n\t\tcontainer_of(rhp, struct rcu_tasks_test_desc, rh);\n\n\tpr_info(\"Callback from %s invoked.\\n\", rttd->name);\n\n\trttd->notrun = true;\n}"
  },
  {
    "function_name": "show_rcu_tasks_gp_kthreads",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1617-1622",
    "snippet": "void show_rcu_tasks_gp_kthreads(void)\n{\n\tshow_rcu_tasks_classic_gp_kthread();\n\tshow_rcu_tasks_rude_gp_kthread();\n\tshow_rcu_tasks_trace_gp_kthread();\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "show_rcu_tasks_trace_gp_kthread",
          "args": [],
          "line": 1621
        },
        "resolved": true,
        "details": {
          "function_name": "show_rcu_tasks_trace_gp_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1599-1608",
          "snippet": "void show_rcu_tasks_trace_gp_kthread(void)\n{\n\tchar buf[64];\n\n\tsprintf(buf, \"N%d h:%lu/%lu/%lu\", atomic_read(&trc_n_readers_need_end),\n\t\tdata_race(n_heavy_reader_ofl_updates),\n\t\tdata_race(n_heavy_reader_updates),\n\t\tdata_race(n_heavy_reader_attempts));\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_trace, buf);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_trace_gp_kthread(void)\n{\n\tchar buf[64];\n\n\tsprintf(buf, \"N%d h:%lu/%lu/%lu\", atomic_read(&trc_n_readers_need_end),\n\t\tdata_race(n_heavy_reader_ofl_updates),\n\t\tdata_race(n_heavy_reader_updates),\n\t\tdata_race(n_heavy_reader_attempts));\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_trace, buf);\n}"
        }
      },
      {
        "call_info": {
          "callee": "show_rcu_tasks_rude_gp_kthread",
          "args": [],
          "line": 1620
        },
        "resolved": true,
        "details": {
          "function_name": "show_rcu_tasks_rude_gp_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1026-1029",
          "snippet": "void show_rcu_tasks_rude_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_rude, \"\");\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_rude_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_rude, \"\");\n}"
        }
      },
      {
        "call_info": {
          "callee": "show_rcu_tasks_classic_gp_kthread",
          "args": [],
          "line": 1619
        },
        "resolved": true,
        "details": {
          "function_name": "show_rcu_tasks_classic_gp_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "894-897",
          "snippet": "void show_rcu_tasks_classic_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks, \"\");\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_classic_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks, \"\");\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_gp_kthreads(void)\n{\n\tshow_rcu_tasks_classic_gp_kthread();\n\tshow_rcu_tasks_rude_gp_kthread();\n\tshow_rcu_tasks_trace_gp_kthread();\n}"
  },
  {
    "function_name": "exit_tasks_rcu_finish_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1613-1613",
    "snippet": "static void exit_tasks_rcu_finish_trace(struct task_struct *t) { }",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void exit_tasks_rcu_finish_trace(struct task_struct *t) { }"
  },
  {
    "function_name": "show_rcu_tasks_trace_gp_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1599-1608",
    "snippet": "void show_rcu_tasks_trace_gp_kthread(void)\n{\n\tchar buf[64];\n\n\tsprintf(buf, \"N%d h:%lu/%lu/%lu\", atomic_read(&trc_n_readers_need_end),\n\t\tdata_race(n_heavy_reader_ofl_updates),\n\t\tdata_race(n_heavy_reader_updates),\n\t\tdata_race(n_heavy_reader_attempts));\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_trace, buf);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "show_rcu_tasks_generic_gp_kthread",
          "args": [
            "&rcu_tasks_trace",
            "buf"
          ],
          "line": 1607
        },
        "resolved": true,
        "details": {
          "function_name": "show_rcu_tasks_generic_gp_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "565-577",
          "snippet": "static void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sprintf",
          "args": [
            "buf",
            "\"N%d h:%lu/%lu/%lu\"",
            "atomic_read(&trc_n_readers_need_end)",
            "data_race(n_heavy_reader_ofl_updates)",
            "data_race(n_heavy_reader_updates)",
            "data_race(n_heavy_reader_attempts)"
          ],
          "line": 1603
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_race",
          "args": [
            "n_heavy_reader_attempts"
          ],
          "line": 1606
        },
        "resolved": true,
        "details": {
          "function_name": "test_data_race",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/kcsan_test.c",
          "lines": "998-1008",
          "snippet": "__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}",
          "includes": [
            "#include <trace/events/printk.h>",
            "#include <linux/types.h>",
            "#include <linux/tracepoint.h>",
            "#include <linux/torture.h>",
            "#include <linux/timer.h>",
            "#include <linux/string.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kcsan-checks.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <kunit/test.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline const struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/printk.h>\n#include <linux/types.h>\n#include <linux/tracepoint.h>\n#include <linux/torture.h>\n#include <linux/timer.h>\n#include <linux/string.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n#include <linux/kernel.h>\n#include <linux/kcsan-checks.h>\n#include <linux/jiffies.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <kunit/test.h>\n\nstatic __always_inline const struct;\n\n__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1603
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_trace_gp_kthread(void)\n{\n\tchar buf[64];\n\n\tsprintf(buf, \"N%d h:%lu/%lu/%lu\", atomic_read(&trc_n_readers_need_end),\n\t\tdata_race(n_heavy_reader_ofl_updates),\n\t\tdata_race(n_heavy_reader_updates),\n\t\tdata_race(n_heavy_reader_attempts));\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_trace, buf);\n}"
  },
  {
    "function_name": "rcu_spawn_tasks_trace_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1575-1596",
    "snippet": "static int __init rcu_spawn_tasks_trace_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_trace);\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB)) {\n\t\trcu_tasks_trace.gp_sleep = HZ / 10;\n\t\trcu_tasks_trace.init_fract = HZ / 10;\n\t} else {\n\t\trcu_tasks_trace.gp_sleep = HZ / 200;\n\t\tif (rcu_tasks_trace.gp_sleep <= 0)\n\t\t\trcu_tasks_trace.gp_sleep = 1;\n\t\trcu_tasks_trace.init_fract = HZ / 200;\n\t\tif (rcu_tasks_trace.init_fract <= 0)\n\t\t\trcu_tasks_trace.init_fract = 1;\n\t}\n\trcu_tasks_trace.pregp_func = rcu_tasks_trace_pregp_step;\n\trcu_tasks_trace.pertask_func = rcu_tasks_trace_pertask;\n\trcu_tasks_trace.postscan_func = rcu_tasks_trace_postscan;\n\trcu_tasks_trace.holdouts_func = check_all_holdout_tasks_trace;\n\trcu_tasks_trace.postgp_func = rcu_tasks_trace_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_trace);\n\treturn 0;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_spawn_tasks_kthread_generic",
          "args": [
            "&rcu_tasks_trace"
          ],
          "line": 1594
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_tasks_kthread_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "529-537",
          "snippet": "static void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_TASKS_TRACE_RCU_READ_MB"
          ],
          "line": 1578
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cblist_init_generic",
          "args": [
            "&rcu_tasks_trace"
          ],
          "line": 1577
        },
        "resolved": true,
        "details": {
          "function_name": "cblist_init_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "214-251",
          "snippet": "static void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int __init rcu_spawn_tasks_trace_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_trace);\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB)) {\n\t\trcu_tasks_trace.gp_sleep = HZ / 10;\n\t\trcu_tasks_trace.init_fract = HZ / 10;\n\t} else {\n\t\trcu_tasks_trace.gp_sleep = HZ / 200;\n\t\tif (rcu_tasks_trace.gp_sleep <= 0)\n\t\t\trcu_tasks_trace.gp_sleep = 1;\n\t\trcu_tasks_trace.init_fract = HZ / 200;\n\t\tif (rcu_tasks_trace.init_fract <= 0)\n\t\t\trcu_tasks_trace.init_fract = 1;\n\t}\n\trcu_tasks_trace.pregp_func = rcu_tasks_trace_pregp_step;\n\trcu_tasks_trace.pertask_func = rcu_tasks_trace_pertask;\n\trcu_tasks_trace.postscan_func = rcu_tasks_trace_postscan;\n\trcu_tasks_trace.holdouts_func = check_all_holdout_tasks_trace;\n\trcu_tasks_trace.postgp_func = rcu_tasks_trace_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_trace);\n\treturn 0;\n}"
  },
  {
    "function_name": "rcu_barrier_tasks_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1569-1572",
    "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_barrier_tasks_generic",
          "args": [
            "&rcu_tasks_trace"
          ],
          "line": 1571
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "339-370",
          "snippet": "static void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
  },
  {
    "function_name": "synchronize_rcu_tasks_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1556-1560",
    "snippet": "void synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_rcu_tasks_generic",
          "args": [
            "&rcu_tasks_trace"
          ],
          "line": 1559
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "315-323",
          "snippet": "static void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}"
        }
      },
      {
        "call_info": {
          "callee": "RCU_LOCKDEP_WARN",
          "args": [
            "lock_is_held(&rcu_trace_lock_map)",
            "\"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\""
          ],
          "line": 1558
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lock_is_held",
          "args": [
            "&rcu_trace_lock_map"
          ],
          "line": 1558
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}"
  },
  {
    "function_name": "call_rcu_tasks_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1533-1536",
    "snippet": "void call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu_tasks_generic",
          "args": [
            "rhp",
            "func",
            "&rcu_tasks_trace"
          ],
          "line": 1535
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "264-312",
          "snippet": "static void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}"
  },
  {
    "function_name": "exit_tasks_rcu_finish_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1510-1517",
    "snippet": "static void exit_tasks_rcu_finish_trace(struct task_struct *t)\n{\n\tWRITE_ONCE(t->trc_reader_checked, true);\n\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\tWRITE_ONCE(t->trc_reader_nesting, 0);\n\tif (WARN_ON_ONCE(READ_ONCE(t->trc_reader_special.b.need_qs)))\n\t\trcu_read_unlock_trace_special(t);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock_trace_special",
          "args": [
            "t"
          ],
          "line": 1516
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_trace_special",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1136-1149",
          "snippet": "void rcu_read_unlock_trace_special(struct task_struct *t)\n{\n\tint nq = READ_ONCE(t->trc_reader_special.b.need_qs);\n\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB) &&\n\t    t->trc_reader_special.b.need_mb)\n\t\tsmp_mb(); // Pairs with update-side barriers.\n\t// Update .need_qs before ->trc_reader_nesting for irq/NMI handlers.\n\tif (nq)\n\t\tWRITE_ONCE(t->trc_reader_special.b.need_qs, false);\n\tWRITE_ONCE(t->trc_reader_nesting, 0);\n\tif (nq && atomic_dec_and_test(&trc_n_readers_need_end))\n\t\tirq_work_queue(&rcu_tasks_trace_iw);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_read_unlock_trace_special(struct task_struct *t)\n{\n\tint nq = READ_ONCE(t->trc_reader_special.b.need_qs);\n\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB) &&\n\t    t->trc_reader_special.b.need_mb)\n\t\tsmp_mb(); // Pairs with update-side barriers.\n\t// Update .need_qs before ->trc_reader_nesting for irq/NMI handlers.\n\tif (nq)\n\t\tWRITE_ONCE(t->trc_reader_special.b.need_qs, false);\n\tWRITE_ONCE(t->trc_reader_nesting, 0);\n\tif (nq && atomic_dec_and_test(&trc_n_readers_need_end))\n\t\tirq_work_queue(&rcu_tasks_trace_iw);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "READ_ONCE(t->trc_reader_special.b.need_qs)"
          ],
          "line": 1515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_nesting",
            "0"
          ],
          "line": 1514
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "READ_ONCE(t->trc_reader_nesting)"
          ],
          "line": 1513
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_nesting"
          ],
          "line": 1513
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_checked",
            "true"
          ],
          "line": 1512
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void exit_tasks_rcu_finish_trace(struct task_struct *t)\n{\n\tWRITE_ONCE(t->trc_reader_checked, true);\n\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\tWRITE_ONCE(t->trc_reader_nesting, 0);\n\tif (WARN_ON_ONCE(READ_ONCE(t->trc_reader_special.b.need_qs)))\n\t\trcu_read_unlock_trace_special(t);\n}"
  },
  {
    "function_name": "rcu_tasks_trace_postgp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1457-1507",
    "snippet": "static void rcu_tasks_trace_postgp(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tbool firstreport;\n\tstruct task_struct *g, *t;\n\tLIST_HEAD(holdouts);\n\tlong ret;\n\n\t// Wait for any lingering IPI handlers to complete.  Note that\n\t// if a CPU has gone offline or transitioned to userspace in the\n\t// meantime, all IPI handlers should have been drained beforehand.\n\t// Yes, this assumes that CPUs process IPIs in order.  If that ever\n\t// changes, there will need to be a recheck and/or timed wait.\n\tfor_each_online_cpu(cpu)\n\t\tif (WARN_ON_ONCE(smp_load_acquire(per_cpu_ptr(&trc_ipi_to_cpu, cpu))))\n\t\t\tsmp_call_function_single(cpu, rcu_tasks_trace_empty_fn, NULL, 1);\n\n\t// Remove the safety count.\n\tsmp_mb__before_atomic();  // Order vs. earlier atomics\n\tatomic_dec(&trc_n_readers_need_end);\n\tsmp_mb__after_atomic();  // Order vs. later atomics\n\n\t// Wait for readers.\n\tset_tasks_gp_state(rtp, RTGS_WAIT_READERS);\n\tfor (;;) {\n\t\tret = wait_event_idle_exclusive_timeout(\n\t\t\t\ttrc_wait,\n\t\t\t\tatomic_read(&trc_n_readers_need_end) == 0,\n\t\t\t\tREAD_ONCE(rcu_task_stall_timeout));\n\t\tif (ret)\n\t\t\tbreak;  // Count reached zero.\n\t\t// Stall warning time, so make a list of the offenders.\n\t\trcu_read_lock();\n\t\tfor_each_process_thread(g, t)\n\t\t\tif (READ_ONCE(t->trc_reader_special.b.need_qs))\n\t\t\t\ttrc_add_holdout(t, &holdouts);\n\t\trcu_read_unlock();\n\t\tfirstreport = true;\n\t\tlist_for_each_entry_safe(t, g, &holdouts, trc_holdout_list) {\n\t\t\tif (READ_ONCE(t->trc_reader_special.b.need_qs))\n\t\t\t\tshow_stalled_task_trace(t, &firstreport);\n\t\t\ttrc_del_holdout(t); // Release task_struct reference.\n\t\t}\n\t\tif (firstreport)\n\t\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls? (Counter/taskslist mismatch?)\\n\");\n\t\tshow_stalled_ipi_trace();\n\t\tpr_err(\"\\t%d holdouts\\n\", atomic_read(&trc_n_readers_need_end));\n\t}\n\tsmp_mb(); // Caller's code must be ordered after wakeup.\n\t\t  // Pairs with pretty much every ordering primitive.\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [
      "#define RTGS_WAIT_READERS\t 9"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 1505
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"\\t%d holdouts\\n\"",
            "atomic_read(&trc_n_readers_need_end)"
          ],
          "line": 1503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "show_stalled_ipi_trace",
          "args": [],
          "line": 1502
        },
        "resolved": true,
        "details": {
          "function_name": "show_stalled_ipi_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1410-1417",
          "snippet": "static void show_stalled_ipi_trace(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu))\n\t\t\tpr_alert(\"\\tIPI outstanding to CPU %d\\n\", cpu);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_stalled_ipi_trace(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu))\n\t\t\tpr_alert(\"\\tIPI outstanding to CPU %d\\n\", cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"INFO: rcu_tasks_trace detected stalls? (Counter/taskslist mismatch?)\\n\""
          ],
          "line": 1501
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trc_del_holdout",
          "args": [
            "t"
          ],
          "line": 1498
        },
        "resolved": true,
        "details": {
          "function_name": "trc_del_holdout",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1162-1168",
          "snippet": "static void trc_del_holdout(struct task_struct *t)\n{\n\tif (!list_empty(&t->trc_holdout_list)) {\n\t\tlist_del_init(&t->trc_holdout_list);\n\t\tput_task_struct(t);\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_del_holdout(struct task_struct *t)\n{\n\tif (!list_empty(&t->trc_holdout_list)) {\n\t\tlist_del_init(&t->trc_holdout_list);\n\t\tput_task_struct(t);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "show_stalled_task_trace",
          "args": [
            "t",
            "&firstreport"
          ],
          "line": 1497
        },
        "resolved": true,
        "details": {
          "function_name": "show_stalled_task_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1382-1407",
          "snippet": "static void show_stalled_task_trace(struct task_struct *t, bool *firstreport)\n{\n\tint cpu;\n\tstruct trc_stall_chk_rdr trc_rdr;\n\tbool is_idle_tsk = is_idle_task(t);\n\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tif (!task_call_func(t, trc_check_slow_task, &trc_rdr))\n\t\tpr_alert(\"P%d: %c\\n\",\n\t\t\t t->pid,\n\t\t\t \".i\"[is_idle_tsk]);\n\telse\n\t\tpr_alert(\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\",\n\t\t\t t->pid,\n\t\t\t \".I\"[trc_rdr.ipi_to_cpu >= 0],\n\t\t\t \".i\"[is_idle_tsk],\n\t\t\t \".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)],\n\t\t\t trc_rdr.nesting,\n\t\t\t \" N\"[!!trc_rdr.needqs],\n\t\t\t cpu);\n\tsched_show_task(t);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_stalled_task_trace(struct task_struct *t, bool *firstreport)\n{\n\tint cpu;\n\tstruct trc_stall_chk_rdr trc_rdr;\n\tbool is_idle_tsk = is_idle_task(t);\n\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tif (!task_call_func(t, trc_check_slow_task, &trc_rdr))\n\t\tpr_alert(\"P%d: %c\\n\",\n\t\t\t t->pid,\n\t\t\t \".i\"[is_idle_tsk]);\n\telse\n\t\tpr_alert(\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\",\n\t\t\t t->pid,\n\t\t\t \".I\"[trc_rdr.ipi_to_cpu >= 0],\n\t\t\t \".i\"[is_idle_tsk],\n\t\t\t \".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)],\n\t\t\t trc_rdr.nesting,\n\t\t\t \" N\"[!!trc_rdr.needqs],\n\t\t\t cpu);\n\tsched_show_task(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1496
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "t",
            "g",
            "&holdouts",
            "trc_holdout_list"
          ],
          "line": 1495
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 1493
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trc_add_holdout",
          "args": [
            "t",
            "&holdouts"
          ],
          "line": 1492
        },
        "resolved": true,
        "details": {
          "function_name": "trc_add_holdout",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1153-1159",
          "snippet": "static void trc_add_holdout(struct task_struct *t, struct list_head *bhp)\n{\n\tif (list_empty(&t->trc_holdout_list)) {\n\t\tget_task_struct(t);\n\t\tlist_add(&t->trc_holdout_list, bhp);\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_add_holdout(struct task_struct *t, struct list_head *bhp)\n{\n\tif (list_empty(&t->trc_holdout_list)) {\n\t\tget_task_struct(t);\n\t\tlist_add(&t->trc_holdout_list, bhp);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1491
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_process_thread",
          "args": [
            "g",
            "t"
          ],
          "line": 1490
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 1489
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "wait_event_idle_exclusive_timeout",
          "args": [
            "trc_wait",
            "atomic_read(&trc_n_readers_need_end) == 0",
            "READ_ONCE(rcu_task_stall_timeout)"
          ],
          "line": 1482
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rcu_task_stall_timeout"
          ],
          "line": 1485
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1484
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_tasks_gp_state",
          "args": [
            "rtp",
            "RTGS_WAIT_READERS"
          ],
          "line": 1480
        },
        "resolved": true,
        "details": {
          "function_name": "set_tasks_gp_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "193-197",
          "snippet": "static void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_mb__after_atomic",
          "args": [],
          "line": 1477
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_dec",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1476
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_call_function_single",
          "args": [
            "cpu",
            "rcu_tasks_trace_empty_fn",
            "NULL",
            "1"
          ],
          "line": 1472
        },
        "resolved": true,
        "details": {
          "function_name": "smp_call_function_single",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
          "lines": "12-25",
          "snippet": "int smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/hypervisor.h>",
            "#include <linux/smp.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "LIST_HEAD",
          "args": [
            "holdouts"
          ],
          "line": 1462
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\n#define RTGS_WAIT_READERS\t 9\n\nstatic void rcu_tasks_trace_postgp(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tbool firstreport;\n\tstruct task_struct *g, *t;\n\tLIST_HEAD(holdouts);\n\tlong ret;\n\n\t// Wait for any lingering IPI handlers to complete.  Note that\n\t// if a CPU has gone offline or transitioned to userspace in the\n\t// meantime, all IPI handlers should have been drained beforehand.\n\t// Yes, this assumes that CPUs process IPIs in order.  If that ever\n\t// changes, there will need to be a recheck and/or timed wait.\n\tfor_each_online_cpu(cpu)\n\t\tif (WARN_ON_ONCE(smp_load_acquire(per_cpu_ptr(&trc_ipi_to_cpu, cpu))))\n\t\t\tsmp_call_function_single(cpu, rcu_tasks_trace_empty_fn, NULL, 1);\n\n\t// Remove the safety count.\n\tsmp_mb__before_atomic();  // Order vs. earlier atomics\n\tatomic_dec(&trc_n_readers_need_end);\n\tsmp_mb__after_atomic();  // Order vs. later atomics\n\n\t// Wait for readers.\n\tset_tasks_gp_state(rtp, RTGS_WAIT_READERS);\n\tfor (;;) {\n\t\tret = wait_event_idle_exclusive_timeout(\n\t\t\t\ttrc_wait,\n\t\t\t\tatomic_read(&trc_n_readers_need_end) == 0,\n\t\t\t\tREAD_ONCE(rcu_task_stall_timeout));\n\t\tif (ret)\n\t\t\tbreak;  // Count reached zero.\n\t\t// Stall warning time, so make a list of the offenders.\n\t\trcu_read_lock();\n\t\tfor_each_process_thread(g, t)\n\t\t\tif (READ_ONCE(t->trc_reader_special.b.need_qs))\n\t\t\t\ttrc_add_holdout(t, &holdouts);\n\t\trcu_read_unlock();\n\t\tfirstreport = true;\n\t\tlist_for_each_entry_safe(t, g, &holdouts, trc_holdout_list) {\n\t\t\tif (READ_ONCE(t->trc_reader_special.b.need_qs))\n\t\t\t\tshow_stalled_task_trace(t, &firstreport);\n\t\t\ttrc_del_holdout(t); // Release task_struct reference.\n\t\t}\n\t\tif (firstreport)\n\t\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls? (Counter/taskslist mismatch?)\\n\");\n\t\tshow_stalled_ipi_trace();\n\t\tpr_err(\"\\t%d holdouts\\n\", atomic_read(&trc_n_readers_need_end));\n\t}\n\tsmp_mb(); // Caller's code must be ordered after wakeup.\n\t\t  // Pairs with pretty much every ordering primitive.\n}"
  },
  {
    "function_name": "rcu_tasks_trace_empty_fn",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1452-1454",
    "snippet": "static void rcu_tasks_trace_empty_fn(void *unused)\n{\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_trace_empty_fn(void *unused)\n{\n}"
  },
  {
    "function_name": "check_all_holdout_tasks_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1420-1450",
    "snippet": "static void check_all_holdout_tasks_trace(struct list_head *hop,\n\t\t\t\t\t  bool needreport, bool *firstreport)\n{\n\tstruct task_struct *g, *t;\n\n\t// Disable CPU hotplug across the holdout list scan.\n\tcpus_read_lock();\n\n\tlist_for_each_entry_safe(t, g, hop, trc_holdout_list) {\n\t\t// If safe and needed, try to check the current task.\n\t\tif (READ_ONCE(t->trc_ipi_to_cpu) == -1 &&\n\t\t    !READ_ONCE(t->trc_reader_checked))\n\t\t\ttrc_wait_for_one_reader(t, hop);\n\n\t\t// If check succeeded, remove this task from the list.\n\t\tif (smp_load_acquire(&t->trc_ipi_to_cpu) == -1 &&\n\t\t    READ_ONCE(t->trc_reader_checked))\n\t\t\ttrc_del_holdout(t);\n\t\telse if (needreport)\n\t\t\tshow_stalled_task_trace(t, firstreport);\n\t}\n\n\t// Re-enable CPU hotplug now that the holdout list scan has completed.\n\tcpus_read_unlock();\n\n\tif (needreport) {\n\t\tif (*firstreport)\n\t\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls? (Late IPI?)\\n\");\n\t\tshow_stalled_ipi_trace();\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "show_stalled_ipi_trace",
          "args": [],
          "line": 1448
        },
        "resolved": true,
        "details": {
          "function_name": "show_stalled_ipi_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1410-1417",
          "snippet": "static void show_stalled_ipi_trace(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu))\n\t\t\tpr_alert(\"\\tIPI outstanding to CPU %d\\n\", cpu);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_stalled_ipi_trace(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu))\n\t\t\tpr_alert(\"\\tIPI outstanding to CPU %d\\n\", cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"INFO: rcu_tasks_trace detected stalls? (Late IPI?)\\n\""
          ],
          "line": 1447
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 1443
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "show_stalled_task_trace",
          "args": [
            "t",
            "firstreport"
          ],
          "line": 1439
        },
        "resolved": true,
        "details": {
          "function_name": "show_stalled_task_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1382-1407",
          "snippet": "static void show_stalled_task_trace(struct task_struct *t, bool *firstreport)\n{\n\tint cpu;\n\tstruct trc_stall_chk_rdr trc_rdr;\n\tbool is_idle_tsk = is_idle_task(t);\n\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tif (!task_call_func(t, trc_check_slow_task, &trc_rdr))\n\t\tpr_alert(\"P%d: %c\\n\",\n\t\t\t t->pid,\n\t\t\t \".i\"[is_idle_tsk]);\n\telse\n\t\tpr_alert(\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\",\n\t\t\t t->pid,\n\t\t\t \".I\"[trc_rdr.ipi_to_cpu >= 0],\n\t\t\t \".i\"[is_idle_tsk],\n\t\t\t \".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)],\n\t\t\t trc_rdr.nesting,\n\t\t\t \" N\"[!!trc_rdr.needqs],\n\t\t\t cpu);\n\tsched_show_task(t);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_stalled_task_trace(struct task_struct *t, bool *firstreport)\n{\n\tint cpu;\n\tstruct trc_stall_chk_rdr trc_rdr;\n\tbool is_idle_tsk = is_idle_task(t);\n\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tif (!task_call_func(t, trc_check_slow_task, &trc_rdr))\n\t\tpr_alert(\"P%d: %c\\n\",\n\t\t\t t->pid,\n\t\t\t \".i\"[is_idle_tsk]);\n\telse\n\t\tpr_alert(\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\",\n\t\t\t t->pid,\n\t\t\t \".I\"[trc_rdr.ipi_to_cpu >= 0],\n\t\t\t \".i\"[is_idle_tsk],\n\t\t\t \".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)],\n\t\t\t trc_rdr.nesting,\n\t\t\t \" N\"[!!trc_rdr.needqs],\n\t\t\t cpu);\n\tsched_show_task(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trc_del_holdout",
          "args": [
            "t"
          ],
          "line": 1437
        },
        "resolved": true,
        "details": {
          "function_name": "trc_del_holdout",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1162-1168",
          "snippet": "static void trc_del_holdout(struct task_struct *t)\n{\n\tif (!list_empty(&t->trc_holdout_list)) {\n\t\tlist_del_init(&t->trc_holdout_list);\n\t\tput_task_struct(t);\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_del_holdout(struct task_struct *t)\n{\n\tif (!list_empty(&t->trc_holdout_list)) {\n\t\tlist_del_init(&t->trc_holdout_list);\n\t\tput_task_struct(t);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_checked"
          ],
          "line": 1436
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&t->trc_ipi_to_cpu"
          ],
          "line": 1435
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trc_wait_for_one_reader",
          "args": [
            "t",
            "hop"
          ],
          "line": 1432
        },
        "resolved": true,
        "details": {
          "function_name": "trc_wait_for_one_reader",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1254-1308",
          "snippet": "static void trc_wait_for_one_reader(struct task_struct *t,\n\t\t\t\t    struct list_head *bhp)\n{\n\tint cpu;\n\n\t// If a previous IPI is still in flight, let it complete.\n\tif (smp_load_acquire(&t->trc_ipi_to_cpu) != -1) // Order IPI\n\t\treturn;\n\n\t// The current task had better be in a quiescent state.\n\tif (t == current) {\n\t\tt->trc_reader_checked = true;\n\t\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\t\treturn;\n\t}\n\n\t// Attempt to nail down the task for inspection.\n\tget_task_struct(t);\n\tif (!task_call_func(t, trc_inspect_reader, NULL)) {\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\tput_task_struct(t);\n\n\t// If this task is not yet on the holdout list, then we are in\n\t// an RCU read-side critical section.  Otherwise, the invocation of\n\t// trc_add_holdout() that added it to the list did the necessary\n\t// get_task_struct().  Either way, the task cannot be freed out\n\t// from under this code.\n\n\t// If currently running, send an IPI, either way, add to list.\n\ttrc_add_holdout(t, bhp);\n\tif (task_curr(t) &&\n\t    time_after(jiffies + 1, rcu_tasks_trace.gp_start + rcu_task_ipi_delay)) {\n\t\t// The task is currently running, so try IPIing it.\n\t\tcpu = task_cpu(t);\n\n\t\t// If there is already an IPI outstanding, let it happen.\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu) || t->trc_ipi_to_cpu >= 0)\n\t\t\treturn;\n\n\t\tper_cpu(trc_ipi_to_cpu, cpu) = true;\n\t\tt->trc_ipi_to_cpu = cpu;\n\t\trcu_tasks_trace.n_ipis++;\n\t\tif (smp_call_function_single(cpu, trc_read_check_handler, t, 0)) {\n\t\t\t// Just in case there is some other reason for\n\t\t\t// failure than the target CPU being offline.\n\t\t\tWARN_ONCE(1, \"%s():  smp_call_function_single() failed for CPU: %d\\n\",\n\t\t\t\t  __func__, cpu);\n\t\t\trcu_tasks_trace.n_ipis_fails++;\n\t\t\tper_cpu(trc_ipi_to_cpu, cpu) = false;\n\t\t\tt->trc_ipi_to_cpu = -1;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_wait_for_one_reader(struct task_struct *t,\n\t\t\t\t    struct list_head *bhp)\n{\n\tint cpu;\n\n\t// If a previous IPI is still in flight, let it complete.\n\tif (smp_load_acquire(&t->trc_ipi_to_cpu) != -1) // Order IPI\n\t\treturn;\n\n\t// The current task had better be in a quiescent state.\n\tif (t == current) {\n\t\tt->trc_reader_checked = true;\n\t\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\t\treturn;\n\t}\n\n\t// Attempt to nail down the task for inspection.\n\tget_task_struct(t);\n\tif (!task_call_func(t, trc_inspect_reader, NULL)) {\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\tput_task_struct(t);\n\n\t// If this task is not yet on the holdout list, then we are in\n\t// an RCU read-side critical section.  Otherwise, the invocation of\n\t// trc_add_holdout() that added it to the list did the necessary\n\t// get_task_struct().  Either way, the task cannot be freed out\n\t// from under this code.\n\n\t// If currently running, send an IPI, either way, add to list.\n\ttrc_add_holdout(t, bhp);\n\tif (task_curr(t) &&\n\t    time_after(jiffies + 1, rcu_tasks_trace.gp_start + rcu_task_ipi_delay)) {\n\t\t// The task is currently running, so try IPIing it.\n\t\tcpu = task_cpu(t);\n\n\t\t// If there is already an IPI outstanding, let it happen.\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu) || t->trc_ipi_to_cpu >= 0)\n\t\t\treturn;\n\n\t\tper_cpu(trc_ipi_to_cpu, cpu) = true;\n\t\tt->trc_ipi_to_cpu = cpu;\n\t\trcu_tasks_trace.n_ipis++;\n\t\tif (smp_call_function_single(cpu, trc_read_check_handler, t, 0)) {\n\t\t\t// Just in case there is some other reason for\n\t\t\t// failure than the target CPU being offline.\n\t\t\tWARN_ONCE(1, \"%s():  smp_call_function_single() failed for CPU: %d\\n\",\n\t\t\t\t  __func__, cpu);\n\t\t\trcu_tasks_trace.n_ipis_fails++;\n\t\t\tper_cpu(trc_ipi_to_cpu, cpu) = false;\n\t\t\tt->trc_ipi_to_cpu = -1;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_checked"
          ],
          "line": 1431
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_ipi_to_cpu"
          ],
          "line": 1430
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "t",
            "g",
            "hop",
            "trc_holdout_list"
          ],
          "line": 1428
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 1426
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void check_all_holdout_tasks_trace(struct list_head *hop,\n\t\t\t\t\t  bool needreport, bool *firstreport)\n{\n\tstruct task_struct *g, *t;\n\n\t// Disable CPU hotplug across the holdout list scan.\n\tcpus_read_lock();\n\n\tlist_for_each_entry_safe(t, g, hop, trc_holdout_list) {\n\t\t// If safe and needed, try to check the current task.\n\t\tif (READ_ONCE(t->trc_ipi_to_cpu) == -1 &&\n\t\t    !READ_ONCE(t->trc_reader_checked))\n\t\t\ttrc_wait_for_one_reader(t, hop);\n\n\t\t// If check succeeded, remove this task from the list.\n\t\tif (smp_load_acquire(&t->trc_ipi_to_cpu) == -1 &&\n\t\t    READ_ONCE(t->trc_reader_checked))\n\t\t\ttrc_del_holdout(t);\n\t\telse if (needreport)\n\t\t\tshow_stalled_task_trace(t, firstreport);\n\t}\n\n\t// Re-enable CPU hotplug now that the holdout list scan has completed.\n\tcpus_read_unlock();\n\n\tif (needreport) {\n\t\tif (*firstreport)\n\t\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls? (Late IPI?)\\n\");\n\t\tshow_stalled_ipi_trace();\n\t}\n}"
  },
  {
    "function_name": "show_stalled_ipi_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1410-1417",
    "snippet": "static void show_stalled_ipi_trace(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu))\n\t\t\tpr_alert(\"\\tIPI outstanding to CPU %d\\n\", cpu);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_stalled_ipi_trace(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu))\n\t\t\tpr_alert(\"\\tIPI outstanding to CPU %d\\n\", cpu);\n}"
  },
  {
    "function_name": "show_stalled_task_trace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1382-1407",
    "snippet": "static void show_stalled_task_trace(struct task_struct *t, bool *firstreport)\n{\n\tint cpu;\n\tstruct trc_stall_chk_rdr trc_rdr;\n\tbool is_idle_tsk = is_idle_task(t);\n\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tif (!task_call_func(t, trc_check_slow_task, &trc_rdr))\n\t\tpr_alert(\"P%d: %c\\n\",\n\t\t\t t->pid,\n\t\t\t \".i\"[is_idle_tsk]);\n\telse\n\t\tpr_alert(\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\",\n\t\t\t t->pid,\n\t\t\t \".I\"[trc_rdr.ipi_to_cpu >= 0],\n\t\t\t \".i\"[is_idle_tsk],\n\t\t\t \".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)],\n\t\t\t trc_rdr.nesting,\n\t\t\t \" N\"[!!trc_rdr.needqs],\n\t\t\t cpu);\n\tsched_show_task(t);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_show_task",
          "args": [
            "t"
          ],
          "line": 1406
        },
        "resolved": true,
        "details": {
          "function_name": "sched_show_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8544-8572",
          "snippet": "void sched_show_task(struct task_struct *p)\n{\n\tunsigned long free = 0;\n\tint ppid;\n\n\tif (!try_get_task_stack(p))\n\t\treturn;\n\n\tpr_info(\"task:%-15.15s state:%c\", p->comm, task_state_to_char(p));\n\n\tif (task_is_running(p))\n\t\tpr_cont(\"  running task    \");\n#ifdef CONFIG_DEBUG_STACK_USAGE\n\tfree = stack_not_used(p);\n#endif\n\tppid = 0;\n\trcu_read_lock();\n\tif (pid_alive(p))\n\t\tppid = task_pid_nr(rcu_dereference(p->real_parent));\n\trcu_read_unlock();\n\tpr_cont(\" stack:%5lu pid:%5d ppid:%6d flags:0x%08lx\\n\",\n\t\tfree, task_pid_nr(p), ppid,\n\t\tread_task_thread_flags(p));\n\n\tprint_worker_info(KERN_INFO, p);\n\tprint_stop_info(KERN_INFO, p);\n\tshow_stack(p, NULL, KERN_INFO);\n\tput_task_stack(p);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid sched_show_task(struct task_struct *p)\n{\n\tunsigned long free = 0;\n\tint ppid;\n\n\tif (!try_get_task_stack(p))\n\t\treturn;\n\n\tpr_info(\"task:%-15.15s state:%c\", p->comm, task_state_to_char(p));\n\n\tif (task_is_running(p))\n\t\tpr_cont(\"  running task    \");\n#ifdef CONFIG_DEBUG_STACK_USAGE\n\tfree = stack_not_used(p);\n#endif\n\tppid = 0;\n\trcu_read_lock();\n\tif (pid_alive(p))\n\t\tppid = task_pid_nr(rcu_dereference(p->real_parent));\n\trcu_read_unlock();\n\tpr_cont(\" stack:%5lu pid:%5d ppid:%6d flags:0x%08lx\\n\",\n\t\tfree, task_pid_nr(p), ppid,\n\t\tread_task_thread_flags(p));\n\n\tprint_worker_info(KERN_INFO, p);\n\tprint_stop_info(KERN_INFO, p);\n\tshow_stack(p, NULL, KERN_INFO);\n\tput_task_stack(p);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_alert",
          "args": [
            "\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\"",
            "t->pid",
            "\".I\"[trc_rdr.ipi_to_cpu >= 0]",
            "\".i\"[is_idle_tsk]",
            "\".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)]",
            "trc_rdr.nesting",
            "\" N\"[!!trc_rdr.needqs]",
            "cpu"
          ],
          "line": 1398
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "tick_nohz_full_cpu",
          "args": [
            "cpu"
          ],
          "line": 1402
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_alert",
          "args": [
            "\"P%d: %c\\n\"",
            "t->pid",
            "\".i\"[is_idle_tsk]"
          ],
          "line": 1394
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_call_func",
          "args": [
            "t",
            "trc_check_slow_task",
            "&trc_rdr"
          ],
          "line": 1393
        },
        "resolved": true,
        "details": {
          "function_name": "task_call_func",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4158-4202",
          "snippet": "int task_call_func(struct task_struct *p, task_call_f func, void *arg)\n{\n\tstruct rq *rq = NULL;\n\tunsigned int state;\n\tstruct rq_flags rf;\n\tint ret;\n\n\traw_spin_lock_irqsave(&p->pi_lock, rf.flags);\n\n\tstate = READ_ONCE(p->__state);\n\n\t/*\n\t * Ensure we load p->on_rq after p->__state, otherwise it would be\n\t * possible to, falsely, observe p->on_rq == 0.\n\t *\n\t * See try_to_wake_up() for a longer comment.\n\t */\n\tsmp_rmb();\n\n\t/*\n\t * Since pi->lock blocks try_to_wake_up(), we don't need rq->lock when\n\t * the task is blocked. Make sure to check @state since ttwu() can drop\n\t * locks at the end, see ttwu_queue_wakelist().\n\t */\n\tif (state == TASK_RUNNING || state == TASK_WAKING || p->on_rq)\n\t\trq = __task_rq_lock(p, &rf);\n\n\t/*\n\t * At this point the task is pinned; either:\n\t *  - blocked and we're holding off wakeups\t (pi->lock)\n\t *  - woken, and we're holding off enqueue\t (rq->lock)\n\t *  - queued, and we're holding off schedule\t (rq->lock)\n\t *  - running, and we're holding off de-schedule (rq->lock)\n\t *\n\t * The called function (@func) can use: task_curr(), p->on_rq and\n\t * p->__state to differentiate between these states.\n\t */\n\tret = func(p, arg);\n\n\tif (rq)\n\t\trq_unlock(rq, &rf);\n\n\traw_spin_unlock_irqrestore(&p->pi_lock, rf.flags);\n\treturn ret;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint task_call_func(struct task_struct *p, task_call_f func, void *arg)\n{\n\tstruct rq *rq = NULL;\n\tunsigned int state;\n\tstruct rq_flags rf;\n\tint ret;\n\n\traw_spin_lock_irqsave(&p->pi_lock, rf.flags);\n\n\tstate = READ_ONCE(p->__state);\n\n\t/*\n\t * Ensure we load p->on_rq after p->__state, otherwise it would be\n\t * possible to, falsely, observe p->on_rq == 0.\n\t *\n\t * See try_to_wake_up() for a longer comment.\n\t */\n\tsmp_rmb();\n\n\t/*\n\t * Since pi->lock blocks try_to_wake_up(), we don't need rq->lock when\n\t * the task is blocked. Make sure to check @state since ttwu() can drop\n\t * locks at the end, see ttwu_queue_wakelist().\n\t */\n\tif (state == TASK_RUNNING || state == TASK_WAKING || p->on_rq)\n\t\trq = __task_rq_lock(p, &rf);\n\n\t/*\n\t * At this point the task is pinned; either:\n\t *  - blocked and we're holding off wakeups\t (pi->lock)\n\t *  - woken, and we're holding off enqueue\t (rq->lock)\n\t *  - queued, and we're holding off schedule\t (rq->lock)\n\t *  - running, and we're holding off de-schedule (rq->lock)\n\t *\n\t * The called function (@func) can use: task_curr(), p->on_rq and\n\t * p->__state to differentiate between these states.\n\t */\n\tret = func(p, arg);\n\n\tif (rq)\n\t\trq_unlock(rq, &rf);\n\n\traw_spin_unlock_irqrestore(&p->pi_lock, rf.flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "t"
          ],
          "line": 1392
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ftrace.c",
          "lines": "7612-7633",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include \"ftrace_internal.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include \"ftrace_internal.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\""
          ],
          "line": 1389
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_idle_task",
          "args": [
            "t"
          ],
          "line": 1386
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_stalled_task_trace(struct task_struct *t, bool *firstreport)\n{\n\tint cpu;\n\tstruct trc_stall_chk_rdr trc_rdr;\n\tbool is_idle_tsk = is_idle_task(t);\n\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks_trace detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tif (!task_call_func(t, trc_check_slow_task, &trc_rdr))\n\t\tpr_alert(\"P%d: %c\\n\",\n\t\t\t t->pid,\n\t\t\t \".i\"[is_idle_tsk]);\n\telse\n\t\tpr_alert(\"P%d: %c%c%c nesting: %d%c cpu: %d\\n\",\n\t\t\t t->pid,\n\t\t\t \".I\"[trc_rdr.ipi_to_cpu >= 0],\n\t\t\t \".i\"[is_idle_tsk],\n\t\t\t \".N\"[cpu >= 0 && tick_nohz_full_cpu(cpu)],\n\t\t\t trc_rdr.nesting,\n\t\t\t \" N\"[!!trc_rdr.needqs],\n\t\t\t cpu);\n\tsched_show_task(t);\n}"
  },
  {
    "function_name": "trc_check_slow_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1369-1379",
    "snippet": "static int trc_check_slow_task(struct task_struct *t, void *arg)\n{\n\tstruct trc_stall_chk_rdr *trc_rdrp = arg;\n\n\tif (task_curr(t))\n\t\treturn false; // It is running, so decline to inspect it.\n\ttrc_rdrp->nesting = READ_ONCE(t->trc_reader_nesting);\n\ttrc_rdrp->ipi_to_cpu = READ_ONCE(t->trc_ipi_to_cpu);\n\ttrc_rdrp->needqs = READ_ONCE(t->trc_reader_special.b.need_qs);\n\treturn true;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1377
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_ipi_to_cpu"
          ],
          "line": 1376
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_nesting"
          ],
          "line": 1375
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_curr",
          "args": [
            "t"
          ],
          "line": 1373
        },
        "resolved": true,
        "details": {
          "function_name": "task_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2099-2102",
          "snippet": "inline int task_curr(const struct task_struct *p)\n{\n\treturn cpu_curr(task_cpu(p)) == p;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\ninline int task_curr(const struct task_struct *p)\n{\n\treturn cpu_curr(task_cpu(p)) == p;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int trc_check_slow_task(struct task_struct *t, void *arg)\n{\n\tstruct trc_stall_chk_rdr *trc_rdrp = arg;\n\n\tif (task_curr(t))\n\t\treturn false; // It is running, so decline to inspect it.\n\ttrc_rdrp->nesting = READ_ONCE(t->trc_reader_nesting);\n\ttrc_rdrp->ipi_to_cpu = READ_ONCE(t->trc_ipi_to_cpu);\n\ttrc_rdrp->needqs = READ_ONCE(t->trc_reader_special.b.need_qs);\n\treturn true;\n}"
  },
  {
    "function_name": "rcu_tasks_trace_postscan",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1346-1360",
    "snippet": "static void rcu_tasks_trace_postscan(struct list_head *hop)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\trcu_tasks_trace_pertask(idle_task(cpu), hop);\n\n\t// Re-enable CPU hotplug now that the tasklist scan has completed.\n\tcpus_read_unlock();\n\n\t// Wait for late-stage exiting tasks to finish exiting.\n\t// These might have passed the call to exit_tasks_rcu_finish().\n\tsynchronize_rcu();\n\t// Any tasks that exit after this point will set ->trc_reader_checked.\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 1358
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1556-1560",
          "snippet": "void synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpus_read_unlock",
          "args": [],
          "line": 1354
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "319-322",
          "snippet": "void cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_unlock(void)\n{\n\tpercpu_up_read(&cpu_hotplug_lock);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_trace_postscan(struct list_head *hop)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\trcu_tasks_trace_pertask(idle_task(cpu), hop);\n\n\t// Re-enable CPU hotplug now that the tasklist scan has completed.\n\tcpus_read_unlock();\n\n\t// Wait for late-stage exiting tasks to finish exiting.\n\t// These might have passed the call to exit_tasks_rcu_finish().\n\tsynchronize_rcu();\n\t// Any tasks that exit after this point will set ->trc_reader_checked.\n}"
  },
  {
    "function_name": "rcu_tasks_trace_pertask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1328-1340",
    "snippet": "static void rcu_tasks_trace_pertask(struct task_struct *t,\n\t\t\t\t    struct list_head *hop)\n{\n\t// During early boot when there is only the one boot CPU, there\n\t// is no idle task for the other CPUs. Just return.\n\tif (unlikely(t == NULL))\n\t\treturn;\n\n\tWRITE_ONCE(t->trc_reader_special.b.need_qs, false);\n\tWRITE_ONCE(t->trc_reader_checked, false);\n\tt->trc_ipi_to_cpu = -1;\n\ttrc_wait_for_one_reader(t, hop);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trc_wait_for_one_reader",
          "args": [
            "t",
            "hop"
          ],
          "line": 1339
        },
        "resolved": true,
        "details": {
          "function_name": "trc_wait_for_one_reader",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1254-1308",
          "snippet": "static void trc_wait_for_one_reader(struct task_struct *t,\n\t\t\t\t    struct list_head *bhp)\n{\n\tint cpu;\n\n\t// If a previous IPI is still in flight, let it complete.\n\tif (smp_load_acquire(&t->trc_ipi_to_cpu) != -1) // Order IPI\n\t\treturn;\n\n\t// The current task had better be in a quiescent state.\n\tif (t == current) {\n\t\tt->trc_reader_checked = true;\n\t\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\t\treturn;\n\t}\n\n\t// Attempt to nail down the task for inspection.\n\tget_task_struct(t);\n\tif (!task_call_func(t, trc_inspect_reader, NULL)) {\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\tput_task_struct(t);\n\n\t// If this task is not yet on the holdout list, then we are in\n\t// an RCU read-side critical section.  Otherwise, the invocation of\n\t// trc_add_holdout() that added it to the list did the necessary\n\t// get_task_struct().  Either way, the task cannot be freed out\n\t// from under this code.\n\n\t// If currently running, send an IPI, either way, add to list.\n\ttrc_add_holdout(t, bhp);\n\tif (task_curr(t) &&\n\t    time_after(jiffies + 1, rcu_tasks_trace.gp_start + rcu_task_ipi_delay)) {\n\t\t// The task is currently running, so try IPIing it.\n\t\tcpu = task_cpu(t);\n\n\t\t// If there is already an IPI outstanding, let it happen.\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu) || t->trc_ipi_to_cpu >= 0)\n\t\t\treturn;\n\n\t\tper_cpu(trc_ipi_to_cpu, cpu) = true;\n\t\tt->trc_ipi_to_cpu = cpu;\n\t\trcu_tasks_trace.n_ipis++;\n\t\tif (smp_call_function_single(cpu, trc_read_check_handler, t, 0)) {\n\t\t\t// Just in case there is some other reason for\n\t\t\t// failure than the target CPU being offline.\n\t\t\tWARN_ONCE(1, \"%s():  smp_call_function_single() failed for CPU: %d\\n\",\n\t\t\t\t  __func__, cpu);\n\t\t\trcu_tasks_trace.n_ipis_fails++;\n\t\t\tper_cpu(trc_ipi_to_cpu, cpu) = false;\n\t\t\tt->trc_ipi_to_cpu = -1;\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_wait_for_one_reader(struct task_struct *t,\n\t\t\t\t    struct list_head *bhp)\n{\n\tint cpu;\n\n\t// If a previous IPI is still in flight, let it complete.\n\tif (smp_load_acquire(&t->trc_ipi_to_cpu) != -1) // Order IPI\n\t\treturn;\n\n\t// The current task had better be in a quiescent state.\n\tif (t == current) {\n\t\tt->trc_reader_checked = true;\n\t\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\t\treturn;\n\t}\n\n\t// Attempt to nail down the task for inspection.\n\tget_task_struct(t);\n\tif (!task_call_func(t, trc_inspect_reader, NULL)) {\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\tput_task_struct(t);\n\n\t// If this task is not yet on the holdout list, then we are in\n\t// an RCU read-side critical section.  Otherwise, the invocation of\n\t// trc_add_holdout() that added it to the list did the necessary\n\t// get_task_struct().  Either way, the task cannot be freed out\n\t// from under this code.\n\n\t// If currently running, send an IPI, either way, add to list.\n\ttrc_add_holdout(t, bhp);\n\tif (task_curr(t) &&\n\t    time_after(jiffies + 1, rcu_tasks_trace.gp_start + rcu_task_ipi_delay)) {\n\t\t// The task is currently running, so try IPIing it.\n\t\tcpu = task_cpu(t);\n\n\t\t// If there is already an IPI outstanding, let it happen.\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu) || t->trc_ipi_to_cpu >= 0)\n\t\t\treturn;\n\n\t\tper_cpu(trc_ipi_to_cpu, cpu) = true;\n\t\tt->trc_ipi_to_cpu = cpu;\n\t\trcu_tasks_trace.n_ipis++;\n\t\tif (smp_call_function_single(cpu, trc_read_check_handler, t, 0)) {\n\t\t\t// Just in case there is some other reason for\n\t\t\t// failure than the target CPU being offline.\n\t\t\tWARN_ONCE(1, \"%s():  smp_call_function_single() failed for CPU: %d\\n\",\n\t\t\t\t  __func__, cpu);\n\t\t\trcu_tasks_trace.n_ipis_fails++;\n\t\t\tper_cpu(trc_ipi_to_cpu, cpu) = false;\n\t\t\tt->trc_ipi_to_cpu = -1;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_checked",
            "false"
          ],
          "line": 1337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs",
            "false"
          ],
          "line": 1336
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "t == NULL"
          ],
          "line": 1333
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_trace_pertask(struct task_struct *t,\n\t\t\t\t    struct list_head *hop)\n{\n\t// During early boot when there is only the one boot CPU, there\n\t// is no idle task for the other CPUs. Just return.\n\tif (unlikely(t == NULL))\n\t\treturn;\n\n\tWRITE_ONCE(t->trc_reader_special.b.need_qs, false);\n\tWRITE_ONCE(t->trc_reader_checked, false);\n\tt->trc_ipi_to_cpu = -1;\n\ttrc_wait_for_one_reader(t, hop);\n}"
  },
  {
    "function_name": "rcu_tasks_trace_pregp_step",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1311-1325",
    "snippet": "static void rcu_tasks_trace_pregp_step(void)\n{\n\tint cpu;\n\n\t// Allow for fast-acting IPIs.\n\tatomic_set(&trc_n_readers_need_end, 1);\n\n\t// There shouldn't be any old IPIs, but...\n\tfor_each_possible_cpu(cpu)\n\t\tWARN_ON_ONCE(per_cpu(trc_ipi_to_cpu, cpu));\n\n\t// Disable CPU hotplug across the tasklist scan.\n\t// This also waits for all readers in CPU-hotplug code paths.\n\tcpus_read_lock();\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpus_read_lock",
          "args": [],
          "line": 1324
        },
        "resolved": true,
        "details": {
          "function_name": "cpus_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "307-310",
          "snippet": "void cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid cpus_read_lock(void)\n{\n\tpercpu_down_read(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_set",
          "args": [
            "&trc_n_readers_need_end",
            "1"
          ],
          "line": 1316
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_trace_pregp_step(void)\n{\n\tint cpu;\n\n\t// Allow for fast-acting IPIs.\n\tatomic_set(&trc_n_readers_need_end, 1);\n\n\t// There shouldn't be any old IPIs, but...\n\tfor_each_possible_cpu(cpu)\n\t\tWARN_ON_ONCE(per_cpu(trc_ipi_to_cpu, cpu));\n\n\t// Disable CPU hotplug across the tasklist scan.\n\t// This also waits for all readers in CPU-hotplug code paths.\n\tcpus_read_lock();\n}"
  },
  {
    "function_name": "trc_wait_for_one_reader",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1254-1308",
    "snippet": "static void trc_wait_for_one_reader(struct task_struct *t,\n\t\t\t\t    struct list_head *bhp)\n{\n\tint cpu;\n\n\t// If a previous IPI is still in flight, let it complete.\n\tif (smp_load_acquire(&t->trc_ipi_to_cpu) != -1) // Order IPI\n\t\treturn;\n\n\t// The current task had better be in a quiescent state.\n\tif (t == current) {\n\t\tt->trc_reader_checked = true;\n\t\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\t\treturn;\n\t}\n\n\t// Attempt to nail down the task for inspection.\n\tget_task_struct(t);\n\tif (!task_call_func(t, trc_inspect_reader, NULL)) {\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\tput_task_struct(t);\n\n\t// If this task is not yet on the holdout list, then we are in\n\t// an RCU read-side critical section.  Otherwise, the invocation of\n\t// trc_add_holdout() that added it to the list did the necessary\n\t// get_task_struct().  Either way, the task cannot be freed out\n\t// from under this code.\n\n\t// If currently running, send an IPI, either way, add to list.\n\ttrc_add_holdout(t, bhp);\n\tif (task_curr(t) &&\n\t    time_after(jiffies + 1, rcu_tasks_trace.gp_start + rcu_task_ipi_delay)) {\n\t\t// The task is currently running, so try IPIing it.\n\t\tcpu = task_cpu(t);\n\n\t\t// If there is already an IPI outstanding, let it happen.\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu) || t->trc_ipi_to_cpu >= 0)\n\t\t\treturn;\n\n\t\tper_cpu(trc_ipi_to_cpu, cpu) = true;\n\t\tt->trc_ipi_to_cpu = cpu;\n\t\trcu_tasks_trace.n_ipis++;\n\t\tif (smp_call_function_single(cpu, trc_read_check_handler, t, 0)) {\n\t\t\t// Just in case there is some other reason for\n\t\t\t// failure than the target CPU being offline.\n\t\t\tWARN_ONCE(1, \"%s():  smp_call_function_single() failed for CPU: %d\\n\",\n\t\t\t\t  __func__, cpu);\n\t\t\trcu_tasks_trace.n_ipis_fails++;\n\t\t\tper_cpu(trc_ipi_to_cpu, cpu) = false;\n\t\t\tt->trc_ipi_to_cpu = -1;\n\t\t}\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "per_cpu",
          "args": [
            "trc_ipi_to_cpu",
            "cpu"
          ],
          "line": 1304
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_set_per_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "588-603",
          "snippet": "void kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_set_per_cpu(struct task_struct *k, int cpu)\n{\n\tstruct kthread *kthread = to_kthread(k);\n\tif (!kthread)\n\t\treturn;\n\n\tWARN_ON_ONCE(!(k->flags & PF_NO_SETAFFINITY));\n\n\tif (cpu < 0) {\n\t\tclear_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n\t\treturn;\n\t}\n\n\tkthread->cpu = cpu;\n\tset_bit(KTHREAD_IS_PER_CPU, &kthread->flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ONCE",
          "args": [
            "1",
            "\"%s():  smp_call_function_single() failed for CPU: %d\\n\"",
            "__func__",
            "cpu"
          ],
          "line": 1301
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_call_function_single",
          "args": [
            "cpu",
            "trc_read_check_handler",
            "t",
            "0"
          ],
          "line": 1298
        },
        "resolved": true,
        "details": {
          "function_name": "smp_call_function_single",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/up.c",
          "lines": "12-25",
          "snippet": "int smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/hypervisor.h>",
            "#include <linux/smp.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/hypervisor.h>\n#include <linux/smp.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n\nint smp_call_function_single(int cpu, void (*func) (void *info), void *info,\n\t\t\t\tint wait)\n{\n\tunsigned long flags;\n\n\tif (cpu != 0)\n\t\treturn -ENXIO;\n\n\tlocal_irq_save(flags);\n\tfunc(info);\n\tlocal_irq_restore(flags);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "t"
          ],
          "line": 1289
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ftrace.c",
          "lines": "7612-7633",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include \"ftrace_internal.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include \"ftrace_internal.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "time_after",
          "args": [
            "jiffies + 1",
            "rcu_tasks_trace.gp_start + rcu_task_ipi_delay"
          ],
          "line": 1287
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_curr",
          "args": [
            "t"
          ],
          "line": 1286
        },
        "resolved": true,
        "details": {
          "function_name": "task_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2099-2102",
          "snippet": "inline int task_curr(const struct task_struct *p)\n{\n\treturn cpu_curr(task_cpu(p)) == p;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\ninline int task_curr(const struct task_struct *p)\n{\n\treturn cpu_curr(task_cpu(p)) == p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "trc_add_holdout",
          "args": [
            "t",
            "bhp"
          ],
          "line": 1285
        },
        "resolved": true,
        "details": {
          "function_name": "trc_add_holdout",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1153-1159",
          "snippet": "static void trc_add_holdout(struct task_struct *t, struct list_head *bhp)\n{\n\tif (list_empty(&t->trc_holdout_list)) {\n\t\tget_task_struct(t);\n\t\tlist_add(&t->trc_holdout_list, bhp);\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_add_holdout(struct task_struct *t, struct list_head *bhp)\n{\n\tif (list_empty(&t->trc_holdout_list)) {\n\t\tget_task_struct(t);\n\t\tlist_add(&t->trc_holdout_list, bhp);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_task_struct",
          "args": [
            "t"
          ],
          "line": 1276
        },
        "resolved": true,
        "details": {
          "function_name": "__put_task_struct",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/fork.c",
          "lines": "745-761",
          "snippet": "void __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <linux/bpf.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/scs.h>",
            "#include <linux/kasan.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/anon_inodes.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <linux/bpf.h>\n#include <linux/io_uring.h>\n#include <linux/scs.h>\n#include <linux/kasan.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm_inline.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/seq_file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n\nstatic __latent_entropy struct;\n\nvoid __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "task_call_func",
          "args": [
            "t",
            "trc_inspect_reader",
            "NULL"
          ],
          "line": 1272
        },
        "resolved": true,
        "details": {
          "function_name": "task_call_func",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4158-4202",
          "snippet": "int task_call_func(struct task_struct *p, task_call_f func, void *arg)\n{\n\tstruct rq *rq = NULL;\n\tunsigned int state;\n\tstruct rq_flags rf;\n\tint ret;\n\n\traw_spin_lock_irqsave(&p->pi_lock, rf.flags);\n\n\tstate = READ_ONCE(p->__state);\n\n\t/*\n\t * Ensure we load p->on_rq after p->__state, otherwise it would be\n\t * possible to, falsely, observe p->on_rq == 0.\n\t *\n\t * See try_to_wake_up() for a longer comment.\n\t */\n\tsmp_rmb();\n\n\t/*\n\t * Since pi->lock blocks try_to_wake_up(), we don't need rq->lock when\n\t * the task is blocked. Make sure to check @state since ttwu() can drop\n\t * locks at the end, see ttwu_queue_wakelist().\n\t */\n\tif (state == TASK_RUNNING || state == TASK_WAKING || p->on_rq)\n\t\trq = __task_rq_lock(p, &rf);\n\n\t/*\n\t * At this point the task is pinned; either:\n\t *  - blocked and we're holding off wakeups\t (pi->lock)\n\t *  - woken, and we're holding off enqueue\t (rq->lock)\n\t *  - queued, and we're holding off schedule\t (rq->lock)\n\t *  - running, and we're holding off de-schedule (rq->lock)\n\t *\n\t * The called function (@func) can use: task_curr(), p->on_rq and\n\t * p->__state to differentiate between these states.\n\t */\n\tret = func(p, arg);\n\n\tif (rq)\n\t\trq_unlock(rq, &rf);\n\n\traw_spin_unlock_irqrestore(&p->pi_lock, rf.flags);\n\treturn ret;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint task_call_func(struct task_struct *p, task_call_f func, void *arg)\n{\n\tstruct rq *rq = NULL;\n\tunsigned int state;\n\tstruct rq_flags rf;\n\tint ret;\n\n\traw_spin_lock_irqsave(&p->pi_lock, rf.flags);\n\n\tstate = READ_ONCE(p->__state);\n\n\t/*\n\t * Ensure we load p->on_rq after p->__state, otherwise it would be\n\t * possible to, falsely, observe p->on_rq == 0.\n\t *\n\t * See try_to_wake_up() for a longer comment.\n\t */\n\tsmp_rmb();\n\n\t/*\n\t * Since pi->lock blocks try_to_wake_up(), we don't need rq->lock when\n\t * the task is blocked. Make sure to check @state since ttwu() can drop\n\t * locks at the end, see ttwu_queue_wakelist().\n\t */\n\tif (state == TASK_RUNNING || state == TASK_WAKING || p->on_rq)\n\t\trq = __task_rq_lock(p, &rf);\n\n\t/*\n\t * At this point the task is pinned; either:\n\t *  - blocked and we're holding off wakeups\t (pi->lock)\n\t *  - woken, and we're holding off enqueue\t (rq->lock)\n\t *  - queued, and we're holding off schedule\t (rq->lock)\n\t *  - running, and we're holding off de-schedule (rq->lock)\n\t *\n\t * The called function (@func) can use: task_curr(), p->on_rq and\n\t * p->__state to differentiate between these states.\n\t */\n\tret = func(p, arg);\n\n\tif (rq)\n\t\trq_unlock(rq, &rf);\n\n\traw_spin_unlock_irqrestore(&p->pi_lock, rf.flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_task_struct",
          "args": [
            "t"
          ],
          "line": 1271
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "READ_ONCE(t->trc_reader_nesting)"
          ],
          "line": 1266
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_nesting"
          ],
          "line": 1266
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&t->trc_ipi_to_cpu"
          ],
          "line": 1260
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_wait_for_one_reader(struct task_struct *t,\n\t\t\t\t    struct list_head *bhp)\n{\n\tint cpu;\n\n\t// If a previous IPI is still in flight, let it complete.\n\tif (smp_load_acquire(&t->trc_ipi_to_cpu) != -1) // Order IPI\n\t\treturn;\n\n\t// The current task had better be in a quiescent state.\n\tif (t == current) {\n\t\tt->trc_reader_checked = true;\n\t\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_nesting));\n\t\treturn;\n\t}\n\n\t// Attempt to nail down the task for inspection.\n\tget_task_struct(t);\n\tif (!task_call_func(t, trc_inspect_reader, NULL)) {\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\tput_task_struct(t);\n\n\t// If this task is not yet on the holdout list, then we are in\n\t// an RCU read-side critical section.  Otherwise, the invocation of\n\t// trc_add_holdout() that added it to the list did the necessary\n\t// get_task_struct().  Either way, the task cannot be freed out\n\t// from under this code.\n\n\t// If currently running, send an IPI, either way, add to list.\n\ttrc_add_holdout(t, bhp);\n\tif (task_curr(t) &&\n\t    time_after(jiffies + 1, rcu_tasks_trace.gp_start + rcu_task_ipi_delay)) {\n\t\t// The task is currently running, so try IPIing it.\n\t\tcpu = task_cpu(t);\n\n\t\t// If there is already an IPI outstanding, let it happen.\n\t\tif (per_cpu(trc_ipi_to_cpu, cpu) || t->trc_ipi_to_cpu >= 0)\n\t\t\treturn;\n\n\t\tper_cpu(trc_ipi_to_cpu, cpu) = true;\n\t\tt->trc_ipi_to_cpu = cpu;\n\t\trcu_tasks_trace.n_ipis++;\n\t\tif (smp_call_function_single(cpu, trc_read_check_handler, t, 0)) {\n\t\t\t// Just in case there is some other reason for\n\t\t\t// failure than the target CPU being offline.\n\t\t\tWARN_ONCE(1, \"%s():  smp_call_function_single() failed for CPU: %d\\n\",\n\t\t\t\t  __func__, cpu);\n\t\t\trcu_tasks_trace.n_ipis_fails++;\n\t\t\tper_cpu(trc_ipi_to_cpu, cpu) = false;\n\t\t\tt->trc_ipi_to_cpu = -1;\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "trc_inspect_reader",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1208-1251",
    "snippet": "static int trc_inspect_reader(struct task_struct *t, void *arg)\n{\n\tint cpu = task_cpu(t);\n\tint nesting;\n\tbool ofl = cpu_is_offline(cpu);\n\n\tif (task_curr(t)) {\n\t\tWARN_ON_ONCE(ofl && !is_idle_task(t));\n\n\t\t// If no chance of heavyweight readers, do it the hard way.\n\t\tif (!ofl && !IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\t\treturn -EINVAL;\n\n\t\t// If heavyweight readers are enabled on the remote task,\n\t\t// we can inspect its state despite its currently running.\n\t\t// However, we cannot safely change its state.\n\t\tn_heavy_reader_attempts++;\n\t\tif (!ofl && // Check for \"running\" idle tasks on offline CPUs.\n\t\t    !rcu_dynticks_zero_in_eqs(cpu, &t->trc_reader_nesting))\n\t\t\treturn -EINVAL; // No quiescent state, do it the hard way.\n\t\tn_heavy_reader_updates++;\n\t\tif (ofl)\n\t\t\tn_heavy_reader_ofl_updates++;\n\t\tnesting = 0;\n\t} else {\n\t\t// The task is not running, so C-language access is safe.\n\t\tnesting = t->trc_reader_nesting;\n\t}\n\n\t// If not exiting a read-side critical section, mark as checked\n\t// so that the grace-period kthread will remove it from the\n\t// holdout list.\n\tt->trc_reader_checked = nesting >= 0;\n\tif (nesting <= 0)\n\t\treturn nesting ? -EINVAL : 0;  // If in QS, done, otherwise try again later.\n\n\t// The task is in a read-side critical section, so set up its\n\t// state so that it will awaken the grace-period kthread upon exit\n\t// from that critical section.\n\tatomic_inc(&trc_n_readers_need_end); // One more to wait on.\n\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_special.b.need_qs));\n\tWRITE_ONCE(t->trc_reader_special.b.need_qs, true);\n\treturn 0;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs",
            "true"
          ],
          "line": 1249
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "READ_ONCE(t->trc_reader_special.b.need_qs)"
          ],
          "line": 1248
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1248
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_dynticks_zero_in_eqs",
          "args": [
            "cpu",
            "&t->trc_reader_nesting"
          ],
          "line": 1226
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_dynticks_zero_in_eqs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "516-516",
          "snippet": "static inline bool rcu_dynticks_zero_in_eqs(int cpu, int *vp) { return false; }",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline bool rcu_dynticks_zero_in_eqs(int cpu, int *vp) { return false; }"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_TASKS_TRACE_RCU_READ_MB"
          ],
          "line": 1218
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "ofl && !is_idle_task(t)"
          ],
          "line": 1215
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_idle_task",
          "args": [
            "t"
          ],
          "line": 1215
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_curr",
          "args": [
            "t"
          ],
          "line": 1214
        },
        "resolved": true,
        "details": {
          "function_name": "task_curr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2099-2102",
          "snippet": "inline int task_curr(const struct task_struct *p)\n{\n\treturn cpu_curr(task_cpu(p)) == p;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\ninline int task_curr(const struct task_struct *p)\n{\n\treturn cpu_curr(task_cpu(p)) == p;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_is_offline",
          "args": [
            "cpu"
          ],
          "line": 1212
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "t"
          ],
          "line": 1210
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ftrace.c",
          "lines": "7612-7633",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include \"ftrace_internal.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include \"ftrace_internal.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int trc_inspect_reader(struct task_struct *t, void *arg)\n{\n\tint cpu = task_cpu(t);\n\tint nesting;\n\tbool ofl = cpu_is_offline(cpu);\n\n\tif (task_curr(t)) {\n\t\tWARN_ON_ONCE(ofl && !is_idle_task(t));\n\n\t\t// If no chance of heavyweight readers, do it the hard way.\n\t\tif (!ofl && !IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\t\treturn -EINVAL;\n\n\t\t// If heavyweight readers are enabled on the remote task,\n\t\t// we can inspect its state despite its currently running.\n\t\t// However, we cannot safely change its state.\n\t\tn_heavy_reader_attempts++;\n\t\tif (!ofl && // Check for \"running\" idle tasks on offline CPUs.\n\t\t    !rcu_dynticks_zero_in_eqs(cpu, &t->trc_reader_nesting))\n\t\t\treturn -EINVAL; // No quiescent state, do it the hard way.\n\t\tn_heavy_reader_updates++;\n\t\tif (ofl)\n\t\t\tn_heavy_reader_ofl_updates++;\n\t\tnesting = 0;\n\t} else {\n\t\t// The task is not running, so C-language access is safe.\n\t\tnesting = t->trc_reader_nesting;\n\t}\n\n\t// If not exiting a read-side critical section, mark as checked\n\t// so that the grace-period kthread will remove it from the\n\t// holdout list.\n\tt->trc_reader_checked = nesting >= 0;\n\tif (nesting <= 0)\n\t\treturn nesting ? -EINVAL : 0;  // If in QS, done, otherwise try again later.\n\n\t// The task is in a read-side critical section, so set up its\n\t// state so that it will awaken the grace-period kthread upon exit\n\t// from that critical section.\n\tatomic_inc(&trc_n_readers_need_end); // One more to wait on.\n\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_special.b.need_qs));\n\tWRITE_ONCE(t->trc_reader_special.b.need_qs, true);\n\treturn 0;\n}"
  },
  {
    "function_name": "trc_read_check_handler",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1171-1205",
    "snippet": "static void trc_read_check_handler(void *t_in)\n{\n\tstruct task_struct *t = current;\n\tstruct task_struct *texp = t_in;\n\n\t// If the task is no longer running on this CPU, leave.\n\tif (unlikely(texp != t)) {\n\t\tgoto reset_ipi; // Already on holdout list, so will check later.\n\t}\n\n\t// If the task is not in a read-side critical section, and\n\t// if this is the last reader, awaken the grace-period kthread.\n\tif (likely(!READ_ONCE(t->trc_reader_nesting))) {\n\t\tWRITE_ONCE(t->trc_reader_checked, true);\n\t\tgoto reset_ipi;\n\t}\n\t// If we are racing with an rcu_read_unlock_trace(), try again later.\n\tif (unlikely(READ_ONCE(t->trc_reader_nesting) < 0))\n\t\tgoto reset_ipi;\n\tWRITE_ONCE(t->trc_reader_checked, true);\n\n\t// Get here if the task is in a read-side critical section.  Set\n\t// its state so that it will awaken the grace-period kthread upon\n\t// exit from that critical section.\n\tatomic_inc(&trc_n_readers_need_end); // One more to wait on.\n\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_special.b.need_qs));\n\tWRITE_ONCE(t->trc_reader_special.b.need_qs, true);\n\nreset_ipi:\n\t// Allow future IPIs to be sent on CPU and for task.\n\t// Also order this IPI handler against any later manipulations of\n\t// the intended task.\n\tsmp_store_release(per_cpu_ptr(&trc_ipi_to_cpu, smp_processor_id()), false); // ^^^\n\tsmp_store_release(&texp->trc_ipi_to_cpu, -1); // ^^^\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_store_release",
          "args": [
            "&texp->trc_ipi_to_cpu",
            "-1"
          ],
          "line": 1204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_store_release",
          "args": [
            "per_cpu_ptr(&trc_ipi_to_cpu, smp_processor_id())",
            "false"
          ],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "&trc_ipi_to_cpu",
            "smp_processor_id()"
          ],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 1203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs",
            "true"
          ],
          "line": 1197
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "READ_ONCE(t->trc_reader_special.b.need_qs)"
          ],
          "line": 1196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1196
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1195
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_checked",
            "true"
          ],
          "line": 1190
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "READ_ONCE(t->trc_reader_nesting) < 0"
          ],
          "line": 1188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_nesting"
          ],
          "line": 1188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_checked",
            "true"
          ],
          "line": 1184
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!READ_ONCE(t->trc_reader_nesting)"
          ],
          "line": 1183
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_nesting"
          ],
          "line": 1183
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "texp != t"
          ],
          "line": 1177
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_read_check_handler(void *t_in)\n{\n\tstruct task_struct *t = current;\n\tstruct task_struct *texp = t_in;\n\n\t// If the task is no longer running on this CPU, leave.\n\tif (unlikely(texp != t)) {\n\t\tgoto reset_ipi; // Already on holdout list, so will check later.\n\t}\n\n\t// If the task is not in a read-side critical section, and\n\t// if this is the last reader, awaken the grace-period kthread.\n\tif (likely(!READ_ONCE(t->trc_reader_nesting))) {\n\t\tWRITE_ONCE(t->trc_reader_checked, true);\n\t\tgoto reset_ipi;\n\t}\n\t// If we are racing with an rcu_read_unlock_trace(), try again later.\n\tif (unlikely(READ_ONCE(t->trc_reader_nesting) < 0))\n\t\tgoto reset_ipi;\n\tWRITE_ONCE(t->trc_reader_checked, true);\n\n\t// Get here if the task is in a read-side critical section.  Set\n\t// its state so that it will awaken the grace-period kthread upon\n\t// exit from that critical section.\n\tatomic_inc(&trc_n_readers_need_end); // One more to wait on.\n\tWARN_ON_ONCE(READ_ONCE(t->trc_reader_special.b.need_qs));\n\tWRITE_ONCE(t->trc_reader_special.b.need_qs, true);\n\nreset_ipi:\n\t// Allow future IPIs to be sent on CPU and for task.\n\t// Also order this IPI handler against any later manipulations of\n\t// the intended task.\n\tsmp_store_release(per_cpu_ptr(&trc_ipi_to_cpu, smp_processor_id()), false); // ^^^\n\tsmp_store_release(&texp->trc_ipi_to_cpu, -1); // ^^^\n}"
  },
  {
    "function_name": "trc_del_holdout",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1162-1168",
    "snippet": "static void trc_del_holdout(struct task_struct *t)\n{\n\tif (!list_empty(&t->trc_holdout_list)) {\n\t\tlist_del_init(&t->trc_holdout_list);\n\t\tput_task_struct(t);\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_task_struct",
          "args": [
            "t"
          ],
          "line": 1166
        },
        "resolved": true,
        "details": {
          "function_name": "__put_task_struct",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/fork.c",
          "lines": "745-761",
          "snippet": "void __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <linux/bpf.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/scs.h>",
            "#include <linux/kasan.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/anon_inodes.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <linux/bpf.h>\n#include <linux/io_uring.h>\n#include <linux/scs.h>\n#include <linux/kasan.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm_inline.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/seq_file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n\nstatic __latent_entropy struct;\n\nvoid __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&t->trc_holdout_list"
          ],
          "line": 1165
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&t->trc_holdout_list"
          ],
          "line": 1164
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_del_holdout(struct task_struct *t)\n{\n\tif (!list_empty(&t->trc_holdout_list)) {\n\t\tlist_del_init(&t->trc_holdout_list);\n\t\tput_task_struct(t);\n\t}\n}"
  },
  {
    "function_name": "trc_add_holdout",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1153-1159",
    "snippet": "static void trc_add_holdout(struct task_struct *t, struct list_head *bhp)\n{\n\tif (list_empty(&t->trc_holdout_list)) {\n\t\tget_task_struct(t);\n\t\tlist_add(&t->trc_holdout_list, bhp);\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&t->trc_holdout_list",
            "bhp"
          ],
          "line": 1157
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_add_len",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "210-221",
          "snippet": "void rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_task_struct",
          "args": [
            "t"
          ],
          "line": 1156
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&t->trc_holdout_list"
          ],
          "line": 1155
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void trc_add_holdout(struct task_struct *t, struct list_head *bhp)\n{\n\tif (list_empty(&t->trc_holdout_list)) {\n\t\tget_task_struct(t);\n\t\tlist_add(&t->trc_holdout_list, bhp);\n\t}\n}"
  },
  {
    "function_name": "rcu_read_unlock_trace_special",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1136-1149",
    "snippet": "void rcu_read_unlock_trace_special(struct task_struct *t)\n{\n\tint nq = READ_ONCE(t->trc_reader_special.b.need_qs);\n\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB) &&\n\t    t->trc_reader_special.b.need_mb)\n\t\tsmp_mb(); // Pairs with update-side barriers.\n\t// Update .need_qs before ->trc_reader_nesting for irq/NMI handlers.\n\tif (nq)\n\t\tWRITE_ONCE(t->trc_reader_special.b.need_qs, false);\n\tWRITE_ONCE(t->trc_reader_nesting, 0);\n\tif (nq && atomic_dec_and_test(&trc_n_readers_need_end))\n\t\tirq_work_queue(&rcu_tasks_trace_iw);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue",
          "args": [
            "&rcu_tasks_trace_iw"
          ],
          "line": 1148
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "106-118",
          "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec_and_test",
          "args": [
            "&trc_n_readers_need_end"
          ],
          "line": 1147
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_nesting",
            "0"
          ],
          "line": 1146
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs",
            "false"
          ],
          "line": 1145
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 1142
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_TASKS_TRACE_RCU_READ_MB"
          ],
          "line": 1140
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->trc_reader_special.b.need_qs"
          ],
          "line": 1138
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_read_unlock_trace_special(struct task_struct *t)\n{\n\tint nq = READ_ONCE(t->trc_reader_special.b.need_qs);\n\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB) &&\n\t    t->trc_reader_special.b.need_mb)\n\t\tsmp_mb(); // Pairs with update-side barriers.\n\t// Update .need_qs before ->trc_reader_nesting for irq/NMI handlers.\n\tif (nq)\n\t\tWRITE_ONCE(t->trc_reader_special.b.need_qs, false);\n\tWRITE_ONCE(t->trc_reader_nesting, 0);\n\tif (nq && atomic_dec_and_test(&trc_n_readers_need_end))\n\t\tirq_work_queue(&rcu_tasks_trace_iw);\n}"
  },
  {
    "function_name": "rcu_read_unlock_iw",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1129-1132",
    "snippet": "static void rcu_read_unlock_iw(struct irq_work *iwp)\n{\n\twake_up(&trc_wait);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up",
          "args": [
            "&trc_wait"
          ],
          "line": 1131
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_worker",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "847-853",
          "snippet": "static void wake_up_worker(struct worker_pool *pool)\n{\n\tstruct worker *worker = first_idle_worker(pool);\n\n\tif (likely(worker))\n\t\twake_up_process(worker->task);\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);",
            "static void show_one_worker_pool(struct worker_pool *pool);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);\nstatic void show_one_worker_pool(struct worker_pool *pool);\n\nstatic void wake_up_worker(struct worker_pool *pool)\n{\n\tstruct worker *worker = first_idle_worker(pool);\n\n\tif (likely(worker))\n\t\twake_up_process(worker->task);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_read_unlock_iw(struct irq_work *iwp)\n{\n\twake_up(&trc_wait);\n}"
  },
  {
    "function_name": "show_rcu_tasks_rude_gp_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1026-1029",
    "snippet": "void show_rcu_tasks_rude_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_rude, \"\");\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "show_rcu_tasks_generic_gp_kthread",
          "args": [
            "&rcu_tasks_rude",
            "\"\""
          ],
          "line": 1028
        },
        "resolved": true,
        "details": {
          "function_name": "show_rcu_tasks_generic_gp_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "565-577",
          "snippet": "static void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_rude_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks_rude, \"\");\n}"
  },
  {
    "function_name": "rcu_spawn_tasks_rude_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1017-1023",
    "snippet": "static int __init rcu_spawn_tasks_rude_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_rude);\n\trcu_tasks_rude.gp_sleep = HZ / 10;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_rude);\n\treturn 0;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_spawn_tasks_kthread_generic",
          "args": [
            "&rcu_tasks_rude"
          ],
          "line": 1021
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_tasks_kthread_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "529-537",
          "snippet": "static void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}"
        }
      },
      {
        "call_info": {
          "callee": "cblist_init_generic",
          "args": [
            "&rcu_tasks_rude"
          ],
          "line": 1019
        },
        "resolved": true,
        "details": {
          "function_name": "cblist_init_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "214-251",
          "snippet": "static void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int __init rcu_spawn_tasks_rude_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks_rude);\n\trcu_tasks_rude.gp_sleep = HZ / 10;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks_rude);\n\treturn 0;\n}"
  },
  {
    "function_name": "rcu_barrier_tasks_rude",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "1011-1014",
    "snippet": "void rcu_barrier_tasks_rude(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_rude);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_barrier_tasks_generic",
          "args": [
            "&rcu_tasks_rude"
          ],
          "line": 1013
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "339-370",
          "snippet": "static void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_rude(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_rude);\n}"
  },
  {
    "function_name": "synchronize_rcu_tasks_rude",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "999-1002",
    "snippet": "void synchronize_rcu_tasks_rude(void)\n{\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_rude);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_rcu_tasks_generic",
          "args": [
            "&rcu_tasks_rude"
          ],
          "line": 1001
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "315-323",
          "snippet": "static void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_rude(void)\n{\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_rude);\n}"
  },
  {
    "function_name": "call_rcu_tasks_rude",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "975-978",
    "snippet": "void call_rcu_tasks_rude(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_rude);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu_tasks_generic",
          "args": [
            "rhp",
            "func",
            "&rcu_tasks_rude"
          ],
          "line": 977
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "264-312",
          "snippet": "static void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks_rude(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_rude);\n}"
  },
  {
    "function_name": "rcu_tasks_rude_wait_gp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "947-951",
    "snippet": "static void rcu_tasks_rude_wait_gp(struct rcu_tasks *rtp)\n{\n\trtp->n_ipis += cpumask_weight(cpu_online_mask);\n\tschedule_on_each_cpu(rcu_tasks_be_rude);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_on_each_cpu",
          "args": [
            "rcu_tasks_be_rude"
          ],
          "line": 950
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_on_each_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "3327-3351",
          "snippet": "int schedule_on_each_cpu(work_func_t func)\n{\n\tint cpu;\n\tstruct work_struct __percpu *works;\n\n\tworks = alloc_percpu(struct work_struct);\n\tif (!works)\n\t\treturn -ENOMEM;\n\n\tcpus_read_lock();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct work_struct *work = per_cpu_ptr(works, cpu);\n\n\t\tINIT_WORK(work, func);\n\t\tschedule_work_on(cpu, work);\n\t}\n\n\tfor_each_online_cpu(cpu)\n\t\tflush_work(per_cpu_ptr(works, cpu));\n\n\tcpus_read_unlock();\n\tfree_percpu(works);\n\treturn 0;\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nint schedule_on_each_cpu(work_func_t func)\n{\n\tint cpu;\n\tstruct work_struct __percpu *works;\n\n\tworks = alloc_percpu(struct work_struct);\n\tif (!works)\n\t\treturn -ENOMEM;\n\n\tcpus_read_lock();\n\n\tfor_each_online_cpu(cpu) {\n\t\tstruct work_struct *work = per_cpu_ptr(works, cpu);\n\n\t\tINIT_WORK(work, func);\n\t\tschedule_work_on(cpu, work);\n\t}\n\n\tfor_each_online_cpu(cpu)\n\t\tflush_work(per_cpu_ptr(works, cpu));\n\n\tcpus_read_unlock();\n\tfree_percpu(works);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "cpu_online_mask"
          ],
          "line": 949
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_rude_wait_gp(struct rcu_tasks *rtp)\n{\n\trtp->n_ipis += cpumask_weight(cpu_online_mask);\n\tschedule_on_each_cpu(rcu_tasks_be_rude);\n}"
  },
  {
    "function_name": "rcu_tasks_be_rude",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "942-944",
    "snippet": "static void rcu_tasks_be_rude(struct work_struct *work)\n{\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_be_rude(struct work_struct *work)\n{\n}"
  },
  {
    "function_name": "exit_tasks_rcu_finish",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "922-922",
    "snippet": "void exit_tasks_rcu_finish(void) { exit_tasks_rcu_finish_trace(current); }",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "exit_tasks_rcu_finish_trace",
          "args": [
            "current"
          ],
          "line": 922
        },
        "resolved": true,
        "details": {
          "function_name": "exit_tasks_rcu_finish_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1613-1613",
          "snippet": "static void exit_tasks_rcu_finish_trace(struct task_struct *t) { }",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void exit_tasks_rcu_finish_trace(struct task_struct *t) { }"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid exit_tasks_rcu_finish(void) { exit_tasks_rcu_finish_trace(current); }"
  },
  {
    "function_name": "exit_tasks_rcu_start",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "921-921",
    "snippet": "void exit_tasks_rcu_start(void) { }",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid exit_tasks_rcu_start(void) { }"
  },
  {
    "function_name": "exit_tasks_rcu_finish",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "910-918",
    "snippet": "void exit_tasks_rcu_finish(void) __releases(&tasks_rcu_exit_srcu)\n{\n\tstruct task_struct *t = current;\n\n\tpreempt_disable();\n\t__srcu_read_unlock(&tasks_rcu_exit_srcu, t->rcu_tasks_idx);\n\tpreempt_enable();\n\texit_tasks_rcu_finish_trace(t);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "exit_tasks_rcu_finish_trace",
          "args": [
            "t"
          ],
          "line": 917
        },
        "resolved": true,
        "details": {
          "function_name": "exit_tasks_rcu_finish_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1613-1613",
          "snippet": "static void exit_tasks_rcu_finish_trace(struct task_struct *t) { }",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void exit_tasks_rcu_finish_trace(struct task_struct *t) { }"
        }
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 916
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__srcu_read_unlock",
          "args": [
            "&tasks_rcu_exit_srcu",
            "t->rcu_tasks_idx"
          ],
          "line": 915
        },
        "resolved": true,
        "details": {
          "function_name": "__srcu_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/srcutree.c",
          "lines": "416-420",
          "snippet": "void __srcu_read_unlock(struct srcu_struct *ssp, int idx)\n{\n\tsmp_mb(); /* C */  /* Avoid leaking the critical section. */\n\tthis_cpu_inc(ssp->sda->srcu_unlock_count[idx]);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include \"rcu.h\"",
            "#include <linux/srcu.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/smp.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/preempt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include \"rcu.h\"\n#include <linux/srcu.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/smp.h>\n#include <linux/sched.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/preempt.h>\n#include <linux/percpu.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n\nvoid __srcu_read_unlock(struct srcu_struct *ssp, int idx)\n{\n\tsmp_mb(); /* C */  /* Avoid leaking the critical section. */\n\tthis_cpu_inc(ssp->sda->srcu_unlock_count[idx]);\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 914
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__releases",
          "args": [
            "&tasks_rcu_exit_srcu"
          ],
          "line": 910
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid exit_tasks_rcu_finish(void) __releases(&tasks_rcu_exit_srcu)\n{\n\tstruct task_struct *t = current;\n\n\tpreempt_disable();\n\t__srcu_read_unlock(&tasks_rcu_exit_srcu, t->rcu_tasks_idx);\n\tpreempt_enable();\n\texit_tasks_rcu_finish_trace(t);\n}"
  },
  {
    "function_name": "exit_tasks_rcu_start",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "902-907",
    "snippet": "void exit_tasks_rcu_start(void) __acquires(&tasks_rcu_exit_srcu)\n{\n\tpreempt_disable();\n\tcurrent->rcu_tasks_idx = __srcu_read_lock(&tasks_rcu_exit_srcu);\n\tpreempt_enable();\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 906
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__srcu_read_lock",
          "args": [
            "&tasks_rcu_exit_srcu"
          ],
          "line": 905
        },
        "resolved": true,
        "details": {
          "function_name": "__srcu_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/srcutree.c",
          "lines": "400-408",
          "snippet": "int __srcu_read_lock(struct srcu_struct *ssp)\n{\n\tint idx;\n\n\tidx = READ_ONCE(ssp->srcu_idx) & 0x1;\n\tthis_cpu_inc(ssp->sda->srcu_lock_count[idx]);\n\tsmp_mb(); /* B */  /* Avoid leaking the critical section. */\n\treturn idx;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include \"rcu.h\"",
            "#include <linux/srcu.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/smp.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/preempt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include \"rcu.h\"\n#include <linux/srcu.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/smp.h>\n#include <linux/sched.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/preempt.h>\n#include <linux/percpu.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n\nint __srcu_read_lock(struct srcu_struct *ssp)\n{\n\tint idx;\n\n\tidx = READ_ONCE(ssp->srcu_idx) & 0x1;\n\tthis_cpu_inc(ssp->sda->srcu_lock_count[idx]);\n\tsmp_mb(); /* B */  /* Avoid leaking the critical section. */\n\treturn idx;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 904
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__acquires",
          "args": [
            "&tasks_rcu_exit_srcu"
          ],
          "line": 902
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid exit_tasks_rcu_start(void) __acquires(&tasks_rcu_exit_srcu)\n{\n\tpreempt_disable();\n\tcurrent->rcu_tasks_idx = __srcu_read_lock(&tasks_rcu_exit_srcu);\n\tpreempt_enable();\n}"
  },
  {
    "function_name": "show_rcu_tasks_classic_gp_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "894-897",
    "snippet": "void show_rcu_tasks_classic_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks, \"\");\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "show_rcu_tasks_generic_gp_kthread",
          "args": [
            "&rcu_tasks",
            "\"\""
          ],
          "line": 896
        },
        "resolved": true,
        "details": {
          "function_name": "show_rcu_tasks_generic_gp_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "565-577",
          "snippet": "static void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid show_rcu_tasks_classic_gp_kthread(void)\n{\n\tshow_rcu_tasks_generic_gp_kthread(&rcu_tasks, \"\");\n}"
  },
  {
    "function_name": "rcu_spawn_tasks_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "879-891",
    "snippet": "static int __init rcu_spawn_tasks_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks);\n\trcu_tasks.gp_sleep = HZ / 10;\n\trcu_tasks.init_fract = HZ / 10;\n\trcu_tasks.pregp_func = rcu_tasks_pregp_step;\n\trcu_tasks.pertask_func = rcu_tasks_pertask;\n\trcu_tasks.postscan_func = rcu_tasks_postscan;\n\trcu_tasks.holdouts_func = check_all_holdout_tasks;\n\trcu_tasks.postgp_func = rcu_tasks_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks);\n\treturn 0;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_spawn_tasks_kthread_generic",
          "args": [
            "&rcu_tasks"
          ],
          "line": 889
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_tasks_kthread_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "529-537",
          "snippet": "static void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}"
        }
      },
      {
        "call_info": {
          "callee": "cblist_init_generic",
          "args": [
            "&rcu_tasks"
          ],
          "line": 881
        },
        "resolved": true,
        "details": {
          "function_name": "cblist_init_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "214-251",
          "snippet": "static void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int __init rcu_spawn_tasks_kthread(void)\n{\n\tcblist_init_generic(&rcu_tasks);\n\trcu_tasks.gp_sleep = HZ / 10;\n\trcu_tasks.init_fract = HZ / 10;\n\trcu_tasks.pregp_func = rcu_tasks_pregp_step;\n\trcu_tasks.pertask_func = rcu_tasks_pertask;\n\trcu_tasks.postscan_func = rcu_tasks_postscan;\n\trcu_tasks.holdouts_func = check_all_holdout_tasks;\n\trcu_tasks.postgp_func = rcu_tasks_postgp;\n\trcu_spawn_tasks_kthread_generic(&rcu_tasks);\n\treturn 0;\n}"
  },
  {
    "function_name": "rcu_barrier_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "873-876",
    "snippet": "void rcu_barrier_tasks(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_barrier_tasks_generic",
          "args": [
            "&rcu_tasks"
          ],
          "line": 875
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "339-370",
          "snippet": "static void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks);\n}"
  },
  {
    "function_name": "synchronize_rcu_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "861-864",
    "snippet": "void synchronize_rcu_tasks(void)\n{\n\tsynchronize_rcu_tasks_generic(&rcu_tasks);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_rcu_tasks_generic",
          "args": [
            "&rcu_tasks"
          ],
          "line": 863
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "315-323",
          "snippet": "static void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks(void)\n{\n\tsynchronize_rcu_tasks_generic(&rcu_tasks);\n}"
  },
  {
    "function_name": "call_rcu_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "837-840",
    "snippet": "void call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "call_rcu_tasks_generic",
          "args": [
            "rhp",
            "func",
            "&rcu_tasks"
          ],
          "line": 839
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "264-312",
          "snippet": "static void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks);\n}"
  },
  {
    "function_name": "rcu_tasks_postgp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "794-814",
    "snippet": "static void rcu_tasks_postgp(struct rcu_tasks *rtp)\n{\n\t/*\n\t * Because ->on_rq and ->nvcsw are not guaranteed to have a full\n\t * memory barriers prior to them in the schedule() path, memory\n\t * reordering on other CPUs could cause their RCU-tasks read-side\n\t * critical sections to extend past the end of the grace period.\n\t * However, because these ->nvcsw updates are carried out with\n\t * interrupts disabled, we can use synchronize_rcu() to force the\n\t * needed ordering on all such CPUs.\n\t *\n\t * This synchronize_rcu() also confines all ->rcu_tasks_holdout\n\t * accesses to be within the grace period, avoiding the need for\n\t * memory barriers for ->rcu_tasks_holdout accesses.\n\t *\n\t * In addition, this synchronize_rcu() waits for exiting tasks\n\t * to complete their final preempt_disable() region of execution,\n\t * cleaning up after the synchronize_srcu() above.\n\t */\n\tsynchronize_rcu();\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 813
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1556-1560",
          "snippet": "void synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_postgp(struct rcu_tasks *rtp)\n{\n\t/*\n\t * Because ->on_rq and ->nvcsw are not guaranteed to have a full\n\t * memory barriers prior to them in the schedule() path, memory\n\t * reordering on other CPUs could cause their RCU-tasks read-side\n\t * critical sections to extend past the end of the grace period.\n\t * However, because these ->nvcsw updates are carried out with\n\t * interrupts disabled, we can use synchronize_rcu() to force the\n\t * needed ordering on all such CPUs.\n\t *\n\t * This synchronize_rcu() also confines all ->rcu_tasks_holdout\n\t * accesses to be within the grace period, avoiding the need for\n\t * memory barriers for ->rcu_tasks_holdout accesses.\n\t *\n\t * In addition, this synchronize_rcu() waits for exiting tasks\n\t * to complete their final preempt_disable() region of execution,\n\t * cleaning up after the synchronize_srcu() above.\n\t */\n\tsynchronize_rcu();\n}"
  },
  {
    "function_name": "check_all_holdout_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "782-791",
    "snippet": "static void check_all_holdout_tasks(struct list_head *hop,\n\t\t\t\t    bool needreport, bool *firstreport)\n{\n\tstruct task_struct *t, *t1;\n\n\tlist_for_each_entry_safe(t, t1, hop, rcu_tasks_holdout_list) {\n\t\tcheck_holdout_task(t, needreport, firstreport);\n\t\tcond_resched();\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 789
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "check_holdout_task",
          "args": [
            "t",
            "needreport",
            "firstreport"
          ],
          "line": 788
        },
        "resolved": true,
        "details": {
          "function_name": "check_holdout_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "750-779",
          "snippet": "static void check_holdout_task(struct task_struct *t,\n\t\t\t       bool needreport, bool *firstreport)\n{\n\tint cpu;\n\n\tif (!READ_ONCE(t->rcu_tasks_holdout) ||\n\t    t->rcu_tasks_nvcsw != READ_ONCE(t->nvcsw) ||\n\t    !READ_ONCE(t->on_rq) ||\n\t    (IS_ENABLED(CONFIG_NO_HZ_FULL) &&\n\t     !is_idle_task(t) && t->rcu_tasks_idle_cpu >= 0)) {\n\t\tWRITE_ONCE(t->rcu_tasks_holdout, false);\n\t\tlist_del_init(&t->rcu_tasks_holdout_list);\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\trcu_request_urgent_qs_task(t);\n\tif (!needreport)\n\t\treturn;\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tpr_alert(\"%p: %c%c nvcsw: %lu/%lu holdout: %d idle_cpu: %d/%d\\n\",\n\t\t t, \".I\"[is_idle_task(t)],\n\t\t \"N.\"[cpu < 0 || !tick_nohz_full_cpu(cpu)],\n\t\t t->rcu_tasks_nvcsw, t->nvcsw, t->rcu_tasks_holdout,\n\t\t t->rcu_tasks_idle_cpu, cpu);\n\tsched_show_task(t);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void check_holdout_task(struct task_struct *t,\n\t\t\t       bool needreport, bool *firstreport)\n{\n\tint cpu;\n\n\tif (!READ_ONCE(t->rcu_tasks_holdout) ||\n\t    t->rcu_tasks_nvcsw != READ_ONCE(t->nvcsw) ||\n\t    !READ_ONCE(t->on_rq) ||\n\t    (IS_ENABLED(CONFIG_NO_HZ_FULL) &&\n\t     !is_idle_task(t) && t->rcu_tasks_idle_cpu >= 0)) {\n\t\tWRITE_ONCE(t->rcu_tasks_holdout, false);\n\t\tlist_del_init(&t->rcu_tasks_holdout_list);\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\trcu_request_urgent_qs_task(t);\n\tif (!needreport)\n\t\treturn;\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tpr_alert(\"%p: %c%c nvcsw: %lu/%lu holdout: %d idle_cpu: %d/%d\\n\",\n\t\t t, \".I\"[is_idle_task(t)],\n\t\t \"N.\"[cpu < 0 || !tick_nohz_full_cpu(cpu)],\n\t\t t->rcu_tasks_nvcsw, t->nvcsw, t->rcu_tasks_holdout,\n\t\t t->rcu_tasks_idle_cpu, cpu);\n\tsched_show_task(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "t",
            "t1",
            "hop",
            "rcu_tasks_holdout_list"
          ],
          "line": 787
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void check_all_holdout_tasks(struct list_head *hop,\n\t\t\t\t    bool needreport, bool *firstreport)\n{\n\tstruct task_struct *t, *t1;\n\n\tlist_for_each_entry_safe(t, t1, hop, rcu_tasks_holdout_list) {\n\t\tcheck_holdout_task(t, needreport, firstreport);\n\t\tcond_resched();\n\t}\n}"
  },
  {
    "function_name": "check_holdout_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "750-779",
    "snippet": "static void check_holdout_task(struct task_struct *t,\n\t\t\t       bool needreport, bool *firstreport)\n{\n\tint cpu;\n\n\tif (!READ_ONCE(t->rcu_tasks_holdout) ||\n\t    t->rcu_tasks_nvcsw != READ_ONCE(t->nvcsw) ||\n\t    !READ_ONCE(t->on_rq) ||\n\t    (IS_ENABLED(CONFIG_NO_HZ_FULL) &&\n\t     !is_idle_task(t) && t->rcu_tasks_idle_cpu >= 0)) {\n\t\tWRITE_ONCE(t->rcu_tasks_holdout, false);\n\t\tlist_del_init(&t->rcu_tasks_holdout_list);\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\trcu_request_urgent_qs_task(t);\n\tif (!needreport)\n\t\treturn;\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tpr_alert(\"%p: %c%c nvcsw: %lu/%lu holdout: %d idle_cpu: %d/%d\\n\",\n\t\t t, \".I\"[is_idle_task(t)],\n\t\t \"N.\"[cpu < 0 || !tick_nohz_full_cpu(cpu)],\n\t\t t->rcu_tasks_nvcsw, t->nvcsw, t->rcu_tasks_holdout,\n\t\t t->rcu_tasks_idle_cpu, cpu);\n\tsched_show_task(t);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_show_task",
          "args": [
            "t"
          ],
          "line": 778
        },
        "resolved": true,
        "details": {
          "function_name": "sched_show_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8544-8572",
          "snippet": "void sched_show_task(struct task_struct *p)\n{\n\tunsigned long free = 0;\n\tint ppid;\n\n\tif (!try_get_task_stack(p))\n\t\treturn;\n\n\tpr_info(\"task:%-15.15s state:%c\", p->comm, task_state_to_char(p));\n\n\tif (task_is_running(p))\n\t\tpr_cont(\"  running task    \");\n#ifdef CONFIG_DEBUG_STACK_USAGE\n\tfree = stack_not_used(p);\n#endif\n\tppid = 0;\n\trcu_read_lock();\n\tif (pid_alive(p))\n\t\tppid = task_pid_nr(rcu_dereference(p->real_parent));\n\trcu_read_unlock();\n\tpr_cont(\" stack:%5lu pid:%5d ppid:%6d flags:0x%08lx\\n\",\n\t\tfree, task_pid_nr(p), ppid,\n\t\tread_task_thread_flags(p));\n\n\tprint_worker_info(KERN_INFO, p);\n\tprint_stop_info(KERN_INFO, p);\n\tshow_stack(p, NULL, KERN_INFO);\n\tput_task_stack(p);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid sched_show_task(struct task_struct *p)\n{\n\tunsigned long free = 0;\n\tint ppid;\n\n\tif (!try_get_task_stack(p))\n\t\treturn;\n\n\tpr_info(\"task:%-15.15s state:%c\", p->comm, task_state_to_char(p));\n\n\tif (task_is_running(p))\n\t\tpr_cont(\"  running task    \");\n#ifdef CONFIG_DEBUG_STACK_USAGE\n\tfree = stack_not_used(p);\n#endif\n\tppid = 0;\n\trcu_read_lock();\n\tif (pid_alive(p))\n\t\tppid = task_pid_nr(rcu_dereference(p->real_parent));\n\trcu_read_unlock();\n\tpr_cont(\" stack:%5lu pid:%5d ppid:%6d flags:0x%08lx\\n\",\n\t\tfree, task_pid_nr(p), ppid,\n\t\tread_task_thread_flags(p));\n\n\tprint_worker_info(KERN_INFO, p);\n\tprint_stop_info(KERN_INFO, p);\n\tshow_stack(p, NULL, KERN_INFO);\n\tput_task_stack(p);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_alert",
          "args": [
            "\"%p: %c%c nvcsw: %lu/%lu holdout: %d idle_cpu: %d/%d\\n\"",
            "t",
            "\".I\"[is_idle_task(t)]",
            "\"N.\"[cpu < 0 || !tick_nohz_full_cpu(cpu)]",
            "t->rcu_tasks_nvcsw",
            "t->nvcsw",
            "t->rcu_tasks_holdout",
            "t->rcu_tasks_idle_cpu",
            "cpu"
          ],
          "line": 773
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "tick_nohz_full_cpu",
          "args": [
            "cpu"
          ],
          "line": 775
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_idle_task",
          "args": [
            "t"
          ],
          "line": 774
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "task_cpu",
          "args": [
            "t"
          ],
          "line": 772
        },
        "resolved": true,
        "details": {
          "function_name": "ignore_task_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ftrace.c",
          "lines": "7612-7633",
          "snippet": "static void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}",
          "includes": [
            "#include \"trace_stat.h\"",
            "#include \"trace_output.h\"",
            "#include \"ftrace_internal.h\"",
            "#include <asm/setup.h>",
            "#include <asm/sections.h>",
            "#include <trace/events/sched.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/hash.h>",
            "#include <linux/list.h>",
            "#include <linux/sort.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/module.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/kthread.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/tracefs.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/security.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/clocksource.h>",
            "#include <linux/stop_machine.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"trace_stat.h\"\n#include \"trace_output.h\"\n#include \"ftrace_internal.h\"\n#include <asm/setup.h>\n#include <asm/sections.h>\n#include <trace/events/sched.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/hash.h>\n#include <linux/list.h>\n#include <linux/sort.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/sysctl.h>\n#include <linux/ftrace.h>\n#include <linux/module.h>\n#include <linux/bsearch.h>\n#include <linux/uaccess.h>\n#include <linux/kthread.h>\n#include <linux/hardirq.h>\n#include <linux/tracefs.h>\n#include <linux/seq_file.h>\n#include <linux/security.h>\n#include <linux/kallsyms.h>\n#include <linux/sched/task.h>\n#include <linux/clocksource.h>\n#include <linux/stop_machine.h>\n\nstatic void ignore_task_cpu(void *data)\n{\n\tstruct trace_array *tr = data;\n\tstruct trace_pid_list *pid_list;\n\tstruct trace_pid_list *no_pid_list;\n\n\t/*\n\t * This function is called by on_each_cpu() while the\n\t * event_mutex is held.\n\t */\n\tpid_list = rcu_dereference_protected(tr->function_pids,\n\t\t\t\t\t     mutex_is_locked(&ftrace_lock));\n\tno_pid_list = rcu_dereference_protected(tr->function_no_pids,\n\t\t\t\t\t\tmutex_is_locked(&ftrace_lock));\n\n\tif (trace_ignore_this_task(pid_list, no_pid_list, current))\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       FTRACE_PID_IGNORE);\n\telse\n\t\tthis_cpu_write(tr->array_buffer.data->ftrace_ignore_pid,\n\t\t\t       current->pid);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_err",
          "args": [
            "\"INFO: rcu_tasks detected stalls on tasks:\\n\""
          ],
          "line": 769
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_request_urgent_qs_task",
          "args": [
            "t"
          ],
          "line": 765
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_request_urgent_qs_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "433-433",
          "snippet": "static inline void rcu_request_urgent_qs_task(struct task_struct *t) { }",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline void rcu_request_urgent_qs_task(struct task_struct *t) { }"
        }
      },
      {
        "call_info": {
          "callee": "put_task_struct",
          "args": [
            "t"
          ],
          "line": 762
        },
        "resolved": true,
        "details": {
          "function_name": "__put_task_struct",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/fork.c",
          "lines": "745-761",
          "snippet": "void __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}",
          "includes": [
            "#include <linux/init_task.h>",
            "#include <trace/events/task.h>",
            "#include <trace/events/sched.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/cacheflush.h>",
            "#include <asm/mmu_context.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <linux/bpf.h>",
            "#include <linux/io_uring.h>",
            "#include <linux/scs.h>",
            "#include <linux/kasan.h>",
            "#include <linux/stackleak.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/kcov.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/compiler.h>",
            "#include <linux/aio.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/oom.h>",
            "#include <linux/user-return-notifier.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/magic.h>",
            "#include <linux/fs_struct.h>",
            "#include <linux/tty.h>",
            "#include <linux/random.h>",
            "#include <linux/taskstats_kern.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/tsacct_kern.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/acct.h>",
            "#include <linux/ksm.h>",
            "#include <linux/rmap.h>",
            "#include <linux/profile.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/audit.h>",
            "#include <linux/mount.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/task_io_accounting_ops.h>",
            "#include <linux/kthread.h>",
            "#include <linux/compat.h>",
            "#include <linux/futex.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/swap.h>",
            "#include <linux/seccomp.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/security.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/cpu.h>",
            "#include <linux/capability.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/mm.h>",
            "#include <linux/fs.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/mman.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/key.h>",
            "#include <linux/iocontext.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/file.h>",
            "#include <linux/sem.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/personality.h>",
            "#include <linux/completion.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/module.h>",
            "#include <linux/unistd.h>",
            "#include <linux/init.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/stat.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/autogroup.h>",
            "#include <linux/slab.h>",
            "#include <linux/anon_inodes.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __latent_entropy struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/init_task.h>\n#include <trace/events/task.h>\n#include <trace/events/sched.h>\n#include <asm/tlbflush.h>\n#include <asm/cacheflush.h>\n#include <asm/mmu_context.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <linux/bpf.h>\n#include <linux/io_uring.h>\n#include <linux/scs.h>\n#include <linux/kasan.h>\n#include <linux/stackleak.h>\n#include <linux/thread_info.h>\n#include <linux/livepatch.h>\n#include <linux/kcov.h>\n#include <linux/sysctl.h>\n#include <linux/compiler.h>\n#include <linux/aio.h>\n#include <linux/uprobes.h>\n#include <linux/signalfd.h>\n#include <linux/khugepaged.h>\n#include <linux/oom.h>\n#include <linux/user-return-notifier.h>\n#include <linux/posix-timers.h>\n#include <linux/perf_event.h>\n#include <linux/magic.h>\n#include <linux/fs_struct.h>\n#include <linux/tty.h>\n#include <linux/random.h>\n#include <linux/taskstats_kern.h>\n#include <linux/delayacct.h>\n#include <linux/freezer.h>\n#include <linux/cn_proc.h>\n#include <linux/tsacct_kern.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/acct.h>\n#include <linux/ksm.h>\n#include <linux/rmap.h>\n#include <linux/profile.h>\n#include <linux/proc_fs.h>\n#include <linux/ftrace.h>\n#include <linux/memcontrol.h>\n#include <linux/audit.h>\n#include <linux/mount.h>\n#include <linux/ptrace.h>\n#include <linux/rcupdate.h>\n#include <linux/task_io_accounting_ops.h>\n#include <linux/kthread.h>\n#include <linux/compat.h>\n#include <linux/futex.h>\n#include <linux/jiffies.h>\n#include <linux/syscalls.h>\n#include <linux/swap.h>\n#include <linux/seccomp.h>\n#include <linux/hugetlb.h>\n#include <linux/security.h>\n#include <linux/cgroup.h>\n#include <linux/cpu.h>\n#include <linux/capability.h>\n#include <linux/nsproxy.h>\n#include <linux/vmacache.h>\n#include <linux/mm_inline.h>\n#include <linux/mm.h>\n#include <linux/fs.h>\n#include <linux/mmu_notifier.h>\n#include <linux/mman.h>\n#include <linux/binfmts.h>\n#include <linux/key.h>\n#include <linux/iocontext.h>\n#include <linux/fdtable.h>\n#include <linux/file.h>\n#include <linux/sem.h>\n#include <linux/mempolicy.h>\n#include <linux/personality.h>\n#include <linux/completion.h>\n#include <linux/vmalloc.h>\n#include <linux/module.h>\n#include <linux/unistd.h>\n#include <linux/init.h>\n#include <linux/rtmutex.h>\n#include <linux/seq_file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/stat.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/user.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/autogroup.h>\n#include <linux/slab.h>\n#include <linux/anon_inodes.h>\n\nstatic __latent_entropy struct;\n\nvoid __put_task_struct(struct task_struct *tsk)\n{\n\tWARN_ON(!tsk->exit_state);\n\tWARN_ON(refcount_read(&tsk->usage));\n\tWARN_ON(tsk == current);\n\n\tio_uring_free(tsk);\n\tcgroup_free(tsk);\n\ttask_numa_free(tsk, true);\n\tsecurity_task_free(tsk);\n\tbpf_task_storage_free(tsk);\n\texit_creds(tsk);\n\tdelayacct_tsk_free(tsk);\n\tput_signal_struct(tsk->signal);\n\tsched_core_free(tsk);\n\tfree_task(tsk);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&t->rcu_tasks_holdout_list"
          ],
          "line": 761
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->rcu_tasks_holdout",
            "false"
          ],
          "line": 760
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_idle_task",
          "args": [
            "t"
          ],
          "line": 759
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_NO_HZ_FULL"
          ],
          "line": 758
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->on_rq"
          ],
          "line": 757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->nvcsw"
          ],
          "line": 756
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->rcu_tasks_holdout"
          ],
          "line": 755
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void check_holdout_task(struct task_struct *t,\n\t\t\t       bool needreport, bool *firstreport)\n{\n\tint cpu;\n\n\tif (!READ_ONCE(t->rcu_tasks_holdout) ||\n\t    t->rcu_tasks_nvcsw != READ_ONCE(t->nvcsw) ||\n\t    !READ_ONCE(t->on_rq) ||\n\t    (IS_ENABLED(CONFIG_NO_HZ_FULL) &&\n\t     !is_idle_task(t) && t->rcu_tasks_idle_cpu >= 0)) {\n\t\tWRITE_ONCE(t->rcu_tasks_holdout, false);\n\t\tlist_del_init(&t->rcu_tasks_holdout_list);\n\t\tput_task_struct(t);\n\t\treturn;\n\t}\n\trcu_request_urgent_qs_task(t);\n\tif (!needreport)\n\t\treturn;\n\tif (*firstreport) {\n\t\tpr_err(\"INFO: rcu_tasks detected stalls on tasks:\\n\");\n\t\t*firstreport = false;\n\t}\n\tcpu = task_cpu(t);\n\tpr_alert(\"%p: %c%c nvcsw: %lu/%lu holdout: %d idle_cpu: %d/%d\\n\",\n\t\t t, \".I\"[is_idle_task(t)],\n\t\t \"N.\"[cpu < 0 || !tick_nohz_full_cpu(cpu)],\n\t\t t->rcu_tasks_nvcsw, t->nvcsw, t->rcu_tasks_holdout,\n\t\t t->rcu_tasks_idle_cpu, cpu);\n\tsched_show_task(t);\n}"
  },
  {
    "function_name": "rcu_tasks_postscan",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "737-747",
    "snippet": "static void rcu_tasks_postscan(struct list_head *hop)\n{\n\t/*\n\t * Wait for tasks that are in the process of exiting.  This\n\t * does only part of the job, ensuring that all tasks that were\n\t * previously exiting reach the point where they have disabled\n\t * preemption, allowing the later synchronize_rcu() to finish\n\t * the job.\n\t */\n\tsynchronize_srcu(&tasks_rcu_exit_srcu);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_srcu",
          "args": [
            "&tasks_rcu_exit_srcu"
          ],
          "line": 746
        },
        "resolved": true,
        "details": {
          "function_name": "start_poll_synchronize_srcu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/srcutree.c",
          "lines": "1044-1047",
          "snippet": "unsigned long start_poll_synchronize_srcu(struct srcu_struct *ssp)\n{\n\treturn srcu_gp_start_if_needed(ssp, NULL, true);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include \"rcu.h\"",
            "#include <linux/srcu.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/smp.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/preempt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include \"rcu.h\"\n#include <linux/srcu.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/smp.h>\n#include <linux/sched.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/preempt.h>\n#include <linux/percpu.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n\nunsigned long start_poll_synchronize_srcu(struct srcu_struct *ssp)\n{\n\treturn srcu_gp_start_if_needed(ssp, NULL, true);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_postscan(struct list_head *hop)\n{\n\t/*\n\t * Wait for tasks that are in the process of exiting.  This\n\t * does only part of the job, ensuring that all tasks that were\n\t * previously exiting reach the point where they have disabled\n\t * preemption, allowing the later synchronize_rcu() to finish\n\t * the job.\n\t */\n\tsynchronize_srcu(&tasks_rcu_exit_srcu);\n}"
  },
  {
    "function_name": "rcu_tasks_pertask",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "726-734",
    "snippet": "static void rcu_tasks_pertask(struct task_struct *t, struct list_head *hop)\n{\n\tif (t != current && READ_ONCE(t->on_rq) && !is_idle_task(t)) {\n\t\tget_task_struct(t);\n\t\tt->rcu_tasks_nvcsw = READ_ONCE(t->nvcsw);\n\t\tWRITE_ONCE(t->rcu_tasks_holdout, true);\n\t\tlist_add(&t->rcu_tasks_holdout_list, hop);\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&t->rcu_tasks_holdout_list",
            "hop"
          ],
          "line": 732
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_add_len",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "210-221",
          "snippet": "void rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->rcu_tasks_holdout",
            "true"
          ],
          "line": 731
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->nvcsw"
          ],
          "line": 730
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_task_struct",
          "args": [
            "t"
          ],
          "line": 729
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_idle_task",
          "args": [
            "t"
          ],
          "line": 728
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->on_rq"
          ],
          "line": 728
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_pertask(struct task_struct *t, struct list_head *hop)\n{\n\tif (t != current && READ_ONCE(t->on_rq) && !is_idle_task(t)) {\n\t\tget_task_struct(t);\n\t\tt->rcu_tasks_nvcsw = READ_ONCE(t->nvcsw);\n\t\tWRITE_ONCE(t->rcu_tasks_holdout, true);\n\t\tlist_add(&t->rcu_tasks_holdout_list, hop);\n\t}\n}"
  },
  {
    "function_name": "rcu_tasks_pregp_step",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "707-723",
    "snippet": "static void rcu_tasks_pregp_step(void)\n{\n\t/*\n\t * Wait for all pre-existing t->on_rq and t->nvcsw transitions\n\t * to complete.  Invoking synchronize_rcu() suffices because all\n\t * these transitions occur with interrupts disabled.  Without this\n\t * synchronize_rcu(), a read-side critical section that started\n\t * before the grace period might be incorrectly seen as having\n\t * started after the grace period.\n\t *\n\t * This synchronize_rcu() also dispenses with the need for a\n\t * memory barrier on the first store to t->rcu_tasks_holdout,\n\t * as it forces the store to happen after the beginning of the\n\t * grace period.\n\t */\n\tsynchronize_rcu();\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 722
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1556-1560",
          "snippet": "void synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid synchronize_rcu_tasks_trace(void)\n{\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_trace_lock_map), \"Illegal synchronize_rcu_tasks_trace() in RCU Tasks Trace read-side critical section\");\n\tsynchronize_rcu_tasks_generic(&rcu_tasks_trace);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_pregp_step(void)\n{\n\t/*\n\t * Wait for all pre-existing t->on_rq and t->nvcsw transitions\n\t * to complete.  Invoking synchronize_rcu() suffices because all\n\t * these transitions occur with interrupts disabled.  Without this\n\t * synchronize_rcu(), a read-side critical section that started\n\t * before the grace period might be incorrectly seen as having\n\t * started after the grace period.\n\t *\n\t * This synchronize_rcu() also dispenses with the need for a\n\t * memory barrier on the first store to t->rcu_tasks_holdout,\n\t * as it forces the store to happen after the beginning of the\n\t * grace period.\n\t */\n\tsynchronize_rcu();\n}"
  },
  {
    "function_name": "rcu_tasks_wait_gp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "589-648",
    "snippet": "static void rcu_tasks_wait_gp(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *g, *t;\n\tunsigned long lastreport;\n\tLIST_HEAD(holdouts);\n\tint fract;\n\n\tset_tasks_gp_state(rtp, RTGS_PRE_WAIT_GP);\n\trtp->pregp_func();\n\n\t/*\n\t * There were callbacks, so we need to wait for an RCU-tasks\n\t * grace period.  Start off by scanning the task list for tasks\n\t * that are not already voluntarily blocked.  Mark these tasks\n\t * and make a list of them in holdouts.\n\t */\n\tset_tasks_gp_state(rtp, RTGS_SCAN_TASKLIST);\n\trcu_read_lock();\n\tfor_each_process_thread(g, t)\n\t\trtp->pertask_func(t, &holdouts);\n\trcu_read_unlock();\n\n\tset_tasks_gp_state(rtp, RTGS_POST_SCAN_TASKLIST);\n\trtp->postscan_func(&holdouts);\n\n\t/*\n\t * Each pass through the following loop scans the list of holdout\n\t * tasks, removing any that are no longer holdouts.  When the list\n\t * is empty, we are done.\n\t */\n\tlastreport = jiffies;\n\n\t// Start off with initial wait and slowly back off to 1 HZ wait.\n\tfract = rtp->init_fract;\n\n\twhile (!list_empty(&holdouts)) {\n\t\tbool firstreport;\n\t\tbool needreport;\n\t\tint rtst;\n\n\t\t/* Slowly back off waiting for holdouts */\n\t\tset_tasks_gp_state(rtp, RTGS_WAIT_SCAN_HOLDOUTS);\n\t\tschedule_timeout_idle(fract);\n\n\t\tif (fract < HZ)\n\t\t\tfract++;\n\n\t\trtst = READ_ONCE(rcu_task_stall_timeout);\n\t\tneedreport = rtst > 0 && time_after(jiffies, lastreport + rtst);\n\t\tif (needreport)\n\t\t\tlastreport = jiffies;\n\t\tfirstreport = true;\n\t\tWARN_ON(signal_pending(current));\n\t\tset_tasks_gp_state(rtp, RTGS_SCAN_HOLDOUTS);\n\t\trtp->holdouts_func(&holdouts, needreport, &firstreport);\n\t}\n\n\tset_tasks_gp_state(rtp, RTGS_POST_GP);\n\trtp->postgp_func(rtp);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [
      "#define RTGS_POST_GP\t\t 8",
      "#define RTGS_SCAN_HOLDOUTS\t 7",
      "#define RTGS_WAIT_SCAN_HOLDOUTS\t 6",
      "#define RTGS_POST_SCAN_TASKLIST\t 5",
      "#define RTGS_SCAN_TASKLIST\t 4",
      "#define RTGS_PRE_WAIT_GP\t 3"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rtp->postgp_func",
          "args": [
            "rtp"
          ],
          "line": 647
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_tasks_gp_state",
          "args": [
            "rtp",
            "RTGS_POST_GP"
          ],
          "line": 646
        },
        "resolved": true,
        "details": {
          "function_name": "set_tasks_gp_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "193-197",
          "snippet": "static void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtp->holdouts_func",
          "args": [
            "&holdouts",
            "needreport",
            "&firstreport"
          ],
          "line": 643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "signal_pending(current)"
          ],
          "line": 641
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "signal_pending",
          "args": [
            "current"
          ],
          "line": 641
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "time_after",
          "args": [
            "jiffies",
            "lastreport + rtst"
          ],
          "line": 637
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rcu_task_stall_timeout"
          ],
          "line": 636
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule_timeout_idle",
          "args": [
            "fract"
          ],
          "line": 631
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_timeout_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/timer.c",
          "lines": "1923-1927",
          "snippet": "signed long __sched schedule_timeout_idle(signed long timeout)\n{\n\t__set_current_state(TASK_IDLE);\n\treturn schedule_timeout(timeout);\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/io.h>",
            "#include <asm/timex.h>",
            "#include <asm/div64.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/random.h>",
            "#include <linux/compat.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/tick.h>",
            "#include <linux/delay.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cpu.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/time.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/notifier.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/io.h>\n#include <asm/timex.h>\n#include <asm/div64.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/random.h>\n#include <linux/compat.h>\n#include <linux/slab.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/irq_work.h>\n#include <linux/kallsyms.h>\n#include <linux/tick.h>\n#include <linux/delay.h>\n#include <linux/syscalls.h>\n#include <linux/cpu.h>\n#include <linux/posix-timers.h>\n#include <linux/jiffies.h>\n#include <linux/time.h>\n#include <linux/thread_info.h>\n#include <linux/notifier.h>\n#include <linux/pid_namespace.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/kernel_stat.h>\n\nsigned long __sched schedule_timeout_idle(signed long timeout)\n{\n\t__set_current_state(TASK_IDLE);\n\treturn schedule_timeout(timeout);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&holdouts"
          ],
          "line": 624
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtp->postscan_func",
          "args": [
            "&holdouts"
          ],
          "line": 612
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 609
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "for_each_process_thread",
          "args": [
            "t",
            "&holdouts"
          ],
          "line": 607
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_process_thread",
          "args": [
            "g",
            "t"
          ],
          "line": 607
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 606
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtp->pregp_func",
          "args": [],
          "line": 597
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LIST_HEAD",
          "args": [
            "holdouts"
          ],
          "line": 593
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\n#define RTGS_POST_GP\t\t 8\n#define RTGS_SCAN_HOLDOUTS\t 7\n#define RTGS_WAIT_SCAN_HOLDOUTS\t 6\n#define RTGS_POST_SCAN_TASKLIST\t 5\n#define RTGS_SCAN_TASKLIST\t 4\n#define RTGS_PRE_WAIT_GP\t 3\n\nstatic void rcu_tasks_wait_gp(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *g, *t;\n\tunsigned long lastreport;\n\tLIST_HEAD(holdouts);\n\tint fract;\n\n\tset_tasks_gp_state(rtp, RTGS_PRE_WAIT_GP);\n\trtp->pregp_func();\n\n\t/*\n\t * There were callbacks, so we need to wait for an RCU-tasks\n\t * grace period.  Start off by scanning the task list for tasks\n\t * that are not already voluntarily blocked.  Mark these tasks\n\t * and make a list of them in holdouts.\n\t */\n\tset_tasks_gp_state(rtp, RTGS_SCAN_TASKLIST);\n\trcu_read_lock();\n\tfor_each_process_thread(g, t)\n\t\trtp->pertask_func(t, &holdouts);\n\trcu_read_unlock();\n\n\tset_tasks_gp_state(rtp, RTGS_POST_SCAN_TASKLIST);\n\trtp->postscan_func(&holdouts);\n\n\t/*\n\t * Each pass through the following loop scans the list of holdout\n\t * tasks, removing any that are no longer holdouts.  When the list\n\t * is empty, we are done.\n\t */\n\tlastreport = jiffies;\n\n\t// Start off with initial wait and slowly back off to 1 HZ wait.\n\tfract = rtp->init_fract;\n\n\twhile (!list_empty(&holdouts)) {\n\t\tbool firstreport;\n\t\tbool needreport;\n\t\tint rtst;\n\n\t\t/* Slowly back off waiting for holdouts */\n\t\tset_tasks_gp_state(rtp, RTGS_WAIT_SCAN_HOLDOUTS);\n\t\tschedule_timeout_idle(fract);\n\n\t\tif (fract < HZ)\n\t\t\tfract++;\n\n\t\trtst = READ_ONCE(rcu_task_stall_timeout);\n\t\tneedreport = rtst > 0 && time_after(jiffies, lastreport + rtst);\n\t\tif (needreport)\n\t\t\tlastreport = jiffies;\n\t\tfirstreport = true;\n\t\tWARN_ON(signal_pending(current));\n\t\tset_tasks_gp_state(rtp, RTGS_SCAN_HOLDOUTS);\n\t\trtp->holdouts_func(&holdouts, needreport, &firstreport);\n\t}\n\n\tset_tasks_gp_state(rtp, RTGS_POST_GP);\n\trtp->postgp_func(rtp);\n}"
  },
  {
    "function_name": "show_rcu_tasks_generic_gp_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "565-577",
    "snippet": "static void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\"",
            "rtp->kname",
            "tasks_gp_state_getname(rtp)",
            "data_race(rtp->gp_state)",
            "jiffies - data_race(rtp->gp_jiffies)",
            "data_race(rcu_seq_current(&rtp->tasks_gp_seq))",
            "data_race(rtp->n_ipis_fails)",
            "data_race(rtp->n_ipis)",
            "\".k\"[!!data_race(rtp->kthread_ptr)]",
            "\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))]",
            "s"
          ],
          "line": 568
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_race",
          "args": [
            "rcu_segcblist_empty(&rtpcp->cblist)"
          ],
          "line": 575
        },
        "resolved": true,
        "details": {
          "function_name": "test_data_race",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/kcsan_test.c",
          "lines": "998-1008",
          "snippet": "__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}",
          "includes": [
            "#include <trace/events/printk.h>",
            "#include <linux/types.h>",
            "#include <linux/tracepoint.h>",
            "#include <linux/torture.h>",
            "#include <linux/timer.h>",
            "#include <linux/string.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kcsan-checks.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <kunit/test.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline const struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/printk.h>\n#include <linux/types.h>\n#include <linux/tracepoint.h>\n#include <linux/torture.h>\n#include <linux/timer.h>\n#include <linux/string.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n#include <linux/kernel.h>\n#include <linux/kcsan-checks.h>\n#include <linux/jiffies.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <kunit/test.h>\n\nstatic __always_inline const struct;\n\n__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_empty",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 575
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_current",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 572
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "97-100",
          "snippet": "static inline unsigned long rcu_seq_current(unsigned long *sp)\n{\n\treturn READ_ONCE(*sp);\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline unsigned long rcu_seq_current(unsigned long *sp)\n{\n\treturn READ_ONCE(*sp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "tasks_gp_state_getname",
          "args": [
            "rtp"
          ],
          "line": 570
        },
        "resolved": true,
        "details": {
          "function_name": "tasks_gp_state_getname",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "201-209",
          "snippet": "static const char *tasks_gp_state_getname(struct rcu_tasks *rtp)\n{\n\tint i = data_race(rtp->gp_state); // Let KCSAN detect update races\n\tint j = READ_ONCE(i); // Prevent the compiler from reading twice\n\n\tif (j >= ARRAY_SIZE(rcu_tasks_gp_state_names))\n\t\treturn \"???\";\n\treturn rcu_tasks_gp_state_names[j];\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic const char *tasks_gp_state_getname(struct rcu_tasks *rtp)\n{\n\tint i = data_race(rtp->gp_state); // Let KCSAN detect update races\n\tint j = READ_ONCE(i); // Prevent the compiler from reading twice\n\n\tif (j >= ARRAY_SIZE(rcu_tasks_gp_state_names))\n\t\treturn \"???\";\n\treturn rcu_tasks_gp_state_names[j];\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "0"
          ],
          "line": 567
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void show_rcu_tasks_generic_gp_kthread(struct rcu_tasks *rtp, char *s)\n{\n\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, 0); // for_each...\n\tpr_info(\"%s: %s(%d) since %lu g:%lu i:%lu/%lu %c%c %s\\n\",\n\t\trtp->kname,\n\t\ttasks_gp_state_getname(rtp), data_race(rtp->gp_state),\n\t\tjiffies - data_race(rtp->gp_jiffies),\n\t\tdata_race(rcu_seq_current(&rtp->tasks_gp_seq)),\n\t\tdata_race(rtp->n_ipis_fails), data_race(rtp->n_ipis),\n\t\t\".k\"[!!data_race(rtp->kthread_ptr)],\n\t\t\".C\"[!data_race(rcu_segcblist_empty(&rtpcp->cblist))],\n\t\ts);\n}"
  },
  {
    "function_name": "rcu_tasks_bootup_oddness",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "544-559",
    "snippet": "static void __init rcu_tasks_bootup_oddness(void)\n{\n#if defined(CONFIG_TASKS_RCU) || defined(CONFIG_TASKS_TRACE_RCU)\n\tif (rcu_task_stall_timeout != RCU_TASK_STALL_TIMEOUT)\n\t\tpr_info(\"\\tTasks-RCU CPU stall warnings timeout set to %d (rcu_task_stall_timeout).\\n\", rcu_task_stall_timeout);\n#endif /* #ifdef CONFIG_TASKS_RCU */\n#ifdef CONFIG_TASKS_RCU\n\tpr_info(\"\\tTrampoline variant of Tasks RCU enabled.\\n\");\n#endif /* #ifdef CONFIG_TASKS_RCU */\n#ifdef CONFIG_TASKS_RUDE_RCU\n\tpr_info(\"\\tRude variant of Tasks RCU enabled.\\n\");\n#endif /* #ifdef CONFIG_TASKS_RUDE_RCU */\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tpr_info(\"\\tTracing variant of Tasks RCU enabled.\\n\");\n#endif /* #ifdef CONFIG_TASKS_TRACE_RCU */\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [
      "#define RCU_TASK_STALL_TIMEOUT (HZ * 60 * 10)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tTracing variant of Tasks RCU enabled.\\n\""
          ],
          "line": 557
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRude variant of Tasks RCU enabled.\\n\""
          ],
          "line": 554
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tTrampoline variant of Tasks RCU enabled.\\n\""
          ],
          "line": 551
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tTasks-RCU CPU stall warnings timeout set to %d (rcu_task_stall_timeout).\\n\"",
            "rcu_task_stall_timeout"
          ],
          "line": 548
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\n#define RCU_TASK_STALL_TIMEOUT (HZ * 60 * 10)\n\nstatic void __init rcu_tasks_bootup_oddness(void)\n{\n#if defined(CONFIG_TASKS_RCU) || defined(CONFIG_TASKS_TRACE_RCU)\n\tif (rcu_task_stall_timeout != RCU_TASK_STALL_TIMEOUT)\n\t\tpr_info(\"\\tTasks-RCU CPU stall warnings timeout set to %d (rcu_task_stall_timeout).\\n\", rcu_task_stall_timeout);\n#endif /* #ifdef CONFIG_TASKS_RCU */\n#ifdef CONFIG_TASKS_RCU\n\tpr_info(\"\\tTrampoline variant of Tasks RCU enabled.\\n\");\n#endif /* #ifdef CONFIG_TASKS_RCU */\n#ifdef CONFIG_TASKS_RUDE_RCU\n\tpr_info(\"\\tRude variant of Tasks RCU enabled.\\n\");\n#endif /* #ifdef CONFIG_TASKS_RUDE_RCU */\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tpr_info(\"\\tTracing variant of Tasks RCU enabled.\\n\");\n#endif /* #ifdef CONFIG_TASKS_TRACE_RCU */\n}"
  },
  {
    "function_name": "rcu_spawn_tasks_kthread_generic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "529-537",
    "snippet": "static void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 536
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ONCE",
          "args": [
            "IS_ERR(t)",
            "\"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\"",
            "__func__",
            "rtp->name"
          ],
          "line": 534
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "t"
          ],
          "line": 534
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_run",
          "args": [
            "rcu_tasks_kthread",
            "rtp",
            "\"%s_kthread\"",
            "rtp->kname"
          ],
          "line": 533
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void __init rcu_spawn_tasks_kthread_generic(struct rcu_tasks *rtp)\n{\n\tstruct task_struct *t;\n\n\tt = kthread_run(rcu_tasks_kthread, rtp, \"%s_kthread\", rtp->kname);\n\tif (WARN_ONCE(IS_ERR(t), \"%s: Could not start %s grace-period kthread, OOM is now expected behavior\\n\", __func__, rtp->name))\n\t\treturn;\n\tsmp_mb(); /* Ensure others see full kthread. */\n}"
  },
  {
    "function_name": "rcu_tasks_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "489-526",
    "snippet": "static int __noreturn rcu_tasks_kthread(void *arg)\n{\n\tint needgpcb;\n\tstruct rcu_tasks *rtp = arg;\n\n\t/* Run on housekeeping CPUs by default.  Sysadm can move if desired. */\n\thousekeeping_affine(current, HK_FLAG_RCU);\n\tWRITE_ONCE(rtp->kthread_ptr, current); // Let GPs start!\n\n\t/*\n\t * Each pass through the following loop makes one check for\n\t * newly arrived callbacks, and, if there are some, waits for\n\t * one RCU-tasks grace period and then invokes the callbacks.\n\t * This loop is terminated by the system going down.  ;-)\n\t */\n\tfor (;;) {\n\t\tset_tasks_gp_state(rtp, RTGS_WAIT_CBS);\n\n\t\t/* If there were none, wait a bit and start over. */\n\t\twait_event_idle(rtp->cbs_wq, (needgpcb = rcu_tasks_need_gpcb(rtp)));\n\n\t\tif (needgpcb & 0x2) {\n\t\t\t// Wait for one grace period.\n\t\t\tset_tasks_gp_state(rtp, RTGS_WAIT_GP);\n\t\t\trtp->gp_start = jiffies;\n\t\t\trcu_seq_start(&rtp->tasks_gp_seq);\n\t\t\trtp->gp_func(rtp);\n\t\t\trcu_seq_end(&rtp->tasks_gp_seq);\n\t\t}\n\n\t\t/* Invoke callbacks. */\n\t\tset_tasks_gp_state(rtp, RTGS_INVOKE_CBS);\n\t\trcu_tasks_invoke_cbs(rtp, per_cpu_ptr(rtp->rtpcpu, 0));\n\n\t\t/* Paranoid sleep to keep this from entering a tight loop */\n\t\tschedule_timeout_idle(rtp->gp_sleep);\n\t}\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [
      "#define RTGS_WAIT_CBS\t\t11",
      "#define RTGS_INVOKE_CBS\t\t10",
      "#define RTGS_WAIT_GP\t\t 2"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_timeout_idle",
          "args": [
            "rtp->gp_sleep"
          ],
          "line": 524
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_timeout_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/timer.c",
          "lines": "1923-1927",
          "snippet": "signed long __sched schedule_timeout_idle(signed long timeout)\n{\n\t__set_current_state(TASK_IDLE);\n\treturn schedule_timeout(timeout);\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/io.h>",
            "#include <asm/timex.h>",
            "#include <asm/div64.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/random.h>",
            "#include <linux/compat.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/tick.h>",
            "#include <linux/delay.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cpu.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/time.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/notifier.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/io.h>\n#include <asm/timex.h>\n#include <asm/div64.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/random.h>\n#include <linux/compat.h>\n#include <linux/slab.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/irq_work.h>\n#include <linux/kallsyms.h>\n#include <linux/tick.h>\n#include <linux/delay.h>\n#include <linux/syscalls.h>\n#include <linux/cpu.h>\n#include <linux/posix-timers.h>\n#include <linux/jiffies.h>\n#include <linux/time.h>\n#include <linux/thread_info.h>\n#include <linux/notifier.h>\n#include <linux/pid_namespace.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/kernel_stat.h>\n\nsigned long __sched schedule_timeout_idle(signed long timeout)\n{\n\t__set_current_state(TASK_IDLE);\n\treturn schedule_timeout(timeout);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_tasks_invoke_cbs",
          "args": [
            "rtp",
            "per_cpu_ptr(rtp->rtpcpu, 0)"
          ],
          "line": 521
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_tasks_invoke_cbs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "437-476",
          "snippet": "static void rcu_tasks_invoke_cbs(struct rcu_tasks *rtp, struct rcu_tasks_percpu *rtpcp)\n{\n\tint cpu;\n\tint cpunext;\n\tunsigned long flags;\n\tint len;\n\tstruct rcu_head *rhp;\n\tstruct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);\n\tstruct rcu_tasks_percpu *rtpcp_next;\n\n\tcpu = rtpcp->cpu;\n\tcpunext = cpu * 2 + 1;\n\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\tcpunext++;\n\t\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\t}\n\t}\n\n\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\treturn;\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\trcu_segcblist_extract_done_cbs(&rtpcp->cblist, &rcl);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tlen = rcl.len;\n\tfor (rhp = rcu_cblist_dequeue(&rcl); rhp; rhp = rcu_cblist_dequeue(&rcl)) {\n\t\tlocal_bh_disable();\n\t\trhp->func(rhp);\n\t\tlocal_bh_enable();\n\t\tcond_resched();\n\t}\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_add_len(&rtpcp->cblist, -len);\n\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_invoke_cbs(struct rcu_tasks *rtp, struct rcu_tasks_percpu *rtpcp)\n{\n\tint cpu;\n\tint cpunext;\n\tunsigned long flags;\n\tint len;\n\tstruct rcu_head *rhp;\n\tstruct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);\n\tstruct rcu_tasks_percpu *rtpcp_next;\n\n\tcpu = rtpcp->cpu;\n\tcpunext = cpu * 2 + 1;\n\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\tcpunext++;\n\t\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\t}\n\t}\n\n\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\treturn;\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\trcu_segcblist_extract_done_cbs(&rtpcp->cblist, &rcl);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tlen = rcl.len;\n\tfor (rhp = rcu_cblist_dequeue(&rcl); rhp; rhp = rcu_cblist_dequeue(&rcl)) {\n\t\tlocal_bh_disable();\n\t\trhp->func(rhp);\n\t\tlocal_bh_enable();\n\t\tcond_resched();\n\t}\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_add_len(&rtpcp->cblist, -len);\n\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "0"
          ],
          "line": 521
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_tasks_gp_state",
          "args": [
            "rtp",
            "RTGS_INVOKE_CBS"
          ],
          "line": 520
        },
        "resolved": true,
        "details": {
          "function_name": "set_tasks_gp_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "193-197",
          "snippet": "static void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_end",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 516
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "69-74",
          "snippet": "static inline void rcu_seq_end(unsigned long *sp)\n{\n\tsmp_mb(); /* Ensure update-side operation before counter increment. */\n\tWARN_ON_ONCE(!rcu_seq_state(*sp));\n\tWRITE_ONCE(*sp, rcu_seq_endval(sp));\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline void rcu_seq_end(unsigned long *sp)\n{\n\tsmp_mb(); /* Ensure update-side operation before counter increment. */\n\tWARN_ON_ONCE(!rcu_seq_state(*sp));\n\tWRITE_ONCE(*sp, rcu_seq_endval(sp));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rtp->gp_func",
          "args": [
            "rtp"
          ],
          "line": 515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_seq_start",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 514
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "55-60",
          "snippet": "static inline void rcu_seq_start(unsigned long *sp)\n{\n\tWRITE_ONCE(*sp, *sp + 1);\n\tsmp_mb(); /* Ensure update-side operation after counter increment. */\n\tWARN_ON_ONCE(rcu_seq_state(*sp) != 1);\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline void rcu_seq_start(unsigned long *sp)\n{\n\tWRITE_ONCE(*sp, *sp + 1);\n\tsmp_mb(); /* Ensure update-side operation after counter increment. */\n\tWARN_ON_ONCE(rcu_seq_state(*sp) != 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "wait_event_idle",
          "args": [
            "rtp->cbs_wq",
            "(needgpcb = rcu_tasks_need_gpcb(rtp))"
          ],
          "line": 508
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_tasks_need_gpcb",
          "args": [
            "rtp"
          ],
          "line": 508
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_tasks_need_gpcb",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "374-434",
          "snippet": "static int rcu_tasks_need_gpcb(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tlong n;\n\tlong ncbs = 0;\n\tlong ncbsnz = 0;\n\tint needgpcb = 0;\n\n\tfor (cpu = 0; cpu < smp_load_acquire(&rtp->percpu_dequeue_lim); cpu++) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\t/* Advance and accelerate any new callbacks. */\n\t\tif (!rcu_segcblist_n_cbs(&rtpcp->cblist))\n\t\t\tcontinue;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\t// Should we shrink down to a single callback queue?\n\t\tn = rcu_segcblist_n_cbs(&rtpcp->cblist);\n\t\tif (n) {\n\t\t\tncbs += n;\n\t\t\tif (cpu > 0)\n\t\t\t\tncbsnz += n;\n\t\t}\n\t\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\t\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\t\tif (rcu_segcblist_pend_cbs(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x3;\n\t\tif (!rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x1;\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\n\t// Shrink down to a single callback queue if appropriate.\n\t// This is done in two stages: (1) If there are no more than\n\t// rcu_task_collapse_lim callbacks on CPU 0 and none on any other\n\t// CPU, limit enqueueing to CPU 0.  (2) After an RCU grace period,\n\t// if there has not been an increase in callbacks, limit dequeuing\n\t// to CPU 0.  Note the matching RCU read-side critical section in\n\t// call_rcu_tasks_generic().\n\tif (rcu_task_cb_adjust && ncbs <= rcu_task_collapse_lim) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim > 1) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, 1);\n\t\t\trtp->percpu_dequeue_gpseq = get_state_synchronize_rcu();\n\t\t\tpr_info(\"Starting switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\tif (rcu_task_cb_adjust && !ncbsnz &&\n\t    poll_state_synchronize_rcu(rtp->percpu_dequeue_gpseq)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim < rtp->percpu_dequeue_lim) {\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, 1);\n\t\t\tpr_info(\"Completing switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\n\treturn needgpcb;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int rcu_tasks_need_gpcb(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tlong n;\n\tlong ncbs = 0;\n\tlong ncbsnz = 0;\n\tint needgpcb = 0;\n\n\tfor (cpu = 0; cpu < smp_load_acquire(&rtp->percpu_dequeue_lim); cpu++) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\t/* Advance and accelerate any new callbacks. */\n\t\tif (!rcu_segcblist_n_cbs(&rtpcp->cblist))\n\t\t\tcontinue;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\t// Should we shrink down to a single callback queue?\n\t\tn = rcu_segcblist_n_cbs(&rtpcp->cblist);\n\t\tif (n) {\n\t\t\tncbs += n;\n\t\t\tif (cpu > 0)\n\t\t\t\tncbsnz += n;\n\t\t}\n\t\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\t\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\t\tif (rcu_segcblist_pend_cbs(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x3;\n\t\tif (!rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x1;\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\n\t// Shrink down to a single callback queue if appropriate.\n\t// This is done in two stages: (1) If there are no more than\n\t// rcu_task_collapse_lim callbacks on CPU 0 and none on any other\n\t// CPU, limit enqueueing to CPU 0.  (2) After an RCU grace period,\n\t// if there has not been an increase in callbacks, limit dequeuing\n\t// to CPU 0.  Note the matching RCU read-side critical section in\n\t// call_rcu_tasks_generic().\n\tif (rcu_task_cb_adjust && ncbs <= rcu_task_collapse_lim) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim > 1) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, 1);\n\t\t\trtp->percpu_dequeue_gpseq = get_state_synchronize_rcu();\n\t\t\tpr_info(\"Starting switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\tif (rcu_task_cb_adjust && !ncbsnz &&\n\t    poll_state_synchronize_rcu(rtp->percpu_dequeue_gpseq)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim < rtp->percpu_dequeue_lim) {\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, 1);\n\t\t\tpr_info(\"Completing switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\n\treturn needgpcb;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->kthread_ptr",
            "current"
          ],
          "line": 496
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "housekeeping_affine",
          "args": [
            "current",
            "HK_FLAG_RCU"
          ],
          "line": 495
        },
        "resolved": true,
        "details": {
          "function_name": "housekeeping_affine",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/isolation.c",
          "lines": "49-54",
          "snippet": "void housekeeping_affine(struct task_struct *t, enum hk_flags flags)\n{\n\tif (static_branch_unlikely(&housekeeping_overridden))\n\t\tif (housekeeping_flags & flags)\n\t\t\tset_cpus_allowed_ptr(t, housekeeping_mask);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static cpumask_var_t housekeeping_mask;",
            "static unsigned int housekeeping_flags;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic cpumask_var_t housekeeping_mask;\nstatic unsigned int housekeeping_flags;\n\nvoid housekeeping_affine(struct task_struct *t, enum hk_flags flags)\n{\n\tif (static_branch_unlikely(&housekeeping_overridden))\n\t\tif (housekeeping_flags & flags)\n\t\t\tset_cpus_allowed_ptr(t, housekeeping_mask);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\n#define RTGS_WAIT_CBS\t\t11\n#define RTGS_INVOKE_CBS\t\t10\n#define RTGS_WAIT_GP\t\t 2\n\nstatic int __noreturn rcu_tasks_kthread(void *arg)\n{\n\tint needgpcb;\n\tstruct rcu_tasks *rtp = arg;\n\n\t/* Run on housekeeping CPUs by default.  Sysadm can move if desired. */\n\thousekeeping_affine(current, HK_FLAG_RCU);\n\tWRITE_ONCE(rtp->kthread_ptr, current); // Let GPs start!\n\n\t/*\n\t * Each pass through the following loop makes one check for\n\t * newly arrived callbacks, and, if there are some, waits for\n\t * one RCU-tasks grace period and then invokes the callbacks.\n\t * This loop is terminated by the system going down.  ;-)\n\t */\n\tfor (;;) {\n\t\tset_tasks_gp_state(rtp, RTGS_WAIT_CBS);\n\n\t\t/* If there were none, wait a bit and start over. */\n\t\twait_event_idle(rtp->cbs_wq, (needgpcb = rcu_tasks_need_gpcb(rtp)));\n\n\t\tif (needgpcb & 0x2) {\n\t\t\t// Wait for one grace period.\n\t\t\tset_tasks_gp_state(rtp, RTGS_WAIT_GP);\n\t\t\trtp->gp_start = jiffies;\n\t\t\trcu_seq_start(&rtp->tasks_gp_seq);\n\t\t\trtp->gp_func(rtp);\n\t\t\trcu_seq_end(&rtp->tasks_gp_seq);\n\t\t}\n\n\t\t/* Invoke callbacks. */\n\t\tset_tasks_gp_state(rtp, RTGS_INVOKE_CBS);\n\t\trcu_tasks_invoke_cbs(rtp, per_cpu_ptr(rtp->rtpcpu, 0));\n\n\t\t/* Paranoid sleep to keep this from entering a tight loop */\n\t\tschedule_timeout_idle(rtp->gp_sleep);\n\t}\n}"
  },
  {
    "function_name": "rcu_tasks_invoke_cbs_wq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "479-486",
    "snippet": "static void rcu_tasks_invoke_cbs_wq(struct work_struct *wp)\n{\n\tstruct rcu_tasks *rtp;\n\tstruct rcu_tasks_percpu *rtpcp = container_of(wp, struct rcu_tasks_percpu, rtp_work);\n\n\trtp = rtpcp->rtpp;\n\trcu_tasks_invoke_cbs(rtp, rtpcp);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_tasks_invoke_cbs",
          "args": [
            "rtp",
            "rtpcp"
          ],
          "line": 485
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_tasks_invoke_cbs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "437-476",
          "snippet": "static void rcu_tasks_invoke_cbs(struct rcu_tasks *rtp, struct rcu_tasks_percpu *rtpcp)\n{\n\tint cpu;\n\tint cpunext;\n\tunsigned long flags;\n\tint len;\n\tstruct rcu_head *rhp;\n\tstruct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);\n\tstruct rcu_tasks_percpu *rtpcp_next;\n\n\tcpu = rtpcp->cpu;\n\tcpunext = cpu * 2 + 1;\n\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\tcpunext++;\n\t\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\t}\n\t}\n\n\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\treturn;\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\trcu_segcblist_extract_done_cbs(&rtpcp->cblist, &rcl);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tlen = rcl.len;\n\tfor (rhp = rcu_cblist_dequeue(&rcl); rhp; rhp = rcu_cblist_dequeue(&rcl)) {\n\t\tlocal_bh_disable();\n\t\trhp->func(rhp);\n\t\tlocal_bh_enable();\n\t\tcond_resched();\n\t}\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_add_len(&rtpcp->cblist, -len);\n\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_invoke_cbs(struct rcu_tasks *rtp, struct rcu_tasks_percpu *rtpcp)\n{\n\tint cpu;\n\tint cpunext;\n\tunsigned long flags;\n\tint len;\n\tstruct rcu_head *rhp;\n\tstruct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);\n\tstruct rcu_tasks_percpu *rtpcp_next;\n\n\tcpu = rtpcp->cpu;\n\tcpunext = cpu * 2 + 1;\n\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\tcpunext++;\n\t\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\t}\n\t}\n\n\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\treturn;\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\trcu_segcblist_extract_done_cbs(&rtpcp->cblist, &rcl);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tlen = rcl.len;\n\tfor (rhp = rcu_cblist_dequeue(&rcl); rhp; rhp = rcu_cblist_dequeue(&rcl)) {\n\t\tlocal_bh_disable();\n\t\trhp->func(rhp);\n\t\tlocal_bh_enable();\n\t\tcond_resched();\n\t}\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_add_len(&rtpcp->cblist, -len);\n\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "wp",
            "structrcu_tasks_percpu",
            "rtp_work"
          ],
          "line": 482
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_invoke_cbs_wq(struct work_struct *wp)\n{\n\tstruct rcu_tasks *rtp;\n\tstruct rcu_tasks_percpu *rtpcp = container_of(wp, struct rcu_tasks_percpu, rtp_work);\n\n\trtp = rtpcp->rtpp;\n\trcu_tasks_invoke_cbs(rtp, rtpcp);\n}"
  },
  {
    "function_name": "rcu_tasks_invoke_cbs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "437-476",
    "snippet": "static void rcu_tasks_invoke_cbs(struct rcu_tasks *rtp, struct rcu_tasks_percpu *rtpcp)\n{\n\tint cpu;\n\tint cpunext;\n\tunsigned long flags;\n\tint len;\n\tstruct rcu_head *rhp;\n\tstruct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);\n\tstruct rcu_tasks_percpu *rtpcp_next;\n\n\tcpu = rtpcp->cpu;\n\tcpunext = cpu * 2 + 1;\n\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\tcpunext++;\n\t\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\t}\n\t}\n\n\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\treturn;\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\trcu_segcblist_extract_done_cbs(&rtpcp->cblist, &rcl);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tlen = rcl.len;\n\tfor (rhp = rcu_cblist_dequeue(&rcl); rhp; rhp = rcu_cblist_dequeue(&rcl)) {\n\t\tlocal_bh_disable();\n\t\trhp->func(rhp);\n\t\tlocal_bh_enable();\n\t\tcond_resched();\n\t}\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_add_len(&rtpcp->cblist, -len);\n\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 475
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_accelerate",
          "args": [
            "&rtpcp->cblist",
            "rcu_seq_snap(&rtp->tasks_gp_seq)"
          ],
          "line": 474
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_accelerate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "537-598",
          "snippet": "bool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn false;\n\n\t/*\n\t * Find the segment preceding the oldest segment of callbacks\n\t * whose ->gp_seq[] completion is at or after that passed in via\n\t * \"seq\", skipping any empty segments.  This oldest segment, along\n\t * with any later segments, can be merged in with any newly arrived\n\t * callbacks in the RCU_NEXT_TAIL segment, and assigned \"seq\"\n\t * as their ->gp_seq[] grace-period completion sequence number.\n\t */\n\tfor (i = RCU_NEXT_READY_TAIL; i > RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] != rsclp->tails[i - 1] &&\n\t\t    ULONG_CMP_LT(rsclp->gp_seq[i], seq))\n\t\t\tbreak;\n\n\t/*\n\t * If all the segments contain callbacks that correspond to\n\t * earlier grace-period sequence numbers than \"seq\", leave.\n\t * Assuming that the rcu_segcblist structure has enough\n\t * segments in its arrays, this can only happen if some of\n\t * the non-done segments contain callbacks that really are\n\t * ready to invoke.  This situation will get straightened\n\t * out by the next call to rcu_segcblist_advance().\n\t *\n\t * Also advance to the oldest segment of callbacks whose\n\t * ->gp_seq[] completion is at or after that passed in via \"seq\",\n\t * skipping any empty segments.\n\t *\n\t * Note that segment \"i\" (and any lower-numbered segments\n\t * containing older callbacks) will be unaffected, and their\n\t * grace-period numbers remain unchanged.  For example, if i ==\n\t * WAIT_TAIL, then neither WAIT_TAIL nor DONE_TAIL will be touched.\n\t * Instead, the CBs in NEXT_TAIL will be merged with those in\n\t * NEXT_READY_TAIL and the grace-period number of NEXT_READY_TAIL\n\t * would be updated.  NEXT_TAIL would then be empty.\n\t */\n\tif (rcu_segcblist_restempty(rsclp, i) || ++i >= RCU_NEXT_TAIL)\n\t\treturn false;\n\n\t/* Accounting: everything below i is about to get merged into i. */\n\tfor (j = i + 1; j <= RCU_NEXT_TAIL; j++)\n\t\trcu_segcblist_move_seglen(rsclp, j, i);\n\n\t/*\n\t * Merge all later callbacks, including newly arrived callbacks,\n\t * into the segment located by the for-loop above.  Assign \"seq\"\n\t * as the ->gp_seq[] value in order to correctly handle the case\n\t * where there were no pending callbacks in the rcu_segcblist\n\t * structure other than in the RCU_NEXT_TAIL segment.\n\t */\n\tfor (; i < RCU_NEXT_TAIL; i++) {\n\t\tWRITE_ONCE(rsclp->tails[i], rsclp->tails[RCU_NEXT_TAIL]);\n\t\trsclp->gp_seq[i] = seq;\n\t}\n\treturn true;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nbool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn false;\n\n\t/*\n\t * Find the segment preceding the oldest segment of callbacks\n\t * whose ->gp_seq[] completion is at or after that passed in via\n\t * \"seq\", skipping any empty segments.  This oldest segment, along\n\t * with any later segments, can be merged in with any newly arrived\n\t * callbacks in the RCU_NEXT_TAIL segment, and assigned \"seq\"\n\t * as their ->gp_seq[] grace-period completion sequence number.\n\t */\n\tfor (i = RCU_NEXT_READY_TAIL; i > RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] != rsclp->tails[i - 1] &&\n\t\t    ULONG_CMP_LT(rsclp->gp_seq[i], seq))\n\t\t\tbreak;\n\n\t/*\n\t * If all the segments contain callbacks that correspond to\n\t * earlier grace-period sequence numbers than \"seq\", leave.\n\t * Assuming that the rcu_segcblist structure has enough\n\t * segments in its arrays, this can only happen if some of\n\t * the non-done segments contain callbacks that really are\n\t * ready to invoke.  This situation will get straightened\n\t * out by the next call to rcu_segcblist_advance().\n\t *\n\t * Also advance to the oldest segment of callbacks whose\n\t * ->gp_seq[] completion is at or after that passed in via \"seq\",\n\t * skipping any empty segments.\n\t *\n\t * Note that segment \"i\" (and any lower-numbered segments\n\t * containing older callbacks) will be unaffected, and their\n\t * grace-period numbers remain unchanged.  For example, if i ==\n\t * WAIT_TAIL, then neither WAIT_TAIL nor DONE_TAIL will be touched.\n\t * Instead, the CBs in NEXT_TAIL will be merged with those in\n\t * NEXT_READY_TAIL and the grace-period number of NEXT_READY_TAIL\n\t * would be updated.  NEXT_TAIL would then be empty.\n\t */\n\tif (rcu_segcblist_restempty(rsclp, i) || ++i >= RCU_NEXT_TAIL)\n\t\treturn false;\n\n\t/* Accounting: everything below i is about to get merged into i. */\n\tfor (j = i + 1; j <= RCU_NEXT_TAIL; j++)\n\t\trcu_segcblist_move_seglen(rsclp, j, i);\n\n\t/*\n\t * Merge all later callbacks, including newly arrived callbacks,\n\t * into the segment located by the for-loop above.  Assign \"seq\"\n\t * as the ->gp_seq[] value in order to correctly handle the case\n\t * where there were no pending callbacks in the rcu_segcblist\n\t * structure other than in the RCU_NEXT_TAIL segment.\n\t */\n\tfor (; i < RCU_NEXT_TAIL; i++) {\n\t\tWRITE_ONCE(rsclp->tails[i], rsclp->tails[RCU_NEXT_TAIL]);\n\t\trsclp->gp_seq[i] = seq;\n\t}\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_snap",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 474
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_snap",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "87-94",
          "snippet": "static inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [
            "#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\n#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)\n\nstatic inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_add_len",
          "args": [
            "&rtpcp->cblist",
            "-len"
          ],
          "line": 473
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_add_len",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "210-221",
          "snippet": "void rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 472
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 470
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_bh_enable",
          "args": [],
          "line": 469
        },
        "resolved": true,
        "details": {
          "function_name": "_local_bh_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/softirq.c",
          "lines": "353-357",
          "snippet": "void _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}",
          "includes": [
            "#include <trace/events/irq.h>",
            "#include <asm/softirq_stack.h>",
            "#include <linux/wait_bit.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cpu.h>",
            "#include <linux/percpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/mm.h>",
            "#include <linux/local_lock.h>",
            "#include <linux/init.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/irq.h>\n#include <asm/softirq_stack.h>\n#include <linux/wait_bit.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/ftrace.h>\n#include <linux/rcupdate.h>\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n#include <linux/cpu.h>\n#include <linux/percpu.h>\n#include <linux/notifier.h>\n#include <linux/mm.h>\n#include <linux/local_lock.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel_stat.h>\n#include <linux/export.h>\n\nvoid _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rhp->func",
          "args": [
            "rhp"
          ],
          "line": 468
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_bh_disable",
          "args": [],
          "line": 467
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_cblist_dequeue",
          "args": [
            "&rcl"
          ],
          "line": 466
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_cblist_dequeue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "67-79",
          "snippet": "struct rcu_head *rcu_cblist_dequeue(struct rcu_cblist *rclp)\n{\n\tstruct rcu_head *rhp;\n\n\trhp = rclp->head;\n\tif (!rhp)\n\t\treturn NULL;\n\trclp->len--;\n\trclp->head = rhp->next;\n\tif (!rclp->head)\n\t\trclp->tail = &rclp->head;\n\treturn rhp;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nstruct rcu_head *rcu_cblist_dequeue(struct rcu_cblist *rclp)\n{\n\tstruct rcu_head *rhp;\n\n\trhp = rclp->head;\n\tif (!rhp)\n\t\treturn NULL;\n\trclp->len--;\n\trclp->head = rhp->next;\n\tif (!rclp->head)\n\t\trclp->tail = &rclp->head;\n\treturn rhp;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 464
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_extract_done_cbs",
          "args": [
            "&rtpcp->cblist",
            "&rcl"
          ],
          "line": 463
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_extract_done_cbs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "385-401",
          "snippet": "void rcu_segcblist_extract_done_cbs(struct rcu_segcblist *rsclp,\n\t\t\t\t    struct rcu_cblist *rclp)\n{\n\tint i;\n\n\tif (!rcu_segcblist_ready_cbs(rsclp))\n\t\treturn; /* Nothing to do. */\n\trclp->len = rcu_segcblist_get_seglen(rsclp, RCU_DONE_TAIL);\n\t*rclp->tail = rsclp->head;\n\tWRITE_ONCE(rsclp->head, *rsclp->tails[RCU_DONE_TAIL]);\n\tWRITE_ONCE(*rsclp->tails[RCU_DONE_TAIL], NULL);\n\trclp->tail = rsclp->tails[RCU_DONE_TAIL];\n\tfor (i = RCU_CBLIST_NSEGS - 1; i >= RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] == rsclp->tails[RCU_DONE_TAIL])\n\t\t\tWRITE_ONCE(rsclp->tails[i], &rsclp->head);\n\trcu_segcblist_set_seglen(rsclp, RCU_DONE_TAIL, 0);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_extract_done_cbs(struct rcu_segcblist *rsclp,\n\t\t\t\t    struct rcu_cblist *rclp)\n{\n\tint i;\n\n\tif (!rcu_segcblist_ready_cbs(rsclp))\n\t\treturn; /* Nothing to do. */\n\trclp->len = rcu_segcblist_get_seglen(rsclp, RCU_DONE_TAIL);\n\t*rclp->tail = rsclp->head;\n\tWRITE_ONCE(rsclp->head, *rsclp->tails[RCU_DONE_TAIL]);\n\tWRITE_ONCE(*rsclp->tails[RCU_DONE_TAIL], NULL);\n\trclp->tail = rsclp->tails[RCU_DONE_TAIL];\n\tfor (i = RCU_CBLIST_NSEGS - 1; i >= RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] == rsclp->tails[RCU_DONE_TAIL])\n\t\t\tWRITE_ONCE(rsclp->tails[i], &rsclp->head);\n\trcu_segcblist_set_seglen(rsclp, RCU_DONE_TAIL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_advance",
          "args": [
            "&rtpcp->cblist",
            "rcu_seq_current(&rtp->tasks_gp_seq)"
          ],
          "line": 462
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_advance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "480-520",
          "snippet": "void rcu_segcblist_advance(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn;\n\n\t/*\n\t * Find all callbacks whose ->gp_seq numbers indicate that they\n\t * are ready to invoke, and put them into the RCU_DONE_TAIL segment.\n\t */\n\tfor (i = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++) {\n\t\tif (ULONG_CMP_LT(seq, rsclp->gp_seq[i]))\n\t\t\tbreak;\n\t\tWRITE_ONCE(rsclp->tails[RCU_DONE_TAIL], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, RCU_DONE_TAIL);\n\t}\n\n\t/* If no callbacks moved, nothing more need be done. */\n\tif (i == RCU_WAIT_TAIL)\n\t\treturn;\n\n\t/* Clean up tail pointers that might have been misordered above. */\n\tfor (j = RCU_WAIT_TAIL; j < i; j++)\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[RCU_DONE_TAIL]);\n\n\t/*\n\t * Callbacks moved, so clean up the misordered ->tails[] pointers\n\t * that now point into the middle of the list of ready-to-invoke\n\t * callbacks.  The overall effect is to copy down the later pointers\n\t * into the gap that was created by the now-ready segments.\n\t */\n\tfor (j = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++, j++) {\n\t\tif (rsclp->tails[j] == rsclp->tails[RCU_NEXT_TAIL])\n\t\t\tbreak;  /* No more callbacks. */\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, j);\n\t\trsclp->gp_seq[j] = rsclp->gp_seq[i];\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_advance(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn;\n\n\t/*\n\t * Find all callbacks whose ->gp_seq numbers indicate that they\n\t * are ready to invoke, and put them into the RCU_DONE_TAIL segment.\n\t */\n\tfor (i = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++) {\n\t\tif (ULONG_CMP_LT(seq, rsclp->gp_seq[i]))\n\t\t\tbreak;\n\t\tWRITE_ONCE(rsclp->tails[RCU_DONE_TAIL], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, RCU_DONE_TAIL);\n\t}\n\n\t/* If no callbacks moved, nothing more need be done. */\n\tif (i == RCU_WAIT_TAIL)\n\t\treturn;\n\n\t/* Clean up tail pointers that might have been misordered above. */\n\tfor (j = RCU_WAIT_TAIL; j < i; j++)\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[RCU_DONE_TAIL]);\n\n\t/*\n\t * Callbacks moved, so clean up the misordered ->tails[] pointers\n\t * that now point into the middle of the list of ready-to-invoke\n\t * callbacks.  The overall effect is to copy down the later pointers\n\t * into the gap that was created by the now-ready segments.\n\t */\n\tfor (j = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++, j++) {\n\t\tif (rsclp->tails[j] == rsclp->tails[RCU_NEXT_TAIL])\n\t\t\tbreak;  /* No more callbacks. */\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, j);\n\t\trsclp->gp_seq[j] = rsclp->gp_seq[i];\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_current",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 462
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "97-100",
          "snippet": "static inline unsigned long rcu_seq_current(unsigned long *sp)\n{\n\treturn READ_ONCE(*sp);\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline unsigned long rcu_seq_current(unsigned long *sp)\n{\n\treturn READ_ONCE(*sp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 461
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_empty",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 459
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "queue_work_on",
          "args": [
            "cpunext",
            "system_wq",
            "&rtpcp_next->rtp_work"
          ],
          "line": 455
        },
        "resolved": true,
        "details": {
          "function_name": "queue_work_on",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "1553-1568",
          "snippet": "bool queue_work_on(int cpu, struct workqueue_struct *wq,\n\t\t   struct work_struct *work)\n{\n\tbool ret = false;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\n\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {\n\t\t__queue_work(cpu, wq, work);\n\t\tret = true;\n\t}\n\n\tlocal_irq_restore(flags);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void workqueue_sysfs_unregister(struct workqueue_struct *wq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic void workqueue_sysfs_unregister(struct workqueue_struct *wq);\n\nbool queue_work_on(int cpu, struct workqueue_struct *wq,\n\t\t   struct work_struct *work)\n{\n\tbool ret = false;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\n\tif (!test_and_set_bit(WORK_STRUCT_PENDING_BIT, work_data_bits(work))) {\n\t\t__queue_work(cpu, wq, work);\n\t\tret = true;\n\t}\n\n\tlocal_irq_restore(flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "cpunext"
          ],
          "line": 454
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&rtp->percpu_dequeue_lim"
          ],
          "line": 453
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "cpunext"
          ],
          "line": 450
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&rtp->percpu_dequeue_lim"
          ],
          "line": 449
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RCU_CBLIST_INITIALIZER",
          "args": [
            "rcl"
          ],
          "line": 444
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_tasks_invoke_cbs(struct rcu_tasks *rtp, struct rcu_tasks_percpu *rtpcp)\n{\n\tint cpu;\n\tint cpunext;\n\tunsigned long flags;\n\tint len;\n\tstruct rcu_head *rhp;\n\tstruct rcu_cblist rcl = RCU_CBLIST_INITIALIZER(rcl);\n\tstruct rcu_tasks_percpu *rtpcp_next;\n\n\tcpu = rtpcp->cpu;\n\tcpunext = cpu * 2 + 1;\n\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\tcpunext++;\n\t\tif (cpunext < smp_load_acquire(&rtp->percpu_dequeue_lim)) {\n\t\t\trtpcp_next = per_cpu_ptr(rtp->rtpcpu, cpunext);\n\t\t\tqueue_work_on(cpunext, system_wq, &rtpcp_next->rtp_work);\n\t\t}\n\t}\n\n\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\treturn;\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\trcu_segcblist_extract_done_cbs(&rtpcp->cblist, &rcl);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tlen = rcl.len;\n\tfor (rhp = rcu_cblist_dequeue(&rcl); rhp; rhp = rcu_cblist_dequeue(&rcl)) {\n\t\tlocal_bh_disable();\n\t\trhp->func(rhp);\n\t\tlocal_bh_enable();\n\t\tcond_resched();\n\t}\n\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\trcu_segcblist_add_len(&rtpcp->cblist, -len);\n\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n}"
  },
  {
    "function_name": "rcu_tasks_need_gpcb",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "374-434",
    "snippet": "static int rcu_tasks_need_gpcb(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tlong n;\n\tlong ncbs = 0;\n\tlong ncbsnz = 0;\n\tint needgpcb = 0;\n\n\tfor (cpu = 0; cpu < smp_load_acquire(&rtp->percpu_dequeue_lim); cpu++) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\t/* Advance and accelerate any new callbacks. */\n\t\tif (!rcu_segcblist_n_cbs(&rtpcp->cblist))\n\t\t\tcontinue;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\t// Should we shrink down to a single callback queue?\n\t\tn = rcu_segcblist_n_cbs(&rtpcp->cblist);\n\t\tif (n) {\n\t\t\tncbs += n;\n\t\t\tif (cpu > 0)\n\t\t\t\tncbsnz += n;\n\t\t}\n\t\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\t\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\t\tif (rcu_segcblist_pend_cbs(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x3;\n\t\tif (!rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x1;\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\n\t// Shrink down to a single callback queue if appropriate.\n\t// This is done in two stages: (1) If there are no more than\n\t// rcu_task_collapse_lim callbacks on CPU 0 and none on any other\n\t// CPU, limit enqueueing to CPU 0.  (2) After an RCU grace period,\n\t// if there has not been an increase in callbacks, limit dequeuing\n\t// to CPU 0.  Note the matching RCU read-side critical section in\n\t// call_rcu_tasks_generic().\n\tif (rcu_task_cb_adjust && ncbs <= rcu_task_collapse_lim) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim > 1) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, 1);\n\t\t\trtp->percpu_dequeue_gpseq = get_state_synchronize_rcu();\n\t\t\tpr_info(\"Starting switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\tif (rcu_task_cb_adjust && !ncbsnz &&\n\t    poll_state_synchronize_rcu(rtp->percpu_dequeue_gpseq)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim < rtp->percpu_dequeue_lim) {\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, 1);\n\t\t\tpr_info(\"Completing switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\n\treturn needgpcb;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&rtp->cbs_gbl_lock",
            "flags"
          ],
          "line": 430
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Completing switch %s to CPU-0 callback queuing.\\n\"",
            "rtp->name"
          ],
          "line": 428
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->percpu_dequeue_lim",
            "1"
          ],
          "line": 427
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&rtp->cbs_gbl_lock",
            "flags"
          ],
          "line": 425
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "poll_state_synchronize_rcu",
          "args": [
            "rtp->percpu_dequeue_gpseq"
          ],
          "line": 424
        },
        "resolved": true,
        "details": {
          "function_name": "poll_state_synchronize_rcu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "3867-3874",
          "snippet": "bool poll_state_synchronize_rcu(unsigned long oldstate)\n{\n\tif (rcu_seq_done(&rcu_state.gp_seq, oldstate)) {\n\t\tsmp_mb(); /* Ensure GP ends before subsequent accesses. */\n\t\treturn true;\n\t}\n\treturn false;\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};\n\nbool poll_state_synchronize_rcu(unsigned long oldstate)\n{\n\tif (rcu_seq_done(&rcu_state.gp_seq, oldstate)) {\n\t\tsmp_mb(); /* Ensure GP ends before subsequent accesses. */\n\t\treturn true;\n\t}\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Starting switch %s to CPU-0 callback queuing.\\n\"",
            "rtp->name"
          ],
          "line": 419
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_state_synchronize_rcu",
          "args": [],
          "line": 418
        },
        "resolved": true,
        "details": {
          "function_name": "get_state_synchronize_rcu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "3798-3806",
          "snippet": "unsigned long get_state_synchronize_rcu(void)\n{\n\t/*\n\t * Any prior manipulation of RCU-protected data must happen\n\t * before the load from ->gp_seq.\n\t */\n\tsmp_mb();  /* ^^^ */\n\treturn rcu_seq_snap(&rcu_state.gp_seq);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};\n\nunsigned long get_state_synchronize_rcu(void)\n{\n\t/*\n\t * Any prior manipulation of RCU-protected data must happen\n\t * before the load from ->gp_seq.\n\t */\n\tsmp_mb();  /* ^^^ */\n\treturn rcu_seq_snap(&rcu_state.gp_seq);\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_store_release",
          "args": [
            "&rtp->percpu_enqueue_lim",
            "1"
          ],
          "line": 417
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->percpu_enqueue_shift",
            "ilog2(nr_cpu_ids)"
          ],
          "line": 416
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ilog2",
          "args": [
            "nr_cpu_ids"
          ],
          "line": 416
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_empty",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 401
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_pend_cbs",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 399
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_pend_cbs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "288-292",
          "snippet": "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp)\n{\n\treturn rcu_segcblist_is_enabled(rsclp) &&\n\t       !rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp)\n{\n\treturn rcu_segcblist_is_enabled(rsclp) &&\n\t       !rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_accelerate",
          "args": [
            "&rtpcp->cblist",
            "rcu_seq_snap(&rtp->tasks_gp_seq)"
          ],
          "line": 398
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_accelerate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "537-598",
          "snippet": "bool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn false;\n\n\t/*\n\t * Find the segment preceding the oldest segment of callbacks\n\t * whose ->gp_seq[] completion is at or after that passed in via\n\t * \"seq\", skipping any empty segments.  This oldest segment, along\n\t * with any later segments, can be merged in with any newly arrived\n\t * callbacks in the RCU_NEXT_TAIL segment, and assigned \"seq\"\n\t * as their ->gp_seq[] grace-period completion sequence number.\n\t */\n\tfor (i = RCU_NEXT_READY_TAIL; i > RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] != rsclp->tails[i - 1] &&\n\t\t    ULONG_CMP_LT(rsclp->gp_seq[i], seq))\n\t\t\tbreak;\n\n\t/*\n\t * If all the segments contain callbacks that correspond to\n\t * earlier grace-period sequence numbers than \"seq\", leave.\n\t * Assuming that the rcu_segcblist structure has enough\n\t * segments in its arrays, this can only happen if some of\n\t * the non-done segments contain callbacks that really are\n\t * ready to invoke.  This situation will get straightened\n\t * out by the next call to rcu_segcblist_advance().\n\t *\n\t * Also advance to the oldest segment of callbacks whose\n\t * ->gp_seq[] completion is at or after that passed in via \"seq\",\n\t * skipping any empty segments.\n\t *\n\t * Note that segment \"i\" (and any lower-numbered segments\n\t * containing older callbacks) will be unaffected, and their\n\t * grace-period numbers remain unchanged.  For example, if i ==\n\t * WAIT_TAIL, then neither WAIT_TAIL nor DONE_TAIL will be touched.\n\t * Instead, the CBs in NEXT_TAIL will be merged with those in\n\t * NEXT_READY_TAIL and the grace-period number of NEXT_READY_TAIL\n\t * would be updated.  NEXT_TAIL would then be empty.\n\t */\n\tif (rcu_segcblist_restempty(rsclp, i) || ++i >= RCU_NEXT_TAIL)\n\t\treturn false;\n\n\t/* Accounting: everything below i is about to get merged into i. */\n\tfor (j = i + 1; j <= RCU_NEXT_TAIL; j++)\n\t\trcu_segcblist_move_seglen(rsclp, j, i);\n\n\t/*\n\t * Merge all later callbacks, including newly arrived callbacks,\n\t * into the segment located by the for-loop above.  Assign \"seq\"\n\t * as the ->gp_seq[] value in order to correctly handle the case\n\t * where there were no pending callbacks in the rcu_segcblist\n\t * structure other than in the RCU_NEXT_TAIL segment.\n\t */\n\tfor (; i < RCU_NEXT_TAIL; i++) {\n\t\tWRITE_ONCE(rsclp->tails[i], rsclp->tails[RCU_NEXT_TAIL]);\n\t\trsclp->gp_seq[i] = seq;\n\t}\n\treturn true;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nbool rcu_segcblist_accelerate(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn false;\n\n\t/*\n\t * Find the segment preceding the oldest segment of callbacks\n\t * whose ->gp_seq[] completion is at or after that passed in via\n\t * \"seq\", skipping any empty segments.  This oldest segment, along\n\t * with any later segments, can be merged in with any newly arrived\n\t * callbacks in the RCU_NEXT_TAIL segment, and assigned \"seq\"\n\t * as their ->gp_seq[] grace-period completion sequence number.\n\t */\n\tfor (i = RCU_NEXT_READY_TAIL; i > RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] != rsclp->tails[i - 1] &&\n\t\t    ULONG_CMP_LT(rsclp->gp_seq[i], seq))\n\t\t\tbreak;\n\n\t/*\n\t * If all the segments contain callbacks that correspond to\n\t * earlier grace-period sequence numbers than \"seq\", leave.\n\t * Assuming that the rcu_segcblist structure has enough\n\t * segments in its arrays, this can only happen if some of\n\t * the non-done segments contain callbacks that really are\n\t * ready to invoke.  This situation will get straightened\n\t * out by the next call to rcu_segcblist_advance().\n\t *\n\t * Also advance to the oldest segment of callbacks whose\n\t * ->gp_seq[] completion is at or after that passed in via \"seq\",\n\t * skipping any empty segments.\n\t *\n\t * Note that segment \"i\" (and any lower-numbered segments\n\t * containing older callbacks) will be unaffected, and their\n\t * grace-period numbers remain unchanged.  For example, if i ==\n\t * WAIT_TAIL, then neither WAIT_TAIL nor DONE_TAIL will be touched.\n\t * Instead, the CBs in NEXT_TAIL will be merged with those in\n\t * NEXT_READY_TAIL and the grace-period number of NEXT_READY_TAIL\n\t * would be updated.  NEXT_TAIL would then be empty.\n\t */\n\tif (rcu_segcblist_restempty(rsclp, i) || ++i >= RCU_NEXT_TAIL)\n\t\treturn false;\n\n\t/* Accounting: everything below i is about to get merged into i. */\n\tfor (j = i + 1; j <= RCU_NEXT_TAIL; j++)\n\t\trcu_segcblist_move_seglen(rsclp, j, i);\n\n\t/*\n\t * Merge all later callbacks, including newly arrived callbacks,\n\t * into the segment located by the for-loop above.  Assign \"seq\"\n\t * as the ->gp_seq[] value in order to correctly handle the case\n\t * where there were no pending callbacks in the rcu_segcblist\n\t * structure other than in the RCU_NEXT_TAIL segment.\n\t */\n\tfor (; i < RCU_NEXT_TAIL; i++) {\n\t\tWRITE_ONCE(rsclp->tails[i], rsclp->tails[RCU_NEXT_TAIL]);\n\t\trsclp->gp_seq[i] = seq;\n\t}\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_snap",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 398
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_snap",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "87-94",
          "snippet": "static inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [
            "#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\n#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)\n\nstatic inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_advance",
          "args": [
            "&rtpcp->cblist",
            "rcu_seq_current(&rtp->tasks_gp_seq)"
          ],
          "line": 397
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_advance",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "480-520",
          "snippet": "void rcu_segcblist_advance(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn;\n\n\t/*\n\t * Find all callbacks whose ->gp_seq numbers indicate that they\n\t * are ready to invoke, and put them into the RCU_DONE_TAIL segment.\n\t */\n\tfor (i = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++) {\n\t\tif (ULONG_CMP_LT(seq, rsclp->gp_seq[i]))\n\t\t\tbreak;\n\t\tWRITE_ONCE(rsclp->tails[RCU_DONE_TAIL], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, RCU_DONE_TAIL);\n\t}\n\n\t/* If no callbacks moved, nothing more need be done. */\n\tif (i == RCU_WAIT_TAIL)\n\t\treturn;\n\n\t/* Clean up tail pointers that might have been misordered above. */\n\tfor (j = RCU_WAIT_TAIL; j < i; j++)\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[RCU_DONE_TAIL]);\n\n\t/*\n\t * Callbacks moved, so clean up the misordered ->tails[] pointers\n\t * that now point into the middle of the list of ready-to-invoke\n\t * callbacks.  The overall effect is to copy down the later pointers\n\t * into the gap that was created by the now-ready segments.\n\t */\n\tfor (j = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++, j++) {\n\t\tif (rsclp->tails[j] == rsclp->tails[RCU_NEXT_TAIL])\n\t\t\tbreak;  /* No more callbacks. */\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, j);\n\t\trsclp->gp_seq[j] = rsclp->gp_seq[i];\n\t}\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_advance(struct rcu_segcblist *rsclp, unsigned long seq)\n{\n\tint i, j;\n\n\tWARN_ON_ONCE(!rcu_segcblist_is_enabled(rsclp));\n\tif (rcu_segcblist_restempty(rsclp, RCU_DONE_TAIL))\n\t\treturn;\n\n\t/*\n\t * Find all callbacks whose ->gp_seq numbers indicate that they\n\t * are ready to invoke, and put them into the RCU_DONE_TAIL segment.\n\t */\n\tfor (i = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++) {\n\t\tif (ULONG_CMP_LT(seq, rsclp->gp_seq[i]))\n\t\t\tbreak;\n\t\tWRITE_ONCE(rsclp->tails[RCU_DONE_TAIL], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, RCU_DONE_TAIL);\n\t}\n\n\t/* If no callbacks moved, nothing more need be done. */\n\tif (i == RCU_WAIT_TAIL)\n\t\treturn;\n\n\t/* Clean up tail pointers that might have been misordered above. */\n\tfor (j = RCU_WAIT_TAIL; j < i; j++)\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[RCU_DONE_TAIL]);\n\n\t/*\n\t * Callbacks moved, so clean up the misordered ->tails[] pointers\n\t * that now point into the middle of the list of ready-to-invoke\n\t * callbacks.  The overall effect is to copy down the later pointers\n\t * into the gap that was created by the now-ready segments.\n\t */\n\tfor (j = RCU_WAIT_TAIL; i < RCU_NEXT_TAIL; i++, j++) {\n\t\tif (rsclp->tails[j] == rsclp->tails[RCU_NEXT_TAIL])\n\t\t\tbreak;  /* No more callbacks. */\n\t\tWRITE_ONCE(rsclp->tails[j], rsclp->tails[i]);\n\t\trcu_segcblist_move_seglen(rsclp, i, j);\n\t\trsclp->gp_seq[j] = rsclp->gp_seq[i];\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_current",
          "args": [
            "&rtp->tasks_gp_seq"
          ],
          "line": 397
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_current",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "97-100",
          "snippet": "static inline unsigned long rcu_seq_current(unsigned long *sp)\n{\n\treturn READ_ONCE(*sp);\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline unsigned long rcu_seq_current(unsigned long *sp)\n{\n\treturn READ_ONCE(*sp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_n_cbs",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 391
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_n_cbs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "47-54",
          "snippet": "static inline long rcu_segcblist_n_cbs(struct rcu_segcblist *rsclp)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\treturn atomic_long_read(&rsclp->len);\n#else\n\treturn READ_ONCE(rsclp->len);\n#endif\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline long rcu_segcblist_n_cbs(struct rcu_segcblist *rsclp)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\treturn atomic_long_read(&rsclp->len);\n#else\n\treturn READ_ONCE(rsclp->len);\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 389
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "cpu"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&rtp->percpu_dequeue_lim"
          ],
          "line": 383
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic int rcu_tasks_need_gpcb(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tlong n;\n\tlong ncbs = 0;\n\tlong ncbsnz = 0;\n\tint needgpcb = 0;\n\n\tfor (cpu = 0; cpu < smp_load_acquire(&rtp->percpu_dequeue_lim); cpu++) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\t/* Advance and accelerate any new callbacks. */\n\t\tif (!rcu_segcblist_n_cbs(&rtpcp->cblist))\n\t\t\tcontinue;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\t// Should we shrink down to a single callback queue?\n\t\tn = rcu_segcblist_n_cbs(&rtpcp->cblist);\n\t\tif (n) {\n\t\t\tncbs += n;\n\t\t\tif (cpu > 0)\n\t\t\t\tncbsnz += n;\n\t\t}\n\t\trcu_segcblist_advance(&rtpcp->cblist, rcu_seq_current(&rtp->tasks_gp_seq));\n\t\t(void)rcu_segcblist_accelerate(&rtpcp->cblist, rcu_seq_snap(&rtp->tasks_gp_seq));\n\t\tif (rcu_segcblist_pend_cbs(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x3;\n\t\tif (!rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\tneedgpcb |= 0x1;\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\n\t// Shrink down to a single callback queue if appropriate.\n\t// This is done in two stages: (1) If there are no more than\n\t// rcu_task_collapse_lim callbacks on CPU 0 and none on any other\n\t// CPU, limit enqueueing to CPU 0.  (2) After an RCU grace period,\n\t// if there has not been an increase in callbacks, limit dequeuing\n\t// to CPU 0.  Note the matching RCU read-side critical section in\n\t// call_rcu_tasks_generic().\n\tif (rcu_task_cb_adjust && ncbs <= rcu_task_collapse_lim) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim > 1) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, 1);\n\t\t\trtp->percpu_dequeue_gpseq = get_state_synchronize_rcu();\n\t\t\tpr_info(\"Starting switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\tif (rcu_task_cb_adjust && !ncbsnz &&\n\t    poll_state_synchronize_rcu(rtp->percpu_dequeue_gpseq)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim < rtp->percpu_dequeue_lim) {\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, 1);\n\t\t\tpr_info(\"Completing switch %s to CPU-0 callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\n\treturn needgpcb;\n}"
  },
  {
    "function_name": "rcu_barrier_tasks_generic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "339-370",
    "snippet": "static void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&rtp->barrier_q_mutex"
          ],
          "line": 369
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_end",
          "args": [
            "&rtp->barrier_q_seq"
          ],
          "line": 368
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_end",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "69-74",
          "snippet": "static inline void rcu_seq_end(unsigned long *sp)\n{\n\tsmp_mb(); /* Ensure update-side operation before counter increment. */\n\tWARN_ON_ONCE(!rcu_seq_state(*sp));\n\tWRITE_ONCE(*sp, rcu_seq_endval(sp));\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline void rcu_seq_end(unsigned long *sp)\n{\n\tsmp_mb(); /* Ensure update-side operation before counter increment. */\n\tWARN_ON_ONCE(!rcu_seq_state(*sp));\n\tWRITE_ONCE(*sp, rcu_seq_endval(sp));\n}"
        }
      },
      {
        "call_info": {
          "callee": "wait_for_completion",
          "args": [
            "&rtp->barrier_q_completion"
          ],
          "line": 367
        },
        "resolved": true,
        "details": {
          "function_name": "try_wait_for_completion",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/completion.c",
          "lines": "282-303",
          "snippet": "bool try_wait_for_completion(struct completion *x)\n{\n\tunsigned long flags;\n\tbool ret = true;\n\n\t/*\n\t * Since x->done will need to be locked only\n\t * in the non-blocking case, we check x->done\n\t * first without taking the lock so we can\n\t * return early in the blocking case.\n\t */\n\tif (!READ_ONCE(x->done))\n\t\treturn false;\n\n\traw_spin_lock_irqsave(&x->wait.lock, flags);\n\tif (!x->done)\n\t\tret = false;\n\telse if (x->done != UINT_MAX)\n\t\tx->done--;\n\traw_spin_unlock_irqrestore(&x->wait.lock, flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nbool try_wait_for_completion(struct completion *x)\n{\n\tunsigned long flags;\n\tbool ret = true;\n\n\t/*\n\t * Since x->done will need to be locked only\n\t * in the non-blocking case, we check x->done\n\t * first without taking the lock so we can\n\t * return early in the blocking case.\n\t */\n\tif (!READ_ONCE(x->done))\n\t\treturn false;\n\n\traw_spin_lock_irqsave(&x->wait.lock, flags);\n\tif (!x->done)\n\t\tret = false;\n\telse if (x->done != UINT_MAX)\n\t\tx->done--;\n\traw_spin_unlock_irqrestore(&x->wait.lock, flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "complete",
          "args": [
            "&rtp->barrier_q_completion"
          ],
          "line": 366
        },
        "resolved": true,
        "details": {
          "function_name": "srcu_batches_completed",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/srcutree.c",
          "lines": "1162-1165",
          "snippet": "unsigned long srcu_batches_completed(struct srcu_struct *ssp)\n{\n\treturn READ_ONCE(ssp->srcu_idx);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include \"rcu.h\"",
            "#include <linux/srcu.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/smp.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/preempt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include \"rcu.h\"\n#include <linux/srcu.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/smp.h>\n#include <linux/sched.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/preempt.h>\n#include <linux/percpu.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n\nunsigned long srcu_batches_completed(struct srcu_struct *ssp)\n{\n\treturn READ_ONCE(ssp->srcu_idx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_sub_and_test",
          "args": [
            "2",
            "&rtp->barrier_q_count"
          ],
          "line": 365
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 363
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&rtp->barrier_q_count"
          ],
          "line": 362
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_entrain",
          "args": [
            "&rtpcp->cblist",
            "&rtpcp->barrier_q_head"
          ],
          "line": 361
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_entrain",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "360-378",
          "snippet": "bool rcu_segcblist_entrain(struct rcu_segcblist *rsclp,\n\t\t\t   struct rcu_head *rhp)\n{\n\tint i;\n\n\tif (rcu_segcblist_n_cbs(rsclp) == 0)\n\t\treturn false;\n\trcu_segcblist_inc_len(rsclp);\n\tsmp_mb(); /* Ensure counts are updated before callback is entrained. */\n\trhp->next = NULL;\n\tfor (i = RCU_NEXT_TAIL; i > RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] != rsclp->tails[i - 1])\n\t\t\tbreak;\n\trcu_segcblist_inc_seglen(rsclp, i);\n\tWRITE_ONCE(*rsclp->tails[i], rhp);\n\tfor (; i <= RCU_NEXT_TAIL; i++)\n\t\tWRITE_ONCE(rsclp->tails[i], &rhp->next);\n\treturn true;\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nbool rcu_segcblist_entrain(struct rcu_segcblist *rsclp,\n\t\t\t   struct rcu_head *rhp)\n{\n\tint i;\n\n\tif (rcu_segcblist_n_cbs(rsclp) == 0)\n\t\treturn false;\n\trcu_segcblist_inc_len(rsclp);\n\tsmp_mb(); /* Ensure counts are updated before callback is entrained. */\n\trhp->next = NULL;\n\tfor (i = RCU_NEXT_TAIL; i > RCU_DONE_TAIL; i--)\n\t\tif (rsclp->tails[i] != rsclp->tails[i - 1])\n\t\t\tbreak;\n\trcu_segcblist_inc_seglen(rsclp, i);\n\tWRITE_ONCE(*rsclp->tails[i], rhp);\n\tfor (; i <= RCU_NEXT_TAIL; i++)\n\t\tWRITE_ONCE(rsclp->tails[i], &rhp->next);\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 360
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "cpu"
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&rtp->percpu_dequeue_lim"
          ],
          "line": 356
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_set",
          "args": [
            "&rtp->barrier_q_count",
            "2"
          ],
          "line": 354
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "init_completion",
          "args": [
            "&rtp->barrier_q_completion"
          ],
          "line": 353
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_seq_start",
          "args": [
            "&rtp->barrier_q_seq"
          ],
          "line": 352
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_start",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "55-60",
          "snippet": "static inline void rcu_seq_start(unsigned long *sp)\n{\n\tWRITE_ONCE(*sp, *sp + 1);\n\tsmp_mb(); /* Ensure update-side operation after counter increment. */\n\tWARN_ON_ONCE(rcu_seq_state(*sp) != 1);\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline void rcu_seq_start(unsigned long *sp)\n{\n\tWRITE_ONCE(*sp, *sp + 1);\n\tsmp_mb(); /* Ensure update-side operation after counter increment. */\n\tWARN_ON_ONCE(rcu_seq_state(*sp) != 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 348
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_seq_done",
          "args": [
            "&rtp->barrier_q_seq",
            "s"
          ],
          "line": 347
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_done",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "115-118",
          "snippet": "static inline bool rcu_seq_done(unsigned long *sp, unsigned long s)\n{\n\treturn ULONG_CMP_GE(READ_ONCE(*sp), s);\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\nstatic inline bool rcu_seq_done(unsigned long *sp, unsigned long s)\n{\n\treturn ULONG_CMP_GE(READ_ONCE(*sp), s);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&rtp->barrier_q_mutex"
          ],
          "line": 346
        },
        "resolved": true,
        "details": {
          "function_name": "mutex_lock_io",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "580-586",
          "snippet": "void __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched mutex_lock_io(struct mutex *lock)\n{\n\tint token = io_schedule_prepare();\n\n\t__mutex_lock_common(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_);\n\tio_schedule_finish(token);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_seq_snap",
          "args": [
            "&rtp->barrier_q_seq"
          ],
          "line": 344
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_snap",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "87-94",
          "snippet": "static inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [
            "#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\n#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)\n\nstatic inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_barrier_tasks_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tstruct rcu_tasks_percpu *rtpcp;\n\tunsigned long s = rcu_seq_snap(&rtp->barrier_q_seq);\n\n\tmutex_lock(&rtp->barrier_q_mutex);\n\tif (rcu_seq_done(&rtp->barrier_q_seq, s)) {\n\t\tsmp_mb();\n\t\tmutex_unlock(&rtp->barrier_q_mutex);\n\t\treturn;\n\t}\n\trcu_seq_start(&rtp->barrier_q_seq);\n\tinit_completion(&rtp->barrier_q_completion);\n\tatomic_set(&rtp->barrier_q_count, 2);\n\tfor_each_possible_cpu(cpu) {\n\t\tif (cpu >= smp_load_acquire(&rtp->percpu_dequeue_lim))\n\t\t\tbreak;\n\t\trtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\t\trtpcp->barrier_q_head.func = rcu_barrier_tasks_generic_cb;\n\t\traw_spin_lock_irqsave_rcu_node(rtpcp, flags);\n\t\tif (rcu_segcblist_entrain(&rtpcp->cblist, &rtpcp->barrier_q_head))\n\t\t\tatomic_inc(&rtp->barrier_q_count);\n\t\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\t}\n\tif (atomic_sub_and_test(2, &rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n\twait_for_completion(&rtp->barrier_q_completion);\n\trcu_seq_end(&rtp->barrier_q_seq);\n\tmutex_unlock(&rtp->barrier_q_mutex);\n}"
  },
  {
    "function_name": "rcu_barrier_tasks_generic_cb",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "326-335",
    "snippet": "static void rcu_barrier_tasks_generic_cb(struct rcu_head *rhp)\n{\n\tstruct rcu_tasks *rtp;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trtpcp = container_of(rhp, struct rcu_tasks_percpu, barrier_q_head);\n\trtp = rtpcp->rtpp;\n\tif (atomic_dec_and_test(&rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "complete",
          "args": [
            "&rtp->barrier_q_completion"
          ],
          "line": 334
        },
        "resolved": true,
        "details": {
          "function_name": "srcu_batches_completed",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/srcutree.c",
          "lines": "1162-1165",
          "snippet": "unsigned long srcu_batches_completed(struct srcu_struct *ssp)\n{\n\treturn READ_ONCE(ssp->srcu_idx);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include \"rcu.h\"",
            "#include <linux/srcu.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/smp.h>",
            "#include <linux/sched.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/preempt.h>",
            "#include <linux/percpu.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include \"rcu.h\"\n#include <linux/srcu.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/smp.h>\n#include <linux/sched.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/preempt.h>\n#include <linux/percpu.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n\nunsigned long srcu_batches_completed(struct srcu_struct *ssp)\n{\n\treturn READ_ONCE(ssp->srcu_idx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec_and_test",
          "args": [
            "&rtp->barrier_q_count"
          ],
          "line": 333
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rhp",
            "structrcu_tasks_percpu",
            "barrier_q_head"
          ],
          "line": 331
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void rcu_barrier_tasks_generic_cb(struct rcu_head *rhp)\n{\n\tstruct rcu_tasks *rtp;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trtpcp = container_of(rhp, struct rcu_tasks_percpu, barrier_q_head);\n\trtp = rtpcp->rtpp;\n\tif (atomic_dec_and_test(&rtp->barrier_q_count))\n\t\tcomplete(&rtp->barrier_q_completion);\n}"
  },
  {
    "function_name": "synchronize_rcu_tasks_generic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "315-323",
    "snippet": "static void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wait_rcu_gp",
          "args": [
            "rtp->call_func"
          ],
          "line": 322
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RCU_LOCKDEP_WARN",
          "args": [
            "rcu_scheduler_active == RCU_SCHEDULER_INACTIVE",
            "\"synchronize_rcu_tasks called too soon\""
          ],
          "line": 318
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void synchronize_rcu_tasks_generic(struct rcu_tasks *rtp)\n{\n\t/* Complain if the scheduler has not started.  */\n\tRCU_LOCKDEP_WARN(rcu_scheduler_active == RCU_SCHEDULER_INACTIVE,\n\t\t\t \"synchronize_rcu_tasks called too soon\");\n\n\t/* Wait for the grace period. */\n\twait_rcu_gp(rtp->call_func);\n}"
  },
  {
    "function_name": "call_rcu_tasks_generic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "264-312",
    "snippet": "static void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "irq_work_queue",
          "args": [
            "&rtpcp->rtp_irq_work"
          ],
          "line": 311
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "106-118",
          "snippet": "bool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nbool irq_work_queue(struct irq_work *work)\n{\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\t/* Queue the entry and raise the IPI if needed. */\n\tpreempt_disable();\n\t__irq_work_queue_local(work);\n\tpreempt_enable();\n\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rtp->kthread_ptr"
          ],
          "line": 310
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 308
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&rtp->cbs_gbl_lock",
            "flags"
          ],
          "line": 306
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Switching %s to per-CPU callback queuing.\\n\"",
            "rtp->name"
          ],
          "line": 304
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_store_release",
          "args": [
            "&rtp->percpu_enqueue_lim",
            "nr_cpu_ids"
          ],
          "line": 303
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->percpu_dequeue_lim",
            "nr_cpu_ids"
          ],
          "line": 302
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->percpu_enqueue_shift",
            "ilog2(nr_cpu_ids)"
          ],
          "line": 301
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ilog2",
          "args": [
            "nr_cpu_ids"
          ],
          "line": 301
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&rtp->cbs_gbl_lock",
            "flags"
          ],
          "line": 299
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "needadjust"
          ],
          "line": 298
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rtpcp",
            "flags"
          ],
          "line": 297
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_enqueue",
          "args": [
            "&rtpcp->cblist",
            "rhp"
          ],
          "line": 296
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_enqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "340-348",
          "snippet": "void rcu_segcblist_enqueue(struct rcu_segcblist *rsclp,\n\t\t\t   struct rcu_head *rhp)\n{\n\trcu_segcblist_inc_len(rsclp);\n\trcu_segcblist_inc_seglen(rsclp, RCU_NEXT_TAIL);\n\trhp->next = NULL;\n\tWRITE_ONCE(*rsclp->tails[RCU_NEXT_TAIL], rhp);\n\tWRITE_ONCE(rsclp->tails[RCU_NEXT_TAIL], &rhp->next);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_enqueue(struct rcu_segcblist *rsclp,\n\t\t\t   struct rcu_head *rhp)\n{\n\trcu_segcblist_inc_len(rsclp);\n\trcu_segcblist_inc_seglen(rsclp, RCU_NEXT_TAIL);\n\trhp->next = NULL;\n\tWRITE_ONCE(*rsclp->tails[RCU_NEXT_TAIL], rhp);\n\tWRITE_ONCE(rsclp->tails[RCU_NEXT_TAIL], &rhp->next);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_empty",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 295
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_rcu_node",
          "args": [
            "rtpcp"
          ],
          "line": 293
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cblist_init_generic",
          "args": [
            "rtp"
          ],
          "line": 292
        },
        "resolved": true,
        "details": {
          "function_name": "cblist_init_generic",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "214-251",
          "snippet": "static void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_rcu_node",
          "args": [
            "rtpcp"
          ],
          "line": 291
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_is_enabled",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 290
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_is_enabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "78-81",
          "snippet": "static inline bool rcu_segcblist_is_enabled(struct rcu_segcblist *rsclp)\n{\n\treturn rcu_segcblist_test_flags(rsclp, SEGCBLIST_ENABLED);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_is_enabled(struct rcu_segcblist *rsclp)\n{\n\treturn rcu_segcblist_test_flags(rsclp, SEGCBLIST_ENABLED);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rtp->percpu_enqueue_lim"
          ],
          "line": 287
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_rcu_node",
          "args": [
            "rtpcp"
          ],
          "line": 280
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_trylock_rcu_node",
          "args": [
            "rtpcp"
          ],
          "line": 279
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift)"
          ],
          "line": 277
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rtp->percpu_enqueue_shift"
          ],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 276
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 275
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void call_rcu_tasks_generic(struct rcu_head *rhp, rcu_callback_t func,\n\t\t\t\t   struct rcu_tasks *rtp)\n{\n\tunsigned long flags;\n\tunsigned long j;\n\tbool needadjust = false;\n\tbool needwake;\n\tstruct rcu_tasks_percpu *rtpcp;\n\n\trhp->next = NULL;\n\trhp->func = func;\n\tlocal_irq_save(flags);\n\trcu_read_lock();\n\trtpcp = per_cpu_ptr(rtp->rtpcpu,\n\t\t\t    smp_processor_id() >> READ_ONCE(rtp->percpu_enqueue_shift));\n\tif (!raw_spin_trylock_rcu_node(rtpcp)) { // irqs already disabled.\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tj = jiffies;\n\t\tif (rtpcp->rtp_jiffies != j) {\n\t\t\trtpcp->rtp_jiffies = j;\n\t\t\trtpcp->rtp_n_lock_retries = 0;\n\t\t}\n\t\tif (rcu_task_cb_adjust && ++rtpcp->rtp_n_lock_retries > rcu_task_contend_lim &&\n\t\t    READ_ONCE(rtp->percpu_enqueue_lim) != nr_cpu_ids)\n\t\t\tneedadjust = true;  // Defer adjustment to avoid deadlock.\n\t}\n\tif (!rcu_segcblist_is_enabled(&rtpcp->cblist)) {\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t\tcblist_init_generic(rtp);\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t}\n\tneedwake = rcu_segcblist_empty(&rtpcp->cblist);\n\trcu_segcblist_enqueue(&rtpcp->cblist, rhp);\n\traw_spin_unlock_irqrestore_rcu_node(rtpcp, flags);\n\tif (unlikely(needadjust)) {\n\t\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\t\tif (rtp->percpu_enqueue_lim != nr_cpu_ids) {\n\t\t\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids));\n\t\t\tWRITE_ONCE(rtp->percpu_dequeue_lim, nr_cpu_ids);\n\t\t\tsmp_store_release(&rtp->percpu_enqueue_lim, nr_cpu_ids);\n\t\t\tpr_info(\"Switching %s to per-CPU callback queuing.\\n\", rtp->name);\n\t\t}\n\t\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\t}\n\trcu_read_unlock();\n\t/* We can't create the thread unless interrupts are enabled. */\n\tif (needwake && READ_ONCE(rtp->kthread_ptr))\n\t\tirq_work_queue(&rtpcp->rtp_irq_work);\n}"
  },
  {
    "function_name": "call_rcu_tasks_iw_wakeup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "254-261",
    "snippet": "static void call_rcu_tasks_iw_wakeup(struct irq_work *iwp)\n{\n\tstruct rcu_tasks *rtp;\n\tstruct rcu_tasks_percpu *rtpcp = container_of(iwp, struct rcu_tasks_percpu, rtp_irq_work);\n\n\trtp = rtpcp->rtpp;\n\twake_up(&rtp->cbs_wq);\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up",
          "args": [
            "&rtp->cbs_wq"
          ],
          "line": 260
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_worker",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "847-853",
          "snippet": "static void wake_up_worker(struct worker_pool *pool)\n{\n\tstruct worker *worker = first_idle_worker(pool);\n\n\tif (likely(worker))\n\t\twake_up_process(worker->task);\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);",
            "static void show_one_worker_pool(struct worker_pool *pool);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);\nstatic void show_one_worker_pool(struct worker_pool *pool);\n\nstatic void wake_up_worker(struct worker_pool *pool)\n{\n\tstruct worker *worker = first_idle_worker(pool);\n\n\tif (likely(worker))\n\t\twake_up_process(worker->task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "iwp",
            "structrcu_tasks_percpu",
            "rtp_irq_work"
          ],
          "line": 257
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void call_rcu_tasks_iw_wakeup(struct irq_work *iwp)\n{\n\tstruct rcu_tasks *rtp;\n\tstruct rcu_tasks_percpu *rtpcp = container_of(iwp, struct rcu_tasks_percpu, rtp_irq_work);\n\n\trtp = rtpcp->rtpp;\n\twake_up(&rtp->cbs_wq);\n}"
  },
  {
    "function_name": "cblist_init_generic",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "214-251",
    "snippet": "static void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: Setting shift to %d and lim to %d.\\n\"",
            "__func__",
            "data_race(rtp->percpu_enqueue_shift)",
            "data_race(rtp->percpu_enqueue_lim)"
          ],
          "line": 250
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_race",
          "args": [
            "rtp->percpu_enqueue_lim"
          ],
          "line": 250
        },
        "resolved": true,
        "details": {
          "function_name": "test_data_race",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/kcsan_test.c",
          "lines": "998-1008",
          "snippet": "__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}",
          "includes": [
            "#include <trace/events/printk.h>",
            "#include <linux/types.h>",
            "#include <linux/tracepoint.h>",
            "#include <linux/torture.h>",
            "#include <linux/timer.h>",
            "#include <linux/string.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kcsan-checks.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <kunit/test.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline const struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/printk.h>\n#include <linux/types.h>\n#include <linux/tracepoint.h>\n#include <linux/torture.h>\n#include <linux/timer.h>\n#include <linux/string.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n#include <linux/kernel.h>\n#include <linux/kcsan-checks.h>\n#include <linux/jiffies.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <kunit/test.h>\n\nstatic __always_inline const struct;\n\n__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&rtp->cbs_gbl_lock",
            "flags"
          ],
          "line": 249
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_rcu_node",
          "args": [
            "rtpcp"
          ],
          "line": 247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_WORK",
          "args": [
            "&rtpcp->rtp_work",
            "rcu_tasks_invoke_cbs_wq"
          ],
          "line": 244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_init",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 243
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "237-250",
          "snippet": "void rcu_segcblist_init(struct rcu_segcblist *rsclp)\n{\n\tint i;\n\n\tBUILD_BUG_ON(RCU_NEXT_TAIL + 1 != ARRAY_SIZE(rsclp->gp_seq));\n\tBUILD_BUG_ON(ARRAY_SIZE(rsclp->tails) != ARRAY_SIZE(rsclp->gp_seq));\n\trsclp->head = NULL;\n\tfor (i = 0; i < RCU_CBLIST_NSEGS; i++) {\n\t\trsclp->tails[i] = &rsclp->head;\n\t\trcu_segcblist_set_seglen(rsclp, i, 0);\n\t}\n\trcu_segcblist_set_len(rsclp, 0);\n\trcu_segcblist_set_flags(rsclp, SEGCBLIST_ENABLED);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp)\n{\n\tint i;\n\n\tBUILD_BUG_ON(RCU_NEXT_TAIL + 1 != ARRAY_SIZE(rsclp->gp_seq));\n\tBUILD_BUG_ON(ARRAY_SIZE(rsclp->tails) != ARRAY_SIZE(rsclp->gp_seq));\n\trsclp->head = NULL;\n\tfor (i = 0; i < RCU_CBLIST_NSEGS; i++) {\n\t\trsclp->tails[i] = &rsclp->head;\n\t\trcu_segcblist_set_seglen(rsclp, i, 0);\n\t}\n\trcu_segcblist_set_len(rsclp, 0);\n\trcu_segcblist_set_flags(rsclp, SEGCBLIST_ENABLED);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_segcblist_empty",
          "args": [
            "&rtpcp->cblist"
          ],
          "line": 242
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_rcu_node",
          "args": [
            "rtpcp"
          ],
          "line": 241
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&ACCESS_PRIVATE(rtpcp, lock)"
          ],
          "line": 240
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ACCESS_PRIVATE",
          "args": [
            "rtpcp",
            "lock"
          ],
          "line": 240
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rtpcp"
          ],
          "line": 238
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rtp->rtpcpu",
            "cpu"
          ],
          "line": 236
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_store_release",
          "args": [
            "&rtp->percpu_enqueue_lim",
            "lim"
          ],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->percpu_dequeue_lim",
            "lim"
          ],
          "line": 233
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rtp->percpu_enqueue_shift",
            "ilog2(nr_cpu_ids / lim)"
          ],
          "line": 232
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ilog2",
          "args": [
            "nr_cpu_ids / lim"
          ],
          "line": 232
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: Setting adjustable number of callback queues.\\n\"",
            "__func__"
          ],
          "line": 224
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&rtp->cbs_gbl_lock",
            "flags"
          ],
          "line": 220
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void cblist_init_generic(struct rcu_tasks *rtp)\n{\n\tint cpu;\n\tunsigned long flags;\n\tint lim;\n\n\traw_spin_lock_irqsave(&rtp->cbs_gbl_lock, flags);\n\tif (rcu_task_enqueue_lim < 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t\trcu_task_cb_adjust = true;\n\t\tpr_info(\"%s: Setting adjustable number of callback queues.\\n\", __func__);\n\t} else if (rcu_task_enqueue_lim == 0) {\n\t\trcu_task_enqueue_lim = 1;\n\t}\n\tlim = rcu_task_enqueue_lim;\n\n\tif (lim > nr_cpu_ids)\n\t\tlim = nr_cpu_ids;\n\tWRITE_ONCE(rtp->percpu_enqueue_shift, ilog2(nr_cpu_ids / lim));\n\tWRITE_ONCE(rtp->percpu_dequeue_lim, lim);\n\tsmp_store_release(&rtp->percpu_enqueue_lim, lim);\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct rcu_tasks_percpu *rtpcp = per_cpu_ptr(rtp->rtpcpu, cpu);\n\n\t\tWARN_ON_ONCE(!rtpcp);\n\t\tif (cpu)\n\t\t\traw_spin_lock_init(&ACCESS_PRIVATE(rtpcp, lock));\n\t\traw_spin_lock_rcu_node(rtpcp); // irqs already disabled.\n\t\tif (rcu_segcblist_empty(&rtpcp->cblist))\n\t\t\trcu_segcblist_init(&rtpcp->cblist);\n\t\tINIT_WORK(&rtpcp->rtp_work, rcu_tasks_invoke_cbs_wq);\n\t\trtpcp->cpu = cpu;\n\t\trtpcp->rtpp = rtp;\n\t\traw_spin_unlock_rcu_node(rtpcp); // irqs remain disabled.\n\t}\n\traw_spin_unlock_irqrestore(&rtp->cbs_gbl_lock, flags);\n\tpr_info(\"%s: Setting shift to %d and lim to %d.\\n\", __func__, data_race(rtp->percpu_enqueue_shift), data_race(rtp->percpu_enqueue_lim));\n}"
  },
  {
    "function_name": "tasks_gp_state_getname",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "201-209",
    "snippet": "static const char *tasks_gp_state_getname(struct rcu_tasks *rtp)\n{\n\tint i = data_race(rtp->gp_state); // Let KCSAN detect update races\n\tint j = READ_ONCE(i); // Prevent the compiler from reading twice\n\n\tif (j >= ARRAY_SIZE(rcu_tasks_gp_state_names))\n\t\treturn \"???\";\n\treturn rcu_tasks_gp_state_names[j];\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ARRAY_SIZE",
          "args": [
            "rcu_tasks_gp_state_names"
          ],
          "line": 206
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "i"
          ],
          "line": 204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_race",
          "args": [
            "rtp->gp_state"
          ],
          "line": 203
        },
        "resolved": true,
        "details": {
          "function_name": "test_data_race",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/kcsan_test.c",
          "lines": "998-1008",
          "snippet": "__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}",
          "includes": [
            "#include <trace/events/printk.h>",
            "#include <linux/types.h>",
            "#include <linux/tracepoint.h>",
            "#include <linux/torture.h>",
            "#include <linux/timer.h>",
            "#include <linux/string.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kcsan-checks.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <kunit/test.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline const struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/printk.h>\n#include <linux/types.h>\n#include <linux/tracepoint.h>\n#include <linux/torture.h>\n#include <linux/timer.h>\n#include <linux/string.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n#include <linux/kernel.h>\n#include <linux/kcsan-checks.h>\n#include <linux/jiffies.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <kunit/test.h>\n\nstatic __always_inline const struct;\n\n__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic const char *tasks_gp_state_getname(struct rcu_tasks *rtp)\n{\n\tint i = data_race(rtp->gp_state); // Let KCSAN detect update races\n\tint j = READ_ONCE(i); // Prevent the compiler from reading twice\n\n\tif (j >= ARRAY_SIZE(rcu_tasks_gp_state_names))\n\t\treturn \"???\";\n\treturn rcu_tasks_gp_state_names[j];\n}"
  },
  {
    "function_name": "set_tasks_gp_state",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
    "lines": "193-197",
    "snippet": "static void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}",
    "includes": [
      "#include \"rcu_segcblist.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nstatic void set_tasks_gp_state(struct rcu_tasks *rtp, int newstate)\n{\n\trtp->gp_state = newstate;\n\trtp->gp_jiffies = jiffies;\n}"
  }
]