[
  {
    "function_name": "up_read_non_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1644-1648",
    "snippet": "void up_read_non_owner(struct rw_semaphore *sem)\n{\n\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t__up_read(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__up_read",
          "args": [
            "sem"
          ],
          "line": 1647
        },
        "resolved": true,
        "details": {
          "function_name": "__up_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1408-1411",
          "snippet": "static inline void __up_read(struct rw_semaphore *sem)\n{\n\trwbase_read_unlock(&sem->rwbase, TASK_NORMAL);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __up_read(struct rw_semaphore *sem)\n{\n\trwbase_read_unlock(&sem->rwbase, TASK_NORMAL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "!is_rwsem_reader_owned(sem)",
            "sem"
          ],
          "line": 1646
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_rwsem_reader_owned",
          "args": [
            "sem"
          ],
          "line": 1646
        },
        "resolved": true,
        "details": {
          "function_name": "is_rwsem_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1446-1451",
          "snippet": "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid up_read_non_owner(struct rw_semaphore *sem)\n{\n\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t__up_read(sem);\n}"
  },
  {
    "function_name": "down_write_killable_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1629-1641",
    "snippet": "int __sched down_write_killable_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_write_trylock,\n\t\t\t\t  __down_write_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1636
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LOCK_CONTENDED_RETURN",
          "args": [
            "sem",
            "__down_write_trylock",
            "__down_write_killable"
          ],
          "line": 1634
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire",
          "args": [
            "&sem->dep_map",
            "subclass",
            "0",
            "_RET_IP_"
          ],
          "line": 1632
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1631
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint __sched down_write_killable_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_write_trylock,\n\t\t\t\t  __down_write_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "down_write_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1621-1626",
    "snippet": "void down_write_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "LOCK_CONTENDED",
          "args": [
            "sem",
            "__down_write_trylock",
            "__down_write"
          ],
          "line": 1625
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire",
          "args": [
            "&sem->dep_map",
            "subclass",
            "0",
            "_RET_IP_"
          ],
          "line": 1624
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1623
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid down_write_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);\n}"
  },
  {
    "function_name": "down_read_non_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1613-1618",
    "snippet": "void down_read_non_owner(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\t__down_read(sem);\n\t__rwsem_set_reader_owned(sem, NULL);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rwsem_set_reader_owned",
          "args": [
            "sem",
            "NULL"
          ],
          "line": 1617
        },
        "resolved": true,
        "details": {
          "function_name": "__rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1441-1444",
          "snippet": "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "__down_read",
          "args": [
            "sem"
          ],
          "line": 1616
        },
        "resolved": true,
        "details": {
          "function_name": "__down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1403-1406",
          "snippet": "static inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_trylock(&sem->rwbase);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_trylock(&sem->rwbase);\n}"
        }
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1615
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid down_read_non_owner(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\t__down_read(sem);\n\t__rwsem_set_reader_owned(sem, NULL);\n}"
  },
  {
    "function_name": "_down_write_nest_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1605-1610",
    "snippet": "void _down_write_nest_lock(struct rw_semaphore *sem, struct lockdep_map *nest)\n{\n\tmight_sleep();\n\trwsem_acquire_nest(&sem->dep_map, 0, 0, nest, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "LOCK_CONTENDED",
          "args": [
            "sem",
            "__down_write_trylock",
            "__down_write"
          ],
          "line": 1609
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire_nest",
          "args": [
            "&sem->dep_map",
            "0",
            "0",
            "nest",
            "_RET_IP_"
          ],
          "line": 1608
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1607
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid _down_write_nest_lock(struct rw_semaphore *sem, struct lockdep_map *nest)\n{\n\tmight_sleep();\n\trwsem_acquire_nest(&sem->dep_map, 0, 0, nest, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);\n}"
  },
  {
    "function_name": "down_read_killable_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1591-1602",
    "snippet": "int down_read_killable_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1597
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LOCK_CONTENDED_RETURN",
          "args": [
            "sem",
            "__down_read_trylock",
            "__down_read_killable"
          ],
          "line": 1596
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire_read",
          "args": [
            "&sem->dep_map",
            "subclass",
            "0",
            "_RET_IP_"
          ],
          "line": 1594
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1593
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint down_read_killable_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "down_read_nested",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1583-1588",
    "snippet": "void down_read_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_read_trylock, __down_read);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "LOCK_CONTENDED",
          "args": [
            "sem",
            "__down_read_trylock",
            "__down_read"
          ],
          "line": 1587
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire_read",
          "args": [
            "&sem->dep_map",
            "subclass",
            "0",
            "_RET_IP_"
          ],
          "line": 1586
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1585
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid down_read_nested(struct rw_semaphore *sem, int subclass)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_read_trylock, __down_read);\n}"
  },
  {
    "function_name": "downgrade_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1574-1578",
    "snippet": "void downgrade_write(struct rw_semaphore *sem)\n{\n\tlock_downgrade(&sem->dep_map, _RET_IP_);\n\t__downgrade_write(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__downgrade_write",
          "args": [
            "sem"
          ],
          "line": 1577
        },
        "resolved": true,
        "details": {
          "function_name": "__downgrade_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1433-1436",
          "snippet": "static inline void __downgrade_write(struct rw_semaphore *sem)\n{\n\trwbase_write_downgrade(&sem->rwbase);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __downgrade_write(struct rw_semaphore *sem)\n{\n\trwbase_write_downgrade(&sem->rwbase);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lock_downgrade",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1576
        },
        "resolved": true,
        "details": {
          "function_name": "lock_downgrade",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "5531-5545",
          "snippet": "void lock_downgrade(struct lockdep_map *lock, unsigned long ip)\n{\n\tunsigned long flags;\n\n\tif (unlikely(!lockdep_enabled()))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tlockdep_recursion_inc();\n\tcheck_flags(flags);\n\tif (__lock_downgrade(lock, ip))\n\t\tcheck_chain_key(current);\n\tlockdep_recursion_finish();\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid lock_downgrade(struct lockdep_map *lock, unsigned long ip)\n{\n\tunsigned long flags;\n\n\tif (unlikely(!lockdep_enabled()))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tlockdep_recursion_inc();\n\tcheck_flags(flags);\n\tif (__lock_downgrade(lock, ip))\n\t\tcheck_chain_key(current);\n\tlockdep_recursion_finish();\n\traw_local_irq_restore(flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid downgrade_write(struct rw_semaphore *sem)\n{\n\tlock_downgrade(&sem->dep_map, _RET_IP_);\n\t__downgrade_write(sem);\n}"
  },
  {
    "function_name": "up_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1564-1568",
    "snippet": "void up_write(struct rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\t__up_write(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__up_write",
          "args": [
            "sem"
          ],
          "line": 1567
        },
        "resolved": true,
        "details": {
          "function_name": "__up_write",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1428-1431",
          "snippet": "static inline void __up_write(struct rw_semaphore *sem)\n{\n\trwbase_write_unlock(&sem->rwbase);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __up_write(struct rw_semaphore *sem)\n{\n\trwbase_write_unlock(&sem->rwbase);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1566
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid up_write(struct rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\t__up_write(sem);\n}"
  },
  {
    "function_name": "up_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1554-1558",
    "snippet": "void up_read(struct rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\t__up_read(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__up_read",
          "args": [
            "sem"
          ],
          "line": 1557
        },
        "resolved": true,
        "details": {
          "function_name": "__up_read",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1408-1411",
          "snippet": "static inline void __up_read(struct rw_semaphore *sem)\n{\n\trwbase_read_unlock(&sem->rwbase, TASK_NORMAL);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __up_read(struct rw_semaphore *sem)\n{\n\trwbase_read_unlock(&sem->rwbase, TASK_NORMAL);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1556
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid up_read(struct rw_semaphore *sem)\n{\n\trwsem_release(&sem->dep_map, _RET_IP_);\n\t__up_read(sem);\n}"
  },
  {
    "function_name": "down_write_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1540-1548",
    "snippet": "int down_write_trylock(struct rw_semaphore *sem)\n{\n\tint ret = __down_write_trylock(sem);\n\n\tif (ret == 1)\n\t\trwsem_acquire(&sem->dep_map, 0, 1, _RET_IP_);\n\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_acquire",
          "args": [
            "&sem->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 1545
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__down_write_trylock",
          "args": [
            "sem"
          ],
          "line": 1542
        },
        "resolved": true,
        "details": {
          "function_name": "__down_write_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1423-1426",
          "snippet": "static inline int __down_write_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_write_trylock(&sem->rwbase);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_write_trylock(&sem->rwbase);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint down_write_trylock(struct rw_semaphore *sem)\n{\n\tint ret = __down_write_trylock(sem);\n\n\tif (ret == 1)\n\t\trwsem_acquire(&sem->dep_map, 0, 1, _RET_IP_);\n\n\treturn ret;\n}"
  },
  {
    "function_name": "down_write_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1522-1534",
    "snippet": "int __sched down_write_killable(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_write_trylock,\n\t\t\t\t  __down_write_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1529
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LOCK_CONTENDED_RETURN",
          "args": [
            "sem",
            "__down_write_trylock",
            "__down_write_killable"
          ],
          "line": 1527
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire",
          "args": [
            "&sem->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 1525
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1524
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint __sched down_write_killable(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_write_trylock,\n\t\t\t\t  __down_write_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "down_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1511-1516",
    "snippet": "void __sched down_write(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "LOCK_CONTENDED",
          "args": [
            "sem",
            "__down_write_trylock",
            "__down_write"
          ],
          "line": 1515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire",
          "args": [
            "&sem->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 1514
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1513
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid __sched down_write(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire(&sem->dep_map, 0, 0, _RET_IP_);\n\tLOCK_CONTENDED(sem, __down_write_trylock, __down_write);\n}"
  },
  {
    "function_name": "down_read_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1498-1505",
    "snippet": "int down_read_trylock(struct rw_semaphore *sem)\n{\n\tint ret = __down_read_trylock(sem);\n\n\tif (ret == 1)\n\t\trwsem_acquire_read(&sem->dep_map, 0, 1, _RET_IP_);\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_acquire_read",
          "args": [
            "&sem->dep_map",
            "0",
            "1",
            "_RET_IP_"
          ],
          "line": 1503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__down_read_trylock",
          "args": [
            "sem"
          ],
          "line": 1500
        },
        "resolved": true,
        "details": {
          "function_name": "__down_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1403-1406",
          "snippet": "static inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_trylock(&sem->rwbase);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_trylock(&sem->rwbase);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint down_read_trylock(struct rw_semaphore *sem)\n{\n\tint ret = __down_read_trylock(sem);\n\n\tif (ret == 1)\n\t\trwsem_acquire_read(&sem->dep_map, 0, 1, _RET_IP_);\n\treturn ret;\n}"
  },
  {
    "function_name": "down_read_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1481-1492",
    "snippet": "int __sched down_read_killable(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1487
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LOCK_CONTENDED_RETURN",
          "args": [
            "sem",
            "__down_read_trylock",
            "__down_read_killable"
          ],
          "line": 1486
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire_read",
          "args": [
            "&sem->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 1484
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1483
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint __sched down_read_killable(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_killable)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "down_read_interruptible",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1467-1478",
    "snippet": "int __sched down_read_interruptible(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_interruptible)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_release",
          "args": [
            "&sem->dep_map",
            "_RET_IP_"
          ],
          "line": 1473
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LOCK_CONTENDED_RETURN",
          "args": [
            "sem",
            "__down_read_trylock",
            "__down_read_interruptible"
          ],
          "line": 1472
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire_read",
          "args": [
            "&sem->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 1470
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1469
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint __sched down_read_interruptible(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tif (LOCK_CONTENDED_RETURN(sem, __down_read_trylock, __down_read_interruptible)) {\n\t\trwsem_release(&sem->dep_map, _RET_IP_);\n\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "down_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1458-1464",
    "snippet": "void __sched down_read(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tLOCK_CONTENDED(sem, __down_read_trylock, __down_read);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "LOCK_CONTENDED",
          "args": [
            "sem",
            "__down_read_trylock",
            "__down_read"
          ],
          "line": 1463
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_acquire_read",
          "args": [
            "&sem->dep_map",
            "0",
            "0",
            "_RET_IP_"
          ],
          "line": 1461
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "might_sleep",
          "args": [],
          "line": 1460
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid __sched down_read(struct rw_semaphore *sem)\n{\n\tmight_sleep();\n\trwsem_acquire_read(&sem->dep_map, 0, 0, _RET_IP_);\n\n\tLOCK_CONTENDED(sem, __down_read_trylock, __down_read);\n}"
  },
  {
    "function_name": "is_rwsem_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1446-1451",
    "snippet": "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_read",
          "args": [
            "&sem->rwbase.readers"
          ],
          "line": 1448
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}"
  },
  {
    "function_name": "__rwsem_set_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1441-1444",
    "snippet": "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}"
  },
  {
    "function_name": "__downgrade_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1433-1436",
    "snippet": "static inline void __downgrade_write(struct rw_semaphore *sem)\n{\n\trwbase_write_downgrade(&sem->rwbase);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_write_downgrade",
          "args": [
            "&sem->rwbase"
          ],
          "line": 1435
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_downgrade",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "205-213",
          "snippet": "static inline void rwbase_write_downgrade(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\t/* Release it and account current as reader */\n\t__rwbase_write_unlock(rwb, WRITER_BIAS - 1, flags);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void rwbase_write_downgrade(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\t/* Release it and account current as reader */\n\t__rwbase_write_unlock(rwb, WRITER_BIAS - 1, flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __downgrade_write(struct rw_semaphore *sem)\n{\n\trwbase_write_downgrade(&sem->rwbase);\n}"
  },
  {
    "function_name": "__up_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1428-1431",
    "snippet": "static inline void __up_write(struct rw_semaphore *sem)\n{\n\trwbase_write_unlock(&sem->rwbase);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_write_unlock",
          "args": [
            "&sem->rwbase"
          ],
          "line": 1430
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "196-203",
          "snippet": "static inline void rwbase_write_unlock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\t__rwbase_write_unlock(rwb, WRITER_BIAS, flags);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline void rwbase_write_unlock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\t__rwbase_write_unlock(rwb, WRITER_BIAS, flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __up_write(struct rw_semaphore *sem)\n{\n\trwbase_write_unlock(&sem->rwbase);\n}"
  },
  {
    "function_name": "__down_write_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1423-1426",
    "snippet": "static inline int __down_write_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_write_trylock(&sem->rwbase);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_write_trylock",
          "args": [
            "&sem->rwbase"
          ],
          "line": 1425
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "274-291",
          "snippet": "static inline int rwbase_write_trylock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\tif (!rwbase_rtmutex_trylock(rtm))\n\t\treturn 0;\n\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb)) {\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\treturn 1;\n\t}\n\t__rwbase_write_unlock(rwb, 0, flags);\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline int rwbase_write_trylock(struct rwbase_rt *rwb)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\tif (!rwbase_rtmutex_trylock(rtm))\n\t\treturn 0;\n\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb)) {\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\treturn 1;\n\t}\n\t__rwbase_write_unlock(rwb, 0, flags);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_write_trylock(&sem->rwbase);\n}"
  },
  {
    "function_name": "__down_write_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1418-1421",
    "snippet": "static inline int __sched __down_write_killable(struct rw_semaphore *sem)\n{\n\treturn rwbase_write_lock(&sem->rwbase, TASK_KILLABLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_write_lock",
          "args": [
            "&sem->rwbase",
            "TASK_KILLABLE"
          ],
          "line": 1420
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "232-272",
          "snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __sched __down_write_killable(struct rw_semaphore *sem)\n{\n\treturn rwbase_write_lock(&sem->rwbase, TASK_KILLABLE);\n}"
  },
  {
    "function_name": "__down_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1413-1416",
    "snippet": "static inline void __sched __down_write(struct rw_semaphore *sem)\n{\n\trwbase_write_lock(&sem->rwbase, TASK_UNINTERRUPTIBLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_write_lock",
          "args": [
            "&sem->rwbase",
            "TASK_UNINTERRUPTIBLE"
          ],
          "line": 1415
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_write_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "232-272",
          "snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static int __sched rwbase_write_lock(struct rwbase_rt *rwb,\n\t\t\t\t     unsigned int state)\n{\n\tstruct rt_mutex_base *rtm = &rwb->rtmutex;\n\tunsigned long flags;\n\n\t/* Take the rtmutex as a first step */\n\tif (rwbase_rtmutex_lock_state(rtm, state))\n\t\treturn -EINTR;\n\n\t/* Force readers into slow path */\n\tatomic_sub(READER_BIAS, &rwb->readers);\n\n\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\tif (__rwbase_write_trylock(rwb))\n\t\tgoto out_unlock;\n\n\trwbase_set_and_save_current_state(state);\n\tfor (;;) {\n\t\t/* Optimized out for rwlocks */\n\t\tif (rwbase_signal_pending_state(state, current)) {\n\t\t\trwbase_restore_current_state();\n\t\t\t__rwbase_write_unlock(rwb, 0, flags);\n\t\t\treturn -EINTR;\n\t\t}\n\n\t\tif (__rwbase_write_trylock(rwb))\n\t\t\tbreak;\n\n\t\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\t\trwbase_schedule();\n\t\traw_spin_lock_irqsave(&rtm->wait_lock, flags);\n\n\t\tset_current_state(state);\n\t}\n\trwbase_restore_current_state();\n\nout_unlock:\n\traw_spin_unlock_irqrestore(&rtm->wait_lock, flags);\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __sched __down_write(struct rw_semaphore *sem)\n{\n\trwbase_write_lock(&sem->rwbase, TASK_UNINTERRUPTIBLE);\n}"
  },
  {
    "function_name": "__up_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1408-1411",
    "snippet": "static inline void __up_read(struct rw_semaphore *sem)\n{\n\trwbase_read_unlock(&sem->rwbase, TASK_NORMAL);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_read_unlock",
          "args": [
            "&sem->rwbase",
            "TASK_NORMAL"
          ],
          "line": 1410
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "169-180",
          "snippet": "static __always_inline void rwbase_read_unlock(struct rwbase_rt *rwb,\n\t\t\t\t\t       unsigned int state)\n{\n\t/*\n\t * rwb->readers can only hit 0 when a writer is waiting for the\n\t * active readers to leave the critical section.\n\t *\n\t * dec_and_test() is fully ordered, provides RELEASE.\n\t */\n\tif (unlikely(atomic_dec_and_test(&rwb->readers)))\n\t\t__rwbase_read_unlock(rwb, state);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline void rwbase_read_unlock(struct rwbase_rt *rwb,\n\t\t\t\t\t       unsigned int state)\n{\n\t/*\n\t * rwb->readers can only hit 0 when a writer is waiting for the\n\t * active readers to leave the critical section.\n\t *\n\t * dec_and_test() is fully ordered, provides RELEASE.\n\t */\n\tif (unlikely(atomic_dec_and_test(&rwb->readers)))\n\t\t__rwbase_read_unlock(rwb, state);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __up_read(struct rw_semaphore *sem)\n{\n\trwbase_read_unlock(&sem->rwbase, TASK_NORMAL);\n}"
  },
  {
    "function_name": "__down_read_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1403-1406",
    "snippet": "static inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_trylock(&sem->rwbase);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_read_trylock",
          "args": [
            "&sem->rwbase"
          ],
          "line": 1405
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "53-66",
          "snippet": "static __always_inline int rwbase_read_trylock(struct rwbase_rt *rwb)\n{\n\tint r;\n\n\t/*\n\t * Increment reader count, if sem->readers < 0, i.e. READER_BIAS is\n\t * set.\n\t */\n\tfor (r = atomic_read(&rwb->readers); r < 0;) {\n\t\tif (likely(atomic_try_cmpxchg_acquire(&rwb->readers, &r, r + 1)))\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline int rwbase_read_trylock(struct rwbase_rt *rwb)\n{\n\tint r;\n\n\t/*\n\t * Increment reader count, if sem->readers < 0, i.e. READER_BIAS is\n\t * set.\n\t */\n\tfor (r = atomic_read(&rwb->readers); r < 0;) {\n\t\tif (likely(atomic_try_cmpxchg_acquire(&rwb->readers, &r, r + 1)))\n\t\t\treturn 1;\n\t}\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_trylock(&sem->rwbase);\n}"
  },
  {
    "function_name": "__down_read_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1398-1401",
    "snippet": "static inline int __down_read_killable(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_lock(&sem->rwbase, TASK_KILLABLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_read_lock",
          "args": [
            "&sem->rwbase",
            "TASK_KILLABLE"
          ],
          "line": 1400
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "136-143",
          "snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_killable(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_lock(&sem->rwbase, TASK_KILLABLE);\n}"
  },
  {
    "function_name": "__down_read_interruptible",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1393-1396",
    "snippet": "static inline int __down_read_interruptible(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_lock(&sem->rwbase, TASK_INTERRUPTIBLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_read_lock",
          "args": [
            "&sem->rwbase",
            "TASK_INTERRUPTIBLE"
          ],
          "line": 1395
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "136-143",
          "snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_interruptible(struct rw_semaphore *sem)\n{\n\treturn rwbase_read_lock(&sem->rwbase, TASK_INTERRUPTIBLE);\n}"
  },
  {
    "function_name": "__down_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1388-1391",
    "snippet": "static inline void __down_read(struct rw_semaphore *sem)\n{\n\trwbase_read_lock(&sem->rwbase, TASK_UNINTERRUPTIBLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwbase_read_lock",
          "args": [
            "&sem->rwbase",
            "TASK_UNINTERRUPTIBLE"
          ],
          "line": 1390
        },
        "resolved": true,
        "details": {
          "function_name": "rwbase_read_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwbase_rt.c",
          "lines": "136-143",
          "snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static __always_inline int rwbase_read_lock(struct rwbase_rt *rwb,\n\t\t\t\t\t    unsigned int state)\n{\n\tif (rwbase_read_trylock(rwb))\n\t\treturn 0;\n\n\treturn __rwbase_read_lock(rwb, state);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __down_read(struct rw_semaphore *sem)\n{\n\trwbase_read_lock(&sem->rwbase, TASK_UNINTERRUPTIBLE);\n}"
  },
  {
    "function_name": "__init_rwsem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1376-1385",
    "snippet": "void __init_rwsem(struct rw_semaphore *sem, const char *name,\n\t\t  struct lock_class_key *key)\n{\n\tinit_rwbase_rt(&(sem)->rwbase);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));\n\tlockdep_init_map_wait(&sem->dep_map, name, key, 0, LD_WAIT_SLEEP);\n#endif\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lockdep_init_map_wait",
          "args": [
            "&sem->dep_map",
            "name",
            "key",
            "0",
            "LD_WAIT_SLEEP"
          ],
          "line": 1383
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_check_no_locks_freed",
          "args": [
            "(void *)sem",
            "sizeof(*sem)"
          ],
          "line": 1382
        },
        "resolved": true,
        "details": {
          "function_name": "debug_check_no_locks_freed",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "6405-6427",
          "snippet": "void debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_rwbase_rt",
          "args": [
            "&(sem)->rwbase"
          ],
          "line": 1379
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid __init_rwsem(struct rw_semaphore *sem, const char *name,\n\t\t  struct lock_class_key *key)\n{\n\tinit_rwbase_rt(&(sem)->rwbase);\n\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));\n\tlockdep_init_map_wait(&sem->dep_map, name, key, 0, LD_WAIT_SLEEP);\n#endif\n}"
  },
  {
    "function_name": "__downgrade_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1326-1343",
    "snippet": "static inline void __downgrade_write(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\t/*\n\t * When downgrading from exclusive to shared ownership,\n\t * anything inside the write-locked region cannot leak\n\t * into the read side. In contrast, anything in the\n\t * read-locked region is ok to be re-ordered into the\n\t * write side. As such, rely on RELEASE semantics.\n\t */\n\tDEBUG_RWSEMS_WARN_ON(rwsem_owner(sem) != current, sem);\n\ttmp = atomic_long_fetch_add_release(\n\t\t-RWSEM_WRITER_LOCKED+RWSEM_READER_BIAS, &sem->count);\n\trwsem_set_reader_owned(sem);\n\tif (tmp & RWSEM_FLAG_WAITERS)\n\t\trwsem_downgrade_wake(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)",
      "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_downgrade_wake",
          "args": [
            "sem"
          ],
          "line": 1342
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_downgrade_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1190-1204",
          "snippet": "static struct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_set_reader_owned",
          "args": [
            "sem"
          ],
          "line": 1340
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "173-176",
          "snippet": "static inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_fetch_add_release",
          "args": [
            "-RWSEM_WRITER_LOCKED+RWSEM_READER_BIAS",
            "&sem->count"
          ],
          "line": 1338
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "rwsem_owner(sem) != current",
            "sem"
          ],
          "line": 1337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_owner",
          "args": [
            "sem"
          ],
          "line": 1337
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "265-269",
          "snippet": "static inline struct task_struct *rwsem_owner(struct rw_semaphore *sem)\n{\n\treturn (struct task_struct *)\n\t\t(atomic_long_read(&sem->owner) & ~RWSEM_OWNER_FLAGS_MASK);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline struct task_struct *rwsem_owner(struct rw_semaphore *sem)\n{\n\treturn (struct task_struct *)\n\t\t(atomic_long_read(&sem->owner) & ~RWSEM_OWNER_FLAGS_MASK);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline void __downgrade_write(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\t/*\n\t * When downgrading from exclusive to shared ownership,\n\t * anything inside the write-locked region cannot leak\n\t * into the read side. In contrast, anything in the\n\t * read-locked region is ok to be re-ordered into the\n\t * write side. As such, rely on RELEASE semantics.\n\t */\n\tDEBUG_RWSEMS_WARN_ON(rwsem_owner(sem) != current, sem);\n\ttmp = atomic_long_fetch_add_release(\n\t\t-RWSEM_WRITER_LOCKED+RWSEM_READER_BIAS, &sem->count);\n\trwsem_set_reader_owned(sem);\n\tif (tmp & RWSEM_FLAG_WAITERS)\n\t\trwsem_downgrade_wake(sem);\n}"
  },
  {
    "function_name": "__up_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1305-1321",
    "snippet": "static inline void __up_write(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\t/*\n\t * sem->owner may differ from current if the ownership is transferred\n\t * to an anonymous writer by setting the RWSEM_NONSPINNABLE bits.\n\t */\n\tDEBUG_RWSEMS_WARN_ON((rwsem_owner(sem) != current) &&\n\t\t\t    !rwsem_test_oflags(sem, RWSEM_NONSPINNABLE), sem);\n\n\trwsem_clear_owner(sem);\n\ttmp = atomic_long_fetch_add_release(-RWSEM_WRITER_LOCKED, &sem->count);\n\tif (unlikely(tmp & RWSEM_FLAG_WAITERS))\n\t\trwsem_wake(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)",
      "#define RWSEM_WRITER_LOCKED\t(1UL << 0)",
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_wake",
          "args": [
            "sem"
          ],
          "line": 1320
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1169-1183",
          "snippet": "static struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "tmp & RWSEM_FLAG_WAITERS"
          ],
          "line": 1319
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_fetch_add_release",
          "args": [
            "-RWSEM_WRITER_LOCKED",
            "&sem->count"
          ],
          "line": 1318
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_clear_owner",
          "args": [
            "sem"
          ],
          "line": 1317
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_clear_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "141-144",
          "snippet": "static inline void rwsem_clear_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, 0);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_clear_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "(rwsem_owner(sem) != current) &&\n\t\t\t    !rwsem_test_oflags(sem, RWSEM_NONSPINNABLE)",
            "sem"
          ],
          "line": 1314
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_test_oflags",
          "args": [
            "sem",
            "RWSEM_NONSPINNABLE"
          ],
          "line": 1315
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_test_oflags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "149-152",
          "snippet": "static inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_owner",
          "args": [
            "sem"
          ],
          "line": 1314
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "265-269",
          "snippet": "static inline struct task_struct *rwsem_owner(struct rw_semaphore *sem)\n{\n\treturn (struct task_struct *)\n\t\t(atomic_long_read(&sem->owner) & ~RWSEM_OWNER_FLAGS_MASK);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline struct task_struct *rwsem_owner(struct rw_semaphore *sem)\n{\n\treturn (struct task_struct *)\n\t\t(atomic_long_read(&sem->owner) & ~RWSEM_OWNER_FLAGS_MASK);\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "sem->magic != sem",
            "sem"
          ],
          "line": 1309
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n\nstatic inline void __up_write(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\t/*\n\t * sem->owner may differ from current if the ownership is transferred\n\t * to an anonymous writer by setting the RWSEM_NONSPINNABLE bits.\n\t */\n\tDEBUG_RWSEMS_WARN_ON((rwsem_owner(sem) != current) &&\n\t\t\t    !rwsem_test_oflags(sem, RWSEM_NONSPINNABLE), sem);\n\n\trwsem_clear_owner(sem);\n\ttmp = atomic_long_fetch_add_release(-RWSEM_WRITER_LOCKED, &sem->count);\n\tif (unlikely(tmp & RWSEM_FLAG_WAITERS))\n\t\trwsem_wake(sem);\n}"
  },
  {
    "function_name": "__up_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1285-1300",
    "snippet": "static inline void __up_read(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\n\trwsem_clear_reader_owned(sem);\n\ttmp = atomic_long_add_return_release(-RWSEM_READER_BIAS, &sem->count);\n\tDEBUG_RWSEMS_WARN_ON(tmp < 0, sem);\n\tif (unlikely((tmp & (RWSEM_LOCK_MASK|RWSEM_FLAG_WAITERS)) ==\n\t\t      RWSEM_FLAG_WAITERS)) {\n\t\tclear_nonspinnable(sem);\n\t\trwsem_wake(sem);\n\t}\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
      "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_wake",
          "args": [
            "sem"
          ],
          "line": 1298
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1169-1183",
          "snippet": "static struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}"
        }
      },
      {
        "call_info": {
          "callee": "clear_nonspinnable",
          "args": [
            "sem"
          ],
          "line": 1297
        },
        "resolved": true,
        "details": {
          "function_name": "clear_nonspinnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "919-919",
          "snippet": "static inline void clear_nonspinnable(struct rw_semaphore *sem) { }",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void clear_nonspinnable(struct rw_semaphore *sem) { }"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "(tmp & (RWSEM_LOCK_MASK|RWSEM_FLAG_WAITERS)) ==\n\t\t      RWSEM_FLAG_WAITERS"
          ],
          "line": 1295
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "tmp < 0",
            "sem"
          ],
          "line": 1294
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_add_return_release",
          "args": [
            "-RWSEM_READER_BIAS",
            "&sem->count"
          ],
          "line": 1293
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_clear_reader_owned",
          "args": [
            "sem"
          ],
          "line": 1292
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_clear_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "213-215",
          "snippet": "static inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)\n{\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "!is_rwsem_reader_owned(sem)",
            "sem"
          ],
          "line": 1290
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_rwsem_reader_owned",
          "args": [
            "sem"
          ],
          "line": 1290
        },
        "resolved": true,
        "details": {
          "function_name": "is_rwsem_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1446-1451",
          "snippet": "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "sem->magic != sem",
            "sem"
          ],
          "line": 1289
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void __up_read(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\n\trwsem_clear_reader_owned(sem);\n\ttmp = atomic_long_add_return_release(-RWSEM_READER_BIAS, &sem->count);\n\tDEBUG_RWSEMS_WARN_ON(tmp < 0, sem);\n\tif (unlikely((tmp & (RWSEM_LOCK_MASK|RWSEM_FLAG_WAITERS)) ==\n\t\t      RWSEM_FLAG_WAITERS)) {\n\t\tclear_nonspinnable(sem);\n\t\trwsem_wake(sem);\n\t}\n}"
  },
  {
    "function_name": "__down_write_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1276-1280",
    "snippet": "static inline int __down_write_trylock(struct rw_semaphore *sem)\n{\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\treturn rwsem_write_trylock(sem);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_write_trylock",
          "args": [
            "sem"
          ],
          "line": 1279
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_write_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "250-260",
          "snippet": "static inline bool rwsem_write_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp = RWSEM_UNLOCKED_VALUE;\n\n\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {\n\t\trwsem_set_owner(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_write_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp = RWSEM_UNLOCKED_VALUE;\n\n\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {\n\t\trwsem_set_owner(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "sem->magic != sem",
            "sem"
          ],
          "line": 1278
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_trylock(struct rw_semaphore *sem)\n{\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\treturn rwsem_write_trylock(sem);\n}"
  },
  {
    "function_name": "__down_write_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1271-1274",
    "snippet": "static inline int __down_write_killable(struct rw_semaphore *sem)\n{\n\treturn __down_write_common(sem, TASK_KILLABLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__down_write_common",
          "args": [
            "sem",
            "TASK_KILLABLE"
          ],
          "line": 1273
        },
        "resolved": true,
        "details": {
          "function_name": "__down_write_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1256-1264",
          "snippet": "static inline int __down_write_common(struct rw_semaphore *sem, int state)\n{\n\tif (unlikely(!rwsem_write_trylock(sem))) {\n\t\tif (IS_ERR(rwsem_down_write_slowpath(sem, state)))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_common(struct rw_semaphore *sem, int state)\n{\n\tif (unlikely(!rwsem_write_trylock(sem))) {\n\t\tif (IS_ERR(rwsem_down_write_slowpath(sem, state)))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_killable(struct rw_semaphore *sem)\n{\n\treturn __down_write_common(sem, TASK_KILLABLE);\n}"
  },
  {
    "function_name": "__down_write",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1266-1269",
    "snippet": "static inline void __down_write(struct rw_semaphore *sem)\n{\n\t__down_write_common(sem, TASK_UNINTERRUPTIBLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__down_write_common",
          "args": [
            "sem",
            "TASK_UNINTERRUPTIBLE"
          ],
          "line": 1268
        },
        "resolved": true,
        "details": {
          "function_name": "__down_write_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1256-1264",
          "snippet": "static inline int __down_write_common(struct rw_semaphore *sem, int state)\n{\n\tif (unlikely(!rwsem_write_trylock(sem))) {\n\t\tif (IS_ERR(rwsem_down_write_slowpath(sem, state)))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_common(struct rw_semaphore *sem, int state)\n{\n\tif (unlikely(!rwsem_write_trylock(sem))) {\n\t\tif (IS_ERR(rwsem_down_write_slowpath(sem, state)))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __down_write(struct rw_semaphore *sem)\n{\n\t__down_write_common(sem, TASK_UNINTERRUPTIBLE);\n}"
  },
  {
    "function_name": "__down_write_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1256-1264",
    "snippet": "static inline int __down_write_common(struct rw_semaphore *sem, int state)\n{\n\tif (unlikely(!rwsem_write_trylock(sem))) {\n\t\tif (IS_ERR(rwsem_down_write_slowpath(sem, state)))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "rwsem_down_write_slowpath(sem, state)"
          ],
          "line": 1259
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_down_write_slowpath",
          "args": [
            "sem",
            "state"
          ],
          "line": 1259
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_down_write_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1051-1163",
          "snippet": "static struct rw_semaphore *\nrwsem_down_write_slowpath(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/* do optimistic spinning and steal lock if possible */\n\tif (rwsem_can_spin_on_owner(sem) && rwsem_optimistic_spin(sem)) {\n\t\t/* rwsem_optimistic_spin() implies ACQUIRE on success */\n\t\treturn sem;\n\t}\n\n\t/*\n\t * Optimistic spinning failed, proceed to the slowpath\n\t * and block until we can acquire the sem.\n\t */\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_WRITE;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\twaiter.handoff_set = false;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock */\n\tif (rwsem_first_waiter(sem) != &waiter) {\n\t\tcount = atomic_long_read(&sem->count);\n\n\t\t/*\n\t\t * If there were already threads queued before us and:\n\t\t *  1) there are no active locks, wake the front\n\t\t *     queued process(es) as the handoff bit might be set.\n\t\t *  2) there are no active writers and some readers, the lock\n\t\t *     must be read owned; so we try to wake any read lock\n\t\t *     waiters that were queued ahead of us.\n\t\t */\n\t\tif (count & RWSEM_WRITER_MASK)\n\t\t\tgoto wait;\n\n\t\trwsem_mark_wake(sem, (count & RWSEM_READER_MASK)\n\t\t\t\t\t? RWSEM_WAKE_READERS\n\t\t\t\t\t: RWSEM_WAKE_ANY, &wake_q);\n\n\t\tif (!wake_q_empty(&wake_q)) {\n\t\t\t/*\n\t\t\t * We want to minimize wait_lock hold time especially\n\t\t\t * when a large number of readers are to be woken up.\n\t\t\t */\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t\twake_q_init(&wake_q);\t/* Used again, reinit */\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t}\n\t} else {\n\t\tatomic_long_or(RWSEM_FLAG_WAITERS, &sem->count);\n\t}\n\nwait:\n\t/* wait until we successfully acquire the lock */\n\tset_current_state(state);\n\tfor (;;) {\n\t\tif (rwsem_try_write_lock(sem, &waiter)) {\n\t\t\t/* rwsem_try_write_lock() implies ACQUIRE on success */\n\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_unlock_irq(&sem->wait_lock);\n\n\t\tif (signal_pending_state(state, current))\n\t\t\tgoto out_nolock;\n\n\t\t/*\n\t\t * After setting the handoff bit and failing to acquire\n\t\t * the lock, attempt to spin on owner to accelerate lock\n\t\t * transfer. If the previous owner is a on-cpu writer and it\n\t\t * has just released the lock, OWNER_NULL will be returned.\n\t\t * In this case, we attempt to acquire the lock again\n\t\t * without sleeping.\n\t\t */\n\t\tif (waiter.handoff_set) {\n\t\t\tenum owner_state owner_state;\n\n\t\t\tpreempt_disable();\n\t\t\towner_state = rwsem_spin_on_owner(sem);\n\t\t\tpreempt_enable();\n\n\t\t\tif (owner_state == OWNER_NULL)\n\t\t\t\tgoto trylock_again;\n\t\t}\n\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_writer);\n\t\tset_current_state(state);\ntrylock_again:\n\t\traw_spin_lock_irq(&sem->wait_lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\tlockevent_inc(rwsem_wlock);\n\treturn sem;\n\nout_nolock:\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_del_waiter(sem, &waiter);\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\tlockevent_inc(rwsem_wlock_fail);\n\treturn ERR_PTR(-EINTR);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)",
            "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
            "#define RWSEM_READER_MASK\t(~(RWSEM_READER_BIAS - 1))",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_MASK\t(~(RWSEM_READER_BIAS - 1))\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic struct rw_semaphore *\nrwsem_down_write_slowpath(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/* do optimistic spinning and steal lock if possible */\n\tif (rwsem_can_spin_on_owner(sem) && rwsem_optimistic_spin(sem)) {\n\t\t/* rwsem_optimistic_spin() implies ACQUIRE on success */\n\t\treturn sem;\n\t}\n\n\t/*\n\t * Optimistic spinning failed, proceed to the slowpath\n\t * and block until we can acquire the sem.\n\t */\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_WRITE;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\twaiter.handoff_set = false;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock */\n\tif (rwsem_first_waiter(sem) != &waiter) {\n\t\tcount = atomic_long_read(&sem->count);\n\n\t\t/*\n\t\t * If there were already threads queued before us and:\n\t\t *  1) there are no active locks, wake the front\n\t\t *     queued process(es) as the handoff bit might be set.\n\t\t *  2) there are no active writers and some readers, the lock\n\t\t *     must be read owned; so we try to wake any read lock\n\t\t *     waiters that were queued ahead of us.\n\t\t */\n\t\tif (count & RWSEM_WRITER_MASK)\n\t\t\tgoto wait;\n\n\t\trwsem_mark_wake(sem, (count & RWSEM_READER_MASK)\n\t\t\t\t\t? RWSEM_WAKE_READERS\n\t\t\t\t\t: RWSEM_WAKE_ANY, &wake_q);\n\n\t\tif (!wake_q_empty(&wake_q)) {\n\t\t\t/*\n\t\t\t * We want to minimize wait_lock hold time especially\n\t\t\t * when a large number of readers are to be woken up.\n\t\t\t */\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t\twake_q_init(&wake_q);\t/* Used again, reinit */\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t}\n\t} else {\n\t\tatomic_long_or(RWSEM_FLAG_WAITERS, &sem->count);\n\t}\n\nwait:\n\t/* wait until we successfully acquire the lock */\n\tset_current_state(state);\n\tfor (;;) {\n\t\tif (rwsem_try_write_lock(sem, &waiter)) {\n\t\t\t/* rwsem_try_write_lock() implies ACQUIRE on success */\n\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_unlock_irq(&sem->wait_lock);\n\n\t\tif (signal_pending_state(state, current))\n\t\t\tgoto out_nolock;\n\n\t\t/*\n\t\t * After setting the handoff bit and failing to acquire\n\t\t * the lock, attempt to spin on owner to accelerate lock\n\t\t * transfer. If the previous owner is a on-cpu writer and it\n\t\t * has just released the lock, OWNER_NULL will be returned.\n\t\t * In this case, we attempt to acquire the lock again\n\t\t * without sleeping.\n\t\t */\n\t\tif (waiter.handoff_set) {\n\t\t\tenum owner_state owner_state;\n\n\t\t\tpreempt_disable();\n\t\t\towner_state = rwsem_spin_on_owner(sem);\n\t\t\tpreempt_enable();\n\n\t\t\tif (owner_state == OWNER_NULL)\n\t\t\t\tgoto trylock_again;\n\t\t}\n\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_writer);\n\t\tset_current_state(state);\ntrylock_again:\n\t\traw_spin_lock_irq(&sem->wait_lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\tlockevent_inc(rwsem_wlock);\n\treturn sem;\n\nout_nolock:\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_del_waiter(sem, &waiter);\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\tlockevent_inc(rwsem_wlock_fail);\n\treturn ERR_PTR(-EINTR);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!rwsem_write_trylock(sem)"
          ],
          "line": 1258
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_write_trylock",
          "args": [
            "sem"
          ],
          "line": 1258
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_write_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "250-260",
          "snippet": "static inline bool rwsem_write_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp = RWSEM_UNLOCKED_VALUE;\n\n\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {\n\t\trwsem_set_owner(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_write_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp = RWSEM_UNLOCKED_VALUE;\n\n\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {\n\t\trwsem_set_owner(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_write_common(struct rw_semaphore *sem, int state)\n{\n\tif (unlikely(!rwsem_write_trylock(sem))) {\n\t\tif (IS_ERR(rwsem_down_write_slowpath(sem, state)))\n\t\t\treturn -EINTR;\n\t}\n\n\treturn 0;\n}"
  },
  {
    "function_name": "__down_read_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1236-1251",
    "snippet": "static inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\n\ttmp = atomic_long_read(&sem->count);\n\twhile (!(tmp & RWSEM_READ_FAILED_MASK)) {\n\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp,\n\t\t\t\t\t\t    tmp + RWSEM_READER_BIAS)) {\n\t\t\trwsem_set_reader_owned(sem);\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_READ_FAILED_MASK\t(RWSEM_WRITER_MASK|RWSEM_FLAG_WAITERS|\\\n\t\t\t\t RWSEM_FLAG_HANDOFF|RWSEM_FLAG_READFAIL)",
      "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_set_reader_owned",
          "args": [
            "sem"
          ],
          "line": 1246
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "173-176",
          "snippet": "static inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&sem->count",
            "&tmp",
            "tmp + RWSEM_READER_BIAS"
          ],
          "line": 1244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 1242
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "sem->magic != sem",
            "sem"
          ],
          "line": 1240
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_READ_FAILED_MASK\t(RWSEM_WRITER_MASK|RWSEM_FLAG_WAITERS|\\\n\t\t\t\t RWSEM_FLAG_HANDOFF|RWSEM_FLAG_READFAIL)\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n\nstatic inline int __down_read_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp;\n\n\tDEBUG_RWSEMS_WARN_ON(sem->magic != sem, sem);\n\n\ttmp = atomic_long_read(&sem->count);\n\twhile (!(tmp & RWSEM_READ_FAILED_MASK)) {\n\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp,\n\t\t\t\t\t\t    tmp + RWSEM_READER_BIAS)) {\n\t\t\trwsem_set_reader_owned(sem);\n\t\t\treturn 1;\n\t\t}\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "__down_read_killable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1231-1234",
    "snippet": "static inline int __down_read_killable(struct rw_semaphore *sem)\n{\n\treturn __down_read_common(sem, TASK_KILLABLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__down_read_common",
          "args": [
            "sem",
            "TASK_KILLABLE"
          ],
          "line": 1233
        },
        "resolved": true,
        "details": {
          "function_name": "__down_read_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1209-1219",
          "snippet": "static inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_killable(struct rw_semaphore *sem)\n{\n\treturn __down_read_common(sem, TASK_KILLABLE);\n}"
  },
  {
    "function_name": "__down_read_interruptible",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1226-1229",
    "snippet": "static inline int __down_read_interruptible(struct rw_semaphore *sem)\n{\n\treturn __down_read_common(sem, TASK_INTERRUPTIBLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__down_read_common",
          "args": [
            "sem",
            "TASK_INTERRUPTIBLE"
          ],
          "line": 1228
        },
        "resolved": true,
        "details": {
          "function_name": "__down_read_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1209-1219",
          "snippet": "static inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_interruptible(struct rw_semaphore *sem)\n{\n\treturn __down_read_common(sem, TASK_INTERRUPTIBLE);\n}"
  },
  {
    "function_name": "__down_read",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1221-1224",
    "snippet": "static inline void __down_read(struct rw_semaphore *sem)\n{\n\t__down_read_common(sem, TASK_UNINTERRUPTIBLE);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__down_read_common",
          "args": [
            "sem",
            "TASK_UNINTERRUPTIBLE"
          ],
          "line": 1223
        },
        "resolved": true,
        "details": {
          "function_name": "__down_read_common",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1209-1219",
          "snippet": "static inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __down_read(struct rw_semaphore *sem)\n{\n\t__down_read_common(sem, TASK_UNINTERRUPTIBLE);\n}"
  },
  {
    "function_name": "__down_read_common",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1209-1219",
    "snippet": "static inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "DEBUG_RWSEMS_WARN_ON",
          "args": [
            "!is_rwsem_reader_owned(sem)",
            "sem"
          ],
          "line": 1216
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "is_rwsem_reader_owned",
          "args": [
            "sem"
          ],
          "line": 1216
        },
        "resolved": true,
        "details": {
          "function_name": "is_rwsem_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1446-1451",
          "snippet": "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n\tint count = atomic_read(&sem->rwbase.readers);\n\n\treturn count < 0 && count != READER_BIAS;\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "rwsem_down_read_slowpath(sem, count, state)"
          ],
          "line": 1214
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_down_read_slowpath",
          "args": [
            "sem",
            "count",
            "state"
          ],
          "line": 1214
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_down_read_slowpath",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "931-1046",
          "snippet": "static struct rw_semaphore __sched *\nrwsem_down_read_slowpath(struct rw_semaphore *sem, long count, unsigned int state)\n{\n\tlong adjustment = -RWSEM_READER_BIAS;\n\tlong rcnt = (count >> RWSEM_READER_SHIFT);\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\tbool wake = false;\n\n\t/*\n\t * To prevent a constant stream of readers from starving a sleeping\n\t * waiter, don't attempt optimistic lock stealing if the lock is\n\t * currently owned by readers.\n\t */\n\tif ((atomic_long_read(&sem->owner) & RWSEM_READER_OWNED) &&\n\t    (rcnt > 1) && !(count & RWSEM_WRITER_LOCKED))\n\t\tgoto queue;\n\n\t/*\n\t * Reader optimistic lock stealing.\n\t */\n\tif (!(count & (RWSEM_WRITER_LOCKED | RWSEM_FLAG_HANDOFF))) {\n\t\trwsem_set_reader_owned(sem);\n\t\tlockevent_inc(rwsem_rlock_steal);\n\n\t\t/*\n\t\t * Wake up other readers in the wait queue if it is\n\t\t * the first reader.\n\t\t */\n\t\tif ((rcnt == 1) && (count & RWSEM_FLAG_WAITERS)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (!list_empty(&sem->wait_list))\n\t\t\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED,\n\t\t\t\t\t\t&wake_q);\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t}\n\t\treturn sem;\n\t}\n\nqueue:\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_READ;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * In case the wait queue is empty and the lock isn't owned\n\t\t * by a writer or has the handoff bit set, this reader can\n\t\t * exit the slowpath and return immediately as its\n\t\t * RWSEM_READER_BIAS has already been set in the count.\n\t\t */\n\t\tif (!(atomic_long_read(&sem->count) &\n\t\t     (RWSEM_WRITER_MASK | RWSEM_FLAG_HANDOFF))) {\n\t\t\t/* Provide lock ACQUIRE */\n\t\t\tsmp_acquire__after_ctrl_dep();\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\trwsem_set_reader_owned(sem);\n\t\t\tlockevent_inc(rwsem_rlock_fast);\n\t\t\treturn sem;\n\t\t}\n\t\tadjustment += RWSEM_FLAG_WAITERS;\n\t}\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock, but no longer actively locking */\n\tcount = atomic_long_add_return(adjustment, &sem->count);\n\n\t/*\n\t * If there are no active locks, wake the front queued process(es).\n\t *\n\t * If there are no writers and we are first in the queue,\n\t * wake our own waiter to join the existing active readers !\n\t */\n\tif (!(count & RWSEM_LOCK_MASK)) {\n\t\tclear_nonspinnable(sem);\n\t\twake = true;\n\t}\n\tif (wake || (!(count & RWSEM_WRITER_MASK) &&\n\t\t    (adjustment & RWSEM_FLAG_WAITERS)))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\n\t/* wait to be given the lock */\n\tfor (;;) {\n\t\tset_current_state(state);\n\t\tif (!smp_load_acquire(&waiter.task)) {\n\t\t\t/* Matches rwsem_mark_wake()'s smp_store_release(). */\n\t\t\tbreak;\n\t\t}\n\t\tif (signal_pending_state(state, current)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (waiter.task)\n\t\t\t\tgoto out_nolock;\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\t/* Ordered by sem->wait_lock against rwsem_mark_wake(). */\n\t\t\tbreak;\n\t\t}\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_reader);\n\t}\n\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock);\n\treturn sem;\n\nout_nolock:\n\trwsem_del_waiter(sem, &waiter);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock_fail);\n\treturn ERR_PTR(-EINTR);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)",
            "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
            "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
            "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
            "#define RWSEM_READER_SHIFT\t8",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)",
            "#define RWSEM_WRITER_LOCKED\t(1UL << 0)",
            "#define RWSEM_READER_OWNED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_READER_SHIFT\t8\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic struct rw_semaphore __sched *\nrwsem_down_read_slowpath(struct rw_semaphore *sem, long count, unsigned int state)\n{\n\tlong adjustment = -RWSEM_READER_BIAS;\n\tlong rcnt = (count >> RWSEM_READER_SHIFT);\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\tbool wake = false;\n\n\t/*\n\t * To prevent a constant stream of readers from starving a sleeping\n\t * waiter, don't attempt optimistic lock stealing if the lock is\n\t * currently owned by readers.\n\t */\n\tif ((atomic_long_read(&sem->owner) & RWSEM_READER_OWNED) &&\n\t    (rcnt > 1) && !(count & RWSEM_WRITER_LOCKED))\n\t\tgoto queue;\n\n\t/*\n\t * Reader optimistic lock stealing.\n\t */\n\tif (!(count & (RWSEM_WRITER_LOCKED | RWSEM_FLAG_HANDOFF))) {\n\t\trwsem_set_reader_owned(sem);\n\t\tlockevent_inc(rwsem_rlock_steal);\n\n\t\t/*\n\t\t * Wake up other readers in the wait queue if it is\n\t\t * the first reader.\n\t\t */\n\t\tif ((rcnt == 1) && (count & RWSEM_FLAG_WAITERS)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (!list_empty(&sem->wait_list))\n\t\t\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED,\n\t\t\t\t\t\t&wake_q);\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t}\n\t\treturn sem;\n\t}\n\nqueue:\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_READ;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * In case the wait queue is empty and the lock isn't owned\n\t\t * by a writer or has the handoff bit set, this reader can\n\t\t * exit the slowpath and return immediately as its\n\t\t * RWSEM_READER_BIAS has already been set in the count.\n\t\t */\n\t\tif (!(atomic_long_read(&sem->count) &\n\t\t     (RWSEM_WRITER_MASK | RWSEM_FLAG_HANDOFF))) {\n\t\t\t/* Provide lock ACQUIRE */\n\t\t\tsmp_acquire__after_ctrl_dep();\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\trwsem_set_reader_owned(sem);\n\t\t\tlockevent_inc(rwsem_rlock_fast);\n\t\t\treturn sem;\n\t\t}\n\t\tadjustment += RWSEM_FLAG_WAITERS;\n\t}\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock, but no longer actively locking */\n\tcount = atomic_long_add_return(adjustment, &sem->count);\n\n\t/*\n\t * If there are no active locks, wake the front queued process(es).\n\t *\n\t * If there are no writers and we are first in the queue,\n\t * wake our own waiter to join the existing active readers !\n\t */\n\tif (!(count & RWSEM_LOCK_MASK)) {\n\t\tclear_nonspinnable(sem);\n\t\twake = true;\n\t}\n\tif (wake || (!(count & RWSEM_WRITER_MASK) &&\n\t\t    (adjustment & RWSEM_FLAG_WAITERS)))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\n\t/* wait to be given the lock */\n\tfor (;;) {\n\t\tset_current_state(state);\n\t\tif (!smp_load_acquire(&waiter.task)) {\n\t\t\t/* Matches rwsem_mark_wake()'s smp_store_release(). */\n\t\t\tbreak;\n\t\t}\n\t\tif (signal_pending_state(state, current)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (waiter.task)\n\t\t\t\tgoto out_nolock;\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\t/* Ordered by sem->wait_lock against rwsem_mark_wake(). */\n\t\t\tbreak;\n\t\t}\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_reader);\n\t}\n\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock);\n\treturn sem;\n\nout_nolock:\n\trwsem_del_waiter(sem, &waiter);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock_fail);\n\treturn ERR_PTR(-EINTR);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_read_trylock",
          "args": [
            "sem",
            "&count"
          ],
          "line": 1213
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_read_trylock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "235-248",
          "snippet": "static inline bool rwsem_read_trylock(struct rw_semaphore *sem, long *cntp)\n{\n\t*cntp = atomic_long_add_return_acquire(RWSEM_READER_BIAS, &sem->count);\n\n\tif (WARN_ON_ONCE(*cntp < 0))\n\t\trwsem_set_nonspinnable(sem);\n\n\tif (!(*cntp & RWSEM_READ_FAILED_MASK)) {\n\t\trwsem_set_reader_owned(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_READ_FAILED_MASK\t(RWSEM_WRITER_MASK|RWSEM_FLAG_WAITERS|\\\n\t\t\t\t RWSEM_FLAG_HANDOFF|RWSEM_FLAG_READFAIL)",
            "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_READ_FAILED_MASK\t(RWSEM_WRITER_MASK|RWSEM_FLAG_WAITERS|\\\n\t\t\t\t RWSEM_FLAG_HANDOFF|RWSEM_FLAG_READFAIL)\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n\nstatic inline bool rwsem_read_trylock(struct rw_semaphore *sem, long *cntp)\n{\n\t*cntp = atomic_long_add_return_acquire(RWSEM_READER_BIAS, &sem->count);\n\n\tif (WARN_ON_ONCE(*cntp < 0))\n\t\trwsem_set_nonspinnable(sem);\n\n\tif (!(*cntp & RWSEM_READ_FAILED_MASK)) {\n\t\trwsem_set_reader_owned(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline int __down_read_common(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\n\tif (!rwsem_read_trylock(sem, &count)) {\n\t\tif (IS_ERR(rwsem_down_read_slowpath(sem, count, state)))\n\t\t\treturn -EINTR;\n\t\tDEBUG_RWSEMS_WARN_ON(!is_rwsem_reader_owned(sem), sem);\n\t}\n\treturn 0;\n}"
  },
  {
    "function_name": "rwsem_downgrade_wake",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1190-1204",
    "snippet": "static struct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 1201
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_up_q",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "469-482",
          "snippet": "static __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&sem->wait_lock",
            "flags"
          ],
          "line": 1200
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_mark_wake",
          "args": [
            "sem",
            "RWSEM_WAKE_READ_OWNED",
            "&wake_q"
          ],
          "line": 1198
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_mark_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "404-559",
          "snippet": "static void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define MAX_READERS_WAKEUP\t0x100",
            "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
            "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define MAX_READERS_WAKEUP\t0x100\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&sem->wait_list"
          ],
          "line": 1197
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&sem->wait_lock",
            "flags"
          ],
          "line": 1195
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 1193
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}"
  },
  {
    "function_name": "rwsem_wake",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1169-1183",
    "snippet": "static struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 1180
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_up_q",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "469-482",
          "snippet": "static __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore",
          "args": [
            "&sem->wait_lock",
            "flags"
          ],
          "line": 1179
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "192-195",
          "snippet": "void __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)\n{\n\t__raw_spin_unlock_irqrestore(lock, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_mark_wake",
          "args": [
            "sem",
            "RWSEM_WAKE_ANY",
            "&wake_q"
          ],
          "line": 1177
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_mark_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "404-559",
          "snippet": "static void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define MAX_READERS_WAKEUP\t0x100",
            "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
            "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define MAX_READERS_WAKEUP\t0x100\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&sem->wait_list"
          ],
          "line": 1176
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave",
          "args": [
            "&sem->wait_lock",
            "flags"
          ],
          "line": 1174
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irqsave_nested",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "383-393",
          "snippet": "unsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nunsigned long __lockfunc _raw_spin_lock_irqsave_nested(raw_spinlock_t *lock,\n\t\t\t\t\t\t   int subclass)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tpreempt_disable();\n\tspin_acquire(&lock->dep_map, subclass, 0, _RET_IP_);\n\tLOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);\n\treturn flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 1172
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\n{\n\tunsigned long flags;\n\tDEFINE_WAKE_Q(wake_q);\n\n\traw_spin_lock_irqsave(&sem->wait_lock, flags);\n\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irqrestore(&sem->wait_lock, flags);\n\twake_up_q(&wake_q);\n\n\treturn sem;\n}"
  },
  {
    "function_name": "rwsem_down_write_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "1051-1163",
    "snippet": "static struct rw_semaphore *\nrwsem_down_write_slowpath(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/* do optimistic spinning and steal lock if possible */\n\tif (rwsem_can_spin_on_owner(sem) && rwsem_optimistic_spin(sem)) {\n\t\t/* rwsem_optimistic_spin() implies ACQUIRE on success */\n\t\treturn sem;\n\t}\n\n\t/*\n\t * Optimistic spinning failed, proceed to the slowpath\n\t * and block until we can acquire the sem.\n\t */\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_WRITE;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\twaiter.handoff_set = false;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock */\n\tif (rwsem_first_waiter(sem) != &waiter) {\n\t\tcount = atomic_long_read(&sem->count);\n\n\t\t/*\n\t\t * If there were already threads queued before us and:\n\t\t *  1) there are no active locks, wake the front\n\t\t *     queued process(es) as the handoff bit might be set.\n\t\t *  2) there are no active writers and some readers, the lock\n\t\t *     must be read owned; so we try to wake any read lock\n\t\t *     waiters that were queued ahead of us.\n\t\t */\n\t\tif (count & RWSEM_WRITER_MASK)\n\t\t\tgoto wait;\n\n\t\trwsem_mark_wake(sem, (count & RWSEM_READER_MASK)\n\t\t\t\t\t? RWSEM_WAKE_READERS\n\t\t\t\t\t: RWSEM_WAKE_ANY, &wake_q);\n\n\t\tif (!wake_q_empty(&wake_q)) {\n\t\t\t/*\n\t\t\t * We want to minimize wait_lock hold time especially\n\t\t\t * when a large number of readers are to be woken up.\n\t\t\t */\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t\twake_q_init(&wake_q);\t/* Used again, reinit */\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t}\n\t} else {\n\t\tatomic_long_or(RWSEM_FLAG_WAITERS, &sem->count);\n\t}\n\nwait:\n\t/* wait until we successfully acquire the lock */\n\tset_current_state(state);\n\tfor (;;) {\n\t\tif (rwsem_try_write_lock(sem, &waiter)) {\n\t\t\t/* rwsem_try_write_lock() implies ACQUIRE on success */\n\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_unlock_irq(&sem->wait_lock);\n\n\t\tif (signal_pending_state(state, current))\n\t\t\tgoto out_nolock;\n\n\t\t/*\n\t\t * After setting the handoff bit and failing to acquire\n\t\t * the lock, attempt to spin on owner to accelerate lock\n\t\t * transfer. If the previous owner is a on-cpu writer and it\n\t\t * has just released the lock, OWNER_NULL will be returned.\n\t\t * In this case, we attempt to acquire the lock again\n\t\t * without sleeping.\n\t\t */\n\t\tif (waiter.handoff_set) {\n\t\t\tenum owner_state owner_state;\n\n\t\t\tpreempt_disable();\n\t\t\towner_state = rwsem_spin_on_owner(sem);\n\t\t\tpreempt_enable();\n\n\t\t\tif (owner_state == OWNER_NULL)\n\t\t\t\tgoto trylock_again;\n\t\t}\n\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_writer);\n\t\tset_current_state(state);\ntrylock_again:\n\t\traw_spin_lock_irq(&sem->wait_lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\tlockevent_inc(rwsem_wlock);\n\treturn sem;\n\nout_nolock:\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_del_waiter(sem, &waiter);\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\tlockevent_inc(rwsem_wlock_fail);\n\treturn ERR_PTR(-EINTR);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)",
      "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
      "#define RWSEM_READER_MASK\t(~(RWSEM_READER_BIAS - 1))",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINTR"
          ],
          "line": 1162
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_wlock_fail"
          ],
          "line": 1161
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 1160
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_up_q",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "469-482",
          "snippet": "static __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irq",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 1159
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "200-203",
          "snippet": "void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_mark_wake",
          "args": [
            "sem",
            "RWSEM_WAKE_ANY",
            "&wake_q"
          ],
          "line": 1158
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_mark_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "404-559",
          "snippet": "static void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define MAX_READERS_WAKEUP\t0x100",
            "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
            "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define MAX_READERS_WAKEUP\t0x100\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&sem->wait_list"
          ],
          "line": 1157
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_del_waiter",
          "args": [
            "sem",
            "&waiter"
          ],
          "line": 1156
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_del_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "379-388",
          "snippet": "static inline void\nrwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_del(&waiter->list);\n\tif (likely(!list_empty(&sem->wait_list)))\n\t\treturn;\n\n\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void\nrwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_del(&waiter->list);\n\tif (likely(!list_empty(&sem->wait_list)))\n\t\treturn;\n\n\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irq",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 1155
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "168-171",
          "snippet": "void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 1154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_wlock"
          ],
          "line": 1150
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 1148
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 1144
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_sleep_writer"
          ],
          "line": 1143
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule",
          "args": [],
          "line": 1142
        },
        "resolved": true,
        "details": {
          "function_name": "audit_schedule_prune",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/audit_tree.c",
          "lines": "963-966",
          "snippet": "static void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}",
          "includes": [
            "#include <linux/slab.h>",
            "#include <linux/refcount.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mount.h>",
            "#include <linux/namei.h>",
            "#include <linux/fsnotify_backend.h>",
            "#include \"audit.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct task_struct *prune_thread;",
            "static void audit_schedule_prune(void);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/slab.h>\n#include <linux/refcount.h>\n#include <linux/kthread.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fsnotify_backend.h>\n#include \"audit.h\"\n\nstatic struct task_struct *prune_thread;\nstatic void audit_schedule_prune(void);\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 1136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_spin_on_owner",
          "args": [
            "sem"
          ],
          "line": 1135
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_spin_on_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "921-925",
          "snippet": "static inline enum owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn OWNER_NONSPINNABLE;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline enum owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn OWNER_NONSPINNABLE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 1134
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "signal_pending_state",
          "args": [
            "state",
            "current"
          ],
          "line": 1120
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_try_write_lock",
          "args": [
            "sem",
            "&waiter"
          ],
          "line": 1113
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_try_write_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "568-622",
          "snippet": "static inline bool rwsem_try_write_lock(struct rw_semaphore *sem,\n\t\t\t\t\tstruct rwsem_waiter *waiter)\n{\n\tbool first = rwsem_first_waiter(sem) == waiter;\n\tlong count, new;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\tcount = atomic_long_read(&sem->count);\n\tdo {\n\t\tbool has_handoff = !!(count & RWSEM_FLAG_HANDOFF);\n\n\t\tif (has_handoff) {\n\t\t\tif (!first)\n\t\t\t\treturn false;\n\n\t\t\t/* First waiter inherits a previously set handoff bit */\n\t\t\twaiter->handoff_set = true;\n\t\t}\n\n\t\tnew = count;\n\n\t\tif (count & RWSEM_LOCK_MASK) {\n\t\t\tif (has_handoff || (!rt_task(waiter->task) &&\n\t\t\t\t\t    !time_after(jiffies, waiter->timeout)))\n\t\t\t\treturn false;\n\n\t\t\tnew |= RWSEM_FLAG_HANDOFF;\n\t\t} else {\n\t\t\tnew |= RWSEM_WRITER_LOCKED;\n\t\t\tnew &= ~RWSEM_FLAG_HANDOFF;\n\n\t\t\tif (list_is_singular(&sem->wait_list))\n\t\t\t\tnew &= ~RWSEM_FLAG_WAITERS;\n\t\t}\n\t} while (!atomic_long_try_cmpxchg_acquire(&sem->count, &count, new));\n\n\t/*\n\t * We have either acquired the lock with handoff bit cleared or\n\t * set the handoff bit.\n\t */\n\tif (new & RWSEM_FLAG_HANDOFF) {\n\t\twaiter->handoff_set = true;\n\t\tlockevent_inc(rwsem_wlock_handoff);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Have rwsem_try_write_lock() fully imply rwsem_del_waiter() on\n\t * success.\n\t */\n\tlist_del(&waiter->list);\n\trwsem_set_owner(sem);\n\treturn true;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)",
            "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_try_write_lock(struct rw_semaphore *sem,\n\t\t\t\t\tstruct rwsem_waiter *waiter)\n{\n\tbool first = rwsem_first_waiter(sem) == waiter;\n\tlong count, new;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\tcount = atomic_long_read(&sem->count);\n\tdo {\n\t\tbool has_handoff = !!(count & RWSEM_FLAG_HANDOFF);\n\n\t\tif (has_handoff) {\n\t\t\tif (!first)\n\t\t\t\treturn false;\n\n\t\t\t/* First waiter inherits a previously set handoff bit */\n\t\t\twaiter->handoff_set = true;\n\t\t}\n\n\t\tnew = count;\n\n\t\tif (count & RWSEM_LOCK_MASK) {\n\t\t\tif (has_handoff || (!rt_task(waiter->task) &&\n\t\t\t\t\t    !time_after(jiffies, waiter->timeout)))\n\t\t\t\treturn false;\n\n\t\t\tnew |= RWSEM_FLAG_HANDOFF;\n\t\t} else {\n\t\t\tnew |= RWSEM_WRITER_LOCKED;\n\t\t\tnew &= ~RWSEM_FLAG_HANDOFF;\n\n\t\t\tif (list_is_singular(&sem->wait_list))\n\t\t\t\tnew &= ~RWSEM_FLAG_WAITERS;\n\t\t}\n\t} while (!atomic_long_try_cmpxchg_acquire(&sem->count, &count, new));\n\n\t/*\n\t * We have either acquired the lock with handoff bit cleared or\n\t * set the handoff bit.\n\t */\n\tif (new & RWSEM_FLAG_HANDOFF) {\n\t\twaiter->handoff_set = true;\n\t\tlockevent_inc(rwsem_wlock_handoff);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Have rwsem_try_write_lock() fully imply rwsem_del_waiter() on\n\t * success.\n\t */\n\tlist_del(&waiter->list);\n\trwsem_set_owner(sem);\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 1111
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_or",
          "args": [
            "RWSEM_FLAG_WAITERS",
            "&sem->count"
          ],
          "line": 1106
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_q_init",
          "args": [
            "&wake_q"
          ],
          "line": 1102
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_q_empty",
          "args": [
            "&wake_q"
          ],
          "line": 1095
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 1078
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_first_waiter",
          "args": [
            "sem"
          ],
          "line": 1077
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_add_waiter",
          "args": [
            "sem",
            "&waiter"
          ],
          "line": 1074
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_add_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "365-371",
          "snippet": "static inline void\nrwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_add_tail(&waiter->list, &sem->wait_list);\n\t/* caller will set RWSEM_FLAG_WAITERS */\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void\nrwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_add_tail(&waiter->list, &sem->wait_list);\n\t/* caller will set RWSEM_FLAG_WAITERS */\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_optimistic_spin",
          "args": [
            "sem"
          ],
          "line": 1059
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_optimistic_spin",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "914-917",
          "snippet": "static inline bool rwsem_optimistic_spin(struct rw_semaphore *sem)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_optimistic_spin(struct rw_semaphore *sem)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_can_spin_on_owner",
          "args": [
            "sem"
          ],
          "line": 1059
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_can_spin_on_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "909-912",
          "snippet": "static inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 1056
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_MASK\t(~(RWSEM_READER_BIAS - 1))\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic struct rw_semaphore *\nrwsem_down_write_slowpath(struct rw_semaphore *sem, int state)\n{\n\tlong count;\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/* do optimistic spinning and steal lock if possible */\n\tif (rwsem_can_spin_on_owner(sem) && rwsem_optimistic_spin(sem)) {\n\t\t/* rwsem_optimistic_spin() implies ACQUIRE on success */\n\t\treturn sem;\n\t}\n\n\t/*\n\t * Optimistic spinning failed, proceed to the slowpath\n\t * and block until we can acquire the sem.\n\t */\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_WRITE;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\twaiter.handoff_set = false;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock */\n\tif (rwsem_first_waiter(sem) != &waiter) {\n\t\tcount = atomic_long_read(&sem->count);\n\n\t\t/*\n\t\t * If there were already threads queued before us and:\n\t\t *  1) there are no active locks, wake the front\n\t\t *     queued process(es) as the handoff bit might be set.\n\t\t *  2) there are no active writers and some readers, the lock\n\t\t *     must be read owned; so we try to wake any read lock\n\t\t *     waiters that were queued ahead of us.\n\t\t */\n\t\tif (count & RWSEM_WRITER_MASK)\n\t\t\tgoto wait;\n\n\t\trwsem_mark_wake(sem, (count & RWSEM_READER_MASK)\n\t\t\t\t\t? RWSEM_WAKE_READERS\n\t\t\t\t\t: RWSEM_WAKE_ANY, &wake_q);\n\n\t\tif (!wake_q_empty(&wake_q)) {\n\t\t\t/*\n\t\t\t * We want to minimize wait_lock hold time especially\n\t\t\t * when a large number of readers are to be woken up.\n\t\t\t */\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t\twake_q_init(&wake_q);\t/* Used again, reinit */\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t}\n\t} else {\n\t\tatomic_long_or(RWSEM_FLAG_WAITERS, &sem->count);\n\t}\n\nwait:\n\t/* wait until we successfully acquire the lock */\n\tset_current_state(state);\n\tfor (;;) {\n\t\tif (rwsem_try_write_lock(sem, &waiter)) {\n\t\t\t/* rwsem_try_write_lock() implies ACQUIRE on success */\n\t\t\tbreak;\n\t\t}\n\n\t\traw_spin_unlock_irq(&sem->wait_lock);\n\n\t\tif (signal_pending_state(state, current))\n\t\t\tgoto out_nolock;\n\n\t\t/*\n\t\t * After setting the handoff bit and failing to acquire\n\t\t * the lock, attempt to spin on owner to accelerate lock\n\t\t * transfer. If the previous owner is a on-cpu writer and it\n\t\t * has just released the lock, OWNER_NULL will be returned.\n\t\t * In this case, we attempt to acquire the lock again\n\t\t * without sleeping.\n\t\t */\n\t\tif (waiter.handoff_set) {\n\t\t\tenum owner_state owner_state;\n\n\t\t\tpreempt_disable();\n\t\t\towner_state = rwsem_spin_on_owner(sem);\n\t\t\tpreempt_enable();\n\n\t\t\tif (owner_state == OWNER_NULL)\n\t\t\t\tgoto trylock_again;\n\t\t}\n\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_writer);\n\t\tset_current_state(state);\ntrylock_again:\n\t\traw_spin_lock_irq(&sem->wait_lock);\n\t}\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\tlockevent_inc(rwsem_wlock);\n\treturn sem;\n\nout_nolock:\n\t__set_current_state(TASK_RUNNING);\n\traw_spin_lock_irq(&sem->wait_lock);\n\trwsem_del_waiter(sem, &waiter);\n\tif (!list_empty(&sem->wait_list))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\tlockevent_inc(rwsem_wlock_fail);\n\treturn ERR_PTR(-EINTR);\n}"
  },
  {
    "function_name": "rwsem_down_read_slowpath",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "931-1046",
    "snippet": "static struct rw_semaphore __sched *\nrwsem_down_read_slowpath(struct rw_semaphore *sem, long count, unsigned int state)\n{\n\tlong adjustment = -RWSEM_READER_BIAS;\n\tlong rcnt = (count >> RWSEM_READER_SHIFT);\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\tbool wake = false;\n\n\t/*\n\t * To prevent a constant stream of readers from starving a sleeping\n\t * waiter, don't attempt optimistic lock stealing if the lock is\n\t * currently owned by readers.\n\t */\n\tif ((atomic_long_read(&sem->owner) & RWSEM_READER_OWNED) &&\n\t    (rcnt > 1) && !(count & RWSEM_WRITER_LOCKED))\n\t\tgoto queue;\n\n\t/*\n\t * Reader optimistic lock stealing.\n\t */\n\tif (!(count & (RWSEM_WRITER_LOCKED | RWSEM_FLAG_HANDOFF))) {\n\t\trwsem_set_reader_owned(sem);\n\t\tlockevent_inc(rwsem_rlock_steal);\n\n\t\t/*\n\t\t * Wake up other readers in the wait queue if it is\n\t\t * the first reader.\n\t\t */\n\t\tif ((rcnt == 1) && (count & RWSEM_FLAG_WAITERS)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (!list_empty(&sem->wait_list))\n\t\t\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED,\n\t\t\t\t\t\t&wake_q);\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t}\n\t\treturn sem;\n\t}\n\nqueue:\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_READ;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * In case the wait queue is empty and the lock isn't owned\n\t\t * by a writer or has the handoff bit set, this reader can\n\t\t * exit the slowpath and return immediately as its\n\t\t * RWSEM_READER_BIAS has already been set in the count.\n\t\t */\n\t\tif (!(atomic_long_read(&sem->count) &\n\t\t     (RWSEM_WRITER_MASK | RWSEM_FLAG_HANDOFF))) {\n\t\t\t/* Provide lock ACQUIRE */\n\t\t\tsmp_acquire__after_ctrl_dep();\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\trwsem_set_reader_owned(sem);\n\t\t\tlockevent_inc(rwsem_rlock_fast);\n\t\t\treturn sem;\n\t\t}\n\t\tadjustment += RWSEM_FLAG_WAITERS;\n\t}\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock, but no longer actively locking */\n\tcount = atomic_long_add_return(adjustment, &sem->count);\n\n\t/*\n\t * If there are no active locks, wake the front queued process(es).\n\t *\n\t * If there are no writers and we are first in the queue,\n\t * wake our own waiter to join the existing active readers !\n\t */\n\tif (!(count & RWSEM_LOCK_MASK)) {\n\t\tclear_nonspinnable(sem);\n\t\twake = true;\n\t}\n\tif (wake || (!(count & RWSEM_WRITER_MASK) &&\n\t\t    (adjustment & RWSEM_FLAG_WAITERS)))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\n\t/* wait to be given the lock */\n\tfor (;;) {\n\t\tset_current_state(state);\n\t\tif (!smp_load_acquire(&waiter.task)) {\n\t\t\t/* Matches rwsem_mark_wake()'s smp_store_release(). */\n\t\t\tbreak;\n\t\t}\n\t\tif (signal_pending_state(state, current)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (waiter.task)\n\t\t\t\tgoto out_nolock;\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\t/* Ordered by sem->wait_lock against rwsem_mark_wake(). */\n\t\t\tbreak;\n\t\t}\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_reader);\n\t}\n\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock);\n\treturn sem;\n\nout_nolock:\n\trwsem_del_waiter(sem, &waiter);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock_fail);\n\treturn ERR_PTR(-EINTR);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)",
      "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
      "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
      "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
      "#define RWSEM_READER_SHIFT\t8",
      "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)",
      "#define RWSEM_WRITER_LOCKED\t(1UL << 0)",
      "#define RWSEM_READER_OWNED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINTR"
          ],
          "line": 1045
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_rlock_fail"
          ],
          "line": 1044
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 1043
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irq",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 1042
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_unlock_irq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "200-203",
          "snippet": "void __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_unlock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_del_waiter",
          "args": [
            "sem",
            "&waiter"
          ],
          "line": 1041
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_del_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "379-388",
          "snippet": "static inline void\nrwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_del(&waiter->list);\n\tif (likely(!list_empty(&sem->wait_list)))\n\t\treturn;\n\n\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void\nrwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_del(&waiter->list);\n\tif (likely(!list_empty(&sem->wait_list)))\n\t\treturn;\n\n\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_rlock"
          ],
          "line": 1037
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 1036
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_sleep_reader"
          ],
          "line": 1033
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule",
          "args": [],
          "line": 1032
        },
        "resolved": true,
        "details": {
          "function_name": "audit_schedule_prune",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/audit_tree.c",
          "lines": "963-966",
          "snippet": "static void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}",
          "includes": [
            "#include <linux/slab.h>",
            "#include <linux/refcount.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mount.h>",
            "#include <linux/namei.h>",
            "#include <linux/fsnotify_backend.h>",
            "#include \"audit.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct task_struct *prune_thread;",
            "static void audit_schedule_prune(void);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/slab.h>\n#include <linux/refcount.h>\n#include <linux/kthread.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fsnotify_backend.h>\n#include \"audit.h\"\n\nstatic struct task_struct *prune_thread;\nstatic void audit_schedule_prune(void);\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irq",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 1025
        },
        "resolved": true,
        "details": {
          "function_name": "_raw_spin_lock_irq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/spinlock.c",
          "lines": "168-171",
          "snippet": "void __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}",
          "includes": [
            "#include <linux/export.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/preempt.h>",
            "#include <linux/linkage.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/export.h>\n#include <linux/debug_locks.h>\n#include <linux/interrupt.h>\n#include <linux/spinlock.h>\n#include <linux/preempt.h>\n#include <linux/linkage.h>\n\nvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)\n{\n\t__raw_spin_lock_irq(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "signal_pending_state",
          "args": [
            "state",
            "current"
          ],
          "line": 1024
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "&waiter.task"
          ],
          "line": 1020
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "state"
          ],
          "line": 1019
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_up_q",
          "args": [
            "&wake_q"
          ],
          "line": 1015
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_up_q",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "469-482",
          "snippet": "static __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_up_q(struct rt_wake_q_head *wqh)\n{\n\tif (IS_ENABLED(CONFIG_PREEMPT_RT) && wqh->rtlock_task) {\n\t\twake_up_state(wqh->rtlock_task, TASK_RTLOCK_WAIT);\n\t\tput_task_struct(wqh->rtlock_task);\n\t\twqh->rtlock_task = NULL;\n\t}\n\n\tif (!wake_q_empty(&wqh->head))\n\t\twake_up_q(&wqh->head);\n\n\t/* Pairs with preempt_disable() in mark_wakeup_next_waiter() */\n\tpreempt_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_mark_wake",
          "args": [
            "sem",
            "RWSEM_WAKE_ANY",
            "&wake_q"
          ],
          "line": 1012
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_mark_wake",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "404-559",
          "snippet": "static void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define MAX_READERS_WAKEUP\t0x100",
            "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
            "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define MAX_READERS_WAKEUP\t0x100\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "clear_nonspinnable",
          "args": [
            "sem"
          ],
          "line": 1007
        },
        "resolved": true,
        "details": {
          "function_name": "clear_nonspinnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "919-919",
          "snippet": "static inline void clear_nonspinnable(struct rw_semaphore *sem) { }",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void clear_nonspinnable(struct rw_semaphore *sem) { }"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_add_return",
          "args": [
            "adjustment",
            "&sem->count"
          ],
          "line": 998
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_add_waiter",
          "args": [
            "sem",
            "&waiter"
          ],
          "line": 995
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_add_waiter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "365-371",
          "snippet": "static inline void\nrwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_add_tail(&waiter->list, &sem->wait_list);\n\t/* caller will set RWSEM_FLAG_WAITERS */\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void\nrwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_add_tail(&waiter->list, &sem->wait_list);\n\t/* caller will set RWSEM_FLAG_WAITERS */\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_rlock_fast"
          ],
          "line": 990
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_set_reader_owned",
          "args": [
            "sem"
          ],
          "line": 989
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "173-176",
          "snippet": "static inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_acquire__after_ctrl_dep",
          "args": [],
          "line": 987
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 984
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&sem->wait_list"
          ],
          "line": 977
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_rlock_steal"
          ],
          "line": 954
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 945
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "DEFINE_WAKE_Q",
          "args": [
            "wake_q"
          ],
          "line": 937
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WAIT_TIMEOUT\tDIV_ROUND_UP(HZ, 250)\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_READER_SHIFT\t8\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic struct rw_semaphore __sched *\nrwsem_down_read_slowpath(struct rw_semaphore *sem, long count, unsigned int state)\n{\n\tlong adjustment = -RWSEM_READER_BIAS;\n\tlong rcnt = (count >> RWSEM_READER_SHIFT);\n\tstruct rwsem_waiter waiter;\n\tDEFINE_WAKE_Q(wake_q);\n\tbool wake = false;\n\n\t/*\n\t * To prevent a constant stream of readers from starving a sleeping\n\t * waiter, don't attempt optimistic lock stealing if the lock is\n\t * currently owned by readers.\n\t */\n\tif ((atomic_long_read(&sem->owner) & RWSEM_READER_OWNED) &&\n\t    (rcnt > 1) && !(count & RWSEM_WRITER_LOCKED))\n\t\tgoto queue;\n\n\t/*\n\t * Reader optimistic lock stealing.\n\t */\n\tif (!(count & (RWSEM_WRITER_LOCKED | RWSEM_FLAG_HANDOFF))) {\n\t\trwsem_set_reader_owned(sem);\n\t\tlockevent_inc(rwsem_rlock_steal);\n\n\t\t/*\n\t\t * Wake up other readers in the wait queue if it is\n\t\t * the first reader.\n\t\t */\n\t\tif ((rcnt == 1) && (count & RWSEM_FLAG_WAITERS)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (!list_empty(&sem->wait_list))\n\t\t\t\trwsem_mark_wake(sem, RWSEM_WAKE_READ_OWNED,\n\t\t\t\t\t\t&wake_q);\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\twake_up_q(&wake_q);\n\t\t}\n\t\treturn sem;\n\t}\n\nqueue:\n\twaiter.task = current;\n\twaiter.type = RWSEM_WAITING_FOR_READ;\n\twaiter.timeout = jiffies + RWSEM_WAIT_TIMEOUT;\n\n\traw_spin_lock_irq(&sem->wait_lock);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * In case the wait queue is empty and the lock isn't owned\n\t\t * by a writer or has the handoff bit set, this reader can\n\t\t * exit the slowpath and return immediately as its\n\t\t * RWSEM_READER_BIAS has already been set in the count.\n\t\t */\n\t\tif (!(atomic_long_read(&sem->count) &\n\t\t     (RWSEM_WRITER_MASK | RWSEM_FLAG_HANDOFF))) {\n\t\t\t/* Provide lock ACQUIRE */\n\t\t\tsmp_acquire__after_ctrl_dep();\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\trwsem_set_reader_owned(sem);\n\t\t\tlockevent_inc(rwsem_rlock_fast);\n\t\t\treturn sem;\n\t\t}\n\t\tadjustment += RWSEM_FLAG_WAITERS;\n\t}\n\trwsem_add_waiter(sem, &waiter);\n\n\t/* we're now waiting on the lock, but no longer actively locking */\n\tcount = atomic_long_add_return(adjustment, &sem->count);\n\n\t/*\n\t * If there are no active locks, wake the front queued process(es).\n\t *\n\t * If there are no writers and we are first in the queue,\n\t * wake our own waiter to join the existing active readers !\n\t */\n\tif (!(count & RWSEM_LOCK_MASK)) {\n\t\tclear_nonspinnable(sem);\n\t\twake = true;\n\t}\n\tif (wake || (!(count & RWSEM_WRITER_MASK) &&\n\t\t    (adjustment & RWSEM_FLAG_WAITERS)))\n\t\trwsem_mark_wake(sem, RWSEM_WAKE_ANY, &wake_q);\n\n\traw_spin_unlock_irq(&sem->wait_lock);\n\twake_up_q(&wake_q);\n\n\t/* wait to be given the lock */\n\tfor (;;) {\n\t\tset_current_state(state);\n\t\tif (!smp_load_acquire(&waiter.task)) {\n\t\t\t/* Matches rwsem_mark_wake()'s smp_store_release(). */\n\t\t\tbreak;\n\t\t}\n\t\tif (signal_pending_state(state, current)) {\n\t\t\traw_spin_lock_irq(&sem->wait_lock);\n\t\t\tif (waiter.task)\n\t\t\t\tgoto out_nolock;\n\t\t\traw_spin_unlock_irq(&sem->wait_lock);\n\t\t\t/* Ordered by sem->wait_lock against rwsem_mark_wake(). */\n\t\t\tbreak;\n\t\t}\n\t\tschedule();\n\t\tlockevent_inc(rwsem_sleep_reader);\n\t}\n\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock);\n\treturn sem;\n\nout_nolock:\n\trwsem_del_waiter(sem, &waiter);\n\traw_spin_unlock_irq(&sem->wait_lock);\n\t__set_current_state(TASK_RUNNING);\n\tlockevent_inc(rwsem_rlock_fail);\n\treturn ERR_PTR(-EINTR);\n}"
  },
  {
    "function_name": "rwsem_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "921-925",
    "snippet": "static inline enum owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn OWNER_NONSPINNABLE;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline enum owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn OWNER_NONSPINNABLE;\n}"
  },
  {
    "function_name": "clear_nonspinnable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "919-919",
    "snippet": "static inline void clear_nonspinnable(struct rw_semaphore *sem) { }",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void clear_nonspinnable(struct rw_semaphore *sem) { }"
  },
  {
    "function_name": "rwsem_optimistic_spin",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "914-917",
    "snippet": "static inline bool rwsem_optimistic_spin(struct rw_semaphore *sem)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_optimistic_spin(struct rw_semaphore *sem)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "rwsem_can_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "909-912",
    "snippet": "static inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "clear_nonspinnable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "902-906",
    "snippet": "static inline void clear_nonspinnable(struct rw_semaphore *sem)\n{\n\tif (rwsem_test_oflags(sem, RWSEM_NONSPINNABLE))\n\t\tatomic_long_andnot(RWSEM_NONSPINNABLE, &sem->owner);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_andnot",
          "args": [
            "RWSEM_NONSPINNABLE",
            "&sem->owner"
          ],
          "line": 905
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_test_oflags",
          "args": [
            "sem",
            "RWSEM_NONSPINNABLE"
          ],
          "line": 904
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_test_oflags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "149-152",
          "snippet": "static inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n\nstatic inline void clear_nonspinnable(struct rw_semaphore *sem)\n{\n\tif (rwsem_test_oflags(sem, RWSEM_NONSPINNABLE))\n\t\tatomic_long_andnot(RWSEM_NONSPINNABLE, &sem->owner);\n}"
  },
  {
    "function_name": "rwsem_optimistic_spin",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "777-896",
    "snippet": "static bool rwsem_optimistic_spin(struct rw_semaphore *sem)\n{\n\tbool taken = false;\n\tint prev_owner_state = OWNER_NULL;\n\tint loop = 0;\n\tu64 rspin_threshold = 0;\n\n\tpreempt_disable();\n\n\t/* sem->wait_lock should not be held when doing optimistic spinning */\n\tif (!osq_lock(&sem->osq))\n\t\tgoto done;\n\n\t/*\n\t * Optimistically spin on the owner field and attempt to acquire the\n\t * lock whenever the owner changes. Spinning will be stopped when:\n\t *  1) the owning writer isn't running; or\n\t *  2) readers own the lock and spinning time has exceeded limit.\n\t */\n\tfor (;;) {\n\t\tenum owner_state owner_state;\n\n\t\towner_state = rwsem_spin_on_owner(sem);\n\t\tif (!(owner_state & OWNER_SPINNABLE))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Try to acquire the lock\n\t\t */\n\t\ttaken = rwsem_try_write_lock_unqueued(sem);\n\n\t\tif (taken)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Time-based reader-owned rwsem optimistic spinning\n\t\t */\n\t\tif (owner_state == OWNER_READER) {\n\t\t\t/*\n\t\t\t * Re-initialize rspin_threshold every time when\n\t\t\t * the owner state changes from non-reader to reader.\n\t\t\t * This allows a writer to steal the lock in between\n\t\t\t * 2 reader phases and have the threshold reset at\n\t\t\t * the beginning of the 2nd reader phase.\n\t\t\t */\n\t\t\tif (prev_owner_state != OWNER_READER) {\n\t\t\t\tif (rwsem_test_oflags(sem, RWSEM_NONSPINNABLE))\n\t\t\t\t\tbreak;\n\t\t\t\trspin_threshold = rwsem_rspin_threshold(sem);\n\t\t\t\tloop = 0;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Check time threshold once every 16 iterations to\n\t\t\t * avoid calling sched_clock() too frequently so\n\t\t\t * as to reduce the average latency between the times\n\t\t\t * when the lock becomes free and when the spinner\n\t\t\t * is ready to do a trylock.\n\t\t\t */\n\t\t\telse if (!(++loop & 0xf) && (sched_clock() > rspin_threshold)) {\n\t\t\t\trwsem_set_nonspinnable(sem);\n\t\t\t\tlockevent_inc(rwsem_opt_nospin);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * An RT task cannot do optimistic spinning if it cannot\n\t\t * be sure the lock holder is running or live-lock may\n\t\t * happen if the current task and the lock holder happen\n\t\t * to run in the same CPU. However, aborting optimistic\n\t\t * spinning while a NULL owner is detected may miss some\n\t\t * opportunity where spinning can continue without causing\n\t\t * problem.\n\t\t *\n\t\t * There are 2 possible cases where an RT task may be able\n\t\t * to continue spinning.\n\t\t *\n\t\t * 1) The lock owner is in the process of releasing the\n\t\t *    lock, sem->owner is cleared but the lock has not\n\t\t *    been released yet.\n\t\t * 2) The lock was free and owner cleared, but another\n\t\t *    task just comes in and acquire the lock before\n\t\t *    we try to get it. The new owner may be a spinnable\n\t\t *    writer.\n\t\t *\n\t\t * To take advantage of two scenarios listed above, the RT\n\t\t * task is made to retry one more time to see if it can\n\t\t * acquire the lock or continue spinning on the new owning\n\t\t * writer. Of course, if the time lag is long enough or the\n\t\t * new owner is not a writer or spinnable, the RT task will\n\t\t * quit spinning.\n\t\t *\n\t\t * If the owner is a writer, the need_resched() check is\n\t\t * done inside rwsem_spin_on_owner(). If the owner is not\n\t\t * a writer, need_resched() check needs to be done here.\n\t\t */\n\t\tif (owner_state != OWNER_WRITER) {\n\t\t\tif (need_resched())\n\t\t\t\tbreak;\n\t\t\tif (rt_task(current) &&\n\t\t\t   (prev_owner_state != OWNER_WRITER))\n\t\t\t\tbreak;\n\t\t}\n\t\tprev_owner_state = owner_state;\n\n\t\t/*\n\t\t * The cpu_relax() call is a compiler barrier which forces\n\t\t * everything in this loop to be re-loaded. We don't need\n\t\t * memory barriers as we'll eventually observe the right\n\t\t * values at the cost of a few extra spins.\n\t\t */\n\t\tcpu_relax();\n\t}\n\tosq_unlock(&sem->osq);\ndone:\n\tpreempt_enable();\n\tlockevent_cond_inc(rwsem_opt_fail, !taken);\n\treturn taken;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define OWNER_SPINNABLE\t\t(OWNER_NULL | OWNER_WRITER | OWNER_READER)",
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lockevent_cond_inc",
          "args": [
            "rwsem_opt_fail",
            "!taken"
          ],
          "line": 894
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 893
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "osq_unlock",
          "args": [
            "&sem->osq"
          ],
          "line": 891
        },
        "resolved": true,
        "details": {
          "function_name": "osq_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/osq_lock.c",
          "lines": "207-232",
          "snippet": "void osq_unlock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\n\t/*\n\t * Fast path for the uncontended case.\n\t */\n\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,\n\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))\n\t\treturn;\n\n\t/*\n\t * Second most likely case.\n\t */\n\tnode = this_cpu_ptr(&osq_node);\n\tnext = xchg(&node->next, NULL);\n\tif (next) {\n\t\tWRITE_ONCE(next->locked, 1);\n\t\treturn;\n\t}\n\n\tnext = osq_wait_next(lock, node, NULL);\n\tif (next)\n\t\tWRITE_ONCE(next->locked, 1);\n}",
          "includes": [
            "#include <linux/osq_lock.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/osq_lock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);\n\nvoid osq_unlock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\n\t/*\n\t * Fast path for the uncontended case.\n\t */\n\tif (likely(atomic_cmpxchg_release(&lock->tail, curr,\n\t\t\t\t\t  OSQ_UNLOCKED_VAL) == curr))\n\t\treturn;\n\n\t/*\n\t * Second most likely case.\n\t */\n\tnode = this_cpu_ptr(&osq_node);\n\tnext = xchg(&node->next, NULL);\n\tif (next) {\n\t\tWRITE_ONCE(next->locked, 1);\n\t\treturn;\n\t}\n\n\tnext = osq_wait_next(lock, node, NULL);\n\tif (next)\n\t\tWRITE_ONCE(next->locked, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 889
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "current"
          ],
          "line": 877
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_assert_task_sighand_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/signal.c",
          "lines": "1417-1428",
          "snippet": "void lockdep_assert_task_sighand_held(struct task_struct *task)\n{\n\tstruct sighand_struct *sighand;\n\n\trcu_read_lock();\n\tsighand = rcu_dereference(task->sighand);\n\tif (sighand)\n\t\tlockdep_assert_held(&sighand->siglock);\n\telse\n\t\tWARN_ON_ONCE(1);\n\trcu_read_unlock();\n}",
          "includes": [
            "#include <linux/kdb.h>",
            "#include <asm/syscall.h>\t/* for syscall_get_* */",
            "#include <asm/cacheflush.h>",
            "#include <asm/siginfo.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/param.h>",
            "#include <trace/events/signal.h>",
            "#include <linux/audit.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/compiler.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/compat.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/capability.h>",
            "#include <linux/task_work.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/signal.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/coredump.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/tty.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kdb.h>\n#include <asm/syscall.h>\t/* for syscall_get_* */\n#include <asm/cacheflush.h>\n#include <asm/siginfo.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <asm/param.h>\n#include <trace/events/signal.h>\n#include <linux/audit.h>\n#include <linux/cgroup.h>\n#include <linux/posix-timers.h>\n#include <linux/compiler.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/uprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/pid_namespace.h>\n#include <linux/freezer.h>\n#include <linux/capability.h>\n#include <linux/task_work.h>\n#include <linux/ratelimit.h>\n#include <linux/signalfd.h>\n#include <linux/signal.h>\n#include <linux/ptrace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/coredump.h>\n#include <linux/binfmts.h>\n#include <linux/tty.h>\n#include <linux/proc_fs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/user.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\nvoid lockdep_assert_task_sighand_held(struct task_struct *task)\n{\n\tstruct sighand_struct *sighand;\n\n\trcu_read_lock();\n\tsighand = rcu_dereference(task->sighand);\n\tif (sighand)\n\t\tlockdep_assert_held(&sighand->siglock);\n\telse\n\t\tWARN_ON_ONCE(1);\n\trcu_read_unlock();\n}"
        }
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 875
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_opt_nospin"
          ],
          "line": 838
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_set_nonspinnable",
          "args": [
            "sem"
          ],
          "line": 837
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_nonspinnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "222-233",
          "snippet": "static inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\tdo {\n\t\tif (!(owner & RWSEM_READER_OWNED))\n\t\t\tbreak;\n\t\tif (owner & RWSEM_NONSPINNABLE)\n\t\t\tbreak;\n\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,\n\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
            "#define RWSEM_READER_OWNED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\tdo {\n\t\tif (!(owner & RWSEM_READER_OWNED))\n\t\t\tbreak;\n\t\tif (owner & RWSEM_NONSPINNABLE)\n\t\t\tbreak;\n\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,\n\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_clock",
          "args": [],
          "line": 836
        },
        "resolved": true,
        "details": {
          "function_name": "sched_clock_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "453-459",
          "snippet": "void __init sched_clock_init(void)\n{\n\tstatic_branch_inc(&sched_clock_running);\n\tlocal_irq_disable();\n\tgeneric_sched_clock_init();\n\tlocal_irq_enable();\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_STATIC_KEY_FALSE(sched_clock_running);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic DEFINE_STATIC_KEY_FALSE(sched_clock_running);\n\nvoid __init sched_clock_init(void)\n{\n\tstatic_branch_inc(&sched_clock_running);\n\tlocal_irq_disable();\n\tgeneric_sched_clock_init();\n\tlocal_irq_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_rspin_threshold",
          "args": [
            "sem"
          ],
          "line": 825
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_rspin_threshold",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "764-775",
          "snippet": "static inline u64 rwsem_rspin_threshold(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\tint readers = count >> RWSEM_READER_SHIFT;\n\tu64 delta;\n\n\tif (readers > 30)\n\t\treaders = 30;\n\tdelta = (20 + readers) * NSEC_PER_USEC / 2;\n\n\treturn sched_clock() + delta;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_READER_SHIFT\t8"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_READER_SHIFT\t8\n\nstatic inline u64 rwsem_rspin_threshold(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\tint readers = count >> RWSEM_READER_SHIFT;\n\tu64 delta;\n\n\tif (readers > 30)\n\t\treaders = 30;\n\tdelta = (20 + readers) * NSEC_PER_USEC / 2;\n\n\treturn sched_clock() + delta;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_test_oflags",
          "args": [
            "sem",
            "RWSEM_NONSPINNABLE"
          ],
          "line": 823
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_test_oflags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "149-152",
          "snippet": "static inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_try_write_lock_unqueued",
          "args": [
            "sem"
          ],
          "line": 806
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_try_write_lock_unqueued",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "646-659",
          "snippet": "static inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\n\twhile (!(count & (RWSEM_LOCK_MASK|RWSEM_FLAG_HANDOFF))) {\n\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &count,\n\t\t\t\t\tcount | RWSEM_WRITER_LOCKED)) {\n\t\t\trwsem_set_owner(sem);\n\t\t\tlockevent_inc(rwsem_opt_lock);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
            "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
            "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\n\twhile (!(count & (RWSEM_LOCK_MASK|RWSEM_FLAG_HANDOFF))) {\n\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &count,\n\t\t\t\t\tcount | RWSEM_WRITER_LOCKED)) {\n\t\t\trwsem_set_owner(sem);\n\t\t\tlockevent_inc(rwsem_opt_lock);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_spin_on_owner",
          "args": [
            "sem"
          ],
          "line": 799
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_spin_on_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "921-925",
          "snippet": "static inline enum owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn OWNER_NONSPINNABLE;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline enum owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\treturn OWNER_NONSPINNABLE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "osq_lock",
          "args": [
            "&sem->osq"
          ],
          "line": 787
        },
        "resolved": true,
        "details": {
          "function_name": "osq_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/osq_lock.c",
          "lines": "90-205",
          "snippet": "bool osq_lock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);\n\tstruct optimistic_spin_node *prev, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\tint old;\n\n\tnode->locked = 0;\n\tnode->next = NULL;\n\tnode->cpu = curr;\n\n\t/*\n\t * We need both ACQUIRE (pairs with corresponding RELEASE in\n\t * unlock() uncontended, or fastpath) and RELEASE (to publish\n\t * the node fields we just initialised) semantics when updating\n\t * the lock tail.\n\t */\n\told = atomic_xchg(&lock->tail, curr);\n\tif (old == OSQ_UNLOCKED_VAL)\n\t\treturn true;\n\n\tprev = decode_cpu(old);\n\tnode->prev = prev;\n\n\t/*\n\t * osq_lock()\t\t\tunqueue\n\t *\n\t * node->prev = prev\t\tosq_wait_next()\n\t * WMB\t\t\t\tMB\n\t * prev->next = node\t\tnext->prev = prev // unqueue-C\n\t *\n\t * Here 'node->prev' and 'next->prev' are the same variable and we need\n\t * to ensure these stores happen in-order to avoid corrupting the list.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(prev->next, node);\n\n\t/*\n\t * Normally @prev is untouchable after the above store; because at that\n\t * moment unlock can proceed and wipe the node element from stack.\n\t *\n\t * However, since our nodes are static per-cpu storage, we're\n\t * guaranteed their existence -- this allows us to apply\n\t * cmpxchg in an attempt to undo our queueing.\n\t */\n\n\t/*\n\t * Wait to acquire the lock or cancellation. Note that need_resched()\n\t * will come with an IPI, which will wake smp_cond_load_relaxed() if it\n\t * is implemented with a monitor-wait. vcpu_is_preempted() relies on\n\t * polling, be careful.\n\t */\n\tif (smp_cond_load_relaxed(&node->locked, VAL || need_resched() ||\n\t\t\t\t  vcpu_is_preempted(node_cpu(node->prev))))\n\t\treturn true;\n\n\t/* unqueue */\n\t/*\n\t * Step - A  -- stabilize @prev\n\t *\n\t * Undo our @prev->next assignment; this will make @prev's\n\t * unlock()/unqueue() wait for a next pointer since @lock points to us\n\t * (or later).\n\t */\n\n\tfor (;;) {\n\t\t/*\n\t\t * cpu_relax() below implies a compiler barrier which would\n\t\t * prevent this comparison being optimized away.\n\t\t */\n\t\tif (data_race(prev->next) == node &&\n\t\t    cmpxchg(&prev->next, node, NULL) == node)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We can only fail the cmpxchg() racing against an unlock(),\n\t\t * in which case we should observe @node->locked becoming\n\t\t * true.\n\t\t */\n\t\tif (smp_load_acquire(&node->locked))\n\t\t\treturn true;\n\n\t\tcpu_relax();\n\n\t\t/*\n\t\t * Or we race against a concurrent unqueue()'s step-B, in which\n\t\t * case its step-C will write us a new @node->prev pointer.\n\t\t */\n\t\tprev = READ_ONCE(node->prev);\n\t}\n\n\t/*\n\t * Step - B -- stabilize @next\n\t *\n\t * Similar to unlock(), wait for @node->next or move @lock from @node\n\t * back to @prev.\n\t */\n\n\tnext = osq_wait_next(lock, node, prev);\n\tif (!next)\n\t\treturn false;\n\n\t/*\n\t * Step - C -- unlink\n\t *\n\t * @prev is stable because its still waiting for a new @prev->next\n\t * pointer, @next is stable because our @node->next pointer is NULL and\n\t * it will wait in Step-A.\n\t */\n\n\tWRITE_ONCE(next->prev, prev);\n\tWRITE_ONCE(prev->next, next);\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/osq_lock.h>",
            "#include <linux/sched.h>",
            "#include <linux/percpu.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/osq_lock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct optimistic_spin_node, osq_node);\n\nbool osq_lock(struct optimistic_spin_queue *lock)\n{\n\tstruct optimistic_spin_node *node = this_cpu_ptr(&osq_node);\n\tstruct optimistic_spin_node *prev, *next;\n\tint curr = encode_cpu(smp_processor_id());\n\tint old;\n\n\tnode->locked = 0;\n\tnode->next = NULL;\n\tnode->cpu = curr;\n\n\t/*\n\t * We need both ACQUIRE (pairs with corresponding RELEASE in\n\t * unlock() uncontended, or fastpath) and RELEASE (to publish\n\t * the node fields we just initialised) semantics when updating\n\t * the lock tail.\n\t */\n\told = atomic_xchg(&lock->tail, curr);\n\tif (old == OSQ_UNLOCKED_VAL)\n\t\treturn true;\n\n\tprev = decode_cpu(old);\n\tnode->prev = prev;\n\n\t/*\n\t * osq_lock()\t\t\tunqueue\n\t *\n\t * node->prev = prev\t\tosq_wait_next()\n\t * WMB\t\t\t\tMB\n\t * prev->next = node\t\tnext->prev = prev // unqueue-C\n\t *\n\t * Here 'node->prev' and 'next->prev' are the same variable and we need\n\t * to ensure these stores happen in-order to avoid corrupting the list.\n\t */\n\tsmp_wmb();\n\n\tWRITE_ONCE(prev->next, node);\n\n\t/*\n\t * Normally @prev is untouchable after the above store; because at that\n\t * moment unlock can proceed and wipe the node element from stack.\n\t *\n\t * However, since our nodes are static per-cpu storage, we're\n\t * guaranteed their existence -- this allows us to apply\n\t * cmpxchg in an attempt to undo our queueing.\n\t */\n\n\t/*\n\t * Wait to acquire the lock or cancellation. Note that need_resched()\n\t * will come with an IPI, which will wake smp_cond_load_relaxed() if it\n\t * is implemented with a monitor-wait. vcpu_is_preempted() relies on\n\t * polling, be careful.\n\t */\n\tif (smp_cond_load_relaxed(&node->locked, VAL || need_resched() ||\n\t\t\t\t  vcpu_is_preempted(node_cpu(node->prev))))\n\t\treturn true;\n\n\t/* unqueue */\n\t/*\n\t * Step - A  -- stabilize @prev\n\t *\n\t * Undo our @prev->next assignment; this will make @prev's\n\t * unlock()/unqueue() wait for a next pointer since @lock points to us\n\t * (or later).\n\t */\n\n\tfor (;;) {\n\t\t/*\n\t\t * cpu_relax() below implies a compiler barrier which would\n\t\t * prevent this comparison being optimized away.\n\t\t */\n\t\tif (data_race(prev->next) == node &&\n\t\t    cmpxchg(&prev->next, node, NULL) == node)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * We can only fail the cmpxchg() racing against an unlock(),\n\t\t * in which case we should observe @node->locked becoming\n\t\t * true.\n\t\t */\n\t\tif (smp_load_acquire(&node->locked))\n\t\t\treturn true;\n\n\t\tcpu_relax();\n\n\t\t/*\n\t\t * Or we race against a concurrent unqueue()'s step-B, in which\n\t\t * case its step-C will write us a new @node->prev pointer.\n\t\t */\n\t\tprev = READ_ONCE(node->prev);\n\t}\n\n\t/*\n\t * Step - B -- stabilize @next\n\t *\n\t * Similar to unlock(), wait for @node->next or move @lock from @node\n\t * back to @prev.\n\t */\n\n\tnext = osq_wait_next(lock, node, prev);\n\tif (!next)\n\t\treturn false;\n\n\t/*\n\t * Step - C -- unlink\n\t *\n\t * @prev is stable because its still waiting for a new @prev->next\n\t * pointer, @next is stable because our @node->next pointer is NULL and\n\t * it will wait in Step-A.\n\t */\n\n\tWRITE_ONCE(next->prev, prev);\n\tWRITE_ONCE(prev->next, next);\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 784
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define OWNER_SPINNABLE\t\t(OWNER_NULL | OWNER_WRITER | OWNER_READER)\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n\nstatic bool rwsem_optimistic_spin(struct rw_semaphore *sem)\n{\n\tbool taken = false;\n\tint prev_owner_state = OWNER_NULL;\n\tint loop = 0;\n\tu64 rspin_threshold = 0;\n\n\tpreempt_disable();\n\n\t/* sem->wait_lock should not be held when doing optimistic spinning */\n\tif (!osq_lock(&sem->osq))\n\t\tgoto done;\n\n\t/*\n\t * Optimistically spin on the owner field and attempt to acquire the\n\t * lock whenever the owner changes. Spinning will be stopped when:\n\t *  1) the owning writer isn't running; or\n\t *  2) readers own the lock and spinning time has exceeded limit.\n\t */\n\tfor (;;) {\n\t\tenum owner_state owner_state;\n\n\t\towner_state = rwsem_spin_on_owner(sem);\n\t\tif (!(owner_state & OWNER_SPINNABLE))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Try to acquire the lock\n\t\t */\n\t\ttaken = rwsem_try_write_lock_unqueued(sem);\n\n\t\tif (taken)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Time-based reader-owned rwsem optimistic spinning\n\t\t */\n\t\tif (owner_state == OWNER_READER) {\n\t\t\t/*\n\t\t\t * Re-initialize rspin_threshold every time when\n\t\t\t * the owner state changes from non-reader to reader.\n\t\t\t * This allows a writer to steal the lock in between\n\t\t\t * 2 reader phases and have the threshold reset at\n\t\t\t * the beginning of the 2nd reader phase.\n\t\t\t */\n\t\t\tif (prev_owner_state != OWNER_READER) {\n\t\t\t\tif (rwsem_test_oflags(sem, RWSEM_NONSPINNABLE))\n\t\t\t\t\tbreak;\n\t\t\t\trspin_threshold = rwsem_rspin_threshold(sem);\n\t\t\t\tloop = 0;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * Check time threshold once every 16 iterations to\n\t\t\t * avoid calling sched_clock() too frequently so\n\t\t\t * as to reduce the average latency between the times\n\t\t\t * when the lock becomes free and when the spinner\n\t\t\t * is ready to do a trylock.\n\t\t\t */\n\t\t\telse if (!(++loop & 0xf) && (sched_clock() > rspin_threshold)) {\n\t\t\t\trwsem_set_nonspinnable(sem);\n\t\t\t\tlockevent_inc(rwsem_opt_nospin);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * An RT task cannot do optimistic spinning if it cannot\n\t\t * be sure the lock holder is running or live-lock may\n\t\t * happen if the current task and the lock holder happen\n\t\t * to run in the same CPU. However, aborting optimistic\n\t\t * spinning while a NULL owner is detected may miss some\n\t\t * opportunity where spinning can continue without causing\n\t\t * problem.\n\t\t *\n\t\t * There are 2 possible cases where an RT task may be able\n\t\t * to continue spinning.\n\t\t *\n\t\t * 1) The lock owner is in the process of releasing the\n\t\t *    lock, sem->owner is cleared but the lock has not\n\t\t *    been released yet.\n\t\t * 2) The lock was free and owner cleared, but another\n\t\t *    task just comes in and acquire the lock before\n\t\t *    we try to get it. The new owner may be a spinnable\n\t\t *    writer.\n\t\t *\n\t\t * To take advantage of two scenarios listed above, the RT\n\t\t * task is made to retry one more time to see if it can\n\t\t * acquire the lock or continue spinning on the new owning\n\t\t * writer. Of course, if the time lag is long enough or the\n\t\t * new owner is not a writer or spinnable, the RT task will\n\t\t * quit spinning.\n\t\t *\n\t\t * If the owner is a writer, the need_resched() check is\n\t\t * done inside rwsem_spin_on_owner(). If the owner is not\n\t\t * a writer, need_resched() check needs to be done here.\n\t\t */\n\t\tif (owner_state != OWNER_WRITER) {\n\t\t\tif (need_resched())\n\t\t\t\tbreak;\n\t\t\tif (rt_task(current) &&\n\t\t\t   (prev_owner_state != OWNER_WRITER))\n\t\t\t\tbreak;\n\t\t}\n\t\tprev_owner_state = owner_state;\n\n\t\t/*\n\t\t * The cpu_relax() call is a compiler barrier which forces\n\t\t * everything in this loop to be re-loaded. We don't need\n\t\t * memory barriers as we'll eventually observe the right\n\t\t * values at the cost of a few extra spins.\n\t\t */\n\t\tcpu_relax();\n\t}\n\tosq_unlock(&sem->osq);\ndone:\n\tpreempt_enable();\n\tlockevent_cond_inc(rwsem_opt_fail, !taken);\n\treturn taken;\n}"
  },
  {
    "function_name": "rwsem_rspin_threshold",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "764-775",
    "snippet": "static inline u64 rwsem_rspin_threshold(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\tint readers = count >> RWSEM_READER_SHIFT;\n\tu64 delta;\n\n\tif (readers > 30)\n\t\treaders = 30;\n\tdelta = (20 + readers) * NSEC_PER_USEC / 2;\n\n\treturn sched_clock() + delta;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_READER_SHIFT\t8"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_clock",
          "args": [],
          "line": 774
        },
        "resolved": true,
        "details": {
          "function_name": "sched_clock_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "453-459",
          "snippet": "void __init sched_clock_init(void)\n{\n\tstatic_branch_inc(&sched_clock_running);\n\tlocal_irq_disable();\n\tgeneric_sched_clock_init();\n\tlocal_irq_enable();\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_STATIC_KEY_FALSE(sched_clock_running);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic DEFINE_STATIC_KEY_FALSE(sched_clock_running);\n\nvoid __init sched_clock_init(void)\n{\n\tstatic_branch_inc(&sched_clock_running);\n\tlocal_irq_disable();\n\tgeneric_sched_clock_init();\n\tlocal_irq_enable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 766
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_READER_SHIFT\t8\n\nstatic inline u64 rwsem_rspin_threshold(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\tint readers = count >> RWSEM_READER_SHIFT;\n\tu64 delta;\n\n\tif (readers > 30)\n\t\treaders = 30;\n\tdelta = (20 + readers) * NSEC_PER_USEC / 2;\n\n\treturn sched_clock() + delta;\n}"
  },
  {
    "function_name": "rwsem_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "704-750",
    "snippet": "owner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\tstruct task_struct *new, *owner;\n\tunsigned long flags, new_flags;\n\tenum owner_state state;\n\n\tlockdep_assert_preemption_disabled();\n\n\towner = rwsem_owner_flags(sem, &flags);\n\tstate = rwsem_owner_state(owner, flags);\n\tif (state != OWNER_WRITER)\n\t\treturn state;\n\n\tfor (;;) {\n\t\t/*\n\t\t * When a waiting writer set the handoff flag, it may spin\n\t\t * on the owner as well. Once that writer acquires the lock,\n\t\t * we can spin on it. So we don't need to quit even when the\n\t\t * handoff bit is set.\n\t\t */\n\t\tnew = rwsem_owner_flags(sem, &new_flags);\n\t\tif ((new != owner) || (new_flags != flags)) {\n\t\t\tstate = rwsem_owner_state(new, new_flags);\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking sem->owner still matches owner, if that fails,\n\t\t * owner might point to free()d memory, if it still matches,\n\t\t * our spinning context already disabled preemption which is\n\t\t * equal to RCU read-side crital section ensures the memory\n\t\t * stays valid.\n\t\t */\n\t\tbarrier();\n\n\t\tif (need_resched() || !owner_on_cpu(owner)) {\n\t\t\tstate = OWNER_NONSPINNABLE;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\treturn state;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "cpu_relax",
          "args": [],
          "line": 746
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "owner_on_cpu",
          "args": [
            "owner"
          ],
          "line": 741
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 741
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 739
        },
        "resolved": true,
        "details": {
          "function_name": "membarrier_register_global_expedited",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/membarrier.c",
          "lines": "482-499",
          "snippet": "static int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ret;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic int membarrier_register_global_expedited(void)\n{\n\tstruct task_struct *p = current;\n\tstruct mm_struct *mm = p->mm;\n\tint ret;\n\n\tif (atomic_read(&mm->membarrier_state) &\n\t    MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY)\n\t\treturn 0;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED, &mm->membarrier_state);\n\tret = sync_runqueues_membarrier_state(mm);\n\tif (ret)\n\t\treturn ret;\n\tatomic_or(MEMBARRIER_STATE_GLOBAL_EXPEDITED_READY,\n\t\t  &mm->membarrier_state);\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_owner_state",
          "args": [
            "new",
            "new_flags"
          ],
          "line": 727
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_owner_state",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "692-702",
          "snippet": "static inline enum owner_state\nrwsem_owner_state(struct task_struct *owner, unsigned long flags)\n{\n\tif (flags & RWSEM_NONSPINNABLE)\n\t\treturn OWNER_NONSPINNABLE;\n\n\tif (flags & RWSEM_READER_OWNED)\n\t\treturn OWNER_READER;\n\n\treturn owner ? OWNER_WRITER : OWNER_NULL;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
            "#define RWSEM_READER_OWNED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline enum owner_state\nrwsem_owner_state(struct task_struct *owner, unsigned long flags)\n{\n\tif (flags & RWSEM_NONSPINNABLE)\n\t\treturn OWNER_NONSPINNABLE;\n\n\tif (flags & RWSEM_READER_OWNED)\n\t\treturn OWNER_READER;\n\n\treturn owner ? OWNER_WRITER : OWNER_NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_owner_flags",
          "args": [
            "sem",
            "&new_flags"
          ],
          "line": 725
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_owner_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "275-282",
          "snippet": "static inline struct task_struct *\nrwsem_owner_flags(struct rw_semaphore *sem, unsigned long *pflags)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\t*pflags = owner & RWSEM_OWNER_FLAGS_MASK;\n\treturn (struct task_struct *)(owner & ~RWSEM_OWNER_FLAGS_MASK);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline struct task_struct *\nrwsem_owner_flags(struct rw_semaphore *sem, unsigned long *pflags)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\t*pflags = owner & RWSEM_OWNER_FLAGS_MASK;\n\treturn (struct task_struct *)(owner & ~RWSEM_OWNER_FLAGS_MASK);\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_preemption_disabled",
          "args": [],
          "line": 711
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nowner_state\nrwsem_spin_on_owner(struct rw_semaphore *sem)\n{\n\tstruct task_struct *new, *owner;\n\tunsigned long flags, new_flags;\n\tenum owner_state state;\n\n\tlockdep_assert_preemption_disabled();\n\n\towner = rwsem_owner_flags(sem, &flags);\n\tstate = rwsem_owner_state(owner, flags);\n\tif (state != OWNER_WRITER)\n\t\treturn state;\n\n\tfor (;;) {\n\t\t/*\n\t\t * When a waiting writer set the handoff flag, it may spin\n\t\t * on the owner as well. Once that writer acquires the lock,\n\t\t * we can spin on it. So we don't need to quit even when the\n\t\t * handoff bit is set.\n\t\t */\n\t\tnew = rwsem_owner_flags(sem, &new_flags);\n\t\tif ((new != owner) || (new_flags != flags)) {\n\t\t\tstate = rwsem_owner_state(new, new_flags);\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Ensure we emit the owner->on_cpu, dereference _after_\n\t\t * checking sem->owner still matches owner, if that fails,\n\t\t * owner might point to free()d memory, if it still matches,\n\t\t * our spinning context already disabled preemption which is\n\t\t * equal to RCU read-side crital section ensures the memory\n\t\t * stays valid.\n\t\t */\n\t\tbarrier();\n\n\t\tif (need_resched() || !owner_on_cpu(owner)) {\n\t\t\tstate = OWNER_NONSPINNABLE;\n\t\t\tbreak;\n\t\t}\n\n\t\tcpu_relax();\n\t}\n\n\treturn state;\n}"
  },
  {
    "function_name": "rwsem_owner_state",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "692-702",
    "snippet": "static inline enum owner_state\nrwsem_owner_state(struct task_struct *owner, unsigned long flags)\n{\n\tif (flags & RWSEM_NONSPINNABLE)\n\t\treturn OWNER_NONSPINNABLE;\n\n\tif (flags & RWSEM_READER_OWNED)\n\t\treturn OWNER_READER;\n\n\treturn owner ? OWNER_WRITER : OWNER_NULL;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
      "#define RWSEM_READER_OWNED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline enum owner_state\nrwsem_owner_state(struct task_struct *owner, unsigned long flags)\n{\n\tif (flags & RWSEM_NONSPINNABLE)\n\t\treturn OWNER_NONSPINNABLE;\n\n\tif (flags & RWSEM_READER_OWNED)\n\t\treturn OWNER_READER;\n\n\treturn owner ? OWNER_WRITER : OWNER_NULL;\n}"
  },
  {
    "function_name": "rwsem_can_spin_on_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "661-688",
    "snippet": "static inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\n{\n\tstruct task_struct *owner;\n\tunsigned long flags;\n\tbool ret = true;\n\n\tif (need_resched()) {\n\t\tlockevent_inc(rwsem_opt_fail);\n\t\treturn false;\n\t}\n\n\tpreempt_disable();\n\t/*\n\t * Disable preemption is equal to the RCU read-side crital section,\n\t * thus the task_strcut structure won't go away.\n\t */\n\towner = rwsem_owner_flags(sem, &flags);\n\t/*\n\t * Don't check the read-owner as the entry may be stale.\n\t */\n\tif ((flags & RWSEM_NONSPINNABLE) ||\n\t    (owner && !(flags & RWSEM_READER_OWNED) && !owner_on_cpu(owner)))\n\t\tret = false;\n\tpreempt_enable();\n\n\tlockevent_cond_inc(rwsem_opt_fail, !ret);\n\treturn ret;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
      "#define RWSEM_READER_OWNED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lockevent_cond_inc",
          "args": [
            "rwsem_opt_fail",
            "!ret"
          ],
          "line": 686
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 684
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "owner_on_cpu",
          "args": [
            "owner"
          ],
          "line": 682
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_owner_flags",
          "args": [
            "sem",
            "&flags"
          ],
          "line": 677
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_owner_flags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "275-282",
          "snippet": "static inline struct task_struct *\nrwsem_owner_flags(struct rw_semaphore *sem, unsigned long *pflags)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\t*pflags = owner & RWSEM_OWNER_FLAGS_MASK;\n\treturn (struct task_struct *)(owner & ~RWSEM_OWNER_FLAGS_MASK);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline struct task_struct *\nrwsem_owner_flags(struct rw_semaphore *sem, unsigned long *pflags)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\t*pflags = owner & RWSEM_OWNER_FLAGS_MASK;\n\treturn (struct task_struct *)(owner & ~RWSEM_OWNER_FLAGS_MASK);\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 672
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_opt_fail"
          ],
          "line": 668
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "need_resched",
          "args": [],
          "line": 667
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\n{\n\tstruct task_struct *owner;\n\tunsigned long flags;\n\tbool ret = true;\n\n\tif (need_resched()) {\n\t\tlockevent_inc(rwsem_opt_fail);\n\t\treturn false;\n\t}\n\n\tpreempt_disable();\n\t/*\n\t * Disable preemption is equal to the RCU read-side crital section,\n\t * thus the task_strcut structure won't go away.\n\t */\n\towner = rwsem_owner_flags(sem, &flags);\n\t/*\n\t * Don't check the read-owner as the entry may be stale.\n\t */\n\tif ((flags & RWSEM_NONSPINNABLE) ||\n\t    (owner && !(flags & RWSEM_READER_OWNED) && !owner_on_cpu(owner)))\n\t\tret = false;\n\tpreempt_enable();\n\n\tlockevent_cond_inc(rwsem_opt_fail, !ret);\n\treturn ret;\n}"
  },
  {
    "function_name": "rwsem_try_write_lock_unqueued",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "646-659",
    "snippet": "static inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\n\twhile (!(count & (RWSEM_LOCK_MASK|RWSEM_FLAG_HANDOFF))) {\n\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &count,\n\t\t\t\t\tcount | RWSEM_WRITER_LOCKED)) {\n\t\t\trwsem_set_owner(sem);\n\t\t\tlockevent_inc(rwsem_opt_lock);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
      "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
      "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_opt_lock"
          ],
          "line": 654
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_set_owner",
          "args": [
            "sem"
          ],
          "line": 653
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "136-139",
          "snippet": "static inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&sem->count",
            "&count",
            "count | RWSEM_WRITER_LOCKED"
          ],
          "line": 651
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 648
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)\n{\n\tlong count = atomic_long_read(&sem->count);\n\n\twhile (!(count & (RWSEM_LOCK_MASK|RWSEM_FLAG_HANDOFF))) {\n\t\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &count,\n\t\t\t\t\tcount | RWSEM_WRITER_LOCKED)) {\n\t\t\trwsem_set_owner(sem);\n\t\t\tlockevent_inc(rwsem_opt_lock);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}"
  },
  {
    "function_name": "rwsem_try_write_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "568-622",
    "snippet": "static inline bool rwsem_try_write_lock(struct rw_semaphore *sem,\n\t\t\t\t\tstruct rwsem_waiter *waiter)\n{\n\tbool first = rwsem_first_waiter(sem) == waiter;\n\tlong count, new;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\tcount = atomic_long_read(&sem->count);\n\tdo {\n\t\tbool has_handoff = !!(count & RWSEM_FLAG_HANDOFF);\n\n\t\tif (has_handoff) {\n\t\t\tif (!first)\n\t\t\t\treturn false;\n\n\t\t\t/* First waiter inherits a previously set handoff bit */\n\t\t\twaiter->handoff_set = true;\n\t\t}\n\n\t\tnew = count;\n\n\t\tif (count & RWSEM_LOCK_MASK) {\n\t\t\tif (has_handoff || (!rt_task(waiter->task) &&\n\t\t\t\t\t    !time_after(jiffies, waiter->timeout)))\n\t\t\t\treturn false;\n\n\t\t\tnew |= RWSEM_FLAG_HANDOFF;\n\t\t} else {\n\t\t\tnew |= RWSEM_WRITER_LOCKED;\n\t\t\tnew &= ~RWSEM_FLAG_HANDOFF;\n\n\t\t\tif (list_is_singular(&sem->wait_list))\n\t\t\t\tnew &= ~RWSEM_FLAG_WAITERS;\n\t\t}\n\t} while (!atomic_long_try_cmpxchg_acquire(&sem->count, &count, new));\n\n\t/*\n\t * We have either acquired the lock with handoff bit cleared or\n\t * set the handoff bit.\n\t */\n\tif (new & RWSEM_FLAG_HANDOFF) {\n\t\twaiter->handoff_set = true;\n\t\tlockevent_inc(rwsem_wlock_handoff);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Have rwsem_try_write_lock() fully imply rwsem_del_waiter() on\n\t * success.\n\t */\n\tlist_del(&waiter->list);\n\trwsem_set_owner(sem);\n\treturn true;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)",
      "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)",
      "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_set_owner",
          "args": [
            "sem"
          ],
          "line": 620
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "136-139",
          "snippet": "static inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&waiter->list"
          ],
          "line": 619
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/fair.c",
          "lines": "475-477",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);",
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_wlock_handoff"
          ],
          "line": 611
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&sem->count",
            "&count",
            "new"
          ],
          "line": 603
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_is_singular",
          "args": [
            "&sem->wait_list"
          ],
          "line": 600
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "time_after",
          "args": [
            "jiffies",
            "waiter->timeout"
          ],
          "line": 592
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_task",
          "args": [
            "waiter->task"
          ],
          "line": 591
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_assert_task_sighand_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/signal.c",
          "lines": "1417-1428",
          "snippet": "void lockdep_assert_task_sighand_held(struct task_struct *task)\n{\n\tstruct sighand_struct *sighand;\n\n\trcu_read_lock();\n\tsighand = rcu_dereference(task->sighand);\n\tif (sighand)\n\t\tlockdep_assert_held(&sighand->siglock);\n\telse\n\t\tWARN_ON_ONCE(1);\n\trcu_read_unlock();\n}",
          "includes": [
            "#include <linux/kdb.h>",
            "#include <asm/syscall.h>\t/* for syscall_get_* */",
            "#include <asm/cacheflush.h>",
            "#include <asm/siginfo.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/param.h>",
            "#include <trace/events/signal.h>",
            "#include <linux/audit.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/compiler.h>",
            "#include <linux/cn_proc.h>",
            "#include <linux/compat.h>",
            "#include <linux/uprobes.h>",
            "#include <linux/user_namespace.h>",
            "#include <linux/nsproxy.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/capability.h>",
            "#include <linux/task_work.h>",
            "#include <linux/ratelimit.h>",
            "#include <linux/signalfd.h>",
            "#include <linux/signal.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/coredump.h>",
            "#include <linux/binfmts.h>",
            "#include <linux/tty.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/sched/cputime.h>",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/user.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/export.h>",
            "#include <linux/slab.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kdb.h>\n#include <asm/syscall.h>\t/* for syscall_get_* */\n#include <asm/cacheflush.h>\n#include <asm/siginfo.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <asm/param.h>\n#include <trace/events/signal.h>\n#include <linux/audit.h>\n#include <linux/cgroup.h>\n#include <linux/posix-timers.h>\n#include <linux/compiler.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/uprobes.h>\n#include <linux/user_namespace.h>\n#include <linux/nsproxy.h>\n#include <linux/pid_namespace.h>\n#include <linux/freezer.h>\n#include <linux/capability.h>\n#include <linux/task_work.h>\n#include <linux/ratelimit.h>\n#include <linux/signalfd.h>\n#include <linux/signal.h>\n#include <linux/ptrace.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/coredump.h>\n#include <linux/binfmts.h>\n#include <linux/tty.h>\n#include <linux/proc_fs.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/sched/cputime.h>\n#include <linux/sched/task_stack.h>\n#include <linux/sched/task.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/user.h>\n#include <linux/sched/mm.h>\n#include <linux/init.h>\n#include <linux/export.h>\n#include <linux/slab.h>\n\nvoid lockdep_assert_task_sighand_held(struct task_struct *task)\n{\n\tstruct sighand_struct *sighand;\n\n\trcu_read_lock();\n\tsighand = rcu_dereference(task->sighand);\n\tif (sighand)\n\t\tlockdep_assert_held(&sighand->siglock);\n\telse\n\t\tWARN_ON_ONCE(1);\n\trcu_read_unlock();\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 576
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 574
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rwsem_first_waiter",
          "args": [
            "sem"
          ],
          "line": 571
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_LOCK_MASK\t\t(RWSEM_WRITER_MASK|RWSEM_READER_MASK)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_try_write_lock(struct rw_semaphore *sem,\n\t\t\t\t\tstruct rwsem_waiter *waiter)\n{\n\tbool first = rwsem_first_waiter(sem) == waiter;\n\tlong count, new;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\tcount = atomic_long_read(&sem->count);\n\tdo {\n\t\tbool has_handoff = !!(count & RWSEM_FLAG_HANDOFF);\n\n\t\tif (has_handoff) {\n\t\t\tif (!first)\n\t\t\t\treturn false;\n\n\t\t\t/* First waiter inherits a previously set handoff bit */\n\t\t\twaiter->handoff_set = true;\n\t\t}\n\n\t\tnew = count;\n\n\t\tif (count & RWSEM_LOCK_MASK) {\n\t\t\tif (has_handoff || (!rt_task(waiter->task) &&\n\t\t\t\t\t    !time_after(jiffies, waiter->timeout)))\n\t\t\t\treturn false;\n\n\t\t\tnew |= RWSEM_FLAG_HANDOFF;\n\t\t} else {\n\t\t\tnew |= RWSEM_WRITER_LOCKED;\n\t\t\tnew &= ~RWSEM_FLAG_HANDOFF;\n\n\t\t\tif (list_is_singular(&sem->wait_list))\n\t\t\t\tnew &= ~RWSEM_FLAG_WAITERS;\n\t\t}\n\t} while (!atomic_long_try_cmpxchg_acquire(&sem->count, &count, new));\n\n\t/*\n\t * We have either acquired the lock with handoff bit cleared or\n\t * set the handoff bit.\n\t */\n\tif (new & RWSEM_FLAG_HANDOFF) {\n\t\twaiter->handoff_set = true;\n\t\tlockevent_inc(rwsem_wlock_handoff);\n\t\treturn false;\n\t}\n\n\t/*\n\t * Have rwsem_try_write_lock() fully imply rwsem_del_waiter() on\n\t * success.\n\t */\n\tlist_del(&waiter->list);\n\trwsem_set_owner(sem);\n\treturn true;\n}"
  },
  {
    "function_name": "rwsem_mark_wake",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "404-559",
    "snippet": "static void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define MAX_READERS_WAKEUP\t0x100",
      "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
      "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)",
      "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_q_add_safe",
          "args": [
            "wake_q",
            "tsk"
          ],
          "line": 557
        },
        "resolved": true,
        "details": {
          "function_name": "wake_q_add_safe",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "942-946",
          "snippet": "void wake_q_add_safe(struct wake_q_head *head, struct task_struct *task)\n{\n\tif (!__wake_q_add(head, task))\n\t\tput_task_struct(task);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nvoid wake_q_add_safe(struct wake_q_head *head, struct task_struct *task)\n{\n\tif (!__wake_q_add(head, task))\n\t\tput_task_struct(task);\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_store_release",
          "args": [
            "&waiter->task",
            "NULL"
          ],
          "line": 552
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_task_struct",
          "args": [
            "tsk"
          ],
          "line": 544
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "waiter",
            "tmp",
            "&wlist",
            "list"
          ],
          "line": 540
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_add",
          "args": [
            "adjustment",
            "&sem->count"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&sem->wait_list"
          ],
          "line": 519
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 518
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_cond_inc",
          "args": [
            "rwsem_wake_reader",
            "woken"
          ],
          "line": 516
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "woken >= MAX_READERS_WAKEUP"
          ],
          "line": 511
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_move_tail",
          "args": [
            "&waiter->list",
            "&wlist"
          ],
          "line": 506
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "waiter",
            "tmp",
            "&sem->wait_list",
            "list"
          ],
          "line": 501
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&wlist"
          ],
          "line": 500
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__rwsem_set_reader_owned",
          "args": [
            "sem",
            "owner"
          ],
          "line": 474
        },
        "resolved": true,
        "details": {
          "function_name": "__rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1441-1444",
          "snippet": "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_add",
          "args": [
            "-adjustment",
            "&sem->count"
          ],
          "line": 464
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_rlock_handoff"
          ],
          "line": 461
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "time_after",
          "args": [
            "jiffies",
            "waiter->timeout"
          ],
          "line": 459
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "oldcount & RWSEM_WRITER_MASK"
          ],
          "line": 452
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_fetch_add",
          "args": [
            "adjustment",
            "&sem->count"
          ],
          "line": 451
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "atomic_long_read(&sem->count) < 0"
          ],
          "line": 439
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 439
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockevent_inc",
          "args": [
            "rwsem_wake_writer"
          ],
          "line": 430
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_q_add",
          "args": [
            "wake_q",
            "waiter->task"
          ],
          "line": 429
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_wake_q_add",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "463-467",
          "snippet": "static __always_inline void rt_mutex_wake_q_add(struct rt_wake_q_head *wqh,\n\t\t\t\t\t\tstruct rt_mutex_waiter *w)\n{\n\trt_mutex_wake_q_add_task(wqh, w->task, w->wake_state);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void rt_mutex_wake_q_add(struct rt_wake_q_head *wqh,\n\t\t\t\t\t\tstruct rt_mutex_waiter *w)\n{\n\trt_mutex_wake_q_add_task(wqh, w->task, w->wake_state);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_first_waiter",
          "args": [
            "sem"
          ],
          "line": 418
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 412
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define MAX_READERS_WAKEUP\t0x100\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic void rwsem_mark_wake(struct rw_semaphore *sem,\n\t\t\t    enum rwsem_wake_type wake_type,\n\t\t\t    struct wake_q_head *wake_q)\n{\n\tstruct rwsem_waiter *waiter, *tmp;\n\tlong oldcount, woken = 0, adjustment = 0;\n\tstruct list_head wlist;\n\n\tlockdep_assert_held(&sem->wait_lock);\n\n\t/*\n\t * Take a peek at the queue head waiter such that we can determine\n\t * the wakeup(s) to perform.\n\t */\n\twaiter = rwsem_first_waiter(sem);\n\n\tif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\n\t\tif (wake_type == RWSEM_WAKE_ANY) {\n\t\t\t/*\n\t\t\t * Mark writer at the front of the queue for wakeup.\n\t\t\t * Until the task is actually later awoken later by\n\t\t\t * the caller, other writers are able to steal it.\n\t\t\t * Readers, on the other hand, will block as they\n\t\t\t * will notice the queued writer.\n\t\t\t */\n\t\t\twake_q_add(wake_q, waiter->task);\n\t\t\tlockevent_inc(rwsem_wake_writer);\n\t\t}\n\n\t\treturn;\n\t}\n\n\t/*\n\t * No reader wakeup if there are too many of them already.\n\t */\n\tif (unlikely(atomic_long_read(&sem->count) < 0))\n\t\treturn;\n\n\t/*\n\t * Writers might steal the lock before we grant it to the next reader.\n\t * We prefer to do the first reader grant before counting readers\n\t * so we can bail out early if a writer stole the lock.\n\t */\n\tif (wake_type != RWSEM_WAKE_READ_OWNED) {\n\t\tstruct task_struct *owner;\n\n\t\tadjustment = RWSEM_READER_BIAS;\n\t\toldcount = atomic_long_fetch_add(adjustment, &sem->count);\n\t\tif (unlikely(oldcount & RWSEM_WRITER_MASK)) {\n\t\t\t/*\n\t\t\t * When we've been waiting \"too\" long (for writers\n\t\t\t * to give up the lock), request a HANDOFF to\n\t\t\t * force the issue.\n\t\t\t */\n\t\t\tif (!(oldcount & RWSEM_FLAG_HANDOFF) &&\n\t\t\t    time_after(jiffies, waiter->timeout)) {\n\t\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t\t\t\tlockevent_inc(rwsem_rlock_handoff);\n\t\t\t}\n\n\t\t\tatomic_long_add(-adjustment, &sem->count);\n\t\t\treturn;\n\t\t}\n\t\t/*\n\t\t * Set it to reader-owned to give spinners an early\n\t\t * indication that readers now have the lock.\n\t\t * The reader nonspinnable bit seen at slowpath entry of\n\t\t * the reader is copied over.\n\t\t */\n\t\towner = waiter->task;\n\t\t__rwsem_set_reader_owned(sem, owner);\n\t}\n\n\t/*\n\t * Grant up to MAX_READERS_WAKEUP read locks to all the readers in the\n\t * queue. We know that the woken will be at least 1 as we accounted\n\t * for above. Note we increment the 'active part' of the count by the\n\t * number of readers before waking any processes up.\n\t *\n\t * This is an adaptation of the phase-fair R/W locks where at the\n\t * reader phase (first waiter is a reader), all readers are eligible\n\t * to acquire the lock at the same time irrespective of their order\n\t * in the queue. The writers acquire the lock according to their\n\t * order in the queue.\n\t *\n\t * We have to do wakeup in 2 passes to prevent the possibility that\n\t * the reader count may be decremented before it is incremented. It\n\t * is because the to-be-woken waiter may not have slept yet. So it\n\t * may see waiter->task got cleared, finish its critical section and\n\t * do an unlock before the reader count increment.\n\t *\n\t * 1) Collect the read-waiters in a separate list, count them and\n\t *    fully increment the reader count in rwsem.\n\t * 2) For each waiters in the new list, clear waiter->task and\n\t *    put them into wake_q to be woken up later.\n\t */\n\tINIT_LIST_HEAD(&wlist);\n\tlist_for_each_entry_safe(waiter, tmp, &sem->wait_list, list) {\n\t\tif (waiter->type == RWSEM_WAITING_FOR_WRITE)\n\t\t\tcontinue;\n\n\t\twoken++;\n\t\tlist_move_tail(&waiter->list, &wlist);\n\n\t\t/*\n\t\t * Limit # of readers that can be woken up per wakeup call.\n\t\t */\n\t\tif (unlikely(woken >= MAX_READERS_WAKEUP))\n\t\t\tbreak;\n\t}\n\n\tadjustment = woken * RWSEM_READER_BIAS - adjustment;\n\tlockevent_cond_inc(rwsem_wake_reader, woken);\n\n\toldcount = atomic_long_read(&sem->count);\n\tif (list_empty(&sem->wait_list)) {\n\t\t/*\n\t\t * Combined with list_move_tail() above, this implies\n\t\t * rwsem_del_waiter().\n\t\t */\n\t\tadjustment -= RWSEM_FLAG_WAITERS;\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t} else if (woken) {\n\t\t/*\n\t\t * When we've woken a reader, we no longer need to force\n\t\t * writers to give up the lock and we can clear HANDOFF.\n\t\t */\n\t\tif (oldcount & RWSEM_FLAG_HANDOFF)\n\t\t\tadjustment -= RWSEM_FLAG_HANDOFF;\n\t}\n\n\tif (adjustment)\n\t\tatomic_long_add(adjustment, &sem->count);\n\n\t/* 2nd pass */\n\tlist_for_each_entry_safe(waiter, tmp, &wlist, list) {\n\t\tstruct task_struct *tsk;\n\n\t\ttsk = waiter->task;\n\t\tget_task_struct(tsk);\n\n\t\t/*\n\t\t * Ensure calling get_task_struct() before setting the reader\n\t\t * waiter to nil such that rwsem_down_read_slowpath() cannot\n\t\t * race with do_exit() by always holding a reference count\n\t\t * to the task to wakeup.\n\t\t */\n\t\tsmp_store_release(&waiter->task, NULL);\n\t\t/*\n\t\t * Ensure issuing the wakeup (either by us or someone else)\n\t\t * after setting the reader waiter to nil.\n\t\t */\n\t\twake_q_add_safe(wake_q, tsk);\n\t}\n}"
  },
  {
    "function_name": "rwsem_del_waiter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "379-388",
    "snippet": "static inline void\nrwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_del(&waiter->list);\n\tif (likely(!list_empty(&sem->wait_list)))\n\t\treturn;\n\n\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_FLAG_HANDOFF\t(1UL << 2)",
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_andnot",
          "args": [
            "RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS",
            "&sem->count"
          ],
          "line": 387
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "likely",
          "args": [
            "!list_empty(&sem->wait_list)"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&sem->wait_list"
          ],
          "line": 384
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_del",
          "args": [
            "&waiter->list"
          ],
          "line": 383
        },
        "resolved": true,
        "details": {
          "function_name": "list_del_leaf_cfs_rq",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/fair.c",
          "lines": "475-477",
          "snippet": "static inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}",
          "includes": [
            "#include \"pelt.h\"",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);",
            "static void check_enqueue_throttle(struct cfs_rq *cfs_rq);",
            "static __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);",
            "static bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"pelt.h\"\n#include \"sched.h\"\n\nstatic bool sched_idle_cfs_rq(struct cfs_rq *cfs_rq);\nstatic void check_enqueue_throttle(struct cfs_rq *cfs_rq);\nstatic __always_inline void return_cfs_rq_runtime(struct cfs_rq *cfs_rq);\nstatic bool check_cfs_rq_runtime(struct cfs_rq *cfs_rq);\n\nstatic inline void list_del_leaf_cfs_rq(struct cfs_rq *cfs_rq)\n{\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 382
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_HANDOFF\t(1UL << 2)\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void\nrwsem_del_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_del(&waiter->list);\n\tif (likely(!list_empty(&sem->wait_list)))\n\t\treturn;\n\n\tatomic_long_andnot(RWSEM_FLAG_HANDOFF | RWSEM_FLAG_WAITERS, &sem->count);\n}"
  },
  {
    "function_name": "rwsem_add_waiter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "365-371",
    "snippet": "static inline void\nrwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_add_tail(&waiter->list, &sem->wait_list);\n\t/* caller will set RWSEM_FLAG_WAITERS */\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_FLAG_WAITERS\t(1UL << 1)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&waiter->list",
            "&sem->wait_list"
          ],
          "line": 369
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_held",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 368
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_FLAG_WAITERS\t(1UL << 1)\n\nstatic inline void\nrwsem_add_waiter(struct rw_semaphore *sem, struct rwsem_waiter *waiter)\n{\n\tlockdep_assert_held(&sem->wait_lock);\n\tlist_add_tail(&waiter->list, &sem->wait_list);\n\t/* caller will set RWSEM_FLAG_WAITERS */\n}"
  },
  {
    "function_name": "__init_rwsem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "304-324",
    "snippet": "void __init_rwsem(struct rw_semaphore *sem, const char *name,\n\t\t  struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t/*\n\t * Make sure we are not reinitializing a held semaphore:\n\t */\n\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));\n\tlockdep_init_map_wait(&sem->dep_map, name, key, 0, LD_WAIT_SLEEP);\n#endif\n#ifdef CONFIG_DEBUG_RWSEMS\n\tsem->magic = sem;\n#endif\n\tatomic_long_set(&sem->count, RWSEM_UNLOCKED_VALUE);\n\traw_spin_lock_init(&sem->wait_lock);\n\tINIT_LIST_HEAD(&sem->wait_list);\n\tatomic_long_set(&sem->owner, 0L);\n#ifdef CONFIG_RWSEM_SPIN_ON_OWNER\n\tosq_lock_init(&sem->osq);\n#endif\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "osq_lock_init",
          "args": [
            "&sem->osq"
          ],
          "line": 322
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&sem->owner",
            "0L"
          ],
          "line": 320
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_LIST_HEAD",
          "args": [
            "&sem->wait_list"
          ],
          "line": 319
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_init",
          "args": [
            "&sem->wait_lock"
          ],
          "line": 318
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&sem->count",
            "RWSEM_UNLOCKED_VALUE"
          ],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_init_map_wait",
          "args": [
            "&sem->dep_map",
            "name",
            "key",
            "0",
            "LD_WAIT_SLEEP"
          ],
          "line": 312
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "debug_check_no_locks_freed",
          "args": [
            "(void *)sem",
            "sizeof(*sem)"
          ],
          "line": 311
        },
        "resolved": true,
        "details": {
          "function_name": "debug_check_no_locks_freed",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/lockdep.c",
          "lines": "6405-6427",
          "snippet": "void debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}",
          "includes": [
            "#include \"lockdep_states.h\"",
            "#include <trace/events/lock.h>",
            "#include \"lockdep_internals.h\"",
            "#include <asm/sections.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/nmi.h>",
            "#include <linux/jhash.h>",
            "#include <linux/random.h>",
            "#include <linux/gfp.h>",
            "#include <linux/bitops.h>",
            "#include <linux/bitmap.h>",
            "#include <linux/stringify.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/hash.h>",
            "#include <linux/utsname.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/module.h>",
            "#include <linux/delay.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static noinstr struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"lockdep_states.h\"\n#include <trace/events/lock.h>\n#include \"lockdep_internals.h\"\n#include <asm/sections.h>\n#include <linux/lockdep.h>\n#include <linux/kprobes.h>\n#include <linux/rcupdate.h>\n#include <linux/nmi.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/gfp.h>\n#include <linux/bitops.h>\n#include <linux/bitmap.h>\n#include <linux/stringify.h>\n#include <linux/ftrace.h>\n#include <linux/hash.h>\n#include <linux/utsname.h>\n#include <linux/irqflags.h>\n#include <linux/debug_locks.h>\n#include <linux/stacktrace.h>\n#include <linux/interrupt.h>\n#include <linux/kallsyms.h>\n#include <linux/spinlock.h>\n#include <linux/seq_file.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/delay.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/task.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n\nstatic noinstr struct;\n\nvoid debug_check_no_locks_freed(const void *mem_from, unsigned long mem_len)\n{\n\tstruct task_struct *curr = current;\n\tstruct held_lock *hlock;\n\tunsigned long flags;\n\tint i;\n\n\tif (unlikely(!debug_locks))\n\t\treturn;\n\n\traw_local_irq_save(flags);\n\tfor (i = 0; i < curr->lockdep_depth; i++) {\n\t\thlock = curr->held_locks + i;\n\n\t\tif (not_in_range(mem_from, mem_len, hlock->instance,\n\t\t\t\t\tsizeof(*hlock->instance)))\n\t\t\tcontinue;\n\n\t\tprint_freed_lock_bug(curr, mem_from, mem_from + mem_len, hlock);\n\t\tbreak;\n\t}\n\traw_local_irq_restore(flags);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid __init_rwsem(struct rw_semaphore *sem, const char *name,\n\t\t  struct lock_class_key *key)\n{\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\n\t/*\n\t * Make sure we are not reinitializing a held semaphore:\n\t */\n\tdebug_check_no_locks_freed((void *)sem, sizeof(*sem));\n\tlockdep_init_map_wait(&sem->dep_map, name, key, 0, LD_WAIT_SLEEP);\n#endif\n#ifdef CONFIG_DEBUG_RWSEMS\n\tsem->magic = sem;\n#endif\n\tatomic_long_set(&sem->count, RWSEM_UNLOCKED_VALUE);\n\traw_spin_lock_init(&sem->wait_lock);\n\tINIT_LIST_HEAD(&sem->wait_list);\n\tatomic_long_set(&sem->owner, 0L);\n#ifdef CONFIG_RWSEM_SPIN_ON_OWNER\n\tosq_lock_init(&sem->osq);\n#endif\n}"
  },
  {
    "function_name": "rwsem_owner_flags",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "275-282",
    "snippet": "static inline struct task_struct *\nrwsem_owner_flags(struct rw_semaphore *sem, unsigned long *pflags)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\t*pflags = owner & RWSEM_OWNER_FLAGS_MASK;\n\treturn (struct task_struct *)(owner & ~RWSEM_OWNER_FLAGS_MASK);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline struct task_struct *\nrwsem_owner_flags(struct rw_semaphore *sem, unsigned long *pflags)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\t*pflags = owner & RWSEM_OWNER_FLAGS_MASK;\n\treturn (struct task_struct *)(owner & ~RWSEM_OWNER_FLAGS_MASK);\n}"
  },
  {
    "function_name": "rwsem_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "265-269",
    "snippet": "static inline struct task_struct *rwsem_owner(struct rw_semaphore *sem)\n{\n\treturn (struct task_struct *)\n\t\t(atomic_long_read(&sem->owner) & ~RWSEM_OWNER_FLAGS_MASK);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 268
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline struct task_struct *rwsem_owner(struct rw_semaphore *sem)\n{\n\treturn (struct task_struct *)\n\t\t(atomic_long_read(&sem->owner) & ~RWSEM_OWNER_FLAGS_MASK);\n}"
  },
  {
    "function_name": "rwsem_write_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "250-260",
    "snippet": "static inline bool rwsem_write_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp = RWSEM_UNLOCKED_VALUE;\n\n\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {\n\t\trwsem_set_owner(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_WRITER_LOCKED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_set_owner",
          "args": [
            "sem"
          ],
          "line": 255
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "136-139",
          "snippet": "static inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg_acquire",
          "args": [
            "&sem->count",
            "&tmp",
            "RWSEM_WRITER_LOCKED"
          ],
          "line": 254
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WRITER_LOCKED\t(1UL << 0)\n\nstatic inline bool rwsem_write_trylock(struct rw_semaphore *sem)\n{\n\tlong tmp = RWSEM_UNLOCKED_VALUE;\n\n\tif (atomic_long_try_cmpxchg_acquire(&sem->count, &tmp, RWSEM_WRITER_LOCKED)) {\n\t\trwsem_set_owner(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
  },
  {
    "function_name": "rwsem_read_trylock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "235-248",
    "snippet": "static inline bool rwsem_read_trylock(struct rw_semaphore *sem, long *cntp)\n{\n\t*cntp = atomic_long_add_return_acquire(RWSEM_READER_BIAS, &sem->count);\n\n\tif (WARN_ON_ONCE(*cntp < 0))\n\t\trwsem_set_nonspinnable(sem);\n\n\tif (!(*cntp & RWSEM_READ_FAILED_MASK)) {\n\t\trwsem_set_reader_owned(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_READ_FAILED_MASK\t(RWSEM_WRITER_MASK|RWSEM_FLAG_WAITERS|\\\n\t\t\t\t RWSEM_FLAG_HANDOFF|RWSEM_FLAG_READFAIL)",
      "#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_set_reader_owned",
          "args": [
            "sem"
          ],
          "line": 243
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "173-176",
          "snippet": "static inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rwsem_set_nonspinnable",
          "args": [
            "sem"
          ],
          "line": 240
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_set_nonspinnable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "222-233",
          "snippet": "static inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\tdo {\n\t\tif (!(owner & RWSEM_READER_OWNED))\n\t\t\tbreak;\n\t\tif (owner & RWSEM_NONSPINNABLE)\n\t\t\tbreak;\n\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,\n\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [
            "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
            "#define RWSEM_READER_OWNED\t(1UL << 0)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\tdo {\n\t\tif (!(owner & RWSEM_READER_OWNED))\n\t\t\tbreak;\n\t\tif (owner & RWSEM_NONSPINNABLE)\n\t\t\tbreak;\n\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,\n\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "*cntp < 0"
          ],
          "line": 239
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_add_return_acquire",
          "args": [
            "RWSEM_READER_BIAS",
            "&sem->count"
          ],
          "line": 237
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_READ_FAILED_MASK\t(RWSEM_WRITER_MASK|RWSEM_FLAG_WAITERS|\\\n\t\t\t\t RWSEM_FLAG_HANDOFF|RWSEM_FLAG_READFAIL)\n#define RWSEM_READER_BIAS\t(1UL << RWSEM_READER_SHIFT)\n\nstatic inline bool rwsem_read_trylock(struct rw_semaphore *sem, long *cntp)\n{\n\t*cntp = atomic_long_add_return_acquire(RWSEM_READER_BIAS, &sem->count);\n\n\tif (WARN_ON_ONCE(*cntp < 0))\n\t\trwsem_set_nonspinnable(sem);\n\n\tif (!(*cntp & RWSEM_READ_FAILED_MASK)) {\n\t\trwsem_set_reader_owned(sem);\n\t\treturn true;\n\t}\n\n\treturn false;\n}"
  },
  {
    "function_name": "rwsem_set_nonspinnable",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "222-233",
    "snippet": "static inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\tdo {\n\t\tif (!(owner & RWSEM_READER_OWNED))\n\t\t\tbreak;\n\t\tif (owner & RWSEM_NONSPINNABLE)\n\t\t\tbreak;\n\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,\n\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
      "#define RWSEM_READER_OWNED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&sem->owner",
            "&owner",
            "owner | RWSEM_NONSPINNABLE"
          ],
          "line": 231
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 224
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline void rwsem_set_nonspinnable(struct rw_semaphore *sem)\n{\n\tunsigned long owner = atomic_long_read(&sem->owner);\n\n\tdo {\n\t\tif (!(owner & RWSEM_READER_OWNED))\n\t\t\tbreak;\n\t\tif (owner & RWSEM_NONSPINNABLE)\n\t\t\tbreak;\n\t} while (!atomic_long_try_cmpxchg(&sem->owner, &owner,\n\t\t\t\t\t  owner | RWSEM_NONSPINNABLE));\n}"
  },
  {
    "function_name": "rwsem_clear_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "213-215",
    "snippet": "static inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)\n{\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)\n{\n}"
  },
  {
    "function_name": "rwsem_clear_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "202-211",
    "snippet": "static inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)\n{\n\tunsigned long val = atomic_long_read(&sem->owner);\n\n\twhile ((val & ~RWSEM_OWNER_FLAGS_MASK) == (unsigned long)current) {\n\t\tif (atomic_long_try_cmpxchg(&sem->owner, &val,\n\t\t\t\t\t    val & RWSEM_OWNER_FLAGS_MASK))\n\t\t\treturn;\n\t}\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_try_cmpxchg",
          "args": [
            "&sem->owner",
            "&val",
            "val & RWSEM_OWNER_FLAGS_MASK"
          ],
          "line": 207
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 204
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_OWNER_FLAGS_MASK\t(RWSEM_READER_OWNED | RWSEM_NONSPINNABLE)\n\nstatic inline void rwsem_clear_reader_owned(struct rw_semaphore *sem)\n{\n\tunsigned long val = atomic_long_read(&sem->owner);\n\n\twhile ((val & ~RWSEM_OWNER_FLAGS_MASK) == (unsigned long)current) {\n\t\tif (atomic_long_try_cmpxchg(&sem->owner, &val,\n\t\t\t\t\t    val & RWSEM_OWNER_FLAGS_MASK))\n\t\t\treturn;\n\t}\n}"
  },
  {
    "function_name": "is_rwsem_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "181-193",
    "snippet": "static inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n#ifdef CONFIG_DEBUG_RWSEMS\n\t/*\n\t * Check the count to see if it is write-locked.\n\t */\n\tlong count = atomic_long_read(&sem->count);\n\n\tif (count & RWSEM_WRITER_MASK)\n\t\treturn false;\n#endif\n\treturn rwsem_test_oflags(sem, RWSEM_READER_OWNED);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED",
      "#define RWSEM_READER_OWNED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rwsem_test_oflags",
          "args": [
            "sem",
            "RWSEM_READER_OWNED"
          ],
          "line": 192
        },
        "resolved": true,
        "details": {
          "function_name": "rwsem_test_oflags",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "149-152",
          "snippet": "static inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->count"
          ],
          "line": 187
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_WRITER_MASK\tRWSEM_WRITER_LOCKED\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline bool is_rwsem_reader_owned(struct rw_semaphore *sem)\n{\n#ifdef CONFIG_DEBUG_RWSEMS\n\t/*\n\t * Check the count to see if it is write-locked.\n\t */\n\tlong count = atomic_long_read(&sem->count);\n\n\tif (count & RWSEM_WRITER_MASK)\n\t\treturn false;\n#endif\n\treturn rwsem_test_oflags(sem, RWSEM_READER_OWNED);\n}"
  },
  {
    "function_name": "rwsem_set_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "173-176",
    "snippet": "static inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__rwsem_set_reader_owned",
          "args": [
            "sem",
            "current"
          ],
          "line": 175
        },
        "resolved": true,
        "details": {
          "function_name": "__rwsem_set_reader_owned",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
          "lines": "1441-1444",
          "snippet": "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}",
          "includes": [
            "#include \"rwbase_rt.c\"",
            "#include \"rtmutex.c\"",
            "#include \"lock_events.h\"",
            "#include <linux/atomic.h>",
            "#include <linux/rwsem.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_reader_owned(struct rw_semaphore *sem)\n{\n\t__rwsem_set_reader_owned(sem, current);\n}"
  },
  {
    "function_name": "__rwsem_set_reader_owned",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "164-171",
    "snippet": "static inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n\tunsigned long val = (unsigned long)owner | RWSEM_READER_OWNED |\n\t\t(atomic_long_read(&sem->owner) & RWSEM_NONSPINNABLE);\n\n\tatomic_long_set(&sem->owner, val);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [
      "#define RWSEM_NONSPINNABLE\t(1UL << 1)",
      "#define RWSEM_READER_OWNED\t(1UL << 0)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&sem->owner",
            "val"
          ],
          "line": 170
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 168
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\n#define RWSEM_NONSPINNABLE\t(1UL << 1)\n#define RWSEM_READER_OWNED\t(1UL << 0)\n\nstatic inline void __rwsem_set_reader_owned(struct rw_semaphore *sem,\n\t\t\t\t\t    struct task_struct *owner)\n{\n\tunsigned long val = (unsigned long)owner | RWSEM_READER_OWNED |\n\t\t(atomic_long_read(&sem->owner) & RWSEM_NONSPINNABLE);\n\n\tatomic_long_set(&sem->owner, val);\n}"
  },
  {
    "function_name": "rwsem_test_oflags",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "149-152",
    "snippet": "static inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_read",
          "args": [
            "&sem->owner"
          ],
          "line": 151
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline bool rwsem_test_oflags(struct rw_semaphore *sem, long flags)\n{\n\treturn atomic_long_read(&sem->owner) & flags;\n}"
  },
  {
    "function_name": "rwsem_clear_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "141-144",
    "snippet": "static inline void rwsem_clear_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, 0);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&sem->owner",
            "0"
          ],
          "line": 143
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_clear_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, 0);\n}"
  },
  {
    "function_name": "rwsem_set_owner",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rwsem.c",
    "lines": "136-139",
    "snippet": "static inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}",
    "includes": [
      "#include \"rwbase_rt.c\"",
      "#include \"rtmutex.c\"",
      "#include \"lock_events.h\"",
      "#include <linux/atomic.h>",
      "#include <linux/rwsem.h>",
      "#include <linux/export.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/sched/wake_q.h>",
      "#include <linux/sched/debug.h>",
      "#include <linux/sched/task.h>",
      "#include <linux/sched/rt.h>",
      "#include <linux/sched.h>",
      "#include <linux/kernel.h>",
      "#include <linux/types.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_long_set",
          "args": [
            "&sem->owner",
            "(long)current"
          ],
          "line": 138
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"rwbase_rt.c\"\n#include \"rtmutex.c\"\n#include \"lock_events.h\"\n#include <linux/atomic.h>\n#include <linux/rwsem.h>\n#include <linux/export.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task.h>\n#include <linux/sched/rt.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic inline void rwsem_set_owner(struct rw_semaphore *sem)\n{\n\tatomic_long_set(&sem->owner, (long)current);\n}"
  }
]