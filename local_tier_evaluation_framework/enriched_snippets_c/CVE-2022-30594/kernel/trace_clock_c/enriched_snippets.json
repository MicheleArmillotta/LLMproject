[
  {
    "function_name": "trace_clock_counter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_clock.c",
    "lines": "155-158",
    "snippet": "u64 notrace trace_clock_counter(void)\n{\n\treturn atomic64_add_return(1, &trace_counter);\n}",
    "includes": [
      "#include <linux/trace_clock.h>",
      "#include <linux/ktime.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static atomic64_t trace_counter;"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic64_add_return",
          "args": [
            "1",
            "&trace_counter"
          ],
          "line": 157
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/trace_clock.h>\n#include <linux/ktime.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/irqflags.h>\n#include <linux/spinlock.h>\n\nstatic atomic64_t trace_counter;\n\nu64 notrace trace_clock_counter(void)\n{\n\treturn atomic64_add_return(1, &trace_counter);\n}"
  },
  {
    "function_name": "trace_clock_global",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_clock.c",
    "lines": "94-145",
    "snippet": "u64 notrace trace_clock_global(void)\n{\n\tunsigned long flags;\n\tint this_cpu;\n\tu64 now, prev_time;\n\n\traw_local_irq_save(flags);\n\n\tthis_cpu = raw_smp_processor_id();\n\n\t/*\n\t * The global clock \"guarantees\" that the events are ordered\n\t * between CPUs. But if two events on two different CPUS call\n\t * trace_clock_global at roughly the same time, it really does\n\t * not matter which one gets the earlier time. Just make sure\n\t * that the same CPU will always show a monotonic clock.\n\t *\n\t * Use a read memory barrier to get the latest written\n\t * time that was recorded.\n\t */\n\tsmp_rmb();\n\tprev_time = READ_ONCE(trace_clock_struct.prev_time);\n\tnow = sched_clock_cpu(this_cpu);\n\n\t/* Make sure that now is always greater than or equal to prev_time */\n\tif ((s64)(now - prev_time) < 0)\n\t\tnow = prev_time;\n\n\t/*\n\t * If in an NMI context then dont risk lockups and simply return\n\t * the current time.\n\t */\n\tif (unlikely(in_nmi()))\n\t\tgoto out;\n\n\t/* Tracing can cause strange recursion, always use a try lock */\n\tif (arch_spin_trylock(&trace_clock_struct.lock)) {\n\t\t/* Reread prev_time in case it was already updated */\n\t\tprev_time = READ_ONCE(trace_clock_struct.prev_time);\n\t\tif ((s64)(now - prev_time) < 0)\n\t\t\tnow = prev_time;\n\n\t\ttrace_clock_struct.prev_time = now;\n\n\t\t/* The unlock acts as the wmb for the above rmb */\n\t\tarch_spin_unlock(&trace_clock_struct.lock);\n\t}\n out:\n\traw_local_irq_restore(flags);\n\n\treturn now;\n}",
    "includes": [
      "#include <linux/trace_clock.h>",
      "#include <linux/ktime.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 142
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_unlock",
          "args": [
            "&trace_clock_struct.lock"
          ],
          "line": 139
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "",
          "args": [
            "now - prev_time"
          ],
          "line": 133
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "trace_clock_struct.prev_time"
          ],
          "line": 132
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "arch_spin_trylock",
          "args": [
            "&trace_clock_struct.lock"
          ],
          "line": 130
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "in_nmi()"
          ],
          "line": 126
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "in_nmi",
          "args": [],
          "line": 126
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "",
          "args": [
            "now - prev_time"
          ],
          "line": 119
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_clock_cpu",
          "args": [
            "this_cpu"
          ],
          "line": 116
        },
        "resolved": true,
        "details": {
          "function_name": "sched_clock_cpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/clock.c",
          "lines": "461-467",
          "snippet": "u64 sched_clock_cpu(int cpu)\n{\n\tif (!static_branch_likely(&sched_clock_running))\n\t\treturn 0;\n\n\treturn sched_clock();\n}",
          "includes": [
            "#include <linux/sched_clock.h>",
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_STATIC_KEY_FALSE(sched_clock_running);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched_clock.h>\n#include \"sched.h\"\n\nstatic DEFINE_STATIC_KEY_FALSE(sched_clock_running);\n\nu64 sched_clock_cpu(int cpu)\n{\n\tif (!static_branch_likely(&sched_clock_running))\n\t\treturn 0;\n\n\treturn sched_clock();\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "trace_clock_struct.prev_time"
          ],
          "line": 115
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_rmb",
          "args": [],
          "line": 114
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_smp_processor_id",
          "args": [],
          "line": 102
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_local_irq_save",
          "args": [
            "flags"
          ],
          "line": 100
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/trace_clock.h>\n#include <linux/ktime.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/irqflags.h>\n#include <linux/spinlock.h>\n\nu64 notrace trace_clock_global(void)\n{\n\tunsigned long flags;\n\tint this_cpu;\n\tu64 now, prev_time;\n\n\traw_local_irq_save(flags);\n\n\tthis_cpu = raw_smp_processor_id();\n\n\t/*\n\t * The global clock \"guarantees\" that the events are ordered\n\t * between CPUs. But if two events on two different CPUS call\n\t * trace_clock_global at roughly the same time, it really does\n\t * not matter which one gets the earlier time. Just make sure\n\t * that the same CPU will always show a monotonic clock.\n\t *\n\t * Use a read memory barrier to get the latest written\n\t * time that was recorded.\n\t */\n\tsmp_rmb();\n\tprev_time = READ_ONCE(trace_clock_struct.prev_time);\n\tnow = sched_clock_cpu(this_cpu);\n\n\t/* Make sure that now is always greater than or equal to prev_time */\n\tif ((s64)(now - prev_time) < 0)\n\t\tnow = prev_time;\n\n\t/*\n\t * If in an NMI context then dont risk lockups and simply return\n\t * the current time.\n\t */\n\tif (unlikely(in_nmi()))\n\t\tgoto out;\n\n\t/* Tracing can cause strange recursion, always use a try lock */\n\tif (arch_spin_trylock(&trace_clock_struct.lock)) {\n\t\t/* Reread prev_time in case it was already updated */\n\t\tprev_time = READ_ONCE(trace_clock_struct.prev_time);\n\t\tif ((s64)(now - prev_time) < 0)\n\t\t\tnow = prev_time;\n\n\t\ttrace_clock_struct.prev_time = now;\n\n\t\t/* The unlock acts as the wmb for the above rmb */\n\t\tarch_spin_unlock(&trace_clock_struct.lock);\n\t}\n out:\n\traw_local_irq_restore(flags);\n\n\treturn now;\n}"
  },
  {
    "function_name": "trace_clock_jiffies",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_clock.c",
    "lines": "70-73",
    "snippet": "u64 notrace trace_clock_jiffies(void)\n{\n\treturn jiffies_64_to_clock_t(jiffies_64 - INITIAL_JIFFIES);\n}",
    "includes": [
      "#include <linux/trace_clock.h>",
      "#include <linux/ktime.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "jiffies_64_to_clock_t",
          "args": [
            "jiffies_64 - INITIAL_JIFFIES"
          ],
          "line": 72
        },
        "resolved": true,
        "details": {
          "function_name": "jiffies_64_to_clock_t",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/time.c",
          "lines": "652-671",
          "snippet": "u64 jiffies_64_to_clock_t(u64 x)\n{\n#if (TICK_NSEC % (NSEC_PER_SEC / USER_HZ)) == 0\n# if HZ < USER_HZ\n\tx = div_u64(x * USER_HZ, HZ);\n# elif HZ > USER_HZ\n\tx = div_u64(x, HZ / USER_HZ);\n# else\n\t/* Nothing to do */\n# endif\n#else\n\t/*\n\t * There are better ways that don't overflow early,\n\t * but even this doesn't overflow in hundreds of years\n\t * in 64 bits, so..\n\t */\n\tx = div_u64(x * TICK_NSEC, (NSEC_PER_SEC / USER_HZ));\n#endif\n\treturn x;\n}",
          "includes": [
            "#include \"timekeeping.h\"",
            "#include <generated/timeconst.h>",
            "#include <asm/unistd.h>",
            "#include <linux/compat.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/math64.h>",
            "#include <linux/fs.h>",
            "#include <linux/security.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/errno.h>",
            "#include <linux/timekeeper_internal.h>",
            "#include <linux/capability.h>",
            "#include <linux/timex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"timekeeping.h\"\n#include <generated/timeconst.h>\n#include <asm/unistd.h>\n#include <linux/compat.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/math64.h>\n#include <linux/fs.h>\n#include <linux/security.h>\n#include <linux/syscalls.h>\n#include <linux/errno.h>\n#include <linux/timekeeper_internal.h>\n#include <linux/capability.h>\n#include <linux/timex.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nu64 jiffies_64_to_clock_t(u64 x)\n{\n#if (TICK_NSEC % (NSEC_PER_SEC / USER_HZ)) == 0\n# if HZ < USER_HZ\n\tx = div_u64(x * USER_HZ, HZ);\n# elif HZ > USER_HZ\n\tx = div_u64(x, HZ / USER_HZ);\n# else\n\t/* Nothing to do */\n# endif\n#else\n\t/*\n\t * There are better ways that don't overflow early,\n\t * but even this doesn't overflow in hundreds of years\n\t * in 64 bits, so..\n\t */\n\tx = div_u64(x * TICK_NSEC, (NSEC_PER_SEC / USER_HZ));\n#endif\n\treturn x;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/trace_clock.h>\n#include <linux/ktime.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/irqflags.h>\n#include <linux/spinlock.h>\n\nu64 notrace trace_clock_jiffies(void)\n{\n\treturn jiffies_64_to_clock_t(jiffies_64 - INITIAL_JIFFIES);\n}"
  },
  {
    "function_name": "trace_clock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_clock.c",
    "lines": "57-60",
    "snippet": "u64 notrace trace_clock(void)\n{\n\treturn local_clock();\n}",
    "includes": [
      "#include <linux/trace_clock.h>",
      "#include <linux/ktime.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_clock",
          "args": [],
          "line": 59
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/trace_clock.h>\n#include <linux/ktime.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/irqflags.h>\n#include <linux/spinlock.h>\n\nu64 notrace trace_clock(void)\n{\n\treturn local_clock();\n}"
  },
  {
    "function_name": "trace_clock_local",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/trace_clock.c",
    "lines": "32-46",
    "snippet": "u64 notrace trace_clock_local(void)\n{\n\tu64 clock;\n\n\t/*\n\t * sched_clock() is an architecture implemented, fast, scalable,\n\t * lockless clock. It is not guaranteed to be coherent across\n\t * CPUs, nor across CPU idle events.\n\t */\n\tpreempt_disable_notrace();\n\tclock = sched_clock();\n\tpreempt_enable_notrace();\n\n\treturn clock;\n}",
    "includes": [
      "#include <linux/trace_clock.h>",
      "#include <linux/ktime.h>",
      "#include <linux/sched/clock.h>",
      "#include <linux/sched.h>",
      "#include <linux/percpu.h>",
      "#include <linux/module.h>",
      "#include <linux/hardirq.h>",
      "#include <linux/irqflags.h>",
      "#include <linux/spinlock.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable_notrace",
          "args": [],
          "line": 43
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "sched_clock",
          "args": [],
          "line": 42
        },
        "resolved": true,
        "details": {
          "function_name": "sched_clock_stable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/trace/ring_buffer.c",
          "lines": "2722-2725",
          "snippet": "static inline bool sched_clock_stable(void)\n{\n\treturn true;\n}",
          "includes": [
            "#include <asm/local64.h>",
            "#include <asm/local.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/list.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/delay.h>",
            "#include <linux/mutex.h>",
            "#include <linux/percpu.h>",
            "#include <linux/module.h>",
            "#include <linux/kthread.h>\t/* for self test */",
            "#include <linux/hardirq.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/security.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/trace_seq.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/trace_clock.h>",
            "#include <linux/ring_buffer.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/trace_recursion.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/local64.h>\n#include <asm/local.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/list.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/delay.h>\n#include <linux/mutex.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/kthread.h>\t/* for self test */\n#include <linux/hardirq.h>\n#include <linux/uaccess.h>\n#include <linux/security.h>\n#include <linux/irq_work.h>\n#include <linux/spinlock.h>\n#include <linux/trace_seq.h>\n#include <linux/sched/clock.h>\n#include <linux/trace_clock.h>\n#include <linux/ring_buffer.h>\n#include <linux/trace_events.h>\n#include <linux/trace_recursion.h>\n\nstatic inline bool sched_clock_stable(void)\n{\n\treturn true;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preempt_disable_notrace",
          "args": [],
          "line": 41
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/trace_clock.h>\n#include <linux/ktime.h>\n#include <linux/sched/clock.h>\n#include <linux/sched.h>\n#include <linux/percpu.h>\n#include <linux/module.h>\n#include <linux/hardirq.h>\n#include <linux/irqflags.h>\n#include <linux/spinlock.h>\n\nu64 notrace trace_clock_local(void)\n{\n\tu64 clock;\n\n\t/*\n\t * sched_clock() is an architecture implemented, fast, scalable,\n\t * lockless clock. It is not guaranteed to be coherent across\n\t * CPUs, nor across CPU idle events.\n\t */\n\tpreempt_disable_notrace();\n\tclock = sched_clock();\n\tpreempt_enable_notrace();\n\n\treturn clock;\n}"
  }
]