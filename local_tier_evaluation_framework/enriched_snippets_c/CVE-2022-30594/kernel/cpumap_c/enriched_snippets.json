[
  {
    "function_name": "cpu_map_init",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "791-798",
    "snippet": "static int __init cpu_map_init(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tINIT_LIST_HEAD(&per_cpu(cpu_map_flush_list, cpu));\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);"
    ],
    "called_functions": [],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);\n\nstatic int __init cpu_map_init(void)\n{\n\tint cpu;\n\n\tfor_each_possible_cpu(cpu)\n\t\tINIT_LIST_HEAD(&per_cpu(cpu_map_flush_list, cpu));\n\treturn 0;\n}"
  },
  {
    "function_name": "__cpu_map_flush",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "778-789",
    "snippet": "void __cpu_map_flush(void)\n{\n\tstruct list_head *flush_list = this_cpu_ptr(&cpu_map_flush_list);\n\tstruct xdp_bulk_queue *bq, *tmp;\n\n\tlist_for_each_entry_safe(bq, tmp, flush_list, flush_node) {\n\t\tbq_flush_to_queue(bq);\n\n\t\t/* If already running, costs spin_lock_irqsave + smb_mb */\n\t\twake_up_process(bq->obj->kthread);\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [
      "static DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "bq->obj->kthread"
          ],
          "line": 787
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4215-4218",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bq_flush_to_queue",
          "args": [
            "bq"
          ],
          "line": 784
        },
        "resolved": true,
        "details": {
          "function_name": "bq_flush_to_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "689-721",
          "snippet": "static void bq_flush_to_queue(struct xdp_bulk_queue *bq)\n{\n\tstruct bpf_cpu_map_entry *rcpu = bq->obj;\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t__list_del_clearprev(&bq->flush_node);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void bq_flush_to_queue(struct xdp_bulk_queue *bq)\n{\n\tstruct bpf_cpu_map_entry *rcpu = bq->obj;\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t__list_del_clearprev(&bq->flush_node);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "bq",
            "tmp",
            "flush_list",
            "flush_node"
          ],
          "line": 783
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&cpu_map_flush_list"
          ],
          "line": 780
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);\n\nvoid __cpu_map_flush(void)\n{\n\tstruct list_head *flush_list = this_cpu_ptr(&cpu_map_flush_list);\n\tstruct xdp_bulk_queue *bq, *tmp;\n\n\tlist_for_each_entry_safe(bq, tmp, flush_list, flush_node) {\n\t\tbq_flush_to_queue(bq);\n\n\t\t/* If already running, costs spin_lock_irqsave + smb_mb */\n\t\twake_up_process(bq->obj->kthread);\n\t}\n}"
  },
  {
    "function_name": "cpu_map_generic_redirect",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "759-776",
    "snippet": "int cpu_map_generic_redirect(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct sk_buff *skb)\n{\n\tint ret;\n\n\t__skb_pull(skb, skb->mac_len);\n\tskb_set_redirected(skb, false);\n\t__ptr_set_bit(0, &skb);\n\n\tret = ptr_ring_produce(rcpu->queue, skb);\n\tif (ret < 0)\n\t\tgoto trace;\n\n\twake_up_process(rcpu->kthread);\ntrace:\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, !ret, !!ret, rcpu->cpu);\n\treturn ret;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_xdp_cpumap_enqueue",
          "args": [
            "rcpu->map_id",
            "!ret",
            "!!ret",
            "rcpu->cpu"
          ],
          "line": 774
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "rcpu->kthread"
          ],
          "line": 772
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4215-4218",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_produce",
          "args": [
            "rcpu->queue",
            "skb"
          ],
          "line": 768
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_set_bit",
          "args": [
            "0",
            "&skb"
          ],
          "line": 766
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "skb_set_redirected",
          "args": [
            "skb",
            "false"
          ],
          "line": 765
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__skb_pull",
          "args": [
            "skb",
            "skb->mac_len"
          ],
          "line": 764
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nint cpu_map_generic_redirect(struct bpf_cpu_map_entry *rcpu,\n\t\t\t     struct sk_buff *skb)\n{\n\tint ret;\n\n\t__skb_pull(skb, skb->mac_len);\n\tskb_set_redirected(skb, false);\n\t__ptr_set_bit(0, &skb);\n\n\tret = ptr_ring_produce(rcpu->queue, skb);\n\tif (ret < 0)\n\t\tgoto trace;\n\n\twake_up_process(rcpu->kthread);\ntrace:\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, !ret, !!ret, rcpu->cpu);\n\treturn ret;\n}"
  },
  {
    "function_name": "cpu_map_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "749-757",
    "snippet": "int cpu_map_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf,\n\t\t    struct net_device *dev_rx)\n{\n\t/* Info needed when constructing SKB on remote CPU */\n\txdpf->dev_rx = dev_rx;\n\n\tbq_enqueue(rcpu, xdpf);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bq_enqueue",
          "args": [
            "rcpu",
            "xdpf"
          ],
          "line": 755
        },
        "resolved": true,
        "details": {
          "function_name": "bq_enqueue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "726-747",
          "snippet": "static void bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct list_head *flush_list = this_cpu_ptr(&cpu_map_flush_list);\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(bq);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\n\tif (!bq->flush_node.prev)\n\t\tlist_add(&bq->flush_node, flush_list);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [
            "#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */"
          ],
          "globals_used": [
            "static DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\n#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */\n\nstatic DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);\n\nstatic void bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct list_head *flush_list = this_cpu_ptr(&cpu_map_flush_list);\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(bq);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\n\tif (!bq->flush_node.prev)\n\t\tlist_add(&bq->flush_node, flush_list);\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nint cpu_map_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf,\n\t\t    struct net_device *dev_rx)\n{\n\t/* Info needed when constructing SKB on remote CPU */\n\txdpf->dev_rx = dev_rx;\n\n\tbq_enqueue(rcpu, xdpf);\n\treturn 0;\n}"
  },
  {
    "function_name": "bq_enqueue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "726-747",
    "snippet": "static void bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct list_head *flush_list = this_cpu_ptr(&cpu_map_flush_list);\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(bq);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\n\tif (!bq->flush_node.prev)\n\t\tlist_add(&bq->flush_node, flush_list);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [
      "#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */"
    ],
    "globals_used": [
      "static DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);"
    ],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&bq->flush_node",
            "flush_list"
          ],
          "line": 746
        },
        "resolved": true,
        "details": {
          "function_name": "cmp_filterlist_addrs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/debugfs.c",
          "lines": "95-101",
          "snippet": "static int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}",
          "includes": [
            "#include \"kcsan.h\"",
            "#include <linux/uaccess.h>",
            "#include <linux/string.h>",
            "#include <linux/sort.h>",
            "#include <linux/slab.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/sched.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/init.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/bug.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/atomic.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"kcsan.h\"\n#include <linux/uaccess.h>\n#include <linux/string.h>\n#include <linux/sort.h>\n#include <linux/slab.h>\n#include <linux/seq_file.h>\n#include <linux/sched.h>\n#include <linux/kallsyms.h>\n#include <linux/init.h>\n#include <linux/debugfs.h>\n#include <linux/bug.h>\n#include <linux/bsearch.h>\n#include <linux/atomic.h>\n\nstatic int cmp_filterlist_addrs(const void *rhs, const void *lhs)\n{\n\tconst unsigned long a = *(const unsigned long *)rhs;\n\tconst unsigned long b = *(const unsigned long *)lhs;\n\n\treturn a < b ? -1 : a == b ? 0 : 1;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bq_flush_to_queue",
          "args": [
            "bq"
          ],
          "line": 732
        },
        "resolved": true,
        "details": {
          "function_name": "bq_flush_to_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "689-721",
          "snippet": "static void bq_flush_to_queue(struct xdp_bulk_queue *bq)\n{\n\tstruct bpf_cpu_map_entry *rcpu = bq->obj;\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t__list_del_clearprev(&bq->flush_node);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void bq_flush_to_queue(struct xdp_bulk_queue *bq)\n{\n\tstruct bpf_cpu_map_entry *rcpu = bq->obj;\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t__list_del_clearprev(&bq->flush_node);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "bq->count == CPU_MAP_BULK_SIZE"
          ],
          "line": 731
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 729
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&cpu_map_flush_list"
          ],
          "line": 728
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\n#define CPU_MAP_BULK_SIZE 8  /* 8 == one cacheline on 64-bit archs */\n\nstatic DEFINE_PER_CPU(struct list_head, cpu_map_flush_list);\n\nstatic void bq_enqueue(struct bpf_cpu_map_entry *rcpu, struct xdp_frame *xdpf)\n{\n\tstruct list_head *flush_list = this_cpu_ptr(&cpu_map_flush_list);\n\tstruct xdp_bulk_queue *bq = this_cpu_ptr(rcpu->bulkq);\n\n\tif (unlikely(bq->count == CPU_MAP_BULK_SIZE))\n\t\tbq_flush_to_queue(bq);\n\n\t/* Notice, xdp_buff/page MUST be queued here, long enough for\n\t * driver to code invoking us to finished, due to driver\n\t * (e.g. ixgbe) recycle tricks based on page-refcnt.\n\t *\n\t * Thus, incoming xdp_frame is always queued here (else we race\n\t * with another CPU on page-refcnt and remaining driver code).\n\t * Queue time is very short, as driver will invoke flush\n\t * operation, when completing napi->poll call.\n\t */\n\tbq->q[bq->count++] = xdpf;\n\n\tif (!bq->flush_node.prev)\n\t\tlist_add(&bq->flush_node, flush_list);\n}"
  },
  {
    "function_name": "bq_flush_to_queue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "689-721",
    "snippet": "static void bq_flush_to_queue(struct xdp_bulk_queue *bq)\n{\n\tstruct bpf_cpu_map_entry *rcpu = bq->obj;\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t__list_del_clearprev(&bq->flush_node);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_xdp_cpumap_enqueue",
          "args": [
            "rcpu->map_id",
            "processed",
            "drops",
            "to_cpu"
          ],
          "line": 720
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__list_del_clearprev",
          "args": [
            "&bq->flush_node"
          ],
          "line": 717
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_unlock",
          "args": [
            "&q->producer_lock"
          ],
          "line": 715
        },
        "resolved": true,
        "details": {
          "function_name": "__bpf_spin_unlock_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/helpers.c",
          "lines": "315-322",
          "snippet": "static inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"../../lib/kstrtox.h\"",
            "#include <linux/security.h>",
            "#include <linux/proc_ns.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/ctype.h>",
            "#include <linux/filter.h>",
            "#include <linux/uidgid.h>",
            "#include <linux/sched.h>",
            "#include <linux/ktime.h>",
            "#include <linux/topology.h>",
            "#include <linux/smp.h>",
            "#include <linux/random.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(unsigned long, irqsave_flags);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"../../lib/kstrtox.h\"\n#include <linux/security.h>\n#include <linux/proc_ns.h>\n#include <linux/pid_namespace.h>\n#include <linux/jiffies.h>\n#include <linux/ctype.h>\n#include <linux/filter.h>\n#include <linux/uidgid.h>\n#include <linux/sched.h>\n#include <linux/ktime.h>\n#include <linux/topology.h>\n#include <linux/smp.h>\n#include <linux/random.h>\n#include <linux/rcupdate.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nstatic DEFINE_PER_CPU(unsigned long, irqsave_flags);\n\nstatic inline void __bpf_spin_unlock_irqrestore(struct bpf_spin_lock *lock)\n{\n\tunsigned long flags;\n\n\tflags = __this_cpu_read(irqsave_flags);\n\t__bpf_spin_unlock(lock);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xdp_return_frame_rx_napi",
          "args": [
            "xdpf"
          ],
          "line": 710
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_produce",
          "args": [
            "q",
            "xdpf"
          ],
          "line": 707
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "spin_lock",
          "args": [
            "&q->producer_lock"
          ],
          "line": 701
        },
        "resolved": true,
        "details": {
          "function_name": "reg_may_point_to_spin_lock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/verifier.c",
          "lines": "445-449",
          "snippet": "static bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}",
          "includes": [
            "#include \"disasm.h\"",
            "#include <linux/btf_ids.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/error-injection.h>",
            "#include <linux/ctype.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/sort.h>",
            "#include <linux/bsearch.h>",
            "#include <linux/stringify.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/file.h>",
            "#include <net/netlink.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>",
            "#include <linux/slab.h>",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <uapi/linux/btf.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"disasm.h\"\n#include <linux/btf_ids.h>\n#include <linux/bpf_lsm.h>\n#include <linux/error-injection.h>\n#include <linux/ctype.h>\n#include <linux/perf_event.h>\n#include <linux/sort.h>\n#include <linux/bsearch.h>\n#include <linux/stringify.h>\n#include <linux/vmalloc.h>\n#include <linux/file.h>\n#include <net/netlink.h>\n#include <linux/filter.h>\n#include <linux/bpf_verifier.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n#include <linux/slab.h>\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/bpf-cgroup.h>\n#include <uapi/linux/btf.h>\n\nstatic void __mark_reg_not_init(const struct bpf_verifier_env *env,\n\t\t\t\tstruct bpf_reg_state *reg);\n\nstatic bool reg_may_point_to_spin_lock(const struct bpf_reg_state *reg)\n{\n\treturn reg->type == PTR_TO_MAP_VALUE &&\n\t\tmap_value_has_spin_lock(reg->map_ptr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!bq->count"
          ],
          "line": 697
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void bq_flush_to_queue(struct xdp_bulk_queue *bq)\n{\n\tstruct bpf_cpu_map_entry *rcpu = bq->obj;\n\tunsigned int processed = 0, drops = 0;\n\tconst int to_cpu = rcpu->cpu;\n\tstruct ptr_ring *q;\n\tint i;\n\n\tif (unlikely(!bq->count))\n\t\treturn;\n\n\tq = rcpu->queue;\n\tspin_lock(&q->producer_lock);\n\n\tfor (i = 0; i < bq->count; i++) {\n\t\tstruct xdp_frame *xdpf = bq->q[i];\n\t\tint err;\n\n\t\terr = __ptr_ring_produce(q, xdpf);\n\t\tif (err) {\n\t\t\tdrops++;\n\t\t\txdp_return_frame_rx_napi(xdpf);\n\t\t}\n\t\tprocessed++;\n\t}\n\tbq->count = 0;\n\tspin_unlock(&q->producer_lock);\n\n\t__list_del_clearprev(&bq->flush_node);\n\n\t/* Feedback loop via tracepoints */\n\ttrace_xdp_cpumap_enqueue(rcpu->map_id, processed, drops, to_cpu);\n}"
  },
  {
    "function_name": "cpu_map_redirect",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "668-672",
    "snippet": "static int cpu_map_redirect(struct bpf_map *map, u32 ifindex, u64 flags)\n{\n\treturn __bpf_xdp_redirect_map(map, ifindex, flags, 0,\n\t\t\t\t      __cpu_map_lookup_elem);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__bpf_xdp_redirect_map",
          "args": [
            "map",
            "ifindex",
            "flags",
            "0",
            "__cpu_map_lookup_elem"
          ],
          "line": 670
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_redirect(struct bpf_map *map, u32 ifindex, u64 flags)\n{\n\treturn __bpf_xdp_redirect_map(map, ifindex, flags, 0,\n\t\t\t\t      __cpu_map_lookup_elem);\n}"
  },
  {
    "function_name": "cpu_map_get_next_key",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "651-666",
    "snippet": "static int cpu_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= cmap->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == cmap->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 653
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_get_next_key(struct bpf_map *map, void *key, void *next_key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 index = key ? *(u32 *)key : U32_MAX;\n\tu32 *next = next_key;\n\n\tif (index >= cmap->map.max_entries) {\n\t\t*next = 0;\n\t\treturn 0;\n\t}\n\n\tif (index == cmap->map.max_entries - 1)\n\t\treturn -ENOENT;\n\t*next = index + 1;\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "643-649",
    "snippet": "static void *cpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map_entry *rcpu =\n\t\t__cpu_map_lookup_elem(map, *(u32 *)key);\n\n\treturn rcpu ? &rcpu->value : NULL;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cpu_map_lookup_elem",
          "args": [
            "map",
            "*(u32 *)key"
          ],
          "line": 646
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_lookup_elem",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "630-641",
          "snippet": "static void *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = rcu_dereference_check(cmap->cpu_map[key],\n\t\t\t\t     rcu_read_lock_bh_held());\n\treturn rcpu;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = rcu_dereference_check(cmap->cpu_map[key],\n\t\t\t\t     rcu_read_lock_bh_held());\n\treturn rcpu;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void *cpu_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map_entry *rcpu =\n\t\t__cpu_map_lookup_elem(map, *(u32 *)key);\n\n\treturn rcpu ? &rcpu->value : NULL;\n}"
  },
  {
    "function_name": "__cpu_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "630-641",
    "snippet": "static void *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = rcu_dereference_check(cmap->cpu_map[key],\n\t\t\t\t     rcu_read_lock_bh_held());\n\treturn rcpu;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_dereference_check",
          "args": [
            "cmap->cpu_map[key]",
            "rcu_read_lock_bh_held()"
          ],
          "line": 638
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh_held",
          "args": [],
          "line": 639
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 632
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void *__cpu_map_lookup_elem(struct bpf_map *map, u32 key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\tif (key >= map->max_entries)\n\t\treturn NULL;\n\n\trcpu = rcu_dereference_check(cmap->cpu_map[key],\n\t\t\t\t     rcu_read_lock_bh_held());\n\treturn rcpu;\n}"
  },
  {
    "function_name": "cpu_map_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "593-624",
    "snippet": "static void cpu_map_free(struct bpf_map *map)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 i;\n\n\t/* At this point bpf_prog->aux->refcnt == 0 and this map->refcnt == 0,\n\t * so the bpf programs (can be more than one that used this map) were\n\t * disconnected from events. Wait for outstanding critical sections in\n\t * these programs to complete. The rcu critical section only guarantees\n\t * no further \"XDP/bpf-side\" reads against bpf_cpu_map->cpu_map.\n\t * It does __not__ ensure pending flush operations (if any) are\n\t * complete.\n\t */\n\n\tsynchronize_rcu();\n\n\t/* For cpu_map the remote CPUs can still be using the entries\n\t * (struct bpf_cpu_map_entry).\n\t */\n\tfor (i = 0; i < cmap->map.max_entries; i++) {\n\t\tstruct bpf_cpu_map_entry *rcpu;\n\n\t\trcpu = rcu_dereference_raw(cmap->cpu_map[i]);\n\t\tif (!rcpu)\n\t\t\tcontinue;\n\n\t\t/* bq flush and cleanup happens after RCU grace-period */\n\t\t__cpu_map_entry_replace(cmap, i, NULL); /* call_rcu */\n\t}\n\tbpf_map_area_free(cmap->cpu_map);\n\tkfree(cmap);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "cmap"
          ],
          "line": 623
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "cmap->cpu_map"
          ],
          "line": 622
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_entry_replace",
          "args": [
            "cmap",
            "i",
            "NULL"
          ],
          "line": 620
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_replace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "528-539",
          "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_dereference_raw",
          "args": [
            "cmap->cpu_map[i]"
          ],
          "line": 615
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "synchronize_rcu",
          "args": [],
          "line": 607
        },
        "resolved": true,
        "details": {
          "function_name": "synchronize_rcu_expedited",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "816-865",
          "snippet": "void synchronize_rcu_expedited(void)\n{\n\tbool boottime = (rcu_scheduler_active == RCU_SCHEDULER_INIT);\n\tstruct rcu_exp_work rew;\n\tstruct rcu_node *rnp;\n\tunsigned long s;\n\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu_expedited() in RCU read-side critical section\");\n\n\t/* Is the state is such that the call is a grace period? */\n\tif (rcu_blocking_is_gp())\n\t\treturn;\n\n\t/* If expedited grace periods are prohibited, fall back to normal. */\n\tif (rcu_gp_is_normal()) {\n\t\twait_rcu_gp(call_rcu);\n\t\treturn;\n\t}\n\n\t/* Take a snapshot of the sequence number.  */\n\ts = rcu_exp_gp_seq_snap();\n\tif (exp_funnel_lock(s))\n\t\treturn;  /* Someone else did our work for us. */\n\n\t/* Ensure that load happens before action based on it. */\n\tif (unlikely(boottime)) {\n\t\t/* Direct call during scheduler init and early_initcalls(). */\n\t\trcu_exp_sel_wait_wake(s);\n\t} else {\n\t\t/* Marshall arguments & schedule the expedited grace period. */\n\t\trew.rew_s = s;\n\t\tINIT_WORK_ONSTACK(&rew.rew_work, wait_rcu_exp_gp);\n\t\tqueue_work(rcu_gp_wq, &rew.rew_work);\n\t}\n\n\t/* Wait for expedited grace period to complete. */\n\trnp = rcu_get_root();\n\twait_event(rnp->exp_wq[rcu_seq_ctr(s) & 0x3],\n\t\t   sync_exp_work_done(s));\n\tsmp_mb(); /* Workqueue actions happen before return. */\n\n\t/* Let the next expedited grace period start. */\n\tmutex_unlock(&rcu_state.exp_mutex);\n\n\tif (likely(!boottime))\n\t\tdestroy_work_on_stack(&rew.rew_work);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int rcu_print_task_exp_stall(struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic int rcu_print_task_exp_stall(struct rcu_node *rnp);\n\nvoid synchronize_rcu_expedited(void)\n{\n\tbool boottime = (rcu_scheduler_active == RCU_SCHEDULER_INIT);\n\tstruct rcu_exp_work rew;\n\tstruct rcu_node *rnp;\n\tunsigned long s;\n\n\tRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\n\t\t\t lock_is_held(&rcu_lock_map) ||\n\t\t\t lock_is_held(&rcu_sched_lock_map),\n\t\t\t \"Illegal synchronize_rcu_expedited() in RCU read-side critical section\");\n\n\t/* Is the state is such that the call is a grace period? */\n\tif (rcu_blocking_is_gp())\n\t\treturn;\n\n\t/* If expedited grace periods are prohibited, fall back to normal. */\n\tif (rcu_gp_is_normal()) {\n\t\twait_rcu_gp(call_rcu);\n\t\treturn;\n\t}\n\n\t/* Take a snapshot of the sequence number.  */\n\ts = rcu_exp_gp_seq_snap();\n\tif (exp_funnel_lock(s))\n\t\treturn;  /* Someone else did our work for us. */\n\n\t/* Ensure that load happens before action based on it. */\n\tif (unlikely(boottime)) {\n\t\t/* Direct call during scheduler init and early_initcalls(). */\n\t\trcu_exp_sel_wait_wake(s);\n\t} else {\n\t\t/* Marshall arguments & schedule the expedited grace period. */\n\t\trew.rew_s = s;\n\t\tINIT_WORK_ONSTACK(&rew.rew_work, wait_rcu_exp_gp);\n\t\tqueue_work(rcu_gp_wq, &rew.rew_work);\n\t}\n\n\t/* Wait for expedited grace period to complete. */\n\trnp = rcu_get_root();\n\twait_event(rnp->exp_wq[rcu_seq_ctr(s) & 0x3],\n\t\t   sync_exp_work_done(s));\n\tsmp_mb(); /* Workqueue actions happen before return. */\n\n\t/* Let the next expedited grace period start. */\n\tmutex_unlock(&rcu_state.exp_mutex);\n\n\tif (likely(!boottime))\n\t\tdestroy_work_on_stack(&rew.rew_work);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 595
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void cpu_map_free(struct bpf_map *map)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 i;\n\n\t/* At this point bpf_prog->aux->refcnt == 0 and this map->refcnt == 0,\n\t * so the bpf programs (can be more than one that used this map) were\n\t * disconnected from events. Wait for outstanding critical sections in\n\t * these programs to complete. The rcu critical section only guarantees\n\t * no further \"XDP/bpf-side\" reads against bpf_cpu_map->cpu_map.\n\t * It does __not__ ensure pending flush operations (if any) are\n\t * complete.\n\t */\n\n\tsynchronize_rcu();\n\n\t/* For cpu_map the remote CPUs can still be using the entries\n\t * (struct bpf_cpu_map_entry).\n\t */\n\tfor (i = 0; i < cmap->map.max_entries; i++) {\n\t\tstruct bpf_cpu_map_entry *rcpu;\n\n\t\trcpu = rcu_dereference_raw(cmap->cpu_map[i]);\n\t\tif (!rcpu)\n\t\t\tcontinue;\n\n\t\t/* bq flush and cleanup happens after RCU grace-period */\n\t\t__cpu_map_entry_replace(cmap, i, NULL); /* call_rcu */\n\t}\n\tbpf_map_area_free(cmap->cpu_map);\n\tkfree(cmap);\n}"
  },
  {
    "function_name": "cpu_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "554-591",
    "snippet": "static int cpu_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t       u64 map_flags)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpumap_val cpumap_value = {};\n\tstruct bpf_cpu_map_entry *rcpu;\n\t/* Array index key correspond to CPU number */\n\tu32 key_cpu = *(u32 *)key;\n\n\tmemcpy(&cpumap_value, value, map->value_size);\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(key_cpu >= cmap->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\tif (unlikely(cpumap_value.qsize > 16384)) /* sanity limit on qsize */\n\t\treturn -EOVERFLOW;\n\n\t/* Make sure CPU is a valid possible cpu */\n\tif (key_cpu >= nr_cpumask_bits || !cpu_possible(key_cpu))\n\t\treturn -ENODEV;\n\n\tif (cpumap_value.qsize == 0) {\n\t\trcpu = NULL; /* Same as deleting */\n\t} else {\n\t\t/* Updating qsize cause re-allocation of bpf_cpu_map_entry */\n\t\trcpu = __cpu_map_entry_alloc(map, &cpumap_value, key_cpu);\n\t\tif (!rcpu)\n\t\t\treturn -ENOMEM;\n\t\trcpu->cmap = cmap;\n\t}\n\trcu_read_lock();\n\t__cpu_map_entry_replace(cmap, key_cpu, rcpu);\n\trcu_read_unlock();\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock",
          "args": [],
          "line": 589
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_strict",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "815-824",
          "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_entry_replace",
          "args": [
            "cmap",
            "key_cpu",
            "rcpu"
          ],
          "line": 588
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_replace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "528-539",
          "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock",
          "args": [],
          "line": 587
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_any_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "340-351",
          "snippet": "int rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_any_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\tif (lock_is_held(&rcu_lock_map) ||\n\t    lock_is_held(&rcu_bh_lock_map) ||\n\t    lock_is_held(&rcu_sched_lock_map))\n\t\treturn 1;\n\treturn !preemptible();\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_entry_alloc",
          "args": [
            "map",
            "&cpumap_value",
            "key_cpu"
          ],
          "line": 582
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "419-491",
          "snippet": "static struct bpf_cpu_map_entry *\n__cpu_map_entry_alloc(struct bpf_map *map, struct bpf_cpumap_val *value,\n\t\t      u32 cpu)\n{\n\tint numa, err, i, fd = value->bpf_prog.fd;\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tstruct xdp_bulk_queue *bq;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = bpf_map_kmalloc_node(map, sizeof(*rcpu), gfp | __GFP_ZERO, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = bpf_map_alloc_percpu(map, sizeof(*rcpu->bulkq),\n\t\t\t\t\t   sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\tfor_each_possible_cpu(i) {\n\t\tbq = per_cpu_ptr(rcpu->bulkq, i);\n\t\tbq->obj = rcpu;\n\t}\n\n\t/* Alloc queue */\n\trcpu->queue = bpf_map_kmalloc_node(map, sizeof(*rcpu->queue), gfp,\n\t\t\t\t\t   numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, value->qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map->id;\n\trcpu->value.qsize  = value->qsize;\n\n\tif (fd > 0 && __cpu_map_load_bpf_program(rcpu, fd))\n\t\tgoto free_ptr_ring;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu,\n\t\t\t\t\t       map->id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_prog;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_prog:\n\tif (rcpu->prog)\n\t\tbpf_prog_put(rcpu->prog);\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic struct bpf_cpu_map_entry *\n__cpu_map_entry_alloc(struct bpf_map *map, struct bpf_cpumap_val *value,\n\t\t      u32 cpu)\n{\n\tint numa, err, i, fd = value->bpf_prog.fd;\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tstruct xdp_bulk_queue *bq;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = bpf_map_kmalloc_node(map, sizeof(*rcpu), gfp | __GFP_ZERO, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = bpf_map_alloc_percpu(map, sizeof(*rcpu->bulkq),\n\t\t\t\t\t   sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\tfor_each_possible_cpu(i) {\n\t\tbq = per_cpu_ptr(rcpu->bulkq, i);\n\t\tbq->obj = rcpu;\n\t}\n\n\t/* Alloc queue */\n\trcpu->queue = bpf_map_kmalloc_node(map, sizeof(*rcpu->queue), gfp,\n\t\t\t\t\t   numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, value->qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map->id;\n\trcpu->value.qsize  = value->qsize;\n\n\tif (fd > 0 && __cpu_map_load_bpf_program(rcpu, fd))\n\t\tgoto free_ptr_ring;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu,\n\t\t\t\t\t       map->id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_prog;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_prog:\n\tif (rcpu->prog)\n\t\tbpf_prog_put(rcpu->prog);\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_possible",
          "args": [
            "key_cpu"
          ],
          "line": 575
        },
        "resolved": true,
        "details": {
          "function_name": "init_cpu_possible",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "2611-2614",
          "snippet": "void init_cpu_possible(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_possible_mask, src);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nvoid init_cpu_possible(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_possible_mask, src);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "cpumap_value.qsize > 16384"
          ],
          "line": 571
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags == BPF_NOEXIST"
          ],
          "line": 569
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "key_cpu >= cmap->map.max_entries"
          ],
          "line": 567
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "map_flags > BPF_EXIST"
          ],
          "line": 565
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "&cpumap_value",
            "value",
            "map->value_size"
          ],
          "line": 563
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 557
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t       u64 map_flags)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tstruct bpf_cpumap_val cpumap_value = {};\n\tstruct bpf_cpu_map_entry *rcpu;\n\t/* Array index key correspond to CPU number */\n\tu32 key_cpu = *(u32 *)key;\n\n\tmemcpy(&cpumap_value, value, map->value_size);\n\n\tif (unlikely(map_flags > BPF_EXIST))\n\t\treturn -EINVAL;\n\tif (unlikely(key_cpu >= cmap->map.max_entries))\n\t\treturn -E2BIG;\n\tif (unlikely(map_flags == BPF_NOEXIST))\n\t\treturn -EEXIST;\n\tif (unlikely(cpumap_value.qsize > 16384)) /* sanity limit on qsize */\n\t\treturn -EOVERFLOW;\n\n\t/* Make sure CPU is a valid possible cpu */\n\tif (key_cpu >= nr_cpumask_bits || !cpu_possible(key_cpu))\n\t\treturn -ENODEV;\n\n\tif (cpumap_value.qsize == 0) {\n\t\trcpu = NULL; /* Same as deleting */\n\t} else {\n\t\t/* Updating qsize cause re-allocation of bpf_cpu_map_entry */\n\t\trcpu = __cpu_map_entry_alloc(map, &cpumap_value, key_cpu);\n\t\tif (!rcpu)\n\t\t\treturn -ENOMEM;\n\t\trcpu->cmap = cmap;\n\t}\n\trcu_read_lock();\n\t__cpu_map_entry_replace(cmap, key_cpu, rcpu);\n\trcu_read_unlock();\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "541-552",
    "snippet": "static int cpu_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 key_cpu = *(u32 *)key;\n\n\tif (key_cpu >= map->max_entries)\n\t\treturn -EINVAL;\n\n\t/* notice caller map_delete_elem() use preempt_disable() */\n\t__cpu_map_entry_replace(cmap, key_cpu, NULL);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__cpu_map_entry_replace",
          "args": [
            "cmap",
            "key_cpu",
            "NULL"
          ],
          "line": 550
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_entry_replace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "528-539",
          "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_cpu_map",
            "map"
          ],
          "line": 543
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_cpu_map *cmap = container_of(map, struct bpf_cpu_map, map);\n\tu32 key_cpu = *(u32 *)key;\n\n\tif (key_cpu >= map->max_entries)\n\t\treturn -EINVAL;\n\n\t/* notice caller map_delete_elem() use preempt_disable() */\n\t__cpu_map_entry_replace(cmap, key_cpu, NULL);\n\treturn 0;\n}"
  },
  {
    "function_name": "__cpu_map_entry_replace",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "528-539",
    "snippet": "static void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "schedule_work",
          "args": [
            "&old_rcpu->kthread_stop_wq"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "INIT_WORK",
          "args": [
            "&old_rcpu->kthread_stop_wq",
            "cpu_map_kthread_stop"
          ],
          "line": 536
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "call_rcu",
          "args": [
            "&old_rcpu->rcu",
            "__cpu_map_entry_free"
          ],
          "line": 535
        },
        "resolved": true,
        "details": {
          "function_name": "call_rcu_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1533-1536",
          "snippet": "void call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid call_rcu_tasks_trace(struct rcu_head *rhp, rcu_callback_t func)\n{\n\tcall_rcu_tasks_generic(rhp, func, &rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unrcu_pointer",
          "args": [
            "xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu))"
          ],
          "line": 533
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&cmap->cpu_map[key_cpu]",
            "RCU_INITIALIZER(rcpu)"
          ],
          "line": 533
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/qspinlock.c",
          "lines": "220-238",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RCU_INITIALIZER",
          "args": [
            "rcpu"
          ],
          "line": 533
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_entry_replace(struct bpf_cpu_map *cmap,\n\t\t\t\t    u32 key_cpu, struct bpf_cpu_map_entry *rcpu)\n{\n\tstruct bpf_cpu_map_entry *old_rcpu;\n\n\told_rcpu = unrcu_pointer(xchg(&cmap->cpu_map[key_cpu], RCU_INITIALIZER(rcpu)));\n\tif (old_rcpu) {\n\t\tcall_rcu(&old_rcpu->rcu, __cpu_map_entry_free);\n\t\tINIT_WORK(&old_rcpu->kthread_stop_wq, cpu_map_kthread_stop);\n\t\tschedule_work(&old_rcpu->kthread_stop_wq);\n\t}\n}"
  },
  {
    "function_name": "__cpu_map_entry_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "493-507",
    "snippet": "static void __cpu_map_entry_free(struct rcu_head *rcu)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\t/* This cpu_map_entry have been disconnected from map and one\n\t * RCU grace-period have elapsed.  Thus, XDP cannot queue any\n\t * new packets and cannot change/set flush_needed that can\n\t * find this entry.\n\t */\n\trcpu = container_of(rcu, struct bpf_cpu_map_entry, rcu);\n\n\tfree_percpu(rcpu->bulkq);\n\t/* Cannot kthread_stop() here, last put free rcpu resources */\n\tput_cpu_map_entry(rcpu);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_cpu_map_entry",
          "args": [
            "rcpu"
          ],
          "line": 506
        },
        "resolved": true,
        "details": {
          "function_name": "put_cpu_map_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "159-170",
          "snippet": "static void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\tif (rcpu->prog)\n\t\t\tbpf_prog_put(rcpu->prog);\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\tif (rcpu->prog)\n\t\t\tbpf_prog_put(rcpu->prog);\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 504
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/arraymap.c",
          "lines": "21-29",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rcu",
            "structbpf_cpu_map_entry",
            "rcu"
          ],
          "line": 502
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_entry_free(struct rcu_head *rcu)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\t/* This cpu_map_entry have been disconnected from map and one\n\t * RCU grace-period have elapsed.  Thus, XDP cannot queue any\n\t * new packets and cannot change/set flush_needed that can\n\t * find this entry.\n\t */\n\trcpu = container_of(rcu, struct bpf_cpu_map_entry, rcu);\n\n\tfree_percpu(rcpu->bulkq);\n\t/* Cannot kthread_stop() here, last put free rcpu resources */\n\tput_cpu_map_entry(rcpu);\n}"
  },
  {
    "function_name": "__cpu_map_entry_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "419-491",
    "snippet": "static struct bpf_cpu_map_entry *\n__cpu_map_entry_alloc(struct bpf_map *map, struct bpf_cpumap_val *value,\n\t\t      u32 cpu)\n{\n\tint numa, err, i, fd = value->bpf_prog.fd;\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tstruct xdp_bulk_queue *bq;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = bpf_map_kmalloc_node(map, sizeof(*rcpu), gfp | __GFP_ZERO, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = bpf_map_alloc_percpu(map, sizeof(*rcpu->bulkq),\n\t\t\t\t\t   sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\tfor_each_possible_cpu(i) {\n\t\tbq = per_cpu_ptr(rcpu->bulkq, i);\n\t\tbq->obj = rcpu;\n\t}\n\n\t/* Alloc queue */\n\trcpu->queue = bpf_map_kmalloc_node(map, sizeof(*rcpu->queue), gfp,\n\t\t\t\t\t   numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, value->qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map->id;\n\trcpu->value.qsize  = value->qsize;\n\n\tif (fd > 0 && __cpu_map_load_bpf_program(rcpu, fd))\n\t\tgoto free_ptr_ring;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu,\n\t\t\t\t\t       map->id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_prog;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_prog:\n\tif (rcpu->prog)\n\t\tbpf_prog_put(rcpu->prog);\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "rcpu"
          ],
          "line": 489
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "free_percpu",
          "args": [
            "rcpu->bulkq"
          ],
          "line": 487
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_array_free_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/arraymap.c",
          "lines": "21-29",
          "snippet": "static void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}",
          "includes": [
            "#include \"map_in_map.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/filter.h>",
            "#include <linux/mm.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"map_in_map.h\"\n#include <linux/rcupdate_trace.h>\n#include <uapi/linux/btf.h>\n#include <linux/perf_event.h>\n#include <linux/filter.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/btf.h>\n#include <linux/bpf.h>\n\nstatic void bpf_array_free_percpu(struct bpf_array *array)\n{\n\tint i;\n\n\tfor (i = 0; i < array->map.max_entries; i++) {\n\t\tfree_percpu(array->pptrs[i]);\n\t\tcond_resched();\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_cleanup",
          "args": [
            "rcpu->queue",
            "NULL"
          ],
          "line": 483
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_put",
          "args": [
            "rcpu->prog"
          ],
          "line": 481
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_put",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "1828-1831",
          "snippet": "void bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "rcpu->kthread"
          ],
          "line": 475
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4215-4218",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "kthread_bind",
          "args": [
            "rcpu->kthread",
            "cpu"
          ],
          "line": 474
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_bind",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "555-558",
          "snippet": "void kthread_bind(struct task_struct *p, unsigned int cpu)\n{\n\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nvoid kthread_bind(struct task_struct *p, unsigned int cpu)\n{\n\t__kthread_bind(p, cpu, TASK_UNINTERRUPTIBLE);\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_cpu_map_entry",
          "args": [
            "rcpu"
          ],
          "line": 471
        },
        "resolved": true,
        "details": {
          "function_name": "get_cpu_map_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "124-127",
          "snippet": "static void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "rcpu->kthread"
          ],
          "line": 467
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_create_on_node",
          "args": [
            "cpu_map_kthread_run",
            "rcpu",
            "numa",
            "\"cpumap/%d/map:%d\"",
            "cpu",
            "map->id"
          ],
          "line": 464
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_create_on_node",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "504-517",
          "snippet": "struct task_struct *kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t   void *data, int node,\n\t\t\t\t\t   const char namefmt[],\n\t\t\t\t\t   ...)\n{\n\tstruct task_struct *task;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\ttask = __kthread_create_on_node(threadfn, data, node, namefmt, args);\n\tva_end(args);\n\n\treturn task;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;",
            "static __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;",
            "struct task_struct *task;",
            "int node = NUMA_NO_NODE;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nstatic __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;\nstatic __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;\nstruct task_struct *task;\nint node = NUMA_NO_NODE;\n\nstruct task_struct *kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t   void *data, int node,\n\t\t\t\t\t   const char namefmt[],\n\t\t\t\t\t   ...)\n{\n\tstruct task_struct *task;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\ttask = __kthread_create_on_node(threadfn, data, node, namefmt, args);\n\tva_end(args);\n\n\treturn task;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__cpu_map_load_bpf_program",
          "args": [
            "rcpu",
            "fd"
          ],
          "line": 460
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_load_bpf_program",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "400-417",
          "snippet": "static int __cpu_map_load_bpf_program(struct bpf_cpu_map_entry *rcpu, int fd)\n{\n\tstruct bpf_prog *prog;\n\n\tprog = bpf_prog_get_type(fd, BPF_PROG_TYPE_XDP);\n\tif (IS_ERR(prog))\n\t\treturn PTR_ERR(prog);\n\n\tif (prog->expected_attach_type != BPF_XDP_CPUMAP) {\n\t\tbpf_prog_put(prog);\n\t\treturn -EINVAL;\n\t}\n\n\trcpu->value.bpf_prog.id = prog->aux->id;\n\trcpu->prog = prog;\n\n\treturn 0;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int __cpu_map_load_bpf_program(struct bpf_cpu_map_entry *rcpu, int fd)\n{\n\tstruct bpf_prog *prog;\n\n\tprog = bpf_prog_get_type(fd, BPF_PROG_TYPE_XDP);\n\tif (IS_ERR(prog))\n\t\treturn PTR_ERR(prog);\n\n\tif (prog->expected_attach_type != BPF_XDP_CPUMAP) {\n\t\tbpf_prog_put(prog);\n\t\treturn -EINVAL;\n\t}\n\n\trcpu->value.bpf_prog.id = prog->aux->id;\n\trcpu->prog = prog;\n\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_init",
          "args": [
            "rcpu->queue",
            "value->qsize",
            "gfp"
          ],
          "line": 452
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_kmalloc_node",
          "args": [
            "map",
            "sizeof(*rcpu->queue)",
            "gfp",
            "numa"
          ],
          "line": 447
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_kmalloc_node",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "427-438",
          "snippet": "void *bpf_map_kmalloc_node(const struct bpf_map *map, size_t size, gfp_t flags,\n\t\t\t   int node)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = kmalloc_node(size, flags | __GFP_ACCOUNT, node);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_kmalloc_node(const struct bpf_map *map, size_t size, gfp_t flags,\n\t\t\t   int node)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = kmalloc_node(size, flags | __GFP_ACCOUNT, node);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "rcpu->bulkq",
            "i"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_alloc_percpu",
          "args": [
            "map",
            "sizeof(*rcpu->bulkq)",
            "sizeof(void *)",
            "gfp"
          ],
          "line": 436
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_alloc_percpu",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "452-463",
          "snippet": "void __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid __percpu *bpf_map_alloc_percpu(const struct bpf_map *map, size_t size,\n\t\t\t\t    size_t align, gfp_t flags)\n{\n\tstruct mem_cgroup *old_memcg;\n\tvoid __percpu *ptr;\n\n\told_memcg = set_active_memcg(map->memcg);\n\tptr = __alloc_percpu_gfp(size, align, flags | __GFP_ACCOUNT);\n\tset_active_memcg(old_memcg);\n\n\treturn ptr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpu_to_node",
          "args": [
            "cpu"
          ],
          "line": 429
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic struct bpf_cpu_map_entry *\n__cpu_map_entry_alloc(struct bpf_map *map, struct bpf_cpumap_val *value,\n\t\t      u32 cpu)\n{\n\tint numa, err, i, fd = value->bpf_prog.fd;\n\tgfp_t gfp = GFP_KERNEL | __GFP_NOWARN;\n\tstruct bpf_cpu_map_entry *rcpu;\n\tstruct xdp_bulk_queue *bq;\n\n\t/* Have map->numa_node, but choose node of redirect target CPU */\n\tnuma = cpu_to_node(cpu);\n\n\trcpu = bpf_map_kmalloc_node(map, sizeof(*rcpu), gfp | __GFP_ZERO, numa);\n\tif (!rcpu)\n\t\treturn NULL;\n\n\t/* Alloc percpu bulkq */\n\trcpu->bulkq = bpf_map_alloc_percpu(map, sizeof(*rcpu->bulkq),\n\t\t\t\t\t   sizeof(void *), gfp);\n\tif (!rcpu->bulkq)\n\t\tgoto free_rcu;\n\n\tfor_each_possible_cpu(i) {\n\t\tbq = per_cpu_ptr(rcpu->bulkq, i);\n\t\tbq->obj = rcpu;\n\t}\n\n\t/* Alloc queue */\n\trcpu->queue = bpf_map_kmalloc_node(map, sizeof(*rcpu->queue), gfp,\n\t\t\t\t\t   numa);\n\tif (!rcpu->queue)\n\t\tgoto free_bulkq;\n\n\terr = ptr_ring_init(rcpu->queue, value->qsize, gfp);\n\tif (err)\n\t\tgoto free_queue;\n\n\trcpu->cpu    = cpu;\n\trcpu->map_id = map->id;\n\trcpu->value.qsize  = value->qsize;\n\n\tif (fd > 0 && __cpu_map_load_bpf_program(rcpu, fd))\n\t\tgoto free_ptr_ring;\n\n\t/* Setup kthread */\n\trcpu->kthread = kthread_create_on_node(cpu_map_kthread_run, rcpu, numa,\n\t\t\t\t\t       \"cpumap/%d/map:%d\", cpu,\n\t\t\t\t\t       map->id);\n\tif (IS_ERR(rcpu->kthread))\n\t\tgoto free_prog;\n\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for being in cmap->cpu_map[] */\n\tget_cpu_map_entry(rcpu); /* 1-refcnt for kthread */\n\n\t/* Make sure kthread runs on a single CPU */\n\tkthread_bind(rcpu->kthread, cpu);\n\twake_up_process(rcpu->kthread);\n\n\treturn rcpu;\n\nfree_prog:\n\tif (rcpu->prog)\n\t\tbpf_prog_put(rcpu->prog);\nfree_ptr_ring:\n\tptr_ring_cleanup(rcpu->queue, NULL);\nfree_queue:\n\tkfree(rcpu->queue);\nfree_bulkq:\n\tfree_percpu(rcpu->bulkq);\nfree_rcu:\n\tkfree(rcpu);\n\treturn NULL;\n}"
  },
  {
    "function_name": "__cpu_map_load_bpf_program",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "400-417",
    "snippet": "static int __cpu_map_load_bpf_program(struct bpf_cpu_map_entry *rcpu, int fd)\n{\n\tstruct bpf_prog *prog;\n\n\tprog = bpf_prog_get_type(fd, BPF_PROG_TYPE_XDP);\n\tif (IS_ERR(prog))\n\t\treturn PTR_ERR(prog);\n\n\tif (prog->expected_attach_type != BPF_XDP_CPUMAP) {\n\t\tbpf_prog_put(prog);\n\t\treturn -EINVAL;\n\t}\n\n\trcpu->value.bpf_prog.id = prog->aux->id;\n\trcpu->prog = prog;\n\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_prog_put",
          "args": [
            "prog"
          ],
          "line": 409
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_put",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "1828-1831",
          "snippet": "void bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "PTR_ERR",
          "args": [
            "prog"
          ],
          "line": 406
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "prog"
          ],
          "line": 405
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_get_type",
          "args": [
            "fd",
            "BPF_PROG_TYPE_XDP"
          ],
          "line": 404
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_get_type_path",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/inode.c",
          "lines": "586-598",
          "snippet": "struct bpf_prog *bpf_prog_get_type_path(const char *name, enum bpf_prog_type type)\n{\n\tstruct bpf_prog *prog;\n\tstruct path path;\n\tint ret = kern_path(name, LOOKUP_FOLLOW, &path);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tprog = __get_prog_inode(d_backing_inode(path.dentry), type);\n\tif (!IS_ERR(prog))\n\t\ttouch_atime(&path);\n\tpath_put(&path);\n\treturn prog;\n}",
          "includes": [
            "#include \"preload/bpf_preload.h\"",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf.h>",
            "#include <linux/filter.h>",
            "#include <linux/kdev_t.h>",
            "#include <linux/fs_parser.h>",
            "#include <linux/fs_context.h>",
            "#include <linux/fs.h>",
            "#include <linux/namei.h>",
            "#include <linux/mount.h>",
            "#include <linux/major.h>",
            "#include <linux/magic.h>",
            "#include <linux/init.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"preload/bpf_preload.h\"\n#include <linux/bpf_trace.h>\n#include <linux/bpf.h>\n#include <linux/filter.h>\n#include <linux/kdev_t.h>\n#include <linux/fs_parser.h>\n#include <linux/fs_context.h>\n#include <linux/fs.h>\n#include <linux/namei.h>\n#include <linux/mount.h>\n#include <linux/major.h>\n#include <linux/magic.h>\n#include <linux/init.h>\n\nstruct bpf_prog *bpf_prog_get_type_path(const char *name, enum bpf_prog_type type)\n{\n\tstruct bpf_prog *prog;\n\tstruct path path;\n\tint ret = kern_path(name, LOOKUP_FOLLOW, &path);\n\tif (ret)\n\t\treturn ERR_PTR(ret);\n\tprog = __get_prog_inode(d_backing_inode(path.dentry), type);\n\tif (!IS_ERR(prog))\n\t\ttouch_atime(&path);\n\tpath_put(&path);\n\treturn prog;\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int __cpu_map_load_bpf_program(struct bpf_cpu_map_entry *rcpu, int fd)\n{\n\tstruct bpf_prog *prog;\n\n\tprog = bpf_prog_get_type(fd, BPF_PROG_TYPE_XDP);\n\tif (IS_ERR(prog))\n\t\treturn PTR_ERR(prog);\n\n\tif (prog->expected_attach_type != BPF_XDP_CPUMAP) {\n\t\tbpf_prog_put(prog);\n\t\treturn -EINVAL;\n\t}\n\n\trcpu->value.bpf_prog.id = prog->aux->id;\n\trcpu->prog = prog;\n\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_kthread_run",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "298-398",
    "snippet": "static int cpu_map_kthread_run(void *data)\n{\n\tstruct bpf_cpu_map_entry *rcpu = data;\n\n\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t/* When kthread gives stop order, then rcpu have been disconnected\n\t * from map, thus no new packets can enter. Remaining in-flight\n\t * per CPU stored packets are flushed to this queue.  Wait honoring\n\t * kthread_stop signal until queue is empty.\n\t */\n\twhile (!kthread_should_stop() || !__ptr_ring_empty(rcpu->queue)) {\n\t\tstruct xdp_cpumap_stats stats = {}; /* zero stats */\n\t\tunsigned int kmem_alloc_drops = 0, sched = 0;\n\t\tgfp_t gfp = __GFP_ZERO | GFP_ATOMIC;\n\t\tint i, n, m, nframes, xdp_n;\n\t\tvoid *frames[CPUMAP_BATCH];\n\t\tvoid *skbs[CPUMAP_BATCH];\n\t\tLIST_HEAD(list);\n\n\t\t/* Release CPU reschedule checks */\n\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\t/* Recheck to avoid lost wake-up */\n\t\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\t\tschedule();\n\t\t\t\tsched = 1;\n\t\t\t} else {\n\t\t\t\t__set_current_state(TASK_RUNNING);\n\t\t\t}\n\t\t} else {\n\t\t\tsched = cond_resched();\n\t\t}\n\n\t\t/*\n\t\t * The bpf_cpu_map_entry is single consumer, with this\n\t\t * kthread CPU pinned. Lockless access to ptr_ring\n\t\t * consume side valid as no-resize allowed of queue.\n\t\t */\n\t\tn = __ptr_ring_consume_batched(rcpu->queue, frames,\n\t\t\t\t\t       CPUMAP_BATCH);\n\t\tfor (i = 0, xdp_n = 0; i < n; i++) {\n\t\t\tvoid *f = frames[i];\n\t\t\tstruct page *page;\n\n\t\t\tif (unlikely(__ptr_test_bit(0, &f))) {\n\t\t\t\tstruct sk_buff *skb = f;\n\n\t\t\t\t__ptr_clear_bit(0, &skb);\n\t\t\t\tlist_add_tail(&skb->list, &list);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tframes[xdp_n++] = f;\n\t\t\tpage = virt_to_page(f);\n\n\t\t\t/* Bring struct page memory area to curr CPU. Read by\n\t\t\t * build_skb_around via page_is_pfmemalloc(), and when\n\t\t\t * freed written by page_frag_free call.\n\t\t\t */\n\t\t\tprefetchw(page);\n\t\t}\n\n\t\t/* Support running another XDP prog on this CPU */\n\t\tnframes = cpu_map_bpf_prog_run(rcpu, frames, xdp_n, &stats, &list);\n\t\tif (nframes) {\n\t\t\tm = kmem_cache_alloc_bulk(skbuff_head_cache, gfp, nframes, skbs);\n\t\t\tif (unlikely(m == 0)) {\n\t\t\t\tfor (i = 0; i < nframes; i++)\n\t\t\t\t\tskbs[i] = NULL; /* effect: xdp_return_frame */\n\t\t\t\tkmem_alloc_drops += nframes;\n\t\t\t}\n\t\t}\n\n\t\tlocal_bh_disable();\n\t\tfor (i = 0; i < nframes; i++) {\n\t\t\tstruct xdp_frame *xdpf = frames[i];\n\t\t\tstruct sk_buff *skb = skbs[i];\n\n\t\t\tskb = __xdp_build_skb_from_frame(xdpf, skb,\n\t\t\t\t\t\t\t xdpf->dev_rx);\n\t\t\tif (!skb) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tlist_add_tail(&skb->list, &list);\n\t\t}\n\t\tnetif_receive_skb_list(&list);\n\n\t\t/* Feedback loop via tracepoint */\n\t\ttrace_xdp_cpumap_kthread(rcpu->map_id, n, kmem_alloc_drops,\n\t\t\t\t\t sched, &stats);\n\n\t\tlocal_bh_enable(); /* resched point, may call do_softirq() */\n\t}\n\t__set_current_state(TASK_RUNNING);\n\n\tput_cpu_map_entry(rcpu);\n\treturn 0;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [
      "#define CPUMAP_BATCH 8"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_cpu_map_entry",
          "args": [
            "rcpu"
          ],
          "line": 396
        },
        "resolved": true,
        "details": {
          "function_name": "put_cpu_map_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "159-170",
          "snippet": "static void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\tif (rcpu->prog)\n\t\t\tbpf_prog_put(rcpu->prog);\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\tif (rcpu->prog)\n\t\t\tbpf_prog_put(rcpu->prog);\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 394
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_bh_enable",
          "args": [],
          "line": 392
        },
        "resolved": true,
        "details": {
          "function_name": "_local_bh_enable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/softirq.c",
          "lines": "353-357",
          "snippet": "void _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}",
          "includes": [
            "#include <trace/events/irq.h>",
            "#include <asm/softirq_stack.h>",
            "#include <linux/wait_bit.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cpu.h>",
            "#include <linux/percpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/mm.h>",
            "#include <linux/local_lock.h>",
            "#include <linux/init.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/irq.h>\n#include <asm/softirq_stack.h>\n#include <linux/wait_bit.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/ftrace.h>\n#include <linux/rcupdate.h>\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n#include <linux/cpu.h>\n#include <linux/percpu.h>\n#include <linux/notifier.h>\n#include <linux/mm.h>\n#include <linux/local_lock.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel_stat.h>\n#include <linux/export.h>\n\nvoid _local_bh_enable(void)\n{\n\tWARN_ON_ONCE(in_irq());\n\t__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_xdp_cpumap_kthread",
          "args": [
            "rcpu->map_id",
            "n",
            "kmem_alloc_drops",
            "sched",
            "&stats"
          ],
          "line": 389
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "netif_receive_skb_list",
          "args": [
            "&list"
          ],
          "line": 386
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&skb->list",
            "&list"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 380
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__xdp_build_skb_from_frame",
          "args": [
            "xdpf",
            "skb",
            "xdpf->dev_rx"
          ],
          "line": 377
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_bh_disable",
          "args": [],
          "line": 372
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "m == 0"
          ],
          "line": 365
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmem_cache_alloc_bulk",
          "args": [
            "skbuff_head_cache",
            "gfp",
            "nframes",
            "skbs"
          ],
          "line": 364
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_map_bpf_prog_run",
          "args": [
            "rcpu",
            "frames",
            "xdp_n",
            "&stats",
            "&list"
          ],
          "line": 362
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_bpf_prog_run",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "273-295",
          "snippet": "static int cpu_map_bpf_prog_run(struct bpf_cpu_map_entry *rcpu, void **frames,\n\t\t\t\tint xdp_n, struct xdp_cpumap_stats *stats,\n\t\t\t\tstruct list_head *list)\n{\n\tint nframes;\n\n\tif (!rcpu->prog)\n\t\treturn xdp_n;\n\n\trcu_read_lock_bh();\n\n\tnframes = cpu_map_bpf_prog_run_xdp(rcpu, frames, xdp_n, stats);\n\n\tif (stats->redirect)\n\t\txdp_do_flush();\n\n\tif (unlikely(!list_empty(list)))\n\t\tcpu_map_bpf_prog_run_skb(rcpu, list, stats);\n\n\trcu_read_unlock_bh(); /* resched point, may call do_softirq() */\n\n\treturn nframes;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_bpf_prog_run(struct bpf_cpu_map_entry *rcpu, void **frames,\n\t\t\t\tint xdp_n, struct xdp_cpumap_stats *stats,\n\t\t\t\tstruct list_head *list)\n{\n\tint nframes;\n\n\tif (!rcpu->prog)\n\t\treturn xdp_n;\n\n\trcu_read_lock_bh();\n\n\tnframes = cpu_map_bpf_prog_run_xdp(rcpu, frames, xdp_n, stats);\n\n\tif (stats->redirect)\n\t\txdp_do_flush();\n\n\tif (unlikely(!list_empty(list)))\n\t\tcpu_map_bpf_prog_run_skb(rcpu, list, stats);\n\n\trcu_read_unlock_bh(); /* resched point, may call do_softirq() */\n\n\treturn nframes;\n}"
        }
      },
      {
        "call_info": {
          "callee": "prefetchw",
          "args": [
            "page"
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "virt_to_page",
          "args": [
            "f"
          ],
          "line": 352
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&skb->list",
            "&list"
          ],
          "line": 347
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_clear_bit",
          "args": [
            "0",
            "&skb"
          ],
          "line": 346
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "__ptr_test_bit(0, &f)"
          ],
          "line": 343
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_test_bit",
          "args": [
            "0",
            "&f"
          ],
          "line": 343
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_consume_batched",
          "args": [
            "rcpu->queue",
            "frames",
            "CPUMAP_BATCH"
          ],
          "line": 337
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 329
        },
        "resolved": true,
        "details": {
          "function_name": "__cond_resched",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "8172-8193",
          "snippet": "int __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nint __sched __cond_resched(void)\n{\n\tif (should_resched(0)) {\n\t\tpreempt_schedule_common();\n\t\treturn 1;\n\t}\n\t/*\n\t * In preemptible kernels, ->rcu_read_lock_nesting tells the tick\n\t * whether the current CPU is in an RCU read-side critical section,\n\t * so the tick can report quiescent states even for CPUs looping\n\t * in kernel context.  In contrast, in non-preemptible kernels,\n\t * RCU readers leave no in-memory hints, which means that CPU-bound\n\t * processes executing in kernel context might never report an\n\t * RCU quiescent state.  Therefore, the following code causes\n\t * cond_resched() to report a quiescent state, but only when RCU\n\t * is in urgent need of one.\n\t */\n#ifndef CONFIG_PREEMPT_RCU\n\trcu_all_qs();\n#endif\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__set_current_state",
          "args": [
            "TASK_RUNNING"
          ],
          "line": 326
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule",
          "args": [],
          "line": 323
        },
        "resolved": true,
        "details": {
          "function_name": "audit_schedule_prune",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/audit_tree.c",
          "lines": "963-966",
          "snippet": "static void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}",
          "includes": [
            "#include <linux/slab.h>",
            "#include <linux/refcount.h>",
            "#include <linux/kthread.h>",
            "#include <linux/mount.h>",
            "#include <linux/namei.h>",
            "#include <linux/fsnotify_backend.h>",
            "#include \"audit.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static struct task_struct *prune_thread;",
            "static void audit_schedule_prune(void);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/slab.h>\n#include <linux/refcount.h>\n#include <linux/kthread.h>\n#include <linux/mount.h>\n#include <linux/namei.h>\n#include <linux/fsnotify_backend.h>\n#include \"audit.h\"\n\nstatic struct task_struct *prune_thread;\nstatic void audit_schedule_prune(void);\n\nstatic void audit_schedule_prune(void)\n{\n\twake_up_process(prune_thread);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__ptr_ring_empty",
          "args": [
            "rcpu->queue"
          ],
          "line": 322
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "TASK_INTERRUPTIBLE"
          ],
          "line": 320
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_empty",
          "args": [
            "rcpu->queue"
          ],
          "line": 319
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "LIST_HEAD",
          "args": [
            "list"
          ],
          "line": 316
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__ptr_ring_empty",
          "args": [
            "rcpu->queue"
          ],
          "line": 309
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_should_stop",
          "args": [],
          "line": 309
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_should_stop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "156-159",
          "snippet": "bool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nbool kthread_should_stop(void)\n{\n\treturn test_bit(KTHREAD_SHOULD_STOP, &to_kthread(current)->flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_current_state",
          "args": [
            "TASK_INTERRUPTIBLE"
          ],
          "line": 302
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\n#define CPUMAP_BATCH 8\n\nstatic int cpu_map_kthread_run(void *data)\n{\n\tstruct bpf_cpu_map_entry *rcpu = data;\n\n\tset_current_state(TASK_INTERRUPTIBLE);\n\n\t/* When kthread gives stop order, then rcpu have been disconnected\n\t * from map, thus no new packets can enter. Remaining in-flight\n\t * per CPU stored packets are flushed to this queue.  Wait honoring\n\t * kthread_stop signal until queue is empty.\n\t */\n\twhile (!kthread_should_stop() || !__ptr_ring_empty(rcpu->queue)) {\n\t\tstruct xdp_cpumap_stats stats = {}; /* zero stats */\n\t\tunsigned int kmem_alloc_drops = 0, sched = 0;\n\t\tgfp_t gfp = __GFP_ZERO | GFP_ATOMIC;\n\t\tint i, n, m, nframes, xdp_n;\n\t\tvoid *frames[CPUMAP_BATCH];\n\t\tvoid *skbs[CPUMAP_BATCH];\n\t\tLIST_HEAD(list);\n\n\t\t/* Release CPU reschedule checks */\n\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\t/* Recheck to avoid lost wake-up */\n\t\t\tif (__ptr_ring_empty(rcpu->queue)) {\n\t\t\t\tschedule();\n\t\t\t\tsched = 1;\n\t\t\t} else {\n\t\t\t\t__set_current_state(TASK_RUNNING);\n\t\t\t}\n\t\t} else {\n\t\t\tsched = cond_resched();\n\t\t}\n\n\t\t/*\n\t\t * The bpf_cpu_map_entry is single consumer, with this\n\t\t * kthread CPU pinned. Lockless access to ptr_ring\n\t\t * consume side valid as no-resize allowed of queue.\n\t\t */\n\t\tn = __ptr_ring_consume_batched(rcpu->queue, frames,\n\t\t\t\t\t       CPUMAP_BATCH);\n\t\tfor (i = 0, xdp_n = 0; i < n; i++) {\n\t\t\tvoid *f = frames[i];\n\t\t\tstruct page *page;\n\n\t\t\tif (unlikely(__ptr_test_bit(0, &f))) {\n\t\t\t\tstruct sk_buff *skb = f;\n\n\t\t\t\t__ptr_clear_bit(0, &skb);\n\t\t\t\tlist_add_tail(&skb->list, &list);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tframes[xdp_n++] = f;\n\t\t\tpage = virt_to_page(f);\n\n\t\t\t/* Bring struct page memory area to curr CPU. Read by\n\t\t\t * build_skb_around via page_is_pfmemalloc(), and when\n\t\t\t * freed written by page_frag_free call.\n\t\t\t */\n\t\t\tprefetchw(page);\n\t\t}\n\n\t\t/* Support running another XDP prog on this CPU */\n\t\tnframes = cpu_map_bpf_prog_run(rcpu, frames, xdp_n, &stats, &list);\n\t\tif (nframes) {\n\t\t\tm = kmem_cache_alloc_bulk(skbuff_head_cache, gfp, nframes, skbs);\n\t\t\tif (unlikely(m == 0)) {\n\t\t\t\tfor (i = 0; i < nframes; i++)\n\t\t\t\t\tskbs[i] = NULL; /* effect: xdp_return_frame */\n\t\t\t\tkmem_alloc_drops += nframes;\n\t\t\t}\n\t\t}\n\n\t\tlocal_bh_disable();\n\t\tfor (i = 0; i < nframes; i++) {\n\t\t\tstruct xdp_frame *xdpf = frames[i];\n\t\t\tstruct sk_buff *skb = skbs[i];\n\n\t\t\tskb = __xdp_build_skb_from_frame(xdpf, skb,\n\t\t\t\t\t\t\t xdpf->dev_rx);\n\t\t\tif (!skb) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tlist_add_tail(&skb->list, &list);\n\t\t}\n\t\tnetif_receive_skb_list(&list);\n\n\t\t/* Feedback loop via tracepoint */\n\t\ttrace_xdp_cpumap_kthread(rcpu->map_id, n, kmem_alloc_drops,\n\t\t\t\t\t sched, &stats);\n\n\t\tlocal_bh_enable(); /* resched point, may call do_softirq() */\n\t}\n\t__set_current_state(TASK_RUNNING);\n\n\tput_cpu_map_entry(rcpu);\n\treturn 0;\n}"
  },
  {
    "function_name": "cpu_map_bpf_prog_run",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "273-295",
    "snippet": "static int cpu_map_bpf_prog_run(struct bpf_cpu_map_entry *rcpu, void **frames,\n\t\t\t\tint xdp_n, struct xdp_cpumap_stats *stats,\n\t\t\t\tstruct list_head *list)\n{\n\tint nframes;\n\n\tif (!rcpu->prog)\n\t\treturn xdp_n;\n\n\trcu_read_lock_bh();\n\n\tnframes = cpu_map_bpf_prog_run_xdp(rcpu, frames, xdp_n, stats);\n\n\tif (stats->redirect)\n\t\txdp_do_flush();\n\n\tif (unlikely(!list_empty(list)))\n\t\tcpu_map_bpf_prog_run_skb(rcpu, list, stats);\n\n\trcu_read_unlock_bh(); /* resched point, may call do_softirq() */\n\n\treturn nframes;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_read_unlock_bh",
          "args": [],
          "line": 292
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_map_bpf_prog_run_skb",
          "args": [
            "rcpu",
            "list",
            "stats"
          ],
          "line": 290
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_bpf_prog_run_skb",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "172-210",
          "snippet": "static void cpu_map_bpf_prog_run_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t     struct list_head *listp,\n\t\t\t\t     struct xdp_cpumap_stats *stats)\n{\n\tstruct sk_buff *skb, *tmp;\n\tstruct xdp_buff xdp;\n\tu32 act;\n\tint err;\n\n\tlist_for_each_entry_safe(skb, tmp, listp, list) {\n\t\tact = bpf_prog_run_generic_xdp(skb, &xdp, rcpu->prog);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\tskb_list_del_init(skb);\n\t\t\terr = xdp_do_generic_redirect(skb->dev, skb, &xdp,\n\t\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\treturn;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_ABORTED:\n\t\t\ttrace_xdp_exception(skb->dev, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\tskb_list_del_init(skb);\n\t\t\tkfree_skb(skb);\n\t\t\tstats->drop++;\n\t\t\treturn;\n\t\t}\n\t}\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void cpu_map_bpf_prog_run_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t     struct list_head *listp,\n\t\t\t\t     struct xdp_cpumap_stats *stats)\n{\n\tstruct sk_buff *skb, *tmp;\n\tstruct xdp_buff xdp;\n\tu32 act;\n\tint err;\n\n\tlist_for_each_entry_safe(skb, tmp, listp, list) {\n\t\tact = bpf_prog_run_generic_xdp(skb, &xdp, rcpu->prog);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\tskb_list_del_init(skb);\n\t\t\terr = xdp_do_generic_redirect(skb->dev, skb, &xdp,\n\t\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\treturn;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_ABORTED:\n\t\t\ttrace_xdp_exception(skb->dev, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\tskb_list_del_init(skb);\n\t\t\tkfree_skb(skb);\n\t\t\tstats->drop++;\n\t\t\treturn;\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!list_empty(list)"
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "list"
          ],
          "line": 289
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xdp_do_flush",
          "args": [],
          "line": 287
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_map_bpf_prog_run_xdp",
          "args": [
            "rcpu",
            "frames",
            "xdp_n",
            "stats"
          ],
          "line": 284
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_bpf_prog_run_xdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "212-269",
          "snippet": "static int cpu_map_bpf_prog_run_xdp(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t    void **frames, int n,\n\t\t\t\t    struct xdp_cpumap_stats *stats)\n{\n\tstruct xdp_rxq_info rxq;\n\tstruct xdp_buff xdp;\n\tint i, nframes = 0;\n\n\txdp_set_return_frame_no_direct();\n\txdp.rxq = &rxq;\n\n\tfor (i = 0; i < n; i++) {\n\t\tstruct xdp_frame *xdpf = frames[i];\n\t\tu32 act;\n\t\tint err;\n\n\t\trxq.dev = xdpf->dev_rx;\n\t\trxq.mem = xdpf->mem;\n\t\t/* TODO: report queue_index to xdp_rxq_info */\n\n\t\txdp_convert_frame_to_buff(xdpf, &xdp);\n\n\t\tact = bpf_prog_run_xdp(rcpu->prog, &xdp);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\terr = xdp_update_frame_from_buff(&xdp, xdpf);\n\t\t\tif (err < 0) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tframes[nframes++] = xdpf;\n\t\t\t\tstats->pass++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\terr = xdp_do_redirect(xdpf->dev_rx, &xdp,\n\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\txdp_return_frame(xdpf);\n\t\t\tstats->drop++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\txdp_clear_return_frame_no_direct();\n\n\treturn nframes;\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_bpf_prog_run_xdp(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t    void **frames, int n,\n\t\t\t\t    struct xdp_cpumap_stats *stats)\n{\n\tstruct xdp_rxq_info rxq;\n\tstruct xdp_buff xdp;\n\tint i, nframes = 0;\n\n\txdp_set_return_frame_no_direct();\n\txdp.rxq = &rxq;\n\n\tfor (i = 0; i < n; i++) {\n\t\tstruct xdp_frame *xdpf = frames[i];\n\t\tu32 act;\n\t\tint err;\n\n\t\trxq.dev = xdpf->dev_rx;\n\t\trxq.mem = xdpf->mem;\n\t\t/* TODO: report queue_index to xdp_rxq_info */\n\n\t\txdp_convert_frame_to_buff(xdpf, &xdp);\n\n\t\tact = bpf_prog_run_xdp(rcpu->prog, &xdp);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\terr = xdp_update_frame_from_buff(&xdp, xdpf);\n\t\t\tif (err < 0) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tframes[nframes++] = xdpf;\n\t\t\t\tstats->pass++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\terr = xdp_do_redirect(xdpf->dev_rx, &xdp,\n\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\txdp_return_frame(xdpf);\n\t\t\tstats->drop++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\txdp_clear_return_frame_no_direct();\n\n\treturn nframes;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_bh",
          "args": [],
          "line": 282
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_bh_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "330-337",
          "snippet": "int rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_bh_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn in_softirq() || irqs_disabled();\n}"
        }
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_bpf_prog_run(struct bpf_cpu_map_entry *rcpu, void **frames,\n\t\t\t\tint xdp_n, struct xdp_cpumap_stats *stats,\n\t\t\t\tstruct list_head *list)\n{\n\tint nframes;\n\n\tif (!rcpu->prog)\n\t\treturn xdp_n;\n\n\trcu_read_lock_bh();\n\n\tnframes = cpu_map_bpf_prog_run_xdp(rcpu, frames, xdp_n, stats);\n\n\tif (stats->redirect)\n\t\txdp_do_flush();\n\n\tif (unlikely(!list_empty(list)))\n\t\tcpu_map_bpf_prog_run_skb(rcpu, list, stats);\n\n\trcu_read_unlock_bh(); /* resched point, may call do_softirq() */\n\n\treturn nframes;\n}"
  },
  {
    "function_name": "cpu_map_bpf_prog_run_xdp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "212-269",
    "snippet": "static int cpu_map_bpf_prog_run_xdp(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t    void **frames, int n,\n\t\t\t\t    struct xdp_cpumap_stats *stats)\n{\n\tstruct xdp_rxq_info rxq;\n\tstruct xdp_buff xdp;\n\tint i, nframes = 0;\n\n\txdp_set_return_frame_no_direct();\n\txdp.rxq = &rxq;\n\n\tfor (i = 0; i < n; i++) {\n\t\tstruct xdp_frame *xdpf = frames[i];\n\t\tu32 act;\n\t\tint err;\n\n\t\trxq.dev = xdpf->dev_rx;\n\t\trxq.mem = xdpf->mem;\n\t\t/* TODO: report queue_index to xdp_rxq_info */\n\n\t\txdp_convert_frame_to_buff(xdpf, &xdp);\n\n\t\tact = bpf_prog_run_xdp(rcpu->prog, &xdp);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\terr = xdp_update_frame_from_buff(&xdp, xdpf);\n\t\t\tif (err < 0) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tframes[nframes++] = xdpf;\n\t\t\t\tstats->pass++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\terr = xdp_do_redirect(xdpf->dev_rx, &xdp,\n\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\txdp_return_frame(xdpf);\n\t\t\tstats->drop++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\txdp_clear_return_frame_no_direct();\n\n\treturn nframes;\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "xdp_clear_return_frame_no_direct",
          "args": [],
          "line": 266
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 260
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_warn_invalid_xdp_action",
          "args": [
            "NULL",
            "rcpu->prog",
            "act"
          ],
          "line": 257
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 250
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err"
          ],
          "line": 249
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_do_redirect",
          "args": [
            "xdpf->dev_rx",
            "&xdp",
            "rcpu->prog"
          ],
          "line": 247
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 239
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_update_frame_from_buff",
          "args": [
            "&xdp",
            "xdpf"
          ],
          "line": 237
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_run_xdp",
          "args": [
            "rcpu->prog",
            "&xdp"
          ],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_convert_frame_to_buff",
          "args": [
            "xdpf",
            "&xdp"
          ],
          "line": 232
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_set_return_frame_no_direct",
          "args": [],
          "line": 220
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic int cpu_map_bpf_prog_run_xdp(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t    void **frames, int n,\n\t\t\t\t    struct xdp_cpumap_stats *stats)\n{\n\tstruct xdp_rxq_info rxq;\n\tstruct xdp_buff xdp;\n\tint i, nframes = 0;\n\n\txdp_set_return_frame_no_direct();\n\txdp.rxq = &rxq;\n\n\tfor (i = 0; i < n; i++) {\n\t\tstruct xdp_frame *xdpf = frames[i];\n\t\tu32 act;\n\t\tint err;\n\n\t\trxq.dev = xdpf->dev_rx;\n\t\trxq.mem = xdpf->mem;\n\t\t/* TODO: report queue_index to xdp_rxq_info */\n\n\t\txdp_convert_frame_to_buff(xdpf, &xdp);\n\n\t\tact = bpf_prog_run_xdp(rcpu->prog, &xdp);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\terr = xdp_update_frame_from_buff(&xdp, xdpf);\n\t\t\tif (err < 0) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tframes[nframes++] = xdpf;\n\t\t\t\tstats->pass++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\terr = xdp_do_redirect(xdpf->dev_rx, &xdp,\n\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\txdp_return_frame(xdpf);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\txdp_return_frame(xdpf);\n\t\t\tstats->drop++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\txdp_clear_return_frame_no_direct();\n\n\treturn nframes;\n}"
  },
  {
    "function_name": "cpu_map_bpf_prog_run_skb",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "172-210",
    "snippet": "static void cpu_map_bpf_prog_run_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t     struct list_head *listp,\n\t\t\t\t     struct xdp_cpumap_stats *stats)\n{\n\tstruct sk_buff *skb, *tmp;\n\tstruct xdp_buff xdp;\n\tu32 act;\n\tint err;\n\n\tlist_for_each_entry_safe(skb, tmp, listp, list) {\n\t\tact = bpf_prog_run_generic_xdp(skb, &xdp, rcpu->prog);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\tskb_list_del_init(skb);\n\t\t\terr = xdp_do_generic_redirect(skb->dev, skb, &xdp,\n\t\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\treturn;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_ABORTED:\n\t\t\ttrace_xdp_exception(skb->dev, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\tskb_list_del_init(skb);\n\t\t\tkfree_skb(skb);\n\t\t\tstats->drop++;\n\t\t\treturn;\n\t\t}\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree_skb",
          "args": [
            "skb"
          ],
          "line": 205
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "skb_list_del_init",
          "args": [
            "skb"
          ],
          "line": 204
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_xdp_exception",
          "args": [
            "skb->dev",
            "rcpu->prog",
            "act"
          ],
          "line": 201
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_warn_invalid_xdp_action",
          "args": [
            "NULL",
            "rcpu->prog",
            "act"
          ],
          "line": 198
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree_skb",
          "args": [
            "skb"
          ],
          "line": 191
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err"
          ],
          "line": 190
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "xdp_do_generic_redirect",
          "args": [
            "skb->dev",
            "skb",
            "&xdp",
            "rcpu->prog"
          ],
          "line": 188
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "skb_list_del_init",
          "args": [
            "skb"
          ],
          "line": 187
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_prog_run_generic_xdp",
          "args": [
            "skb",
            "&xdp",
            "rcpu->prog"
          ],
          "line": 182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_for_each_entry_safe",
          "args": [
            "skb",
            "tmp",
            "listp",
            "list"
          ],
          "line": 181
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void cpu_map_bpf_prog_run_skb(struct bpf_cpu_map_entry *rcpu,\n\t\t\t\t     struct list_head *listp,\n\t\t\t\t     struct xdp_cpumap_stats *stats)\n{\n\tstruct sk_buff *skb, *tmp;\n\tstruct xdp_buff xdp;\n\tu32 act;\n\tint err;\n\n\tlist_for_each_entry_safe(skb, tmp, listp, list) {\n\t\tact = bpf_prog_run_generic_xdp(skb, &xdp, rcpu->prog);\n\t\tswitch (act) {\n\t\tcase XDP_PASS:\n\t\t\tbreak;\n\t\tcase XDP_REDIRECT:\n\t\t\tskb_list_del_init(skb);\n\t\t\terr = xdp_do_generic_redirect(skb->dev, skb, &xdp,\n\t\t\t\t\t\t      rcpu->prog);\n\t\t\tif (unlikely(err)) {\n\t\t\t\tkfree_skb(skb);\n\t\t\t\tstats->drop++;\n\t\t\t} else {\n\t\t\t\tstats->redirect++;\n\t\t\t}\n\t\t\treturn;\n\t\tdefault:\n\t\t\tbpf_warn_invalid_xdp_action(NULL, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_ABORTED:\n\t\t\ttrace_xdp_exception(skb->dev, rcpu->prog, act);\n\t\t\tfallthrough;\n\t\tcase XDP_DROP:\n\t\t\tskb_list_del_init(skb);\n\t\t\tkfree_skb(skb);\n\t\t\tstats->drop++;\n\t\t\treturn;\n\t\t}\n\t}\n}"
  },
  {
    "function_name": "put_cpu_map_entry",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "159-170",
    "snippet": "static void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\tif (rcpu->prog)\n\t\t\tbpf_prog_put(rcpu->prog);\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "rcpu"
          ],
          "line": 168
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "ptr_ring_cleanup",
          "args": [
            "rcpu->queue",
            "NULL"
          ],
          "line": 166
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__cpu_map_ring_cleanup",
          "args": [
            "rcpu->queue"
          ],
          "line": 165
        },
        "resolved": true,
        "details": {
          "function_name": "__cpu_map_ring_cleanup",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "145-157",
          "snippet": "static void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}",
          "includes": [
            "#include <linux/etherdevice.h> /* eth_type_trans */",
            "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
            "#include <trace/events/xdp.h>",
            "#include <linux/capability.h>",
            "#include <linux/kthread.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/sched.h>",
            "#include <net/xdp.h>",
            "#include <linux/ptr_ring.h>",
            "#include <linux/filter.h>",
            "#include <linux/bpf.h>",
            "#include <linux/bitops.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_prog_put",
          "args": [
            "rcpu->prog"
          ],
          "line": 163
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_prog_put",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "1828-1831",
          "snippet": "void bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_prog_put(struct bpf_prog *prog)\n{\n\t__bpf_prog_put(prog, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "atomic_dec_and_test",
          "args": [
            "&rcpu->refcnt"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void put_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tif (atomic_dec_and_test(&rcpu->refcnt)) {\n\t\tif (rcpu->prog)\n\t\t\tbpf_prog_put(rcpu->prog);\n\t\t/* The queue should be empty at this point */\n\t\t__cpu_map_ring_cleanup(rcpu->queue);\n\t\tptr_ring_cleanup(rcpu->queue, NULL);\n\t\tkfree(rcpu->queue);\n\t\tkfree(rcpu);\n\t}\n}"
  },
  {
    "function_name": "__cpu_map_ring_cleanup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "145-157",
    "snippet": "static void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "xdp_return_frame",
          "args": [
            "xdpf"
          ],
          "line": 156
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "xdpf"
          ],
          "line": 155
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ptr_ring_consume",
          "args": [
            "ring"
          ],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void __cpu_map_ring_cleanup(struct ptr_ring *ring)\n{\n\t/* The tear-down procedure should have made sure that queue is\n\t * empty.  See __cpu_map_entry_replace() and work-queue\n\t * invoked cpu_map_kthread_stop(). Catch any broken behaviour\n\t * gracefully and warn once.\n\t */\n\tstruct xdp_frame *xdpf;\n\n\twhile ((xdpf = ptr_ring_consume(ring)))\n\t\tif (WARN_ON_ONCE(xdpf))\n\t\t\txdp_return_frame(xdpf);\n}"
  },
  {
    "function_name": "cpu_map_kthread_stop",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "130-143",
    "snippet": "static void cpu_map_kthread_stop(struct work_struct *work)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\trcpu = container_of(work, struct bpf_cpu_map_entry, kthread_stop_wq);\n\n\t/* Wait for flush in __cpu_map_entry_free(), via full RCU barrier,\n\t * as it waits until all in-flight call_rcu() callbacks complete.\n\t */\n\trcu_barrier();\n\n\t/* kthread_stop will wake_up_process and wait for it to complete */\n\tkthread_stop(rcpu->kthread);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "kthread_stop",
          "args": [
            "rcpu->kthread"
          ],
          "line": 142
        },
        "resolved": true,
        "details": {
          "function_name": "cpu_map_kthread_stop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
          "lines": "130-143",
          "snippet": "static void cpu_map_kthread_stop(struct work_struct *work)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\trcpu = container_of(work, struct bpf_cpu_map_entry, kthread_stop_wq);\n\n\t/* Wait for flush in __cpu_map_entry_free(), via full RCU barrier,\n\t * as it waits until all in-flight call_rcu() callbacks complete.\n\t */\n\trcu_barrier();\n\n\t/* kthread_stop will wake_up_process and wait for it to complete */\n\tkthread_stop(rcpu->kthread);\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "rcu_barrier",
          "args": [],
          "line": 139
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1569-1572",
          "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "work",
            "structbpf_cpu_map_entry",
            "kthread_stop_wq"
          ],
          "line": 134
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void cpu_map_kthread_stop(struct work_struct *work)\n{\n\tstruct bpf_cpu_map_entry *rcpu;\n\n\trcpu = container_of(work, struct bpf_cpu_map_entry, kthread_stop_wq);\n\n\t/* Wait for flush in __cpu_map_entry_free(), via full RCU barrier,\n\t * as it waits until all in-flight call_rcu() callbacks complete.\n\t */\n\trcu_barrier();\n\n\t/* kthread_stop will wake_up_process and wait for it to complete */\n\tkthread_stop(rcpu->kthread);\n}"
  },
  {
    "function_name": "get_cpu_map_entry",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "124-127",
    "snippet": "static void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "atomic_inc",
          "args": [
            "&rcpu->refcnt"
          ],
          "line": 126
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic void get_cpu_map_entry(struct bpf_cpu_map_entry *rcpu)\n{\n\tatomic_inc(&rcpu->refcnt);\n}"
  },
  {
    "function_name": "cpu_map_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/cpumap.c",
    "lines": "83-122",
    "snippet": "static struct bpf_map *cpu_map_alloc(union bpf_attr *attr)\n{\n\tu32 value_size = attr->value_size;\n\tstruct bpf_cpu_map *cmap;\n\tint err = -ENOMEM;\n\n\tif (!bpf_capable())\n\t\treturn ERR_PTR(-EPERM);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    (value_size != offsetofend(struct bpf_cpumap_val, qsize) &&\n\t     value_size != offsetofend(struct bpf_cpumap_val, bpf_prog.fd)) ||\n\t    attr->map_flags & ~BPF_F_NUMA_NODE)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcmap = kzalloc(sizeof(*cmap), GFP_USER | __GFP_ACCOUNT);\n\tif (!cmap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&cmap->map, attr);\n\n\t/* Pre-limit array size based on NR_CPUS, not final CPU check */\n\tif (cmap->map.max_entries > NR_CPUS) {\n\t\terr = -E2BIG;\n\t\tgoto free_cmap;\n\t}\n\n\t/* Alloc array for possible remote \"destination\" CPUs */\n\tcmap->cpu_map = bpf_map_area_alloc(cmap->map.max_entries *\n\t\t\t\t\t   sizeof(struct bpf_cpu_map_entry *),\n\t\t\t\t\t   cmap->map.numa_node);\n\tif (!cmap->cpu_map)\n\t\tgoto free_cmap;\n\n\treturn &cmap->map;\nfree_cmap:\n\tkfree(cmap);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include <linux/etherdevice.h> /* eth_type_trans */",
      "#include <linux/netdevice.h>   /* netif_receive_skb_list */",
      "#include <trace/events/xdp.h>",
      "#include <linux/capability.h>",
      "#include <linux/kthread.h>",
      "#include <linux/workqueue.h>",
      "#include <linux/sched.h>",
      "#include <net/xdp.h>",
      "#include <linux/ptr_ring.h>",
      "#include <linux/filter.h>",
      "#include <linux/bpf.h>",
      "#include <linux/bitops.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 121
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kfree",
          "args": [
            "cmap"
          ],
          "line": 120
        },
        "resolved": true,
        "details": {
          "function_name": "maybe_kfree_parameter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/params.c",
          "lines": "62-75",
          "snippet": "static void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}",
          "includes": [
            "#include <linux/security.h>",
            "#include <linux/ctype.h>",
            "#include <linux/slab.h>",
            "#include <linux/err.h>",
            "#include <linux/device.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/module.h>",
            "#include <linux/errno.h>",
            "#include <linux/string.h>",
            "#include <linux/kernel.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static LIST_HEAD(kmalloced_params);",
            "static DEFINE_SPINLOCK(kmalloced_params_lock);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/security.h>\n#include <linux/ctype.h>\n#include <linux/slab.h>\n#include <linux/err.h>\n#include <linux/device.h>\n#include <linux/moduleparam.h>\n#include <linux/module.h>\n#include <linux/errno.h>\n#include <linux/string.h>\n#include <linux/kernel.h>\n\nstatic LIST_HEAD(kmalloced_params);\nstatic DEFINE_SPINLOCK(kmalloced_params_lock);\n\nstatic void maybe_kfree_parameter(void *param)\n{\n\tstruct kmalloced_param *p;\n\n\tspin_lock(&kmalloced_params_lock);\n\tlist_for_each_entry(p, &kmalloced_params, list) {\n\t\tif (p->val == param) {\n\t\t\tlist_del(&p->list);\n\t\t\tkfree(p);\n\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&kmalloced_params_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "cmap->map.max_entries *\n\t\t\t\t\t   sizeof(struct bpf_cpu_map_entry *)",
            "cmap->map.numa_node"
          ],
          "line": 112
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "334-337",
          "snippet": "void *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&cmap->map",
            "attr"
          ],
          "line": 103
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "361-370",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kzalloc",
          "args": [
            "sizeof(*cmap)",
            "GFP_USER | __GFP_ACCOUNT"
          ],
          "line": 99
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 97
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "offsetofend",
          "args": [
            "structbpf_cpumap_val",
            "bpf_prog.fd"
          ],
          "line": 95
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "offsetofend",
          "args": [
            "structbpf_cpumap_val",
            "qsize"
          ],
          "line": 94
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 90
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_capable",
          "args": [],
          "line": 89
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include <linux/etherdevice.h> /* eth_type_trans */\n#include <linux/netdevice.h>   /* netif_receive_skb_list */\n#include <trace/events/xdp.h>\n#include <linux/capability.h>\n#include <linux/kthread.h>\n#include <linux/workqueue.h>\n#include <linux/sched.h>\n#include <net/xdp.h>\n#include <linux/ptr_ring.h>\n#include <linux/filter.h>\n#include <linux/bpf.h>\n#include <linux/bitops.h>\n\nstatic struct bpf_map *cpu_map_alloc(union bpf_attr *attr)\n{\n\tu32 value_size = attr->value_size;\n\tstruct bpf_cpu_map *cmap;\n\tint err = -ENOMEM;\n\n\tif (!bpf_capable())\n\t\treturn ERR_PTR(-EPERM);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    (value_size != offsetofend(struct bpf_cpumap_val, qsize) &&\n\t     value_size != offsetofend(struct bpf_cpumap_val, bpf_prog.fd)) ||\n\t    attr->map_flags & ~BPF_F_NUMA_NODE)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tcmap = kzalloc(sizeof(*cmap), GFP_USER | __GFP_ACCOUNT);\n\tif (!cmap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&cmap->map, attr);\n\n\t/* Pre-limit array size based on NR_CPUS, not final CPU check */\n\tif (cmap->map.max_entries > NR_CPUS) {\n\t\terr = -E2BIG;\n\t\tgoto free_cmap;\n\t}\n\n\t/* Alloc array for possible remote \"destination\" CPUs */\n\tcmap->cpu_map = bpf_map_area_alloc(cmap->map.max_entries *\n\t\t\t\t\t   sizeof(struct bpf_cpu_map_entry *),\n\t\t\t\t\t   cmap->map.numa_node);\n\tif (!cmap->cpu_map)\n\t\tgoto free_cmap;\n\n\treturn &cmap->map;\nfree_cmap:\n\tkfree(cmap);\n\treturn ERR_PTR(err);\n}"
  }
]