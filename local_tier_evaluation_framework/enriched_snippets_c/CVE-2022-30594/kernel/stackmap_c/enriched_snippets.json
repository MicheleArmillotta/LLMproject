[
  {
    "function_name": "stack_map_free",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "646-654",
    "snippet": "static void stack_map_free(struct bpf_map *map)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\n\tbpf_map_area_free(smap->elems);\n\tpcpu_freelist_destroy(&smap->freelist);\n\tbpf_map_area_free(smap);\n\tput_callchain_buffers();\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_callchain_buffers",
          "args": [],
          "line": 653
        },
        "resolved": true,
        "details": {
          "function_name": "put_callchain_buffers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/callchain.c",
          "lines": "144-150",
          "snippet": "void put_callchain_buffers(void)\n{\n\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {\n\t\trelease_callchain_buffers();\n\t\tmutex_unlock(&callchain_mutex);\n\t}\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/slab.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static atomic_t nr_callchain_events;",
            "static DEFINE_MUTEX(callchain_mutex);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/sched/task_stack.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n\nstatic atomic_t nr_callchain_events;\nstatic DEFINE_MUTEX(callchain_mutex);\n\nvoid put_callchain_buffers(void)\n{\n\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {\n\t\trelease_callchain_buffers();\n\t\tmutex_unlock(&callchain_mutex);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "smap"
          ],
          "line": 652
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_destroy",
          "args": [
            "&smap->freelist"
          ],
          "line": 651
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_destroy",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "25-28",
          "snippet": "void pcpu_freelist_destroy(struct pcpu_freelist *s)\n{\n\tfree_percpu(s->freelist);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_destroy(struct pcpu_freelist *s)\n{\n\tfree_percpu(s->freelist);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_stack_map",
            "map"
          ],
          "line": 648
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic void stack_map_free(struct bpf_map *map)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\n\tbpf_map_area_free(smap->elems);\n\tpcpu_freelist_destroy(&smap->freelist);\n\tbpf_map_area_free(smap);\n\tput_callchain_buffers();\n}"
  },
  {
    "function_name": "stack_map_delete_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "627-643",
    "snippet": "static int stack_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\tstruct stack_map_bucket *old_bucket;\n\tu32 id = *(u32 *)key;\n\n\tif (unlikely(id >= smap->n_buckets))\n\t\treturn -E2BIG;\n\n\told_bucket = xchg(&smap->buckets[id], NULL);\n\tif (old_bucket) {\n\t\tpcpu_freelist_push(&smap->freelist, &old_bucket->fnode);\n\t\treturn 0;\n\t} else {\n\t\treturn -ENOENT;\n\t}\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pcpu_freelist_push",
          "args": [
            "&smap->freelist",
            "&old_bucket->fnode"
          ],
          "line": 638
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_push",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "91-99",
          "snippet": "void pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__pcpu_freelist_push(s, node);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__pcpu_freelist_push(s, node);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&smap->buckets[id]",
            "NULL"
          ],
          "line": 636
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/qspinlock.c",
          "lines": "220-238",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "id >= smap->n_buckets"
          ],
          "line": 633
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_stack_map",
            "map"
          ],
          "line": 629
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic int stack_map_delete_elem(struct bpf_map *map, void *key)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\tstruct stack_map_bucket *old_bucket;\n\tu32 id = *(u32 *)key;\n\n\tif (unlikely(id >= smap->n_buckets))\n\t\treturn -E2BIG;\n\n\told_bucket = xchg(&smap->buckets[id], NULL);\n\tif (old_bucket) {\n\t\tpcpu_freelist_push(&smap->freelist, &old_bucket->fnode);\n\t\treturn 0;\n\t} else {\n\t\treturn -ENOENT;\n\t}\n}"
  },
  {
    "function_name": "stack_map_update_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "620-624",
    "snippet": "static int stack_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\t u64 map_flags)\n{\n\treturn -EINVAL;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic int stack_map_update_elem(struct bpf_map *map, void *key, void *value,\n\t\t\t\t u64 map_flags)\n{\n\treturn -EINVAL;\n}"
  },
  {
    "function_name": "stack_map_get_next_key",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "591-618",
    "snippet": "static int stack_map_get_next_key(struct bpf_map *map, void *key,\n\t\t\t\t  void *next_key)\n{\n\tstruct bpf_stack_map *smap = container_of(map,\n\t\t\t\t\t\t  struct bpf_stack_map, map);\n\tu32 id;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\n\tif (!key) {\n\t\tid = 0;\n\t} else {\n\t\tid = *(u32 *)key;\n\t\tif (id >= smap->n_buckets || !smap->buckets[id])\n\t\t\tid = 0;\n\t\telse\n\t\t\tid++;\n\t}\n\n\twhile (id < smap->n_buckets && !smap->buckets[id])\n\t\tid++;\n\n\tif (id >= smap->n_buckets)\n\t\treturn -ENOENT;\n\n\t*(u32 *)next_key = id;\n\treturn 0;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_read_lock_held()"
          ],
          "line": 598
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_lock_held",
          "args": [],
          "line": 598
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_lock_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "305-312",
          "snippet": "int rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nint rcu_read_lock_held(void)\n{\n\tbool ret;\n\n\tif (rcu_read_lock_held_common(&ret))\n\t\treturn ret;\n\treturn lock_is_held(&rcu_lock_map);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_stack_map",
            "map"
          ],
          "line": 594
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic int stack_map_get_next_key(struct bpf_map *map, void *key,\n\t\t\t\t  void *next_key)\n{\n\tstruct bpf_stack_map *smap = container_of(map,\n\t\t\t\t\t\t  struct bpf_stack_map, map);\n\tu32 id;\n\n\tWARN_ON_ONCE(!rcu_read_lock_held());\n\n\tif (!key) {\n\t\tid = 0;\n\t} else {\n\t\tid = *(u32 *)key;\n\t\tif (id >= smap->n_buckets || !smap->buckets[id])\n\t\t\tid = 0;\n\t\telse\n\t\t\tid++;\n\t}\n\n\twhile (id < smap->n_buckets && !smap->buckets[id])\n\t\tid++;\n\n\tif (id >= smap->n_buckets)\n\t\treturn -ENOENT;\n\n\t*(u32 *)next_key = id;\n\treturn 0;\n}"
  },
  {
    "function_name": "bpf_stackmap_copy",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "568-589",
    "snippet": "int bpf_stackmap_copy(struct bpf_map *map, void *key, void *value)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\tstruct stack_map_bucket *bucket, *old_bucket;\n\tu32 id = *(u32 *)key, trace_len;\n\n\tif (unlikely(id >= smap->n_buckets))\n\t\treturn -ENOENT;\n\n\tbucket = xchg(&smap->buckets[id], NULL);\n\tif (!bucket)\n\t\treturn -ENOENT;\n\n\ttrace_len = bucket->nr * stack_map_data_size(map);\n\tmemcpy(value, bucket->data, trace_len);\n\tmemset(value + trace_len, 0, map->value_size - trace_len);\n\n\told_bucket = xchg(&smap->buckets[id], bucket);\n\tif (old_bucket)\n\t\tpcpu_freelist_push(&smap->freelist, &old_bucket->fnode);\n\treturn 0;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pcpu_freelist_push",
          "args": [
            "&smap->freelist",
            "&old_bucket->fnode"
          ],
          "line": 587
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_push",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "91-99",
          "snippet": "void pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__pcpu_freelist_push(s, node);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__pcpu_freelist_push(s, node);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&smap->buckets[id]",
            "bucket"
          ],
          "line": 585
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/qspinlock.c",
          "lines": "220-238",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "value + trace_len",
            "0",
            "map->value_size - trace_len"
          ],
          "line": 583
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "value",
            "bucket->data",
            "trace_len"
          ],
          "line": 582
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "stack_map_data_size",
          "args": [
            "map"
          ],
          "line": 581
        },
        "resolved": true,
        "details": {
          "function_name": "stack_map_data_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "39-43",
          "snippet": "static inline int stack_map_data_size(struct bpf_map *map)\n{\n\treturn stack_map_use_build_id(map) ?\n\t\tsizeof(struct bpf_stack_build_id) : sizeof(u64);\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic inline int stack_map_data_size(struct bpf_map *map)\n{\n\treturn stack_map_use_build_id(map) ?\n\t\tsizeof(struct bpf_stack_build_id) : sizeof(u64);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "id >= smap->n_buckets"
          ],
          "line": 574
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_stack_map",
            "map"
          ],
          "line": 570
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nint bpf_stackmap_copy(struct bpf_map *map, void *key, void *value)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\tstruct stack_map_bucket *bucket, *old_bucket;\n\tu32 id = *(u32 *)key, trace_len;\n\n\tif (unlikely(id >= smap->n_buckets))\n\t\treturn -ENOENT;\n\n\tbucket = xchg(&smap->buckets[id], NULL);\n\tif (!bucket)\n\t\treturn -ENOENT;\n\n\ttrace_len = bucket->nr * stack_map_data_size(map);\n\tmemcpy(value, bucket->data, trace_len);\n\tmemset(value + trace_len, 0, map->value_size - trace_len);\n\n\told_bucket = xchg(&smap->buckets[id], bucket);\n\tif (old_bucket)\n\t\tpcpu_freelist_push(&smap->freelist, &old_bucket->fnode);\n\treturn 0;\n}"
  },
  {
    "function_name": "stack_map_lookup_elem",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "562-565",
    "snippet": "static void *stack_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn ERR_PTR(-EOPNOTSUPP);\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EOPNOTSUPP"
          ],
          "line": 564
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic void *stack_map_lookup_elem(struct bpf_map *map, void *key)\n{\n\treturn ERR_PTR(-EOPNOTSUPP);\n}"
  },
  {
    "function_name": "__bpf_get_stack",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "386-453",
    "snippet": "static long __bpf_get_stack(struct pt_regs *regs, struct task_struct *task,\n\t\t\t    struct perf_callchain_entry *trace_in,\n\t\t\t    void *buf, u32 size, u64 flags)\n{\n\tu32 init_nr, trace_nr, copy_len, elem_size, num_elem;\n\tbool user_build_id = flags & BPF_F_USER_BUILD_ID;\n\tu32 skip = flags & BPF_F_SKIP_FIELD_MASK;\n\tbool user = flags & BPF_F_USER_STACK;\n\tstruct perf_callchain_entry *trace;\n\tbool kernel = !user;\n\tint err = -EINVAL;\n\tu64 *ips;\n\n\tif (unlikely(flags & ~(BPF_F_SKIP_FIELD_MASK | BPF_F_USER_STACK |\n\t\t\t       BPF_F_USER_BUILD_ID)))\n\t\tgoto clear;\n\tif (kernel && user_build_id)\n\t\tgoto clear;\n\n\telem_size = (user && user_build_id) ? sizeof(struct bpf_stack_build_id)\n\t\t\t\t\t    : sizeof(u64);\n\tif (unlikely(size % elem_size))\n\t\tgoto clear;\n\n\t/* cannot get valid user stack for task without user_mode regs */\n\tif (task && user && !user_mode(regs))\n\t\tgoto err_fault;\n\n\tnum_elem = size / elem_size;\n\tif (sysctl_perf_event_max_stack < num_elem)\n\t\tinit_nr = 0;\n\telse\n\t\tinit_nr = sysctl_perf_event_max_stack - num_elem;\n\n\tif (trace_in)\n\t\ttrace = trace_in;\n\telse if (kernel && task)\n\t\ttrace = get_callchain_entry_for_task(task, init_nr);\n\telse\n\t\ttrace = get_perf_callchain(regs, init_nr, kernel, user,\n\t\t\t\t\t   sysctl_perf_event_max_stack,\n\t\t\t\t\t   false, false);\n\tif (unlikely(!trace))\n\t\tgoto err_fault;\n\n\ttrace_nr = trace->nr - init_nr;\n\tif (trace_nr < skip)\n\t\tgoto err_fault;\n\n\ttrace_nr -= skip;\n\ttrace_nr = (trace_nr <= num_elem) ? trace_nr : num_elem;\n\tcopy_len = trace_nr * elem_size;\n\tips = trace->ip + skip + init_nr;\n\tif (user && user_build_id)\n\t\tstack_map_get_build_id_offset(buf, ips, trace_nr, user);\n\telse\n\t\tmemcpy(buf, ips, copy_len);\n\n\tif (size > copy_len)\n\t\tmemset(buf + copy_len, 0, size - copy_len);\n\treturn copy_len;\n\nerr_fault:\n\terr = -EFAULT;\nclear:\n\tmemset(buf, 0, size);\n\treturn err;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "buf",
            "0",
            "size"
          ],
          "line": 451
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "buf + copy_len",
            "0",
            "size - copy_len"
          ],
          "line": 445
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "buf",
            "ips",
            "copy_len"
          ],
          "line": 442
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "stack_map_get_build_id_offset",
          "args": [
            "buf",
            "ips",
            "trace_nr",
            "user"
          ],
          "line": 440
        },
        "resolved": true,
        "details": {
          "function_name": "stack_map_get_build_id_offset",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "129-166",
          "snippet": "static void stack_map_get_build_id_offset(struct bpf_stack_build_id *id_offs,\n\t\t\t\t\t  u64 *ips, u32 trace_nr, bool user)\n{\n\tint i;\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = bpf_mmap_unlock_get_irq_work(&work);\n\tstruct vm_area_struct *vma;\n\n\t/* If the irq_work is in use, fall back to report ips. Same\n\t * fallback is used for kernel stack (!user) on a stackmap with\n\t * build_id.\n\t */\n\tif (!user || !current || !current->mm || irq_work_busy ||\n\t    !mmap_read_trylock(current->mm)) {\n\t\t/* cannot access current->mm, fall back to ips */\n\t\tfor (i = 0; i < trace_nr; i++) {\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < trace_nr; i++) {\n\t\tvma = find_vma(current->mm, ips[i]);\n\t\tif (!vma || build_id_parse(vma, id_offs[i].build_id, NULL)) {\n\t\t\t/* per entry fall back to ips */\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t\tcontinue;\n\t\t}\n\t\tid_offs[i].offset = (vma->vm_pgoff << PAGE_SHIFT) + ips[i]\n\t\t\t- vma->vm_start;\n\t\tid_offs[i].status = BPF_STACK_BUILD_ID_VALID;\n\t}\n\tbpf_mmap_unlock_mm(work, current->mm);\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic void stack_map_get_build_id_offset(struct bpf_stack_build_id *id_offs,\n\t\t\t\t\t  u64 *ips, u32 trace_nr, bool user)\n{\n\tint i;\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = bpf_mmap_unlock_get_irq_work(&work);\n\tstruct vm_area_struct *vma;\n\n\t/* If the irq_work is in use, fall back to report ips. Same\n\t * fallback is used for kernel stack (!user) on a stackmap with\n\t * build_id.\n\t */\n\tif (!user || !current || !current->mm || irq_work_busy ||\n\t    !mmap_read_trylock(current->mm)) {\n\t\t/* cannot access current->mm, fall back to ips */\n\t\tfor (i = 0; i < trace_nr; i++) {\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < trace_nr; i++) {\n\t\tvma = find_vma(current->mm, ips[i]);\n\t\tif (!vma || build_id_parse(vma, id_offs[i].build_id, NULL)) {\n\t\t\t/* per entry fall back to ips */\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t\tcontinue;\n\t\t}\n\t\tid_offs[i].offset = (vma->vm_pgoff << PAGE_SHIFT) + ips[i]\n\t\t\t- vma->vm_start;\n\t\tid_offs[i].status = BPF_STACK_BUILD_ID_VALID;\n\t}\n\tbpf_mmap_unlock_mm(work, current->mm);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!trace"
          ],
          "line": 428
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "get_perf_callchain",
          "args": [
            "regs",
            "init_nr",
            "kernel",
            "user",
            "sysctl_perf_event_max_stack",
            "false",
            "false"
          ],
          "line": 425
        },
        "resolved": true,
        "details": {
          "function_name": "get_perf_callchain",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/callchain.c",
          "lines": "179-230",
          "snippet": "struct perf_callchain_entry *\nget_perf_callchain(struct pt_regs *regs, u32 init_nr, bool kernel, bool user,\n\t\t   u32 max_stack, bool crosstask, bool add_mark)\n{\n\tstruct perf_callchain_entry *entry;\n\tstruct perf_callchain_entry_ctx ctx;\n\tint rctx;\n\n\tentry = get_callchain_entry(&rctx);\n\tif (!entry)\n\t\treturn NULL;\n\n\tctx.entry     = entry;\n\tctx.max_stack = max_stack;\n\tctx.nr\t      = entry->nr = init_nr;\n\tctx.contexts       = 0;\n\tctx.contexts_maxed = false;\n\n\tif (kernel && !user_mode(regs)) {\n\t\tif (add_mark)\n\t\t\tperf_callchain_store_context(&ctx, PERF_CONTEXT_KERNEL);\n\t\tperf_callchain_kernel(&ctx, regs);\n\t}\n\n\tif (user) {\n\t\tif (!user_mode(regs)) {\n\t\t\tif  (current->mm)\n\t\t\t\tregs = task_pt_regs(current);\n\t\t\telse\n\t\t\t\tregs = NULL;\n\t\t}\n\n\t\tif (regs) {\n\t\t\tmm_segment_t fs;\n\n\t\t\tif (crosstask)\n\t\t\t\tgoto exit_put;\n\n\t\t\tif (add_mark)\n\t\t\t\tperf_callchain_store_context(&ctx, PERF_CONTEXT_USER);\n\n\t\t\tfs = force_uaccess_begin();\n\t\t\tperf_callchain_user(&ctx, regs);\n\t\t\tforce_uaccess_end(fs);\n\t\t}\n\t}\n\nexit_put:\n\tput_callchain_entry(rctx);\n\n\treturn entry;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/slab.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/sched/task_stack.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n\nstruct perf_callchain_entry *\nget_perf_callchain(struct pt_regs *regs, u32 init_nr, bool kernel, bool user,\n\t\t   u32 max_stack, bool crosstask, bool add_mark)\n{\n\tstruct perf_callchain_entry *entry;\n\tstruct perf_callchain_entry_ctx ctx;\n\tint rctx;\n\n\tentry = get_callchain_entry(&rctx);\n\tif (!entry)\n\t\treturn NULL;\n\n\tctx.entry     = entry;\n\tctx.max_stack = max_stack;\n\tctx.nr\t      = entry->nr = init_nr;\n\tctx.contexts       = 0;\n\tctx.contexts_maxed = false;\n\n\tif (kernel && !user_mode(regs)) {\n\t\tif (add_mark)\n\t\t\tperf_callchain_store_context(&ctx, PERF_CONTEXT_KERNEL);\n\t\tperf_callchain_kernel(&ctx, regs);\n\t}\n\n\tif (user) {\n\t\tif (!user_mode(regs)) {\n\t\t\tif  (current->mm)\n\t\t\t\tregs = task_pt_regs(current);\n\t\t\telse\n\t\t\t\tregs = NULL;\n\t\t}\n\n\t\tif (regs) {\n\t\t\tmm_segment_t fs;\n\n\t\t\tif (crosstask)\n\t\t\t\tgoto exit_put;\n\n\t\t\tif (add_mark)\n\t\t\t\tperf_callchain_store_context(&ctx, PERF_CONTEXT_USER);\n\n\t\t\tfs = force_uaccess_begin();\n\t\t\tperf_callchain_user(&ctx, regs);\n\t\t\tforce_uaccess_end(fs);\n\t\t}\n\t}\n\nexit_put:\n\tput_callchain_entry(rctx);\n\n\treturn entry;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_callchain_entry_for_task",
          "args": [
            "task",
            "init_nr"
          ],
          "line": 423
        },
        "resolved": true,
        "details": {
          "function_name": "get_callchain_entry_for_task",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "168-204",
          "snippet": "static struct perf_callchain_entry *\nget_callchain_entry_for_task(struct task_struct *task, u32 init_nr)\n{\n#ifdef CONFIG_STACKTRACE\n\tstruct perf_callchain_entry *entry;\n\tint rctx;\n\n\tentry = get_callchain_entry(&rctx);\n\n\tif (!entry)\n\t\treturn NULL;\n\n\tentry->nr = init_nr +\n\t\tstack_trace_save_tsk(task, (unsigned long *)(entry->ip + init_nr),\n\t\t\t\t     sysctl_perf_event_max_stack - init_nr, 0);\n\n\t/* stack_trace_save_tsk() works on unsigned long array, while\n\t * perf_callchain_entry uses u64 array. For 32-bit systems, it is\n\t * necessary to fix this mismatch.\n\t */\n\tif (__BITS_PER_LONG != 64) {\n\t\tunsigned long *from = (unsigned long *) entry->ip;\n\t\tu64 *to = entry->ip;\n\t\tint i;\n\n\t\t/* copy data from the end to avoid using extra buffer */\n\t\tfor (i = entry->nr - 1; i >= (int)init_nr; i--)\n\t\t\tto[i] = (u64)(from[i]);\n\t}\n\n\tput_callchain_entry(rctx);\n\n\treturn entry;\n#else /* CONFIG_STACKTRACE */\n\treturn NULL;\n#endif\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic struct perf_callchain_entry *\nget_callchain_entry_for_task(struct task_struct *task, u32 init_nr)\n{\n#ifdef CONFIG_STACKTRACE\n\tstruct perf_callchain_entry *entry;\n\tint rctx;\n\n\tentry = get_callchain_entry(&rctx);\n\n\tif (!entry)\n\t\treturn NULL;\n\n\tentry->nr = init_nr +\n\t\tstack_trace_save_tsk(task, (unsigned long *)(entry->ip + init_nr),\n\t\t\t\t     sysctl_perf_event_max_stack - init_nr, 0);\n\n\t/* stack_trace_save_tsk() works on unsigned long array, while\n\t * perf_callchain_entry uses u64 array. For 32-bit systems, it is\n\t * necessary to fix this mismatch.\n\t */\n\tif (__BITS_PER_LONG != 64) {\n\t\tunsigned long *from = (unsigned long *) entry->ip;\n\t\tu64 *to = entry->ip;\n\t\tint i;\n\n\t\t/* copy data from the end to avoid using extra buffer */\n\t\tfor (i = entry->nr - 1; i >= (int)init_nr; i--)\n\t\t\tto[i] = (u64)(from[i]);\n\t}\n\n\tput_callchain_entry(rctx);\n\n\treturn entry;\n#else /* CONFIG_STACKTRACE */\n\treturn NULL;\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "user_mode",
          "args": [
            "regs"
          ],
          "line": 411
        },
        "resolved": true,
        "details": {
          "function_name": "irqentry_exit_to_user_mode",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/entry/common.c",
          "lines": "303-309",
          "snippet": "noinstr void irqentry_exit_to_user_mode(struct pt_regs *regs)\n{\n\tinstrumentation_begin();\n\texit_to_user_mode_prepare(regs);\n\tinstrumentation_end();\n\t__exit_to_user_mode();\n}",
          "includes": [
            "#include <trace/events/syscalls.h>",
            "#include \"common.h\"",
            "#include <linux/tick.h>",
            "#include <linux/audit.h>",
            "#include <linux/livepatch.h>",
            "#include <linux/highmem.h>",
            "#include <linux/resume_user_mode.h>",
            "#include <linux/entry-common.h>",
            "#include <linux/context_tracking.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "__visible noinstr"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/syscalls.h>\n#include \"common.h\"\n#include <linux/tick.h>\n#include <linux/audit.h>\n#include <linux/livepatch.h>\n#include <linux/highmem.h>\n#include <linux/resume_user_mode.h>\n#include <linux/entry-common.h>\n#include <linux/context_tracking.h>\n\n__visible noinstr;\n\nnoinstr void irqentry_exit_to_user_mode(struct pt_regs *regs)\n{\n\tinstrumentation_begin();\n\texit_to_user_mode_prepare(regs);\n\tinstrumentation_end();\n\t__exit_to_user_mode();\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "size % elem_size"
          ],
          "line": 407
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "flags & ~(BPF_F_SKIP_FIELD_MASK | BPF_F_USER_STACK |\n\t\t\t       BPF_F_USER_BUILD_ID)"
          ],
          "line": 399
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic long __bpf_get_stack(struct pt_regs *regs, struct task_struct *task,\n\t\t\t    struct perf_callchain_entry *trace_in,\n\t\t\t    void *buf, u32 size, u64 flags)\n{\n\tu32 init_nr, trace_nr, copy_len, elem_size, num_elem;\n\tbool user_build_id = flags & BPF_F_USER_BUILD_ID;\n\tu32 skip = flags & BPF_F_SKIP_FIELD_MASK;\n\tbool user = flags & BPF_F_USER_STACK;\n\tstruct perf_callchain_entry *trace;\n\tbool kernel = !user;\n\tint err = -EINVAL;\n\tu64 *ips;\n\n\tif (unlikely(flags & ~(BPF_F_SKIP_FIELD_MASK | BPF_F_USER_STACK |\n\t\t\t       BPF_F_USER_BUILD_ID)))\n\t\tgoto clear;\n\tif (kernel && user_build_id)\n\t\tgoto clear;\n\n\telem_size = (user && user_build_id) ? sizeof(struct bpf_stack_build_id)\n\t\t\t\t\t    : sizeof(u64);\n\tif (unlikely(size % elem_size))\n\t\tgoto clear;\n\n\t/* cannot get valid user stack for task without user_mode regs */\n\tif (task && user && !user_mode(regs))\n\t\tgoto err_fault;\n\n\tnum_elem = size / elem_size;\n\tif (sysctl_perf_event_max_stack < num_elem)\n\t\tinit_nr = 0;\n\telse\n\t\tinit_nr = sysctl_perf_event_max_stack - num_elem;\n\n\tif (trace_in)\n\t\ttrace = trace_in;\n\telse if (kernel && task)\n\t\ttrace = get_callchain_entry_for_task(task, init_nr);\n\telse\n\t\ttrace = get_perf_callchain(regs, init_nr, kernel, user,\n\t\t\t\t\t   sysctl_perf_event_max_stack,\n\t\t\t\t\t   false, false);\n\tif (unlikely(!trace))\n\t\tgoto err_fault;\n\n\ttrace_nr = trace->nr - init_nr;\n\tif (trace_nr < skip)\n\t\tgoto err_fault;\n\n\ttrace_nr -= skip;\n\ttrace_nr = (trace_nr <= num_elem) ? trace_nr : num_elem;\n\tcopy_len = trace_nr * elem_size;\n\tips = trace->ip + skip + init_nr;\n\tif (user && user_build_id)\n\t\tstack_map_get_build_id_offset(buf, ips, trace_nr, user);\n\telse\n\t\tmemcpy(buf, ips, copy_len);\n\n\tif (size > copy_len)\n\t\tmemset(buf + copy_len, 0, size - copy_len);\n\treturn copy_len;\n\nerr_fault:\n\terr = -EFAULT;\nclear:\n\tmemset(buf, 0, size);\n\treturn err;\n}"
  },
  {
    "function_name": "count_kernel_ip",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "317-327",
    "snippet": "static __u64 count_kernel_ip(struct perf_callchain_entry *trace)\n{\n\t__u64 nr_kernel = 0;\n\n\twhile (nr_kernel < trace->nr) {\n\t\tif (trace->ip[nr_kernel] == PERF_CONTEXT_USER)\n\t\t\tbreak;\n\t\tnr_kernel++;\n\t}\n\treturn nr_kernel;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic __u64 count_kernel_ip(struct perf_callchain_entry *trace)\n{\n\t__u64 nr_kernel = 0;\n\n\twhile (nr_kernel < trace->nr) {\n\t\tif (trace->ip[nr_kernel] == PERF_CONTEXT_USER)\n\t\t\tbreak;\n\t\tnr_kernel++;\n\t}\n\treturn nr_kernel;\n}"
  },
  {
    "function_name": "__bpf_get_stackid",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "206-282",
    "snippet": "static long __bpf_get_stackid(struct bpf_map *map,\n\t\t\t      struct perf_callchain_entry *trace, u64 flags)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\tstruct stack_map_bucket *bucket, *new_bucket, *old_bucket;\n\tu32 max_depth = map->value_size / stack_map_data_size(map);\n\t/* stack_map_alloc() checks that max_depth <= sysctl_perf_event_max_stack */\n\tu32 init_nr = sysctl_perf_event_max_stack - max_depth;\n\tu32 skip = flags & BPF_F_SKIP_FIELD_MASK;\n\tu32 hash, id, trace_nr, trace_len;\n\tbool user = flags & BPF_F_USER_STACK;\n\tu64 *ips;\n\tbool hash_matches;\n\n\t/* get_perf_callchain() guarantees that trace->nr >= init_nr\n\t * and trace-nr <= sysctl_perf_event_max_stack, so trace_nr <= max_depth\n\t */\n\ttrace_nr = trace->nr - init_nr;\n\n\tif (trace_nr <= skip)\n\t\t/* skipping more than usable stack trace */\n\t\treturn -EFAULT;\n\n\ttrace_nr -= skip;\n\ttrace_len = trace_nr * sizeof(u64);\n\tips = trace->ip + skip + init_nr;\n\thash = jhash2((u32 *)ips, trace_len / sizeof(u32), 0);\n\tid = hash & (smap->n_buckets - 1);\n\tbucket = READ_ONCE(smap->buckets[id]);\n\n\thash_matches = bucket && bucket->hash == hash;\n\t/* fast cmp */\n\tif (hash_matches && flags & BPF_F_FAST_STACK_CMP)\n\t\treturn id;\n\n\tif (stack_map_use_build_id(map)) {\n\t\t/* for build_id+offset, pop a bucket before slow cmp */\n\t\tnew_bucket = (struct stack_map_bucket *)\n\t\t\tpcpu_freelist_pop(&smap->freelist);\n\t\tif (unlikely(!new_bucket))\n\t\t\treturn -ENOMEM;\n\t\tnew_bucket->nr = trace_nr;\n\t\tstack_map_get_build_id_offset(\n\t\t\t(struct bpf_stack_build_id *)new_bucket->data,\n\t\t\tips, trace_nr, user);\n\t\ttrace_len = trace_nr * sizeof(struct bpf_stack_build_id);\n\t\tif (hash_matches && bucket->nr == trace_nr &&\n\t\t    memcmp(bucket->data, new_bucket->data, trace_len) == 0) {\n\t\t\tpcpu_freelist_push(&smap->freelist, &new_bucket->fnode);\n\t\t\treturn id;\n\t\t}\n\t\tif (bucket && !(flags & BPF_F_REUSE_STACKID)) {\n\t\t\tpcpu_freelist_push(&smap->freelist, &new_bucket->fnode);\n\t\t\treturn -EEXIST;\n\t\t}\n\t} else {\n\t\tif (hash_matches && bucket->nr == trace_nr &&\n\t\t    memcmp(bucket->data, ips, trace_len) == 0)\n\t\t\treturn id;\n\t\tif (bucket && !(flags & BPF_F_REUSE_STACKID))\n\t\t\treturn -EEXIST;\n\n\t\tnew_bucket = (struct stack_map_bucket *)\n\t\t\tpcpu_freelist_pop(&smap->freelist);\n\t\tif (unlikely(!new_bucket))\n\t\t\treturn -ENOMEM;\n\t\tmemcpy(new_bucket->data, ips, trace_len);\n\t}\n\n\tnew_bucket->hash = hash;\n\tnew_bucket->nr = trace_nr;\n\n\told_bucket = xchg(&smap->buckets[id], new_bucket);\n\tif (old_bucket)\n\t\tpcpu_freelist_push(&smap->freelist, &old_bucket->fnode);\n\treturn id;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pcpu_freelist_push",
          "args": [
            "&smap->freelist",
            "&old_bucket->fnode"
          ],
          "line": 280
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_push",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "91-99",
          "snippet": "void pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__pcpu_freelist_push(s, node);\n\tlocal_irq_restore(flags);\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_push(struct pcpu_freelist *s,\n\t\t\tstruct pcpu_freelist_node *node)\n{\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\t__pcpu_freelist_push(s, node);\n\tlocal_irq_restore(flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "xchg",
          "args": [
            "&smap->buckets[id]",
            "new_bucket"
          ],
          "line": 278
        },
        "resolved": true,
        "details": {
          "function_name": "xchg_tail",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/qspinlock.c",
          "lines": "220-238",
          "snippet": "static __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}",
          "includes": [
            "#include \"qspinlock.c\"",
            "#include \"qspinlock_paravirt.h\"",
            "#include \"mcs_spinlock.h\"",
            "#include \"qspinlock_stat.h\"",
            "#include <asm/qspinlock.h>",
            "#include <asm/byteorder.h>",
            "#include <linux/prefetch.h>",
            "#include <linux/mutex.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/cpumask.h>",
            "#include <linux/bug.h>",
            "#include <linux/smp.h>"
          ],
          "macros_used": [
            "#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"qspinlock.c\"\n#include \"qspinlock_paravirt.h\"\n#include \"mcs_spinlock.h\"\n#include \"qspinlock_stat.h\"\n#include <asm/qspinlock.h>\n#include <asm/byteorder.h>\n#include <linux/prefetch.h>\n#include <linux/mutex.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/cpumask.h>\n#include <linux/bug.h>\n#include <linux/smp.h>\n\n#define _Q_LOCKED_PENDING_MASK (_Q_LOCKED_MASK | _Q_PENDING_MASK)\n\nstatic __always_inline u32 xchg_tail(struct qspinlock *lock, u32 tail)\n{\n\tu32 old, new, val = atomic_read(&lock->val);\n\n\tfor (;;) {\n\t\tnew = (val & _Q_LOCKED_PENDING_MASK) | tail;\n\t\t/*\n\t\t * We can use relaxed semantics since the caller ensures that\n\t\t * the MCS node is properly initialized before updating the\n\t\t * tail.\n\t\t */\n\t\told = atomic_cmpxchg_relaxed(&lock->val, val, new);\n\t\tif (old == val)\n\t\t\tbreak;\n\n\t\tval = old;\n\t}\n\treturn old;\n}"
        }
      },
      {
        "call_info": {
          "callee": "memcpy",
          "args": [
            "new_bucket->data",
            "ips",
            "trace_len"
          ],
          "line": 272
        },
        "resolved": true,
        "details": {
          "function_name": "memcpy_skip",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/internal.h",
          "lines": "180-184",
          "snippet": "static inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}",
          "includes": [
            "#include <linux/refcount.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/hardirq.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/refcount.h>\n#include <linux/uaccess.h>\n#include <linux/hardirq.h>\n\nstatic inline unsigned long\nmemcpy_skip(void *dst, const void *src, unsigned long n)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!new_bucket"
          ],
          "line": 270
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_pop",
          "args": [
            "&smap->freelist"
          ],
          "line": 269
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_pop",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "200-209",
          "snippet": "struct pcpu_freelist_node *pcpu_freelist_pop(struct pcpu_freelist *s)\n{\n\tstruct pcpu_freelist_node *ret;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tret = __pcpu_freelist_pop(s);\n\tlocal_irq_restore(flags);\n\treturn ret;\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nstruct pcpu_freelist_node *pcpu_freelist_pop(struct pcpu_freelist *s)\n{\n\tstruct pcpu_freelist_node *ret;\n\tunsigned long flags;\n\n\tlocal_irq_save(flags);\n\tret = __pcpu_freelist_pop(s);\n\tlocal_irq_restore(flags);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "memcmp",
          "args": [
            "bucket->data",
            "ips",
            "trace_len"
          ],
          "line": 263
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memcmp",
          "args": [
            "bucket->data",
            "new_bucket->data",
            "trace_len"
          ],
          "line": 253
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "stack_map_get_build_id_offset",
          "args": [
            "(struct bpf_stack_build_id *)new_bucket->data",
            "ips",
            "trace_nr",
            "user"
          ],
          "line": 248
        },
        "resolved": true,
        "details": {
          "function_name": "stack_map_get_build_id_offset",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "129-166",
          "snippet": "static void stack_map_get_build_id_offset(struct bpf_stack_build_id *id_offs,\n\t\t\t\t\t  u64 *ips, u32 trace_nr, bool user)\n{\n\tint i;\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = bpf_mmap_unlock_get_irq_work(&work);\n\tstruct vm_area_struct *vma;\n\n\t/* If the irq_work is in use, fall back to report ips. Same\n\t * fallback is used for kernel stack (!user) on a stackmap with\n\t * build_id.\n\t */\n\tif (!user || !current || !current->mm || irq_work_busy ||\n\t    !mmap_read_trylock(current->mm)) {\n\t\t/* cannot access current->mm, fall back to ips */\n\t\tfor (i = 0; i < trace_nr; i++) {\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < trace_nr; i++) {\n\t\tvma = find_vma(current->mm, ips[i]);\n\t\tif (!vma || build_id_parse(vma, id_offs[i].build_id, NULL)) {\n\t\t\t/* per entry fall back to ips */\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t\tcontinue;\n\t\t}\n\t\tid_offs[i].offset = (vma->vm_pgoff << PAGE_SHIFT) + ips[i]\n\t\t\t- vma->vm_start;\n\t\tid_offs[i].status = BPF_STACK_BUILD_ID_VALID;\n\t}\n\tbpf_mmap_unlock_mm(work, current->mm);\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic void stack_map_get_build_id_offset(struct bpf_stack_build_id *id_offs,\n\t\t\t\t\t  u64 *ips, u32 trace_nr, bool user)\n{\n\tint i;\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = bpf_mmap_unlock_get_irq_work(&work);\n\tstruct vm_area_struct *vma;\n\n\t/* If the irq_work is in use, fall back to report ips. Same\n\t * fallback is used for kernel stack (!user) on a stackmap with\n\t * build_id.\n\t */\n\tif (!user || !current || !current->mm || irq_work_busy ||\n\t    !mmap_read_trylock(current->mm)) {\n\t\t/* cannot access current->mm, fall back to ips */\n\t\tfor (i = 0; i < trace_nr; i++) {\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < trace_nr; i++) {\n\t\tvma = find_vma(current->mm, ips[i]);\n\t\tif (!vma || build_id_parse(vma, id_offs[i].build_id, NULL)) {\n\t\t\t/* per entry fall back to ips */\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t\tcontinue;\n\t\t}\n\t\tid_offs[i].offset = (vma->vm_pgoff << PAGE_SHIFT) + ips[i]\n\t\t\t- vma->vm_start;\n\t\tid_offs[i].status = BPF_STACK_BUILD_ID_VALID;\n\t}\n\tbpf_mmap_unlock_mm(work, current->mm);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!new_bucket"
          ],
          "line": 245
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "stack_map_use_build_id",
          "args": [
            "map"
          ],
          "line": 241
        },
        "resolved": true,
        "details": {
          "function_name": "stack_map_use_build_id",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "34-37",
          "snippet": "static inline bool stack_map_use_build_id(struct bpf_map *map)\n{\n\treturn (map->map_flags & BPF_F_STACK_BUILD_ID);\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic inline bool stack_map_use_build_id(struct bpf_map *map)\n{\n\treturn (map->map_flags & BPF_F_STACK_BUILD_ID);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "smap->buckets[id]"
          ],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "jhash2",
          "args": [
            "(u32 *)ips",
            "trace_len / sizeof(u32)",
            "0"
          ],
          "line": 232
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "stack_map_data_size",
          "args": [
            "map"
          ],
          "line": 211
        },
        "resolved": true,
        "details": {
          "function_name": "stack_map_data_size",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "39-43",
          "snippet": "static inline int stack_map_data_size(struct bpf_map *map)\n{\n\treturn stack_map_use_build_id(map) ?\n\t\tsizeof(struct bpf_stack_build_id) : sizeof(u64);\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic inline int stack_map_data_size(struct bpf_map *map)\n{\n\treturn stack_map_use_build_id(map) ?\n\t\tsizeof(struct bpf_stack_build_id) : sizeof(u64);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "map",
            "structbpf_stack_map",
            "map"
          ],
          "line": 209
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic long __bpf_get_stackid(struct bpf_map *map,\n\t\t\t      struct perf_callchain_entry *trace, u64 flags)\n{\n\tstruct bpf_stack_map *smap = container_of(map, struct bpf_stack_map, map);\n\tstruct stack_map_bucket *bucket, *new_bucket, *old_bucket;\n\tu32 max_depth = map->value_size / stack_map_data_size(map);\n\t/* stack_map_alloc() checks that max_depth <= sysctl_perf_event_max_stack */\n\tu32 init_nr = sysctl_perf_event_max_stack - max_depth;\n\tu32 skip = flags & BPF_F_SKIP_FIELD_MASK;\n\tu32 hash, id, trace_nr, trace_len;\n\tbool user = flags & BPF_F_USER_STACK;\n\tu64 *ips;\n\tbool hash_matches;\n\n\t/* get_perf_callchain() guarantees that trace->nr >= init_nr\n\t * and trace-nr <= sysctl_perf_event_max_stack, so trace_nr <= max_depth\n\t */\n\ttrace_nr = trace->nr - init_nr;\n\n\tif (trace_nr <= skip)\n\t\t/* skipping more than usable stack trace */\n\t\treturn -EFAULT;\n\n\ttrace_nr -= skip;\n\ttrace_len = trace_nr * sizeof(u64);\n\tips = trace->ip + skip + init_nr;\n\thash = jhash2((u32 *)ips, trace_len / sizeof(u32), 0);\n\tid = hash & (smap->n_buckets - 1);\n\tbucket = READ_ONCE(smap->buckets[id]);\n\n\thash_matches = bucket && bucket->hash == hash;\n\t/* fast cmp */\n\tif (hash_matches && flags & BPF_F_FAST_STACK_CMP)\n\t\treturn id;\n\n\tif (stack_map_use_build_id(map)) {\n\t\t/* for build_id+offset, pop a bucket before slow cmp */\n\t\tnew_bucket = (struct stack_map_bucket *)\n\t\t\tpcpu_freelist_pop(&smap->freelist);\n\t\tif (unlikely(!new_bucket))\n\t\t\treturn -ENOMEM;\n\t\tnew_bucket->nr = trace_nr;\n\t\tstack_map_get_build_id_offset(\n\t\t\t(struct bpf_stack_build_id *)new_bucket->data,\n\t\t\tips, trace_nr, user);\n\t\ttrace_len = trace_nr * sizeof(struct bpf_stack_build_id);\n\t\tif (hash_matches && bucket->nr == trace_nr &&\n\t\t    memcmp(bucket->data, new_bucket->data, trace_len) == 0) {\n\t\t\tpcpu_freelist_push(&smap->freelist, &new_bucket->fnode);\n\t\t\treturn id;\n\t\t}\n\t\tif (bucket && !(flags & BPF_F_REUSE_STACKID)) {\n\t\t\tpcpu_freelist_push(&smap->freelist, &new_bucket->fnode);\n\t\t\treturn -EEXIST;\n\t\t}\n\t} else {\n\t\tif (hash_matches && bucket->nr == trace_nr &&\n\t\t    memcmp(bucket->data, ips, trace_len) == 0)\n\t\t\treturn id;\n\t\tif (bucket && !(flags & BPF_F_REUSE_STACKID))\n\t\t\treturn -EEXIST;\n\n\t\tnew_bucket = (struct stack_map_bucket *)\n\t\t\tpcpu_freelist_pop(&smap->freelist);\n\t\tif (unlikely(!new_bucket))\n\t\t\treturn -ENOMEM;\n\t\tmemcpy(new_bucket->data, ips, trace_len);\n\t}\n\n\tnew_bucket->hash = hash;\n\tnew_bucket->nr = trace_nr;\n\n\told_bucket = xchg(&smap->buckets[id], new_bucket);\n\tif (old_bucket)\n\t\tpcpu_freelist_push(&smap->freelist, &old_bucket->fnode);\n\treturn id;\n}"
  },
  {
    "function_name": "get_callchain_entry_for_task",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "168-204",
    "snippet": "static struct perf_callchain_entry *\nget_callchain_entry_for_task(struct task_struct *task, u32 init_nr)\n{\n#ifdef CONFIG_STACKTRACE\n\tstruct perf_callchain_entry *entry;\n\tint rctx;\n\n\tentry = get_callchain_entry(&rctx);\n\n\tif (!entry)\n\t\treturn NULL;\n\n\tentry->nr = init_nr +\n\t\tstack_trace_save_tsk(task, (unsigned long *)(entry->ip + init_nr),\n\t\t\t\t     sysctl_perf_event_max_stack - init_nr, 0);\n\n\t/* stack_trace_save_tsk() works on unsigned long array, while\n\t * perf_callchain_entry uses u64 array. For 32-bit systems, it is\n\t * necessary to fix this mismatch.\n\t */\n\tif (__BITS_PER_LONG != 64) {\n\t\tunsigned long *from = (unsigned long *) entry->ip;\n\t\tu64 *to = entry->ip;\n\t\tint i;\n\n\t\t/* copy data from the end to avoid using extra buffer */\n\t\tfor (i = entry->nr - 1; i >= (int)init_nr; i--)\n\t\t\tto[i] = (u64)(from[i]);\n\t}\n\n\tput_callchain_entry(rctx);\n\n\treturn entry;\n#else /* CONFIG_STACKTRACE */\n\treturn NULL;\n#endif\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_callchain_entry",
          "args": [
            "rctx"
          ],
          "line": 198
        },
        "resolved": true,
        "details": {
          "function_name": "put_callchain_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/callchain.c",
          "lines": "173-177",
          "snippet": "void\nput_callchain_entry(int rctx)\n{\n\tput_recursion_context(this_cpu_ptr(callchain_recursion), rctx);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/slab.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(int, callchain_recursion[PERF_NR_CONTEXTS]);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/sched/task_stack.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n\nstatic DEFINE_PER_CPU(int, callchain_recursion[PERF_NR_CONTEXTS]);\n\nvoid\nput_callchain_entry(int rctx)\n{\n\tput_recursion_context(this_cpu_ptr(callchain_recursion), rctx);\n}"
        }
      },
      {
        "call_info": {
          "callee": "",
          "args": [
            "from[i]"
          ],
          "line": 195
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "stack_trace_save_tsk",
          "args": [
            "task",
            "(unsigned long *)(entry->ip + init_nr)",
            "sysctl_perf_event_max_stack - init_nr",
            "0"
          ],
          "line": 181
        },
        "resolved": true,
        "details": {
          "function_name": "stack_trace_save_tsk",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/stacktrace.c",
          "lines": "293-306",
          "snippet": "unsigned int stack_trace_save_tsk(struct task_struct *task,\n\t\t\t\t  unsigned long *store, unsigned int size,\n\t\t\t\t  unsigned int skipnr)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t\t/* skip this function if they are tracing us */\n\t\t.skip\t= skipnr + (current == task),\n\t};\n\n\tsave_stack_trace_tsk(task, &trace);\n\treturn trace.nr_entries;\n}",
          "includes": [
            "#include <linux/interrupt.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/sched.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/task_stack.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/interrupt.h>\n#include <linux/stacktrace.h>\n#include <linux/kallsyms.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/sched.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/task_stack.h>\n\nunsigned int stack_trace_save_tsk(struct task_struct *task,\n\t\t\t\t  unsigned long *store, unsigned int size,\n\t\t\t\t  unsigned int skipnr)\n{\n\tstruct stack_trace trace = {\n\t\t.entries\t= store,\n\t\t.max_entries\t= size,\n\t\t/* skip this function if they are tracing us */\n\t\t.skip\t= skipnr + (current == task),\n\t};\n\n\tsave_stack_trace_tsk(task, &trace);\n\treturn trace.nr_entries;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_callchain_entry",
          "args": [
            "&rctx"
          ],
          "line": 175
        },
        "resolved": true,
        "details": {
          "function_name": "get_callchain_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/callchain.c",
          "lines": "152-171",
          "snippet": "struct perf_callchain_entry *get_callchain_entry(int *rctx)\n{\n\tint cpu;\n\tstruct callchain_cpus_entries *entries;\n\n\t*rctx = get_recursion_context(this_cpu_ptr(callchain_recursion));\n\tif (*rctx == -1)\n\t\treturn NULL;\n\n\tentries = rcu_dereference(callchain_cpus_entries);\n\tif (!entries) {\n\t\tput_recursion_context(this_cpu_ptr(callchain_recursion), *rctx);\n\t\treturn NULL;\n\t}\n\n\tcpu = smp_processor_id();\n\n\treturn (((void *)entries->cpu_entries[cpu]) +\n\t\t(*rctx * perf_callchain_entry__sizeof()));\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/slab.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(int, callchain_recursion[PERF_NR_CONTEXTS]);",
            "static struct callchain_cpus_entries *callchain_cpus_entries;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/sched/task_stack.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n\nstatic DEFINE_PER_CPU(int, callchain_recursion[PERF_NR_CONTEXTS]);\nstatic struct callchain_cpus_entries *callchain_cpus_entries;\n\nstruct perf_callchain_entry *get_callchain_entry(int *rctx)\n{\n\tint cpu;\n\tstruct callchain_cpus_entries *entries;\n\n\t*rctx = get_recursion_context(this_cpu_ptr(callchain_recursion));\n\tif (*rctx == -1)\n\t\treturn NULL;\n\n\tentries = rcu_dereference(callchain_cpus_entries);\n\tif (!entries) {\n\t\tput_recursion_context(this_cpu_ptr(callchain_recursion), *rctx);\n\t\treturn NULL;\n\t}\n\n\tcpu = smp_processor_id();\n\n\treturn (((void *)entries->cpu_entries[cpu]) +\n\t\t(*rctx * perf_callchain_entry__sizeof()));\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic struct perf_callchain_entry *\nget_callchain_entry_for_task(struct task_struct *task, u32 init_nr)\n{\n#ifdef CONFIG_STACKTRACE\n\tstruct perf_callchain_entry *entry;\n\tint rctx;\n\n\tentry = get_callchain_entry(&rctx);\n\n\tif (!entry)\n\t\treturn NULL;\n\n\tentry->nr = init_nr +\n\t\tstack_trace_save_tsk(task, (unsigned long *)(entry->ip + init_nr),\n\t\t\t\t     sysctl_perf_event_max_stack - init_nr, 0);\n\n\t/* stack_trace_save_tsk() works on unsigned long array, while\n\t * perf_callchain_entry uses u64 array. For 32-bit systems, it is\n\t * necessary to fix this mismatch.\n\t */\n\tif (__BITS_PER_LONG != 64) {\n\t\tunsigned long *from = (unsigned long *) entry->ip;\n\t\tu64 *to = entry->ip;\n\t\tint i;\n\n\t\t/* copy data from the end to avoid using extra buffer */\n\t\tfor (i = entry->nr - 1; i >= (int)init_nr; i--)\n\t\t\tto[i] = (u64)(from[i]);\n\t}\n\n\tput_callchain_entry(rctx);\n\n\treturn entry;\n#else /* CONFIG_STACKTRACE */\n\treturn NULL;\n#endif\n}"
  },
  {
    "function_name": "stack_map_get_build_id_offset",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "129-166",
    "snippet": "static void stack_map_get_build_id_offset(struct bpf_stack_build_id *id_offs,\n\t\t\t\t\t  u64 *ips, u32 trace_nr, bool user)\n{\n\tint i;\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = bpf_mmap_unlock_get_irq_work(&work);\n\tstruct vm_area_struct *vma;\n\n\t/* If the irq_work is in use, fall back to report ips. Same\n\t * fallback is used for kernel stack (!user) on a stackmap with\n\t * build_id.\n\t */\n\tif (!user || !current || !current->mm || irq_work_busy ||\n\t    !mmap_read_trylock(current->mm)) {\n\t\t/* cannot access current->mm, fall back to ips */\n\t\tfor (i = 0; i < trace_nr; i++) {\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < trace_nr; i++) {\n\t\tvma = find_vma(current->mm, ips[i]);\n\t\tif (!vma || build_id_parse(vma, id_offs[i].build_id, NULL)) {\n\t\t\t/* per entry fall back to ips */\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t\tcontinue;\n\t\t}\n\t\tid_offs[i].offset = (vma->vm_pgoff << PAGE_SHIFT) + ips[i]\n\t\t\t- vma->vm_start;\n\t\tid_offs[i].status = BPF_STACK_BUILD_ID_VALID;\n\t}\n\tbpf_mmap_unlock_mm(work, current->mm);\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_mmap_unlock_mm",
          "args": [
            "work",
            "current->mm"
          ],
          "line": 165
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_mmap_unlock_mm",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/mmap_unlock_work.h",
          "lines": "49-63",
          "snippet": "static inline void bpf_mmap_unlock_mm(struct mmap_unlock_irq_work *work, struct mm_struct *mm)\n{\n\tif (!work) {\n\t\tmmap_read_unlock(mm);\n\t} else {\n\t\twork->mm = mm;\n\n\t\t/* The lock will be released once we're out of interrupt\n\t\t * context. Tell lockdep that we've released it now so\n\t\t * it doesn't complain that we forgot to release it.\n\t\t */\n\t\trwsem_release(&mm->mmap_lock.dep_map, _RET_IP_);\n\t\tirq_work_queue(&work->irq_work);\n\t}\n}",
          "includes": [
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/irq_work.h>\n\nstatic inline void bpf_mmap_unlock_mm(struct mmap_unlock_irq_work *work, struct mm_struct *mm)\n{\n\tif (!work) {\n\t\tmmap_read_unlock(mm);\n\t} else {\n\t\twork->mm = mm;\n\n\t\t/* The lock will be released once we're out of interrupt\n\t\t * context. Tell lockdep that we've released it now so\n\t\t * it doesn't complain that we forgot to release it.\n\t\t */\n\t\trwsem_release(&mm->mmap_lock.dep_map, _RET_IP_);\n\t\tirq_work_queue(&work->irq_work);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "id_offs[i].build_id",
            "0",
            "BUILD_ID_SIZE_MAX"
          ],
          "line": 158
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "build_id_parse",
          "args": [
            "vma",
            "id_offs[i].build_id",
            "NULL"
          ],
          "line": 154
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "find_vma",
          "args": [
            "current->mm",
            "ips[i]"
          ],
          "line": 153
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "memset",
          "args": [
            "id_offs[i].build_id",
            "0",
            "BUILD_ID_SIZE_MAX"
          ],
          "line": 147
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mmap_read_trylock",
          "args": [
            "current->mm"
          ],
          "line": 142
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_mmap_unlock_get_irq_work",
          "args": [
            "&work"
          ],
          "line": 134
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_mmap_unlock_get_irq_work",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/mmap_unlock_work.h",
          "lines": "24-47",
          "snippet": "static inline bool bpf_mmap_unlock_get_irq_work(struct mmap_unlock_irq_work **work_ptr)\n{\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = false;\n\n\tif (irqs_disabled()) {\n\t\tif (!IS_ENABLED(CONFIG_PREEMPT_RT)) {\n\t\t\twork = this_cpu_ptr(&mmap_unlock_work);\n\t\t\tif (irq_work_is_busy(&work->irq_work)) {\n\t\t\t\t/* cannot queue more up_read, fallback */\n\t\t\t\tirq_work_busy = true;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * PREEMPT_RT does not allow to trylock mmap sem in\n\t\t\t * interrupt disabled context. Force the fallback code.\n\t\t\t */\n\t\t\tirq_work_busy = true;\n\t\t}\n\t}\n\n\t*work_ptr = work;\n\treturn irq_work_busy;\n}",
          "includes": [
            "#include <linux/irq_work.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/irq_work.h>\n\nstatic inline bool bpf_mmap_unlock_get_irq_work(struct mmap_unlock_irq_work **work_ptr)\n{\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = false;\n\n\tif (irqs_disabled()) {\n\t\tif (!IS_ENABLED(CONFIG_PREEMPT_RT)) {\n\t\t\twork = this_cpu_ptr(&mmap_unlock_work);\n\t\t\tif (irq_work_is_busy(&work->irq_work)) {\n\t\t\t\t/* cannot queue more up_read, fallback */\n\t\t\t\tirq_work_busy = true;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * PREEMPT_RT does not allow to trylock mmap sem in\n\t\t\t * interrupt disabled context. Force the fallback code.\n\t\t\t */\n\t\t\tirq_work_busy = true;\n\t\t}\n\t}\n\n\t*work_ptr = work;\n\treturn irq_work_busy;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic void stack_map_get_build_id_offset(struct bpf_stack_build_id *id_offs,\n\t\t\t\t\t  u64 *ips, u32 trace_nr, bool user)\n{\n\tint i;\n\tstruct mmap_unlock_irq_work *work = NULL;\n\tbool irq_work_busy = bpf_mmap_unlock_get_irq_work(&work);\n\tstruct vm_area_struct *vma;\n\n\t/* If the irq_work is in use, fall back to report ips. Same\n\t * fallback is used for kernel stack (!user) on a stackmap with\n\t * build_id.\n\t */\n\tif (!user || !current || !current->mm || irq_work_busy ||\n\t    !mmap_read_trylock(current->mm)) {\n\t\t/* cannot access current->mm, fall back to ips */\n\t\tfor (i = 0; i < trace_nr; i++) {\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (i = 0; i < trace_nr; i++) {\n\t\tvma = find_vma(current->mm, ips[i]);\n\t\tif (!vma || build_id_parse(vma, id_offs[i].build_id, NULL)) {\n\t\t\t/* per entry fall back to ips */\n\t\t\tid_offs[i].status = BPF_STACK_BUILD_ID_IP;\n\t\t\tid_offs[i].ip = ips[i];\n\t\t\tmemset(id_offs[i].build_id, 0, BUILD_ID_SIZE_MAX);\n\t\t\tcontinue;\n\t\t}\n\t\tid_offs[i].offset = (vma->vm_pgoff << PAGE_SHIFT) + ips[i]\n\t\t\t- vma->vm_start;\n\t\tid_offs[i].status = BPF_STACK_BUILD_ID_VALID;\n\t}\n\tbpf_mmap_unlock_mm(work, current->mm);\n}"
  },
  {
    "function_name": "stack_map_alloc",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "70-127",
    "snippet": "static struct bpf_map *stack_map_alloc(union bpf_attr *attr)\n{\n\tu32 value_size = attr->value_size;\n\tstruct bpf_stack_map *smap;\n\tu64 cost, n_buckets;\n\tint err;\n\n\tif (!bpf_capable())\n\t\treturn ERR_PTR(-EPERM);\n\n\tif (attr->map_flags & ~STACK_CREATE_FLAG_MASK)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    value_size < 8 || value_size % 8)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tBUILD_BUG_ON(sizeof(struct bpf_stack_build_id) % sizeof(u64));\n\tif (attr->map_flags & BPF_F_STACK_BUILD_ID) {\n\t\tif (value_size % sizeof(struct bpf_stack_build_id) ||\n\t\t    value_size / sizeof(struct bpf_stack_build_id)\n\t\t    > sysctl_perf_event_max_stack)\n\t\t\treturn ERR_PTR(-EINVAL);\n\t} else if (value_size / 8 > sysctl_perf_event_max_stack)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/* hash table size must be power of 2 */\n\tn_buckets = roundup_pow_of_two(attr->max_entries);\n\tif (!n_buckets)\n\t\treturn ERR_PTR(-E2BIG);\n\n\tcost = n_buckets * sizeof(struct stack_map_bucket *) + sizeof(*smap);\n\tcost += n_buckets * (value_size + sizeof(struct stack_map_bucket));\n\tsmap = bpf_map_area_alloc(cost, bpf_map_attr_numa_node(attr));\n\tif (!smap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&smap->map, attr);\n\tsmap->map.value_size = value_size;\n\tsmap->n_buckets = n_buckets;\n\n\terr = get_callchain_buffers(sysctl_perf_event_max_stack);\n\tif (err)\n\t\tgoto free_smap;\n\n\terr = prealloc_elems_and_freelist(smap);\n\tif (err)\n\t\tgoto put_buffers;\n\n\treturn &smap->map;\n\nput_buffers:\n\tput_callchain_buffers();\nfree_smap:\n\tbpf_map_area_free(smap);\n\treturn ERR_PTR(err);\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [
      "#define STACK_CREATE_FLAG_MASK\t\t\t\t\t\\\n\t(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY |\t\\\n\t BPF_F_STACK_BUILD_ID)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "err"
          ],
          "line": 126
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "smap"
          ],
          "line": 125
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "put_callchain_buffers",
          "args": [],
          "line": 123
        },
        "resolved": true,
        "details": {
          "function_name": "put_callchain_buffers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/callchain.c",
          "lines": "144-150",
          "snippet": "void put_callchain_buffers(void)\n{\n\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {\n\t\trelease_callchain_buffers();\n\t\tmutex_unlock(&callchain_mutex);\n\t}\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/slab.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static atomic_t nr_callchain_events;",
            "static DEFINE_MUTEX(callchain_mutex);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/sched/task_stack.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n\nstatic atomic_t nr_callchain_events;\nstatic DEFINE_MUTEX(callchain_mutex);\n\nvoid put_callchain_buffers(void)\n{\n\tif (atomic_dec_and_mutex_lock(&nr_callchain_events, &callchain_mutex)) {\n\t\trelease_callchain_buffers();\n\t\tmutex_unlock(&callchain_mutex);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "prealloc_elems_and_freelist",
          "args": [
            "smap"
          ],
          "line": 116
        },
        "resolved": true,
        "details": {
          "function_name": "prealloc_elems_and_freelist",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "45-67",
          "snippet": "static int prealloc_elems_and_freelist(struct bpf_stack_map *smap)\n{\n\tu64 elem_size = sizeof(struct stack_map_bucket) +\n\t\t\t(u64)smap->map.value_size;\n\tint err;\n\n\tsmap->elems = bpf_map_area_alloc(elem_size * smap->map.max_entries,\n\t\t\t\t\t smap->map.numa_node);\n\tif (!smap->elems)\n\t\treturn -ENOMEM;\n\n\terr = pcpu_freelist_init(&smap->freelist);\n\tif (err)\n\t\tgoto free_elems;\n\n\tpcpu_freelist_populate(&smap->freelist, smap->elems, elem_size,\n\t\t\t       smap->map.max_entries);\n\treturn 0;\n\nfree_elems:\n\tbpf_map_area_free(smap->elems);\n\treturn err;\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic int prealloc_elems_and_freelist(struct bpf_stack_map *smap)\n{\n\tu64 elem_size = sizeof(struct stack_map_bucket) +\n\t\t\t(u64)smap->map.value_size;\n\tint err;\n\n\tsmap->elems = bpf_map_area_alloc(elem_size * smap->map.max_entries,\n\t\t\t\t\t smap->map.numa_node);\n\tif (!smap->elems)\n\t\treturn -ENOMEM;\n\n\terr = pcpu_freelist_init(&smap->freelist);\n\tif (err)\n\t\tgoto free_elems;\n\n\tpcpu_freelist_populate(&smap->freelist, smap->elems, elem_size,\n\t\t\t       smap->map.max_entries);\n\treturn 0;\n\nfree_elems:\n\tbpf_map_area_free(smap->elems);\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "get_callchain_buffers",
          "args": [
            "sysctl_perf_event_max_stack"
          ],
          "line": 112
        },
        "resolved": true,
        "details": {
          "function_name": "get_callchain_buffers",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/events/callchain.c",
          "lines": "108-142",
          "snippet": "int get_callchain_buffers(int event_max_stack)\n{\n\tint err = 0;\n\tint count;\n\n\tmutex_lock(&callchain_mutex);\n\n\tcount = atomic_inc_return(&nr_callchain_events);\n\tif (WARN_ON_ONCE(count < 1)) {\n\t\terr = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t/*\n\t * If requesting per event more than the global cap,\n\t * return a different error to help userspace figure\n\t * this out.\n\t *\n\t * And also do it here so that we have &callchain_mutex held.\n\t */\n\tif (event_max_stack > sysctl_perf_event_max_stack) {\n\t\terr = -EOVERFLOW;\n\t\tgoto exit;\n\t}\n\n\tif (count == 1)\n\t\terr = alloc_callchain_buffers();\nexit:\n\tif (err)\n\t\tatomic_dec(&nr_callchain_events);\n\n\tmutex_unlock(&callchain_mutex);\n\n\treturn err;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/sched/task_stack.h>",
            "#include <linux/slab.h>",
            "#include <linux/perf_event.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "int sysctl_perf_event_max_stack",
            "static atomic_t nr_callchain_events;",
            "static DEFINE_MUTEX(callchain_mutex);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/sched/task_stack.h>\n#include <linux/slab.h>\n#include <linux/perf_event.h>\n\nint sysctl_perf_event_max_stack;\nstatic atomic_t nr_callchain_events;\nstatic DEFINE_MUTEX(callchain_mutex);\n\nint get_callchain_buffers(int event_max_stack)\n{\n\tint err = 0;\n\tint count;\n\n\tmutex_lock(&callchain_mutex);\n\n\tcount = atomic_inc_return(&nr_callchain_events);\n\tif (WARN_ON_ONCE(count < 1)) {\n\t\terr = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\t/*\n\t * If requesting per event more than the global cap,\n\t * return a different error to help userspace figure\n\t * this out.\n\t *\n\t * And also do it here so that we have &callchain_mutex held.\n\t */\n\tif (event_max_stack > sysctl_perf_event_max_stack) {\n\t\terr = -EOVERFLOW;\n\t\tgoto exit;\n\t}\n\n\tif (count == 1)\n\t\terr = alloc_callchain_buffers();\nexit:\n\tif (err)\n\t\tatomic_dec(&nr_callchain_events);\n\n\tmutex_unlock(&callchain_mutex);\n\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_init_from_attr",
          "args": [
            "&smap->map",
            "attr"
          ],
          "line": 108
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_init_from_attr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "361-370",
          "snippet": "void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr)\n{\n\tmap->map_type = attr->map_type;\n\tmap->key_size = attr->key_size;\n\tmap->value_size = attr->value_size;\n\tmap->max_entries = attr->max_entries;\n\tmap->map_flags = bpf_map_flags_retain_permanent(attr->map_flags);\n\tmap->numa_node = bpf_map_attr_numa_node(attr);\n\tmap->map_extra = attr->map_extra;\n}"
        }
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-ENOMEM"
          ],
          "line": 106
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "cost",
            "bpf_map_attr_numa_node(attr)"
          ],
          "line": 104
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "334-337",
          "snippet": "void *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_attr_numa_node",
          "args": [
            "attr"
          ],
          "line": 104
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-E2BIG"
          ],
          "line": 100
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "roundup_pow_of_two",
          "args": [
            "attr->max_entries"
          ],
          "line": 98
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 95
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 93
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUILD_BUG_ON",
          "args": [
            "sizeof(struct bpf_stack_build_id) % sizeof(u64)"
          ],
          "line": 88
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 86
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EINVAL"
          ],
          "line": 81
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "ERR_PTR",
          "args": [
            "-EPERM"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "bpf_capable",
          "args": [],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\n#define STACK_CREATE_FLAG_MASK\t\t\t\t\t\\\n\t(BPF_F_NUMA_NODE | BPF_F_RDONLY | BPF_F_WRONLY |\t\\\n\t BPF_F_STACK_BUILD_ID)\n\nstatic struct bpf_map *stack_map_alloc(union bpf_attr *attr)\n{\n\tu32 value_size = attr->value_size;\n\tstruct bpf_stack_map *smap;\n\tu64 cost, n_buckets;\n\tint err;\n\n\tif (!bpf_capable())\n\t\treturn ERR_PTR(-EPERM);\n\n\tif (attr->map_flags & ~STACK_CREATE_FLAG_MASK)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/* check sanity of attributes */\n\tif (attr->max_entries == 0 || attr->key_size != 4 ||\n\t    value_size < 8 || value_size % 8)\n\t\treturn ERR_PTR(-EINVAL);\n\n\tBUILD_BUG_ON(sizeof(struct bpf_stack_build_id) % sizeof(u64));\n\tif (attr->map_flags & BPF_F_STACK_BUILD_ID) {\n\t\tif (value_size % sizeof(struct bpf_stack_build_id) ||\n\t\t    value_size / sizeof(struct bpf_stack_build_id)\n\t\t    > sysctl_perf_event_max_stack)\n\t\t\treturn ERR_PTR(-EINVAL);\n\t} else if (value_size / 8 > sysctl_perf_event_max_stack)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/* hash table size must be power of 2 */\n\tn_buckets = roundup_pow_of_two(attr->max_entries);\n\tif (!n_buckets)\n\t\treturn ERR_PTR(-E2BIG);\n\n\tcost = n_buckets * sizeof(struct stack_map_bucket *) + sizeof(*smap);\n\tcost += n_buckets * (value_size + sizeof(struct stack_map_bucket));\n\tsmap = bpf_map_area_alloc(cost, bpf_map_attr_numa_node(attr));\n\tif (!smap)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tbpf_map_init_from_attr(&smap->map, attr);\n\tsmap->map.value_size = value_size;\n\tsmap->n_buckets = n_buckets;\n\n\terr = get_callchain_buffers(sysctl_perf_event_max_stack);\n\tif (err)\n\t\tgoto free_smap;\n\n\terr = prealloc_elems_and_freelist(smap);\n\tif (err)\n\t\tgoto put_buffers;\n\n\treturn &smap->map;\n\nput_buffers:\n\tput_callchain_buffers();\nfree_smap:\n\tbpf_map_area_free(smap);\n\treturn ERR_PTR(err);\n}"
  },
  {
    "function_name": "prealloc_elems_and_freelist",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "45-67",
    "snippet": "static int prealloc_elems_and_freelist(struct bpf_stack_map *smap)\n{\n\tu64 elem_size = sizeof(struct stack_map_bucket) +\n\t\t\t(u64)smap->map.value_size;\n\tint err;\n\n\tsmap->elems = bpf_map_area_alloc(elem_size * smap->map.max_entries,\n\t\t\t\t\t smap->map.numa_node);\n\tif (!smap->elems)\n\t\treturn -ENOMEM;\n\n\terr = pcpu_freelist_init(&smap->freelist);\n\tif (err)\n\t\tgoto free_elems;\n\n\tpcpu_freelist_populate(&smap->freelist, smap->elems, elem_size,\n\t\t\t       smap->map.max_entries);\n\treturn 0;\n\nfree_elems:\n\tbpf_map_area_free(smap->elems);\n\treturn err;\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "bpf_map_area_free",
          "args": [
            "smap->elems"
          ],
          "line": 65
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_free",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "344-347",
          "snippet": "void bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid bpf_map_area_free(void *area)\n{\n\tkvfree(area);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_populate",
          "args": [
            "&smap->freelist",
            "smap->elems",
            "elem_size",
            "smap->map.max_entries"
          ],
          "line": 60
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_populate",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "101-122",
          "snippet": "void pcpu_freelist_populate(struct pcpu_freelist *s, void *buf, u32 elem_size,\n\t\t\t    u32 nr_elems)\n{\n\tstruct pcpu_freelist_head *head;\n\tint i, cpu, pcpu_entries;\n\n\tpcpu_entries = nr_elems / num_possible_cpus() + 1;\n\ti = 0;\n\n\tfor_each_possible_cpu(cpu) {\nagain:\n\t\thead = per_cpu_ptr(s->freelist, cpu);\n\t\t/* No locking required as this is not visible yet. */\n\t\tpcpu_freelist_push_node(head, buf);\n\t\ti++;\n\t\tbuf += elem_size;\n\t\tif (i == nr_elems)\n\t\t\tbreak;\n\t\tif (i % pcpu_entries)\n\t\t\tgoto again;\n\t}\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nvoid pcpu_freelist_populate(struct pcpu_freelist *s, void *buf, u32 elem_size,\n\t\t\t    u32 nr_elems)\n{\n\tstruct pcpu_freelist_head *head;\n\tint i, cpu, pcpu_entries;\n\n\tpcpu_entries = nr_elems / num_possible_cpus() + 1;\n\ti = 0;\n\n\tfor_each_possible_cpu(cpu) {\nagain:\n\t\thead = per_cpu_ptr(s->freelist, cpu);\n\t\t/* No locking required as this is not visible yet. */\n\t\tpcpu_freelist_push_node(head, buf);\n\t\ti++;\n\t\tbuf += elem_size;\n\t\tif (i == nr_elems)\n\t\t\tbreak;\n\t\tif (i % pcpu_entries)\n\t\t\tgoto again;\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "pcpu_freelist_init",
          "args": [
            "&smap->freelist"
          ],
          "line": 56
        },
        "resolved": true,
        "details": {
          "function_name": "pcpu_freelist_init",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/percpu_freelist.c",
          "lines": "6-23",
          "snippet": "int pcpu_freelist_init(struct pcpu_freelist *s)\n{\n\tint cpu;\n\n\ts->freelist = alloc_percpu(struct pcpu_freelist_head);\n\tif (!s->freelist)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct pcpu_freelist_head *head = per_cpu_ptr(s->freelist, cpu);\n\n\t\traw_spin_lock_init(&head->lock);\n\t\thead->first = NULL;\n\t}\n\traw_spin_lock_init(&s->extralist.lock);\n\ts->extralist.first = NULL;\n\treturn 0;\n}",
          "includes": [
            "#include \"percpu_freelist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"percpu_freelist.h\"\n\nint pcpu_freelist_init(struct pcpu_freelist *s)\n{\n\tint cpu;\n\n\ts->freelist = alloc_percpu(struct pcpu_freelist_head);\n\tif (!s->freelist)\n\t\treturn -ENOMEM;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct pcpu_freelist_head *head = per_cpu_ptr(s->freelist, cpu);\n\n\t\traw_spin_lock_init(&head->lock);\n\t\thead->first = NULL;\n\t}\n\traw_spin_lock_init(&s->extralist.lock);\n\ts->extralist.first = NULL;\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "bpf_map_area_alloc",
          "args": [
            "elem_size * smap->map.max_entries",
            "smap->map.numa_node"
          ],
          "line": 51
        },
        "resolved": true,
        "details": {
          "function_name": "bpf_map_area_alloc",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/syscall.c",
          "lines": "334-337",
          "snippet": "void *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}",
          "includes": [
            "#include <linux/memcontrol.h>",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/bpf-netns.h>",
            "#include <linux/poll.h>",
            "#include <linux/bpf_lsm.h>",
            "#include <linux/pgtable.h>",
            "#include <uapi/linux/btf.h>",
            "#include <linux/audit.h>",
            "#include <linux/nospec.h>",
            "#include <linux/ctype.h>",
            "#include <linux/timekeeping.h>",
            "#include <linux/cred.h>",
            "#include <linux/idr.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/license.h>",
            "#include <linux/fs.h>",
            "#include <linux/file.h>",
            "#include <linux/fdtable.h>",
            "#include <linux/anon_inodes.h>",
            "#include <linux/mmzone.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/slab.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/btf.h>",
            "#include <linux/bpf_verifier.h>",
            "#include <linux/bpf_lirc.h>",
            "#include <linux/bpf_trace.h>",
            "#include <linux/bpf-cgroup.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/memcontrol.h>\n#include <linux/rcupdate_trace.h>\n#include <linux/bpf-netns.h>\n#include <linux/poll.h>\n#include <linux/bpf_lsm.h>\n#include <linux/pgtable.h>\n#include <uapi/linux/btf.h>\n#include <linux/audit.h>\n#include <linux/nospec.h>\n#include <linux/ctype.h>\n#include <linux/timekeeping.h>\n#include <linux/cred.h>\n#include <linux/idr.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/license.h>\n#include <linux/fs.h>\n#include <linux/file.h>\n#include <linux/fdtable.h>\n#include <linux/anon_inodes.h>\n#include <linux/mmzone.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/signal.h>\n#include <linux/slab.h>\n#include <linux/syscalls.h>\n#include <linux/btf.h>\n#include <linux/bpf_verifier.h>\n#include <linux/bpf_lirc.h>\n#include <linux/bpf_trace.h>\n#include <linux/bpf-cgroup.h>\n#include <linux/bpf.h>\n\nvoid *bpf_map_area_alloc(u64 size, int numa_node)\n{\n\treturn __bpf_map_area_alloc(size, numa_node, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic int prealloc_elems_and_freelist(struct bpf_stack_map *smap)\n{\n\tu64 elem_size = sizeof(struct stack_map_bucket) +\n\t\t\t(u64)smap->map.value_size;\n\tint err;\n\n\tsmap->elems = bpf_map_area_alloc(elem_size * smap->map.max_entries,\n\t\t\t\t\t smap->map.numa_node);\n\tif (!smap->elems)\n\t\treturn -ENOMEM;\n\n\terr = pcpu_freelist_init(&smap->freelist);\n\tif (err)\n\t\tgoto free_elems;\n\n\tpcpu_freelist_populate(&smap->freelist, smap->elems, elem_size,\n\t\t\t       smap->map.max_entries);\n\treturn 0;\n\nfree_elems:\n\tbpf_map_area_free(smap->elems);\n\treturn err;\n}"
  },
  {
    "function_name": "stack_map_data_size",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "39-43",
    "snippet": "static inline int stack_map_data_size(struct bpf_map *map)\n{\n\treturn stack_map_use_build_id(map) ?\n\t\tsizeof(struct bpf_stack_build_id) : sizeof(u64);\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "stack_map_use_build_id",
          "args": [
            "map"
          ],
          "line": 41
        },
        "resolved": true,
        "details": {
          "function_name": "stack_map_use_build_id",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
          "lines": "34-37",
          "snippet": "static inline bool stack_map_use_build_id(struct bpf_map *map)\n{\n\treturn (map->map_flags & BPF_F_STACK_BUILD_ID);\n}",
          "includes": [
            "#include \"mmap_unlock_work.h\"",
            "#include \"percpu_freelist.h\"",
            "#include <linux/buildid.h>",
            "#include <linux/btf_ids.h>",
            "#include <linux/perf_event.h>",
            "#include <linux/stacktrace.h>",
            "#include <linux/kernel.h>",
            "#include <linux/filter.h>",
            "#include <linux/jhash.h>",
            "#include <linux/bpf.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic inline bool stack_map_use_build_id(struct bpf_map *map)\n{\n\treturn (map->map_flags & BPF_F_STACK_BUILD_ID);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic inline int stack_map_data_size(struct bpf_map *map)\n{\n\treturn stack_map_use_build_id(map) ?\n\t\tsizeof(struct bpf_stack_build_id) : sizeof(u64);\n}"
  },
  {
    "function_name": "stack_map_use_build_id",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/bpf/stackmap.c",
    "lines": "34-37",
    "snippet": "static inline bool stack_map_use_build_id(struct bpf_map *map)\n{\n\treturn (map->map_flags & BPF_F_STACK_BUILD_ID);\n}",
    "includes": [
      "#include \"mmap_unlock_work.h\"",
      "#include \"percpu_freelist.h\"",
      "#include <linux/buildid.h>",
      "#include <linux/btf_ids.h>",
      "#include <linux/perf_event.h>",
      "#include <linux/stacktrace.h>",
      "#include <linux/kernel.h>",
      "#include <linux/filter.h>",
      "#include <linux/jhash.h>",
      "#include <linux/bpf.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"mmap_unlock_work.h\"\n#include \"percpu_freelist.h\"\n#include <linux/buildid.h>\n#include <linux/btf_ids.h>\n#include <linux/perf_event.h>\n#include <linux/stacktrace.h>\n#include <linux/kernel.h>\n#include <linux/filter.h>\n#include <linux/jhash.h>\n#include <linux/bpf.h>\n\nstatic inline bool stack_map_use_build_id(struct bpf_map *map)\n{\n\treturn (map->map_flags & BPF_F_STACK_BUILD_ID);\n}"
  }
]