[
  {
    "function_name": "rcu_dynticks_task_trace_exit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1323-1329",
    "snippet": "static __always_inline void rcu_dynticks_task_trace_exit(void)\n{\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\tcurrent->trc_reader_special.b.need_mb = false;\n#endif /* #ifdef CONFIG_TASKS_TRACE_RCU */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_TASKS_TRACE_RCU_READ_MB"
          ],
          "line": 1326
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic __always_inline void rcu_dynticks_task_trace_exit(void)\n{\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\tcurrent->trc_reader_special.b.need_mb = false;\n#endif /* #ifdef CONFIG_TASKS_TRACE_RCU */\n}"
  },
  {
    "function_name": "rcu_dynticks_task_trace_enter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1314-1320",
    "snippet": "static __always_inline void rcu_dynticks_task_trace_enter(void)\n{\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\tcurrent->trc_reader_special.b.need_mb = true;\n#endif /* #ifdef CONFIG_TASKS_TRACE_RCU */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_TASKS_TRACE_RCU_READ_MB"
          ],
          "line": 1317
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic __always_inline void rcu_dynticks_task_trace_enter(void)\n{\n#ifdef CONFIG_TASKS_TRACE_RCU\n\tif (IS_ENABLED(CONFIG_TASKS_TRACE_RCU_READ_MB))\n\t\tcurrent->trc_reader_special.b.need_mb = true;\n#endif /* #ifdef CONFIG_TASKS_TRACE_RCU */\n}"
  },
  {
    "function_name": "rcu_dynticks_task_exit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1306-1311",
    "snippet": "static __always_inline void rcu_dynticks_task_exit(void)\n{\n#if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL)\n\tWRITE_ONCE(current->rcu_tasks_idle_cpu, -1);\n#endif /* #if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL) */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_tasks_idle_cpu",
            "-1"
          ],
          "line": 1309
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic __always_inline void rcu_dynticks_task_exit(void)\n{\n#if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL)\n\tWRITE_ONCE(current->rcu_tasks_idle_cpu, -1);\n#endif /* #if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL) */\n}"
  },
  {
    "function_name": "rcu_dynticks_task_enter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1298-1303",
    "snippet": "static __always_inline void rcu_dynticks_task_enter(void)\n{\n#if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL)\n\tWRITE_ONCE(current->rcu_tasks_idle_cpu, smp_processor_id());\n#endif /* #if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL) */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_tasks_idle_cpu",
            "smp_processor_id()"
          ],
          "line": 1301
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 1301
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic __always_inline void rcu_dynticks_task_enter(void)\n{\n#if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL)\n\tWRITE_ONCE(current->rcu_tasks_idle_cpu, smp_processor_id());\n#endif /* #if defined(CONFIG_TASKS_RCU) && defined(CONFIG_NO_HZ_FULL) */\n}"
  },
  {
    "function_name": "rcu_bind_gp_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1290-1295",
    "snippet": "static void rcu_bind_gp_kthread(void)\n{\n\tif (!tick_nohz_full_enabled())\n\t\treturn;\n\thousekeeping_affine(current, HK_FLAG_RCU);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "housekeeping_affine",
          "args": [
            "current",
            "HK_FLAG_RCU"
          ],
          "line": 1294
        },
        "resolved": true,
        "details": {
          "function_name": "housekeeping_affine",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/isolation.c",
          "lines": "49-54",
          "snippet": "void housekeeping_affine(struct task_struct *t, enum hk_flags flags)\n{\n\tif (static_branch_unlikely(&housekeeping_overridden))\n\t\tif (housekeeping_flags & flags)\n\t\t\tset_cpus_allowed_ptr(t, housekeeping_mask);\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static cpumask_var_t housekeeping_mask;",
            "static unsigned int housekeeping_flags;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic cpumask_var_t housekeeping_mask;\nstatic unsigned int housekeeping_flags;\n\nvoid housekeeping_affine(struct task_struct *t, enum hk_flags flags)\n{\n\tif (static_branch_unlikely(&housekeeping_overridden))\n\t\tif (housekeeping_flags & flags)\n\t\t\tset_cpus_allowed_ptr(t, housekeeping_mask);\n}"
        }
      },
      {
        "call_info": {
          "callee": "tick_nohz_full_enabled",
          "args": [],
          "line": 1292
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_bind_gp_kthread(void)\n{\n\tif (!tick_nohz_full_enabled())\n\t\treturn;\n\thousekeeping_affine(current, HK_FLAG_RCU);\n}"
  },
  {
    "function_name": "rcu_nohz_full_cpu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1276-1285",
    "snippet": "static bool rcu_nohz_full_cpu(void)\n{\n#ifdef CONFIG_NO_HZ_FULL\n\tif (tick_nohz_full_cpu(smp_processor_id()) &&\n\t    (!rcu_gp_in_progress() ||\n\t     time_before(jiffies, READ_ONCE(rcu_state.gp_start) + HZ)))\n\t\treturn true;\n#endif /* #ifdef CONFIG_NO_HZ_FULL */\n\treturn false;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "time_before",
          "args": [
            "jiffies",
            "READ_ONCE(rcu_state.gp_start) + HZ"
          ],
          "line": 1281
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rcu_state.gp_start"
          ],
          "line": 1281
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_gp_in_progress",
          "args": [],
          "line": 1280
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_gp_in_progress",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "229-232",
          "snippet": "static int rcu_gp_in_progress(void)\n{\n\treturn rcu_seq_state(rcu_seq_current(&rcu_state.gp_seq));\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};\n\nstatic int rcu_gp_in_progress(void)\n{\n\treturn rcu_seq_state(rcu_seq_current(&rcu_state.gp_seq));\n}"
        }
      },
      {
        "call_info": {
          "callee": "tick_nohz_full_cpu",
          "args": [
            "smp_processor_id()"
          ],
          "line": 1279
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_processor_id",
          "args": [],
          "line": 1279
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_nohz_full_cpu(void)\n{\n#ifdef CONFIG_NO_HZ_FULL\n\tif (tick_nohz_full_cpu(smp_processor_id()) &&\n\t    (!rcu_gp_in_progress() ||\n\t     time_before(jiffies, READ_ONCE(rcu_state.gp_start) + HZ)))\n\t\treturn true;\n#endif /* #ifdef CONFIG_NO_HZ_FULL */\n\treturn false;\n}"
  },
  {
    "function_name": "rcu_spawn_boost_kthreads",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1261-1263",
    "snippet": "static void __init rcu_spawn_boost_kthreads(void)\n{\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_spawn_boost_kthreads(void)\n{\n}"
  },
  {
    "function_name": "rcu_boost_kthread_setaffinity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1257-1259",
    "snippet": "static void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu)\n{\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu)\n{\n}"
  },
  {
    "function_name": "rcu_spawn_one_boost_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1253-1255",
    "snippet": "static void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)\n{\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)\n{\n}"
  },
  {
    "function_name": "rcu_preempt_boost_start_gp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1249-1251",
    "snippet": "static void rcu_preempt_boost_start_gp(struct rcu_node *rnp)\n{\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_boost_start_gp(struct rcu_node *rnp)\n{\n}"
  },
  {
    "function_name": "rcu_is_callbacks_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1244-1247",
    "snippet": "static bool rcu_is_callbacks_kthread(void)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_is_callbacks_kthread(void)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "rcu_initiate_boost",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1238-1242",
    "snippet": "static void rcu_initiate_boost(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1241
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__releases",
          "args": [
            "rnp->lock"
          ],
          "line": 1239
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_initiate_boost(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n}"
  },
  {
    "function_name": "rcu_spawn_boost_kthreads",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1227-1234",
    "snippet": "static void __init rcu_spawn_boost_kthreads(void)\n{\n\tstruct rcu_node *rnp;\n\n\trcu_for_each_leaf_node(rnp)\n\t\tif (rcu_rnp_online_cpus(rnp))\n\t\t\trcu_spawn_one_boost_kthread(rnp);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_spawn_one_boost_kthread",
          "args": [
            "rnp"
          ],
          "line": 1233
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_spawn_one_boost_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "1253-1255",
          "snippet": "static void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)\n{\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)\n{\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_spawn_boost_kthreads(void)\n{\n\tstruct rcu_node *rnp;\n\n\trcu_for_each_leaf_node(rnp)\n\t\tif (rcu_rnp_online_cpus(rnp))\n\t\t\trcu_spawn_one_boost_kthread(rnp);\n}"
  },
  {
    "function_name": "rcu_boost_kthread_setaffinity",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1202-1222",
    "snippet": "static void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu)\n{\n\tstruct task_struct *t = rnp->boost_kthread_task;\n\tunsigned long mask = rcu_rnp_online_cpus(rnp);\n\tcpumask_var_t cm;\n\tint cpu;\n\n\tif (!t)\n\t\treturn;\n\tif (!zalloc_cpumask_var(&cm, GFP_KERNEL))\n\t\treturn;\n\tfor_each_leaf_node_possible_cpu(rnp, cpu)\n\t\tif ((mask & leaf_node_cpu_bit(rnp, cpu)) &&\n\t\t    cpu != outgoingcpu)\n\t\t\tcpumask_set_cpu(cpu, cm);\n\tcpumask_and(cm, cm, housekeeping_cpumask(HK_FLAG_RCU));\n\tif (cpumask_weight(cm) == 0)\n\t\tcpumask_copy(cm, housekeeping_cpumask(HK_FLAG_RCU));\n\tset_cpus_allowed_ptr(t, cm);\n\tfree_cpumask_var(cm);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "free_cpumask_var",
          "args": [
            "cm"
          ],
          "line": 1221
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_cpus_allowed_ptr",
          "args": [
            "t",
            "cm"
          ],
          "line": 1220
        },
        "resolved": true,
        "details": {
          "function_name": "set_cpus_allowed_ptr",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "2888-2891",
          "snippet": "int set_cpus_allowed_ptr(struct task_struct *p, const struct cpumask *new_mask)\n{\n\treturn __set_cpus_allowed_ptr(p, new_mask, 0);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint set_cpus_allowed_ptr(struct task_struct *p, const struct cpumask *new_mask)\n{\n\treturn __set_cpus_allowed_ptr(p, new_mask, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_copy",
          "args": [
            "cm",
            "housekeeping_cpumask(HK_FLAG_RCU)"
          ],
          "line": 1219
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "housekeeping_cpumask",
          "args": [
            "HK_FLAG_RCU"
          ],
          "line": 1219
        },
        "resolved": true,
        "details": {
          "function_name": "housekeeping_cpumask",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/isolation.c",
          "lines": "40-46",
          "snippet": "const struct cpumask *housekeeping_cpumask(enum hk_flags flags)\n{\n\tif (static_branch_unlikely(&housekeeping_overridden))\n\t\tif (housekeeping_flags & flags)\n\t\t\treturn housekeeping_mask;\n\treturn cpu_possible_mask;\n}",
          "includes": [
            "#include \"sched.h\""
          ],
          "macros_used": [],
          "globals_used": [
            "static cpumask_var_t housekeeping_mask;",
            "static unsigned int housekeeping_flags;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"sched.h\"\n\nstatic cpumask_var_t housekeeping_mask;\nstatic unsigned int housekeeping_flags;\n\nconst struct cpumask *housekeeping_cpumask(enum hk_flags flags)\n{\n\tif (static_branch_unlikely(&housekeeping_overridden))\n\t\tif (housekeeping_flags & flags)\n\t\t\treturn housekeeping_mask;\n\treturn cpu_possible_mask;\n}"
        }
      },
      {
        "call_info": {
          "callee": "cpumask_weight",
          "args": [
            "cm"
          ],
          "line": 1218
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_and",
          "args": [
            "cm",
            "cm",
            "housekeeping_cpumask(HK_FLAG_RCU)"
          ],
          "line": 1217
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpumask_set_cpu",
          "args": [
            "cpu",
            "cm"
          ],
          "line": 1216
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "leaf_node_cpu_bit",
          "args": [
            "rnp",
            "cpu"
          ],
          "line": 1214
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "for_each_leaf_node_possible_cpu",
          "args": [
            "rnp",
            "cpu"
          ],
          "line": 1213
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "zalloc_cpumask_var",
          "args": [
            "&cm",
            "GFP_KERNEL"
          ],
          "line": 1211
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_rnp_online_cpus",
          "args": [
            "rnp"
          ],
          "line": 1205
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_rnp_online_cpus",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "219-222",
          "snippet": "static unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->qsmaskinitnext);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);\n\nstatic unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->qsmaskinitnext);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_boost_kthread_setaffinity(struct rcu_node *rnp, int outgoingcpu)\n{\n\tstruct task_struct *t = rnp->boost_kthread_task;\n\tunsigned long mask = rcu_rnp_online_cpus(rnp);\n\tcpumask_var_t cm;\n\tint cpu;\n\n\tif (!t)\n\t\treturn;\n\tif (!zalloc_cpumask_var(&cm, GFP_KERNEL))\n\t\treturn;\n\tfor_each_leaf_node_possible_cpu(rnp, cpu)\n\t\tif ((mask & leaf_node_cpu_bit(rnp, cpu)) &&\n\t\t    cpu != outgoingcpu)\n\t\t\tcpumask_set_cpu(cpu, cm);\n\tcpumask_and(cm, cm, housekeeping_cpumask(HK_FLAG_RCU));\n\tif (cpumask_weight(cm) == 0)\n\t\tcpumask_copy(cm, housekeeping_cpumask(HK_FLAG_RCU));\n\tset_cpus_allowed_ptr(t, cm);\n\tfree_cpumask_var(cm);\n}"
  },
  {
    "function_name": "rcu_spawn_one_boost_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1168-1191",
    "snippet": "static void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tint rnp_index = rnp - rcu_get_root();\n\tstruct sched_param sp;\n\tstruct task_struct *t;\n\n\tif (rnp->boost_kthread_task || !rcu_scheduler_fully_active)\n\t\treturn;\n\n\trcu_state.boost = 1;\n\n\tt = kthread_create(rcu_boost_kthread, (void *)rnp,\n\t\t\t   \"rcub/%d\", rnp_index);\n\tif (WARN_ON_ONCE(IS_ERR(t)))\n\t\treturn;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\trnp->boost_kthread_task = t;\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\tsp.sched_priority = kthread_prio;\n\tsched_setscheduler_nocheck(t, SCHED_FIFO, &sp);\n\twake_up_process(t); /* get to TASK_INTERRUPTIBLE quickly. */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "wake_up_process",
          "args": [
            "t"
          ],
          "line": 1190
        },
        "resolved": true,
        "details": {
          "function_name": "wake_up_process",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "4215-4218",
          "snippet": "int wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint wake_up_process(struct task_struct *p)\n{\n\treturn try_to_wake_up(p, TASK_NORMAL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "sched_setscheduler_nocheck",
          "args": [
            "t",
            "SCHED_FIFO",
            "&sp"
          ],
          "line": 1189
        },
        "resolved": true,
        "details": {
          "function_name": "sched_setscheduler_nocheck",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "7565-7569",
          "snippet": "int sched_setscheduler_nocheck(struct task_struct *p, int policy,\n\t\t\t       const struct sched_param *param)\n{\n\treturn _sched_setscheduler(p, policy, param, false);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint sched_setscheduler_nocheck(struct task_struct *p, int policy,\n\t\t\t       const struct sched_param *param)\n{\n\treturn _sched_setscheduler(p, policy, param, false);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1187
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1185
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "IS_ERR(t)"
          ],
          "line": 1182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ERR",
          "args": [
            "t"
          ],
          "line": 1182
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kthread_create",
          "args": [
            "rcu_boost_kthread",
            "(void *)rnp",
            "\"rcub/%d\"",
            "rnp_index"
          ],
          "line": 1180
        },
        "resolved": true,
        "details": {
          "function_name": "kthread_create_worker",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kthread.c",
          "lines": "882-893",
          "snippet": "struct kthread_worker *\nkthread_create_worker(unsigned int flags, const char namefmt[], ...)\n{\n\tstruct kthread_worker *worker;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\tworker = __kthread_create_worker(-1, flags, namefmt, args);\n\tva_end(args);\n\n\treturn worker;\n}",
          "includes": [
            "#include <trace/events/sched.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/numa.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/ptrace.h>",
            "#include <linux/freezer.h>",
            "#include <linux/slab.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/file.h>",
            "#include <linux/unistd.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/err.h>",
            "#include <linux/completion.h>",
            "#include <linux/kthread.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/sched.h>",
            "#include <linux/mmu_context.h>",
            "#include <linux/mm.h>",
            "#include <uapi/linux/sched/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;",
            "static __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/sched.h>\n#include <linux/sched/isolation.h>\n#include <linux/numa.h>\n#include <linux/uaccess.h>\n#include <linux/ptrace.h>\n#include <linux/freezer.h>\n#include <linux/slab.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/file.h>\n#include <linux/unistd.h>\n#include <linux/cpuset.h>\n#include <linux/cgroup.h>\n#include <linux/err.h>\n#include <linux/completion.h>\n#include <linux/kthread.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/sched.h>\n#include <linux/mmu_context.h>\n#include <linux/mm.h>\n#include <uapi/linux/sched/types.h>\n\nstatic __printf(4, 0)\nstruct task_struct *__kthread_create_on_node(int (*threadfn)(void *data),\n\t\t\t\t\t\t    void *data, int node,\n\t\t\t\t\t\t    const char namefmt[],\n\t\t\t\t\t\t    va_list args)\n{\n\tDECLARE_COMPLETION_ONSTACK(done);\n\tstruct task_struct *task;\nstatic __printf(3, 0) struct kthread_worker *\n__kthread_create_worker(int cpu, unsigned int flags,\n\t\t\tconst char namefmt[], va_list args)\n{\n\tstruct kthread_worker *worker;\n\nstruct kthread_worker *\nkthread_create_worker(unsigned int flags, const char namefmt[], ...)\n{\n\tstruct kthread_worker *worker;\n\tva_list args;\n\n\tva_start(args, namefmt);\n\tworker = __kthread_create_worker(-1, flags, namefmt, args);\n\tva_end(args);\n\n\treturn worker;\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_get_root",
          "args": [],
          "line": 1171
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_get_root",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "579-582",
          "snippet": "static struct rcu_node *rcu_get_root(void)\n{\n\treturn &rcu_state.node[0];\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic struct rcu_state rcu_state = {\n\t.level = { &rcu_state.node[0] },\n\t.gp_state = RCU_GP_IDLE,\n\t.gp_seq = (0UL - 300UL) << RCU_SEQ_CTR_SHIFT,\n\t.barrier_mutex = __MUTEX_INITIALIZER(rcu_state.barrier_mutex),\n\t.name = RCU_NAME,\n\t.abbr = RCU_ABBR,\n\t.exp_mutex = __MUTEX_INITIALIZER(rcu_state.exp_mutex),\n\t.exp_wake_mutex = __MUTEX_INITIALIZER(rcu_state.exp_wake_mutex),\n\t.ofl_lock = __RAW_SPIN_LOCK_UNLOCKED(rcu_state.ofl_lock),\n};\n\nstatic struct rcu_node *rcu_get_root(void)\n{\n\treturn &rcu_state.node[0];\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_spawn_one_boost_kthread(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tint rnp_index = rnp - rcu_get_root();\n\tstruct sched_param sp;\n\tstruct task_struct *t;\n\n\tif (rnp->boost_kthread_task || !rcu_scheduler_fully_active)\n\t\treturn;\n\n\trcu_state.boost = 1;\n\n\tt = kthread_create(rcu_boost_kthread, (void *)rnp,\n\t\t\t   \"rcub/%d\", rnp_index);\n\tif (WARN_ON_ONCE(IS_ERR(t)))\n\t\treturn;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\trnp->boost_kthread_task = t;\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\tsp.sched_priority = kthread_prio;\n\tsched_setscheduler_nocheck(t, SCHED_FIFO, &sp);\n\twake_up_process(t); /* get to TASK_INTERRUPTIBLE quickly. */\n}"
  },
  {
    "function_name": "rcu_preempt_boost_start_gp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1159-1162",
    "snippet": "static void rcu_preempt_boost_start_gp(struct rcu_node *rnp)\n{\n\trnp->boost_time = jiffies + RCU_BOOST_DELAY_JIFFIES;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [
      "#define RCU_BOOST_DELAY_JIFFIES DIV_ROUND_UP(CONFIG_RCU_BOOST_DELAY * HZ, 1000)"
    ],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\n#define RCU_BOOST_DELAY_JIFFIES DIV_ROUND_UP(CONFIG_RCU_BOOST_DELAY * HZ, 1000)\n\nstatic void rcu_preempt_boost_start_gp(struct rcu_node *rnp)\n{\n\trnp->boost_time = jiffies + RCU_BOOST_DELAY_JIFFIES;\n}"
  },
  {
    "function_name": "rcu_is_callbacks_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1149-1152",
    "snippet": "static bool rcu_is_callbacks_kthread(void)\n{\n\treturn __this_cpu_read(rcu_data.rcu_cpu_kthread_task) == current;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.rcu_cpu_kthread_task"
          ],
          "line": 1151
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_is_callbacks_kthread(void)\n{\n\treturn __this_cpu_read(rcu_data.rcu_cpu_kthread_task) == current;\n}"
  },
  {
    "function_name": "rcu_initiate_boost",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1122-1143",
    "snippet": "static void rcu_initiate_boost(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tif (!rcu_preempt_blocked_readers_cgp(rnp) && rnp->exp_tasks == NULL) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tif (rnp->exp_tasks != NULL ||\n\t    (rnp->gp_tasks != NULL &&\n\t     rnp->boost_tasks == NULL &&\n\t     rnp->qsmask == 0 &&\n\t     (!time_after(rnp->boost_time, jiffies) || rcu_state.cbovld))) {\n\t\tif (rnp->exp_tasks == NULL)\n\t\t\tWRITE_ONCE(rnp->boost_tasks, rnp->gp_tasks);\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\trcu_wake_cond(rnp->boost_kthread_task,\n\t\t\t      READ_ONCE(rnp->boost_kthread_status));\n\t} else {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t}\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1141
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_wake_cond",
          "args": [
            "rnp->boost_kthread_task",
            "READ_ONCE(rnp->boost_kthread_status)"
          ],
          "line": 1138
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_wake_cond",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "2798-2806",
          "snippet": "static void rcu_wake_cond(struct task_struct *t, int status)\n{\n\t/*\n\t * If the thread is yielding, only wake it when this\n\t * is invoked from idle\n\t */\n\tif (t && (status != RCU_KTHREAD_YIELDING || is_idle_task(current)))\n\t\twake_up_process(t);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic void rcu_wake_cond(struct task_struct *t, int status)\n{\n\t/*\n\t * If the thread is yielding, only wake it when this\n\t * is invoked from idle\n\t */\n\tif (t && (status != RCU_KTHREAD_YIELDING || is_idle_task(current)))\n\t\twake_up_process(t);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->boost_kthread_status"
          ],
          "line": 1139
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1137
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->boost_tasks",
            "rnp->gp_tasks"
          ],
          "line": 1136
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "time_after",
          "args": [
            "rnp->boost_time",
            "jiffies"
          ],
          "line": 1134
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1127
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_blocked_readers_cgp",
          "args": [
            "rnp"
          ],
          "line": 1126
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_blocked_readers_cgp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "907-910",
          "snippet": "static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_lockdep_assert_held_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 1125
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__releases",
          "args": [
            "rnp->lock"
          ],
          "line": 1123
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_initiate_boost(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tif (!rcu_preempt_blocked_readers_cgp(rnp) && rnp->exp_tasks == NULL) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tif (rnp->exp_tasks != NULL ||\n\t    (rnp->gp_tasks != NULL &&\n\t     rnp->boost_tasks == NULL &&\n\t     rnp->qsmask == 0 &&\n\t     (!time_after(rnp->boost_time, jiffies) || rcu_state.cbovld))) {\n\t\tif (rnp->exp_tasks == NULL)\n\t\t\tWRITE_ONCE(rnp->boost_tasks, rnp->gp_tasks);\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\trcu_wake_cond(rnp->boost_kthread_task,\n\t\t\t      READ_ONCE(rnp->boost_kthread_status));\n\t} else {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t}\n}"
  },
  {
    "function_name": "rcu_boost_kthread",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1080-1110",
    "snippet": "static int rcu_boost_kthread(void *arg)\n{\n\tstruct rcu_node *rnp = (struct rcu_node *)arg;\n\tint spincnt = 0;\n\tint more2boost;\n\n\ttrace_rcu_utilization(TPS(\"Start boost kthread@init\"));\n\tfor (;;) {\n\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_WAITING);\n\t\ttrace_rcu_utilization(TPS(\"End boost kthread@rcu_wait\"));\n\t\trcu_wait(READ_ONCE(rnp->boost_tasks) ||\n\t\t\t READ_ONCE(rnp->exp_tasks));\n\t\ttrace_rcu_utilization(TPS(\"Start boost kthread@rcu_wait\"));\n\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_RUNNING);\n\t\tmore2boost = rcu_boost(rnp);\n\t\tif (more2boost)\n\t\t\tspincnt++;\n\t\telse\n\t\t\tspincnt = 0;\n\t\tif (spincnt > 10) {\n\t\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_YIELDING);\n\t\t\ttrace_rcu_utilization(TPS(\"End boost kthread@rcu_yield\"));\n\t\t\tschedule_timeout_idle(2);\n\t\t\ttrace_rcu_utilization(TPS(\"Start boost kthread@rcu_yield\"));\n\t\t\tspincnt = 0;\n\t\t}\n\t}\n\t/* NOTREACHED */\n\ttrace_rcu_utilization(TPS(\"End boost kthread@notreached\"));\n\treturn 0;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"End boost kthread@notreached\")"
          ],
          "line": 1108
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"End boost kthread@notreached\""
          ],
          "line": 1108
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"Start boost kthread@rcu_yield\")"
          ],
          "line": 1103
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"Start boost kthread@rcu_yield\""
          ],
          "line": 1103
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "schedule_timeout_idle",
          "args": [
            "2"
          ],
          "line": 1102
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_timeout_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/time/timer.c",
          "lines": "1923-1927",
          "snippet": "signed long __sched schedule_timeout_idle(signed long timeout)\n{\n\t__set_current_state(TASK_IDLE);\n\treturn schedule_timeout(timeout);\n}",
          "includes": [
            "#include <trace/events/timer.h>",
            "#include \"tick-internal.h\"",
            "#include <asm/io.h>",
            "#include <asm/timex.h>",
            "#include <asm/div64.h>",
            "#include <asm/unistd.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/random.h>",
            "#include <linux/compat.h>",
            "#include <linux/slab.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/nohz.h>",
            "#include <linux/sched/sysctl.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/kallsyms.h>",
            "#include <linux/tick.h>",
            "#include <linux/delay.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/cpu.h>",
            "#include <linux/posix-timers.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/time.h>",
            "#include <linux/thread_info.h>",
            "#include <linux/notifier.h>",
            "#include <linux/pid_namespace.h>",
            "#include <linux/swap.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/percpu.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/timer.h>\n#include \"tick-internal.h\"\n#include <asm/io.h>\n#include <asm/timex.h>\n#include <asm/div64.h>\n#include <asm/unistd.h>\n#include <linux/uaccess.h>\n#include <linux/random.h>\n#include <linux/compat.h>\n#include <linux/slab.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/nohz.h>\n#include <linux/sched/sysctl.h>\n#include <linux/sched/signal.h>\n#include <linux/irq_work.h>\n#include <linux/kallsyms.h>\n#include <linux/tick.h>\n#include <linux/delay.h>\n#include <linux/syscalls.h>\n#include <linux/cpu.h>\n#include <linux/posix-timers.h>\n#include <linux/jiffies.h>\n#include <linux/time.h>\n#include <linux/thread_info.h>\n#include <linux/notifier.h>\n#include <linux/pid_namespace.h>\n#include <linux/swap.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/percpu.h>\n#include <linux/interrupt.h>\n#include <linux/export.h>\n#include <linux/kernel_stat.h>\n\nsigned long __sched schedule_timeout_idle(signed long timeout)\n{\n\t__set_current_state(TASK_IDLE);\n\treturn schedule_timeout(timeout);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"End boost kthread@rcu_yield\")"
          ],
          "line": 1101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"End boost kthread@rcu_yield\""
          ],
          "line": 1101
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->boost_kthread_status",
            "RCU_KTHREAD_YIELDING"
          ],
          "line": 1100
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_boost",
          "args": [
            "rnp"
          ],
          "line": 1094
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_boost_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "1080-1110",
          "snippet": "static int rcu_boost_kthread(void *arg)\n{\n\tstruct rcu_node *rnp = (struct rcu_node *)arg;\n\tint spincnt = 0;\n\tint more2boost;\n\n\ttrace_rcu_utilization(TPS(\"Start boost kthread@init\"));\n\tfor (;;) {\n\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_WAITING);\n\t\ttrace_rcu_utilization(TPS(\"End boost kthread@rcu_wait\"));\n\t\trcu_wait(READ_ONCE(rnp->boost_tasks) ||\n\t\t\t READ_ONCE(rnp->exp_tasks));\n\t\ttrace_rcu_utilization(TPS(\"Start boost kthread@rcu_wait\"));\n\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_RUNNING);\n\t\tmore2boost = rcu_boost(rnp);\n\t\tif (more2boost)\n\t\t\tspincnt++;\n\t\telse\n\t\t\tspincnt = 0;\n\t\tif (spincnt > 10) {\n\t\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_YIELDING);\n\t\t\ttrace_rcu_utilization(TPS(\"End boost kthread@rcu_yield\"));\n\t\t\tschedule_timeout_idle(2);\n\t\t\ttrace_rcu_utilization(TPS(\"Start boost kthread@rcu_yield\"));\n\t\t\tspincnt = 0;\n\t\t}\n\t}\n\t/* NOTREACHED */\n\ttrace_rcu_utilization(TPS(\"End boost kthread@notreached\"));\n\treturn 0;\n}",
          "note": "cyclic_reference_detected"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->boost_kthread_status",
            "RCU_KTHREAD_RUNNING"
          ],
          "line": 1093
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"Start boost kthread@rcu_wait\")"
          ],
          "line": 1092
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"Start boost kthread@rcu_wait\""
          ],
          "line": 1092
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_wait",
          "args": [
            "READ_ONCE(rnp->boost_tasks) ||\n\t\t\t READ_ONCE(rnp->exp_tasks)"
          ],
          "line": 1090
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->exp_tasks"
          ],
          "line": 1091
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->boost_tasks"
          ],
          "line": 1090
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"End boost kthread@rcu_wait\")"
          ],
          "line": 1089
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"End boost kthread@rcu_wait\""
          ],
          "line": 1089
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->boost_kthread_status",
            "RCU_KTHREAD_WAITING"
          ],
          "line": 1088
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"Start boost kthread@init\")"
          ],
          "line": 1086
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"Start boost kthread@init\""
          ],
          "line": 1086
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_boost_kthread(void *arg)\n{\n\tstruct rcu_node *rnp = (struct rcu_node *)arg;\n\tint spincnt = 0;\n\tint more2boost;\n\n\ttrace_rcu_utilization(TPS(\"Start boost kthread@init\"));\n\tfor (;;) {\n\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_WAITING);\n\t\ttrace_rcu_utilization(TPS(\"End boost kthread@rcu_wait\"));\n\t\trcu_wait(READ_ONCE(rnp->boost_tasks) ||\n\t\t\t READ_ONCE(rnp->exp_tasks));\n\t\ttrace_rcu_utilization(TPS(\"Start boost kthread@rcu_wait\"));\n\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_RUNNING);\n\t\tmore2boost = rcu_boost(rnp);\n\t\tif (more2boost)\n\t\t\tspincnt++;\n\t\telse\n\t\t\tspincnt = 0;\n\t\tif (spincnt > 10) {\n\t\t\tWRITE_ONCE(rnp->boost_kthread_status, RCU_KTHREAD_YIELDING);\n\t\t\ttrace_rcu_utilization(TPS(\"End boost kthread@rcu_yield\"));\n\t\t\tschedule_timeout_idle(2);\n\t\t\ttrace_rcu_utilization(TPS(\"Start boost kthread@rcu_yield\"));\n\t\t\tspincnt = 0;\n\t\t}\n\t}\n\t/* NOTREACHED */\n\ttrace_rcu_utilization(TPS(\"End boost kthread@notreached\"));\n\treturn 0;\n}"
  },
  {
    "function_name": "rcu_boost",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "1017-1075",
    "snippet": "static int rcu_boost(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tstruct task_struct *t;\n\tstruct list_head *tb;\n\n\tif (READ_ONCE(rnp->exp_tasks) == NULL &&\n\t    READ_ONCE(rnp->boost_tasks) == NULL)\n\t\treturn 0;  /* Nothing left to boost. */\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\n\t/*\n\t * Recheck under the lock: all tasks in need of boosting\n\t * might exit their RCU read-side critical sections on their own.\n\t */\n\tif (rnp->exp_tasks == NULL && rnp->boost_tasks == NULL) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Preferentially boost tasks blocking expedited grace periods.\n\t * This cannot starve the normal grace periods because a second\n\t * expedited grace period must boost all blocked tasks, including\n\t * those blocking the pre-existing normal grace period.\n\t */\n\tif (rnp->exp_tasks != NULL)\n\t\ttb = rnp->exp_tasks;\n\telse\n\t\ttb = rnp->boost_tasks;\n\n\t/*\n\t * We boost task t by manufacturing an rt_mutex that appears to\n\t * be held by task t.  We leave a pointer to that rt_mutex where\n\t * task t can find it, and task t will release the mutex when it\n\t * exits its outermost RCU read-side critical section.  Then\n\t * simply acquiring this artificial rt_mutex will boost task\n\t * t's priority.  (Thanks to tglx for suggesting this approach!)\n\t *\n\t * Note that task t must acquire rnp->lock to remove itself from\n\t * the ->blkd_tasks list, which it will do from exit() if from\n\t * nowhere else.  We therefore are guaranteed that task t will\n\t * stay around at least until we drop rnp->lock.  Note that\n\t * rnp->lock also resolves races between our priority boosting\n\t * and task t's exiting its outermost RCU read-side critical\n\t * section.\n\t */\n\tt = container_of(tb, struct task_struct, rcu_node_entry);\n\trt_mutex_init_proxy_locked(&rnp->boost_mtx.rtmutex, t);\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t/* Lock only for side effect: boosts task t's priority. */\n\trt_mutex_lock(&rnp->boost_mtx);\n\trt_mutex_unlock(&rnp->boost_mtx);  /* Then keep lockdep happy. */\n\trnp->n_boosts++;\n\n\treturn READ_ONCE(rnp->exp_tasks) != NULL ||\n\t       READ_ONCE(rnp->boost_tasks) != NULL;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->boost_tasks"
          ],
          "line": 1074
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->exp_tasks"
          ],
          "line": 1073
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_unlock",
          "args": [
            "&rnp->boost_mtx"
          ],
          "line": 1070
        },
        "resolved": true,
        "details": {
          "function_name": "__rt_mutex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex.c",
          "lines": "1350-1356",
          "snippet": "static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}",
          "includes": [
            "# include \"ww_mutex.h\"",
            "#include \"rtmutex_common.h\"",
            "#include <linux/ww_mutex.h>",
            "#include <linux/sched/wake_q.h>",
            "#include <linux/sched/rt.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/sched/deadline.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "# include \"ww_mutex.h\"\n#include \"rtmutex_common.h\"\n#include <linux/ww_mutex.h>\n#include <linux/sched/wake_q.h>\n#include <linux/sched/rt.h>\n#include <linux/sched/signal.h>\n#include <linux/sched/deadline.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n\nstatic __always_inline struct;\n\nstatic __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)\n{\n\tif (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))\n\t\treturn;\n\n\trt_mutex_slowunlock(lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_mutex_lock",
          "args": [
            "&rnp->boost_mtx"
          ],
          "line": 1069
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_lock_killable",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "100-103",
          "snippet": "int __sched rt_mutex_lock_killable(struct rt_mutex *lock)\n{\n\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nint __sched rt_mutex_lock_killable(struct rt_mutex *lock)\n{\n\treturn __rt_mutex_lock_common(lock, TASK_KILLABLE, NULL, 0);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1067
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_init_proxy_locked",
          "args": [
            "&rnp->boost_mtx.rtmutex",
            "t"
          ],
          "line": 1066
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_init_proxy_locked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "236-253",
          "snippet": "void __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,\n\t\t\t\t\tstruct task_struct *proxy_owner)\n{\n\tstatic struct lock_class_key pi_futex_key;\n\n\t__rt_mutex_base_init(lock);\n\t/*\n\t * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'\n\t * and rtmutex based. That causes a lockdep false positive, because\n\t * some of the futex functions invoke spin_unlock(&hb->lock) with\n\t * the wait_lock of the rtmutex associated to the pi_futex held.\n\t * spin_unlock() in turn takes wait_lock of the rtmutex on which\n\t * the spinlock is based, which makes lockdep notice a lock\n\t * recursion. Give the futex/rtmutex wait_lock a separate key.\n\t */\n\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);\n\trt_mutex_set_owner(lock, proxy_owner);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,\n\t\t\t\t\tstruct task_struct *proxy_owner)\n{\n\tstatic struct lock_class_key pi_futex_key;\n\n\t__rt_mutex_base_init(lock);\n\t/*\n\t * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'\n\t * and rtmutex based. That causes a lockdep false positive, because\n\t * some of the futex functions invoke spin_unlock(&hb->lock) with\n\t * the wait_lock of the rtmutex associated to the pi_futex held.\n\t * spin_unlock() in turn takes wait_lock of the rtmutex on which\n\t * the spinlock is based, which makes lockdep notice a lock\n\t * recursion. Give the futex/rtmutex wait_lock a separate key.\n\t */\n\tlockdep_set_class(&lock->wait_lock, &pi_futex_key);\n\trt_mutex_set_owner(lock, proxy_owner);\n}"
        }
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "tb",
            "structtask_struct",
            "rcu_node_entry"
          ],
          "line": 1065
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1034
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_irqsave_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 1027
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->boost_tasks"
          ],
          "line": 1024
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->exp_tasks"
          ],
          "line": 1023
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_boost(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tstruct task_struct *t;\n\tstruct list_head *tb;\n\n\tif (READ_ONCE(rnp->exp_tasks) == NULL &&\n\t    READ_ONCE(rnp->boost_tasks) == NULL)\n\t\treturn 0;  /* Nothing left to boost. */\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\n\t/*\n\t * Recheck under the lock: all tasks in need of boosting\n\t * might exit their RCU read-side critical sections on their own.\n\t */\n\tif (rnp->exp_tasks == NULL && rnp->boost_tasks == NULL) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn 0;\n\t}\n\n\t/*\n\t * Preferentially boost tasks blocking expedited grace periods.\n\t * This cannot starve the normal grace periods because a second\n\t * expedited grace period must boost all blocked tasks, including\n\t * those blocking the pre-existing normal grace period.\n\t */\n\tif (rnp->exp_tasks != NULL)\n\t\ttb = rnp->exp_tasks;\n\telse\n\t\ttb = rnp->boost_tasks;\n\n\t/*\n\t * We boost task t by manufacturing an rt_mutex that appears to\n\t * be held by task t.  We leave a pointer to that rt_mutex where\n\t * task t can find it, and task t will release the mutex when it\n\t * exits its outermost RCU read-side critical section.  Then\n\t * simply acquiring this artificial rt_mutex will boost task\n\t * t's priority.  (Thanks to tglx for suggesting this approach!)\n\t *\n\t * Note that task t must acquire rnp->lock to remove itself from\n\t * the ->blkd_tasks list, which it will do from exit() if from\n\t * nowhere else.  We therefore are guaranteed that task t will\n\t * stay around at least until we drop rnp->lock.  Note that\n\t * rnp->lock also resolves races between our priority boosting\n\t * and task t's exiting its outermost RCU read-side critical\n\t * section.\n\t */\n\tt = container_of(tb, struct task_struct, rcu_node_entry);\n\trt_mutex_init_proxy_locked(&rnp->boost_mtx.rtmutex, t);\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t/* Lock only for side effect: boosts task t's priority. */\n\trt_mutex_lock(&rnp->boost_mtx);\n\trt_mutex_unlock(&rnp->boost_mtx);  /* Then keep lockdep happy. */\n\trnp->n_boosts++;\n\n\treturn READ_ONCE(rnp->exp_tasks) != NULL ||\n\t       READ_ONCE(rnp->boost_tasks) != NULL;\n}"
  },
  {
    "function_name": "rcu_cpu_kthread_setup",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "997-1005",
    "snippet": "static void rcu_cpu_kthread_setup(unsigned int cpu)\n{\n#ifdef CONFIG_RCU_BOOST\n\tstruct sched_param sp;\n\n\tsp.sched_priority = kthread_prio;\n\tsched_setscheduler_nocheck(current, SCHED_FIFO, &sp);\n#endif /* #ifdef CONFIG_RCU_BOOST */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "sched_setscheduler_nocheck",
          "args": [
            "current",
            "SCHED_FIFO",
            "&sp"
          ],
          "line": 1003
        },
        "resolved": true,
        "details": {
          "function_name": "sched_setscheduler_nocheck",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "7565-7569",
          "snippet": "int sched_setscheduler_nocheck(struct task_struct *p, int policy,\n\t\t\t       const struct sched_param *param)\n{\n\treturn _sched_setscheduler(p, policy, param, false);\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic __always_inline struct;\n\nint sched_setscheduler_nocheck(struct task_struct *p, int policy,\n\t\t\t       const struct sched_param *param)\n{\n\treturn _sched_setscheduler(p, policy, param, false);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_cpu_kthread_setup(unsigned int cpu)\n{\n#ifdef CONFIG_RCU_BOOST\n\tstruct sched_param sp;\n\n\tsp.sched_priority = kthread_prio;\n\tsched_setscheduler_nocheck(current, SCHED_FIFO, &sp);\n#endif /* #ifdef CONFIG_RCU_BOOST */\n}"
  },
  {
    "function_name": "dump_blkd_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "986-990",
    "snippet": "static void\ndump_blkd_tasks(struct rcu_node *rnp, int ncheck)\n{\n\tWARN_ON_ONCE(!list_empty(&rnp->blkd_tasks));\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!list_empty(&rnp->blkd_tasks)"
          ],
          "line": 989
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&rnp->blkd_tasks"
          ],
          "line": 989
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void\ndump_blkd_tasks(struct rcu_node *rnp, int ncheck)\n{\n\tWARN_ON_ONCE(!list_empty(&rnp->blkd_tasks));\n}"
  },
  {
    "function_name": "exit_rcu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "979-981",
    "snippet": "void exit_rcu(void)\n{\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid exit_rcu(void)\n{\n}"
  },
  {
    "function_name": "rcu_flavor_sched_clock_irq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "955-973",
    "snippet": "static void rcu_flavor_sched_clock_irq(int user)\n{\n\tif (user || rcu_is_cpu_rrupt_from_idle()) {\n\n\t\t/*\n\t\t * Get here if this CPU took its interrupt from user\n\t\t * mode or from the idle loop, and if this is not a\n\t\t * nested interrupt.  In this case, the CPU is in\n\t\t * a quiescent state, so note it.\n\t\t *\n\t\t * No memory barrier is required here because rcu_qs()\n\t\t * references only CPU-local variables that other CPUs\n\t\t * neither access nor modify, at least not while the\n\t\t * corresponding CPU is online.\n\t\t */\n\n\t\trcu_qs();\n\t}\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_qs",
          "args": [],
          "line": 971
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "842-852",
          "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_is_cpu_rrupt_from_idle",
          "args": [],
          "line": 957
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_is_cpu_rrupt_from_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "422-451",
          "snippet": "static int rcu_is_cpu_rrupt_from_idle(void)\n{\n\tlong nesting;\n\n\t/*\n\t * Usually called from the tick; but also used from smp_function_call()\n\t * for expedited grace periods. This latter can result in running from\n\t * the idle task, instead of an actual IPI.\n\t */\n\tlockdep_assert_irqs_disabled();\n\n\t/* Check for counter underflows */\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) < 0,\n\t\t\t \"RCU dynticks_nesting counter underflow!\");\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) <= 0,\n\t\t\t \"RCU dynticks_nmi_nesting counter underflow/zero!\");\n\n\t/* Are we at first interrupt nesting level? */\n\tnesting = __this_cpu_read(rcu_data.dynticks_nmi_nesting);\n\tif (nesting > 1)\n\t\treturn false;\n\n\t/*\n\t * If we're not in an interrupt, we must be in the idle task!\n\t */\n\tWARN_ON_ONCE(!nesting && !is_idle_task(current));\n\n\t/* Does CPU appear to be idle from an RCU standpoint? */\n\treturn __this_cpu_read(rcu_data.dynticks_nesting) == 0;\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};\n\nstatic int rcu_is_cpu_rrupt_from_idle(void)\n{\n\tlong nesting;\n\n\t/*\n\t * Usually called from the tick; but also used from smp_function_call()\n\t * for expedited grace periods. This latter can result in running from\n\t * the idle task, instead of an actual IPI.\n\t */\n\tlockdep_assert_irqs_disabled();\n\n\t/* Check for counter underflows */\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) < 0,\n\t\t\t \"RCU dynticks_nesting counter underflow!\");\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) <= 0,\n\t\t\t \"RCU dynticks_nmi_nesting counter underflow/zero!\");\n\n\t/* Are we at first interrupt nesting level? */\n\tnesting = __this_cpu_read(rcu_data.dynticks_nmi_nesting);\n\tif (nesting > 1)\n\t\treturn false;\n\n\t/*\n\t * If we're not in an interrupt, we must be in the idle task!\n\t */\n\tWARN_ON_ONCE(!nesting && !is_idle_task(current));\n\n\t/* Does CPU appear to be idle from an RCU standpoint? */\n\treturn __this_cpu_read(rcu_data.dynticks_nesting) == 0;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_flavor_sched_clock_irq(int user)\n{\n\tif (user || rcu_is_cpu_rrupt_from_idle()) {\n\n\t\t/*\n\t\t * Get here if this CPU took its interrupt from user\n\t\t * mode or from the idle loop, and if this is not a\n\t\t * nested interrupt.  In this case, the CPU is in\n\t\t * a quiescent state, so note it.\n\t\t *\n\t\t * No memory barrier is required here because rcu_qs()\n\t\t * references only CPU-local variables that other CPUs\n\t\t * neither access nor modify, at least not while the\n\t\t * corresponding CPU is online.\n\t\t */\n\n\t\trcu_qs();\n\t}\n}"
  },
  {
    "function_name": "rcu_preempt_check_blocked_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "946-949",
    "snippet": "static void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)\n{\n\tWARN_ON_ONCE(rnp->qsmask);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rnp->qsmask"
          ],
          "line": 948
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)\n{\n\tWARN_ON_ONCE(rnp->qsmask);\n}"
  },
  {
    "function_name": "rcu_preempt_deferred_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "933-939",
    "snippet": "static void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_report_exp_rdp",
          "args": [
            "rdp"
          ],
          "line": 938
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_exp_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "256-260",
          "snippet": "static void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 935
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}"
  },
  {
    "function_name": "rcu_preempt_need_deferred_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "924-927",
    "snippet": "static bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "rcu_preempt_has_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "915-918",
    "snippet": "static bool rcu_preempt_has_tasks(struct rcu_node *rnp)\n{\n\treturn false;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_has_tasks(struct rcu_node *rnp)\n{\n\treturn false;\n}"
  },
  {
    "function_name": "rcu_preempt_blocked_readers_cgp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "907-910",
    "snippet": "static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}"
  },
  {
    "function_name": "rcu_note_context_switch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "887-900",
    "snippet": "void rcu_note_context_switch(bool preempt)\n{\n\ttrace_rcu_utilization(TPS(\"Start context switch\"));\n\trcu_qs();\n\t/* Load rcu_urgent_qs before other flags. */\n\tif (!smp_load_acquire(this_cpu_ptr(&rcu_data.rcu_urgent_qs)))\n\t\tgoto out;\n\tthis_cpu_write(rcu_data.rcu_urgent_qs, false);\n\tif (unlikely(raw_cpu_read(rcu_data.rcu_need_heavy_qs)))\n\t\trcu_momentary_dyntick_idle();\n\trcu_tasks_qs(current, preempt);\nout:\n\ttrace_rcu_utilization(TPS(\"End context switch\"));\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"End context switch\")"
          ],
          "line": 899
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"End context switch\""
          ],
          "line": 899
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_tasks_qs",
          "args": [
            "current",
            "preempt"
          ],
          "line": 897
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_momentary_dyntick_idle",
          "args": [],
          "line": 896
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_momentary_dyntick_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "402-411",
          "snippet": "notrace void rcu_momentary_dyntick_idle(void)\n{\n\tint seq;\n\n\traw_cpu_write(rcu_data.rcu_need_heavy_qs, false);\n\tseq = rcu_dynticks_inc(2);\n\t/* It is illegal to call this from idle state. */\n\tWARN_ON_ONCE(!(seq & 0x1));\n\trcu_preempt_deferred_qs(current);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};\n\nnotrace void rcu_momentary_dyntick_idle(void)\n{\n\tint seq;\n\n\traw_cpu_write(rcu_data.rcu_need_heavy_qs, false);\n\tseq = rcu_dynticks_inc(2);\n\t/* It is illegal to call this from idle state. */\n\tWARN_ON_ONCE(!(seq & 0x1));\n\trcu_preempt_deferred_qs(current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "raw_cpu_read(rcu_data.rcu_need_heavy_qs)"
          ],
          "line": 895
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_cpu_read",
          "args": [
            "rcu_data.rcu_need_heavy_qs"
          ],
          "line": 895
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "rcu_data.rcu_urgent_qs",
            "false"
          ],
          "line": 894
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "this_cpu_ptr(&rcu_data.rcu_urgent_qs)"
          ],
          "line": 892
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data.rcu_urgent_qs"
          ],
          "line": 892
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_qs",
          "args": [],
          "line": 890
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "842-852",
          "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"Start context switch\")"
          ],
          "line": 889
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"Start context switch\""
          ],
          "line": 889
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_note_context_switch(bool preempt)\n{\n\ttrace_rcu_utilization(TPS(\"Start context switch\"));\n\trcu_qs();\n\t/* Load rcu_urgent_qs before other flags. */\n\tif (!smp_load_acquire(this_cpu_ptr(&rcu_data.rcu_urgent_qs)))\n\t\tgoto out;\n\tthis_cpu_write(rcu_data.rcu_urgent_qs, false);\n\tif (unlikely(raw_cpu_read(rcu_data.rcu_need_heavy_qs)))\n\t\trcu_momentary_dyntick_idle();\n\trcu_tasks_qs(current, preempt);\nout:\n\ttrace_rcu_utilization(TPS(\"End context switch\"));\n}"
  },
  {
    "function_name": "rcu_all_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "861-881",
    "snippet": "void rcu_all_qs(void)\n{\n\tunsigned long flags;\n\n\tif (!raw_cpu_read(rcu_data.rcu_urgent_qs))\n\t\treturn;\n\tpreempt_disable();\n\t/* Load rcu_urgent_qs before other flags. */\n\tif (!smp_load_acquire(this_cpu_ptr(&rcu_data.rcu_urgent_qs))) {\n\t\tpreempt_enable();\n\t\treturn;\n\t}\n\tthis_cpu_write(rcu_data.rcu_urgent_qs, false);\n\tif (unlikely(raw_cpu_read(rcu_data.rcu_need_heavy_qs))) {\n\t\tlocal_irq_save(flags);\n\t\trcu_momentary_dyntick_idle();\n\t\tlocal_irq_restore(flags);\n\t}\n\trcu_qs();\n\tpreempt_enable();\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 880
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_qs",
          "args": [],
          "line": 879
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "842-852",
          "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 877
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_momentary_dyntick_idle",
          "args": [],
          "line": 876
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_momentary_dyntick_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "402-411",
          "snippet": "notrace void rcu_momentary_dyntick_idle(void)\n{\n\tint seq;\n\n\traw_cpu_write(rcu_data.rcu_need_heavy_qs, false);\n\tseq = rcu_dynticks_inc(2);\n\t/* It is illegal to call this from idle state. */\n\tWARN_ON_ONCE(!(seq & 0x1));\n\trcu_preempt_deferred_qs(current);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};\n\nnotrace void rcu_momentary_dyntick_idle(void)\n{\n\tint seq;\n\n\traw_cpu_write(rcu_data.rcu_need_heavy_qs, false);\n\tseq = rcu_dynticks_inc(2);\n\t/* It is illegal to call this from idle state. */\n\tWARN_ON_ONCE(!(seq & 0x1));\n\trcu_preempt_deferred_qs(current);\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 875
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "raw_cpu_read(rcu_data.rcu_need_heavy_qs)"
          ],
          "line": 874
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_cpu_read",
          "args": [
            "rcu_data.rcu_need_heavy_qs"
          ],
          "line": 874
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_write",
          "args": [
            "rcu_data.rcu_urgent_qs",
            "false"
          ],
          "line": 873
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_enable",
          "args": [],
          "line": 870
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "smp_load_acquire",
          "args": [
            "this_cpu_ptr(&rcu_data.rcu_urgent_qs)"
          ],
          "line": 869
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data.rcu_urgent_qs"
          ],
          "line": 869
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_disable",
          "args": [],
          "line": 867
        },
        "resolved": true,
        "details": {
          "function_name": "schedule_preempt_disabled",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/sched/core.c",
          "lines": "6425-6430",
          "snippet": "void __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}",
          "includes": [
            "#include <linux/entry-common.h>",
            "#include \"features.h\"",
            "#include \"smp.h\"",
            "#include \"pelt.h\"",
            "#include \"../smpboot.h\"",
            "#include \"../../fs/io-wq.h\"",
            "#include \"../workqueue_internal.h\"",
            "#include <asm/tlb.h>",
            "#include <asm/switch_to.h>",
            "#include <linux/scs.h>",
            "#include <linux/kcov.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/nospec.h>",
            "#include \"sched.h\"",
            "#include <trace/events/sched.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void __sched",
            "static void __sched"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/entry-common.h>\n#include \"features.h\"\n#include \"smp.h\"\n#include \"pelt.h\"\n#include \"../smpboot.h\"\n#include \"../../fs/io-wq.h\"\n#include \"../workqueue_internal.h\"\n#include <asm/tlb.h>\n#include <asm/switch_to.h>\n#include <linux/scs.h>\n#include <linux/kcov.h>\n#include <linux/blkdev.h>\n#include <linux/nospec.h>\n#include \"sched.h\"\n#include <trace/events/sched.h>\n\nstatic void __sched;\nstatic void __sched;\n\nvoid __sched schedule_preempt_disabled(void)\n{\n\tsched_preempt_enable_no_resched();\n\tschedule();\n\tpreempt_disable();\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_cpu_read",
          "args": [
            "rcu_data.rcu_urgent_qs"
          ],
          "line": 865
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_all_qs(void)\n{\n\tunsigned long flags;\n\n\tif (!raw_cpu_read(rcu_data.rcu_urgent_qs))\n\t\treturn;\n\tpreempt_disable();\n\t/* Load rcu_urgent_qs before other flags. */\n\tif (!smp_load_acquire(this_cpu_ptr(&rcu_data.rcu_urgent_qs))) {\n\t\tpreempt_enable();\n\t\treturn;\n\t}\n\tthis_cpu_write(rcu_data.rcu_urgent_qs, false);\n\tif (unlikely(raw_cpu_read(rcu_data.rcu_need_heavy_qs))) {\n\t\tlocal_irq_save(flags);\n\t\trcu_momentary_dyntick_idle();\n\t\tlocal_irq_restore(flags);\n\t}\n\trcu_qs();\n\tpreempt_enable();\n}"
  },
  {
    "function_name": "rcu_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "842-852",
    "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_report_exp_rdp",
          "args": [
            "this_cpu_ptr(&rcu_data)"
          ],
          "line": 851
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_exp_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "256-260",
          "snippet": "static void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 851
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.cpu_no_qs.b.exp"
          ],
          "line": 850
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "rcu_data.cpu_no_qs.b.norm",
            "false"
          ],
          "line": 849
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_grace_period",
          "args": [
            "TPS(\"rcu_sched\")",
            "__this_cpu_read(rcu_data.gp_seq)",
            "TPS(\"cpuqs\")"
          ],
          "line": 847
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"cpuqs\""
          ],
          "line": 848
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.gp_seq"
          ],
          "line": 848
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"rcu_sched\""
          ],
          "line": 847
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.cpu_no_qs.s"
          ],
          "line": 845
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RCU_LOCKDEP_WARN",
          "args": [
            "preemptible()",
            "\"rcu_qs() invoked with preemption enabled!!!\""
          ],
          "line": 844
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preemptible",
          "args": [],
          "line": 844
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
  },
  {
    "function_name": "rcu_bootup_announce",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "830-834",
    "snippet": "static void __init rcu_bootup_announce(void)\n{\n\tpr_info(\"Hierarchical RCU implementation.\\n\");\n\trcu_bootup_announce_oddness();\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_bootup_announce_oddness",
          "args": [],
          "line": 833
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_bootup_announce_oddness",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "44-101",
          "snippet": "static void __init rcu_bootup_announce_oddness(void)\n{\n\tif (IS_ENABLED(CONFIG_RCU_TRACE))\n\t\tpr_info(\"\\tRCU event tracing is enabled.\\n\");\n\tif ((IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 64) ||\n\t    (!IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 32))\n\t\tpr_info(\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\",\n\t\t\tRCU_FANOUT);\n\tif (rcu_fanout_exact)\n\t\tpr_info(\"\\tHierarchical RCU autobalancing is disabled.\\n\");\n\tif (IS_ENABLED(CONFIG_PROVE_RCU))\n\t\tpr_info(\"\\tRCU lockdep checking is enabled.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))\n\t\tpr_info(\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\");\n\tif (RCU_NUM_LVLS >= 4)\n\t\tpr_info(\"\\tFour(or more)-level hierarchy is enabled.\\n\");\n\tif (RCU_FANOUT_LEAF != 16)\n\t\tpr_info(\"\\tBuild-time adjustment of leaf fanout to %d.\\n\",\n\t\t\tRCU_FANOUT_LEAF);\n\tif (rcu_fanout_leaf != RCU_FANOUT_LEAF)\n\t\tpr_info(\"\\tBoot-time adjustment of leaf fanout to %d.\\n\",\n\t\t\trcu_fanout_leaf);\n\tif (nr_cpu_ids != NR_CPUS)\n\t\tpr_info(\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\", NR_CPUS, nr_cpu_ids);\n#ifdef CONFIG_RCU_BOOST\n\tpr_info(\"\\tRCU priority boosting: priority %d delay %d ms.\\n\",\n\t\tkthread_prio, CONFIG_RCU_BOOST_DELAY);\n#endif\n\tif (blimit != DEFAULT_RCU_BLIMIT)\n\t\tpr_info(\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\", blimit);\n\tif (qhimark != DEFAULT_RCU_QHIMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\", qhimark);\n\tif (qlowmark != DEFAULT_RCU_QLOMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\", qlowmark);\n\tif (qovld != DEFAULT_RCU_QOVLD)\n\t\tpr_info(\"\\tBoot-time adjustment of callback overload level to %ld.\\n\", qovld);\n\tif (jiffies_till_first_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\", jiffies_till_first_fqs);\n\tif (jiffies_till_next_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\", jiffies_till_next_fqs);\n\tif (jiffies_till_sched_qs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\", jiffies_till_sched_qs);\n\tif (rcu_kick_kthreads)\n\t\tpr_info(\"\\tKick kthreads if too-long grace period.\\n\");\n\tif (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))\n\t\tpr_info(\"\\tRCU callback double-/use-after-free debug is enabled.\\n\");\n\tif (gp_preinit_delay)\n\t\tpr_info(\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\", gp_preinit_delay);\n\tif (gp_init_delay)\n\t\tpr_info(\"\\tRCU debug GP init slowdown %d jiffies.\\n\", gp_init_delay);\n\tif (gp_cleanup_delay)\n\t\tpr_info(\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\", gp_cleanup_delay);\n\tif (!use_softirq)\n\t\tpr_info(\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))\n\t\tpr_info(\"\\tRCU debug extended QS entry/exit.\\n\");\n\trcupdate_announce_bootup_oddness();\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_bootup_announce_oddness(void)\n{\n\tif (IS_ENABLED(CONFIG_RCU_TRACE))\n\t\tpr_info(\"\\tRCU event tracing is enabled.\\n\");\n\tif ((IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 64) ||\n\t    (!IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 32))\n\t\tpr_info(\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\",\n\t\t\tRCU_FANOUT);\n\tif (rcu_fanout_exact)\n\t\tpr_info(\"\\tHierarchical RCU autobalancing is disabled.\\n\");\n\tif (IS_ENABLED(CONFIG_PROVE_RCU))\n\t\tpr_info(\"\\tRCU lockdep checking is enabled.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))\n\t\tpr_info(\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\");\n\tif (RCU_NUM_LVLS >= 4)\n\t\tpr_info(\"\\tFour(or more)-level hierarchy is enabled.\\n\");\n\tif (RCU_FANOUT_LEAF != 16)\n\t\tpr_info(\"\\tBuild-time adjustment of leaf fanout to %d.\\n\",\n\t\t\tRCU_FANOUT_LEAF);\n\tif (rcu_fanout_leaf != RCU_FANOUT_LEAF)\n\t\tpr_info(\"\\tBoot-time adjustment of leaf fanout to %d.\\n\",\n\t\t\trcu_fanout_leaf);\n\tif (nr_cpu_ids != NR_CPUS)\n\t\tpr_info(\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\", NR_CPUS, nr_cpu_ids);\n#ifdef CONFIG_RCU_BOOST\n\tpr_info(\"\\tRCU priority boosting: priority %d delay %d ms.\\n\",\n\t\tkthread_prio, CONFIG_RCU_BOOST_DELAY);\n#endif\n\tif (blimit != DEFAULT_RCU_BLIMIT)\n\t\tpr_info(\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\", blimit);\n\tif (qhimark != DEFAULT_RCU_QHIMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\", qhimark);\n\tif (qlowmark != DEFAULT_RCU_QLOMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\", qlowmark);\n\tif (qovld != DEFAULT_RCU_QOVLD)\n\t\tpr_info(\"\\tBoot-time adjustment of callback overload level to %ld.\\n\", qovld);\n\tif (jiffies_till_first_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\", jiffies_till_first_fqs);\n\tif (jiffies_till_next_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\", jiffies_till_next_fqs);\n\tif (jiffies_till_sched_qs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\", jiffies_till_sched_qs);\n\tif (rcu_kick_kthreads)\n\t\tpr_info(\"\\tKick kthreads if too-long grace period.\\n\");\n\tif (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))\n\t\tpr_info(\"\\tRCU callback double-/use-after-free debug is enabled.\\n\");\n\tif (gp_preinit_delay)\n\t\tpr_info(\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\", gp_preinit_delay);\n\tif (gp_init_delay)\n\t\tpr_info(\"\\tRCU debug GP init slowdown %d jiffies.\\n\", gp_init_delay);\n\tif (gp_cleanup_delay)\n\t\tpr_info(\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\", gp_cleanup_delay);\n\tif (!use_softirq)\n\t\tpr_info(\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))\n\t\tpr_info(\"\\tRCU debug extended QS entry/exit.\\n\");\n\trcupdate_announce_bootup_oddness();\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Hierarchical RCU implementation.\\n\""
          ],
          "line": 832
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_bootup_announce(void)\n{\n\tpr_info(\"Hierarchical RCU implementation.\\n\");\n\trcu_bootup_announce_oddness();\n}"
  },
  {
    "function_name": "rcu_read_unlock_strict",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "815-824",
    "snippet": "void rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "udelay",
          "args": [
            "rcu_unlock_delay"
          ],
          "line": 823
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_qs_rdp",
          "args": [
            "rdp"
          ],
          "line": 822
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_qs_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "2282-2340",
          "snippet": "static void\nrcu_report_qs_rdp(struct rcu_data *rdp)\n{\n\tunsigned long flags;\n\tunsigned long mask;\n\tbool needwake = false;\n\tbool needacc = false;\n\tstruct rcu_node *rnp;\n\n\tWARN_ON_ONCE(rdp->cpu != smp_processor_id());\n\trnp = rdp->mynode;\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tif (rdp->cpu_no_qs.b.norm || rdp->gp_seq != rnp->gp_seq ||\n\t    rdp->gpwrap) {\n\n\t\t/*\n\t\t * The grace period in which this quiescent state was\n\t\t * recorded has ended, so don't report it upwards.\n\t\t * We will instead need a new quiescent state that lies\n\t\t * within the current grace period.\n\t\t */\n\t\trdp->cpu_no_qs.b.norm = true;\t/* need qs for new gp. */\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tmask = rdp->grpmask;\n\trdp->core_needs_qs = false;\n\tif ((rnp->qsmask & mask) == 0) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t} else {\n\t\t/*\n\t\t * This GP can't end until cpu checks in, so all of our\n\t\t * callbacks can be processed during the next GP.\n\t\t *\n\t\t * NOCB kthreads have their own way to deal with that...\n\t\t */\n\t\tif (!rcu_rdp_is_offloaded(rdp)) {\n\t\t\tneedwake = rcu_accelerate_cbs(rnp, rdp);\n\t\t} else if (!rcu_segcblist_completely_offloaded(&rdp->cblist)) {\n\t\t\t/*\n\t\t\t * ...but NOCB kthreads may miss or delay callbacks acceleration\n\t\t\t * if in the middle of a (de-)offloading process.\n\t\t\t */\n\t\t\tneedacc = true;\n\t\t}\n\n\t\trcu_disable_urgency_upon_qs(rdp);\n\t\trcu_report_qs_rnp(mask, rnp, rnp->gp_seq, flags);\n\t\t/* ^^^ Released rnp->lock */\n\t\tif (needwake)\n\t\t\trcu_gp_kthread_wake();\n\n\t\tif (needacc) {\n\t\t\trcu_nocb_lock_irqsave(rdp, flags);\n\t\t\trcu_accelerate_cbs_unlocked(rnp, rdp);\n\t\t\trcu_nocb_unlock_irqrestore(rdp, flags);\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};",
            "static void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,\n\t\t\t      unsigned long gps, unsigned long flags);",
            "static void rcu_report_exp_rdp(struct rcu_data *rdp);",
            "static void sync_sched_exp_online_cleanup(int cpu);",
            "static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);",
            "static bool rcu_rdp_is_offloaded(struct rcu_data *rdp);",
            "static void force_qs_rnp(int (*f)(struct rcu_data *rdp));"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};\nstatic void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,\n\t\t\t      unsigned long gps, unsigned long flags);\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp);\nstatic void sync_sched_exp_online_cleanup(int cpu);\nstatic void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);\nstatic bool rcu_rdp_is_offloaded(struct rcu_data *rdp);\nstatic void force_qs_rnp(int (*f)(struct rcu_data *rdp));\n\nstatic void\nrcu_report_qs_rdp(struct rcu_data *rdp)\n{\n\tunsigned long flags;\n\tunsigned long mask;\n\tbool needwake = false;\n\tbool needacc = false;\n\tstruct rcu_node *rnp;\n\n\tWARN_ON_ONCE(rdp->cpu != smp_processor_id());\n\trnp = rdp->mynode;\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tif (rdp->cpu_no_qs.b.norm || rdp->gp_seq != rnp->gp_seq ||\n\t    rdp->gpwrap) {\n\n\t\t/*\n\t\t * The grace period in which this quiescent state was\n\t\t * recorded has ended, so don't report it upwards.\n\t\t * We will instead need a new quiescent state that lies\n\t\t * within the current grace period.\n\t\t */\n\t\trdp->cpu_no_qs.b.norm = true;\t/* need qs for new gp. */\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tmask = rdp->grpmask;\n\trdp->core_needs_qs = false;\n\tif ((rnp->qsmask & mask) == 0) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t} else {\n\t\t/*\n\t\t * This GP can't end until cpu checks in, so all of our\n\t\t * callbacks can be processed during the next GP.\n\t\t *\n\t\t * NOCB kthreads have their own way to deal with that...\n\t\t */\n\t\tif (!rcu_rdp_is_offloaded(rdp)) {\n\t\t\tneedwake = rcu_accelerate_cbs(rnp, rdp);\n\t\t} else if (!rcu_segcblist_completely_offloaded(&rdp->cblist)) {\n\t\t\t/*\n\t\t\t * ...but NOCB kthreads may miss or delay callbacks acceleration\n\t\t\t * if in the middle of a (de-)offloading process.\n\t\t\t */\n\t\t\tneedacc = true;\n\t\t}\n\n\t\trcu_disable_urgency_upon_qs(rdp);\n\t\trcu_report_qs_rnp(mask, rnp, rnp->gp_seq, flags);\n\t\t/* ^^^ Released rnp->lock */\n\t\tif (needwake)\n\t\t\trcu_gp_kthread_wake();\n\n\t\tif (needacc) {\n\t\t\trcu_nocb_lock_irqsave(rdp, flags);\n\t\t\trcu_accelerate_cbs_unlocked(rnp, rdp);\n\t\t\trcu_nocb_unlock_irqrestore(rdp, flags);\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 821
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_count",
          "args": [],
          "line": 819
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqs_disabled",
          "args": [],
          "line": 819
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_read_unlock_strict(void)\n{\n\tstruct rcu_data *rdp;\n\n\tif (irqs_disabled() || preempt_count() || !rcu_state.gp_kthread)\n\t\treturn;\n\trdp = this_cpu_ptr(&rcu_data);\n\trcu_report_qs_rdp(rdp);\n\tudelay(rcu_unlock_delay);\n}"
  },
  {
    "function_name": "dump_blkd_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "770-806",
    "snippet": "static void\ndump_blkd_tasks(struct rcu_node *rnp, int ncheck)\n{\n\tint cpu;\n\tint i;\n\tstruct list_head *lhp;\n\tbool onl;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp1;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tpr_info(\"%s: grp: %d-%d level: %d ->gp_seq %ld ->completedqs %ld\\n\",\n\t\t__func__, rnp->grplo, rnp->grphi, rnp->level,\n\t\t(long)READ_ONCE(rnp->gp_seq), (long)rnp->completedqs);\n\tfor (rnp1 = rnp; rnp1; rnp1 = rnp1->parent)\n\t\tpr_info(\"%s: %d:%d ->qsmask %#lx ->qsmaskinit %#lx ->qsmaskinitnext %#lx\\n\",\n\t\t\t__func__, rnp1->grplo, rnp1->grphi, rnp1->qsmask, rnp1->qsmaskinit, rnp1->qsmaskinitnext);\n\tpr_info(\"%s: ->gp_tasks %p ->boost_tasks %p ->exp_tasks %p\\n\",\n\t\t__func__, READ_ONCE(rnp->gp_tasks), data_race(rnp->boost_tasks),\n\t\tREAD_ONCE(rnp->exp_tasks));\n\tpr_info(\"%s: ->blkd_tasks\", __func__);\n\ti = 0;\n\tlist_for_each(lhp, &rnp->blkd_tasks) {\n\t\tpr_cont(\" %p\", lhp);\n\t\tif (++i >= ncheck)\n\t\t\tbreak;\n\t}\n\tpr_cont(\"\\n\");\n\tfor (cpu = rnp->grplo; cpu <= rnp->grphi; cpu++) {\n\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\tonl = !!(rdp->grpmask & rcu_rnp_online_cpus(rnp));\n\t\tpr_info(\"\\t%d: %c online: %ld(%d) offline: %ld(%d)\\n\",\n\t\t\tcpu, \".o\"[onl],\n\t\t\t(long)rdp->rcu_onl_gp_seq, rdp->rcu_onl_gp_flags,\n\t\t\t(long)rdp->rcu_ofl_gp_seq, rdp->rcu_ofl_gp_flags);\n\t}\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\t%d: %c online: %ld(%d) offline: %ld(%d)\\n\"",
            "cpu",
            "\".o\"[onl]",
            "(long)rdp->rcu_onl_gp_seq",
            "rdp->rcu_onl_gp_flags",
            "(long)rdp->rcu_ofl_gp_seq",
            "rdp->rcu_ofl_gp_flags"
          ],
          "line": 801
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_rnp_online_cpus",
          "args": [
            "rnp"
          ],
          "line": 800
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_rnp_online_cpus",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "219-222",
          "snippet": "static unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->qsmaskinitnext);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);\n\nstatic unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->qsmaskinitnext);\n}"
        }
      },
      {
        "call_info": {
          "callee": "per_cpu_ptr",
          "args": [
            "&rcu_data",
            "cpu"
          ],
          "line": 799
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_cont",
          "args": [
            "\"\\n\""
          ],
          "line": 797
        },
        "resolved": true,
        "details": {
          "function_name": "pr_cont_pool_info",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "4715-4721",
          "snippet": "static void pr_cont_pool_info(struct worker_pool *pool)\n{\n\tpr_cont(\" cpus=%*pbl\", nr_cpumask_bits, pool->attrs->cpumask);\n\tif (pool->node != NUMA_NO_NODE)\n\t\tpr_cont(\" node=%d\", pool->node);\n\tpr_cont(\" flags=0x%x nice=%d\", pool->flags, pool->attrs->nice);\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);",
            "static void show_one_worker_pool(struct worker_pool *pool);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct worker_pool [NR_STD_WORKER_POOLS], cpu_worker_pools);\nstatic void show_one_worker_pool(struct worker_pool *pool);\n\nstatic void pr_cont_pool_info(struct worker_pool *pool)\n{\n\tpr_cont(\" cpus=%*pbl\", nr_cpumask_bits, pool->attrs->cpumask);\n\tif (pool->node != NUMA_NO_NODE)\n\t\tpr_cont(\" node=%d\", pool->node);\n\tpr_cont(\" flags=0x%x nice=%d\", pool->flags, pool->attrs->nice);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_cont",
          "args": [
            "\" %p\"",
            "lhp"
          ],
          "line": 793
        },
        "resolved": true,
        "details": {
          "function_name": "pr_cont_work",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/workqueue.c",
          "lines": "4723-4735",
          "snippet": "static void pr_cont_work(bool comma, struct work_struct *work)\n{\n\tif (work->func == wq_barrier_func) {\n\t\tstruct wq_barrier *barr;\n\n\t\tbarr = container_of(work, struct wq_barrier, work);\n\n\t\tpr_cont(\"%s BAR(%d)\", comma ? \",\" : \"\",\n\t\t\ttask_pid_nr(barr->task));\n\t} else {\n\t\tpr_cont(\"%s %ps\", comma ? \",\" : \"\", work->func);\n\t}\n}",
          "includes": [
            "#include <trace/events/workqueue.h>",
            "#include \"workqueue_internal.h\"",
            "#include <linux/kvm_para.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/rculist.h>",
            "#include <linux/hashtable.h>",
            "#include <linux/jhash.h>",
            "#include <linux/idr.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/debug_locks.h>",
            "#include <linux/freezer.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/kthread.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/slab.h>",
            "#include <linux/workqueue.h>",
            "#include <linux/completion.h>",
            "#include <linux/signal.h>",
            "#include <linux/init.h>",
            "#include <linux/sched.h>",
            "#include <linux/kernel.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/workqueue.h>\n#include \"workqueue_internal.h\"\n#include <linux/kvm_para.h>\n#include <linux/nmi.h>\n#include <linux/sched/isolation.h>\n#include <linux/uaccess.h>\n#include <linux/moduleparam.h>\n#include <linux/nodemask.h>\n#include <linux/rculist.h>\n#include <linux/hashtable.h>\n#include <linux/jhash.h>\n#include <linux/idr.h>\n#include <linux/lockdep.h>\n#include <linux/debug_locks.h>\n#include <linux/freezer.h>\n#include <linux/mempolicy.h>\n#include <linux/hardirq.h>\n#include <linux/kthread.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/slab.h>\n#include <linux/workqueue.h>\n#include <linux/completion.h>\n#include <linux/signal.h>\n#include <linux/init.h>\n#include <linux/sched.h>\n#include <linux/kernel.h>\n#include <linux/export.h>\n\nstatic void pr_cont_work(bool comma, struct work_struct *work)\n{\n\tif (work->func == wq_barrier_func) {\n\t\tstruct wq_barrier *barr;\n\n\t\tbarr = container_of(work, struct wq_barrier, work);\n\n\t\tpr_cont(\"%s BAR(%d)\", comma ? \",\" : \"\",\n\t\t\ttask_pid_nr(barr->task));\n\t} else {\n\t\tpr_cont(\"%s %ps\", comma ? \",\" : \"\", work->func);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_for_each",
          "args": [
            "lhp",
            "&rnp->blkd_tasks"
          ],
          "line": 792
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: ->blkd_tasks\"",
            "__func__"
          ],
          "line": 790
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: ->gp_tasks %p ->boost_tasks %p ->exp_tasks %p\\n\"",
            "__func__",
            "READ_ONCE(rnp->gp_tasks)",
            "data_race(rnp->boost_tasks)",
            "READ_ONCE(rnp->exp_tasks)"
          ],
          "line": 787
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->exp_tasks"
          ],
          "line": 789
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "data_race",
          "args": [
            "rnp->boost_tasks"
          ],
          "line": 788
        },
        "resolved": true,
        "details": {
          "function_name": "test_data_race",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/kcsan/kcsan_test.c",
          "lines": "998-1008",
          "snippet": "__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}",
          "includes": [
            "#include <trace/events/printk.h>",
            "#include <linux/types.h>",
            "#include <linux/tracepoint.h>",
            "#include <linux/torture.h>",
            "#include <linux/timer.h>",
            "#include <linux/string.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/seqlock.h>",
            "#include <linux/sched.h>",
            "#include <linux/mutex.h>",
            "#include <linux/kernel.h>",
            "#include <linux/kcsan-checks.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <kunit/test.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static __always_inline const struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/printk.h>\n#include <linux/types.h>\n#include <linux/tracepoint.h>\n#include <linux/torture.h>\n#include <linux/timer.h>\n#include <linux/string.h>\n#include <linux/spinlock.h>\n#include <linux/seqlock.h>\n#include <linux/sched.h>\n#include <linux/mutex.h>\n#include <linux/kernel.h>\n#include <linux/kcsan-checks.h>\n#include <linux/jiffies.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <kunit/test.h>\n\nstatic __always_inline const struct;\n\n__no_kcsan\nstatic void test_data_race(struct kunit *test)\n{\n\tbool match_never = false;\n\n\tbegin_test_checks(test_kernel_data_race, test_kernel_data_race);\n\tdo {\n\t\tmatch_never = report_available();\n\t} while (!end_test_checks(match_never));\n\tKUNIT_EXPECT_FALSE(test, match_never);\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->gp_tasks"
          ],
          "line": 788
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: %d:%d ->qsmask %#lx ->qsmaskinit %#lx ->qsmaskinitnext %#lx\\n\"",
            "__func__",
            "rnp1->grplo",
            "rnp1->grphi",
            "rnp1->qsmask",
            "rnp1->qsmaskinit",
            "rnp1->qsmaskinitnext"
          ],
          "line": 785
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"%s: grp: %d-%d level: %d ->gp_seq %ld ->completedqs %ld\\n\"",
            "__func__",
            "rnp->grplo",
            "rnp->grphi",
            "rnp->level",
            "(long)READ_ONCE(rnp->gp_seq)",
            "(long)rnp->completedqs"
          ],
          "line": 781
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->gp_seq"
          ],
          "line": 783
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_lockdep_assert_held_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 780
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void\ndump_blkd_tasks(struct rcu_node *rnp, int ncheck)\n{\n\tint cpu;\n\tint i;\n\tstruct list_head *lhp;\n\tbool onl;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp1;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tpr_info(\"%s: grp: %d-%d level: %d ->gp_seq %ld ->completedqs %ld\\n\",\n\t\t__func__, rnp->grplo, rnp->grphi, rnp->level,\n\t\t(long)READ_ONCE(rnp->gp_seq), (long)rnp->completedqs);\n\tfor (rnp1 = rnp; rnp1; rnp1 = rnp1->parent)\n\t\tpr_info(\"%s: %d:%d ->qsmask %#lx ->qsmaskinit %#lx ->qsmaskinitnext %#lx\\n\",\n\t\t\t__func__, rnp1->grplo, rnp1->grphi, rnp1->qsmask, rnp1->qsmaskinit, rnp1->qsmaskinitnext);\n\tpr_info(\"%s: ->gp_tasks %p ->boost_tasks %p ->exp_tasks %p\\n\",\n\t\t__func__, READ_ONCE(rnp->gp_tasks), data_race(rnp->boost_tasks),\n\t\tREAD_ONCE(rnp->exp_tasks));\n\tpr_info(\"%s: ->blkd_tasks\", __func__);\n\ti = 0;\n\tlist_for_each(lhp, &rnp->blkd_tasks) {\n\t\tpr_cont(\" %p\", lhp);\n\t\tif (++i >= ncheck)\n\t\t\tbreak;\n\t}\n\tpr_cont(\"\\n\");\n\tfor (cpu = rnp->grplo; cpu <= rnp->grphi; cpu++) {\n\t\trdp = per_cpu_ptr(&rcu_data, cpu);\n\t\tonl = !!(rdp->grpmask & rcu_rnp_online_cpus(rnp));\n\t\tpr_info(\"\\t%d: %c online: %ld(%d) offline: %ld(%d)\\n\",\n\t\t\tcpu, \".o\"[onl],\n\t\t\t(long)rdp->rcu_onl_gp_seq, rdp->rcu_onl_gp_flags,\n\t\t\t(long)rdp->rcu_ofl_gp_seq, rdp->rcu_ofl_gp_flags);\n\t}\n}"
  },
  {
    "function_name": "exit_rcu",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "749-764",
    "snippet": "void exit_rcu(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (unlikely(!list_empty(&current->rcu_node_entry))) {\n\t\trcu_preempt_depth_set(1);\n\t\tbarrier();\n\t\tWRITE_ONCE(t->rcu_read_unlock_special.b.blocked, true);\n\t} else if (unlikely(rcu_preempt_depth())) {\n\t\trcu_preempt_depth_set(1);\n\t} else {\n\t\treturn;\n\t}\n\t__rcu_read_unlock();\n\trcu_preempt_deferred_qs(current);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_preempt_deferred_qs",
          "args": [
            "current"
          ],
          "line": 763
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_deferred_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "933-939",
          "snippet": "static void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__rcu_read_unlock",
          "args": [],
          "line": 762
        },
        "resolved": true,
        "details": {
          "function_name": "__rcu_read_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "416-431",
          "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tbarrier();  // critical section before exit code.\n\tif (rcu_preempt_read_exit() == 0) {\n\t\tbarrier();  // critical-section exit before .s check.\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t}\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING)) {\n\t\tint rrln = rcu_preempt_depth();\n\n\t\tWARN_ON_ONCE(rrln < 0 || rrln > RCU_NEST_PMAX);\n\t}\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [
            "#define RCU_NEST_PMAX (INT_MAX / 2)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\n#define RCU_NEST_PMAX (INT_MAX / 2)\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tbarrier();  // critical section before exit code.\n\tif (rcu_preempt_read_exit() == 0) {\n\t\tbarrier();  // critical-section exit before .s check.\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t}\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING)) {\n\t\tint rrln = rcu_preempt_depth();\n\n\t\tWARN_ON_ONCE(rrln < 0 || rrln > RCU_NEST_PMAX);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth_set",
          "args": [
            "1"
          ],
          "line": 758
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_depth_set",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "388-391",
          "snippet": "static void rcu_preempt_depth_set(int val)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, val);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_depth_set(int val)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, val);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "rcu_preempt_depth()"
          ],
          "line": 757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 757
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "t->rcu_read_unlock_special.b.blocked",
            "true"
          ],
          "line": 756
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 755
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1569-1572",
          "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!list_empty(&current->rcu_node_entry)"
          ],
          "line": 753
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&current->rcu_node_entry"
          ],
          "line": 753
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid exit_rcu(void)\n{\n\tstruct task_struct *t = current;\n\n\tif (unlikely(!list_empty(&current->rcu_node_entry))) {\n\t\trcu_preempt_depth_set(1);\n\t\tbarrier();\n\t\tWRITE_ONCE(t->rcu_read_unlock_special.b.blocked, true);\n\t} else if (unlikely(rcu_preempt_depth())) {\n\t\trcu_preempt_depth_set(1);\n\t} else {\n\t\treturn;\n\t}\n\t__rcu_read_unlock();\n\trcu_preempt_deferred_qs(current);\n}"
  },
  {
    "function_name": "rcu_flavor_sched_clock_irq",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "709-739",
    "snippet": "static void rcu_flavor_sched_clock_irq(int user)\n{\n\tstruct task_struct *t = current;\n\n\tlockdep_assert_irqs_disabled();\n\tif (user || rcu_is_cpu_rrupt_from_idle()) {\n\t\trcu_note_voluntary_context_switch(current);\n\t}\n\tif (rcu_preempt_depth() > 0 ||\n\t    (preempt_count() & (PREEMPT_MASK | SOFTIRQ_MASK))) {\n\t\t/* No QS, force context switch if deferred. */\n\t\tif (rcu_preempt_need_deferred_qs(t)) {\n\t\t\tset_tsk_need_resched(t);\n\t\t\tset_preempt_need_resched();\n\t\t}\n\t} else if (rcu_preempt_need_deferred_qs(t)) {\n\t\trcu_preempt_deferred_qs(t); /* Report deferred QS. */\n\t\treturn;\n\t} else if (!WARN_ON_ONCE(rcu_preempt_depth())) {\n\t\trcu_qs(); /* Report immediate QS. */\n\t\treturn;\n\t}\n\n\t/* If GP is oldish, ask for help from rcu_read_unlock_special(). */\n\tif (rcu_preempt_depth() > 0 &&\n\t    __this_cpu_read(rcu_data.core_needs_qs) &&\n\t    __this_cpu_read(rcu_data.cpu_no_qs.b.norm) &&\n\t    !t->rcu_read_unlock_special.b.need_qs &&\n\t    time_after(jiffies, rcu_state.gp_start + HZ))\n\t\tt->rcu_read_unlock_special.b.need_qs = true;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "time_after",
          "args": [
            "jiffies",
            "rcu_state.gp_start + HZ"
          ],
          "line": 737
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.cpu_no_qs.b.norm"
          ],
          "line": 735
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.core_needs_qs"
          ],
          "line": 734
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 733
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_qs",
          "args": [],
          "line": 728
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "842-852",
          "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rcu_preempt_depth()"
          ],
          "line": 727
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 727
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_deferred_qs",
          "args": [
            "t"
          ],
          "line": 725
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_deferred_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "933-939",
          "snippet": "static void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_preempt_need_deferred_qs",
          "args": [
            "t"
          ],
          "line": 724
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_need_deferred_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "924-927",
          "snippet": "static bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "set_preempt_need_resched",
          "args": [],
          "line": 722
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_tsk_need_resched",
          "args": [
            "t"
          ],
          "line": 721
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_count",
          "args": [],
          "line": 718
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 717
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_note_voluntary_context_switch",
          "args": [
            "current"
          ],
          "line": 715
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_is_cpu_rrupt_from_idle",
          "args": [],
          "line": 714
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_is_cpu_rrupt_from_idle",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "422-451",
          "snippet": "static int rcu_is_cpu_rrupt_from_idle(void)\n{\n\tlong nesting;\n\n\t/*\n\t * Usually called from the tick; but also used from smp_function_call()\n\t * for expedited grace periods. This latter can result in running from\n\t * the idle task, instead of an actual IPI.\n\t */\n\tlockdep_assert_irqs_disabled();\n\n\t/* Check for counter underflows */\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) < 0,\n\t\t\t \"RCU dynticks_nesting counter underflow!\");\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) <= 0,\n\t\t\t \"RCU dynticks_nmi_nesting counter underflow/zero!\");\n\n\t/* Are we at first interrupt nesting level? */\n\tnesting = __this_cpu_read(rcu_data.dynticks_nmi_nesting);\n\tif (nesting > 1)\n\t\treturn false;\n\n\t/*\n\t * If we're not in an interrupt, we must be in the idle task!\n\t */\n\tWARN_ON_ONCE(!nesting && !is_idle_task(current));\n\n\t/* Does CPU appear to be idle from an RCU standpoint? */\n\treturn __this_cpu_read(rcu_data.dynticks_nesting) == 0;\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};\n\nstatic int rcu_is_cpu_rrupt_from_idle(void)\n{\n\tlong nesting;\n\n\t/*\n\t * Usually called from the tick; but also used from smp_function_call()\n\t * for expedited grace periods. This latter can result in running from\n\t * the idle task, instead of an actual IPI.\n\t */\n\tlockdep_assert_irqs_disabled();\n\n\t/* Check for counter underflows */\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nesting) < 0,\n\t\t\t \"RCU dynticks_nesting counter underflow!\");\n\tRCU_LOCKDEP_WARN(__this_cpu_read(rcu_data.dynticks_nmi_nesting) <= 0,\n\t\t\t \"RCU dynticks_nmi_nesting counter underflow/zero!\");\n\n\t/* Are we at first interrupt nesting level? */\n\tnesting = __this_cpu_read(rcu_data.dynticks_nmi_nesting);\n\tif (nesting > 1)\n\t\treturn false;\n\n\t/*\n\t * If we're not in an interrupt, we must be in the idle task!\n\t */\n\tWARN_ON_ONCE(!nesting && !is_idle_task(current));\n\n\t/* Does CPU appear to be idle from an RCU standpoint? */\n\treturn __this_cpu_read(rcu_data.dynticks_nesting) == 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_assert_irqs_disabled",
          "args": [],
          "line": 713
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_flavor_sched_clock_irq(int user)\n{\n\tstruct task_struct *t = current;\n\n\tlockdep_assert_irqs_disabled();\n\tif (user || rcu_is_cpu_rrupt_from_idle()) {\n\t\trcu_note_voluntary_context_switch(current);\n\t}\n\tif (rcu_preempt_depth() > 0 ||\n\t    (preempt_count() & (PREEMPT_MASK | SOFTIRQ_MASK))) {\n\t\t/* No QS, force context switch if deferred. */\n\t\tif (rcu_preempt_need_deferred_qs(t)) {\n\t\t\tset_tsk_need_resched(t);\n\t\t\tset_preempt_need_resched();\n\t\t}\n\t} else if (rcu_preempt_need_deferred_qs(t)) {\n\t\trcu_preempt_deferred_qs(t); /* Report deferred QS. */\n\t\treturn;\n\t} else if (!WARN_ON_ONCE(rcu_preempt_depth())) {\n\t\trcu_qs(); /* Report immediate QS. */\n\t\treturn;\n\t}\n\n\t/* If GP is oldish, ask for help from rcu_read_unlock_special(). */\n\tif (rcu_preempt_depth() > 0 &&\n\t    __this_cpu_read(rcu_data.core_needs_qs) &&\n\t    __this_cpu_read(rcu_data.cpu_no_qs.b.norm) &&\n\t    !t->rcu_read_unlock_special.b.need_qs &&\n\t    time_after(jiffies, rcu_state.gp_start + HZ))\n\t\tt->rcu_read_unlock_special.b.need_qs = true;\n}"
  },
  {
    "function_name": "rcu_preempt_check_blocked_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "683-700",
    "snippet": "static void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)\n{\n\tstruct task_struct *t;\n\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_preempt_check_blocked_tasks() invoked with preemption enabled!!!\\n\");\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tif (WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)))\n\t\tdump_blkd_tasks(rnp, 10);\n\tif (rcu_preempt_has_tasks(rnp) &&\n\t    (rnp->qsmaskinit || rnp->wait_blkd_tasks)) {\n\t\tWRITE_ONCE(rnp->gp_tasks, rnp->blkd_tasks.next);\n\t\tt = container_of(rnp->gp_tasks, struct task_struct,\n\t\t\t\t rcu_node_entry);\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt-GPS\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t}\n\tWARN_ON_ONCE(rnp->qsmask);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rnp->qsmask"
          ],
          "line": 699
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_unlock_preempted_task",
          "args": [
            "TPS(\"rcu_preempt-GPS\")",
            "rnp->gp_seq",
            "t->pid"
          ],
          "line": 696
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"rcu_preempt-GPS\""
          ],
          "line": 696
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "rnp->gp_tasks",
            "structtask_struct",
            "rcu_node_entry"
          ],
          "line": 694
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->gp_tasks",
            "rnp->blkd_tasks.next"
          ],
          "line": 693
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_has_tasks",
          "args": [
            "rnp"
          ],
          "line": 691
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_has_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "915-918",
          "snippet": "static bool rcu_preempt_has_tasks(struct rcu_node *rnp)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_has_tasks(struct rcu_node *rnp)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "dump_blkd_tasks",
          "args": [
            "rnp",
            "10"
          ],
          "line": 690
        },
        "resolved": true,
        "details": {
          "function_name": "dump_blkd_tasks",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "986-990",
          "snippet": "static void\ndump_blkd_tasks(struct rcu_node *rnp, int ncheck)\n{\n\tWARN_ON_ONCE(!list_empty(&rnp->blkd_tasks));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void\ndump_blkd_tasks(struct rcu_node *rnp, int ncheck)\n{\n\tWARN_ON_ONCE(!list_empty(&rnp->blkd_tasks));\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rcu_preempt_blocked_readers_cgp(rnp)"
          ],
          "line": 689
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_blocked_readers_cgp",
          "args": [
            "rnp"
          ],
          "line": 689
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_blocked_readers_cgp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "907-910",
          "snippet": "static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_lockdep_assert_held_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 688
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RCU_LOCKDEP_WARN",
          "args": [
            "preemptible()",
            "\"rcu_preempt_check_blocked_tasks() invoked with preemption enabled!!!\\n\""
          ],
          "line": 687
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preemptible",
          "args": [],
          "line": 687
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_check_blocked_tasks(struct rcu_node *rnp)\n{\n\tstruct task_struct *t;\n\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_preempt_check_blocked_tasks() invoked with preemption enabled!!!\\n\");\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tif (WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)))\n\t\tdump_blkd_tasks(rnp, 10);\n\tif (rcu_preempt_has_tasks(rnp) &&\n\t    (rnp->qsmaskinit || rnp->wait_blkd_tasks)) {\n\t\tWRITE_ONCE(rnp->gp_tasks, rnp->blkd_tasks.next);\n\t\tt = container_of(rnp->gp_tasks, struct task_struct,\n\t\t\t\t rcu_node_entry);\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt-GPS\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t}\n\tWARN_ON_ONCE(rnp->qsmask);\n}"
  },
  {
    "function_name": "rcu_read_unlock_special",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "623-672",
    "snippet": "static void rcu_read_unlock_special(struct task_struct *t)\n{\n\tunsigned long flags;\n\tbool irqs_were_disabled;\n\tbool preempt_bh_were_disabled =\n\t\t\t!!(preempt_count() & (PREEMPT_MASK | SOFTIRQ_MASK));\n\n\t/* NMI handlers cannot block and cannot safely manipulate state. */\n\tif (in_nmi())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\tirqs_were_disabled = irqs_disabled_flags(flags);\n\tif (preempt_bh_were_disabled || irqs_were_disabled) {\n\t\tbool expboost; // Expedited GP in flight or possible boosting.\n\t\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\t\tstruct rcu_node *rnp = rdp->mynode;\n\n\t\texpboost = (t->rcu_blocked_node && READ_ONCE(t->rcu_blocked_node->exp_tasks)) ||\n\t\t\t   (rdp->grpmask & READ_ONCE(rnp->expmask)) ||\n\t\t\t   IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ||\n\t\t\t   (IS_ENABLED(CONFIG_RCU_BOOST) && irqs_were_disabled &&\n\t\t\t    t->rcu_blocked_node);\n\t\t// Need to defer quiescent state until everything is enabled.\n\t\tif (use_softirq && (in_hardirq() || (expboost && !irqs_were_disabled))) {\n\t\t\t// Using softirq, safe to awaken, and either the\n\t\t\t// wakeup is free or there is either an expedited\n\t\t\t// GP in flight or a potential need to deboost.\n\t\t\traise_softirq_irqoff(RCU_SOFTIRQ);\n\t\t} else {\n\t\t\t// Enabling BH or preempt does reschedule, so...\n\t\t\t// Also if no expediting and no possible deboosting,\n\t\t\t// slow is OK.  Plus nohz_full CPUs eventually get\n\t\t\t// tick enabled.\n\t\t\tset_tsk_need_resched(current);\n\t\t\tset_preempt_need_resched();\n\t\t\tif (IS_ENABLED(CONFIG_IRQ_WORK) && irqs_were_disabled &&\n\t\t\t    expboost && !rdp->defer_qs_iw_pending && cpu_online(rdp->cpu)) {\n\t\t\t\t// Get scheduler to re-evaluate and call hooks.\n\t\t\t\t// If !IRQ_WORK, FQS scan will eventually IPI.\n\t\t\t\tinit_irq_work(&rdp->defer_qs_iw, rcu_preempt_deferred_qs_handler);\n\t\t\t\trdp->defer_qs_iw_pending = true;\n\t\t\t\tirq_work_queue_on(&rdp->defer_qs_iw, rdp->cpu);\n\t\t\t}\n\t\t}\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\trcu_preempt_deferred_qs_irqrestore(t, flags);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_preempt_deferred_qs_irqrestore",
          "args": [
            "t",
            "flags"
          ],
          "line": 671
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_deferred_qs_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "463-572",
          "snippet": "static void\nrcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)\n{\n\tbool empty_exp;\n\tbool empty_norm;\n\tbool empty_exp_now;\n\tstruct list_head *np;\n\tbool drop_boost_mutex = false;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tunion rcu_special special;\n\n\t/*\n\t * If RCU core is waiting for this CPU to exit its critical section,\n\t * report the fact that it has exited.  Because irqs are disabled,\n\t * t->rcu_read_unlock_special cannot change.\n\t */\n\tspecial = t->rcu_read_unlock_special;\n\trdp = this_cpu_ptr(&rcu_data);\n\tif (!special.s && !rdp->cpu_no_qs.b.exp) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tt->rcu_read_unlock_special.s = 0;\n\tif (special.b.need_qs) {\n\t\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {\n\t\t\trcu_report_qs_rdp(rdp);\n\t\t\tudelay(rcu_unlock_delay);\n\t\t} else {\n\t\t\trcu_qs();\n\t\t}\n\t}\n\n\t/*\n\t * Respond to a request by an expedited grace period for a\n\t * quiescent state from this CPU.  Note that requests from\n\t * tasks are handled when removing the task from the\n\t * blocked-tasks list below.\n\t */\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\n\t/* Clean up if blocked during RCU read-side critical section. */\n\tif (special.b.blocked) {\n\n\t\t/*\n\t\t * Remove this task from the list it blocked on.  The task\n\t\t * now remains queued on the rcu_node corresponding to the\n\t\t * CPU it first blocked on, so there is no longer any need\n\t\t * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.\n\t\t */\n\t\trnp = t->rcu_blocked_node;\n\t\traw_spin_lock_rcu_node(rnp); /* irqs already disabled. */\n\t\tWARN_ON_ONCE(rnp != t->rcu_blocked_node);\n\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t\tempty_norm = !rcu_preempt_blocked_readers_cgp(rnp);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask));\n\t\tempty_exp = sync_rcu_exp_done(rnp);\n\t\tsmp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */\n\t\tnp = rcu_next_node_entry(t, rnp);\n\t\tlist_del_init(&t->rcu_node_entry);\n\t\tt->rcu_blocked_node = NULL;\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t\tif (&t->rcu_node_entry == rnp->gp_tasks)\n\t\t\tWRITE_ONCE(rnp->gp_tasks, np);\n\t\tif (&t->rcu_node_entry == rnp->exp_tasks)\n\t\t\tWRITE_ONCE(rnp->exp_tasks, np);\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST)) {\n\t\t\t/* Snapshot ->boost_mtx ownership w/rnp->lock held. */\n\t\t\tdrop_boost_mutex = rt_mutex_owner(&rnp->boost_mtx.rtmutex) == t;\n\t\t\tif (&t->rcu_node_entry == rnp->boost_tasks)\n\t\t\t\tWRITE_ONCE(rnp->boost_tasks, np);\n\t\t}\n\n\t\t/*\n\t\t * If this was the last task on the current list, and if\n\t\t * we aren't waiting on any CPUs, report the quiescent state.\n\t\t * Note that rcu_report_unblock_qs_rnp() releases rnp->lock,\n\t\t * so we must take a snapshot of the expedited state.\n\t\t */\n\t\tempty_exp_now = sync_rcu_exp_done(rnp);\n\t\tif (!empty_norm && !rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\t\ttrace_rcu_quiescent_state_report(TPS(\"preempt_rcu\"),\n\t\t\t\t\t\t\t rnp->gp_seq,\n\t\t\t\t\t\t\t 0, rnp->qsmask,\n\t\t\t\t\t\t\t rnp->level,\n\t\t\t\t\t\t\t rnp->grplo,\n\t\t\t\t\t\t\t rnp->grphi,\n\t\t\t\t\t\t\t !!rnp->gp_tasks);\n\t\t\trcu_report_unblock_qs_rnp(rnp, flags);\n\t\t} else {\n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t}\n\n\t\t/* Unboost if we were boosted. */\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST) && drop_boost_mutex)\n\t\t\trt_mutex_futex_unlock(&rnp->boost_mtx.rtmutex);\n\n\t\t/*\n\t\t * If this was the last task on the expedited lists,\n\t\t * then we need to report up the rcu_node hierarchy.\n\t\t */\n\t\tif (!empty_exp && empty_exp_now)\n\t\t\trcu_report_exp_rnp(rnp, true);\n\t} else {\n\t\tlocal_irq_restore(flags);\n\t}\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void\nrcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)\n{\n\tbool empty_exp;\n\tbool empty_norm;\n\tbool empty_exp_now;\n\tstruct list_head *np;\n\tbool drop_boost_mutex = false;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tunion rcu_special special;\n\n\t/*\n\t * If RCU core is waiting for this CPU to exit its critical section,\n\t * report the fact that it has exited.  Because irqs are disabled,\n\t * t->rcu_read_unlock_special cannot change.\n\t */\n\tspecial = t->rcu_read_unlock_special;\n\trdp = this_cpu_ptr(&rcu_data);\n\tif (!special.s && !rdp->cpu_no_qs.b.exp) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tt->rcu_read_unlock_special.s = 0;\n\tif (special.b.need_qs) {\n\t\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {\n\t\t\trcu_report_qs_rdp(rdp);\n\t\t\tudelay(rcu_unlock_delay);\n\t\t} else {\n\t\t\trcu_qs();\n\t\t}\n\t}\n\n\t/*\n\t * Respond to a request by an expedited grace period for a\n\t * quiescent state from this CPU.  Note that requests from\n\t * tasks are handled when removing the task from the\n\t * blocked-tasks list below.\n\t */\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\n\t/* Clean up if blocked during RCU read-side critical section. */\n\tif (special.b.blocked) {\n\n\t\t/*\n\t\t * Remove this task from the list it blocked on.  The task\n\t\t * now remains queued on the rcu_node corresponding to the\n\t\t * CPU it first blocked on, so there is no longer any need\n\t\t * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.\n\t\t */\n\t\trnp = t->rcu_blocked_node;\n\t\traw_spin_lock_rcu_node(rnp); /* irqs already disabled. */\n\t\tWARN_ON_ONCE(rnp != t->rcu_blocked_node);\n\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t\tempty_norm = !rcu_preempt_blocked_readers_cgp(rnp);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask));\n\t\tempty_exp = sync_rcu_exp_done(rnp);\n\t\tsmp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */\n\t\tnp = rcu_next_node_entry(t, rnp);\n\t\tlist_del_init(&t->rcu_node_entry);\n\t\tt->rcu_blocked_node = NULL;\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t\tif (&t->rcu_node_entry == rnp->gp_tasks)\n\t\t\tWRITE_ONCE(rnp->gp_tasks, np);\n\t\tif (&t->rcu_node_entry == rnp->exp_tasks)\n\t\t\tWRITE_ONCE(rnp->exp_tasks, np);\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST)) {\n\t\t\t/* Snapshot ->boost_mtx ownership w/rnp->lock held. */\n\t\t\tdrop_boost_mutex = rt_mutex_owner(&rnp->boost_mtx.rtmutex) == t;\n\t\t\tif (&t->rcu_node_entry == rnp->boost_tasks)\n\t\t\t\tWRITE_ONCE(rnp->boost_tasks, np);\n\t\t}\n\n\t\t/*\n\t\t * If this was the last task on the current list, and if\n\t\t * we aren't waiting on any CPUs, report the quiescent state.\n\t\t * Note that rcu_report_unblock_qs_rnp() releases rnp->lock,\n\t\t * so we must take a snapshot of the expedited state.\n\t\t */\n\t\tempty_exp_now = sync_rcu_exp_done(rnp);\n\t\tif (!empty_norm && !rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\t\ttrace_rcu_quiescent_state_report(TPS(\"preempt_rcu\"),\n\t\t\t\t\t\t\t rnp->gp_seq,\n\t\t\t\t\t\t\t 0, rnp->qsmask,\n\t\t\t\t\t\t\t rnp->level,\n\t\t\t\t\t\t\t rnp->grplo,\n\t\t\t\t\t\t\t rnp->grphi,\n\t\t\t\t\t\t\t !!rnp->gp_tasks);\n\t\t\trcu_report_unblock_qs_rnp(rnp, flags);\n\t\t} else {\n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t}\n\n\t\t/* Unboost if we were boosted. */\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST) && drop_boost_mutex)\n\t\t\trt_mutex_futex_unlock(&rnp->boost_mtx.rtmutex);\n\n\t\t/*\n\t\t * If this was the last task on the expedited lists,\n\t\t * then we need to report up the rcu_node hierarchy.\n\t\t */\n\t\tif (!empty_exp && empty_exp_now)\n\t\t\trcu_report_exp_rnp(rnp, true);\n\t} else {\n\t\tlocal_irq_restore(flags);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 668
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irq_work_queue_on",
          "args": [
            "&rdp->defer_qs_iw",
            "rdp->cpu"
          ],
          "line": 665
        },
        "resolved": true,
        "details": {
          "function_name": "irq_work_queue_on",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/irq_work.c",
          "lines": "127-172",
          "snippet": "bool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n#ifndef CONFIG_SMP\n\treturn irq_work_queue(work);\n\n#else /* CONFIG_SMP: */\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tkasan_record_aux_stack(work);\n\n\tpreempt_disable();\n\tif (cpu != smp_processor_id()) {\n\t\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\t\tWARN_ON_ONCE(in_nmi());\n\n\t\t/*\n\t\t * On PREEMPT_RT the items which are not marked as\n\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work\n\t\t * item is used on the remote CPU to wake the thread.\n\t\t */\n\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&\n\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {\n\n\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))\n\t\t\t\tgoto out;\n\n\t\t\twork = &per_cpu(irq_work_wakeup, cpu);\n\t\t\tif (!irq_work_claim(work))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t__smp_call_single_queue(cpu, &work->node.llist);\n\t} else {\n\t\t__irq_work_queue_local(work);\n\t}\nout:\n\tpreempt_enable();\n\n\treturn true;\n#endif /* CONFIG_SMP */\n}",
          "includes": [
            "#include <linux/kasan.h>",
            "#include <asm/processor.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/tick.h>",
            "#include <linux/sched.h>",
            "#include <linux/irqflags.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/percpu.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/export.h>",
            "#include <linux/kernel.h>",
            "#include <linux/bug.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU(struct llist_head, lazy_list);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/kasan.h>\n#include <asm/processor.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/tick.h>\n#include <linux/sched.h>\n#include <linux/irqflags.h>\n#include <linux/hardirq.h>\n#include <linux/percpu.h>\n#include <linux/irq_work.h>\n#include <linux/export.h>\n#include <linux/kernel.h>\n#include <linux/bug.h>\n\nstatic DEFINE_PER_CPU(struct llist_head, lazy_list);\n\nbool irq_work_queue_on(struct irq_work *work, int cpu)\n{\n#ifndef CONFIG_SMP\n\treturn irq_work_queue(work);\n\n#else /* CONFIG_SMP: */\n\t/* All work should have been flushed before going offline */\n\tWARN_ON_ONCE(cpu_is_offline(cpu));\n\n\t/* Only queue if not already pending */\n\tif (!irq_work_claim(work))\n\t\treturn false;\n\n\tkasan_record_aux_stack(work);\n\n\tpreempt_disable();\n\tif (cpu != smp_processor_id()) {\n\t\t/* Arch remote IPI send/receive backend aren't NMI safe */\n\t\tWARN_ON_ONCE(in_nmi());\n\n\t\t/*\n\t\t * On PREEMPT_RT the items which are not marked as\n\t\t * IRQ_WORK_HARD_IRQ are added to the lazy list and a HARD work\n\t\t * item is used on the remote CPU to wake the thread.\n\t\t */\n\t\tif (IS_ENABLED(CONFIG_PREEMPT_RT) &&\n\t\t    !(atomic_read(&work->node.a_flags) & IRQ_WORK_HARD_IRQ)) {\n\n\t\t\tif (!llist_add(&work->node.llist, &per_cpu(lazy_list, cpu)))\n\t\t\t\tgoto out;\n\n\t\t\twork = &per_cpu(irq_work_wakeup, cpu);\n\t\t\tif (!irq_work_claim(work))\n\t\t\t\tgoto out;\n\t\t}\n\n\t\t__smp_call_single_queue(cpu, &work->node.llist);\n\t} else {\n\t\t__irq_work_queue_local(work);\n\t}\nout:\n\tpreempt_enable();\n\n\treturn true;\n#endif /* CONFIG_SMP */\n}"
        }
      },
      {
        "call_info": {
          "callee": "init_irq_work",
          "args": [
            "&rdp->defer_qs_iw",
            "rcu_preempt_deferred_qs_handler"
          ],
          "line": 663
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cpu_online",
          "args": [
            "rdp->cpu"
          ],
          "line": 660
        },
        "resolved": true,
        "details": {
          "function_name": "init_cpu_online",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "2616-2619",
          "snippet": "void init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "struct cpumask __cpu_online_mask"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nstruct cpumask __cpu_online_mask;\n\nvoid init_cpu_online(const struct cpumask *src)\n{\n\tcpumask_copy(&__cpu_online_mask, src);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_IRQ_WORK"
          ],
          "line": 659
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_preempt_need_resched",
          "args": [],
          "line": 658
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_tsk_need_resched",
          "args": [
            "current"
          ],
          "line": 657
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raise_softirq_irqoff",
          "args": [
            "RCU_SOFTIRQ"
          ],
          "line": 651
        },
        "resolved": true,
        "details": {
          "function_name": "__raise_softirq_irqoff",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/softirq.c",
          "lines": "696-701",
          "snippet": "void __raise_softirq_irqoff(unsigned int nr)\n{\n\tlockdep_assert_irqs_disabled();\n\ttrace_softirq_raise(nr);\n\tor_softirq_pending(1UL << nr);\n}",
          "includes": [
            "#include <trace/events/irq.h>",
            "#include <asm/softirq_stack.h>",
            "#include <linux/wait_bit.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/smp.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/kthread.h>",
            "#include <linux/freezer.h>",
            "#include <linux/cpu.h>",
            "#include <linux/percpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/mm.h>",
            "#include <linux/local_lock.h>",
            "#include <linux/init.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/irq.h>\n#include <asm/softirq_stack.h>\n#include <linux/wait_bit.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/smpboot.h>\n#include <linux/smp.h>\n#include <linux/ftrace.h>\n#include <linux/rcupdate.h>\n#include <linux/kthread.h>\n#include <linux/freezer.h>\n#include <linux/cpu.h>\n#include <linux/percpu.h>\n#include <linux/notifier.h>\n#include <linux/mm.h>\n#include <linux/local_lock.h>\n#include <linux/init.h>\n#include <linux/interrupt.h>\n#include <linux/kernel_stat.h>\n#include <linux/export.h>\n\nvoid __raise_softirq_irqoff(unsigned int nr)\n{\n\tlockdep_assert_irqs_disabled();\n\ttrace_softirq_raise(nr);\n\tor_softirq_pending(1UL << nr);\n}"
        }
      },
      {
        "call_info": {
          "callee": "in_hardirq",
          "args": [],
          "line": 647
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_BOOST"
          ],
          "line": 644
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_STRICT_GRACE_PERIOD"
          ],
          "line": 643
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->expmask"
          ],
          "line": 642
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->rcu_blocked_node->exp_tasks"
          ],
          "line": 641
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 638
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "irqs_disabled_flags",
          "args": [
            "flags"
          ],
          "line": 635
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 634
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "in_nmi",
          "args": [],
          "line": 631
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preempt_count",
          "args": [],
          "line": 628
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_read_unlock_special(struct task_struct *t)\n{\n\tunsigned long flags;\n\tbool irqs_were_disabled;\n\tbool preempt_bh_were_disabled =\n\t\t\t!!(preempt_count() & (PREEMPT_MASK | SOFTIRQ_MASK));\n\n\t/* NMI handlers cannot block and cannot safely manipulate state. */\n\tif (in_nmi())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\tirqs_were_disabled = irqs_disabled_flags(flags);\n\tif (preempt_bh_were_disabled || irqs_were_disabled) {\n\t\tbool expboost; // Expedited GP in flight or possible boosting.\n\t\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\t\tstruct rcu_node *rnp = rdp->mynode;\n\n\t\texpboost = (t->rcu_blocked_node && READ_ONCE(t->rcu_blocked_node->exp_tasks)) ||\n\t\t\t   (rdp->grpmask & READ_ONCE(rnp->expmask)) ||\n\t\t\t   IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ||\n\t\t\t   (IS_ENABLED(CONFIG_RCU_BOOST) && irqs_were_disabled &&\n\t\t\t    t->rcu_blocked_node);\n\t\t// Need to defer quiescent state until everything is enabled.\n\t\tif (use_softirq && (in_hardirq() || (expboost && !irqs_were_disabled))) {\n\t\t\t// Using softirq, safe to awaken, and either the\n\t\t\t// wakeup is free or there is either an expedited\n\t\t\t// GP in flight or a potential need to deboost.\n\t\t\traise_softirq_irqoff(RCU_SOFTIRQ);\n\t\t} else {\n\t\t\t// Enabling BH or preempt does reschedule, so...\n\t\t\t// Also if no expediting and no possible deboosting,\n\t\t\t// slow is OK.  Plus nohz_full CPUs eventually get\n\t\t\t// tick enabled.\n\t\t\tset_tsk_need_resched(current);\n\t\t\tset_preempt_need_resched();\n\t\t\tif (IS_ENABLED(CONFIG_IRQ_WORK) && irqs_were_disabled &&\n\t\t\t    expboost && !rdp->defer_qs_iw_pending && cpu_online(rdp->cpu)) {\n\t\t\t\t// Get scheduler to re-evaluate and call hooks.\n\t\t\t\t// If !IRQ_WORK, FQS scan will eventually IPI.\n\t\t\t\tinit_irq_work(&rdp->defer_qs_iw, rcu_preempt_deferred_qs_handler);\n\t\t\t\trdp->defer_qs_iw_pending = true;\n\t\t\t\tirq_work_queue_on(&rdp->defer_qs_iw, rdp->cpu);\n\t\t\t}\n\t\t}\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\trcu_preempt_deferred_qs_irqrestore(t, flags);\n}"
  },
  {
    "function_name": "rcu_preempt_deferred_qs_handler",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "610-616",
    "snippet": "static void rcu_preempt_deferred_qs_handler(struct irq_work *iwp)\n{\n\tstruct rcu_data *rdp;\n\n\trdp = container_of(iwp, struct rcu_data, defer_qs_iw);\n\trdp->defer_qs_iw_pending = false;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "container_of",
          "args": [
            "iwp",
            "structrcu_data",
            "defer_qs_iw"
          ],
          "line": 614
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_deferred_qs_handler(struct irq_work *iwp)\n{\n\tstruct rcu_data *rdp;\n\n\trdp = container_of(iwp, struct rcu_data, defer_qs_iw);\n\trdp->defer_qs_iw_pending = false;\n}"
  },
  {
    "function_name": "rcu_preempt_deferred_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "597-605",
    "snippet": "static void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tunsigned long flags;\n\n\tif (!rcu_preempt_need_deferred_qs(t))\n\t\treturn;\n\tlocal_irq_save(flags);\n\trcu_preempt_deferred_qs_irqrestore(t, flags);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_preempt_deferred_qs_irqrestore",
          "args": [
            "t",
            "flags"
          ],
          "line": 604
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_deferred_qs_irqrestore",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "463-572",
          "snippet": "static void\nrcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)\n{\n\tbool empty_exp;\n\tbool empty_norm;\n\tbool empty_exp_now;\n\tstruct list_head *np;\n\tbool drop_boost_mutex = false;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tunion rcu_special special;\n\n\t/*\n\t * If RCU core is waiting for this CPU to exit its critical section,\n\t * report the fact that it has exited.  Because irqs are disabled,\n\t * t->rcu_read_unlock_special cannot change.\n\t */\n\tspecial = t->rcu_read_unlock_special;\n\trdp = this_cpu_ptr(&rcu_data);\n\tif (!special.s && !rdp->cpu_no_qs.b.exp) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tt->rcu_read_unlock_special.s = 0;\n\tif (special.b.need_qs) {\n\t\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {\n\t\t\trcu_report_qs_rdp(rdp);\n\t\t\tudelay(rcu_unlock_delay);\n\t\t} else {\n\t\t\trcu_qs();\n\t\t}\n\t}\n\n\t/*\n\t * Respond to a request by an expedited grace period for a\n\t * quiescent state from this CPU.  Note that requests from\n\t * tasks are handled when removing the task from the\n\t * blocked-tasks list below.\n\t */\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\n\t/* Clean up if blocked during RCU read-side critical section. */\n\tif (special.b.blocked) {\n\n\t\t/*\n\t\t * Remove this task from the list it blocked on.  The task\n\t\t * now remains queued on the rcu_node corresponding to the\n\t\t * CPU it first blocked on, so there is no longer any need\n\t\t * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.\n\t\t */\n\t\trnp = t->rcu_blocked_node;\n\t\traw_spin_lock_rcu_node(rnp); /* irqs already disabled. */\n\t\tWARN_ON_ONCE(rnp != t->rcu_blocked_node);\n\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t\tempty_norm = !rcu_preempt_blocked_readers_cgp(rnp);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask));\n\t\tempty_exp = sync_rcu_exp_done(rnp);\n\t\tsmp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */\n\t\tnp = rcu_next_node_entry(t, rnp);\n\t\tlist_del_init(&t->rcu_node_entry);\n\t\tt->rcu_blocked_node = NULL;\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t\tif (&t->rcu_node_entry == rnp->gp_tasks)\n\t\t\tWRITE_ONCE(rnp->gp_tasks, np);\n\t\tif (&t->rcu_node_entry == rnp->exp_tasks)\n\t\t\tWRITE_ONCE(rnp->exp_tasks, np);\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST)) {\n\t\t\t/* Snapshot ->boost_mtx ownership w/rnp->lock held. */\n\t\t\tdrop_boost_mutex = rt_mutex_owner(&rnp->boost_mtx.rtmutex) == t;\n\t\t\tif (&t->rcu_node_entry == rnp->boost_tasks)\n\t\t\t\tWRITE_ONCE(rnp->boost_tasks, np);\n\t\t}\n\n\t\t/*\n\t\t * If this was the last task on the current list, and if\n\t\t * we aren't waiting on any CPUs, report the quiescent state.\n\t\t * Note that rcu_report_unblock_qs_rnp() releases rnp->lock,\n\t\t * so we must take a snapshot of the expedited state.\n\t\t */\n\t\tempty_exp_now = sync_rcu_exp_done(rnp);\n\t\tif (!empty_norm && !rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\t\ttrace_rcu_quiescent_state_report(TPS(\"preempt_rcu\"),\n\t\t\t\t\t\t\t rnp->gp_seq,\n\t\t\t\t\t\t\t 0, rnp->qsmask,\n\t\t\t\t\t\t\t rnp->level,\n\t\t\t\t\t\t\t rnp->grplo,\n\t\t\t\t\t\t\t rnp->grphi,\n\t\t\t\t\t\t\t !!rnp->gp_tasks);\n\t\t\trcu_report_unblock_qs_rnp(rnp, flags);\n\t\t} else {\n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t}\n\n\t\t/* Unboost if we were boosted. */\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST) && drop_boost_mutex)\n\t\t\trt_mutex_futex_unlock(&rnp->boost_mtx.rtmutex);\n\n\t\t/*\n\t\t * If this was the last task on the expedited lists,\n\t\t * then we need to report up the rcu_node hierarchy.\n\t\t */\n\t\tif (!empty_exp && empty_exp_now)\n\t\t\trcu_report_exp_rnp(rnp, true);\n\t} else {\n\t\tlocal_irq_restore(flags);\n\t}\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void\nrcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)\n{\n\tbool empty_exp;\n\tbool empty_norm;\n\tbool empty_exp_now;\n\tstruct list_head *np;\n\tbool drop_boost_mutex = false;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tunion rcu_special special;\n\n\t/*\n\t * If RCU core is waiting for this CPU to exit its critical section,\n\t * report the fact that it has exited.  Because irqs are disabled,\n\t * t->rcu_read_unlock_special cannot change.\n\t */\n\tspecial = t->rcu_read_unlock_special;\n\trdp = this_cpu_ptr(&rcu_data);\n\tif (!special.s && !rdp->cpu_no_qs.b.exp) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tt->rcu_read_unlock_special.s = 0;\n\tif (special.b.need_qs) {\n\t\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {\n\t\t\trcu_report_qs_rdp(rdp);\n\t\t\tudelay(rcu_unlock_delay);\n\t\t} else {\n\t\t\trcu_qs();\n\t\t}\n\t}\n\n\t/*\n\t * Respond to a request by an expedited grace period for a\n\t * quiescent state from this CPU.  Note that requests from\n\t * tasks are handled when removing the task from the\n\t * blocked-tasks list below.\n\t */\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\n\t/* Clean up if blocked during RCU read-side critical section. */\n\tif (special.b.blocked) {\n\n\t\t/*\n\t\t * Remove this task from the list it blocked on.  The task\n\t\t * now remains queued on the rcu_node corresponding to the\n\t\t * CPU it first blocked on, so there is no longer any need\n\t\t * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.\n\t\t */\n\t\trnp = t->rcu_blocked_node;\n\t\traw_spin_lock_rcu_node(rnp); /* irqs already disabled. */\n\t\tWARN_ON_ONCE(rnp != t->rcu_blocked_node);\n\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t\tempty_norm = !rcu_preempt_blocked_readers_cgp(rnp);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask));\n\t\tempty_exp = sync_rcu_exp_done(rnp);\n\t\tsmp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */\n\t\tnp = rcu_next_node_entry(t, rnp);\n\t\tlist_del_init(&t->rcu_node_entry);\n\t\tt->rcu_blocked_node = NULL;\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t\tif (&t->rcu_node_entry == rnp->gp_tasks)\n\t\t\tWRITE_ONCE(rnp->gp_tasks, np);\n\t\tif (&t->rcu_node_entry == rnp->exp_tasks)\n\t\t\tWRITE_ONCE(rnp->exp_tasks, np);\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST)) {\n\t\t\t/* Snapshot ->boost_mtx ownership w/rnp->lock held. */\n\t\t\tdrop_boost_mutex = rt_mutex_owner(&rnp->boost_mtx.rtmutex) == t;\n\t\t\tif (&t->rcu_node_entry == rnp->boost_tasks)\n\t\t\t\tWRITE_ONCE(rnp->boost_tasks, np);\n\t\t}\n\n\t\t/*\n\t\t * If this was the last task on the current list, and if\n\t\t * we aren't waiting on any CPUs, report the quiescent state.\n\t\t * Note that rcu_report_unblock_qs_rnp() releases rnp->lock,\n\t\t * so we must take a snapshot of the expedited state.\n\t\t */\n\t\tempty_exp_now = sync_rcu_exp_done(rnp);\n\t\tif (!empty_norm && !rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\t\ttrace_rcu_quiescent_state_report(TPS(\"preempt_rcu\"),\n\t\t\t\t\t\t\t rnp->gp_seq,\n\t\t\t\t\t\t\t 0, rnp->qsmask,\n\t\t\t\t\t\t\t rnp->level,\n\t\t\t\t\t\t\t rnp->grplo,\n\t\t\t\t\t\t\t rnp->grphi,\n\t\t\t\t\t\t\t !!rnp->gp_tasks);\n\t\t\trcu_report_unblock_qs_rnp(rnp, flags);\n\t\t} else {\n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t}\n\n\t\t/* Unboost if we were boosted. */\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST) && drop_boost_mutex)\n\t\t\trt_mutex_futex_unlock(&rnp->boost_mtx.rtmutex);\n\n\t\t/*\n\t\t * If this was the last task on the expedited lists,\n\t\t * then we need to report up the rcu_node hierarchy.\n\t\t */\n\t\tif (!empty_exp && empty_exp_now)\n\t\t\trcu_report_exp_rnp(rnp, true);\n\t} else {\n\t\tlocal_irq_restore(flags);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "local_irq_save",
          "args": [
            "flags"
          ],
          "line": 603
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_need_deferred_qs",
          "args": [
            "t"
          ],
          "line": 601
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_need_deferred_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "924-927",
          "snippet": "static bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn false;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn false;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tunsigned long flags;\n\n\tif (!rcu_preempt_need_deferred_qs(t))\n\t\treturn;\n\tlocal_irq_save(flags);\n\trcu_preempt_deferred_qs_irqrestore(t, flags);\n}"
  },
  {
    "function_name": "rcu_preempt_need_deferred_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "583-588",
    "snippet": "static bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn (__this_cpu_read(rcu_data.cpu_no_qs.b.exp) ||\n\t\tREAD_ONCE(t->rcu_read_unlock_special.s)) &&\n\t       rcu_preempt_depth() == 0;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 587
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->rcu_read_unlock_special.s"
          ],
          "line": 586
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.cpu_no_qs.b.exp"
          ],
          "line": 585
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_need_deferred_qs(struct task_struct *t)\n{\n\treturn (__this_cpu_read(rcu_data.cpu_no_qs.b.exp) ||\n\t\tREAD_ONCE(t->rcu_read_unlock_special.s)) &&\n\t       rcu_preempt_depth() == 0;\n}"
  },
  {
    "function_name": "rcu_preempt_deferred_qs_irqrestore",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "463-572",
    "snippet": "static void\nrcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)\n{\n\tbool empty_exp;\n\tbool empty_norm;\n\tbool empty_exp_now;\n\tstruct list_head *np;\n\tbool drop_boost_mutex = false;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tunion rcu_special special;\n\n\t/*\n\t * If RCU core is waiting for this CPU to exit its critical section,\n\t * report the fact that it has exited.  Because irqs are disabled,\n\t * t->rcu_read_unlock_special cannot change.\n\t */\n\tspecial = t->rcu_read_unlock_special;\n\trdp = this_cpu_ptr(&rcu_data);\n\tif (!special.s && !rdp->cpu_no_qs.b.exp) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tt->rcu_read_unlock_special.s = 0;\n\tif (special.b.need_qs) {\n\t\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {\n\t\t\trcu_report_qs_rdp(rdp);\n\t\t\tudelay(rcu_unlock_delay);\n\t\t} else {\n\t\t\trcu_qs();\n\t\t}\n\t}\n\n\t/*\n\t * Respond to a request by an expedited grace period for a\n\t * quiescent state from this CPU.  Note that requests from\n\t * tasks are handled when removing the task from the\n\t * blocked-tasks list below.\n\t */\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\n\t/* Clean up if blocked during RCU read-side critical section. */\n\tif (special.b.blocked) {\n\n\t\t/*\n\t\t * Remove this task from the list it blocked on.  The task\n\t\t * now remains queued on the rcu_node corresponding to the\n\t\t * CPU it first blocked on, so there is no longer any need\n\t\t * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.\n\t\t */\n\t\trnp = t->rcu_blocked_node;\n\t\traw_spin_lock_rcu_node(rnp); /* irqs already disabled. */\n\t\tWARN_ON_ONCE(rnp != t->rcu_blocked_node);\n\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t\tempty_norm = !rcu_preempt_blocked_readers_cgp(rnp);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask));\n\t\tempty_exp = sync_rcu_exp_done(rnp);\n\t\tsmp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */\n\t\tnp = rcu_next_node_entry(t, rnp);\n\t\tlist_del_init(&t->rcu_node_entry);\n\t\tt->rcu_blocked_node = NULL;\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t\tif (&t->rcu_node_entry == rnp->gp_tasks)\n\t\t\tWRITE_ONCE(rnp->gp_tasks, np);\n\t\tif (&t->rcu_node_entry == rnp->exp_tasks)\n\t\t\tWRITE_ONCE(rnp->exp_tasks, np);\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST)) {\n\t\t\t/* Snapshot ->boost_mtx ownership w/rnp->lock held. */\n\t\t\tdrop_boost_mutex = rt_mutex_owner(&rnp->boost_mtx.rtmutex) == t;\n\t\t\tif (&t->rcu_node_entry == rnp->boost_tasks)\n\t\t\t\tWRITE_ONCE(rnp->boost_tasks, np);\n\t\t}\n\n\t\t/*\n\t\t * If this was the last task on the current list, and if\n\t\t * we aren't waiting on any CPUs, report the quiescent state.\n\t\t * Note that rcu_report_unblock_qs_rnp() releases rnp->lock,\n\t\t * so we must take a snapshot of the expedited state.\n\t\t */\n\t\tempty_exp_now = sync_rcu_exp_done(rnp);\n\t\tif (!empty_norm && !rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\t\ttrace_rcu_quiescent_state_report(TPS(\"preempt_rcu\"),\n\t\t\t\t\t\t\t rnp->gp_seq,\n\t\t\t\t\t\t\t 0, rnp->qsmask,\n\t\t\t\t\t\t\t rnp->level,\n\t\t\t\t\t\t\t rnp->grplo,\n\t\t\t\t\t\t\t rnp->grphi,\n\t\t\t\t\t\t\t !!rnp->gp_tasks);\n\t\t\trcu_report_unblock_qs_rnp(rnp, flags);\n\t\t} else {\n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t}\n\n\t\t/* Unboost if we were boosted. */\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST) && drop_boost_mutex)\n\t\t\trt_mutex_futex_unlock(&rnp->boost_mtx.rtmutex);\n\n\t\t/*\n\t\t * If this was the last task on the expedited lists,\n\t\t * then we need to report up the rcu_node hierarchy.\n\t\t */\n\t\tif (!empty_exp && empty_exp_now)\n\t\t\trcu_report_exp_rnp(rnp, true);\n\t} else {\n\t\tlocal_irq_restore(flags);\n\t}\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 570
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_exp_rnp",
          "args": [
            "rnp",
            "true"
          ],
          "line": 568
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_exp_rnp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "218-224",
          "snippet": "static void __maybe_unused rcu_report_exp_rnp(struct rcu_node *rnp, bool wake)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\t__rcu_report_exp_rnp(rnp, wake, flags);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int rcu_print_task_exp_stall(struct rcu_node *rnp);",
            "static void __maybe_unused"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic int rcu_print_task_exp_stall(struct rcu_node *rnp);\nstatic void __maybe_unused;\n\nstatic void __maybe_unused rcu_report_exp_rnp(struct rcu_node *rnp, bool wake)\n{\n\tunsigned long flags;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\t__rcu_report_exp_rnp(rnp, wake, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rt_mutex_futex_unlock",
          "args": [
            "&rnp->boost_mtx.rtmutex"
          ],
          "line": 561
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_futex_unlock",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_api.c",
          "lines": "188-200",
          "snippet": "void __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\tbool postunlock;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\tif (postunlock)\n\t\trt_mutex_postunlock(&wqh);\n}",
          "includes": [
            "#include \"rtmutex.c\"",
            "#include <linux/export.h>",
            "#include <linux/spinlock.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rtmutex.c\"\n#include <linux/export.h>\n#include <linux/spinlock.h>\n\nvoid __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)\n{\n\tDEFINE_RT_WAKE_Q(wqh);\n\tunsigned long flags;\n\tbool postunlock;\n\n\traw_spin_lock_irqsave(&lock->wait_lock, flags);\n\tpostunlock = __rt_mutex_futex_unlock(lock, &wqh);\n\traw_spin_unlock_irqrestore(&lock->wait_lock, flags);\n\n\tif (postunlock)\n\t\trt_mutex_postunlock(&wqh);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_BOOST"
          ],
          "line": 560
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_irqrestore_rcu_node",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 556
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_unblock_qs_rnp",
          "args": [
            "rnp",
            "flags"
          ],
          "line": 554
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_unblock_qs_rnp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "2243-2276",
          "snippet": "static void __maybe_unused\nrcu_report_unblock_qs_rnp(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\tunsigned long gps;\n\tunsigned long mask;\n\tstruct rcu_node *rnp_p;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tif (WARN_ON_ONCE(!IS_ENABLED(CONFIG_PREEMPT_RCU)) ||\n\t    WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)) ||\n\t    rnp->qsmask != 0) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;  /* Still need more quiescent states! */\n\t}\n\n\trnp->completedqs = rnp->gp_seq;\n\trnp_p = rnp->parent;\n\tif (rnp_p == NULL) {\n\t\t/*\n\t\t * Only one rcu_node structure in the tree, so don't\n\t\t * try to report up to its nonexistent parent!\n\t\t */\n\t\trcu_report_qs_rsp(flags);\n\t\treturn;\n\t}\n\n\t/* Report up the rest of the hierarchy, tracking current ->gp_seq. */\n\tgps = rnp->gp_seq;\n\tmask = rnp->grpmask;\n\traw_spin_unlock_rcu_node(rnp);\t/* irqs remain disabled. */\n\traw_spin_lock_rcu_node(rnp_p);\t/* irqs already disabled. */\n\trcu_report_qs_rnp(mask, rnp_p, gps, flags);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,\n\t\t\t      unsigned long gps, unsigned long flags);",
            "static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,\n\t\t\t      unsigned long gps, unsigned long flags);\nstatic void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);\n\nstatic void __maybe_unused\nrcu_report_unblock_qs_rnp(struct rcu_node *rnp, unsigned long flags)\n\t__releases(rnp->lock)\n{\n\tunsigned long gps;\n\tunsigned long mask;\n\tstruct rcu_node *rnp_p;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tif (WARN_ON_ONCE(!IS_ENABLED(CONFIG_PREEMPT_RCU)) ||\n\t    WARN_ON_ONCE(rcu_preempt_blocked_readers_cgp(rnp)) ||\n\t    rnp->qsmask != 0) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;  /* Still need more quiescent states! */\n\t}\n\n\trnp->completedqs = rnp->gp_seq;\n\trnp_p = rnp->parent;\n\tif (rnp_p == NULL) {\n\t\t/*\n\t\t * Only one rcu_node structure in the tree, so don't\n\t\t * try to report up to its nonexistent parent!\n\t\t */\n\t\trcu_report_qs_rsp(flags);\n\t\treturn;\n\t}\n\n\t/* Report up the rest of the hierarchy, tracking current ->gp_seq. */\n\tgps = rnp->gp_seq;\n\tmask = rnp->grpmask;\n\traw_spin_unlock_rcu_node(rnp);\t/* irqs remain disabled. */\n\traw_spin_lock_rcu_node(rnp_p);\t/* irqs already disabled. */\n\trcu_report_qs_rnp(mask, rnp_p, gps, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_rcu_quiescent_state_report",
          "args": [
            "TPS(\"preempt_rcu\")",
            "rnp->gp_seq",
            "0",
            "rnp->qsmask",
            "rnp->level",
            "rnp->grplo",
            "rnp->grphi",
            "!!rnp->gp_tasks"
          ],
          "line": 547
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"preempt_rcu\""
          ],
          "line": 547
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_blocked_readers_cgp",
          "args": [
            "rnp"
          ],
          "line": 546
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_blocked_readers_cgp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "907-910",
          "snippet": "static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "sync_rcu_exp_done",
          "args": [
            "rnp"
          ],
          "line": 545
        },
        "resolved": true,
        "details": {
          "function_name": "sync_rcu_exp_done_unlocked",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "161-171",
          "snippet": "static bool sync_rcu_exp_done_unlocked(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tbool ret;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tret = sync_rcu_exp_done(rnp);\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\n\treturn ret;\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static int rcu_print_task_exp_stall(struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic int rcu_print_task_exp_stall(struct rcu_node *rnp);\n\nstatic bool sync_rcu_exp_done_unlocked(struct rcu_node *rnp)\n{\n\tunsigned long flags;\n\tbool ret;\n\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tret = sync_rcu_exp_done(rnp);\n\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->boost_tasks",
            "np"
          ],
          "line": 536
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rt_mutex_owner",
          "args": [
            "&rnp->boost_mtx.rtmutex"
          ],
          "line": 534
        },
        "resolved": true,
        "details": {
          "function_name": "rt_mutex_owner",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/locking/rtmutex_common.h",
          "lines": "207-210",
          "snippet": "static inline struct task_struct *rt_mutex_owner(struct rt_mutex_base *lock)\n{\n\treturn NULL;\n}",
          "includes": [
            "#include <linux/sched/wake_q.h>",
            "#include <linux/rtmutex.h>",
            "#include <linux/debug_locks.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/sched/wake_q.h>\n#include <linux/rtmutex.h>\n#include <linux/debug_locks.h>\n\nstatic inline struct task_struct *rt_mutex_owner(struct rt_mutex_base *lock)\n{\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_BOOST"
          ],
          "line": 532
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->exp_tasks",
            "np"
          ],
          "line": 531
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->gp_tasks",
            "np"
          ],
          "line": 529
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_unlock_preempted_task",
          "args": [
            "TPS(\"rcu_preempt\")",
            "rnp->gp_seq",
            "t->pid"
          ],
          "line": 526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"rcu_preempt\""
          ],
          "line": 526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_del_init",
          "args": [
            "&t->rcu_node_entry"
          ],
          "line": 524
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_next_node_entry",
          "args": [
            "t",
            "rnp"
          ],
          "line": 523
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_next_node_entry",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "438-447",
          "snippet": "static struct list_head *rcu_next_node_entry(struct task_struct *t,\n\t\t\t\t\t     struct rcu_node *rnp)\n{\n\tstruct list_head *np;\n\n\tnp = t->rcu_node_entry.next;\n\tif (np == &rnp->blkd_tasks)\n\t\tnp = NULL;\n\treturn np;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic struct list_head *rcu_next_node_entry(struct task_struct *t,\n\t\t\t\t\t     struct rcu_node *rnp)\n{\n\tstruct list_head *np;\n\n\tnp = t->rcu_node_entry.next;\n\tif (np == &rnp->blkd_tasks)\n\t\tnp = NULL;\n\treturn np;\n}"
        }
      },
      {
        "call_info": {
          "callee": "smp_mb",
          "args": [],
          "line": 522
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask)"
          ],
          "line": 519
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_is_leaf_node(rnp)"
          ],
          "line": 517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_is_leaf_node",
          "args": [
            "rnp"
          ],
          "line": 517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rnp != t->rcu_blocked_node"
          ],
          "line": 516
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 515
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_exp_rdp",
          "args": [
            "rdp"
          ],
          "line": 503
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_exp_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "256-260",
          "snippet": "static void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_qs",
          "args": [],
          "line": 492
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "842-852",
          "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
        }
      },
      {
        "call_info": {
          "callee": "udelay",
          "args": [
            "rcu_unlock_delay"
          ],
          "line": 490
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_qs_rdp",
          "args": [
            "rdp"
          ],
          "line": 489
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_qs_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "2282-2340",
          "snippet": "static void\nrcu_report_qs_rdp(struct rcu_data *rdp)\n{\n\tunsigned long flags;\n\tunsigned long mask;\n\tbool needwake = false;\n\tbool needacc = false;\n\tstruct rcu_node *rnp;\n\n\tWARN_ON_ONCE(rdp->cpu != smp_processor_id());\n\trnp = rdp->mynode;\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tif (rdp->cpu_no_qs.b.norm || rdp->gp_seq != rnp->gp_seq ||\n\t    rdp->gpwrap) {\n\n\t\t/*\n\t\t * The grace period in which this quiescent state was\n\t\t * recorded has ended, so don't report it upwards.\n\t\t * We will instead need a new quiescent state that lies\n\t\t * within the current grace period.\n\t\t */\n\t\trdp->cpu_no_qs.b.norm = true;\t/* need qs for new gp. */\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tmask = rdp->grpmask;\n\trdp->core_needs_qs = false;\n\tif ((rnp->qsmask & mask) == 0) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t} else {\n\t\t/*\n\t\t * This GP can't end until cpu checks in, so all of our\n\t\t * callbacks can be processed during the next GP.\n\t\t *\n\t\t * NOCB kthreads have their own way to deal with that...\n\t\t */\n\t\tif (!rcu_rdp_is_offloaded(rdp)) {\n\t\t\tneedwake = rcu_accelerate_cbs(rnp, rdp);\n\t\t} else if (!rcu_segcblist_completely_offloaded(&rdp->cblist)) {\n\t\t\t/*\n\t\t\t * ...but NOCB kthreads may miss or delay callbacks acceleration\n\t\t\t * if in the middle of a (de-)offloading process.\n\t\t\t */\n\t\t\tneedacc = true;\n\t\t}\n\n\t\trcu_disable_urgency_upon_qs(rdp);\n\t\trcu_report_qs_rnp(mask, rnp, rnp->gp_seq, flags);\n\t\t/* ^^^ Released rnp->lock */\n\t\tif (needwake)\n\t\t\trcu_gp_kthread_wake();\n\n\t\tif (needacc) {\n\t\t\trcu_nocb_lock_irqsave(rdp, flags);\n\t\t\trcu_accelerate_cbs_unlocked(rnp, rdp);\n\t\t\trcu_nocb_unlock_irqrestore(rdp, flags);\n\t\t}\n\t}\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};",
            "static void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,\n\t\t\t      unsigned long gps, unsigned long flags);",
            "static void rcu_report_exp_rdp(struct rcu_data *rdp);",
            "static void sync_sched_exp_online_cleanup(int cpu);",
            "static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);",
            "static bool rcu_rdp_is_offloaded(struct rcu_data *rdp);",
            "static void force_qs_rnp(int (*f)(struct rcu_data *rdp));"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic DEFINE_PER_CPU_SHARED_ALIGNED(struct rcu_data, rcu_data) = {\n\t.dynticks_nesting = 1,\n\t.dynticks_nmi_nesting = DYNTICK_IRQ_NONIDLE,\n\t.dynticks = ATOMIC_INIT(1),\n#ifdef CONFIG_RCU_NOCB_CPU\n\t.cblist.flags = SEGCBLIST_RCU_CORE,\n#endif\n};\nstatic void rcu_report_qs_rnp(unsigned long mask, struct rcu_node *rnp,\n\t\t\t      unsigned long gps, unsigned long flags);\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp);\nstatic void sync_sched_exp_online_cleanup(int cpu);\nstatic void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);\nstatic bool rcu_rdp_is_offloaded(struct rcu_data *rdp);\nstatic void force_qs_rnp(int (*f)(struct rcu_data *rdp));\n\nstatic void\nrcu_report_qs_rdp(struct rcu_data *rdp)\n{\n\tunsigned long flags;\n\tunsigned long mask;\n\tbool needwake = false;\n\tbool needacc = false;\n\tstruct rcu_node *rnp;\n\n\tWARN_ON_ONCE(rdp->cpu != smp_processor_id());\n\trnp = rdp->mynode;\n\traw_spin_lock_irqsave_rcu_node(rnp, flags);\n\tif (rdp->cpu_no_qs.b.norm || rdp->gp_seq != rnp->gp_seq ||\n\t    rdp->gpwrap) {\n\n\t\t/*\n\t\t * The grace period in which this quiescent state was\n\t\t * recorded has ended, so don't report it upwards.\n\t\t * We will instead need a new quiescent state that lies\n\t\t * within the current grace period.\n\t\t */\n\t\trdp->cpu_no_qs.b.norm = true;\t/* need qs for new gp. */\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\treturn;\n\t}\n\tmask = rdp->grpmask;\n\trdp->core_needs_qs = false;\n\tif ((rnp->qsmask & mask) == 0) {\n\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t} else {\n\t\t/*\n\t\t * This GP can't end until cpu checks in, so all of our\n\t\t * callbacks can be processed during the next GP.\n\t\t *\n\t\t * NOCB kthreads have their own way to deal with that...\n\t\t */\n\t\tif (!rcu_rdp_is_offloaded(rdp)) {\n\t\t\tneedwake = rcu_accelerate_cbs(rnp, rdp);\n\t\t} else if (!rcu_segcblist_completely_offloaded(&rdp->cblist)) {\n\t\t\t/*\n\t\t\t * ...but NOCB kthreads may miss or delay callbacks acceleration\n\t\t\t * if in the middle of a (de-)offloading process.\n\t\t\t */\n\t\t\tneedacc = true;\n\t\t}\n\n\t\trcu_disable_urgency_upon_qs(rdp);\n\t\trcu_report_qs_rnp(mask, rnp, rnp->gp_seq, flags);\n\t\t/* ^^^ Released rnp->lock */\n\t\tif (needwake)\n\t\t\trcu_gp_kthread_wake();\n\n\t\tif (needacc) {\n\t\t\trcu_nocb_lock_irqsave(rdp, flags);\n\t\t\trcu_accelerate_cbs_unlocked(rnp, rdp);\n\t\t\trcu_nocb_unlock_irqrestore(rdp, flags);\n\t\t}\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_STRICT_GRACE_PERIOD"
          ],
          "line": 488
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "local_irq_restore",
          "args": [
            "flags"
          ],
          "line": 483
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 481
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void\nrcu_preempt_deferred_qs_irqrestore(struct task_struct *t, unsigned long flags)\n{\n\tbool empty_exp;\n\tbool empty_norm;\n\tbool empty_exp_now;\n\tstruct list_head *np;\n\tbool drop_boost_mutex = false;\n\tstruct rcu_data *rdp;\n\tstruct rcu_node *rnp;\n\tunion rcu_special special;\n\n\t/*\n\t * If RCU core is waiting for this CPU to exit its critical section,\n\t * report the fact that it has exited.  Because irqs are disabled,\n\t * t->rcu_read_unlock_special cannot change.\n\t */\n\tspecial = t->rcu_read_unlock_special;\n\trdp = this_cpu_ptr(&rcu_data);\n\tif (!special.s && !rdp->cpu_no_qs.b.exp) {\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\tt->rcu_read_unlock_special.s = 0;\n\tif (special.b.need_qs) {\n\t\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD)) {\n\t\t\trcu_report_qs_rdp(rdp);\n\t\t\tudelay(rcu_unlock_delay);\n\t\t} else {\n\t\t\trcu_qs();\n\t\t}\n\t}\n\n\t/*\n\t * Respond to a request by an expedited grace period for a\n\t * quiescent state from this CPU.  Note that requests from\n\t * tasks are handled when removing the task from the\n\t * blocked-tasks list below.\n\t */\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\n\t/* Clean up if blocked during RCU read-side critical section. */\n\tif (special.b.blocked) {\n\n\t\t/*\n\t\t * Remove this task from the list it blocked on.  The task\n\t\t * now remains queued on the rcu_node corresponding to the\n\t\t * CPU it first blocked on, so there is no longer any need\n\t\t * to loop.  Retain a WARN_ON_ONCE() out of sheer paranoia.\n\t\t */\n\t\trnp = t->rcu_blocked_node;\n\t\traw_spin_lock_rcu_node(rnp); /* irqs already disabled. */\n\t\tWARN_ON_ONCE(rnp != t->rcu_blocked_node);\n\t\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t\tempty_norm = !rcu_preempt_blocked_readers_cgp(rnp);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq &&\n\t\t\t     (!empty_norm || rnp->qsmask));\n\t\tempty_exp = sync_rcu_exp_done(rnp);\n\t\tsmp_mb(); /* ensure expedited fastpath sees end of RCU c-s. */\n\t\tnp = rcu_next_node_entry(t, rnp);\n\t\tlist_del_init(&t->rcu_node_entry);\n\t\tt->rcu_blocked_node = NULL;\n\t\ttrace_rcu_unlock_preempted_task(TPS(\"rcu_preempt\"),\n\t\t\t\t\t\trnp->gp_seq, t->pid);\n\t\tif (&t->rcu_node_entry == rnp->gp_tasks)\n\t\t\tWRITE_ONCE(rnp->gp_tasks, np);\n\t\tif (&t->rcu_node_entry == rnp->exp_tasks)\n\t\t\tWRITE_ONCE(rnp->exp_tasks, np);\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST)) {\n\t\t\t/* Snapshot ->boost_mtx ownership w/rnp->lock held. */\n\t\t\tdrop_boost_mutex = rt_mutex_owner(&rnp->boost_mtx.rtmutex) == t;\n\t\t\tif (&t->rcu_node_entry == rnp->boost_tasks)\n\t\t\t\tWRITE_ONCE(rnp->boost_tasks, np);\n\t\t}\n\n\t\t/*\n\t\t * If this was the last task on the current list, and if\n\t\t * we aren't waiting on any CPUs, report the quiescent state.\n\t\t * Note that rcu_report_unblock_qs_rnp() releases rnp->lock,\n\t\t * so we must take a snapshot of the expedited state.\n\t\t */\n\t\tempty_exp_now = sync_rcu_exp_done(rnp);\n\t\tif (!empty_norm && !rcu_preempt_blocked_readers_cgp(rnp)) {\n\t\t\ttrace_rcu_quiescent_state_report(TPS(\"preempt_rcu\"),\n\t\t\t\t\t\t\t rnp->gp_seq,\n\t\t\t\t\t\t\t 0, rnp->qsmask,\n\t\t\t\t\t\t\t rnp->level,\n\t\t\t\t\t\t\t rnp->grplo,\n\t\t\t\t\t\t\t rnp->grphi,\n\t\t\t\t\t\t\t !!rnp->gp_tasks);\n\t\t\trcu_report_unblock_qs_rnp(rnp, flags);\n\t\t} else {\n\t\t\traw_spin_unlock_irqrestore_rcu_node(rnp, flags);\n\t\t}\n\n\t\t/* Unboost if we were boosted. */\n\t\tif (IS_ENABLED(CONFIG_RCU_BOOST) && drop_boost_mutex)\n\t\t\trt_mutex_futex_unlock(&rnp->boost_mtx.rtmutex);\n\n\t\t/*\n\t\t * If this was the last task on the expedited lists,\n\t\t * then we need to report up the rcu_node hierarchy.\n\t\t */\n\t\tif (!empty_exp && empty_exp_now)\n\t\t\trcu_report_exp_rnp(rnp, true);\n\t} else {\n\t\tlocal_irq_restore(flags);\n\t}\n}"
  },
  {
    "function_name": "rcu_preempt_has_tasks",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "453-456",
    "snippet": "static bool rcu_preempt_has_tasks(struct rcu_node *rnp)\n{\n\treturn !list_empty(&rnp->blkd_tasks);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&rnp->blkd_tasks"
          ],
          "line": 455
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_preempt_has_tasks(struct rcu_node *rnp)\n{\n\treturn !list_empty(&rnp->blkd_tasks);\n}"
  },
  {
    "function_name": "rcu_next_node_entry",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "438-447",
    "snippet": "static struct list_head *rcu_next_node_entry(struct task_struct *t,\n\t\t\t\t\t     struct rcu_node *rnp)\n{\n\tstruct list_head *np;\n\n\tnp = t->rcu_node_entry.next;\n\tif (np == &rnp->blkd_tasks)\n\t\tnp = NULL;\n\treturn np;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic struct list_head *rcu_next_node_entry(struct task_struct *t,\n\t\t\t\t\t     struct rcu_node *rnp)\n{\n\tstruct list_head *np;\n\n\tnp = t->rcu_node_entry.next;\n\tif (np == &rnp->blkd_tasks)\n\t\tnp = NULL;\n\treturn np;\n}"
  },
  {
    "function_name": "__rcu_read_unlock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "416-431",
    "snippet": "void __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tbarrier();  // critical section before exit code.\n\tif (rcu_preempt_read_exit() == 0) {\n\t\tbarrier();  // critical-section exit before .s check.\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t}\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING)) {\n\t\tint rrln = rcu_preempt_depth();\n\n\t\tWARN_ON_ONCE(rrln < 0 || rrln > RCU_NEST_PMAX);\n\t}\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [
      "#define RCU_NEST_PMAX (INT_MAX / 2)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rrln < 0 || rrln > RCU_NEST_PMAX"
          ],
          "line": 429
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 427
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_PROVE_LOCKING"
          ],
          "line": 426
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_read_unlock_special",
          "args": [
            "t"
          ],
          "line": 424
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_read_unlock_special",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "623-672",
          "snippet": "static void rcu_read_unlock_special(struct task_struct *t)\n{\n\tunsigned long flags;\n\tbool irqs_were_disabled;\n\tbool preempt_bh_were_disabled =\n\t\t\t!!(preempt_count() & (PREEMPT_MASK | SOFTIRQ_MASK));\n\n\t/* NMI handlers cannot block and cannot safely manipulate state. */\n\tif (in_nmi())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\tirqs_were_disabled = irqs_disabled_flags(flags);\n\tif (preempt_bh_were_disabled || irqs_were_disabled) {\n\t\tbool expboost; // Expedited GP in flight or possible boosting.\n\t\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\t\tstruct rcu_node *rnp = rdp->mynode;\n\n\t\texpboost = (t->rcu_blocked_node && READ_ONCE(t->rcu_blocked_node->exp_tasks)) ||\n\t\t\t   (rdp->grpmask & READ_ONCE(rnp->expmask)) ||\n\t\t\t   IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ||\n\t\t\t   (IS_ENABLED(CONFIG_RCU_BOOST) && irqs_were_disabled &&\n\t\t\t    t->rcu_blocked_node);\n\t\t// Need to defer quiescent state until everything is enabled.\n\t\tif (use_softirq && (in_hardirq() || (expboost && !irqs_were_disabled))) {\n\t\t\t// Using softirq, safe to awaken, and either the\n\t\t\t// wakeup is free or there is either an expedited\n\t\t\t// GP in flight or a potential need to deboost.\n\t\t\traise_softirq_irqoff(RCU_SOFTIRQ);\n\t\t} else {\n\t\t\t// Enabling BH or preempt does reschedule, so...\n\t\t\t// Also if no expediting and no possible deboosting,\n\t\t\t// slow is OK.  Plus nohz_full CPUs eventually get\n\t\t\t// tick enabled.\n\t\t\tset_tsk_need_resched(current);\n\t\t\tset_preempt_need_resched();\n\t\t\tif (IS_ENABLED(CONFIG_IRQ_WORK) && irqs_were_disabled &&\n\t\t\t    expboost && !rdp->defer_qs_iw_pending && cpu_online(rdp->cpu)) {\n\t\t\t\t// Get scheduler to re-evaluate and call hooks.\n\t\t\t\t// If !IRQ_WORK, FQS scan will eventually IPI.\n\t\t\t\tinit_irq_work(&rdp->defer_qs_iw, rcu_preempt_deferred_qs_handler);\n\t\t\t\trdp->defer_qs_iw_pending = true;\n\t\t\t\tirq_work_queue_on(&rdp->defer_qs_iw, rdp->cpu);\n\t\t\t}\n\t\t}\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\trcu_preempt_deferred_qs_irqrestore(t, flags);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_read_unlock_special(struct task_struct *t)\n{\n\tunsigned long flags;\n\tbool irqs_were_disabled;\n\tbool preempt_bh_were_disabled =\n\t\t\t!!(preempt_count() & (PREEMPT_MASK | SOFTIRQ_MASK));\n\n\t/* NMI handlers cannot block and cannot safely manipulate state. */\n\tif (in_nmi())\n\t\treturn;\n\n\tlocal_irq_save(flags);\n\tirqs_were_disabled = irqs_disabled_flags(flags);\n\tif (preempt_bh_were_disabled || irqs_were_disabled) {\n\t\tbool expboost; // Expedited GP in flight or possible boosting.\n\t\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\t\tstruct rcu_node *rnp = rdp->mynode;\n\n\t\texpboost = (t->rcu_blocked_node && READ_ONCE(t->rcu_blocked_node->exp_tasks)) ||\n\t\t\t   (rdp->grpmask & READ_ONCE(rnp->expmask)) ||\n\t\t\t   IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) ||\n\t\t\t   (IS_ENABLED(CONFIG_RCU_BOOST) && irqs_were_disabled &&\n\t\t\t    t->rcu_blocked_node);\n\t\t// Need to defer quiescent state until everything is enabled.\n\t\tif (use_softirq && (in_hardirq() || (expboost && !irqs_were_disabled))) {\n\t\t\t// Using softirq, safe to awaken, and either the\n\t\t\t// wakeup is free or there is either an expedited\n\t\t\t// GP in flight or a potential need to deboost.\n\t\t\traise_softirq_irqoff(RCU_SOFTIRQ);\n\t\t} else {\n\t\t\t// Enabling BH or preempt does reschedule, so...\n\t\t\t// Also if no expediting and no possible deboosting,\n\t\t\t// slow is OK.  Plus nohz_full CPUs eventually get\n\t\t\t// tick enabled.\n\t\t\tset_tsk_need_resched(current);\n\t\t\tset_preempt_need_resched();\n\t\t\tif (IS_ENABLED(CONFIG_IRQ_WORK) && irqs_were_disabled &&\n\t\t\t    expboost && !rdp->defer_qs_iw_pending && cpu_online(rdp->cpu)) {\n\t\t\t\t// Get scheduler to re-evaluate and call hooks.\n\t\t\t\t// If !IRQ_WORK, FQS scan will eventually IPI.\n\t\t\t\tinit_irq_work(&rdp->defer_qs_iw, rcu_preempt_deferred_qs_handler);\n\t\t\t\trdp->defer_qs_iw_pending = true;\n\t\t\t\tirq_work_queue_on(&rdp->defer_qs_iw, rdp->cpu);\n\t\t\t}\n\t\t}\n\t\tlocal_irq_restore(flags);\n\t\treturn;\n\t}\n\trcu_preempt_deferred_qs_irqrestore(t, flags);\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "READ_ONCE(t->rcu_read_unlock_special.s)"
          ],
          "line": 423
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "t->rcu_read_unlock_special.s"
          ],
          "line": 423
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 422
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1569-1572",
          "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_preempt_read_exit",
          "args": [],
          "line": 421
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_read_exit",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "380-386",
          "snippet": "static int rcu_preempt_read_exit(void)\n{\n\tint ret = READ_ONCE(current->rcu_read_lock_nesting) - 1;\n\n\tWRITE_ONCE(current->rcu_read_lock_nesting, ret);\n\treturn ret;\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_read_exit(void)\n{\n\tint ret = READ_ONCE(current->rcu_read_lock_nesting) - 1;\n\n\tWRITE_ONCE(current->rcu_read_lock_nesting, ret);\n\treturn ret;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\n#define RCU_NEST_PMAX (INT_MAX / 2)\n\nvoid __rcu_read_unlock(void)\n{\n\tstruct task_struct *t = current;\n\n\tbarrier();  // critical section before exit code.\n\tif (rcu_preempt_read_exit() == 0) {\n\t\tbarrier();  // critical-section exit before .s check.\n\t\tif (unlikely(READ_ONCE(t->rcu_read_unlock_special.s)))\n\t\t\trcu_read_unlock_special(t);\n\t}\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING)) {\n\t\tint rrln = rcu_preempt_depth();\n\n\t\tWARN_ON_ONCE(rrln < 0 || rrln > RCU_NEST_PMAX);\n\t}\n}"
  },
  {
    "function_name": "__rcu_read_lock",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "398-406",
    "snippet": "void __rcu_read_lock(void)\n{\n\trcu_preempt_read_enter();\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING))\n\t\tWARN_ON_ONCE(rcu_preempt_depth() > RCU_NEST_PMAX);\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) && rcu_state.gp_kthread)\n\t\tWRITE_ONCE(current->rcu_read_unlock_special.b.need_qs, true);\n\tbarrier();  /* critical section after entry code. */\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [
      "#define RCU_NEST_PMAX (INT_MAX / 2)"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 405
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1569-1572",
          "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_read_unlock_special.b.need_qs",
            "true"
          ],
          "line": 404
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_STRICT_GRACE_PERIOD"
          ],
          "line": 403
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rcu_preempt_depth() > RCU_NEST_PMAX"
          ],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 402
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_PROVE_LOCKING"
          ],
          "line": 401
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_read_enter",
          "args": [],
          "line": 400
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_read_enter",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "375-378",
          "snippet": "static void rcu_preempt_read_enter(void)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, READ_ONCE(current->rcu_read_lock_nesting) + 1);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_read_enter(void)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, READ_ONCE(current->rcu_read_lock_nesting) + 1);\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\n#define RCU_NEST_PMAX (INT_MAX / 2)\n\nvoid __rcu_read_lock(void)\n{\n\trcu_preempt_read_enter();\n\tif (IS_ENABLED(CONFIG_PROVE_LOCKING))\n\t\tWARN_ON_ONCE(rcu_preempt_depth() > RCU_NEST_PMAX);\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD) && rcu_state.gp_kthread)\n\t\tWRITE_ONCE(current->rcu_read_unlock_special.b.need_qs, true);\n\tbarrier();  /* critical section after entry code. */\n}"
  },
  {
    "function_name": "rcu_preempt_depth_set",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "388-391",
    "snippet": "static void rcu_preempt_depth_set(int val)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, val);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_read_lock_nesting",
            "val"
          ],
          "line": 390
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_depth_set(int val)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, val);\n}"
  },
  {
    "function_name": "rcu_preempt_read_exit",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "380-386",
    "snippet": "static int rcu_preempt_read_exit(void)\n{\n\tint ret = READ_ONCE(current->rcu_read_lock_nesting) - 1;\n\n\tWRITE_ONCE(current->rcu_read_lock_nesting, ret);\n\treturn ret;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_read_lock_nesting",
            "ret"
          ],
          "line": 384
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "current->rcu_read_lock_nesting"
          ],
          "line": 382
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_read_exit(void)\n{\n\tint ret = READ_ONCE(current->rcu_read_lock_nesting) - 1;\n\n\tWRITE_ONCE(current->rcu_read_lock_nesting, ret);\n\treturn ret;\n}"
  },
  {
    "function_name": "rcu_preempt_read_enter",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "375-378",
    "snippet": "static void rcu_preempt_read_enter(void)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, READ_ONCE(current->rcu_read_lock_nesting) + 1);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_read_lock_nesting",
            "READ_ONCE(current->rcu_read_lock_nesting) + 1"
          ],
          "line": 377
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "current->rcu_read_lock_nesting"
          ],
          "line": 377
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_read_enter(void)\n{\n\tWRITE_ONCE(current->rcu_read_lock_nesting, READ_ONCE(current->rcu_read_lock_nesting) + 1);\n}"
  },
  {
    "function_name": "rcu_preempt_blocked_readers_cgp",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "367-370",
    "snippet": "static int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->gp_tasks) != NULL;\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "rnp->gp_tasks"
          ],
          "line": 369
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic int rcu_preempt_blocked_readers_cgp(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->gp_tasks) != NULL;\n}"
  },
  {
    "function_name": "rcu_note_context_switch",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "310-359",
    "snippet": "void rcu_note_context_switch(bool preempt)\n{\n\tstruct task_struct *t = current;\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\tstruct rcu_node *rnp;\n\n\ttrace_rcu_utilization(TPS(\"Start context switch\"));\n\tlockdep_assert_irqs_disabled();\n\tWARN_ONCE(!preempt && rcu_preempt_depth() > 0, \"Voluntary context switch within RCU read-side critical section!\");\n\tif (rcu_preempt_depth() > 0 &&\n\t    !t->rcu_read_unlock_special.b.blocked) {\n\n\t\t/* Possibly blocking in an RCU read-side critical section. */\n\t\trnp = rdp->mynode;\n\t\traw_spin_lock_rcu_node(rnp);\n\t\tt->rcu_read_unlock_special.b.blocked = true;\n\t\tt->rcu_blocked_node = rnp;\n\n\t\t/*\n\t\t * Verify the CPU's sanity, trace the preemption, and\n\t\t * then queue the task as required based on the states\n\t\t * of any ongoing and expedited grace periods.\n\t\t */\n\t\tWARN_ON_ONCE((rdp->grpmask & rcu_rnp_online_cpus(rnp)) == 0);\n\t\tWARN_ON_ONCE(!list_empty(&t->rcu_node_entry));\n\t\ttrace_rcu_preempt_task(rcu_state.name,\n\t\t\t\t       t->pid,\n\t\t\t\t       (rnp->qsmask & rdp->grpmask)\n\t\t\t\t       ? rnp->gp_seq\n\t\t\t\t       : rcu_seq_snap(&rnp->gp_seq));\n\t\trcu_preempt_ctxt_queue(rnp, rdp);\n\t} else {\n\t\trcu_preempt_deferred_qs(t);\n\t}\n\n\t/*\n\t * Either we were not in an RCU read-side critical section to\n\t * begin with, or we have now recorded that critical section\n\t * globally.  Either way, we can now note a quiescent state\n\t * for this CPU.  Again, if we were in an RCU read-side critical\n\t * section, and if that critical section was blocking the current\n\t * grace period, then the fact that the task has been enqueued\n\t * means that we continue to block the current grace period.\n\t */\n\trcu_qs();\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\trcu_tasks_qs(current, preempt);\n\ttrace_rcu_utilization(TPS(\"End context switch\"));\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"End context switch\")"
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"End context switch\""
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_tasks_qs",
          "args": [
            "current",
            "preempt"
          ],
          "line": 357
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_exp_rdp",
          "args": [
            "rdp"
          ],
          "line": 356
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_exp_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "256-260",
          "snippet": "static void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_qs",
          "args": [],
          "line": 354
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "842-852",
          "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\");\n\tif (!__this_cpu_read(rcu_data.cpu_no_qs.s))\n\t\treturn;\n\ttrace_rcu_grace_period(TPS(\"rcu_sched\"),\n\t\t\t       __this_cpu_read(rcu_data.gp_seq), TPS(\"cpuqs\"));\n\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.exp))\n\t\trcu_report_exp_rdp(this_cpu_ptr(&rcu_data));\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_preempt_deferred_qs",
          "args": [
            "t"
          ],
          "line": 342
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_deferred_qs",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "933-939",
          "snippet": "static void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_preempt_deferred_qs(struct task_struct *t)\n{\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "rcu_preempt_ctxt_queue",
          "args": [
            "rnp",
            "rdp"
          ],
          "line": 340
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_preempt_ctxt_queue",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "151-265",
          "snippet": "static void rcu_preempt_ctxt_queue(struct rcu_node *rnp, struct rcu_data *rdp)\n\t__releases(rnp->lock) /* But leaves rrupts disabled. */\n{\n\tint blkd_state = (rnp->gp_tasks ? RCU_GP_TASKS : 0) +\n\t\t\t (rnp->exp_tasks ? RCU_EXP_TASKS : 0) +\n\t\t\t (rnp->qsmask & rdp->grpmask ? RCU_GP_BLKD : 0) +\n\t\t\t (rnp->expmask & rdp->grpmask ? RCU_EXP_BLKD : 0);\n\tstruct task_struct *t = current;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tWARN_ON_ONCE(rdp->mynode != rnp);\n\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t/* RCU better not be waiting on newly onlined CPUs! */\n\tWARN_ON_ONCE(rnp->qsmaskinitnext & ~rnp->qsmaskinit & rnp->qsmask &\n\t\t     rdp->grpmask);\n\n\t/*\n\t * Decide where to queue the newly blocked task.  In theory,\n\t * this could be an if-statement.  In practice, when I tried\n\t * that, it was quite messy.\n\t */\n\tswitch (blkd_state) {\n\tcase 0:\n\tcase                RCU_EXP_TASKS:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD:\n\tcase RCU_GP_TASKS:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS:\n\n\t\t/*\n\t\t * Blocking neither GP, or first task blocking the normal\n\t\t * GP but not blocking the already-waiting expedited GP.\n\t\t * Queue at the head of the list to avoid unnecessarily\n\t\t * blocking the already-waiting GPs.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                                              RCU_EXP_BLKD:\n\tcase                                RCU_GP_BLKD:\n\tcase                                RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                               RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * First task arriving that blocks either GP, or first task\n\t\t * arriving that blocks the expedited GP (with the normal\n\t\t * GP already waiting), or a task arriving that blocks\n\t\t * both GPs with both GPs already waiting.  Queue at the\n\t\t * tail of the list to avoid any GP waiting on any of the\n\t\t * already queued tasks that are not blocking it.\n\t\t */\n\t\tlist_add_tail(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the expedited GP.\n\t\t * The task either does not block the normal GP, or is the\n\t\t * first task blocking the normal GP.  Queue just after\n\t\t * the first task blocking the expedited GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->exp_tasks);\n\t\tbreak;\n\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the normal GP.\n\t\t * The task does not block the expedited GP. Queue just\n\t\t * after the first task blocking the normal GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->gp_tasks);\n\t\tbreak;\n\n\tdefault:\n\n\t\t/* Yet another exercise in excessive paranoia. */\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n\n\t/*\n\t * We have now queued the task.  If it was the first one to\n\t * block either grace period, update the ->gp_tasks and/or\n\t * ->exp_tasks pointers, respectively, to reference the newly\n\t * blocked tasks.\n\t */\n\tif (!rnp->gp_tasks && (blkd_state & RCU_GP_BLKD)) {\n\t\tWRITE_ONCE(rnp->gp_tasks, &t->rcu_node_entry);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq);\n\t}\n\tif (!rnp->exp_tasks && (blkd_state & RCU_EXP_BLKD))\n\t\tWRITE_ONCE(rnp->exp_tasks, &t->rcu_node_entry);\n\tWARN_ON_ONCE(!(blkd_state & RCU_GP_BLKD) !=\n\t\t     !(rnp->qsmask & rdp->grpmask));\n\tWARN_ON_ONCE(!(blkd_state & RCU_EXP_BLKD) !=\n\t\t     !(rnp->expmask & rdp->grpmask));\n\traw_spin_unlock_rcu_node(rnp); /* interrupts remain disabled. */\n\n\t/*\n\t * Report the quiescent state for the expedited GP.  This expedited\n\t * GP should not be able to end until we report, so there should be\n\t * no need to check for a subsequent expedited GP.  (Though we are\n\t * still in a quiescent state in any case.)\n\t */\n\tif (blkd_state & RCU_EXP_BLKD && rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\telse\n\t\tWARN_ON_ONCE(rdp->cpu_no_qs.b.exp);\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [
            "#define RCU_EXP_BLKD\t0x1",
            "#define RCU_GP_BLKD\t0x2",
            "#define RCU_EXP_TASKS\t0x4",
            "#define RCU_GP_TASKS\t0x8"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\n#define RCU_EXP_BLKD\t0x1\n#define RCU_GP_BLKD\t0x2\n#define RCU_EXP_TASKS\t0x4\n#define RCU_GP_TASKS\t0x8\n\nstatic void rcu_preempt_ctxt_queue(struct rcu_node *rnp, struct rcu_data *rdp)\n\t__releases(rnp->lock) /* But leaves rrupts disabled. */\n{\n\tint blkd_state = (rnp->gp_tasks ? RCU_GP_TASKS : 0) +\n\t\t\t (rnp->exp_tasks ? RCU_EXP_TASKS : 0) +\n\t\t\t (rnp->qsmask & rdp->grpmask ? RCU_GP_BLKD : 0) +\n\t\t\t (rnp->expmask & rdp->grpmask ? RCU_EXP_BLKD : 0);\n\tstruct task_struct *t = current;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tWARN_ON_ONCE(rdp->mynode != rnp);\n\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t/* RCU better not be waiting on newly onlined CPUs! */\n\tWARN_ON_ONCE(rnp->qsmaskinitnext & ~rnp->qsmaskinit & rnp->qsmask &\n\t\t     rdp->grpmask);\n\n\t/*\n\t * Decide where to queue the newly blocked task.  In theory,\n\t * this could be an if-statement.  In practice, when I tried\n\t * that, it was quite messy.\n\t */\n\tswitch (blkd_state) {\n\tcase 0:\n\tcase                RCU_EXP_TASKS:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD:\n\tcase RCU_GP_TASKS:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS:\n\n\t\t/*\n\t\t * Blocking neither GP, or first task blocking the normal\n\t\t * GP but not blocking the already-waiting expedited GP.\n\t\t * Queue at the head of the list to avoid unnecessarily\n\t\t * blocking the already-waiting GPs.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                                              RCU_EXP_BLKD:\n\tcase                                RCU_GP_BLKD:\n\tcase                                RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                               RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * First task arriving that blocks either GP, or first task\n\t\t * arriving that blocks the expedited GP (with the normal\n\t\t * GP already waiting), or a task arriving that blocks\n\t\t * both GPs with both GPs already waiting.  Queue at the\n\t\t * tail of the list to avoid any GP waiting on any of the\n\t\t * already queued tasks that are not blocking it.\n\t\t */\n\t\tlist_add_tail(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the expedited GP.\n\t\t * The task either does not block the normal GP, or is the\n\t\t * first task blocking the normal GP.  Queue just after\n\t\t * the first task blocking the expedited GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->exp_tasks);\n\t\tbreak;\n\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the normal GP.\n\t\t * The task does not block the expedited GP. Queue just\n\t\t * after the first task blocking the normal GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->gp_tasks);\n\t\tbreak;\n\n\tdefault:\n\n\t\t/* Yet another exercise in excessive paranoia. */\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n\n\t/*\n\t * We have now queued the task.  If it was the first one to\n\t * block either grace period, update the ->gp_tasks and/or\n\t * ->exp_tasks pointers, respectively, to reference the newly\n\t * blocked tasks.\n\t */\n\tif (!rnp->gp_tasks && (blkd_state & RCU_GP_BLKD)) {\n\t\tWRITE_ONCE(rnp->gp_tasks, &t->rcu_node_entry);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq);\n\t}\n\tif (!rnp->exp_tasks && (blkd_state & RCU_EXP_BLKD))\n\t\tWRITE_ONCE(rnp->exp_tasks, &t->rcu_node_entry);\n\tWARN_ON_ONCE(!(blkd_state & RCU_GP_BLKD) !=\n\t\t     !(rnp->qsmask & rdp->grpmask));\n\tWARN_ON_ONCE(!(blkd_state & RCU_EXP_BLKD) !=\n\t\t     !(rnp->expmask & rdp->grpmask));\n\traw_spin_unlock_rcu_node(rnp); /* interrupts remain disabled. */\n\n\t/*\n\t * Report the quiescent state for the expedited GP.  This expedited\n\t * GP should not be able to end until we report, so there should be\n\t * no need to check for a subsequent expedited GP.  (Though we are\n\t * still in a quiescent state in any case.)\n\t */\n\tif (blkd_state & RCU_EXP_BLKD && rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\telse\n\t\tWARN_ON_ONCE(rdp->cpu_no_qs.b.exp);\n}"
        }
      },
      {
        "call_info": {
          "callee": "trace_rcu_preempt_task",
          "args": [
            "rcu_state.name",
            "t->pid",
            "(rnp->qsmask & rdp->grpmask)\n\t\t\t\t       ? rnp->gp_seq\n\t\t\t\t       : rcu_seq_snap(&rnp->gp_seq)"
          ],
          "line": 335
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_seq_snap",
          "args": [
            "&rnp->gp_seq"
          ],
          "line": 339
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_seq_snap",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu.h",
          "lines": "87-94",
          "snippet": "static inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}",
          "includes": [
            "#include <linux/rcu_node_tree.h>",
            "#include <trace/events/rcu.h>"
          ],
          "macros_used": [
            "#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_node_tree.h>\n#include <trace/events/rcu.h>\n\n#define RCU_SEQ_STATE_MASK\t((1 << RCU_SEQ_CTR_SHIFT) - 1)\n\nstatic inline unsigned long rcu_seq_snap(unsigned long *sp)\n{\n\tunsigned long s;\n\n\ts = (READ_ONCE(*sp) + 2 * RCU_SEQ_STATE_MASK + 1) & ~RCU_SEQ_STATE_MASK;\n\tsmp_mb(); /* Above access must not bleed into critical section. */\n\treturn s;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!list_empty(&t->rcu_node_entry)"
          ],
          "line": 334
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_empty",
          "args": [
            "&t->rcu_node_entry"
          ],
          "line": 334
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_empty",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "41-44",
          "snippet": "static inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_empty(struct rcu_segcblist *rsclp)\n{\n\treturn !READ_ONCE(rsclp->head);\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "(rdp->grpmask & rcu_rnp_online_cpus(rnp)) == 0"
          ],
          "line": 333
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_rnp_online_cpus",
          "args": [
            "rnp"
          ],
          "line": 333
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_rnp_online_cpus",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree.c",
          "lines": "219-222",
          "snippet": "static unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->qsmaskinitnext);\n}",
          "includes": [
            "#include \"tree_plugin.h\"",
            "#include \"tree_nocb.h\"",
            "#include \"tree_exp.h\"",
            "#include \"tree_stall.h\"",
            "#include \"rcu.h\"",
            "#include \"tree.h\"",
            "#include \"../time/tick-internal.h\"",
            "#include <linux/kasan.h>",
            "#include <linux/mm.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/sched/clock.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/slab.h>",
            "#include <linux/jiffies.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/oom.h>",
            "#include <linux/gfp.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sysrq.h>",
            "#include <linux/tick.h>",
            "#include <linux/ftrace.h>",
            "#include <linux/suspend.h>",
            "#include <linux/trace_events.h>",
            "#include <linux/random.h>",
            "#include <linux/delay.h>",
            "#include <linux/prefetch.h>",
            "#include <uapi/linux/sched/types.h>",
            "#include <linux/kthread.h>",
            "#include <linux/wait.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/time.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/panic_notifier.h>",
            "#include <linux/panic.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/completion.h>",
            "#include <linux/export.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/nmi.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"tree_plugin.h\"\n#include \"tree_nocb.h\"\n#include \"tree_exp.h\"\n#include \"tree_stall.h\"\n#include \"rcu.h\"\n#include \"tree.h\"\n#include \"../time/tick-internal.h\"\n#include <linux/kasan.h>\n#include <linux/mm.h>\n#include <linux/vmalloc.h>\n#include <linux/sched/clock.h>\n#include <linux/sched/isolation.h>\n#include <linux/slab.h>\n#include <linux/jiffies.h>\n#include <linux/smpboot.h>\n#include <linux/oom.h>\n#include <linux/gfp.h>\n#include <linux/kprobes.h>\n#include <linux/sysrq.h>\n#include <linux/tick.h>\n#include <linux/ftrace.h>\n#include <linux/suspend.h>\n#include <linux/trace_events.h>\n#include <linux/random.h>\n#include <linux/delay.h>\n#include <linux/prefetch.h>\n#include <uapi/linux/sched/types.h>\n#include <linux/kthread.h>\n#include <linux/wait.h>\n#include <linux/kernel_stat.h>\n#include <linux/time.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/panic_notifier.h>\n#include <linux/panic.h>\n#include <linux/moduleparam.h>\n#include <linux/completion.h>\n#include <linux/export.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/nmi.h>\n#include <linux/sched/debug.h>\n#include <linux/sched.h>\n#include <linux/interrupt.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nstatic void check_cb_ovld_locked(struct rcu_data *rdp, struct rcu_node *rnp);\n\nstatic unsigned long rcu_rnp_online_cpus(struct rcu_node *rnp)\n{\n\treturn READ_ONCE(rnp->qsmaskinitnext);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_lock_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 324
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 319
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ONCE",
          "args": [
            "!preempt && rcu_preempt_depth() > 0",
            "\"Voluntary context switch within RCU read-side critical section!\""
          ],
          "line": 318
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_preempt_depth",
          "args": [],
          "line": 318
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lockdep_assert_irqs_disabled",
          "args": [],
          "line": 317
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_utilization",
          "args": [
            "TPS(\"Start context switch\")"
          ],
          "line": 316
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"Start context switch\""
          ],
          "line": 316
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 313
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nvoid rcu_note_context_switch(bool preempt)\n{\n\tstruct task_struct *t = current;\n\tstruct rcu_data *rdp = this_cpu_ptr(&rcu_data);\n\tstruct rcu_node *rnp;\n\n\ttrace_rcu_utilization(TPS(\"Start context switch\"));\n\tlockdep_assert_irqs_disabled();\n\tWARN_ONCE(!preempt && rcu_preempt_depth() > 0, \"Voluntary context switch within RCU read-side critical section!\");\n\tif (rcu_preempt_depth() > 0 &&\n\t    !t->rcu_read_unlock_special.b.blocked) {\n\n\t\t/* Possibly blocking in an RCU read-side critical section. */\n\t\trnp = rdp->mynode;\n\t\traw_spin_lock_rcu_node(rnp);\n\t\tt->rcu_read_unlock_special.b.blocked = true;\n\t\tt->rcu_blocked_node = rnp;\n\n\t\t/*\n\t\t * Verify the CPU's sanity, trace the preemption, and\n\t\t * then queue the task as required based on the states\n\t\t * of any ongoing and expedited grace periods.\n\t\t */\n\t\tWARN_ON_ONCE((rdp->grpmask & rcu_rnp_online_cpus(rnp)) == 0);\n\t\tWARN_ON_ONCE(!list_empty(&t->rcu_node_entry));\n\t\ttrace_rcu_preempt_task(rcu_state.name,\n\t\t\t\t       t->pid,\n\t\t\t\t       (rnp->qsmask & rdp->grpmask)\n\t\t\t\t       ? rnp->gp_seq\n\t\t\t\t       : rcu_seq_snap(&rnp->gp_seq));\n\t\trcu_preempt_ctxt_queue(rnp, rdp);\n\t} else {\n\t\trcu_preempt_deferred_qs(t);\n\t}\n\n\t/*\n\t * Either we were not in an RCU read-side critical section to\n\t * begin with, or we have now recorded that critical section\n\t * globally.  Either way, we can now note a quiescent state\n\t * for this CPU.  Again, if we were in an RCU read-side critical\n\t * section, and if that critical section was blocking the current\n\t * grace period, then the fact that the task has been enqueued\n\t * means that we continue to block the current grace period.\n\t */\n\trcu_qs();\n\tif (rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\trcu_tasks_qs(current, preempt);\n\ttrace_rcu_utilization(TPS(\"End context switch\"));\n}"
  },
  {
    "function_name": "rcu_qs",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "284-295",
    "snippet": "static void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\\n\");\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.norm)) {\n\t\ttrace_rcu_grace_period(TPS(\"rcu_preempt\"),\n\t\t\t\t       __this_cpu_read(rcu_data.gp_seq),\n\t\t\t\t       TPS(\"cpuqs\"));\n\t\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\t\tbarrier(); /* Coordinate with rcu_flavor_sched_clock_irq(). */\n\t\tWRITE_ONCE(current->rcu_read_unlock_special.b.need_qs, false);\n\t}\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "current->rcu_read_unlock_special.b.need_qs",
            "false"
          ],
          "line": 293
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "barrier",
          "args": [],
          "line": 292
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_barrier_tasks_trace",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tasks.h",
          "lines": "1569-1572",
          "snippet": "void rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}",
          "includes": [
            "#include \"rcu_segcblist.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n\nvoid rcu_barrier_tasks_trace(void)\n{\n\trcu_barrier_tasks_generic(&rcu_tasks_trace);\n}"
        }
      },
      {
        "call_info": {
          "callee": "__this_cpu_write",
          "args": [
            "rcu_data.cpu_no_qs.b.norm",
            "false"
          ],
          "line": 291
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "trace_rcu_grace_period",
          "args": [
            "TPS(\"rcu_preempt\")",
            "__this_cpu_read(rcu_data.gp_seq)",
            "TPS(\"cpuqs\")"
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"cpuqs\""
          ],
          "line": 290
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.gp_seq"
          ],
          "line": 289
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "TPS",
          "args": [
            "\"rcu_preempt\""
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__this_cpu_read",
          "args": [
            "rcu_data.cpu_no_qs.b.norm"
          ],
          "line": 287
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "RCU_LOCKDEP_WARN",
          "args": [
            "preemptible()",
            "\"rcu_qs() invoked with preemption enabled!!!\\n\""
          ],
          "line": 286
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "preemptible",
          "args": [],
          "line": 286
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void rcu_qs(void)\n{\n\tRCU_LOCKDEP_WARN(preemptible(), \"rcu_qs() invoked with preemption enabled!!!\\n\");\n\tif (__this_cpu_read(rcu_data.cpu_no_qs.b.norm)) {\n\t\ttrace_rcu_grace_period(TPS(\"rcu_preempt\"),\n\t\t\t\t       __this_cpu_read(rcu_data.gp_seq),\n\t\t\t\t       TPS(\"cpuqs\"));\n\t\t__this_cpu_write(rcu_data.cpu_no_qs.b.norm, false);\n\t\tbarrier(); /* Coordinate with rcu_flavor_sched_clock_irq(). */\n\t\tWRITE_ONCE(current->rcu_read_unlock_special.b.need_qs, false);\n\t}\n}"
  },
  {
    "function_name": "rcu_preempt_ctxt_queue",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "151-265",
    "snippet": "static void rcu_preempt_ctxt_queue(struct rcu_node *rnp, struct rcu_data *rdp)\n\t__releases(rnp->lock) /* But leaves rrupts disabled. */\n{\n\tint blkd_state = (rnp->gp_tasks ? RCU_GP_TASKS : 0) +\n\t\t\t (rnp->exp_tasks ? RCU_EXP_TASKS : 0) +\n\t\t\t (rnp->qsmask & rdp->grpmask ? RCU_GP_BLKD : 0) +\n\t\t\t (rnp->expmask & rdp->grpmask ? RCU_EXP_BLKD : 0);\n\tstruct task_struct *t = current;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tWARN_ON_ONCE(rdp->mynode != rnp);\n\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t/* RCU better not be waiting on newly onlined CPUs! */\n\tWARN_ON_ONCE(rnp->qsmaskinitnext & ~rnp->qsmaskinit & rnp->qsmask &\n\t\t     rdp->grpmask);\n\n\t/*\n\t * Decide where to queue the newly blocked task.  In theory,\n\t * this could be an if-statement.  In practice, when I tried\n\t * that, it was quite messy.\n\t */\n\tswitch (blkd_state) {\n\tcase 0:\n\tcase                RCU_EXP_TASKS:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD:\n\tcase RCU_GP_TASKS:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS:\n\n\t\t/*\n\t\t * Blocking neither GP, or first task blocking the normal\n\t\t * GP but not blocking the already-waiting expedited GP.\n\t\t * Queue at the head of the list to avoid unnecessarily\n\t\t * blocking the already-waiting GPs.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                                              RCU_EXP_BLKD:\n\tcase                                RCU_GP_BLKD:\n\tcase                                RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                               RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * First task arriving that blocks either GP, or first task\n\t\t * arriving that blocks the expedited GP (with the normal\n\t\t * GP already waiting), or a task arriving that blocks\n\t\t * both GPs with both GPs already waiting.  Queue at the\n\t\t * tail of the list to avoid any GP waiting on any of the\n\t\t * already queued tasks that are not blocking it.\n\t\t */\n\t\tlist_add_tail(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the expedited GP.\n\t\t * The task either does not block the normal GP, or is the\n\t\t * first task blocking the normal GP.  Queue just after\n\t\t * the first task blocking the expedited GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->exp_tasks);\n\t\tbreak;\n\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the normal GP.\n\t\t * The task does not block the expedited GP. Queue just\n\t\t * after the first task blocking the normal GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->gp_tasks);\n\t\tbreak;\n\n\tdefault:\n\n\t\t/* Yet another exercise in excessive paranoia. */\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n\n\t/*\n\t * We have now queued the task.  If it was the first one to\n\t * block either grace period, update the ->gp_tasks and/or\n\t * ->exp_tasks pointers, respectively, to reference the newly\n\t * blocked tasks.\n\t */\n\tif (!rnp->gp_tasks && (blkd_state & RCU_GP_BLKD)) {\n\t\tWRITE_ONCE(rnp->gp_tasks, &t->rcu_node_entry);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq);\n\t}\n\tif (!rnp->exp_tasks && (blkd_state & RCU_EXP_BLKD))\n\t\tWRITE_ONCE(rnp->exp_tasks, &t->rcu_node_entry);\n\tWARN_ON_ONCE(!(blkd_state & RCU_GP_BLKD) !=\n\t\t     !(rnp->qsmask & rdp->grpmask));\n\tWARN_ON_ONCE(!(blkd_state & RCU_EXP_BLKD) !=\n\t\t     !(rnp->expmask & rdp->grpmask));\n\traw_spin_unlock_rcu_node(rnp); /* interrupts remain disabled. */\n\n\t/*\n\t * Report the quiescent state for the expedited GP.  This expedited\n\t * GP should not be able to end until we report, so there should be\n\t * no need to check for a subsequent expedited GP.  (Though we are\n\t * still in a quiescent state in any case.)\n\t */\n\tif (blkd_state & RCU_EXP_BLKD && rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\telse\n\t\tWARN_ON_ONCE(rdp->cpu_no_qs.b.exp);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [
      "#define RCU_EXP_BLKD\t0x1",
      "#define RCU_GP_BLKD\t0x2",
      "#define RCU_EXP_TASKS\t0x4",
      "#define RCU_GP_TASKS\t0x8"
    ],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rdp->cpu_no_qs.b.exp"
          ],
          "line": 264
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_report_exp_rdp",
          "args": [
            "rdp"
          ],
          "line": 262
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_report_exp_rdp",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_exp.h",
          "lines": "256-260",
          "snippet": "static void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}",
          "includes": [
            "#include <linux/lockdep.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <linux/lockdep.h>\n\nstatic void rcu_report_exp_rdp(struct rcu_data *rdp)\n{\n\tWRITE_ONCE(rdp->cpu_no_qs.b.exp, false);\n\trcu_report_exp_cpu_mult(rdp->mynode, rdp->grpmask, true);\n}"
        }
      },
      {
        "call_info": {
          "callee": "raw_spin_unlock_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 253
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!(blkd_state & RCU_EXP_BLKD) !=\n\t\t     !(rnp->expmask & rdp->grpmask)"
          ],
          "line": 251
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!(blkd_state & RCU_GP_BLKD) !=\n\t\t     !(rnp->qsmask & rdp->grpmask)"
          ],
          "line": 249
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->exp_tasks",
            "&t->rcu_node_entry"
          ],
          "line": 248
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rnp->completedqs == rnp->gp_seq"
          ],
          "line": 245
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WRITE_ONCE",
          "args": [
            "rnp->gp_tasks",
            "&t->rcu_node_entry"
          ],
          "line": 244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "1"
          ],
          "line": 233
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "list_add",
          "args": [
            "&t->rcu_node_entry",
            "rnp->gp_tasks"
          ],
          "line": 227
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_add_len",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.c",
          "lines": "210-221",
          "snippet": "void rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}",
          "includes": [
            "#include \"rcu_segcblist.h\"",
            "#include <linux/types.h>",
            "#include <linux/kernel.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/cpu.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"rcu_segcblist.h\"\n#include <linux/types.h>\n#include <linux/kernel.h>\n#include <linux/interrupt.h>\n#include <linux/cpu.h>\n\nvoid rcu_segcblist_add_len(struct rcu_segcblist *rsclp, long v)\n{\n#ifdef CONFIG_RCU_NOCB_CPU\n\tsmp_mb__before_atomic(); // Read header comment above.\n\tatomic_long_add(v, &rsclp->len);\n\tsmp_mb__after_atomic();  // Read header comment above.\n#else\n\tsmp_mb(); // Read header comment above.\n\tWRITE_ONCE(rsclp->len, rsclp->len + v);\n\tsmp_mb(); // Read header comment above.\n#endif\n}"
        }
      },
      {
        "call_info": {
          "callee": "list_add_tail",
          "args": [
            "&t->rcu_node_entry",
            "&rnp->blkd_tasks"
          ],
          "line": 203
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rnp->qsmaskinitnext & ~rnp->qsmaskinit & rnp->qsmask &\n\t\t     rdp->grpmask"
          ],
          "line": 164
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "!rcu_is_leaf_node(rnp)"
          ],
          "line": 162
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_is_leaf_node",
          "args": [
            "rnp"
          ],
          "line": 162
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "rdp->mynode != rnp"
          ],
          "line": 161
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "raw_lockdep_assert_held_rcu_node",
          "args": [
            "rnp"
          ],
          "line": 160
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__releases",
          "args": [
            "rnp->lock"
          ],
          "line": 152
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\n#define RCU_EXP_BLKD\t0x1\n#define RCU_GP_BLKD\t0x2\n#define RCU_EXP_TASKS\t0x4\n#define RCU_GP_TASKS\t0x8\n\nstatic void rcu_preempt_ctxt_queue(struct rcu_node *rnp, struct rcu_data *rdp)\n\t__releases(rnp->lock) /* But leaves rrupts disabled. */\n{\n\tint blkd_state = (rnp->gp_tasks ? RCU_GP_TASKS : 0) +\n\t\t\t (rnp->exp_tasks ? RCU_EXP_TASKS : 0) +\n\t\t\t (rnp->qsmask & rdp->grpmask ? RCU_GP_BLKD : 0) +\n\t\t\t (rnp->expmask & rdp->grpmask ? RCU_EXP_BLKD : 0);\n\tstruct task_struct *t = current;\n\n\traw_lockdep_assert_held_rcu_node(rnp);\n\tWARN_ON_ONCE(rdp->mynode != rnp);\n\tWARN_ON_ONCE(!rcu_is_leaf_node(rnp));\n\t/* RCU better not be waiting on newly onlined CPUs! */\n\tWARN_ON_ONCE(rnp->qsmaskinitnext & ~rnp->qsmaskinit & rnp->qsmask &\n\t\t     rdp->grpmask);\n\n\t/*\n\t * Decide where to queue the newly blocked task.  In theory,\n\t * this could be an if-statement.  In practice, when I tried\n\t * that, it was quite messy.\n\t */\n\tswitch (blkd_state) {\n\tcase 0:\n\tcase                RCU_EXP_TASKS:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD:\n\tcase RCU_GP_TASKS:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS:\n\n\t\t/*\n\t\t * Blocking neither GP, or first task blocking the normal\n\t\t * GP but not blocking the already-waiting expedited GP.\n\t\t * Queue at the head of the list to avoid unnecessarily\n\t\t * blocking the already-waiting GPs.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                                              RCU_EXP_BLKD:\n\tcase                                RCU_GP_BLKD:\n\tcase                                RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                               RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * First task arriving that blocks either GP, or first task\n\t\t * arriving that blocks the expedited GP (with the normal\n\t\t * GP already waiting), or a task arriving that blocks\n\t\t * both GPs with both GPs already waiting.  Queue at the\n\t\t * tail of the list to avoid any GP waiting on any of the\n\t\t * already queued tasks that are not blocking it.\n\t\t */\n\t\tlist_add_tail(&t->rcu_node_entry, &rnp->blkd_tasks);\n\t\tbreak;\n\n\tcase                RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\tcase                RCU_EXP_TASKS + RCU_GP_BLKD + RCU_EXP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS +               RCU_EXP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the expedited GP.\n\t\t * The task either does not block the normal GP, or is the\n\t\t * first task blocking the normal GP.  Queue just after\n\t\t * the first task blocking the expedited GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->exp_tasks);\n\t\tbreak;\n\n\tcase RCU_GP_TASKS +                 RCU_GP_BLKD:\n\tcase RCU_GP_TASKS + RCU_EXP_TASKS + RCU_GP_BLKD:\n\n\t\t/*\n\t\t * Second or subsequent task blocking the normal GP.\n\t\t * The task does not block the expedited GP. Queue just\n\t\t * after the first task blocking the normal GP.\n\t\t */\n\t\tlist_add(&t->rcu_node_entry, rnp->gp_tasks);\n\t\tbreak;\n\n\tdefault:\n\n\t\t/* Yet another exercise in excessive paranoia. */\n\t\tWARN_ON_ONCE(1);\n\t\tbreak;\n\t}\n\n\t/*\n\t * We have now queued the task.  If it was the first one to\n\t * block either grace period, update the ->gp_tasks and/or\n\t * ->exp_tasks pointers, respectively, to reference the newly\n\t * blocked tasks.\n\t */\n\tif (!rnp->gp_tasks && (blkd_state & RCU_GP_BLKD)) {\n\t\tWRITE_ONCE(rnp->gp_tasks, &t->rcu_node_entry);\n\t\tWARN_ON_ONCE(rnp->completedqs == rnp->gp_seq);\n\t}\n\tif (!rnp->exp_tasks && (blkd_state & RCU_EXP_BLKD))\n\t\tWRITE_ONCE(rnp->exp_tasks, &t->rcu_node_entry);\n\tWARN_ON_ONCE(!(blkd_state & RCU_GP_BLKD) !=\n\t\t     !(rnp->qsmask & rdp->grpmask));\n\tWARN_ON_ONCE(!(blkd_state & RCU_EXP_BLKD) !=\n\t\t     !(rnp->expmask & rdp->grpmask));\n\traw_spin_unlock_rcu_node(rnp); /* interrupts remain disabled. */\n\n\t/*\n\t * Report the quiescent state for the expedited GP.  This expedited\n\t * GP should not be able to end until we report, so there should be\n\t * no need to check for a subsequent expedited GP.  (Though we are\n\t * still in a quiescent state in any case.)\n\t */\n\tif (blkd_state & RCU_EXP_BLKD && rdp->cpu_no_qs.b.exp)\n\t\trcu_report_exp_rdp(rdp);\n\telse\n\t\tWARN_ON_ONCE(rdp->cpu_no_qs.b.exp);\n}"
  },
  {
    "function_name": "rcu_bootup_announce",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "111-115",
    "snippet": "static void __init rcu_bootup_announce(void)\n{\n\tpr_info(\"Preemptible hierarchical RCU implementation.\\n\");\n\trcu_bootup_announce_oddness();\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_bootup_announce_oddness",
          "args": [],
          "line": 114
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_bootup_announce_oddness",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
          "lines": "44-101",
          "snippet": "static void __init rcu_bootup_announce_oddness(void)\n{\n\tif (IS_ENABLED(CONFIG_RCU_TRACE))\n\t\tpr_info(\"\\tRCU event tracing is enabled.\\n\");\n\tif ((IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 64) ||\n\t    (!IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 32))\n\t\tpr_info(\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\",\n\t\t\tRCU_FANOUT);\n\tif (rcu_fanout_exact)\n\t\tpr_info(\"\\tHierarchical RCU autobalancing is disabled.\\n\");\n\tif (IS_ENABLED(CONFIG_PROVE_RCU))\n\t\tpr_info(\"\\tRCU lockdep checking is enabled.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))\n\t\tpr_info(\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\");\n\tif (RCU_NUM_LVLS >= 4)\n\t\tpr_info(\"\\tFour(or more)-level hierarchy is enabled.\\n\");\n\tif (RCU_FANOUT_LEAF != 16)\n\t\tpr_info(\"\\tBuild-time adjustment of leaf fanout to %d.\\n\",\n\t\t\tRCU_FANOUT_LEAF);\n\tif (rcu_fanout_leaf != RCU_FANOUT_LEAF)\n\t\tpr_info(\"\\tBoot-time adjustment of leaf fanout to %d.\\n\",\n\t\t\trcu_fanout_leaf);\n\tif (nr_cpu_ids != NR_CPUS)\n\t\tpr_info(\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\", NR_CPUS, nr_cpu_ids);\n#ifdef CONFIG_RCU_BOOST\n\tpr_info(\"\\tRCU priority boosting: priority %d delay %d ms.\\n\",\n\t\tkthread_prio, CONFIG_RCU_BOOST_DELAY);\n#endif\n\tif (blimit != DEFAULT_RCU_BLIMIT)\n\t\tpr_info(\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\", blimit);\n\tif (qhimark != DEFAULT_RCU_QHIMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\", qhimark);\n\tif (qlowmark != DEFAULT_RCU_QLOMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\", qlowmark);\n\tif (qovld != DEFAULT_RCU_QOVLD)\n\t\tpr_info(\"\\tBoot-time adjustment of callback overload level to %ld.\\n\", qovld);\n\tif (jiffies_till_first_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\", jiffies_till_first_fqs);\n\tif (jiffies_till_next_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\", jiffies_till_next_fqs);\n\tif (jiffies_till_sched_qs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\", jiffies_till_sched_qs);\n\tif (rcu_kick_kthreads)\n\t\tpr_info(\"\\tKick kthreads if too-long grace period.\\n\");\n\tif (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))\n\t\tpr_info(\"\\tRCU callback double-/use-after-free debug is enabled.\\n\");\n\tif (gp_preinit_delay)\n\t\tpr_info(\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\", gp_preinit_delay);\n\tif (gp_init_delay)\n\t\tpr_info(\"\\tRCU debug GP init slowdown %d jiffies.\\n\", gp_init_delay);\n\tif (gp_cleanup_delay)\n\t\tpr_info(\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\", gp_cleanup_delay);\n\tif (!use_softirq)\n\t\tpr_info(\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))\n\t\tpr_info(\"\\tRCU debug extended QS entry/exit.\\n\");\n\trcupdate_announce_bootup_oddness();\n}",
          "includes": [
            "#include \"../locking/rtmutex_common.h\""
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_bootup_announce_oddness(void)\n{\n\tif (IS_ENABLED(CONFIG_RCU_TRACE))\n\t\tpr_info(\"\\tRCU event tracing is enabled.\\n\");\n\tif ((IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 64) ||\n\t    (!IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 32))\n\t\tpr_info(\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\",\n\t\t\tRCU_FANOUT);\n\tif (rcu_fanout_exact)\n\t\tpr_info(\"\\tHierarchical RCU autobalancing is disabled.\\n\");\n\tif (IS_ENABLED(CONFIG_PROVE_RCU))\n\t\tpr_info(\"\\tRCU lockdep checking is enabled.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))\n\t\tpr_info(\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\");\n\tif (RCU_NUM_LVLS >= 4)\n\t\tpr_info(\"\\tFour(or more)-level hierarchy is enabled.\\n\");\n\tif (RCU_FANOUT_LEAF != 16)\n\t\tpr_info(\"\\tBuild-time adjustment of leaf fanout to %d.\\n\",\n\t\t\tRCU_FANOUT_LEAF);\n\tif (rcu_fanout_leaf != RCU_FANOUT_LEAF)\n\t\tpr_info(\"\\tBoot-time adjustment of leaf fanout to %d.\\n\",\n\t\t\trcu_fanout_leaf);\n\tif (nr_cpu_ids != NR_CPUS)\n\t\tpr_info(\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\", NR_CPUS, nr_cpu_ids);\n#ifdef CONFIG_RCU_BOOST\n\tpr_info(\"\\tRCU priority boosting: priority %d delay %d ms.\\n\",\n\t\tkthread_prio, CONFIG_RCU_BOOST_DELAY);\n#endif\n\tif (blimit != DEFAULT_RCU_BLIMIT)\n\t\tpr_info(\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\", blimit);\n\tif (qhimark != DEFAULT_RCU_QHIMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\", qhimark);\n\tif (qlowmark != DEFAULT_RCU_QLOMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\", qlowmark);\n\tif (qovld != DEFAULT_RCU_QOVLD)\n\t\tpr_info(\"\\tBoot-time adjustment of callback overload level to %ld.\\n\", qovld);\n\tif (jiffies_till_first_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\", jiffies_till_first_fqs);\n\tif (jiffies_till_next_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\", jiffies_till_next_fqs);\n\tif (jiffies_till_sched_qs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\", jiffies_till_sched_qs);\n\tif (rcu_kick_kthreads)\n\t\tpr_info(\"\\tKick kthreads if too-long grace period.\\n\");\n\tif (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))\n\t\tpr_info(\"\\tRCU callback double-/use-after-free debug is enabled.\\n\");\n\tif (gp_preinit_delay)\n\t\tpr_info(\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\", gp_preinit_delay);\n\tif (gp_init_delay)\n\t\tpr_info(\"\\tRCU debug GP init slowdown %d jiffies.\\n\", gp_init_delay);\n\tif (gp_cleanup_delay)\n\t\tpr_info(\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\", gp_cleanup_delay);\n\tif (!use_softirq)\n\t\tpr_info(\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))\n\t\tpr_info(\"\\tRCU debug extended QS entry/exit.\\n\");\n\trcupdate_announce_bootup_oddness();\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"Preemptible hierarchical RCU implementation.\\n\""
          ],
          "line": 113
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_bootup_announce(void)\n{\n\tpr_info(\"Preemptible hierarchical RCU implementation.\\n\");\n\trcu_bootup_announce_oddness();\n}"
  },
  {
    "function_name": "rcu_bootup_announce_oddness",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "44-101",
    "snippet": "static void __init rcu_bootup_announce_oddness(void)\n{\n\tif (IS_ENABLED(CONFIG_RCU_TRACE))\n\t\tpr_info(\"\\tRCU event tracing is enabled.\\n\");\n\tif ((IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 64) ||\n\t    (!IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 32))\n\t\tpr_info(\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\",\n\t\t\tRCU_FANOUT);\n\tif (rcu_fanout_exact)\n\t\tpr_info(\"\\tHierarchical RCU autobalancing is disabled.\\n\");\n\tif (IS_ENABLED(CONFIG_PROVE_RCU))\n\t\tpr_info(\"\\tRCU lockdep checking is enabled.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))\n\t\tpr_info(\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\");\n\tif (RCU_NUM_LVLS >= 4)\n\t\tpr_info(\"\\tFour(or more)-level hierarchy is enabled.\\n\");\n\tif (RCU_FANOUT_LEAF != 16)\n\t\tpr_info(\"\\tBuild-time adjustment of leaf fanout to %d.\\n\",\n\t\t\tRCU_FANOUT_LEAF);\n\tif (rcu_fanout_leaf != RCU_FANOUT_LEAF)\n\t\tpr_info(\"\\tBoot-time adjustment of leaf fanout to %d.\\n\",\n\t\t\trcu_fanout_leaf);\n\tif (nr_cpu_ids != NR_CPUS)\n\t\tpr_info(\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\", NR_CPUS, nr_cpu_ids);\n#ifdef CONFIG_RCU_BOOST\n\tpr_info(\"\\tRCU priority boosting: priority %d delay %d ms.\\n\",\n\t\tkthread_prio, CONFIG_RCU_BOOST_DELAY);\n#endif\n\tif (blimit != DEFAULT_RCU_BLIMIT)\n\t\tpr_info(\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\", blimit);\n\tif (qhimark != DEFAULT_RCU_QHIMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\", qhimark);\n\tif (qlowmark != DEFAULT_RCU_QLOMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\", qlowmark);\n\tif (qovld != DEFAULT_RCU_QOVLD)\n\t\tpr_info(\"\\tBoot-time adjustment of callback overload level to %ld.\\n\", qovld);\n\tif (jiffies_till_first_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\", jiffies_till_first_fqs);\n\tif (jiffies_till_next_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\", jiffies_till_next_fqs);\n\tif (jiffies_till_sched_qs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\", jiffies_till_sched_qs);\n\tif (rcu_kick_kthreads)\n\t\tpr_info(\"\\tKick kthreads if too-long grace period.\\n\");\n\tif (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))\n\t\tpr_info(\"\\tRCU callback double-/use-after-free debug is enabled.\\n\");\n\tif (gp_preinit_delay)\n\t\tpr_info(\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\", gp_preinit_delay);\n\tif (gp_init_delay)\n\t\tpr_info(\"\\tRCU debug GP init slowdown %d jiffies.\\n\", gp_init_delay);\n\tif (gp_cleanup_delay)\n\t\tpr_info(\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\", gp_cleanup_delay);\n\tif (!use_softirq)\n\t\tpr_info(\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))\n\t\tpr_info(\"\\tRCU debug extended QS entry/exit.\\n\");\n\trcupdate_announce_bootup_oddness();\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcupdate_announce_bootup_oddness",
          "args": [],
          "line": 100
        },
        "resolved": true,
        "details": {
          "function_name": "rcupdate_announce_bootup_oddness",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/update.c",
          "lines": "591-604",
          "snippet": "void __init rcupdate_announce_bootup_oddness(void)\n{\n\tif (rcu_normal)\n\t\tpr_info(\"\\tNo expedited grace period (rcu_normal).\\n\");\n\telse if (rcu_normal_after_boot)\n\t\tpr_info(\"\\tNo expedited grace period (rcu_normal_after_boot).\\n\");\n\telse if (rcu_expedited)\n\t\tpr_info(\"\\tAll grace periods are expedited (rcu_expedited).\\n\");\n\tif (rcu_cpu_stall_suppress)\n\t\tpr_info(\"\\tRCU CPU stall warnings suppressed (rcu_cpu_stall_suppress).\\n\");\n\tif (rcu_cpu_stall_timeout != CONFIG_RCU_CPU_STALL_TIMEOUT)\n\t\tpr_info(\"\\tRCU CPU stall warnings timeout set to %d (rcu_cpu_stall_timeout).\\n\", rcu_cpu_stall_timeout);\n\trcu_tasks_bootup_oddness();\n}",
          "includes": [
            "#include \"tasks.h\"",
            "#include \"rcu.h\"",
            "#include <linux/rcupdate_trace.h>",
            "#include <linux/irq_work.h>",
            "#include <linux/slab.h>",
            "#include <linux/kprobes.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/rcupdate_wait.h>",
            "#include <linux/tick.h>",
            "#include <linux/kthread.h>",
            "#include <linux/moduleparam.h>",
            "#include <linux/delay.h>",
            "#include <linux/hardirq.h>",
            "#include <linux/export.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpu.h>",
            "#include <linux/notifier.h>",
            "#include <linux/percpu.h>",
            "#include <linux/bitops.h>",
            "#include <linux/atomic.h>",
            "#include <linux/sched/debug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/smp.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/init.h>",
            "#include <linux/kernel.h>",
            "#include <linux/types.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"tasks.h\"\n#include \"rcu.h\"\n#include <linux/rcupdate_trace.h>\n#include <linux/irq_work.h>\n#include <linux/slab.h>\n#include <linux/kprobes.h>\n#include <linux/sched/isolation.h>\n#include <linux/rcupdate_wait.h>\n#include <linux/tick.h>\n#include <linux/kthread.h>\n#include <linux/moduleparam.h>\n#include <linux/delay.h>\n#include <linux/hardirq.h>\n#include <linux/export.h>\n#include <linux/mutex.h>\n#include <linux/cpu.h>\n#include <linux/notifier.h>\n#include <linux/percpu.h>\n#include <linux/bitops.h>\n#include <linux/atomic.h>\n#include <linux/sched/debug.h>\n#include <linux/sched/signal.h>\n#include <linux/interrupt.h>\n#include <linux/smp.h>\n#include <linux/spinlock.h>\n#include <linux/init.h>\n#include <linux/kernel.h>\n#include <linux/types.h>\n\nvoid __init rcupdate_announce_bootup_oddness(void)\n{\n\tif (rcu_normal)\n\t\tpr_info(\"\\tNo expedited grace period (rcu_normal).\\n\");\n\telse if (rcu_normal_after_boot)\n\t\tpr_info(\"\\tNo expedited grace period (rcu_normal_after_boot).\\n\");\n\telse if (rcu_expedited)\n\t\tpr_info(\"\\tAll grace periods are expedited (rcu_expedited).\\n\");\n\tif (rcu_cpu_stall_suppress)\n\t\tpr_info(\"\\tRCU CPU stall warnings suppressed (rcu_cpu_stall_suppress).\\n\");\n\tif (rcu_cpu_stall_timeout != CONFIG_RCU_CPU_STALL_TIMEOUT)\n\t\tpr_info(\"\\tRCU CPU stall warnings timeout set to %d (rcu_cpu_stall_timeout).\\n\", rcu_cpu_stall_timeout);\n\trcu_tasks_bootup_oddness();\n}"
        }
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU debug extended QS entry/exit.\\n\""
          ],
          "line": 99
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_EQS_DEBUG"
          ],
          "line": 98
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\""
          ],
          "line": 97
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\"",
            "gp_cleanup_delay"
          ],
          "line": 95
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU debug GP init slowdown %d jiffies.\\n\"",
            "gp_init_delay"
          ],
          "line": 93
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\"",
            "gp_preinit_delay"
          ],
          "line": 91
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU callback double-/use-after-free debug is enabled.\\n\""
          ],
          "line": 89
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_DEBUG_OBJECTS_RCU_HEAD"
          ],
          "line": 88
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tKick kthreads if too-long grace period.\\n\""
          ],
          "line": 87
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\"",
            "jiffies_till_sched_qs"
          ],
          "line": 85
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\"",
            "jiffies_till_next_fqs"
          ],
          "line": 83
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\"",
            "jiffies_till_first_fqs"
          ],
          "line": 81
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of callback overload level to %ld.\\n\"",
            "qovld"
          ],
          "line": 79
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\"",
            "qlowmark"
          ],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\"",
            "qhimark"
          ],
          "line": 75
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\"",
            "blimit"
          ],
          "line": 73
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU priority boosting: priority %d delay %d ms.\\n\"",
            "kthread_prio",
            "CONFIG_RCU_BOOST_DELAY"
          ],
          "line": 69
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\"",
            "NR_CPUS",
            "nr_cpu_ids"
          ],
          "line": 67
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBoot-time adjustment of leaf fanout to %d.\\n\"",
            "rcu_fanout_leaf"
          ],
          "line": 64
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tBuild-time adjustment of leaf fanout to %d.\\n\"",
            "RCU_FANOUT_LEAF"
          ],
          "line": 61
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tFour(or more)-level hierarchy is enabled.\\n\""
          ],
          "line": 59
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\""
          ],
          "line": 57
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_STRICT_GRACE_PERIOD"
          ],
          "line": 56
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU lockdep checking is enabled.\\n\""
          ],
          "line": 55
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_PROVE_RCU"
          ],
          "line": 54
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tHierarchical RCU autobalancing is disabled.\\n\""
          ],
          "line": 53
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\"",
            "RCU_FANOUT"
          ],
          "line": 50
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_64BIT"
          ],
          "line": 49
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_64BIT"
          ],
          "line": 48
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pr_info",
          "args": [
            "\"\\tRCU event tracing is enabled.\\n\""
          ],
          "line": 47
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_RCU_TRACE"
          ],
          "line": 46
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic void __init rcu_bootup_announce_oddness(void)\n{\n\tif (IS_ENABLED(CONFIG_RCU_TRACE))\n\t\tpr_info(\"\\tRCU event tracing is enabled.\\n\");\n\tif ((IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 64) ||\n\t    (!IS_ENABLED(CONFIG_64BIT) && RCU_FANOUT != 32))\n\t\tpr_info(\"\\tCONFIG_RCU_FANOUT set to non-default value of %d.\\n\",\n\t\t\tRCU_FANOUT);\n\tif (rcu_fanout_exact)\n\t\tpr_info(\"\\tHierarchical RCU autobalancing is disabled.\\n\");\n\tif (IS_ENABLED(CONFIG_PROVE_RCU))\n\t\tpr_info(\"\\tRCU lockdep checking is enabled.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_STRICT_GRACE_PERIOD))\n\t\tpr_info(\"\\tRCU strict (and thus non-scalable) grace periods are enabled.\\n\");\n\tif (RCU_NUM_LVLS >= 4)\n\t\tpr_info(\"\\tFour(or more)-level hierarchy is enabled.\\n\");\n\tif (RCU_FANOUT_LEAF != 16)\n\t\tpr_info(\"\\tBuild-time adjustment of leaf fanout to %d.\\n\",\n\t\t\tRCU_FANOUT_LEAF);\n\tif (rcu_fanout_leaf != RCU_FANOUT_LEAF)\n\t\tpr_info(\"\\tBoot-time adjustment of leaf fanout to %d.\\n\",\n\t\t\trcu_fanout_leaf);\n\tif (nr_cpu_ids != NR_CPUS)\n\t\tpr_info(\"\\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%u.\\n\", NR_CPUS, nr_cpu_ids);\n#ifdef CONFIG_RCU_BOOST\n\tpr_info(\"\\tRCU priority boosting: priority %d delay %d ms.\\n\",\n\t\tkthread_prio, CONFIG_RCU_BOOST_DELAY);\n#endif\n\tif (blimit != DEFAULT_RCU_BLIMIT)\n\t\tpr_info(\"\\tBoot-time adjustment of callback invocation limit to %ld.\\n\", blimit);\n\tif (qhimark != DEFAULT_RCU_QHIMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback high-water mark to %ld.\\n\", qhimark);\n\tif (qlowmark != DEFAULT_RCU_QLOMARK)\n\t\tpr_info(\"\\tBoot-time adjustment of callback low-water mark to %ld.\\n\", qlowmark);\n\tif (qovld != DEFAULT_RCU_QOVLD)\n\t\tpr_info(\"\\tBoot-time adjustment of callback overload level to %ld.\\n\", qovld);\n\tif (jiffies_till_first_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of first FQS scan delay to %ld jiffies.\\n\", jiffies_till_first_fqs);\n\tif (jiffies_till_next_fqs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of subsequent FQS scan delay to %ld jiffies.\\n\", jiffies_till_next_fqs);\n\tif (jiffies_till_sched_qs != ULONG_MAX)\n\t\tpr_info(\"\\tBoot-time adjustment of scheduler-enlistment delay to %ld jiffies.\\n\", jiffies_till_sched_qs);\n\tif (rcu_kick_kthreads)\n\t\tpr_info(\"\\tKick kthreads if too-long grace period.\\n\");\n\tif (IS_ENABLED(CONFIG_DEBUG_OBJECTS_RCU_HEAD))\n\t\tpr_info(\"\\tRCU callback double-/use-after-free debug is enabled.\\n\");\n\tif (gp_preinit_delay)\n\t\tpr_info(\"\\tRCU debug GP pre-init slowdown %d jiffies.\\n\", gp_preinit_delay);\n\tif (gp_init_delay)\n\t\tpr_info(\"\\tRCU debug GP init slowdown %d jiffies.\\n\", gp_init_delay);\n\tif (gp_cleanup_delay)\n\t\tpr_info(\"\\tRCU debug GP cleanup slowdown %d jiffies.\\n\", gp_cleanup_delay);\n\tif (!use_softirq)\n\t\tpr_info(\"\\tRCU_SOFTIRQ processing moved to rcuc kthreads.\\n\");\n\tif (IS_ENABLED(CONFIG_RCU_EQS_DEBUG))\n\t\tpr_info(\"\\tRCU debug extended QS entry/exit.\\n\");\n\trcupdate_announce_bootup_oddness();\n}"
  },
  {
    "function_name": "rcu_rdp_is_offloaded",
    "container": null,
    "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_plugin.h",
    "lines": "16-38",
    "snippet": "static bool rcu_rdp_is_offloaded(struct rcu_data *rdp)\n{\n\t/*\n\t * In order to read the offloaded state of an rdp in a safe\n\t * and stable way and prevent from its value to be changed\n\t * under us, we must either hold the barrier mutex, the cpu\n\t * hotplug lock (read or write) or the nocb lock. Local\n\t * non-preemptible reads are also safe. NOCB kthreads and\n\t * timers have their own means of synchronization against the\n\t * offloaded state updaters.\n\t */\n\tRCU_LOCKDEP_WARN(\n\t\t!(lockdep_is_held(&rcu_state.barrier_mutex) ||\n\t\t  (IS_ENABLED(CONFIG_HOTPLUG_CPU) && lockdep_is_cpus_held()) ||\n\t\t  rcu_lockdep_is_held_nocb(rdp) ||\n\t\t  (rdp == this_cpu_ptr(&rcu_data) &&\n\t\t   !(IS_ENABLED(CONFIG_PREEMPT_COUNT) && preemptible())) ||\n\t\t  rcu_current_is_nocb_kthread(rdp)),\n\t\t\"Unsafe read of RCU_NOCB offloaded state\"\n\t);\n\n\treturn rcu_segcblist_is_offloaded(&rdp->cblist);\n}",
    "includes": [
      "#include \"../locking/rtmutex_common.h\""
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "rcu_segcblist_is_offloaded",
          "args": [
            "&rdp->cblist"
          ],
          "line": 37
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_segcblist_is_offloaded",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/rcu_segcblist.h",
          "lines": "87-94",
          "snippet": "static inline bool rcu_segcblist_is_offloaded(struct rcu_segcblist *rsclp)\n{\n\tif (IS_ENABLED(CONFIG_RCU_NOCB_CPU) &&\n\t    rcu_segcblist_test_flags(rsclp, SEGCBLIST_LOCKING))\n\t\treturn true;\n\n\treturn false;\n}",
          "includes": [
            "#include <linux/rcu_segcblist.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "long rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_init(struct rcu_segcblist *rsclp);",
            "void rcu_segcblist_disable(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);",
            "bool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);",
            "struct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <linux/rcu_segcblist.h>\n\nlong rcu_segcblist_n_segment_cbs(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_inc_len(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_init(struct rcu_segcblist *rsclp);\nvoid rcu_segcblist_disable(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_ready_cbs(struct rcu_segcblist *rsclp);\nbool rcu_segcblist_pend_cbs(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_cb(struct rcu_segcblist *rsclp);\nstruct rcu_head *rcu_segcblist_first_pend_cb(struct rcu_segcblist *rsclp);\n\nstatic inline bool rcu_segcblist_is_offloaded(struct rcu_segcblist *rsclp)\n{\n\tif (IS_ENABLED(CONFIG_RCU_NOCB_CPU) &&\n\t    rcu_segcblist_test_flags(rsclp, SEGCBLIST_LOCKING))\n\t\treturn true;\n\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "RCU_LOCKDEP_WARN",
          "args": [
            "!(lockdep_is_held(&rcu_state.barrier_mutex) ||\n\t\t  (IS_ENABLED(CONFIG_HOTPLUG_CPU) && lockdep_is_cpus_held()) ||\n\t\t  rcu_lockdep_is_held_nocb(rdp) ||\n\t\t  (rdp == this_cpu_ptr(&rcu_data) &&\n\t\t   !(IS_ENABLED(CONFIG_PREEMPT_COUNT) && preemptible())) ||\n\t\t  rcu_current_is_nocb_kthread(rdp))",
            "\"Unsafe read of RCU_NOCB offloaded state\""
          ],
          "line": 27
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_current_is_nocb_kthread",
          "args": [
            "rdp"
          ],
          "line": 33
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_current_is_nocb_kthread",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_nocb.h",
          "lines": "1463-1466",
          "snippet": "static inline bool rcu_current_is_nocb_kthread(struct rcu_data *rdp)\n{\n\treturn false;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline bool rcu_current_is_nocb_kthread(struct rcu_data *rdp)\n{\n\treturn false;\n}"
        }
      },
      {
        "call_info": {
          "callee": "preemptible",
          "args": [],
          "line": 32
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_PREEMPT_COUNT"
          ],
          "line": 32
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "this_cpu_ptr",
          "args": [
            "&rcu_data"
          ],
          "line": 31
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "rcu_lockdep_is_held_nocb",
          "args": [
            "rdp"
          ],
          "line": 30
        },
        "resolved": true,
        "details": {
          "function_name": "rcu_lockdep_is_held_nocb",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/rcu/tree_nocb.h",
          "lines": "1458-1461",
          "snippet": "static inline int rcu_lockdep_is_held_nocb(struct rcu_data *rdp)\n{\n\treturn 0;\n}",
          "includes": [],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "static inline int rcu_lockdep_is_held_nocb(struct rcu_data *rdp)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "lockdep_is_cpus_held",
          "args": [],
          "line": 29
        },
        "resolved": true,
        "details": {
          "function_name": "lockdep_is_cpus_held",
          "container": null,
          "file": "output_repos_c/CVE-2022-30594/repo/kernel/cpu.c",
          "lines": "350-353",
          "snippet": "int lockdep_is_cpus_held(void)\n{\n\treturn percpu_rwsem_is_held(&cpu_hotplug_lock);\n}",
          "includes": [
            "#include \"smpboot.h\"",
            "#include <trace/events/cpuhp.h>",
            "#include <trace/events/power.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/percpu-rwsem.h>",
            "#include <linux/scs.h>",
            "#include <linux/slab.h>",
            "#include <linux/relay.h>",
            "#include <linux/smpboot.h>",
            "#include <linux/nmi.h>",
            "#include <linux/irq.h>",
            "#include <linux/tick.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/suspend.h>",
            "#include <linux/gfp.h>",
            "#include <linux/mutex.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/kthread.h>",
            "#include <linux/bug.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/unistd.h>",
            "#include <linux/sched/smt.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/isolation.h>",
            "#include <linux/sched/hotplug.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/notifier.h>",
            "#include <linux/init.h>",
            "#include <linux/smp.h>",
            "#include <linux/proc_fs.h>",
            "#include <linux/sched/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"smpboot.h\"\n#include <trace/events/cpuhp.h>\n#include <trace/events/power.h>\n#include <linux/cpuset.h>\n#include <linux/percpu-rwsem.h>\n#include <linux/scs.h>\n#include <linux/slab.h>\n#include <linux/relay.h>\n#include <linux/smpboot.h>\n#include <linux/nmi.h>\n#include <linux/irq.h>\n#include <linux/tick.h>\n#include <linux/lockdep.h>\n#include <linux/suspend.h>\n#include <linux/gfp.h>\n#include <linux/mutex.h>\n#include <linux/stop_machine.h>\n#include <linux/kthread.h>\n#include <linux/bug.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/unistd.h>\n#include <linux/sched/smt.h>\n#include <linux/sched/task.h>\n#include <linux/sched/isolation.h>\n#include <linux/sched/hotplug.h>\n#include <linux/sched/signal.h>\n#include <linux/notifier.h>\n#include <linux/init.h>\n#include <linux/smp.h>\n#include <linux/proc_fs.h>\n#include <linux/sched/mm.h>\n\nint lockdep_is_cpus_held(void)\n{\n\treturn percpu_rwsem_is_held(&cpu_hotplug_lock);\n}"
        }
      },
      {
        "call_info": {
          "callee": "IS_ENABLED",
          "args": [
            "CONFIG_HOTPLUG_CPU"
          ],
          "line": 29
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"../locking/rtmutex_common.h\"\n\nstatic bool rcu_rdp_is_offloaded(struct rcu_data *rdp)\n{\n\t/*\n\t * In order to read the offloaded state of an rdp in a safe\n\t * and stable way and prevent from its value to be changed\n\t * under us, we must either hold the barrier mutex, the cpu\n\t * hotplug lock (read or write) or the nocb lock. Local\n\t * non-preemptible reads are also safe. NOCB kthreads and\n\t * timers have their own means of synchronization against the\n\t * offloaded state updaters.\n\t */\n\tRCU_LOCKDEP_WARN(\n\t\t!(lockdep_is_held(&rcu_state.barrier_mutex) ||\n\t\t  (IS_ENABLED(CONFIG_HOTPLUG_CPU) && lockdep_is_cpus_held()) ||\n\t\t  rcu_lockdep_is_held_nocb(rdp) ||\n\t\t  (rdp == this_cpu_ptr(&rcu_data) &&\n\t\t   !(IS_ENABLED(CONFIG_PREEMPT_COUNT) && preemptible())) ||\n\t\t  rcu_current_is_nocb_kthread(rdp)),\n\t\t\"Unsafe read of RCU_NOCB offloaded state\"\n\t);\n\n\treturn rcu_segcblist_is_offloaded(&rdp->cblist);\n}"
  }
]