[
  {
    "function_name": "mfill_zeropage",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "594-598",
    "snippet": "ssize_t mfill_zeropage(struct mm_struct *dst_mm, unsigned long start,\n\t\t       unsigned long len, bool *mmap_changing)\n{\n\treturn __mcopy_atomic(dst_mm, start, 0, len, true, mmap_changing);\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mcopy_atomic",
          "args": [
            "dst_mm",
            "start",
            "0",
            "len",
            "true",
            "mmap_changing"
          ],
          "line": 597
        },
        "resolved": true,
        "details": {
          "function_name": "__mcopy_atomic",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "413-584",
          "snippet": "static __always_inline ssize_t __mcopy_atomic(struct mm_struct *dst_mm,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage,\n\t\t\t\t\t      bool *mmap_changing)\n{\n\tstruct vm_area_struct *dst_vma;\n\tssize_t err;\n\tpmd_t *dst_pmd;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\n\t/*\n\t * Sanitize the command parameters:\n\t */\n\tBUG_ON(dst_start & ~PAGE_MASK);\n\tBUG_ON(len & ~PAGE_MASK);\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tBUG_ON(src_start + len <= src_start);\n\tBUG_ON(dst_start + len <= dst_start);\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\nretry:\n\tdown_read(&dst_mm->mmap_sem);\n\n\t/*\n\t * If memory mappings are changing because of non-cooperative\n\t * operation (e.g. mremap) running in parallel, bail out and\n\t * request the user to retry later\n\t */\n\terr = -EAGAIN;\n\tif (mmap_changing && READ_ONCE(*mmap_changing))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Make sure the vma is not shared, that the dst range is\n\t * both valid and fully within a single existing vma.\n\t */\n\terr = -ENOENT;\n\tdst_vma = find_vma(dst_mm, dst_start);\n\tif (!dst_vma)\n\t\tgoto out_unlock;\n\t/*\n\t * Be strict and only allow __mcopy_atomic on userfaultfd\n\t * registered ranges to prevent userland errors going\n\t * unnoticed. As far as the VM consistency is concerned, it\n\t * would be perfectly safe to remove this check, but there's\n\t * no useful usage for __mcopy_atomic ouside of userfaultfd\n\t * registered ranges. This is after all why these are ioctls\n\t * belonging to the userfaultfd and not syscalls.\n\t */\n\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\tgoto out_unlock;\n\n\tif (dst_start < dst_vma->vm_start ||\n\t    dst_start + len > dst_vma->vm_end)\n\t\tgoto out_unlock;\n\n\terr = -EINVAL;\n\t/*\n\t * shmem_zero_setup is invoked in mmap for MAP_ANONYMOUS|MAP_SHARED but\n\t * it will overwrite vm_ops, so vma_is_anonymous must return false.\n\t */\n\tif (WARN_ON_ONCE(vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If this is a HUGETLB vma, pass off to appropriate routine\n\t */\n\tif (is_vm_hugetlb_page(dst_vma))\n\t\treturn  __mcopy_atomic_hugetlb(dst_mm, dst_vma, dst_start,\n\t\t\t\t\t\tsrc_start, len, zeropage);\n\n\tif (!vma_is_anonymous(dst_vma) && !vma_is_shmem(dst_vma))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Ensure the dst_vma has a anon_vma or this page\n\t * would get a NULL anon_vma when moved in the\n\t * dst_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!(dst_vma->vm_flags & VM_SHARED) &&\n\t    unlikely(anon_vma_prepare(dst_vma)))\n\t\tgoto out_unlock;\n\n\twhile (src_addr < src_start + len) {\n\t\tpmd_t dst_pmdval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\n\t\tdst_pmd = mm_alloc_pmd(dst_mm, dst_addr);\n\t\tif (unlikely(!dst_pmd)) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tdst_pmdval = pmd_read_atomic(dst_pmd);\n\t\t/*\n\t\t * If the dst_pmd is mapped as THP don't\n\t\t * override it and just be strict.\n\t\t */\n\t\tif (unlikely(pmd_trans_huge(dst_pmdval))) {\n\t\t\terr = -EEXIST;\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(pmd_none(dst_pmdval)) &&\n\t\t    unlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\t/* If an huge pmd materialized from under us fail */\n\t\tif (unlikely(pmd_trans_huge(*dst_pmd))) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(pmd_none(*dst_pmd));\n\t\tBUG_ON(pmd_trans_huge(*dst_pmd));\n\n\t\terr = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,\n\t\t\t\t       src_addr, &page, zeropage);\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tvoid *page_kaddr;\n\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\tpage_kaddr = kmap(page);\n\t\t\terr = copy_from_user(page_kaddr,\n\t\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t\t     PAGE_SIZE);\n\t\t\tkunmap(page);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += PAGE_SIZE;\n\t\t\tsrc_addr += PAGE_SIZE;\n\t\t\tcopied += PAGE_SIZE;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page)\n\t\tput_page(page);\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t __mcopy_atomic(struct mm_struct *dst_mm,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage,\n\t\t\t\t\t      bool *mmap_changing)\n{\n\tstruct vm_area_struct *dst_vma;\n\tssize_t err;\n\tpmd_t *dst_pmd;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\n\t/*\n\t * Sanitize the command parameters:\n\t */\n\tBUG_ON(dst_start & ~PAGE_MASK);\n\tBUG_ON(len & ~PAGE_MASK);\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tBUG_ON(src_start + len <= src_start);\n\tBUG_ON(dst_start + len <= dst_start);\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\nretry:\n\tdown_read(&dst_mm->mmap_sem);\n\n\t/*\n\t * If memory mappings are changing because of non-cooperative\n\t * operation (e.g. mremap) running in parallel, bail out and\n\t * request the user to retry later\n\t */\n\terr = -EAGAIN;\n\tif (mmap_changing && READ_ONCE(*mmap_changing))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Make sure the vma is not shared, that the dst range is\n\t * both valid and fully within a single existing vma.\n\t */\n\terr = -ENOENT;\n\tdst_vma = find_vma(dst_mm, dst_start);\n\tif (!dst_vma)\n\t\tgoto out_unlock;\n\t/*\n\t * Be strict and only allow __mcopy_atomic on userfaultfd\n\t * registered ranges to prevent userland errors going\n\t * unnoticed. As far as the VM consistency is concerned, it\n\t * would be perfectly safe to remove this check, but there's\n\t * no useful usage for __mcopy_atomic ouside of userfaultfd\n\t * registered ranges. This is after all why these are ioctls\n\t * belonging to the userfaultfd and not syscalls.\n\t */\n\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\tgoto out_unlock;\n\n\tif (dst_start < dst_vma->vm_start ||\n\t    dst_start + len > dst_vma->vm_end)\n\t\tgoto out_unlock;\n\n\terr = -EINVAL;\n\t/*\n\t * shmem_zero_setup is invoked in mmap for MAP_ANONYMOUS|MAP_SHARED but\n\t * it will overwrite vm_ops, so vma_is_anonymous must return false.\n\t */\n\tif (WARN_ON_ONCE(vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If this is a HUGETLB vma, pass off to appropriate routine\n\t */\n\tif (is_vm_hugetlb_page(dst_vma))\n\t\treturn  __mcopy_atomic_hugetlb(dst_mm, dst_vma, dst_start,\n\t\t\t\t\t\tsrc_start, len, zeropage);\n\n\tif (!vma_is_anonymous(dst_vma) && !vma_is_shmem(dst_vma))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Ensure the dst_vma has a anon_vma or this page\n\t * would get a NULL anon_vma when moved in the\n\t * dst_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!(dst_vma->vm_flags & VM_SHARED) &&\n\t    unlikely(anon_vma_prepare(dst_vma)))\n\t\tgoto out_unlock;\n\n\twhile (src_addr < src_start + len) {\n\t\tpmd_t dst_pmdval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\n\t\tdst_pmd = mm_alloc_pmd(dst_mm, dst_addr);\n\t\tif (unlikely(!dst_pmd)) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tdst_pmdval = pmd_read_atomic(dst_pmd);\n\t\t/*\n\t\t * If the dst_pmd is mapped as THP don't\n\t\t * override it and just be strict.\n\t\t */\n\t\tif (unlikely(pmd_trans_huge(dst_pmdval))) {\n\t\t\terr = -EEXIST;\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(pmd_none(dst_pmdval)) &&\n\t\t    unlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\t/* If an huge pmd materialized from under us fail */\n\t\tif (unlikely(pmd_trans_huge(*dst_pmd))) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(pmd_none(*dst_pmd));\n\t\tBUG_ON(pmd_trans_huge(*dst_pmd));\n\n\t\terr = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,\n\t\t\t\t       src_addr, &page, zeropage);\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tvoid *page_kaddr;\n\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\tpage_kaddr = kmap(page);\n\t\t\terr = copy_from_user(page_kaddr,\n\t\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t\t     PAGE_SIZE);\n\t\t\tkunmap(page);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += PAGE_SIZE;\n\t\t\tsrc_addr += PAGE_SIZE;\n\t\t\tcopied += PAGE_SIZE;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page)\n\t\tput_page(page);\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nssize_t mfill_zeropage(struct mm_struct *dst_mm, unsigned long start,\n\t\t       unsigned long len, bool *mmap_changing)\n{\n\treturn __mcopy_atomic(dst_mm, start, 0, len, true, mmap_changing);\n}"
  },
  {
    "function_name": "mcopy_atomic",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "586-592",
    "snippet": "ssize_t mcopy_atomic(struct mm_struct *dst_mm, unsigned long dst_start,\n\t\t     unsigned long src_start, unsigned long len,\n\t\t     bool *mmap_changing)\n{\n\treturn __mcopy_atomic(dst_mm, dst_start, src_start, len, false,\n\t\t\t      mmap_changing);\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "__mcopy_atomic",
          "args": [
            "dst_mm",
            "dst_start",
            "src_start",
            "len",
            "false",
            "mmap_changing"
          ],
          "line": 590
        },
        "resolved": true,
        "details": {
          "function_name": "__mcopy_atomic",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "413-584",
          "snippet": "static __always_inline ssize_t __mcopy_atomic(struct mm_struct *dst_mm,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage,\n\t\t\t\t\t      bool *mmap_changing)\n{\n\tstruct vm_area_struct *dst_vma;\n\tssize_t err;\n\tpmd_t *dst_pmd;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\n\t/*\n\t * Sanitize the command parameters:\n\t */\n\tBUG_ON(dst_start & ~PAGE_MASK);\n\tBUG_ON(len & ~PAGE_MASK);\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tBUG_ON(src_start + len <= src_start);\n\tBUG_ON(dst_start + len <= dst_start);\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\nretry:\n\tdown_read(&dst_mm->mmap_sem);\n\n\t/*\n\t * If memory mappings are changing because of non-cooperative\n\t * operation (e.g. mremap) running in parallel, bail out and\n\t * request the user to retry later\n\t */\n\terr = -EAGAIN;\n\tif (mmap_changing && READ_ONCE(*mmap_changing))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Make sure the vma is not shared, that the dst range is\n\t * both valid and fully within a single existing vma.\n\t */\n\terr = -ENOENT;\n\tdst_vma = find_vma(dst_mm, dst_start);\n\tif (!dst_vma)\n\t\tgoto out_unlock;\n\t/*\n\t * Be strict and only allow __mcopy_atomic on userfaultfd\n\t * registered ranges to prevent userland errors going\n\t * unnoticed. As far as the VM consistency is concerned, it\n\t * would be perfectly safe to remove this check, but there's\n\t * no useful usage for __mcopy_atomic ouside of userfaultfd\n\t * registered ranges. This is after all why these are ioctls\n\t * belonging to the userfaultfd and not syscalls.\n\t */\n\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\tgoto out_unlock;\n\n\tif (dst_start < dst_vma->vm_start ||\n\t    dst_start + len > dst_vma->vm_end)\n\t\tgoto out_unlock;\n\n\terr = -EINVAL;\n\t/*\n\t * shmem_zero_setup is invoked in mmap for MAP_ANONYMOUS|MAP_SHARED but\n\t * it will overwrite vm_ops, so vma_is_anonymous must return false.\n\t */\n\tif (WARN_ON_ONCE(vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If this is a HUGETLB vma, pass off to appropriate routine\n\t */\n\tif (is_vm_hugetlb_page(dst_vma))\n\t\treturn  __mcopy_atomic_hugetlb(dst_mm, dst_vma, dst_start,\n\t\t\t\t\t\tsrc_start, len, zeropage);\n\n\tif (!vma_is_anonymous(dst_vma) && !vma_is_shmem(dst_vma))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Ensure the dst_vma has a anon_vma or this page\n\t * would get a NULL anon_vma when moved in the\n\t * dst_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!(dst_vma->vm_flags & VM_SHARED) &&\n\t    unlikely(anon_vma_prepare(dst_vma)))\n\t\tgoto out_unlock;\n\n\twhile (src_addr < src_start + len) {\n\t\tpmd_t dst_pmdval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\n\t\tdst_pmd = mm_alloc_pmd(dst_mm, dst_addr);\n\t\tif (unlikely(!dst_pmd)) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tdst_pmdval = pmd_read_atomic(dst_pmd);\n\t\t/*\n\t\t * If the dst_pmd is mapped as THP don't\n\t\t * override it and just be strict.\n\t\t */\n\t\tif (unlikely(pmd_trans_huge(dst_pmdval))) {\n\t\t\terr = -EEXIST;\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(pmd_none(dst_pmdval)) &&\n\t\t    unlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\t/* If an huge pmd materialized from under us fail */\n\t\tif (unlikely(pmd_trans_huge(*dst_pmd))) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(pmd_none(*dst_pmd));\n\t\tBUG_ON(pmd_trans_huge(*dst_pmd));\n\n\t\terr = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,\n\t\t\t\t       src_addr, &page, zeropage);\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tvoid *page_kaddr;\n\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\tpage_kaddr = kmap(page);\n\t\t\terr = copy_from_user(page_kaddr,\n\t\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t\t     PAGE_SIZE);\n\t\t\tkunmap(page);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += PAGE_SIZE;\n\t\t\tsrc_addr += PAGE_SIZE;\n\t\t\tcopied += PAGE_SIZE;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page)\n\t\tput_page(page);\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t __mcopy_atomic(struct mm_struct *dst_mm,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage,\n\t\t\t\t\t      bool *mmap_changing)\n{\n\tstruct vm_area_struct *dst_vma;\n\tssize_t err;\n\tpmd_t *dst_pmd;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\n\t/*\n\t * Sanitize the command parameters:\n\t */\n\tBUG_ON(dst_start & ~PAGE_MASK);\n\tBUG_ON(len & ~PAGE_MASK);\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tBUG_ON(src_start + len <= src_start);\n\tBUG_ON(dst_start + len <= dst_start);\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\nretry:\n\tdown_read(&dst_mm->mmap_sem);\n\n\t/*\n\t * If memory mappings are changing because of non-cooperative\n\t * operation (e.g. mremap) running in parallel, bail out and\n\t * request the user to retry later\n\t */\n\terr = -EAGAIN;\n\tif (mmap_changing && READ_ONCE(*mmap_changing))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Make sure the vma is not shared, that the dst range is\n\t * both valid and fully within a single existing vma.\n\t */\n\terr = -ENOENT;\n\tdst_vma = find_vma(dst_mm, dst_start);\n\tif (!dst_vma)\n\t\tgoto out_unlock;\n\t/*\n\t * Be strict and only allow __mcopy_atomic on userfaultfd\n\t * registered ranges to prevent userland errors going\n\t * unnoticed. As far as the VM consistency is concerned, it\n\t * would be perfectly safe to remove this check, but there's\n\t * no useful usage for __mcopy_atomic ouside of userfaultfd\n\t * registered ranges. This is after all why these are ioctls\n\t * belonging to the userfaultfd and not syscalls.\n\t */\n\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\tgoto out_unlock;\n\n\tif (dst_start < dst_vma->vm_start ||\n\t    dst_start + len > dst_vma->vm_end)\n\t\tgoto out_unlock;\n\n\terr = -EINVAL;\n\t/*\n\t * shmem_zero_setup is invoked in mmap for MAP_ANONYMOUS|MAP_SHARED but\n\t * it will overwrite vm_ops, so vma_is_anonymous must return false.\n\t */\n\tif (WARN_ON_ONCE(vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If this is a HUGETLB vma, pass off to appropriate routine\n\t */\n\tif (is_vm_hugetlb_page(dst_vma))\n\t\treturn  __mcopy_atomic_hugetlb(dst_mm, dst_vma, dst_start,\n\t\t\t\t\t\tsrc_start, len, zeropage);\n\n\tif (!vma_is_anonymous(dst_vma) && !vma_is_shmem(dst_vma))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Ensure the dst_vma has a anon_vma or this page\n\t * would get a NULL anon_vma when moved in the\n\t * dst_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!(dst_vma->vm_flags & VM_SHARED) &&\n\t    unlikely(anon_vma_prepare(dst_vma)))\n\t\tgoto out_unlock;\n\n\twhile (src_addr < src_start + len) {\n\t\tpmd_t dst_pmdval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\n\t\tdst_pmd = mm_alloc_pmd(dst_mm, dst_addr);\n\t\tif (unlikely(!dst_pmd)) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tdst_pmdval = pmd_read_atomic(dst_pmd);\n\t\t/*\n\t\t * If the dst_pmd is mapped as THP don't\n\t\t * override it and just be strict.\n\t\t */\n\t\tif (unlikely(pmd_trans_huge(dst_pmdval))) {\n\t\t\terr = -EEXIST;\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(pmd_none(dst_pmdval)) &&\n\t\t    unlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\t/* If an huge pmd materialized from under us fail */\n\t\tif (unlikely(pmd_trans_huge(*dst_pmd))) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(pmd_none(*dst_pmd));\n\t\tBUG_ON(pmd_trans_huge(*dst_pmd));\n\n\t\terr = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,\n\t\t\t\t       src_addr, &page, zeropage);\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tvoid *page_kaddr;\n\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\tpage_kaddr = kmap(page);\n\t\t\terr = copy_from_user(page_kaddr,\n\t\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t\t     PAGE_SIZE);\n\t\t\tkunmap(page);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += PAGE_SIZE;\n\t\t\tsrc_addr += PAGE_SIZE;\n\t\t\tcopied += PAGE_SIZE;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page)\n\t\tput_page(page);\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nssize_t mcopy_atomic(struct mm_struct *dst_mm, unsigned long dst_start,\n\t\t     unsigned long src_start, unsigned long len,\n\t\t     bool *mmap_changing)\n{\n\treturn __mcopy_atomic(dst_mm, dst_start, src_start, len, false,\n\t\t\t      mmap_changing);\n}"
  },
  {
    "function_name": "__mcopy_atomic",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "413-584",
    "snippet": "static __always_inline ssize_t __mcopy_atomic(struct mm_struct *dst_mm,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage,\n\t\t\t\t\t      bool *mmap_changing)\n{\n\tstruct vm_area_struct *dst_vma;\n\tssize_t err;\n\tpmd_t *dst_pmd;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\n\t/*\n\t * Sanitize the command parameters:\n\t */\n\tBUG_ON(dst_start & ~PAGE_MASK);\n\tBUG_ON(len & ~PAGE_MASK);\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tBUG_ON(src_start + len <= src_start);\n\tBUG_ON(dst_start + len <= dst_start);\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\nretry:\n\tdown_read(&dst_mm->mmap_sem);\n\n\t/*\n\t * If memory mappings are changing because of non-cooperative\n\t * operation (e.g. mremap) running in parallel, bail out and\n\t * request the user to retry later\n\t */\n\terr = -EAGAIN;\n\tif (mmap_changing && READ_ONCE(*mmap_changing))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Make sure the vma is not shared, that the dst range is\n\t * both valid and fully within a single existing vma.\n\t */\n\terr = -ENOENT;\n\tdst_vma = find_vma(dst_mm, dst_start);\n\tif (!dst_vma)\n\t\tgoto out_unlock;\n\t/*\n\t * Be strict and only allow __mcopy_atomic on userfaultfd\n\t * registered ranges to prevent userland errors going\n\t * unnoticed. As far as the VM consistency is concerned, it\n\t * would be perfectly safe to remove this check, but there's\n\t * no useful usage for __mcopy_atomic ouside of userfaultfd\n\t * registered ranges. This is after all why these are ioctls\n\t * belonging to the userfaultfd and not syscalls.\n\t */\n\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\tgoto out_unlock;\n\n\tif (dst_start < dst_vma->vm_start ||\n\t    dst_start + len > dst_vma->vm_end)\n\t\tgoto out_unlock;\n\n\terr = -EINVAL;\n\t/*\n\t * shmem_zero_setup is invoked in mmap for MAP_ANONYMOUS|MAP_SHARED but\n\t * it will overwrite vm_ops, so vma_is_anonymous must return false.\n\t */\n\tif (WARN_ON_ONCE(vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If this is a HUGETLB vma, pass off to appropriate routine\n\t */\n\tif (is_vm_hugetlb_page(dst_vma))\n\t\treturn  __mcopy_atomic_hugetlb(dst_mm, dst_vma, dst_start,\n\t\t\t\t\t\tsrc_start, len, zeropage);\n\n\tif (!vma_is_anonymous(dst_vma) && !vma_is_shmem(dst_vma))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Ensure the dst_vma has a anon_vma or this page\n\t * would get a NULL anon_vma when moved in the\n\t * dst_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!(dst_vma->vm_flags & VM_SHARED) &&\n\t    unlikely(anon_vma_prepare(dst_vma)))\n\t\tgoto out_unlock;\n\n\twhile (src_addr < src_start + len) {\n\t\tpmd_t dst_pmdval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\n\t\tdst_pmd = mm_alloc_pmd(dst_mm, dst_addr);\n\t\tif (unlikely(!dst_pmd)) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tdst_pmdval = pmd_read_atomic(dst_pmd);\n\t\t/*\n\t\t * If the dst_pmd is mapped as THP don't\n\t\t * override it and just be strict.\n\t\t */\n\t\tif (unlikely(pmd_trans_huge(dst_pmdval))) {\n\t\t\terr = -EEXIST;\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(pmd_none(dst_pmdval)) &&\n\t\t    unlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\t/* If an huge pmd materialized from under us fail */\n\t\tif (unlikely(pmd_trans_huge(*dst_pmd))) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(pmd_none(*dst_pmd));\n\t\tBUG_ON(pmd_trans_huge(*dst_pmd));\n\n\t\terr = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,\n\t\t\t\t       src_addr, &page, zeropage);\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tvoid *page_kaddr;\n\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\tpage_kaddr = kmap(page);\n\t\t\terr = copy_from_user(page_kaddr,\n\t\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t\t     PAGE_SIZE);\n\t\t\tkunmap(page);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += PAGE_SIZE;\n\t\t\tsrc_addr += PAGE_SIZE;\n\t\t\tcopied += PAGE_SIZE;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page)\n\t\tput_page(page);\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!copied && !err"
          ],
          "line": 582
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "err > 0"
          ],
          "line": 581
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "copied < 0"
          ],
          "line": 580
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "put_page",
          "args": [
            "page"
          ],
          "line": 579
        },
        "resolved": true,
        "details": {
          "function_name": "put_page_bootmem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory_hotplug.c",
          "lines": "143-158",
          "snippet": "void put_page_bootmem(struct page *page)\n{\n\tunsigned long type;\n\n\ttype = (unsigned long) page->freelist;\n\tBUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||\n\t       type > MEMORY_HOTPLUG_MAX_BOOTMEM_TYPE);\n\n\tif (page_ref_dec_return(page) == 1) {\n\t\tpage->freelist = NULL;\n\t\tClearPagePrivate(page);\n\t\tset_page_private(page, 0);\n\t\tINIT_LIST_HEAD(&page->lru);\n\t\tfree_reserved_page(page);\n\t}\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/compaction.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/firmware-map.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/suspend.h>",
            "#include <linux/pfn.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/migrate.h>",
            "#include <linux/delay.h>",
            "#include <linux/ioport.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/highmem.h>",
            "#include <linux/memory_hotplug.h>",
            "#include <linux/memremap.h>",
            "#include <linux/memory.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/slab.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/export.h>",
            "#include <linux/compiler.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/swap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/stddef.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void generic_online_page(struct page *page);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/compaction.h>\n#include <linux/memblock.h>\n#include <linux/hugetlb.h>\n#include <linux/stop_machine.h>\n#include <linux/firmware-map.h>\n#include <linux/mm_inline.h>\n#include <linux/suspend.h>\n#include <linux/pfn.h>\n#include <linux/page-isolation.h>\n#include <linux/migrate.h>\n#include <linux/delay.h>\n#include <linux/ioport.h>\n#include <linux/vmalloc.h>\n#include <linux/highmem.h>\n#include <linux/memory_hotplug.h>\n#include <linux/memremap.h>\n#include <linux/memory.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/slab.h>\n#include <linux/writeback.h>\n#include <linux/pagevec.h>\n#include <linux/export.h>\n#include <linux/compiler.h>\n#include <linux/pagemap.h>\n#include <linux/interrupt.h>\n#include <linux/swap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/stddef.h>\n\nstatic void generic_online_page(struct page *page);\n\nvoid put_page_bootmem(struct page *page)\n{\n\tunsigned long type;\n\n\ttype = (unsigned long) page->freelist;\n\tBUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||\n\t       type > MEMORY_HOTPLUG_MAX_BOOTMEM_TYPE);\n\n\tif (page_ref_dec_return(page) == 1) {\n\t\tpage->freelist = NULL;\n\t\tClearPagePrivate(page);\n\t\tset_page_private(page, 0);\n\t\tINIT_LIST_HEAD(&page->lru);\n\t\tfree_reserved_page(page);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 576
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fatal_signal_pending",
          "args": [
            "current"
          ],
          "line": 568
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "page"
          ],
          "line": 561
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err"
          ],
          "line": 555
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kunmap",
          "args": [
            "page"
          ],
          "line": 554
        },
        "resolved": true,
        "details": {
          "function_name": "kunmap_high",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/highmem.c",
          "lines": "329-370",
          "snippet": "void kunmap_high(struct page *page)\n{\n\tunsigned long vaddr;\n\tunsigned long nr;\n\tunsigned long flags;\n\tint need_wakeup;\n\tunsigned int color = get_pkmap_color(page);\n\twait_queue_head_t *pkmap_map_wait;\n\n\tlock_kmap_any(flags);\n\tvaddr = (unsigned long)page_address(page);\n\tBUG_ON(!vaddr);\n\tnr = PKMAP_NR(vaddr);\n\n\t/*\n\t * A count must never go down to zero\n\t * without a TLB flush!\n\t */\n\tneed_wakeup = 0;\n\tswitch (--pkmap_count[nr]) {\n\tcase 0:\n\t\tBUG();\n\tcase 1:\n\t\t/*\n\t\t * Avoid an unnecessary wake_up() function call.\n\t\t * The common case is pkmap_count[] == 1, but\n\t\t * no waiters.\n\t\t * The tasks queued in the wait-queue are guarded\n\t\t * by both the lock in the wait-queue-head and by\n\t\t * the kmap_lock.  As the kmap_lock is held here,\n\t\t * no need for the wait-queue-head's lock.  Simply\n\t\t * test if the queue is empty.\n\t\t */\n\t\tpkmap_map_wait = get_pkmap_wait_queue_head(color);\n\t\tneed_wakeup = waitqueue_active(pkmap_map_wait);\n\t}\n\tunlock_kmap_any(flags);\n\n\t/* do wake-up, if needed, race-free outside of the spin lock */\n\tif (need_wakeup)\n\t\twake_up(pkmap_map_wait);\n}",
          "includes": [
            "#include <asm/tlbflush.h>",
            "#include <linux/kgdb.h>",
            "#include <linux/highmem.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/mempool.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/bio.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [
            "#define get_pkmap_color get_pkmap_color"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/tlbflush.h>\n#include <linux/kgdb.h>\n#include <linux/highmem.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/mempool.h>\n#include <linux/pagemap.h>\n#include <linux/bio.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n\n#define get_pkmap_color get_pkmap_color\n\nvoid kunmap_high(struct page *page)\n{\n\tunsigned long vaddr;\n\tunsigned long nr;\n\tunsigned long flags;\n\tint need_wakeup;\n\tunsigned int color = get_pkmap_color(page);\n\twait_queue_head_t *pkmap_map_wait;\n\n\tlock_kmap_any(flags);\n\tvaddr = (unsigned long)page_address(page);\n\tBUG_ON(!vaddr);\n\tnr = PKMAP_NR(vaddr);\n\n\t/*\n\t * A count must never go down to zero\n\t * without a TLB flush!\n\t */\n\tneed_wakeup = 0;\n\tswitch (--pkmap_count[nr]) {\n\tcase 0:\n\t\tBUG();\n\tcase 1:\n\t\t/*\n\t\t * Avoid an unnecessary wake_up() function call.\n\t\t * The common case is pkmap_count[] == 1, but\n\t\t * no waiters.\n\t\t * The tasks queued in the wait-queue are guarded\n\t\t * by both the lock in the wait-queue-head and by\n\t\t * the kmap_lock.  As the kmap_lock is held here,\n\t\t * no need for the wait-queue-head's lock.  Simply\n\t\t * test if the queue is empty.\n\t\t */\n\t\tpkmap_map_wait = get_pkmap_wait_queue_head(color);\n\t\tneed_wakeup = waitqueue_active(pkmap_map_wait);\n\t}\n\tunlock_kmap_any(flags);\n\n\t/* do wake-up, if needed, race-free outside of the spin lock */\n\tif (need_wakeup)\n\t\twake_up(pkmap_map_wait);\n}"
        }
      },
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "page_kaddr",
            "(const void __user *) src_addr",
            "PAGE_SIZE"
          ],
          "line": 551
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmap",
          "args": [
            "page"
          ],
          "line": 550
        },
        "resolved": true,
        "details": {
          "function_name": "kmap_high_get",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/highmem.c",
          "lines": "307-319",
          "snippet": "void *kmap_high_get(struct page *page)\n{\n\tunsigned long vaddr, flags;\n\n\tlock_kmap_any(flags);\n\tvaddr = (unsigned long)page_address(page);\n\tif (vaddr) {\n\t\tBUG_ON(pkmap_count[PKMAP_NR(vaddr)] < 1);\n\t\tpkmap_count[PKMAP_NR(vaddr)]++;\n\t}\n\tunlock_kmap_any(flags);\n\treturn (void*) vaddr;\n}",
          "includes": [
            "#include <asm/tlbflush.h>",
            "#include <linux/kgdb.h>",
            "#include <linux/highmem.h>",
            "#include <linux/hash.h>",
            "#include <linux/init.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/mempool.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/bio.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <asm/tlbflush.h>\n#include <linux/kgdb.h>\n#include <linux/highmem.h>\n#include <linux/hash.h>\n#include <linux/init.h>\n#include <linux/blkdev.h>\n#include <linux/mempool.h>\n#include <linux/pagemap.h>\n#include <linux/bio.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/mm.h>\n\nvoid *kmap_high_get(struct page *page)\n{\n\tunsigned long vaddr, flags;\n\n\tlock_kmap_any(flags);\n\tvaddr = (unsigned long)page_address(page);\n\tif (vaddr) {\n\t\tBUG_ON(pkmap_count[PKMAP_NR(vaddr)] < 1);\n\t\tpkmap_count[PKMAP_NR(vaddr)]++;\n\t}\n\tunlock_kmap_any(flags);\n\treturn (void*) vaddr;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!page"
          ],
          "line": 548
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 547
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err == -ENOENT"
          ],
          "line": 544
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 542
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mfill_atomic_pte",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_vma",
            "dst_addr",
            "src_addr",
            "&page",
            "zeropage"
          ],
          "line": 540
        },
        "resolved": true,
        "details": {
          "function_name": "mfill_atomic_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "373-411",
          "snippet": "static __always_inline ssize_t mfill_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t\t\t\tpmd_t *dst_pmd,\n\t\t\t\t\t\tstruct vm_area_struct *dst_vma,\n\t\t\t\t\t\tunsigned long dst_addr,\n\t\t\t\t\t\tunsigned long src_addr,\n\t\t\t\t\t\tstruct page **page,\n\t\t\t\t\t\tbool zeropage)\n{\n\tssize_t err;\n\n\t/*\n\t * The normal page fault path for a shmem will invoke the\n\t * fault, fill the hole in the file and COW it right away. The\n\t * result generates plain anonymous memory. So when we are\n\t * asked to fill an hole in a MAP_PRIVATE shmem mapping, we'll\n\t * generate anonymous memory directly without actually filling\n\t * the hole. For the MAP_PRIVATE case the robustness check\n\t * only happens in the pagetable (to verify it's still none)\n\t * and not in the radix tree.\n\t */\n\tif (!(dst_vma->vm_flags & VM_SHARED)) {\n\t\tif (!zeropage)\n\t\t\terr = mcopy_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t\t       dst_addr, src_addr, page);\n\t\telse\n\t\t\terr = mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t dst_vma, dst_addr);\n\t} else {\n\t\tif (!zeropage)\n\t\t\terr = shmem_mcopy_atomic_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t     dst_vma, dst_addr,\n\t\t\t\t\t\t     src_addr, page);\n\t\telse\n\t\t\terr = shmem_mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t       dst_vma, dst_addr);\n\t}\n\n\treturn err;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t mfill_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t\t\t\tpmd_t *dst_pmd,\n\t\t\t\t\t\tstruct vm_area_struct *dst_vma,\n\t\t\t\t\t\tunsigned long dst_addr,\n\t\t\t\t\t\tunsigned long src_addr,\n\t\t\t\t\t\tstruct page **page,\n\t\t\t\t\t\tbool zeropage)\n{\n\tssize_t err;\n\n\t/*\n\t * The normal page fault path for a shmem will invoke the\n\t * fault, fill the hole in the file and COW it right away. The\n\t * result generates plain anonymous memory. So when we are\n\t * asked to fill an hole in a MAP_PRIVATE shmem mapping, we'll\n\t * generate anonymous memory directly without actually filling\n\t * the hole. For the MAP_PRIVATE case the robustness check\n\t * only happens in the pagetable (to verify it's still none)\n\t * and not in the radix tree.\n\t */\n\tif (!(dst_vma->vm_flags & VM_SHARED)) {\n\t\tif (!zeropage)\n\t\t\terr = mcopy_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t\t       dst_addr, src_addr, page);\n\t\telse\n\t\t\terr = mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t dst_vma, dst_addr);\n\t} else {\n\t\tif (!zeropage)\n\t\t\terr = shmem_mcopy_atomic_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t     dst_vma, dst_addr,\n\t\t\t\t\t\t     src_addr, page);\n\t\telse\n\t\t\terr = shmem_mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t       dst_vma, dst_addr);\n\t}\n\n\treturn err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "pmd_trans_huge(*dst_pmd)"
          ],
          "line": 538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pmd_trans_huge",
          "args": [
            "*dst_pmd"
          ],
          "line": 538
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "pmd_none(*dst_pmd)"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pmd_none",
          "args": [
            "*dst_pmd"
          ],
          "line": 537
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "pmd_trans_huge(*dst_pmd)"
          ],
          "line": 532
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pmd_trans_huge",
          "args": [
            "*dst_pmd"
          ],
          "line": 532
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "__pte_alloc(dst_mm, dst_pmd, dst_addr)"
          ],
          "line": 527
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__pte_alloc",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_addr"
          ],
          "line": 527
        },
        "resolved": true,
        "details": {
          "function_name": "__pte_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory.c",
          "lines": "403-435",
          "snippet": "int __pte_alloc(struct mm_struct *mm, pmd_t *pmd, unsigned long address)\n{\n\tspinlock_t *ptl;\n\tpgtable_t new = pte_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Ensure all pte setup (eg. pte page lock and page clearing) are\n\t * visible before the pte is made visible to other CPUs by being\n\t * put into page tables.\n\t *\n\t * The other side of the story is the pointer chasing in the page\n\t * table walking code (when walking the page table without locking;\n\t * ie. most of the time). Fortunately, these data accesses consist\n\t * of a chain of data-dependent loads, meaning most CPUs (alpha\n\t * being the notable exception) will already guarantee loads are\n\t * seen in-order. See the alpha page table accessors for the\n\t * smp_read_barrier_depends() barriers in page table walking code.\n\t */\n\tsmp_wmb(); /* Could be smp_wmb__xxx(before|after)_spin_lock */\n\n\tptl = pmd_lock(mm, pmd);\n\tif (likely(pmd_none(*pmd))) {\t/* Has another populated it ? */\n\t\tmm_inc_nr_ptes(mm);\n\t\tpmd_populate(mm, pmd, new);\n\t\tnew = NULL;\n\t}\n\tspin_unlock(ptl);\n\tif (new)\n\t\tpte_free(mm, new);\n\treturn 0;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/mmu_context.h>",
            "#include <asm/io.h>",
            "#include <linux/oom.h>",
            "#include <linux/dax.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-debug.h>",
            "#include <linux/string.h>",
            "#include <linux/migrate.h>",
            "#include <linux/gfp.h>",
            "#include <linux/elf.h>",
            "#include <linux/swapops.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pfn_t.h>",
            "#include <linux/init.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/export.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/memremap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/mmu_context.h>\n#include <asm/io.h>\n#include <linux/oom.h>\n#include <linux/dax.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/debugfs.h>\n#include <linux/dma-debug.h>\n#include <linux/string.h>\n#include <linux/migrate.h>\n#include <linux/gfp.h>\n#include <linux/elf.h>\n#include <linux/swapops.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/writeback.h>\n#include <linux/pfn_t.h>\n#include <linux/init.h>\n#include <linux/delayacct.h>\n#include <linux/export.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/memremap.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/hugetlb.h>\n#include <linux/sched/task.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/kernel_stat.h>\n\nint __pte_alloc(struct mm_struct *mm, pmd_t *pmd, unsigned long address)\n{\n\tspinlock_t *ptl;\n\tpgtable_t new = pte_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\t/*\n\t * Ensure all pte setup (eg. pte page lock and page clearing) are\n\t * visible before the pte is made visible to other CPUs by being\n\t * put into page tables.\n\t *\n\t * The other side of the story is the pointer chasing in the page\n\t * table walking code (when walking the page table without locking;\n\t * ie. most of the time). Fortunately, these data accesses consist\n\t * of a chain of data-dependent loads, meaning most CPUs (alpha\n\t * being the notable exception) will already guarantee loads are\n\t * seen in-order. See the alpha page table accessors for the\n\t * smp_read_barrier_depends() barriers in page table walking code.\n\t */\n\tsmp_wmb(); /* Could be smp_wmb__xxx(before|after)_spin_lock */\n\n\tptl = pmd_lock(mm, pmd);\n\tif (likely(pmd_none(*pmd))) {\t/* Has another populated it ? */\n\t\tmm_inc_nr_ptes(mm);\n\t\tpmd_populate(mm, pmd, new);\n\t\tnew = NULL;\n\t}\n\tspin_unlock(ptl);\n\tif (new)\n\t\tpte_free(mm, new);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "pmd_none(dst_pmdval)"
          ],
          "line": 526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pmd_none",
          "args": [
            "dst_pmdval"
          ],
          "line": 526
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "pmd_trans_huge(dst_pmdval)"
          ],
          "line": 522
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pmd_trans_huge",
          "args": [
            "dst_pmdval"
          ],
          "line": 522
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pmd_read_atomic",
          "args": [
            "dst_pmd"
          ],
          "line": 517
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "!dst_pmd"
          ],
          "line": 512
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mm_alloc_pmd",
          "args": [
            "dst_mm",
            "dst_addr"
          ],
          "line": 511
        },
        "resolved": true,
        "details": {
          "function_name": "mm_alloc_pmd",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "127-146",
          "snippet": "static pmd_t *mm_alloc_pmd(struct mm_struct *mm, unsigned long address)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\n\tpgd = pgd_offset(mm, address);\n\tp4d = p4d_alloc(mm, pgd, address);\n\tif (!p4d)\n\t\treturn NULL;\n\tpud = pud_alloc(mm, p4d, address);\n\tif (!pud)\n\t\treturn NULL;\n\t/*\n\t * Note that we didn't run this because the pmd was\n\t * missing, the *pmd may be already established and in\n\t * turn it may also be a trans_huge_pmd.\n\t */\n\treturn pmd_alloc(mm, pud, address);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic pmd_t *mm_alloc_pmd(struct mm_struct *mm, unsigned long address)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\n\tpgd = pgd_offset(mm, address);\n\tp4d = p4d_alloc(mm, pgd, address);\n\tif (!p4d)\n\t\treturn NULL;\n\tpud = pud_alloc(mm, p4d, address);\n\tif (!pud)\n\t\treturn NULL;\n\t/*\n\t * Note that we didn't run this because the pmd was\n\t * missing, the *pmd may be already established and in\n\t * turn it may also be a trans_huge_pmd.\n\t */\n\treturn pmd_alloc(mm, pud, address);\n}"
        }
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "dst_addr >= dst_start + len"
          ],
          "line": 509
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "anon_vma_prepare(dst_vma)"
          ],
          "line": 503
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "anon_vma_prepare",
          "args": [
            "dst_vma"
          ],
          "line": 503
        },
        "resolved": true,
        "details": {
          "function_name": "__anon_vma_prepare",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/rmap.c",
          "lines": "175-221",
          "snippet": "int __anon_vma_prepare(struct vm_area_struct *vma)\n{\n\tstruct mm_struct *mm = vma->vm_mm;\n\tstruct anon_vma *anon_vma, *allocated;\n\tstruct anon_vma_chain *avc;\n\n\tmight_sleep();\n\n\tavc = anon_vma_chain_alloc(GFP_KERNEL);\n\tif (!avc)\n\t\tgoto out_enomem;\n\n\tanon_vma = find_mergeable_anon_vma(vma);\n\tallocated = NULL;\n\tif (!anon_vma) {\n\t\tanon_vma = anon_vma_alloc();\n\t\tif (unlikely(!anon_vma))\n\t\t\tgoto out_enomem_free_avc;\n\t\tallocated = anon_vma;\n\t}\n\n\tanon_vma_lock_write(anon_vma);\n\t/* page_table_lock to protect against threads */\n\tspin_lock(&mm->page_table_lock);\n\tif (likely(!vma->anon_vma)) {\n\t\tvma->anon_vma = anon_vma;\n\t\tanon_vma_chain_link(vma, avc, anon_vma);\n\t\t/* vma reference or self-parent link for new root */\n\t\tanon_vma->degree++;\n\t\tallocated = NULL;\n\t\tavc = NULL;\n\t}\n\tspin_unlock(&mm->page_table_lock);\n\tanon_vma_unlock_write(anon_vma);\n\n\tif (unlikely(allocated))\n\t\tput_anon_vma(allocated);\n\tif (unlikely(avc))\n\t\tanon_vma_chain_free(avc);\n\n\treturn 0;\n\n out_enomem_free_avc:\n\tanon_vma_chain_free(avc);\n out_enomem:\n\treturn -ENOMEM;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <trace/events/tlb.h>",
            "#include <asm/tlbflush.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/memremap.h>",
            "#include <linux/page_idle.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/migrate.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <trace/events/tlb.h>\n#include <asm/tlbflush.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/memremap.h>\n#include <linux/page_idle.h>\n#include <linux/backing-dev.h>\n#include <linux/hugetlb.h>\n#include <linux/migrate.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n\nint __anon_vma_prepare(struct vm_area_struct *vma)\n{\n\tstruct mm_struct *mm = vma->vm_mm;\n\tstruct anon_vma *anon_vma, *allocated;\n\tstruct anon_vma_chain *avc;\n\n\tmight_sleep();\n\n\tavc = anon_vma_chain_alloc(GFP_KERNEL);\n\tif (!avc)\n\t\tgoto out_enomem;\n\n\tanon_vma = find_mergeable_anon_vma(vma);\n\tallocated = NULL;\n\tif (!anon_vma) {\n\t\tanon_vma = anon_vma_alloc();\n\t\tif (unlikely(!anon_vma))\n\t\t\tgoto out_enomem_free_avc;\n\t\tallocated = anon_vma;\n\t}\n\n\tanon_vma_lock_write(anon_vma);\n\t/* page_table_lock to protect against threads */\n\tspin_lock(&mm->page_table_lock);\n\tif (likely(!vma->anon_vma)) {\n\t\tvma->anon_vma = anon_vma;\n\t\tanon_vma_chain_link(vma, avc, anon_vma);\n\t\t/* vma reference or self-parent link for new root */\n\t\tanon_vma->degree++;\n\t\tallocated = NULL;\n\t\tavc = NULL;\n\t}\n\tspin_unlock(&mm->page_table_lock);\n\tanon_vma_unlock_write(anon_vma);\n\n\tif (unlikely(allocated))\n\t\tput_anon_vma(allocated);\n\tif (unlikely(avc))\n\t\tanon_vma_chain_free(avc);\n\n\treturn 0;\n\n out_enomem_free_avc:\n\tanon_vma_chain_free(avc);\n out_enomem:\n\treturn -ENOMEM;\n}"
        }
      },
      {
        "call_info": {
          "callee": "vma_is_shmem",
          "args": [
            "dst_vma"
          ],
          "line": 493
        },
        "resolved": true,
        "details": {
          "function_name": "vma_is_shmem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/shmem.c",
          "lines": "234-237",
          "snippet": "bool vma_is_shmem(struct vm_area_struct *vma)\n{\n\treturn vma->vm_ops == &shmem_vm_ops;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/uuid.h>",
            "#include <linux/rmap.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <uapi/linux/memfd.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/magic.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/highmem.h>",
            "#include <linux/migrate.h>",
            "#include <linux/ctype.h>",
            "#include <linux/namei.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/swapops.h>",
            "#include <linux/security.h>",
            "#include <linux/splice.h>",
            "#include <linux/falloc.h>",
            "#include <linux/percpu_counter.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/writeback.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/slab.h>",
            "#include <linux/string.h>",
            "#include <linux/mman.h>",
            "#include <linux/posix_acl_xattr.h>",
            "#include <linux/posix_acl.h>",
            "#include <linux/exportfs.h>",
            "#include <linux/xattr.h>",
            "#include <asm/tlbflush.h> /* for arch/microblaze update_mmu_cache() */",
            "#include <linux/hugetlb.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/uio.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/random.h>",
            "#include <linux/mm.h>",
            "#include <linux/file.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/ramfs.h>",
            "#include <linux/mount.h>",
            "#include <linux/vfs.h>",
            "#include <linux/init.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [
            "#define shmem_vm_ops\t\t\t\tgeneric_file_vm_ops"
          ],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <linux/uaccess.h>\n#include <linux/uuid.h>\n#include <linux/rmap.h>\n#include <linux/userfaultfd_k.h>\n#include <uapi/linux/memfd.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/magic.h>\n#include <linux/seq_file.h>\n#include <linux/highmem.h>\n#include <linux/migrate.h>\n#include <linux/ctype.h>\n#include <linux/namei.h>\n#include <linux/mempolicy.h>\n#include <linux/swapops.h>\n#include <linux/security.h>\n#include <linux/splice.h>\n#include <linux/falloc.h>\n#include <linux/percpu_counter.h>\n#include <linux/pagevec.h>\n#include <linux/blkdev.h>\n#include <linux/writeback.h>\n#include <linux/shmem_fs.h>\n#include <linux/backing-dev.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/mman.h>\n#include <linux/posix_acl_xattr.h>\n#include <linux/posix_acl.h>\n#include <linux/exportfs.h>\n#include <linux/xattr.h>\n#include <asm/tlbflush.h> /* for arch/microblaze update_mmu_cache() */\n#include <linux/hugetlb.h>\n#include <linux/khugepaged.h>\n#include <linux/uio.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/sched/signal.h>\n#include <linux/random.h>\n#include <linux/mm.h>\n#include <linux/file.h>\n#include <linux/pagemap.h>\n#include <linux/ramfs.h>\n#include <linux/mount.h>\n#include <linux/vfs.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n\n#define shmem_vm_ops\t\t\t\tgeneric_file_vm_ops\n\nbool vma_is_shmem(struct vm_area_struct *vma)\n{\n\treturn vma->vm_ops == &shmem_vm_ops;\n}"
        }
      },
      {
        "call_info": {
          "callee": "vma_is_anonymous",
          "args": [
            "dst_vma"
          ],
          "line": 493
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "__mcopy_atomic_hugetlb",
          "args": [
            "dst_mm",
            "dst_vma",
            "dst_start",
            "src_start",
            "len",
            "zeropage"
          ],
          "line": 490
        },
        "resolved": true,
        "details": {
          "function_name": "__mcopy_atomic_hugetlb",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "153-362",
          "snippet": "static __always_inline ssize_t __mcopy_atomic_hugetlb(struct mm_struct *dst_mm,\n\t\t\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage)\n{\n\tint vm_alloc_shared = dst_vma->vm_flags & VM_SHARED;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tssize_t err;\n\tpte_t *dst_pte;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\tstruct hstate *h;\n\tunsigned long vma_hpagesize;\n\tpgoff_t idx;\n\tu32 hash;\n\tstruct address_space *mapping;\n\n\t/*\n\t * There is no default zero huge page for all huge page sizes as\n\t * supported by hugetlb.  A PMD_SIZE huge pages may exist as used\n\t * by THP.  Since we can not reliably insert a zero page, this\n\t * feature is not supported.\n\t */\n\tif (zeropage) {\n\t\tup_read(&dst_mm->mmap_sem);\n\t\treturn -EINVAL;\n\t}\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\n\tvma_hpagesize = vma_kernel_pagesize(dst_vma);\n\n\t/*\n\t * Validate alignment based on huge page size\n\t */\n\terr = -EINVAL;\n\tif (dst_start & (vma_hpagesize - 1) || len & (vma_hpagesize - 1))\n\t\tgoto out_unlock;\n\nretry:\n\t/*\n\t * On routine entry dst_vma is set.  If we had to drop mmap_sem and\n\t * retry, dst_vma will be set to NULL and we must lookup again.\n\t */\n\tif (!dst_vma) {\n\t\terr = -ENOENT;\n\t\tdst_vma = find_vma(dst_mm, dst_start);\n\t\tif (!dst_vma || !is_vm_hugetlb_page(dst_vma))\n\t\t\tgoto out_unlock;\n\t\t/*\n\t\t * Only allow __mcopy_atomic_hugetlb on userfaultfd\n\t\t * registered ranges.\n\t\t */\n\t\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\t\tgoto out_unlock;\n\n\t\tif (dst_start < dst_vma->vm_start ||\n\t\t    dst_start + len > dst_vma->vm_end)\n\t\t\tgoto out_unlock;\n\n\t\terr = -EINVAL;\n\t\tif (vma_hpagesize != vma_kernel_pagesize(dst_vma))\n\t\t\tgoto out_unlock;\n\n\t\tvm_shared = dst_vma->vm_flags & VM_SHARED;\n\t}\n\n\tif (WARN_ON(dst_addr & (vma_hpagesize - 1) ||\n\t\t    (len - copied) & (vma_hpagesize - 1)))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If not shared, ensure the dst_vma has a anon_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!vm_shared) {\n\t\tif (unlikely(anon_vma_prepare(dst_vma)))\n\t\t\tgoto out_unlock;\n\t}\n\n\th = hstate_vma(dst_vma);\n\n\twhile (src_addr < src_start + len) {\n\t\tpte_t dst_pteval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\t\tVM_BUG_ON(dst_addr & ~huge_page_mask(h));\n\n\t\t/*\n\t\t * Serialize via hugetlb_fault_mutex\n\t\t */\n\t\tidx = linear_page_index(dst_vma, dst_addr);\n\t\tmapping = dst_vma->vm_file->f_mapping;\n\t\thash = hugetlb_fault_mutex_hash(h, dst_mm, dst_vma, mapping,\n\t\t\t\t\t\t\t\tidx, dst_addr);\n\t\tmutex_lock(&hugetlb_fault_mutex_table[hash]);\n\n\t\terr = -ENOMEM;\n\t\tdst_pte = huge_pte_alloc(dst_mm, dst_addr, huge_page_size(h));\n\t\tif (!dst_pte) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = -EEXIST;\n\t\tdst_pteval = huge_ptep_get(dst_pte);\n\t\tif (!huge_pte_none(dst_pteval)) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = hugetlb_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma,\n\t\t\t\t\t\tdst_addr, src_addr, &page);\n\n\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\tvm_alloc_shared = vm_shared;\n\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\terr = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *)src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), true);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdown_read(&dst_mm->mmap_sem);\n\n\t\t\tdst_vma = NULL;\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += vma_hpagesize;\n\t\t\tsrc_addr += vma_hpagesize;\n\t\t\tcopied += vma_hpagesize;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page) {\n\t\t/*\n\t\t * We encountered an error and are about to free a newly\n\t\t * allocated huge page.\n\t\t *\n\t\t * Reservation handling is very subtle, and is different for\n\t\t * private and shared mappings.  See the routine\n\t\t * restore_reserve_on_error for details.  Unfortunately, we\n\t\t * can not call restore_reserve_on_error now as it would\n\t\t * require holding mmap_sem.\n\t\t *\n\t\t * If a reservation for the page existed in the reservation\n\t\t * map of a private mapping, the map was modified to indicate\n\t\t * the reservation was consumed when the page was allocated.\n\t\t * We clear the PagePrivate flag now so that the global\n\t\t * reserve count will not be incremented in free_huge_page.\n\t\t * The reservation map will still indicate the reservation\n\t\t * was consumed and possibly prevent later page allocation.\n\t\t * This is better than leaking a global reservation.  If no\n\t\t * reservation existed, it is still safe to clear PagePrivate\n\t\t * as no adjustments to reservation counts were made during\n\t\t * allocation.\n\t\t *\n\t\t * The reservation map for shared mappings indicates which\n\t\t * pages have reservations.  When a huge page is allocated\n\t\t * for an address with a reservation, no change is made to\n\t\t * the reserve map.  In this case PagePrivate will be set\n\t\t * to indicate that the global reservation count should be\n\t\t * incremented when the page is freed.  This is the desired\n\t\t * behavior.  However, when a huge page is allocated for an\n\t\t * address without a reservation a reservation entry is added\n\t\t * to the reservation map, and PagePrivate will not be set.\n\t\t * When the page is freed, the global reserve count will NOT\n\t\t * be incremented and it will appear as though we have leaked\n\t\t * reserved page.  In this case, set PagePrivate so that the\n\t\t * global reserve count will be incremented to match the\n\t\t * reservation map entry which was created.\n\t\t *\n\t\t * Note that vm_alloc_shared is based on the flags of the vma\n\t\t * for which the page was originally allocated.  dst_vma could\n\t\t * be different or NULL on error.\n\t\t */\n\t\tif (vm_alloc_shared)\n\t\t\tSetPagePrivate(page);\n\t\telse\n\t\t\tClearPagePrivate(page);\n\t\tput_page(page);\n\t}\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t __mcopy_atomic_hugetlb(struct mm_struct *dst_mm,\n\t\t\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage)\n{\n\tint vm_alloc_shared = dst_vma->vm_flags & VM_SHARED;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tssize_t err;\n\tpte_t *dst_pte;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\tstruct hstate *h;\n\tunsigned long vma_hpagesize;\n\tpgoff_t idx;\n\tu32 hash;\n\tstruct address_space *mapping;\n\n\t/*\n\t * There is no default zero huge page for all huge page sizes as\n\t * supported by hugetlb.  A PMD_SIZE huge pages may exist as used\n\t * by THP.  Since we can not reliably insert a zero page, this\n\t * feature is not supported.\n\t */\n\tif (zeropage) {\n\t\tup_read(&dst_mm->mmap_sem);\n\t\treturn -EINVAL;\n\t}\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\n\tvma_hpagesize = vma_kernel_pagesize(dst_vma);\n\n\t/*\n\t * Validate alignment based on huge page size\n\t */\n\terr = -EINVAL;\n\tif (dst_start & (vma_hpagesize - 1) || len & (vma_hpagesize - 1))\n\t\tgoto out_unlock;\n\nretry:\n\t/*\n\t * On routine entry dst_vma is set.  If we had to drop mmap_sem and\n\t * retry, dst_vma will be set to NULL and we must lookup again.\n\t */\n\tif (!dst_vma) {\n\t\terr = -ENOENT;\n\t\tdst_vma = find_vma(dst_mm, dst_start);\n\t\tif (!dst_vma || !is_vm_hugetlb_page(dst_vma))\n\t\t\tgoto out_unlock;\n\t\t/*\n\t\t * Only allow __mcopy_atomic_hugetlb on userfaultfd\n\t\t * registered ranges.\n\t\t */\n\t\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\t\tgoto out_unlock;\n\n\t\tif (dst_start < dst_vma->vm_start ||\n\t\t    dst_start + len > dst_vma->vm_end)\n\t\t\tgoto out_unlock;\n\n\t\terr = -EINVAL;\n\t\tif (vma_hpagesize != vma_kernel_pagesize(dst_vma))\n\t\t\tgoto out_unlock;\n\n\t\tvm_shared = dst_vma->vm_flags & VM_SHARED;\n\t}\n\n\tif (WARN_ON(dst_addr & (vma_hpagesize - 1) ||\n\t\t    (len - copied) & (vma_hpagesize - 1)))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If not shared, ensure the dst_vma has a anon_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!vm_shared) {\n\t\tif (unlikely(anon_vma_prepare(dst_vma)))\n\t\t\tgoto out_unlock;\n\t}\n\n\th = hstate_vma(dst_vma);\n\n\twhile (src_addr < src_start + len) {\n\t\tpte_t dst_pteval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\t\tVM_BUG_ON(dst_addr & ~huge_page_mask(h));\n\n\t\t/*\n\t\t * Serialize via hugetlb_fault_mutex\n\t\t */\n\t\tidx = linear_page_index(dst_vma, dst_addr);\n\t\tmapping = dst_vma->vm_file->f_mapping;\n\t\thash = hugetlb_fault_mutex_hash(h, dst_mm, dst_vma, mapping,\n\t\t\t\t\t\t\t\tidx, dst_addr);\n\t\tmutex_lock(&hugetlb_fault_mutex_table[hash]);\n\n\t\terr = -ENOMEM;\n\t\tdst_pte = huge_pte_alloc(dst_mm, dst_addr, huge_page_size(h));\n\t\tif (!dst_pte) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = -EEXIST;\n\t\tdst_pteval = huge_ptep_get(dst_pte);\n\t\tif (!huge_pte_none(dst_pteval)) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = hugetlb_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma,\n\t\t\t\t\t\tdst_addr, src_addr, &page);\n\n\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\tvm_alloc_shared = vm_shared;\n\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\terr = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *)src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), true);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdown_read(&dst_mm->mmap_sem);\n\n\t\t\tdst_vma = NULL;\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += vma_hpagesize;\n\t\t\tsrc_addr += vma_hpagesize;\n\t\t\tcopied += vma_hpagesize;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page) {\n\t\t/*\n\t\t * We encountered an error and are about to free a newly\n\t\t * allocated huge page.\n\t\t *\n\t\t * Reservation handling is very subtle, and is different for\n\t\t * private and shared mappings.  See the routine\n\t\t * restore_reserve_on_error for details.  Unfortunately, we\n\t\t * can not call restore_reserve_on_error now as it would\n\t\t * require holding mmap_sem.\n\t\t *\n\t\t * If a reservation for the page existed in the reservation\n\t\t * map of a private mapping, the map was modified to indicate\n\t\t * the reservation was consumed when the page was allocated.\n\t\t * We clear the PagePrivate flag now so that the global\n\t\t * reserve count will not be incremented in free_huge_page.\n\t\t * The reservation map will still indicate the reservation\n\t\t * was consumed and possibly prevent later page allocation.\n\t\t * This is better than leaking a global reservation.  If no\n\t\t * reservation existed, it is still safe to clear PagePrivate\n\t\t * as no adjustments to reservation counts were made during\n\t\t * allocation.\n\t\t *\n\t\t * The reservation map for shared mappings indicates which\n\t\t * pages have reservations.  When a huge page is allocated\n\t\t * for an address with a reservation, no change is made to\n\t\t * the reserve map.  In this case PagePrivate will be set\n\t\t * to indicate that the global reservation count should be\n\t\t * incremented when the page is freed.  This is the desired\n\t\t * behavior.  However, when a huge page is allocated for an\n\t\t * address without a reservation a reservation entry is added\n\t\t * to the reservation map, and PagePrivate will not be set.\n\t\t * When the page is freed, the global reserve count will NOT\n\t\t * be incremented and it will appear as though we have leaked\n\t\t * reserved page.  In this case, set PagePrivate so that the\n\t\t * global reserve count will be incremented to match the\n\t\t * reservation map entry which was created.\n\t\t *\n\t\t * Note that vm_alloc_shared is based on the flags of the vma\n\t\t * for which the page was originally allocated.  dst_vma could\n\t\t * be different or NULL on error.\n\t\t */\n\t\tif (vm_alloc_shared)\n\t\t\tSetPagePrivate(page);\n\t\telse\n\t\t\tClearPagePrivate(page);\n\t\tput_page(page);\n\t}\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_vm_hugetlb_page",
          "args": [
            "dst_vma"
          ],
          "line": 489
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "WARN_ON_ONCE",
          "args": [
            "vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED"
          ],
          "line": 482
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "vma_is_anonymous",
          "args": [
            "dst_vma"
          ],
          "line": 482
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "find_vma",
          "args": [
            "dst_mm",
            "dst_start"
          ],
          "line": 458
        },
        "resolved": true,
        "details": {
          "function_name": "find_vma",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/nommu.c",
          "lines": "775-796",
          "snippet": "struct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)\n{\n\tstruct vm_area_struct *vma;\n\n\t/* check the cache first */\n\tvma = vmacache_find(mm, addr);\n\tif (likely(vma))\n\t\treturn vma;\n\n\t/* trawl the list (there may be multiple mappings in which addr\n\t * resides) */\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->vm_start > addr)\n\t\t\treturn NULL;\n\t\tif (vma->vm_end > addr) {\n\t\t\tvmacache_update(addr, vma);\n\t\t\treturn vma;\n\t\t}\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/mmu_context.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/printk.h>",
            "#include <linux/audit.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/personality.h>",
            "#include <linux/mount.h>",
            "#include <linux/compiler.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/file.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/mmu_context.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <linux/printk.h>\n#include <linux/audit.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/personality.h>\n#include <linux/mount.h>\n#include <linux/compiler.h>\n#include <linux/backing-dev.h>\n#include <linux/blkdev.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/file.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/vmacache.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/export.h>\n\nstruct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)\n{\n\tstruct vm_area_struct *vma;\n\n\t/* check the cache first */\n\tvma = vmacache_find(mm, addr);\n\tif (likely(vma))\n\t\treturn vma;\n\n\t/* trawl the list (there may be multiple mappings in which addr\n\t * resides) */\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->vm_start > addr)\n\t\t\treturn NULL;\n\t\tif (vma->vm_end > addr) {\n\t\t\tvmacache_update(addr, vma);\n\t\t\treturn vma;\n\t\t}\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "READ_ONCE",
          "args": [
            "*mmap_changing"
          ],
          "line": 450
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 442
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "dst_start + len <= dst_start"
          ],
          "line": 435
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "src_start + len <= src_start"
          ],
          "line": 434
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "len & ~PAGE_MASK"
          ],
          "line": 431
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "dst_start & ~PAGE_MASK"
          ],
          "line": 430
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t __mcopy_atomic(struct mm_struct *dst_mm,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage,\n\t\t\t\t\t      bool *mmap_changing)\n{\n\tstruct vm_area_struct *dst_vma;\n\tssize_t err;\n\tpmd_t *dst_pmd;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\n\t/*\n\t * Sanitize the command parameters:\n\t */\n\tBUG_ON(dst_start & ~PAGE_MASK);\n\tBUG_ON(len & ~PAGE_MASK);\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tBUG_ON(src_start + len <= src_start);\n\tBUG_ON(dst_start + len <= dst_start);\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\nretry:\n\tdown_read(&dst_mm->mmap_sem);\n\n\t/*\n\t * If memory mappings are changing because of non-cooperative\n\t * operation (e.g. mremap) running in parallel, bail out and\n\t * request the user to retry later\n\t */\n\terr = -EAGAIN;\n\tif (mmap_changing && READ_ONCE(*mmap_changing))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Make sure the vma is not shared, that the dst range is\n\t * both valid and fully within a single existing vma.\n\t */\n\terr = -ENOENT;\n\tdst_vma = find_vma(dst_mm, dst_start);\n\tif (!dst_vma)\n\t\tgoto out_unlock;\n\t/*\n\t * Be strict and only allow __mcopy_atomic on userfaultfd\n\t * registered ranges to prevent userland errors going\n\t * unnoticed. As far as the VM consistency is concerned, it\n\t * would be perfectly safe to remove this check, but there's\n\t * no useful usage for __mcopy_atomic ouside of userfaultfd\n\t * registered ranges. This is after all why these are ioctls\n\t * belonging to the userfaultfd and not syscalls.\n\t */\n\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\tgoto out_unlock;\n\n\tif (dst_start < dst_vma->vm_start ||\n\t    dst_start + len > dst_vma->vm_end)\n\t\tgoto out_unlock;\n\n\terr = -EINVAL;\n\t/*\n\t * shmem_zero_setup is invoked in mmap for MAP_ANONYMOUS|MAP_SHARED but\n\t * it will overwrite vm_ops, so vma_is_anonymous must return false.\n\t */\n\tif (WARN_ON_ONCE(vma_is_anonymous(dst_vma) &&\n\t    dst_vma->vm_flags & VM_SHARED))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If this is a HUGETLB vma, pass off to appropriate routine\n\t */\n\tif (is_vm_hugetlb_page(dst_vma))\n\t\treturn  __mcopy_atomic_hugetlb(dst_mm, dst_vma, dst_start,\n\t\t\t\t\t\tsrc_start, len, zeropage);\n\n\tif (!vma_is_anonymous(dst_vma) && !vma_is_shmem(dst_vma))\n\t\tgoto out_unlock;\n\n\t/*\n\t * Ensure the dst_vma has a anon_vma or this page\n\t * would get a NULL anon_vma when moved in the\n\t * dst_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!(dst_vma->vm_flags & VM_SHARED) &&\n\t    unlikely(anon_vma_prepare(dst_vma)))\n\t\tgoto out_unlock;\n\n\twhile (src_addr < src_start + len) {\n\t\tpmd_t dst_pmdval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\n\t\tdst_pmd = mm_alloc_pmd(dst_mm, dst_addr);\n\t\tif (unlikely(!dst_pmd)) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tdst_pmdval = pmd_read_atomic(dst_pmd);\n\t\t/*\n\t\t * If the dst_pmd is mapped as THP don't\n\t\t * override it and just be strict.\n\t\t */\n\t\tif (unlikely(pmd_trans_huge(dst_pmdval))) {\n\t\t\terr = -EEXIST;\n\t\t\tbreak;\n\t\t}\n\t\tif (unlikely(pmd_none(dst_pmdval)) &&\n\t\t    unlikely(__pte_alloc(dst_mm, dst_pmd, dst_addr))) {\n\t\t\terr = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\t\t/* If an huge pmd materialized from under us fail */\n\t\tif (unlikely(pmd_trans_huge(*dst_pmd))) {\n\t\t\terr = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tBUG_ON(pmd_none(*dst_pmd));\n\t\tBUG_ON(pmd_trans_huge(*dst_pmd));\n\n\t\terr = mfill_atomic_pte(dst_mm, dst_pmd, dst_vma, dst_addr,\n\t\t\t\t       src_addr, &page, zeropage);\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tvoid *page_kaddr;\n\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\tpage_kaddr = kmap(page);\n\t\t\terr = copy_from_user(page_kaddr,\n\t\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t\t     PAGE_SIZE);\n\t\t\tkunmap(page);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += PAGE_SIZE;\n\t\t\tsrc_addr += PAGE_SIZE;\n\t\t\tcopied += PAGE_SIZE;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page)\n\t\tput_page(page);\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}"
  },
  {
    "function_name": "mfill_atomic_pte",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "373-411",
    "snippet": "static __always_inline ssize_t mfill_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t\t\t\tpmd_t *dst_pmd,\n\t\t\t\t\t\tstruct vm_area_struct *dst_vma,\n\t\t\t\t\t\tunsigned long dst_addr,\n\t\t\t\t\t\tunsigned long src_addr,\n\t\t\t\t\t\tstruct page **page,\n\t\t\t\t\t\tbool zeropage)\n{\n\tssize_t err;\n\n\t/*\n\t * The normal page fault path for a shmem will invoke the\n\t * fault, fill the hole in the file and COW it right away. The\n\t * result generates plain anonymous memory. So when we are\n\t * asked to fill an hole in a MAP_PRIVATE shmem mapping, we'll\n\t * generate anonymous memory directly without actually filling\n\t * the hole. For the MAP_PRIVATE case the robustness check\n\t * only happens in the pagetable (to verify it's still none)\n\t * and not in the radix tree.\n\t */\n\tif (!(dst_vma->vm_flags & VM_SHARED)) {\n\t\tif (!zeropage)\n\t\t\terr = mcopy_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t\t       dst_addr, src_addr, page);\n\t\telse\n\t\t\terr = mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t dst_vma, dst_addr);\n\t} else {\n\t\tif (!zeropage)\n\t\t\terr = shmem_mcopy_atomic_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t     dst_vma, dst_addr,\n\t\t\t\t\t\t     src_addr, page);\n\t\telse\n\t\t\terr = shmem_mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t       dst_vma, dst_addr);\n\t}\n\n\treturn err;\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "shmem_mfill_zeropage_pte",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_vma",
            "dst_addr"
          ],
          "line": 406
        },
        "resolved": true,
        "details": {
          "function_name": "shmem_mfill_zeropage_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/shmem.c",
          "lines": "2318-2327",
          "snippet": "int shmem_mfill_zeropage_pte(struct mm_struct *dst_mm,\n\t\t\t     pmd_t *dst_pmd,\n\t\t\t     struct vm_area_struct *dst_vma,\n\t\t\t     unsigned long dst_addr)\n{\n\tstruct page *page = NULL;\n\n\treturn shmem_mfill_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t      dst_addr, 0, true, &page);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/uuid.h>",
            "#include <linux/rmap.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <uapi/linux/memfd.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/magic.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/highmem.h>",
            "#include <linux/migrate.h>",
            "#include <linux/ctype.h>",
            "#include <linux/namei.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/swapops.h>",
            "#include <linux/security.h>",
            "#include <linux/splice.h>",
            "#include <linux/falloc.h>",
            "#include <linux/percpu_counter.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/writeback.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/slab.h>",
            "#include <linux/string.h>",
            "#include <linux/mman.h>",
            "#include <linux/posix_acl_xattr.h>",
            "#include <linux/posix_acl.h>",
            "#include <linux/exportfs.h>",
            "#include <linux/xattr.h>",
            "#include <asm/tlbflush.h> /* for arch/microblaze update_mmu_cache() */",
            "#include <linux/hugetlb.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/uio.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/random.h>",
            "#include <linux/mm.h>",
            "#include <linux/file.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/ramfs.h>",
            "#include <linux/mount.h>",
            "#include <linux/vfs.h>",
            "#include <linux/init.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <linux/uaccess.h>\n#include <linux/uuid.h>\n#include <linux/rmap.h>\n#include <linux/userfaultfd_k.h>\n#include <uapi/linux/memfd.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/magic.h>\n#include <linux/seq_file.h>\n#include <linux/highmem.h>\n#include <linux/migrate.h>\n#include <linux/ctype.h>\n#include <linux/namei.h>\n#include <linux/mempolicy.h>\n#include <linux/swapops.h>\n#include <linux/security.h>\n#include <linux/splice.h>\n#include <linux/falloc.h>\n#include <linux/percpu_counter.h>\n#include <linux/pagevec.h>\n#include <linux/blkdev.h>\n#include <linux/writeback.h>\n#include <linux/shmem_fs.h>\n#include <linux/backing-dev.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/mman.h>\n#include <linux/posix_acl_xattr.h>\n#include <linux/posix_acl.h>\n#include <linux/exportfs.h>\n#include <linux/xattr.h>\n#include <asm/tlbflush.h> /* for arch/microblaze update_mmu_cache() */\n#include <linux/hugetlb.h>\n#include <linux/khugepaged.h>\n#include <linux/uio.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/sched/signal.h>\n#include <linux/random.h>\n#include <linux/mm.h>\n#include <linux/file.h>\n#include <linux/pagemap.h>\n#include <linux/ramfs.h>\n#include <linux/mount.h>\n#include <linux/vfs.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n\nint shmem_mfill_zeropage_pte(struct mm_struct *dst_mm,\n\t\t\t     pmd_t *dst_pmd,\n\t\t\t     struct vm_area_struct *dst_vma,\n\t\t\t     unsigned long dst_addr)\n{\n\tstruct page *page = NULL;\n\n\treturn shmem_mfill_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t      dst_addr, 0, true, &page);\n}"
        }
      },
      {
        "call_info": {
          "callee": "shmem_mcopy_atomic_pte",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_vma",
            "dst_addr",
            "src_addr",
            "page"
          ],
          "line": 402
        },
        "resolved": true,
        "details": {
          "function_name": "shmem_mcopy_atomic_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/shmem.c",
          "lines": "2307-2316",
          "snippet": "int shmem_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t   pmd_t *dst_pmd,\n\t\t\t   struct vm_area_struct *dst_vma,\n\t\t\t   unsigned long dst_addr,\n\t\t\t   unsigned long src_addr,\n\t\t\t   struct page **pagep)\n{\n\treturn shmem_mfill_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t      dst_addr, src_addr, false, pagep);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/uuid.h>",
            "#include <linux/rmap.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <uapi/linux/memfd.h>",
            "#include <linux/fcntl.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/magic.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/highmem.h>",
            "#include <linux/migrate.h>",
            "#include <linux/ctype.h>",
            "#include <linux/namei.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/swapops.h>",
            "#include <linux/security.h>",
            "#include <linux/splice.h>",
            "#include <linux/falloc.h>",
            "#include <linux/percpu_counter.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/writeback.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/slab.h>",
            "#include <linux/string.h>",
            "#include <linux/mman.h>",
            "#include <linux/posix_acl_xattr.h>",
            "#include <linux/posix_acl.h>",
            "#include <linux/exportfs.h>",
            "#include <linux/xattr.h>",
            "#include <asm/tlbflush.h> /* for arch/microblaze update_mmu_cache() */",
            "#include <linux/hugetlb.h>",
            "#include <linux/khugepaged.h>",
            "#include <linux/uio.h>",
            "#include <linux/swap.h>",
            "#include <linux/export.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/random.h>",
            "#include <linux/mm.h>",
            "#include <linux/file.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/ramfs.h>",
            "#include <linux/mount.h>",
            "#include <linux/vfs.h>",
            "#include <linux/init.h>",
            "#include <linux/fs.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <linux/uaccess.h>\n#include <linux/uuid.h>\n#include <linux/rmap.h>\n#include <linux/userfaultfd_k.h>\n#include <uapi/linux/memfd.h>\n#include <linux/fcntl.h>\n#include <linux/syscalls.h>\n#include <linux/magic.h>\n#include <linux/seq_file.h>\n#include <linux/highmem.h>\n#include <linux/migrate.h>\n#include <linux/ctype.h>\n#include <linux/namei.h>\n#include <linux/mempolicy.h>\n#include <linux/swapops.h>\n#include <linux/security.h>\n#include <linux/splice.h>\n#include <linux/falloc.h>\n#include <linux/percpu_counter.h>\n#include <linux/pagevec.h>\n#include <linux/blkdev.h>\n#include <linux/writeback.h>\n#include <linux/shmem_fs.h>\n#include <linux/backing-dev.h>\n#include <linux/slab.h>\n#include <linux/string.h>\n#include <linux/mman.h>\n#include <linux/posix_acl_xattr.h>\n#include <linux/posix_acl.h>\n#include <linux/exportfs.h>\n#include <linux/xattr.h>\n#include <asm/tlbflush.h> /* for arch/microblaze update_mmu_cache() */\n#include <linux/hugetlb.h>\n#include <linux/khugepaged.h>\n#include <linux/uio.h>\n#include <linux/swap.h>\n#include <linux/export.h>\n#include <linux/sched/signal.h>\n#include <linux/random.h>\n#include <linux/mm.h>\n#include <linux/file.h>\n#include <linux/pagemap.h>\n#include <linux/ramfs.h>\n#include <linux/mount.h>\n#include <linux/vfs.h>\n#include <linux/init.h>\n#include <linux/fs.h>\n\nint shmem_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t   pmd_t *dst_pmd,\n\t\t\t   struct vm_area_struct *dst_vma,\n\t\t\t   unsigned long dst_addr,\n\t\t\t   unsigned long src_addr,\n\t\t\t   struct page **pagep)\n{\n\treturn shmem_mfill_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t      dst_addr, src_addr, false, pagep);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mfill_zeropage_pte",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_vma",
            "dst_addr"
          ],
          "line": 398
        },
        "resolved": true,
        "details": {
          "function_name": "mfill_zeropage_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "103-125",
          "snippet": "static int mfill_zeropage_pte(struct mm_struct *dst_mm,\n\t\t\t      pmd_t *dst_pmd,\n\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t      unsigned long dst_addr)\n{\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\n\t_dst_pte = pte_mkspecial(pfn_pte(my_zero_pfn(dst_addr),\n\t\t\t\t\t dst_vma->vm_page_prot));\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_unlock;\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\tret = 0;\nout_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\treturn ret;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic int mfill_zeropage_pte(struct mm_struct *dst_mm,\n\t\t\t      pmd_t *dst_pmd,\n\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t      unsigned long dst_addr)\n{\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\n\t_dst_pte = pte_mkspecial(pfn_pte(my_zero_pfn(dst_addr),\n\t\t\t\t\t dst_vma->vm_page_prot));\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_unlock;\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\tret = 0;\nout_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mcopy_atomic_pte",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_vma",
            "dst_addr",
            "src_addr",
            "page"
          ],
          "line": 395
        },
        "resolved": true,
        "details": {
          "function_name": "mcopy_atomic_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
          "lines": "23-101",
          "snippet": "static int mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pmd_t *dst_pmd,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct mem_cgroup *memcg;\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tvoid *page_kaddr;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_page_vma(GFP_HIGHUSER_MOVABLE, dst_vma, dst_addr);\n\t\tif (!page)\n\t\t\tgoto out;\n\n\t\tpage_kaddr = kmap_atomic(page);\n\t\tret = copy_from_user(page_kaddr,\n\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t     PAGE_SIZE);\n\t\tkunmap_atomic(page_kaddr);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -ENOENT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceeding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\n\tret = -ENOMEM;\n\tif (mem_cgroup_try_charge(page, dst_mm, GFP_KERNEL, &memcg, false))\n\t\tgoto out_release;\n\n\t_dst_pte = mk_pte(page, dst_vma->vm_page_prot);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = pte_mkwrite(pte_mkdirty(_dst_pte));\n\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_release_uncharge_unlock;\n\n\tinc_mm_counter(dst_mm, MM_ANONPAGES);\n\tpage_add_new_anon_rmap(page, dst_vma, dst_addr, false);\n\tmem_cgroup_commit_charge(page, memcg, false, false);\n\tlru_cache_add_active_or_unevictable(page, dst_vma);\n\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tpte_unmap_unlock(dst_pte, ptl);\n\tret = 0;\nout:\n\treturn ret;\nout_release_uncharge_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\tmem_cgroup_cancel_charge(page, memcg, false);\nout_release:\n\tput_page(page);\n\tgoto out;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/rmap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic int mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pmd_t *dst_pmd,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct mem_cgroup *memcg;\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tvoid *page_kaddr;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_page_vma(GFP_HIGHUSER_MOVABLE, dst_vma, dst_addr);\n\t\tif (!page)\n\t\t\tgoto out;\n\n\t\tpage_kaddr = kmap_atomic(page);\n\t\tret = copy_from_user(page_kaddr,\n\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t     PAGE_SIZE);\n\t\tkunmap_atomic(page_kaddr);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -ENOENT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceeding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\n\tret = -ENOMEM;\n\tif (mem_cgroup_try_charge(page, dst_mm, GFP_KERNEL, &memcg, false))\n\t\tgoto out_release;\n\n\t_dst_pte = mk_pte(page, dst_vma->vm_page_prot);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = pte_mkwrite(pte_mkdirty(_dst_pte));\n\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_release_uncharge_unlock;\n\n\tinc_mm_counter(dst_mm, MM_ANONPAGES);\n\tpage_add_new_anon_rmap(page, dst_vma, dst_addr, false);\n\tmem_cgroup_commit_charge(page, memcg, false, false);\n\tlru_cache_add_active_or_unevictable(page, dst_vma);\n\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tpte_unmap_unlock(dst_pte, ptl);\n\tret = 0;\nout:\n\treturn ret;\nout_release_uncharge_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\tmem_cgroup_cancel_charge(page, memcg, false);\nout_release:\n\tput_page(page);\n\tgoto out;\n}"
        }
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t mfill_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t\t\t\tpmd_t *dst_pmd,\n\t\t\t\t\t\tstruct vm_area_struct *dst_vma,\n\t\t\t\t\t\tunsigned long dst_addr,\n\t\t\t\t\t\tunsigned long src_addr,\n\t\t\t\t\t\tstruct page **page,\n\t\t\t\t\t\tbool zeropage)\n{\n\tssize_t err;\n\n\t/*\n\t * The normal page fault path for a shmem will invoke the\n\t * fault, fill the hole in the file and COW it right away. The\n\t * result generates plain anonymous memory. So when we are\n\t * asked to fill an hole in a MAP_PRIVATE shmem mapping, we'll\n\t * generate anonymous memory directly without actually filling\n\t * the hole. For the MAP_PRIVATE case the robustness check\n\t * only happens in the pagetable (to verify it's still none)\n\t * and not in the radix tree.\n\t */\n\tif (!(dst_vma->vm_flags & VM_SHARED)) {\n\t\tif (!zeropage)\n\t\t\terr = mcopy_atomic_pte(dst_mm, dst_pmd, dst_vma,\n\t\t\t\t\t       dst_addr, src_addr, page);\n\t\telse\n\t\t\terr = mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t dst_vma, dst_addr);\n\t} else {\n\t\tif (!zeropage)\n\t\t\terr = shmem_mcopy_atomic_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t     dst_vma, dst_addr,\n\t\t\t\t\t\t     src_addr, page);\n\t\telse\n\t\t\terr = shmem_mfill_zeropage_pte(dst_mm, dst_pmd,\n\t\t\t\t\t\t       dst_vma, dst_addr);\n\t}\n\n\treturn err;\n}"
  },
  {
    "function_name": "__mcopy_atomic_hugetlb",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "153-362",
    "snippet": "static __always_inline ssize_t __mcopy_atomic_hugetlb(struct mm_struct *dst_mm,\n\t\t\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage)\n{\n\tint vm_alloc_shared = dst_vma->vm_flags & VM_SHARED;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tssize_t err;\n\tpte_t *dst_pte;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\tstruct hstate *h;\n\tunsigned long vma_hpagesize;\n\tpgoff_t idx;\n\tu32 hash;\n\tstruct address_space *mapping;\n\n\t/*\n\t * There is no default zero huge page for all huge page sizes as\n\t * supported by hugetlb.  A PMD_SIZE huge pages may exist as used\n\t * by THP.  Since we can not reliably insert a zero page, this\n\t * feature is not supported.\n\t */\n\tif (zeropage) {\n\t\tup_read(&dst_mm->mmap_sem);\n\t\treturn -EINVAL;\n\t}\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\n\tvma_hpagesize = vma_kernel_pagesize(dst_vma);\n\n\t/*\n\t * Validate alignment based on huge page size\n\t */\n\terr = -EINVAL;\n\tif (dst_start & (vma_hpagesize - 1) || len & (vma_hpagesize - 1))\n\t\tgoto out_unlock;\n\nretry:\n\t/*\n\t * On routine entry dst_vma is set.  If we had to drop mmap_sem and\n\t * retry, dst_vma will be set to NULL and we must lookup again.\n\t */\n\tif (!dst_vma) {\n\t\terr = -ENOENT;\n\t\tdst_vma = find_vma(dst_mm, dst_start);\n\t\tif (!dst_vma || !is_vm_hugetlb_page(dst_vma))\n\t\t\tgoto out_unlock;\n\t\t/*\n\t\t * Only allow __mcopy_atomic_hugetlb on userfaultfd\n\t\t * registered ranges.\n\t\t */\n\t\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\t\tgoto out_unlock;\n\n\t\tif (dst_start < dst_vma->vm_start ||\n\t\t    dst_start + len > dst_vma->vm_end)\n\t\t\tgoto out_unlock;\n\n\t\terr = -EINVAL;\n\t\tif (vma_hpagesize != vma_kernel_pagesize(dst_vma))\n\t\t\tgoto out_unlock;\n\n\t\tvm_shared = dst_vma->vm_flags & VM_SHARED;\n\t}\n\n\tif (WARN_ON(dst_addr & (vma_hpagesize - 1) ||\n\t\t    (len - copied) & (vma_hpagesize - 1)))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If not shared, ensure the dst_vma has a anon_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!vm_shared) {\n\t\tif (unlikely(anon_vma_prepare(dst_vma)))\n\t\t\tgoto out_unlock;\n\t}\n\n\th = hstate_vma(dst_vma);\n\n\twhile (src_addr < src_start + len) {\n\t\tpte_t dst_pteval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\t\tVM_BUG_ON(dst_addr & ~huge_page_mask(h));\n\n\t\t/*\n\t\t * Serialize via hugetlb_fault_mutex\n\t\t */\n\t\tidx = linear_page_index(dst_vma, dst_addr);\n\t\tmapping = dst_vma->vm_file->f_mapping;\n\t\thash = hugetlb_fault_mutex_hash(h, dst_mm, dst_vma, mapping,\n\t\t\t\t\t\t\t\tidx, dst_addr);\n\t\tmutex_lock(&hugetlb_fault_mutex_table[hash]);\n\n\t\terr = -ENOMEM;\n\t\tdst_pte = huge_pte_alloc(dst_mm, dst_addr, huge_page_size(h));\n\t\tif (!dst_pte) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = -EEXIST;\n\t\tdst_pteval = huge_ptep_get(dst_pte);\n\t\tif (!huge_pte_none(dst_pteval)) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = hugetlb_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma,\n\t\t\t\t\t\tdst_addr, src_addr, &page);\n\n\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\tvm_alloc_shared = vm_shared;\n\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\terr = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *)src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), true);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdown_read(&dst_mm->mmap_sem);\n\n\t\t\tdst_vma = NULL;\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += vma_hpagesize;\n\t\t\tsrc_addr += vma_hpagesize;\n\t\t\tcopied += vma_hpagesize;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page) {\n\t\t/*\n\t\t * We encountered an error and are about to free a newly\n\t\t * allocated huge page.\n\t\t *\n\t\t * Reservation handling is very subtle, and is different for\n\t\t * private and shared mappings.  See the routine\n\t\t * restore_reserve_on_error for details.  Unfortunately, we\n\t\t * can not call restore_reserve_on_error now as it would\n\t\t * require holding mmap_sem.\n\t\t *\n\t\t * If a reservation for the page existed in the reservation\n\t\t * map of a private mapping, the map was modified to indicate\n\t\t * the reservation was consumed when the page was allocated.\n\t\t * We clear the PagePrivate flag now so that the global\n\t\t * reserve count will not be incremented in free_huge_page.\n\t\t * The reservation map will still indicate the reservation\n\t\t * was consumed and possibly prevent later page allocation.\n\t\t * This is better than leaking a global reservation.  If no\n\t\t * reservation existed, it is still safe to clear PagePrivate\n\t\t * as no adjustments to reservation counts were made during\n\t\t * allocation.\n\t\t *\n\t\t * The reservation map for shared mappings indicates which\n\t\t * pages have reservations.  When a huge page is allocated\n\t\t * for an address with a reservation, no change is made to\n\t\t * the reserve map.  In this case PagePrivate will be set\n\t\t * to indicate that the global reservation count should be\n\t\t * incremented when the page is freed.  This is the desired\n\t\t * behavior.  However, when a huge page is allocated for an\n\t\t * address without a reservation a reservation entry is added\n\t\t * to the reservation map, and PagePrivate will not be set.\n\t\t * When the page is freed, the global reserve count will NOT\n\t\t * be incremented and it will appear as though we have leaked\n\t\t * reserved page.  In this case, set PagePrivate so that the\n\t\t * global reserve count will be incremented to match the\n\t\t * reservation map entry which was created.\n\t\t *\n\t\t * Note that vm_alloc_shared is based on the flags of the vma\n\t\t * for which the page was originally allocated.  dst_vma could\n\t\t * be different or NULL on error.\n\t\t */\n\t\tif (vm_alloc_shared)\n\t\t\tSetPagePrivate(page);\n\t\telse\n\t\t\tClearPagePrivate(page);\n\t\tput_page(page);\n\t}\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!copied && !err"
          ],
          "line": 360
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "err > 0"
          ],
          "line": 359
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "copied < 0"
          ],
          "line": 358
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "put_page",
          "args": [
            "page"
          ],
          "line": 356
        },
        "resolved": true,
        "details": {
          "function_name": "put_page_bootmem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory_hotplug.c",
          "lines": "143-158",
          "snippet": "void put_page_bootmem(struct page *page)\n{\n\tunsigned long type;\n\n\ttype = (unsigned long) page->freelist;\n\tBUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||\n\t       type > MEMORY_HOTPLUG_MAX_BOOTMEM_TYPE);\n\n\tif (page_ref_dec_return(page) == 1) {\n\t\tpage->freelist = NULL;\n\t\tClearPagePrivate(page);\n\t\tset_page_private(page, 0);\n\t\tINIT_LIST_HEAD(&page->lru);\n\t\tfree_reserved_page(page);\n\t}\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/compaction.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/firmware-map.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/suspend.h>",
            "#include <linux/pfn.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/migrate.h>",
            "#include <linux/delay.h>",
            "#include <linux/ioport.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/highmem.h>",
            "#include <linux/memory_hotplug.h>",
            "#include <linux/memremap.h>",
            "#include <linux/memory.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/slab.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/export.h>",
            "#include <linux/compiler.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/swap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/stddef.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void generic_online_page(struct page *page);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/compaction.h>\n#include <linux/memblock.h>\n#include <linux/hugetlb.h>\n#include <linux/stop_machine.h>\n#include <linux/firmware-map.h>\n#include <linux/mm_inline.h>\n#include <linux/suspend.h>\n#include <linux/pfn.h>\n#include <linux/page-isolation.h>\n#include <linux/migrate.h>\n#include <linux/delay.h>\n#include <linux/ioport.h>\n#include <linux/vmalloc.h>\n#include <linux/highmem.h>\n#include <linux/memory_hotplug.h>\n#include <linux/memremap.h>\n#include <linux/memory.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/slab.h>\n#include <linux/writeback.h>\n#include <linux/pagevec.h>\n#include <linux/export.h>\n#include <linux/compiler.h>\n#include <linux/pagemap.h>\n#include <linux/interrupt.h>\n#include <linux/swap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/stddef.h>\n\nstatic void generic_online_page(struct page *page);\n\nvoid put_page_bootmem(struct page *page)\n{\n\tunsigned long type;\n\n\ttype = (unsigned long) page->freelist;\n\tBUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||\n\t       type > MEMORY_HOTPLUG_MAX_BOOTMEM_TYPE);\n\n\tif (page_ref_dec_return(page) == 1) {\n\t\tpage->freelist = NULL;\n\t\tClearPagePrivate(page);\n\t\tset_page_private(page, 0);\n\t\tINIT_LIST_HEAD(&page->lru);\n\t\tfree_reserved_page(page);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "ClearPagePrivate",
          "args": [
            "page"
          ],
          "line": 355
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "SetPagePrivate",
          "args": [
            "page"
          ],
          "line": 353
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 308
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "fatal_signal_pending",
          "args": [
            "current"
          ],
          "line": 300
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "page"
          ],
          "line": 293
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "down_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 288
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err"
          ],
          "line": 284
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_huge_page_from_user",
          "args": [
            "page",
            "(const void __user *)src_addr",
            "pages_per_huge_page(h)",
            "true"
          ],
          "line": 281
        },
        "resolved": true,
        "details": {
          "function_name": "copy_huge_page_from_user",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory.c",
          "lines": "4508-4538",
          "snippet": "long copy_huge_page_from_user(struct page *dst_page,\n\t\t\t\tconst void __user *usr_src,\n\t\t\t\tunsigned int pages_per_huge_page,\n\t\t\t\tbool allow_pagefault)\n{\n\tvoid *src = (void *)usr_src;\n\tvoid *page_kaddr;\n\tunsigned long i, rc = 0;\n\tunsigned long ret_val = pages_per_huge_page * PAGE_SIZE;\n\n\tfor (i = 0; i < pages_per_huge_page; i++) {\n\t\tif (allow_pagefault)\n\t\t\tpage_kaddr = kmap(dst_page + i);\n\t\telse\n\t\t\tpage_kaddr = kmap_atomic(dst_page + i);\n\t\trc = copy_from_user(page_kaddr,\n\t\t\t\t(const void __user *)(src + i * PAGE_SIZE),\n\t\t\t\tPAGE_SIZE);\n\t\tif (allow_pagefault)\n\t\t\tkunmap(dst_page + i);\n\t\telse\n\t\t\tkunmap_atomic(page_kaddr);\n\n\t\tret_val -= (PAGE_SIZE - rc);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tcond_resched();\n\t}\n\treturn ret_val;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/mmu_context.h>",
            "#include <asm/io.h>",
            "#include <linux/oom.h>",
            "#include <linux/dax.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-debug.h>",
            "#include <linux/string.h>",
            "#include <linux/migrate.h>",
            "#include <linux/gfp.h>",
            "#include <linux/elf.h>",
            "#include <linux/swapops.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pfn_t.h>",
            "#include <linux/init.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/export.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/memremap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/mmu_context.h>\n#include <asm/io.h>\n#include <linux/oom.h>\n#include <linux/dax.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/debugfs.h>\n#include <linux/dma-debug.h>\n#include <linux/string.h>\n#include <linux/migrate.h>\n#include <linux/gfp.h>\n#include <linux/elf.h>\n#include <linux/swapops.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/writeback.h>\n#include <linux/pfn_t.h>\n#include <linux/init.h>\n#include <linux/delayacct.h>\n#include <linux/export.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/memremap.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/hugetlb.h>\n#include <linux/sched/task.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/kernel_stat.h>\n\nlong copy_huge_page_from_user(struct page *dst_page,\n\t\t\t\tconst void __user *usr_src,\n\t\t\t\tunsigned int pages_per_huge_page,\n\t\t\t\tbool allow_pagefault)\n{\n\tvoid *src = (void *)usr_src;\n\tvoid *page_kaddr;\n\tunsigned long i, rc = 0;\n\tunsigned long ret_val = pages_per_huge_page * PAGE_SIZE;\n\n\tfor (i = 0; i < pages_per_huge_page; i++) {\n\t\tif (allow_pagefault)\n\t\t\tpage_kaddr = kmap(dst_page + i);\n\t\telse\n\t\t\tpage_kaddr = kmap_atomic(dst_page + i);\n\t\trc = copy_from_user(page_kaddr,\n\t\t\t\t(const void __user *)(src + i * PAGE_SIZE),\n\t\t\t\tPAGE_SIZE);\n\t\tif (allow_pagefault)\n\t\t\tkunmap(dst_page + i);\n\t\telse\n\t\t\tkunmap_atomic(page_kaddr);\n\n\t\tret_val -= (PAGE_SIZE - rc);\n\t\tif (rc)\n\t\t\tbreak;\n\n\t\tcond_resched();\n\t}\n\treturn ret_val;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pages_per_huge_page",
          "args": [
            "h"
          ],
          "line": 283
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "!page"
          ],
          "line": 279
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 278
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "err == -ENOENT"
          ],
          "line": 277
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "cond_resched",
          "args": [],
          "line": 275
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&hugetlb_fault_mutex_table[hash]"
          ],
          "line": 272
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hugetlb_mcopy_atomic_pte",
          "args": [
            "dst_mm",
            "dst_pte",
            "dst_vma",
            "dst_addr",
            "src_addr",
            "&page"
          ],
          "line": 269
        },
        "resolved": true,
        "details": {
          "function_name": "hugetlb_mcopy_atomic_pte",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/hugetlb.c",
          "lines": "4054-4179",
          "snippet": "int hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -ENOENT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/page_owner.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/node.h>",
            "#include <linux/hugetlb_cgroup.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/io.h>",
            "#include <asm/tlb.h>",
            "#include <asm/pgtable.h>",
            "#include <asm/page.h>",
            "#include <linux/jhash.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/string_helpers.h>",
            "#include <linux/rmap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mmdebug.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/compiler.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/highmem.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "struct mutex *hugetlb_fault_mutex_table"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/page_owner.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/node.h>\n#include <linux/hugetlb_cgroup.h>\n#include <linux/hugetlb.h>\n#include <linux/io.h>\n#include <asm/tlb.h>\n#include <asm/pgtable.h>\n#include <asm/page.h>\n#include <linux/jhash.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/string_helpers.h>\n#include <linux/rmap.h>\n#include <linux/sched/signal.h>\n#include <linux/mmdebug.h>\n#include <linux/slab.h>\n#include <linux/sysfs.h>\n#include <linux/memblock.h>\n#include <linux/mutex.h>\n#include <linux/cpuset.h>\n#include <linux/compiler.h>\n#include <linux/mempolicy.h>\n#include <linux/pagemap.h>\n#include <linux/nodemask.h>\n#include <linux/mmu_notifier.h>\n#include <linux/highmem.h>\n#include <linux/sysctl.h>\n#include <linux/seq_file.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/list.h>\n\nstruct mutex *hugetlb_fault_mutex_table;\n\nint hugetlb_mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pte_t *dst_pte,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct address_space *mapping;\n\tpgoff_t idx;\n\tunsigned long size;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tstruct hstate *h = hstate_vma(dst_vma);\n\tpte_t _dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_huge_page(dst_vma, dst_addr, 0);\n\t\tif (IS_ERR(page))\n\t\t\tgoto out;\n\n\t\tret = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *) src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), false);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -ENOENT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\tset_page_huge_active(page);\n\n\tmapping = dst_vma->vm_file->f_mapping;\n\tidx = vma_hugecache_offset(h, dst_vma, dst_addr);\n\n\t/*\n\t * If shared, add to page cache\n\t */\n\tif (vm_shared) {\n\t\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\t\tret = -EFAULT;\n\t\tif (idx >= size)\n\t\t\tgoto out_release_nounlock;\n\n\t\t/*\n\t\t * Serialization between remove_inode_hugepages() and\n\t\t * huge_add_to_page_cache() below happens through the\n\t\t * hugetlb_fault_mutex_table that here must be hold by\n\t\t * the caller.\n\t\t */\n\t\tret = huge_add_to_page_cache(page, mapping, idx);\n\t\tif (ret)\n\t\t\tgoto out_release_nounlock;\n\t}\n\n\tptl = huge_pte_lockptr(h, dst_mm, dst_pte);\n\tspin_lock(ptl);\n\n\t/*\n\t * Recheck the i_size after holding PT lock to make sure not\n\t * to leave any page mapped (as page_mapped()) beyond the end\n\t * of the i_size (remove_inode_hugepages() is strict about\n\t * enforcing that). If we bail out here, we'll also leave a\n\t * page in the radix tree in the vm_shared case beyond the end\n\t * of the i_size, but remove_inode_hugepages() will take care\n\t * of it as soon as we drop the hugetlb_fault_mutex_table.\n\t */\n\tsize = i_size_read(mapping->host) >> huge_page_shift(h);\n\tret = -EFAULT;\n\tif (idx >= size)\n\t\tgoto out_release_unlock;\n\n\tret = -EEXIST;\n\tif (!huge_pte_none(huge_ptep_get(dst_pte)))\n\t\tgoto out_release_unlock;\n\n\tif (vm_shared) {\n\t\tpage_dup_rmap(page, true);\n\t} else {\n\t\tClearPagePrivate(page);\n\t\thugepage_add_new_anon_rmap(page, dst_vma, dst_addr);\n\t}\n\n\t_dst_pte = make_huge_pte(dst_vma, page, dst_vma->vm_flags & VM_WRITE);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = huge_pte_mkdirty(_dst_pte);\n\t_dst_pte = pte_mkyoung(_dst_pte);\n\n\tset_huge_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t(void)huge_ptep_set_access_flags(dst_vma, dst_addr, dst_pte, _dst_pte,\n\t\t\t\t\tdst_vma->vm_flags & VM_WRITE);\n\thugetlb_count_add(pages_per_huge_page(h), dst_mm);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\n\tret = 0;\nout:\n\treturn ret;\nout_release_unlock:\n\tspin_unlock(ptl);\n\tif (vm_shared)\n\t\tunlock_page(page);\nout_release_nounlock:\n\tput_page(page);\n\tgoto out;\n}"
        }
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&hugetlb_fault_mutex_table[hash]"
          ],
          "line": 265
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "huge_pte_none",
          "args": [
            "dst_pteval"
          ],
          "line": 264
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "huge_ptep_get",
          "args": [
            "dst_pte"
          ],
          "line": 263
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_unlock",
          "args": [
            "&hugetlb_fault_mutex_table[hash]"
          ],
          "line": 258
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "huge_pte_alloc",
          "args": [
            "dst_mm",
            "dst_addr",
            "huge_page_size(h)"
          ],
          "line": 256
        },
        "resolved": true,
        "details": {
          "function_name": "huge_pte_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/hugetlb.c",
          "lines": "4744-4771",
          "snippet": "pte_t *huge_pte_alloc(struct mm_struct *mm,\n\t\t\tunsigned long addr, unsigned long sz)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\tpte_t *pte = NULL;\n\n\tpgd = pgd_offset(mm, addr);\n\tp4d = p4d_alloc(mm, pgd, addr);\n\tif (!p4d)\n\t\treturn NULL;\n\tpud = pud_alloc(mm, p4d, addr);\n\tif (pud) {\n\t\tif (sz == PUD_SIZE) {\n\t\t\tpte = (pte_t *)pud;\n\t\t} else {\n\t\t\tBUG_ON(sz != PMD_SIZE);\n\t\t\tif (want_pmd_share() && pud_none(*pud))\n\t\t\t\tpte = huge_pmd_share(mm, addr, pud);\n\t\t\telse\n\t\t\t\tpte = (pte_t *)pmd_alloc(mm, pud, addr);\n\t\t}\n\t}\n\tBUG_ON(pte && pte_present(*pte) && !pte_huge(*pte));\n\n\treturn pte;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/page_owner.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/node.h>",
            "#include <linux/hugetlb_cgroup.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/io.h>",
            "#include <asm/tlb.h>",
            "#include <asm/pgtable.h>",
            "#include <asm/page.h>",
            "#include <linux/jhash.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/string_helpers.h>",
            "#include <linux/rmap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mmdebug.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/compiler.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/highmem.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/page_owner.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/node.h>\n#include <linux/hugetlb_cgroup.h>\n#include <linux/hugetlb.h>\n#include <linux/io.h>\n#include <asm/tlb.h>\n#include <asm/pgtable.h>\n#include <asm/page.h>\n#include <linux/jhash.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/string_helpers.h>\n#include <linux/rmap.h>\n#include <linux/sched/signal.h>\n#include <linux/mmdebug.h>\n#include <linux/slab.h>\n#include <linux/sysfs.h>\n#include <linux/memblock.h>\n#include <linux/mutex.h>\n#include <linux/cpuset.h>\n#include <linux/compiler.h>\n#include <linux/mempolicy.h>\n#include <linux/pagemap.h>\n#include <linux/nodemask.h>\n#include <linux/mmu_notifier.h>\n#include <linux/highmem.h>\n#include <linux/sysctl.h>\n#include <linux/seq_file.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/list.h>\n\npte_t *huge_pte_alloc(struct mm_struct *mm,\n\t\t\tunsigned long addr, unsigned long sz)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\tpte_t *pte = NULL;\n\n\tpgd = pgd_offset(mm, addr);\n\tp4d = p4d_alloc(mm, pgd, addr);\n\tif (!p4d)\n\t\treturn NULL;\n\tpud = pud_alloc(mm, p4d, addr);\n\tif (pud) {\n\t\tif (sz == PUD_SIZE) {\n\t\t\tpte = (pte_t *)pud;\n\t\t} else {\n\t\t\tBUG_ON(sz != PMD_SIZE);\n\t\t\tif (want_pmd_share() && pud_none(*pud))\n\t\t\t\tpte = huge_pmd_share(mm, addr, pud);\n\t\t\telse\n\t\t\t\tpte = (pte_t *)pmd_alloc(mm, pud, addr);\n\t\t}\n\t}\n\tBUG_ON(pte && pte_present(*pte) && !pte_huge(*pte));\n\n\treturn pte;\n}"
        }
      },
      {
        "call_info": {
          "callee": "huge_page_size",
          "args": [
            "h"
          ],
          "line": 256
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mutex_lock",
          "args": [
            "&hugetlb_fault_mutex_table[hash]"
          ],
          "line": 253
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hugetlb_fault_mutex_hash",
          "args": [
            "h",
            "dst_mm",
            "dst_vma",
            "mapping",
            "idx",
            "dst_addr"
          ],
          "line": 251
        },
        "resolved": true,
        "details": {
          "function_name": "hugetlb_fault_mutex_hash",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/hugetlb.c",
          "lines": "3904-3910",
          "snippet": "u32 hugetlb_fault_mutex_hash(struct hstate *h, struct mm_struct *mm,\n\t\t\t    struct vm_area_struct *vma,\n\t\t\t    struct address_space *mapping,\n\t\t\t    pgoff_t idx, unsigned long address)\n{\n\treturn 0;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/page_owner.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/node.h>",
            "#include <linux/hugetlb_cgroup.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/io.h>",
            "#include <asm/tlb.h>",
            "#include <asm/pgtable.h>",
            "#include <asm/page.h>",
            "#include <linux/jhash.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/string_helpers.h>",
            "#include <linux/rmap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mmdebug.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/compiler.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/highmem.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/page_owner.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/node.h>\n#include <linux/hugetlb_cgroup.h>\n#include <linux/hugetlb.h>\n#include <linux/io.h>\n#include <asm/tlb.h>\n#include <asm/pgtable.h>\n#include <asm/page.h>\n#include <linux/jhash.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/string_helpers.h>\n#include <linux/rmap.h>\n#include <linux/sched/signal.h>\n#include <linux/mmdebug.h>\n#include <linux/slab.h>\n#include <linux/sysfs.h>\n#include <linux/memblock.h>\n#include <linux/mutex.h>\n#include <linux/cpuset.h>\n#include <linux/compiler.h>\n#include <linux/mempolicy.h>\n#include <linux/pagemap.h>\n#include <linux/nodemask.h>\n#include <linux/mmu_notifier.h>\n#include <linux/highmem.h>\n#include <linux/sysctl.h>\n#include <linux/seq_file.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/list.h>\n\nu32 hugetlb_fault_mutex_hash(struct hstate *h, struct mm_struct *mm,\n\t\t\t    struct vm_area_struct *vma,\n\t\t\t    struct address_space *mapping,\n\t\t\t    pgoff_t idx, unsigned long address)\n{\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "linear_page_index",
          "args": [
            "dst_vma",
            "dst_addr"
          ],
          "line": 249
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "VM_BUG_ON",
          "args": [
            "dst_addr & ~huge_page_mask(h)"
          ],
          "line": 244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "huge_page_mask",
          "args": [
            "h"
          ],
          "line": 244
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "BUG_ON",
          "args": [
            "dst_addr >= dst_start + len"
          ],
          "line": 243
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "hstate_vma",
          "args": [
            "dst_vma"
          ],
          "line": 238
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "anon_vma_prepare(dst_vma)"
          ],
          "line": 234
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "anon_vma_prepare",
          "args": [
            "dst_vma"
          ],
          "line": 234
        },
        "resolved": true,
        "details": {
          "function_name": "__anon_vma_prepare",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/rmap.c",
          "lines": "175-221",
          "snippet": "int __anon_vma_prepare(struct vm_area_struct *vma)\n{\n\tstruct mm_struct *mm = vma->vm_mm;\n\tstruct anon_vma *anon_vma, *allocated;\n\tstruct anon_vma_chain *avc;\n\n\tmight_sleep();\n\n\tavc = anon_vma_chain_alloc(GFP_KERNEL);\n\tif (!avc)\n\t\tgoto out_enomem;\n\n\tanon_vma = find_mergeable_anon_vma(vma);\n\tallocated = NULL;\n\tif (!anon_vma) {\n\t\tanon_vma = anon_vma_alloc();\n\t\tif (unlikely(!anon_vma))\n\t\t\tgoto out_enomem_free_avc;\n\t\tallocated = anon_vma;\n\t}\n\n\tanon_vma_lock_write(anon_vma);\n\t/* page_table_lock to protect against threads */\n\tspin_lock(&mm->page_table_lock);\n\tif (likely(!vma->anon_vma)) {\n\t\tvma->anon_vma = anon_vma;\n\t\tanon_vma_chain_link(vma, avc, anon_vma);\n\t\t/* vma reference or self-parent link for new root */\n\t\tanon_vma->degree++;\n\t\tallocated = NULL;\n\t\tavc = NULL;\n\t}\n\tspin_unlock(&mm->page_table_lock);\n\tanon_vma_unlock_write(anon_vma);\n\n\tif (unlikely(allocated))\n\t\tput_anon_vma(allocated);\n\tif (unlikely(avc))\n\t\tanon_vma_chain_free(avc);\n\n\treturn 0;\n\n out_enomem_free_avc:\n\tanon_vma_chain_free(avc);\n out_enomem:\n\treturn -ENOMEM;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <trace/events/tlb.h>",
            "#include <asm/tlbflush.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/memremap.h>",
            "#include <linux/page_idle.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/migrate.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <trace/events/tlb.h>\n#include <asm/tlbflush.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/memremap.h>\n#include <linux/page_idle.h>\n#include <linux/backing-dev.h>\n#include <linux/hugetlb.h>\n#include <linux/migrate.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n\nint __anon_vma_prepare(struct vm_area_struct *vma)\n{\n\tstruct mm_struct *mm = vma->vm_mm;\n\tstruct anon_vma *anon_vma, *allocated;\n\tstruct anon_vma_chain *avc;\n\n\tmight_sleep();\n\n\tavc = anon_vma_chain_alloc(GFP_KERNEL);\n\tif (!avc)\n\t\tgoto out_enomem;\n\n\tanon_vma = find_mergeable_anon_vma(vma);\n\tallocated = NULL;\n\tif (!anon_vma) {\n\t\tanon_vma = anon_vma_alloc();\n\t\tif (unlikely(!anon_vma))\n\t\t\tgoto out_enomem_free_avc;\n\t\tallocated = anon_vma;\n\t}\n\n\tanon_vma_lock_write(anon_vma);\n\t/* page_table_lock to protect against threads */\n\tspin_lock(&mm->page_table_lock);\n\tif (likely(!vma->anon_vma)) {\n\t\tvma->anon_vma = anon_vma;\n\t\tanon_vma_chain_link(vma, avc, anon_vma);\n\t\t/* vma reference or self-parent link for new root */\n\t\tanon_vma->degree++;\n\t\tallocated = NULL;\n\t\tavc = NULL;\n\t}\n\tspin_unlock(&mm->page_table_lock);\n\tanon_vma_unlock_write(anon_vma);\n\n\tif (unlikely(allocated))\n\t\tput_anon_vma(allocated);\n\tif (unlikely(avc))\n\t\tanon_vma_chain_free(avc);\n\n\treturn 0;\n\n out_enomem_free_avc:\n\tanon_vma_chain_free(avc);\n out_enomem:\n\treturn -ENOMEM;\n}"
        }
      },
      {
        "call_info": {
          "callee": "WARN_ON",
          "args": [
            "dst_addr & (vma_hpagesize - 1) ||\n\t\t    (len - copied) & (vma_hpagesize - 1)"
          ],
          "line": 225
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "vma_kernel_pagesize",
          "args": [
            "dst_vma"
          ],
          "line": 219
        },
        "resolved": true,
        "details": {
          "function_name": "vma_kernel_pagesize",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/hugetlb.c",
          "lines": "638-643",
          "snippet": "unsigned long vma_kernel_pagesize(struct vm_area_struct *vma)\n{\n\tif (vma->vm_ops && vma->vm_ops->pagesize)\n\t\treturn vma->vm_ops->pagesize(vma);\n\treturn PAGE_SIZE;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <linux/page_owner.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/node.h>",
            "#include <linux/hugetlb_cgroup.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/io.h>",
            "#include <asm/tlb.h>",
            "#include <asm/pgtable.h>",
            "#include <asm/page.h>",
            "#include <linux/jhash.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/string_helpers.h>",
            "#include <linux/rmap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mmdebug.h>",
            "#include <linux/slab.h>",
            "#include <linux/sysfs.h>",
            "#include <linux/memblock.h>",
            "#include <linux/mutex.h>",
            "#include <linux/cpuset.h>",
            "#include <linux/compiler.h>",
            "#include <linux/mempolicy.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/nodemask.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/highmem.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/mm.h>",
            "#include <linux/init.h>",
            "#include <linux/list.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <linux/page_owner.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/node.h>\n#include <linux/hugetlb_cgroup.h>\n#include <linux/hugetlb.h>\n#include <linux/io.h>\n#include <asm/tlb.h>\n#include <asm/pgtable.h>\n#include <asm/page.h>\n#include <linux/jhash.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/string_helpers.h>\n#include <linux/rmap.h>\n#include <linux/sched/signal.h>\n#include <linux/mmdebug.h>\n#include <linux/slab.h>\n#include <linux/sysfs.h>\n#include <linux/memblock.h>\n#include <linux/mutex.h>\n#include <linux/cpuset.h>\n#include <linux/compiler.h>\n#include <linux/mempolicy.h>\n#include <linux/pagemap.h>\n#include <linux/nodemask.h>\n#include <linux/mmu_notifier.h>\n#include <linux/highmem.h>\n#include <linux/sysctl.h>\n#include <linux/seq_file.h>\n#include <linux/mm.h>\n#include <linux/init.h>\n#include <linux/list.h>\n\nunsigned long vma_kernel_pagesize(struct vm_area_struct *vma)\n{\n\tif (vma->vm_ops && vma->vm_ops->pagesize)\n\t\treturn vma->vm_ops->pagesize(vma);\n\treturn PAGE_SIZE;\n}"
        }
      },
      {
        "call_info": {
          "callee": "is_vm_hugetlb_page",
          "args": [
            "dst_vma"
          ],
          "line": 205
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "find_vma",
          "args": [
            "dst_mm",
            "dst_start"
          ],
          "line": 204
        },
        "resolved": true,
        "details": {
          "function_name": "find_vma",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/nommu.c",
          "lines": "775-796",
          "snippet": "struct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)\n{\n\tstruct vm_area_struct *vma;\n\n\t/* check the cache first */\n\tvma = vmacache_find(mm, addr);\n\tif (likely(vma))\n\t\treturn vma;\n\n\t/* trawl the list (there may be multiple mappings in which addr\n\t * resides) */\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->vm_start > addr)\n\t\t\treturn NULL;\n\t\tif (vma->vm_end > addr) {\n\t\t\tvmacache_update(addr, vma);\n\t\t\treturn vma;\n\t\t}\n\t}\n\n\treturn NULL;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/mmu_context.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <linux/printk.h>",
            "#include <linux/audit.h>",
            "#include <linux/syscalls.h>",
            "#include <linux/security.h>",
            "#include <linux/personality.h>",
            "#include <linux/mount.h>",
            "#include <linux/compiler.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/blkdev.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/slab.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/file.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/vmacache.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/export.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/mmu_context.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <linux/printk.h>\n#include <linux/audit.h>\n#include <linux/syscalls.h>\n#include <linux/security.h>\n#include <linux/personality.h>\n#include <linux/mount.h>\n#include <linux/compiler.h>\n#include <linux/backing-dev.h>\n#include <linux/blkdev.h>\n#include <linux/vmalloc.h>\n#include <linux/slab.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/file.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/vmacache.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/export.h>\n\nstruct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)\n{\n\tstruct vm_area_struct *vma;\n\n\t/* check the cache first */\n\tvma = vmacache_find(mm, addr);\n\tif (likely(vma))\n\t\treturn vma;\n\n\t/* trawl the list (there may be multiple mappings in which addr\n\t * resides) */\n\tfor (vma = mm->mmap; vma; vma = vma->vm_next) {\n\t\tif (vma->vm_start > addr)\n\t\t\treturn NULL;\n\t\tif (vma->vm_end > addr) {\n\t\t\tvmacache_update(addr, vma);\n\t\t\treturn vma;\n\t\t}\n\t}\n\n\treturn NULL;\n}"
        }
      },
      {
        "call_info": {
          "callee": "up_read",
          "args": [
            "&dst_mm->mmap_sem"
          ],
          "line": 180
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic __always_inline ssize_t __mcopy_atomic_hugetlb(struct mm_struct *dst_mm,\n\t\t\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t\t\t      unsigned long dst_start,\n\t\t\t\t\t      unsigned long src_start,\n\t\t\t\t\t      unsigned long len,\n\t\t\t\t\t      bool zeropage)\n{\n\tint vm_alloc_shared = dst_vma->vm_flags & VM_SHARED;\n\tint vm_shared = dst_vma->vm_flags & VM_SHARED;\n\tssize_t err;\n\tpte_t *dst_pte;\n\tunsigned long src_addr, dst_addr;\n\tlong copied;\n\tstruct page *page;\n\tstruct hstate *h;\n\tunsigned long vma_hpagesize;\n\tpgoff_t idx;\n\tu32 hash;\n\tstruct address_space *mapping;\n\n\t/*\n\t * There is no default zero huge page for all huge page sizes as\n\t * supported by hugetlb.  A PMD_SIZE huge pages may exist as used\n\t * by THP.  Since we can not reliably insert a zero page, this\n\t * feature is not supported.\n\t */\n\tif (zeropage) {\n\t\tup_read(&dst_mm->mmap_sem);\n\t\treturn -EINVAL;\n\t}\n\n\tsrc_addr = src_start;\n\tdst_addr = dst_start;\n\tcopied = 0;\n\tpage = NULL;\n\tvma_hpagesize = vma_kernel_pagesize(dst_vma);\n\n\t/*\n\t * Validate alignment based on huge page size\n\t */\n\terr = -EINVAL;\n\tif (dst_start & (vma_hpagesize - 1) || len & (vma_hpagesize - 1))\n\t\tgoto out_unlock;\n\nretry:\n\t/*\n\t * On routine entry dst_vma is set.  If we had to drop mmap_sem and\n\t * retry, dst_vma will be set to NULL and we must lookup again.\n\t */\n\tif (!dst_vma) {\n\t\terr = -ENOENT;\n\t\tdst_vma = find_vma(dst_mm, dst_start);\n\t\tif (!dst_vma || !is_vm_hugetlb_page(dst_vma))\n\t\t\tgoto out_unlock;\n\t\t/*\n\t\t * Only allow __mcopy_atomic_hugetlb on userfaultfd\n\t\t * registered ranges.\n\t\t */\n\t\tif (!dst_vma->vm_userfaultfd_ctx.ctx)\n\t\t\tgoto out_unlock;\n\n\t\tif (dst_start < dst_vma->vm_start ||\n\t\t    dst_start + len > dst_vma->vm_end)\n\t\t\tgoto out_unlock;\n\n\t\terr = -EINVAL;\n\t\tif (vma_hpagesize != vma_kernel_pagesize(dst_vma))\n\t\t\tgoto out_unlock;\n\n\t\tvm_shared = dst_vma->vm_flags & VM_SHARED;\n\t}\n\n\tif (WARN_ON(dst_addr & (vma_hpagesize - 1) ||\n\t\t    (len - copied) & (vma_hpagesize - 1)))\n\t\tgoto out_unlock;\n\n\t/*\n\t * If not shared, ensure the dst_vma has a anon_vma.\n\t */\n\terr = -ENOMEM;\n\tif (!vm_shared) {\n\t\tif (unlikely(anon_vma_prepare(dst_vma)))\n\t\t\tgoto out_unlock;\n\t}\n\n\th = hstate_vma(dst_vma);\n\n\twhile (src_addr < src_start + len) {\n\t\tpte_t dst_pteval;\n\n\t\tBUG_ON(dst_addr >= dst_start + len);\n\t\tVM_BUG_ON(dst_addr & ~huge_page_mask(h));\n\n\t\t/*\n\t\t * Serialize via hugetlb_fault_mutex\n\t\t */\n\t\tidx = linear_page_index(dst_vma, dst_addr);\n\t\tmapping = dst_vma->vm_file->f_mapping;\n\t\thash = hugetlb_fault_mutex_hash(h, dst_mm, dst_vma, mapping,\n\t\t\t\t\t\t\t\tidx, dst_addr);\n\t\tmutex_lock(&hugetlb_fault_mutex_table[hash]);\n\n\t\terr = -ENOMEM;\n\t\tdst_pte = huge_pte_alloc(dst_mm, dst_addr, huge_page_size(h));\n\t\tif (!dst_pte) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = -EEXIST;\n\t\tdst_pteval = huge_ptep_get(dst_pte);\n\t\tif (!huge_pte_none(dst_pteval)) {\n\t\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\terr = hugetlb_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma,\n\t\t\t\t\t\tdst_addr, src_addr, &page);\n\n\t\tmutex_unlock(&hugetlb_fault_mutex_table[hash]);\n\t\tvm_alloc_shared = vm_shared;\n\n\t\tcond_resched();\n\n\t\tif (unlikely(err == -ENOENT)) {\n\t\t\tup_read(&dst_mm->mmap_sem);\n\t\t\tBUG_ON(!page);\n\n\t\t\terr = copy_huge_page_from_user(page,\n\t\t\t\t\t\t(const void __user *)src_addr,\n\t\t\t\t\t\tpages_per_huge_page(h), true);\n\t\t\tif (unlikely(err)) {\n\t\t\t\terr = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdown_read(&dst_mm->mmap_sem);\n\n\t\t\tdst_vma = NULL;\n\t\t\tgoto retry;\n\t\t} else\n\t\t\tBUG_ON(page);\n\n\t\tif (!err) {\n\t\t\tdst_addr += vma_hpagesize;\n\t\t\tsrc_addr += vma_hpagesize;\n\t\t\tcopied += vma_hpagesize;\n\n\t\t\tif (fatal_signal_pending(current))\n\t\t\t\terr = -EINTR;\n\t\t}\n\t\tif (err)\n\t\t\tbreak;\n\t}\n\nout_unlock:\n\tup_read(&dst_mm->mmap_sem);\nout:\n\tif (page) {\n\t\t/*\n\t\t * We encountered an error and are about to free a newly\n\t\t * allocated huge page.\n\t\t *\n\t\t * Reservation handling is very subtle, and is different for\n\t\t * private and shared mappings.  See the routine\n\t\t * restore_reserve_on_error for details.  Unfortunately, we\n\t\t * can not call restore_reserve_on_error now as it would\n\t\t * require holding mmap_sem.\n\t\t *\n\t\t * If a reservation for the page existed in the reservation\n\t\t * map of a private mapping, the map was modified to indicate\n\t\t * the reservation was consumed when the page was allocated.\n\t\t * We clear the PagePrivate flag now so that the global\n\t\t * reserve count will not be incremented in free_huge_page.\n\t\t * The reservation map will still indicate the reservation\n\t\t * was consumed and possibly prevent later page allocation.\n\t\t * This is better than leaking a global reservation.  If no\n\t\t * reservation existed, it is still safe to clear PagePrivate\n\t\t * as no adjustments to reservation counts were made during\n\t\t * allocation.\n\t\t *\n\t\t * The reservation map for shared mappings indicates which\n\t\t * pages have reservations.  When a huge page is allocated\n\t\t * for an address with a reservation, no change is made to\n\t\t * the reserve map.  In this case PagePrivate will be set\n\t\t * to indicate that the global reservation count should be\n\t\t * incremented when the page is freed.  This is the desired\n\t\t * behavior.  However, when a huge page is allocated for an\n\t\t * address without a reservation a reservation entry is added\n\t\t * to the reservation map, and PagePrivate will not be set.\n\t\t * When the page is freed, the global reserve count will NOT\n\t\t * be incremented and it will appear as though we have leaked\n\t\t * reserved page.  In this case, set PagePrivate so that the\n\t\t * global reserve count will be incremented to match the\n\t\t * reservation map entry which was created.\n\t\t *\n\t\t * Note that vm_alloc_shared is based on the flags of the vma\n\t\t * for which the page was originally allocated.  dst_vma could\n\t\t * be different or NULL on error.\n\t\t */\n\t\tif (vm_alloc_shared)\n\t\t\tSetPagePrivate(page);\n\t\telse\n\t\t\tClearPagePrivate(page);\n\t\tput_page(page);\n\t}\n\tBUG_ON(copied < 0);\n\tBUG_ON(err > 0);\n\tBUG_ON(!copied && !err);\n\treturn copied ? copied : err;\n}"
  },
  {
    "function_name": "mm_alloc_pmd",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "127-146",
    "snippet": "static pmd_t *mm_alloc_pmd(struct mm_struct *mm, unsigned long address)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\n\tpgd = pgd_offset(mm, address);\n\tp4d = p4d_alloc(mm, pgd, address);\n\tif (!p4d)\n\t\treturn NULL;\n\tpud = pud_alloc(mm, p4d, address);\n\tif (!pud)\n\t\treturn NULL;\n\t/*\n\t * Note that we didn't run this because the pmd was\n\t * missing, the *pmd may be already established and in\n\t * turn it may also be a trans_huge_pmd.\n\t */\n\treturn pmd_alloc(mm, pud, address);\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pmd_alloc",
          "args": [
            "mm",
            "pud",
            "address"
          ],
          "line": 145
        },
        "resolved": true,
        "details": {
          "function_name": "__pmd_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory.c",
          "lines": "4004-4029",
          "snippet": "int __pmd_alloc(struct mm_struct *mm, pud_t *pud, unsigned long address)\n{\n\tspinlock_t *ptl;\n\tpmd_t *new = pmd_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tsmp_wmb(); /* See comment in __pte_alloc */\n\n\tptl = pud_lock(mm, pud);\n#ifndef __ARCH_HAS_4LEVEL_HACK\n\tif (!pud_present(*pud)) {\n\t\tmm_inc_nr_pmds(mm);\n\t\tpud_populate(mm, pud, new);\n\t} else\t/* Another has populated it */\n\t\tpmd_free(mm, new);\n#else\n\tif (!pgd_present(*pud)) {\n\t\tmm_inc_nr_pmds(mm);\n\t\tpgd_populate(mm, pud, new);\n\t} else /* Another has populated it */\n\t\tpmd_free(mm, new);\n#endif /* __ARCH_HAS_4LEVEL_HACK */\n\tspin_unlock(ptl);\n\treturn 0;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/mmu_context.h>",
            "#include <asm/io.h>",
            "#include <linux/oom.h>",
            "#include <linux/dax.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-debug.h>",
            "#include <linux/string.h>",
            "#include <linux/migrate.h>",
            "#include <linux/gfp.h>",
            "#include <linux/elf.h>",
            "#include <linux/swapops.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pfn_t.h>",
            "#include <linux/init.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/export.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/memremap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/mmu_context.h>\n#include <asm/io.h>\n#include <linux/oom.h>\n#include <linux/dax.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/debugfs.h>\n#include <linux/dma-debug.h>\n#include <linux/string.h>\n#include <linux/migrate.h>\n#include <linux/gfp.h>\n#include <linux/elf.h>\n#include <linux/swapops.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/writeback.h>\n#include <linux/pfn_t.h>\n#include <linux/init.h>\n#include <linux/delayacct.h>\n#include <linux/export.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/memremap.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/hugetlb.h>\n#include <linux/sched/task.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/kernel_stat.h>\n\nint __pmd_alloc(struct mm_struct *mm, pud_t *pud, unsigned long address)\n{\n\tspinlock_t *ptl;\n\tpmd_t *new = pmd_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tsmp_wmb(); /* See comment in __pte_alloc */\n\n\tptl = pud_lock(mm, pud);\n#ifndef __ARCH_HAS_4LEVEL_HACK\n\tif (!pud_present(*pud)) {\n\t\tmm_inc_nr_pmds(mm);\n\t\tpud_populate(mm, pud, new);\n\t} else\t/* Another has populated it */\n\t\tpmd_free(mm, new);\n#else\n\tif (!pgd_present(*pud)) {\n\t\tmm_inc_nr_pmds(mm);\n\t\tpgd_populate(mm, pud, new);\n\t} else /* Another has populated it */\n\t\tpmd_free(mm, new);\n#endif /* __ARCH_HAS_4LEVEL_HACK */\n\tspin_unlock(ptl);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pud_alloc",
          "args": [
            "mm",
            "p4d",
            "address"
          ],
          "line": 137
        },
        "resolved": true,
        "details": {
          "function_name": "__pud_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory.c",
          "lines": "3972-3996",
          "snippet": "int __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)\n{\n\tpud_t *new = pud_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tsmp_wmb(); /* See comment in __pte_alloc */\n\n\tspin_lock(&mm->page_table_lock);\n#ifndef __ARCH_HAS_5LEVEL_HACK\n\tif (!p4d_present(*p4d)) {\n\t\tmm_inc_nr_puds(mm);\n\t\tp4d_populate(mm, p4d, new);\n\t} else\t/* Another has populated it */\n\t\tpud_free(mm, new);\n#else\n\tif (!pgd_present(*p4d)) {\n\t\tmm_inc_nr_puds(mm);\n\t\tpgd_populate(mm, p4d, new);\n\t} else\t/* Another has populated it */\n\t\tpud_free(mm, new);\n#endif /* __ARCH_HAS_5LEVEL_HACK */\n\tspin_unlock(&mm->page_table_lock);\n\treturn 0;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/mmu_context.h>",
            "#include <asm/io.h>",
            "#include <linux/oom.h>",
            "#include <linux/dax.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-debug.h>",
            "#include <linux/string.h>",
            "#include <linux/migrate.h>",
            "#include <linux/gfp.h>",
            "#include <linux/elf.h>",
            "#include <linux/swapops.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pfn_t.h>",
            "#include <linux/init.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/export.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/memremap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/mmu_context.h>\n#include <asm/io.h>\n#include <linux/oom.h>\n#include <linux/dax.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/debugfs.h>\n#include <linux/dma-debug.h>\n#include <linux/string.h>\n#include <linux/migrate.h>\n#include <linux/gfp.h>\n#include <linux/elf.h>\n#include <linux/swapops.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/writeback.h>\n#include <linux/pfn_t.h>\n#include <linux/init.h>\n#include <linux/delayacct.h>\n#include <linux/export.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/memremap.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/hugetlb.h>\n#include <linux/sched/task.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/kernel_stat.h>\n\nint __pud_alloc(struct mm_struct *mm, p4d_t *p4d, unsigned long address)\n{\n\tpud_t *new = pud_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tsmp_wmb(); /* See comment in __pte_alloc */\n\n\tspin_lock(&mm->page_table_lock);\n#ifndef __ARCH_HAS_5LEVEL_HACK\n\tif (!p4d_present(*p4d)) {\n\t\tmm_inc_nr_puds(mm);\n\t\tp4d_populate(mm, p4d, new);\n\t} else\t/* Another has populated it */\n\t\tpud_free(mm, new);\n#else\n\tif (!pgd_present(*p4d)) {\n\t\tmm_inc_nr_puds(mm);\n\t\tpgd_populate(mm, p4d, new);\n\t} else\t/* Another has populated it */\n\t\tpud_free(mm, new);\n#endif /* __ARCH_HAS_5LEVEL_HACK */\n\tspin_unlock(&mm->page_table_lock);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "p4d_alloc",
          "args": [
            "mm",
            "pgd",
            "address"
          ],
          "line": 134
        },
        "resolved": true,
        "details": {
          "function_name": "__p4d_alloc",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory.c",
          "lines": "3949-3964",
          "snippet": "int __p4d_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address)\n{\n\tp4d_t *new = p4d_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tsmp_wmb(); /* See comment in __pte_alloc */\n\n\tspin_lock(&mm->page_table_lock);\n\tif (pgd_present(*pgd))\t\t/* Another has populated it */\n\t\tp4d_free(mm, new);\n\telse\n\t\tpgd_populate(mm, pgd, new);\n\tspin_unlock(&mm->page_table_lock);\n\treturn 0;\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/pgtable.h>",
            "#include <asm/tlbflush.h>",
            "#include <asm/tlb.h>",
            "#include <linux/uaccess.h>",
            "#include <asm/pgalloc.h>",
            "#include <asm/mmu_context.h>",
            "#include <asm/io.h>",
            "#include <linux/oom.h>",
            "#include <linux/dax.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/debugfs.h>",
            "#include <linux/dma-debug.h>",
            "#include <linux/string.h>",
            "#include <linux/migrate.h>",
            "#include <linux/gfp.h>",
            "#include <linux/elf.h>",
            "#include <linux/swapops.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pfn_t.h>",
            "#include <linux/init.h>",
            "#include <linux/delayacct.h>",
            "#include <linux/export.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/memremap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/highmem.h>",
            "#include <linux/swap.h>",
            "#include <linux/mman.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/numa_balancing.h>",
            "#include <linux/sched/coredump.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/kernel_stat.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/pgtable.h>\n#include <asm/tlbflush.h>\n#include <asm/tlb.h>\n#include <linux/uaccess.h>\n#include <asm/pgalloc.h>\n#include <asm/mmu_context.h>\n#include <asm/io.h>\n#include <linux/oom.h>\n#include <linux/dax.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/debugfs.h>\n#include <linux/dma-debug.h>\n#include <linux/string.h>\n#include <linux/migrate.h>\n#include <linux/gfp.h>\n#include <linux/elf.h>\n#include <linux/swapops.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/writeback.h>\n#include <linux/pfn_t.h>\n#include <linux/init.h>\n#include <linux/delayacct.h>\n#include <linux/export.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/memremap.h>\n#include <linux/pagemap.h>\n#include <linux/highmem.h>\n#include <linux/swap.h>\n#include <linux/mman.h>\n#include <linux/hugetlb.h>\n#include <linux/sched/task.h>\n#include <linux/sched/numa_balancing.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/kernel_stat.h>\n\nint __p4d_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long address)\n{\n\tp4d_t *new = p4d_alloc_one(mm, address);\n\tif (!new)\n\t\treturn -ENOMEM;\n\n\tsmp_wmb(); /* See comment in __pte_alloc */\n\n\tspin_lock(&mm->page_table_lock);\n\tif (pgd_present(*pgd))\t\t/* Another has populated it */\n\t\tp4d_free(mm, new);\n\telse\n\t\tpgd_populate(mm, pgd, new);\n\tspin_unlock(&mm->page_table_lock);\n\treturn 0;\n}"
        }
      },
      {
        "call_info": {
          "callee": "pgd_offset",
          "args": [
            "mm",
            "address"
          ],
          "line": 133
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic pmd_t *mm_alloc_pmd(struct mm_struct *mm, unsigned long address)\n{\n\tpgd_t *pgd;\n\tp4d_t *p4d;\n\tpud_t *pud;\n\n\tpgd = pgd_offset(mm, address);\n\tp4d = p4d_alloc(mm, pgd, address);\n\tif (!p4d)\n\t\treturn NULL;\n\tpud = pud_alloc(mm, p4d, address);\n\tif (!pud)\n\t\treturn NULL;\n\t/*\n\t * Note that we didn't run this because the pmd was\n\t * missing, the *pmd may be already established and in\n\t * turn it may also be a trans_huge_pmd.\n\t */\n\treturn pmd_alloc(mm, pud, address);\n}"
  },
  {
    "function_name": "mfill_zeropage_pte",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "103-125",
    "snippet": "static int mfill_zeropage_pte(struct mm_struct *dst_mm,\n\t\t\t      pmd_t *dst_pmd,\n\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t      unsigned long dst_addr)\n{\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\n\t_dst_pte = pte_mkspecial(pfn_pte(my_zero_pfn(dst_addr),\n\t\t\t\t\t dst_vma->vm_page_prot));\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_unlock;\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\tret = 0;\nout_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\treturn ret;\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "pte_unmap_unlock",
          "args": [
            "dst_pte",
            "ptl"
          ],
          "line": 123
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "update_mmu_cache",
          "args": [
            "dst_vma",
            "dst_addr",
            "dst_pte"
          ],
          "line": 120
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_pte_at",
          "args": [
            "dst_mm",
            "dst_addr",
            "dst_pte",
            "_dst_pte"
          ],
          "line": 118
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_none",
          "args": [
            "*dst_pte"
          ],
          "line": 116
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_offset_map_lock",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_addr",
            "&ptl"
          ],
          "line": 115
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_mkspecial",
          "args": [
            "pfn_pte(my_zero_pfn(dst_addr),\n\t\t\t\t\t dst_vma->vm_page_prot)"
          ],
          "line": 112
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pfn_pte",
          "args": [
            "my_zero_pfn(dst_addr)",
            "dst_vma->vm_page_prot"
          ],
          "line": 112
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "my_zero_pfn",
          "args": [
            "dst_addr"
          ],
          "line": 112
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic int mfill_zeropage_pte(struct mm_struct *dst_mm,\n\t\t\t      pmd_t *dst_pmd,\n\t\t\t      struct vm_area_struct *dst_vma,\n\t\t\t      unsigned long dst_addr)\n{\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tint ret;\n\n\t_dst_pte = pte_mkspecial(pfn_pte(my_zero_pfn(dst_addr),\n\t\t\t\t\t dst_vma->vm_page_prot));\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_unlock;\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\tret = 0;\nout_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\treturn ret;\n}"
  },
  {
    "function_name": "mcopy_atomic_pte",
    "container": null,
    "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/userfaultfd.c",
    "lines": "23-101",
    "snippet": "static int mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pmd_t *dst_pmd,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct mem_cgroup *memcg;\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tvoid *page_kaddr;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_page_vma(GFP_HIGHUSER_MOVABLE, dst_vma, dst_addr);\n\t\tif (!page)\n\t\t\tgoto out;\n\n\t\tpage_kaddr = kmap_atomic(page);\n\t\tret = copy_from_user(page_kaddr,\n\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t     PAGE_SIZE);\n\t\tkunmap_atomic(page_kaddr);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -ENOENT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceeding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\n\tret = -ENOMEM;\n\tif (mem_cgroup_try_charge(page, dst_mm, GFP_KERNEL, &memcg, false))\n\t\tgoto out_release;\n\n\t_dst_pte = mk_pte(page, dst_vma->vm_page_prot);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = pte_mkwrite(pte_mkdirty(_dst_pte));\n\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_release_uncharge_unlock;\n\n\tinc_mm_counter(dst_mm, MM_ANONPAGES);\n\tpage_add_new_anon_rmap(page, dst_vma, dst_addr, false);\n\tmem_cgroup_commit_charge(page, memcg, false, false);\n\tlru_cache_add_active_or_unevictable(page, dst_vma);\n\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tpte_unmap_unlock(dst_pte, ptl);\n\tret = 0;\nout:\n\treturn ret;\nout_release_uncharge_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\tmem_cgroup_cancel_charge(page, memcg, false);\nout_release:\n\tput_page(page);\n\tgoto out;\n}",
    "includes": [
      "#include \"internal.h\"",
      "#include <asm/tlbflush.h>",
      "#include <linux/shmem_fs.h>",
      "#include <linux/hugetlb.h>",
      "#include <linux/mmu_notifier.h>",
      "#include <linux/userfaultfd_k.h>",
      "#include <linux/swapops.h>",
      "#include <linux/swap.h>",
      "#include <linux/rmap.h>",
      "#include <linux/pagemap.h>",
      "#include <linux/sched/signal.h>",
      "#include <linux/mm.h>"
    ],
    "macros_used": [],
    "globals_used": [],
    "called_functions": [
      {
        "call_info": {
          "callee": "put_page",
          "args": [
            "page"
          ],
          "line": 99
        },
        "resolved": true,
        "details": {
          "function_name": "put_page_bootmem",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memory_hotplug.c",
          "lines": "143-158",
          "snippet": "void put_page_bootmem(struct page *page)\n{\n\tunsigned long type;\n\n\ttype = (unsigned long) page->freelist;\n\tBUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||\n\t       type > MEMORY_HOTPLUG_MAX_BOOTMEM_TYPE);\n\n\tif (page_ref_dec_return(page) == 1) {\n\t\tpage->freelist = NULL;\n\t\tClearPagePrivate(page);\n\t\tset_page_private(page, 0);\n\t\tINIT_LIST_HEAD(&page->lru);\n\t\tfree_reserved_page(page);\n\t}\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <asm/tlbflush.h>",
            "#include <linux/compaction.h>",
            "#include <linux/memblock.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/stop_machine.h>",
            "#include <linux/firmware-map.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/suspend.h>",
            "#include <linux/pfn.h>",
            "#include <linux/page-isolation.h>",
            "#include <linux/migrate.h>",
            "#include <linux/delay.h>",
            "#include <linux/ioport.h>",
            "#include <linux/vmalloc.h>",
            "#include <linux/highmem.h>",
            "#include <linux/memory_hotplug.h>",
            "#include <linux/memremap.h>",
            "#include <linux/memory.h>",
            "#include <linux/cpu.h>",
            "#include <linux/sysctl.h>",
            "#include <linux/slab.h>",
            "#include <linux/writeback.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/export.h>",
            "#include <linux/compiler.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/interrupt.h>",
            "#include <linux/swap.h>",
            "#include <linux/sched/signal.h>",
            "#include <linux/mm.h>",
            "#include <linux/stddef.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void generic_online_page(struct page *page);"
          ],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/compaction.h>\n#include <linux/memblock.h>\n#include <linux/hugetlb.h>\n#include <linux/stop_machine.h>\n#include <linux/firmware-map.h>\n#include <linux/mm_inline.h>\n#include <linux/suspend.h>\n#include <linux/pfn.h>\n#include <linux/page-isolation.h>\n#include <linux/migrate.h>\n#include <linux/delay.h>\n#include <linux/ioport.h>\n#include <linux/vmalloc.h>\n#include <linux/highmem.h>\n#include <linux/memory_hotplug.h>\n#include <linux/memremap.h>\n#include <linux/memory.h>\n#include <linux/cpu.h>\n#include <linux/sysctl.h>\n#include <linux/slab.h>\n#include <linux/writeback.h>\n#include <linux/pagevec.h>\n#include <linux/export.h>\n#include <linux/compiler.h>\n#include <linux/pagemap.h>\n#include <linux/interrupt.h>\n#include <linux/swap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n#include <linux/stddef.h>\n\nstatic void generic_online_page(struct page *page);\n\nvoid put_page_bootmem(struct page *page)\n{\n\tunsigned long type;\n\n\ttype = (unsigned long) page->freelist;\n\tBUG_ON(type < MEMORY_HOTPLUG_MIN_BOOTMEM_TYPE ||\n\t       type > MEMORY_HOTPLUG_MAX_BOOTMEM_TYPE);\n\n\tif (page_ref_dec_return(page) == 1) {\n\t\tpage->freelist = NULL;\n\t\tClearPagePrivate(page);\n\t\tset_page_private(page, 0);\n\t\tINIT_LIST_HEAD(&page->lru);\n\t\tfree_reserved_page(page);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "mem_cgroup_cancel_charge",
          "args": [
            "page",
            "memcg",
            "false"
          ],
          "line": 97
        },
        "resolved": true,
        "details": {
          "function_name": "mem_cgroup_cancel_charge",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memcontrol.c",
          "lines": "5972-5988",
          "snippet": "void mem_cgroup_cancel_charge(struct page *page, struct mem_cgroup *memcg,\n\t\tbool compound)\n{\n\tunsigned int nr_pages = compound ? hpage_nr_pages(page) : 1;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\t/*\n\t * Swap faults will attempt to charge the same page multiple\n\t * times.  But reuse_swap_page() might have removed the page\n\t * from swapcache already, so we can't check PageSwapCache().\n\t */\n\tif (!memcg)\n\t\treturn;\n\n\tcancel_charge(memcg, nr_pages);\n}",
          "includes": [
            "#include <trace/events/vmscan.h>",
            "#include <linux/uaccess.h>",
            "#include \"slab.h\"",
            "#include <net/ip.h>",
            "#include <net/sock.h>",
            "#include \"internal.h\"",
            "#include <linux/tracehook.h>",
            "#include <linux/file.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/swap_cgroup.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/vmpressure.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/fs.h>",
            "#include <linux/sort.h>",
            "#include <linux/poll.h>",
            "#include <linux/eventfd.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/slab.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/limits.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bit_spinlock.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/smp.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/page_counter.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void mem_cgroup_threshold(struct mem_cgroup *memcg);",
            "static void mem_cgroup_oom_notify(struct mem_cgroup *memcg);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/vmscan.h>\n#include <linux/uaccess.h>\n#include \"slab.h\"\n#include <net/ip.h>\n#include <net/sock.h>\n#include \"internal.h\"\n#include <linux/tracehook.h>\n#include <linux/file.h>\n#include <linux/lockdep.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/swap_cgroup.h>\n#include <linux/mm_inline.h>\n#include <linux/vmpressure.h>\n#include <linux/seq_file.h>\n#include <linux/fs.h>\n#include <linux/sort.h>\n#include <linux/poll.h>\n#include <linux/eventfd.h>\n#include <linux/spinlock.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/slab.h>\n#include <linux/rbtree.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/limits.h>\n#include <linux/rcupdate.h>\n#include <linux/bit_spinlock.h>\n#include <linux/backing-dev.h>\n#include <linux/page-flags.h>\n#include <linux/smp.h>\n#include <linux/pagemap.h>\n#include <linux/hugetlb.h>\n#include <linux/shmem_fs.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/cgroup.h>\n#include <linux/memcontrol.h>\n#include <linux/page_counter.h>\n\nstatic void mem_cgroup_threshold(struct mem_cgroup *memcg);\nstatic void mem_cgroup_oom_notify(struct mem_cgroup *memcg);\nstatic __always_inline struct;\n\nvoid mem_cgroup_cancel_charge(struct page *page, struct mem_cgroup *memcg,\n\t\tbool compound)\n{\n\tunsigned int nr_pages = compound ? hpage_nr_pages(page) : 1;\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\t/*\n\t * Swap faults will attempt to charge the same page multiple\n\t * times.  But reuse_swap_page() might have removed the page\n\t * from swapcache already, so we can't check PageSwapCache().\n\t */\n\tif (!memcg)\n\t\treturn;\n\n\tcancel_charge(memcg, nr_pages);\n}"
        }
      },
      {
        "call_info": {
          "callee": "pte_unmap_unlock",
          "args": [
            "dst_pte",
            "ptl"
          ],
          "line": 96
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_unmap_unlock",
          "args": [
            "dst_pte",
            "ptl"
          ],
          "line": 91
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "update_mmu_cache",
          "args": [
            "dst_vma",
            "dst_addr",
            "dst_pte"
          ],
          "line": 89
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "set_pte_at",
          "args": [
            "dst_mm",
            "dst_addr",
            "dst_pte",
            "_dst_pte"
          ],
          "line": 86
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "lru_cache_add_active_or_unevictable",
          "args": [
            "page",
            "dst_vma"
          ],
          "line": 84
        },
        "resolved": true,
        "details": {
          "function_name": "lru_cache_add_active_or_unevictable",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/swap.c",
          "lines": "458-476",
          "snippet": "void lru_cache_add_active_or_unevictable(struct page *page,\n\t\t\t\t\t struct vm_area_struct *vma)\n{\n\tVM_BUG_ON_PAGE(PageLRU(page), page);\n\n\tif (likely((vma->vm_flags & (VM_LOCKED | VM_SPECIAL)) != VM_LOCKED))\n\t\tSetPageActive(page);\n\telse if (!TestSetPageMlocked(page)) {\n\t\t/*\n\t\t * We use the irq-unsafe __mod_zone_page_stat because this\n\t\t * counter is not modified from interrupt context, and the pte\n\t\t * lock is held(spinlock), which implies preemption disabled.\n\t\t */\n\t\t__mod_zone_page_state(page_zone(page), NR_MLOCK,\n\t\t\t\t    hpage_nr_pages(page));\n\t\tcount_vm_event(UNEVICTABLE_PGMLOCKED);\n\t}\n\tlru_cache_add(page);\n}",
          "includes": [
            "#include <trace/events/pagemap.h>",
            "#include \"internal.h\"",
            "#include <linux/page_idle.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/uio.h>",
            "#include <linux/gfp.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/notifier.h>",
            "#include <linux/cpu.h>",
            "#include <linux/percpu.h>",
            "#include <linux/memremap.h>",
            "#include <linux/percpu_counter.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/export.h>",
            "#include <linux/init.h>",
            "#include <linux/pagevec.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/mman.h>",
            "#include <linux/swap.h>",
            "#include <linux/kernel_stat.h>",
            "#include <linux/sched.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/pagemap.h>\n#include \"internal.h\"\n#include <linux/page_idle.h>\n#include <linux/hugetlb.h>\n#include <linux/uio.h>\n#include <linux/gfp.h>\n#include <linux/memcontrol.h>\n#include <linux/backing-dev.h>\n#include <linux/notifier.h>\n#include <linux/cpu.h>\n#include <linux/percpu.h>\n#include <linux/memremap.h>\n#include <linux/percpu_counter.h>\n#include <linux/mm_inline.h>\n#include <linux/export.h>\n#include <linux/init.h>\n#include <linux/pagevec.h>\n#include <linux/pagemap.h>\n#include <linux/mman.h>\n#include <linux/swap.h>\n#include <linux/kernel_stat.h>\n#include <linux/sched.h>\n#include <linux/mm.h>\n\nvoid lru_cache_add_active_or_unevictable(struct page *page,\n\t\t\t\t\t struct vm_area_struct *vma)\n{\n\tVM_BUG_ON_PAGE(PageLRU(page), page);\n\n\tif (likely((vma->vm_flags & (VM_LOCKED | VM_SPECIAL)) != VM_LOCKED))\n\t\tSetPageActive(page);\n\telse if (!TestSetPageMlocked(page)) {\n\t\t/*\n\t\t * We use the irq-unsafe __mod_zone_page_stat because this\n\t\t * counter is not modified from interrupt context, and the pte\n\t\t * lock is held(spinlock), which implies preemption disabled.\n\t\t */\n\t\t__mod_zone_page_state(page_zone(page), NR_MLOCK,\n\t\t\t\t    hpage_nr_pages(page));\n\t\tcount_vm_event(UNEVICTABLE_PGMLOCKED);\n\t}\n\tlru_cache_add(page);\n}"
        }
      },
      {
        "call_info": {
          "callee": "mem_cgroup_commit_charge",
          "args": [
            "page",
            "memcg",
            "false",
            "false"
          ],
          "line": 83
        },
        "resolved": true,
        "details": {
          "function_name": "mem_cgroup_commit_charge",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memcontrol.c",
          "lines": "5928-5962",
          "snippet": "void mem_cgroup_commit_charge(struct page *page, struct mem_cgroup *memcg,\n\t\t\t      bool lrucare, bool compound)\n{\n\tunsigned int nr_pages = compound ? hpage_nr_pages(page) : 1;\n\n\tVM_BUG_ON_PAGE(!page->mapping, page);\n\tVM_BUG_ON_PAGE(PageLRU(page) && !lrucare, page);\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\t/*\n\t * Swap faults will attempt to charge the same page multiple\n\t * times.  But reuse_swap_page() might have removed the page\n\t * from swapcache already, so we can't check PageSwapCache().\n\t */\n\tif (!memcg)\n\t\treturn;\n\n\tcommit_charge(page, memcg, lrucare);\n\n\tlocal_irq_disable();\n\tmem_cgroup_charge_statistics(memcg, page, compound, nr_pages);\n\tmemcg_check_events(memcg, page);\n\tlocal_irq_enable();\n\n\tif (do_memsw_account() && PageSwapCache(page)) {\n\t\tswp_entry_t entry = { .val = page_private(page) };\n\t\t/*\n\t\t * The swap entry might not get freed for a long time,\n\t\t * let's not wait for it.  The page already received a\n\t\t * memory+swap charge, drop the swap entry duplicate.\n\t\t */\n\t\tmem_cgroup_uncharge_swap(entry, nr_pages);\n\t}\n}",
          "includes": [
            "#include <trace/events/vmscan.h>",
            "#include <linux/uaccess.h>",
            "#include \"slab.h\"",
            "#include <net/ip.h>",
            "#include <net/sock.h>",
            "#include \"internal.h\"",
            "#include <linux/tracehook.h>",
            "#include <linux/file.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/swap_cgroup.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/vmpressure.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/fs.h>",
            "#include <linux/sort.h>",
            "#include <linux/poll.h>",
            "#include <linux/eventfd.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/slab.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/limits.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bit_spinlock.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/smp.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/page_counter.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void mem_cgroup_threshold(struct mem_cgroup *memcg);",
            "static void mem_cgroup_oom_notify(struct mem_cgroup *memcg);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/vmscan.h>\n#include <linux/uaccess.h>\n#include \"slab.h\"\n#include <net/ip.h>\n#include <net/sock.h>\n#include \"internal.h\"\n#include <linux/tracehook.h>\n#include <linux/file.h>\n#include <linux/lockdep.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/swap_cgroup.h>\n#include <linux/mm_inline.h>\n#include <linux/vmpressure.h>\n#include <linux/seq_file.h>\n#include <linux/fs.h>\n#include <linux/sort.h>\n#include <linux/poll.h>\n#include <linux/eventfd.h>\n#include <linux/spinlock.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/slab.h>\n#include <linux/rbtree.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/limits.h>\n#include <linux/rcupdate.h>\n#include <linux/bit_spinlock.h>\n#include <linux/backing-dev.h>\n#include <linux/page-flags.h>\n#include <linux/smp.h>\n#include <linux/pagemap.h>\n#include <linux/hugetlb.h>\n#include <linux/shmem_fs.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/cgroup.h>\n#include <linux/memcontrol.h>\n#include <linux/page_counter.h>\n\nstatic void mem_cgroup_threshold(struct mem_cgroup *memcg);\nstatic void mem_cgroup_oom_notify(struct mem_cgroup *memcg);\nstatic __always_inline struct;\n\nvoid mem_cgroup_commit_charge(struct page *page, struct mem_cgroup *memcg,\n\t\t\t      bool lrucare, bool compound)\n{\n\tunsigned int nr_pages = compound ? hpage_nr_pages(page) : 1;\n\n\tVM_BUG_ON_PAGE(!page->mapping, page);\n\tVM_BUG_ON_PAGE(PageLRU(page) && !lrucare, page);\n\n\tif (mem_cgroup_disabled())\n\t\treturn;\n\t/*\n\t * Swap faults will attempt to charge the same page multiple\n\t * times.  But reuse_swap_page() might have removed the page\n\t * from swapcache already, so we can't check PageSwapCache().\n\t */\n\tif (!memcg)\n\t\treturn;\n\n\tcommit_charge(page, memcg, lrucare);\n\n\tlocal_irq_disable();\n\tmem_cgroup_charge_statistics(memcg, page, compound, nr_pages);\n\tmemcg_check_events(memcg, page);\n\tlocal_irq_enable();\n\n\tif (do_memsw_account() && PageSwapCache(page)) {\n\t\tswp_entry_t entry = { .val = page_private(page) };\n\t\t/*\n\t\t * The swap entry might not get freed for a long time,\n\t\t * let's not wait for it.  The page already received a\n\t\t * memory+swap charge, drop the swap entry duplicate.\n\t\t */\n\t\tmem_cgroup_uncharge_swap(entry, nr_pages);\n\t}\n}"
        }
      },
      {
        "call_info": {
          "callee": "page_add_new_anon_rmap",
          "args": [
            "page",
            "dst_vma",
            "dst_addr",
            "false"
          ],
          "line": 82
        },
        "resolved": true,
        "details": {
          "function_name": "page_add_new_anon_rmap",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/rmap.c",
          "lines": "1150-1170",
          "snippet": "void page_add_new_anon_rmap(struct page *page,\n\tstruct vm_area_struct *vma, unsigned long address, bool compound)\n{\n\tint nr = compound ? hpage_nr_pages(page) : 1;\n\n\tVM_BUG_ON_VMA(address < vma->vm_start || address >= vma->vm_end, vma);\n\t__SetPageSwapBacked(page);\n\tif (compound) {\n\t\tVM_BUG_ON_PAGE(!PageTransHuge(page), page);\n\t\t/* increment count (starts at -1) */\n\t\tatomic_set(compound_mapcount_ptr(page), 0);\n\t\t__inc_node_page_state(page, NR_ANON_THPS);\n\t} else {\n\t\t/* Anon THP always mapped first with PMD */\n\t\tVM_BUG_ON_PAGE(PageTransCompound(page), page);\n\t\t/* increment count (starts at -1) */\n\t\tatomic_set(&page->_mapcount, 0);\n\t}\n\t__mod_node_page_state(page_pgdat(page), NR_ANON_MAPPED, nr);\n\t__page_set_anon_rmap(page, vma, address, 1);\n}",
          "includes": [
            "#include \"internal.h\"",
            "#include <trace/events/tlb.h>",
            "#include <asm/tlbflush.h>",
            "#include <linux/userfaultfd_k.h>",
            "#include <linux/memremap.h>",
            "#include <linux/page_idle.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/migrate.h>",
            "#include <linux/mmu_notifier.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/export.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/rmap.h>",
            "#include <linux/ksm.h>",
            "#include <linux/init.h>",
            "#include <linux/slab.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/sched/task.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>"
          ],
          "macros_used": [],
          "globals_used": [],
          "called_functions": [],
          "contextual_snippet": "#include \"internal.h\"\n#include <trace/events/tlb.h>\n#include <asm/tlbflush.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/memremap.h>\n#include <linux/page_idle.h>\n#include <linux/backing-dev.h>\n#include <linux/hugetlb.h>\n#include <linux/migrate.h>\n#include <linux/mmu_notifier.h>\n#include <linux/memcontrol.h>\n#include <linux/export.h>\n#include <linux/rcupdate.h>\n#include <linux/rmap.h>\n#include <linux/ksm.h>\n#include <linux/init.h>\n#include <linux/slab.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/task.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n\nvoid page_add_new_anon_rmap(struct page *page,\n\tstruct vm_area_struct *vma, unsigned long address, bool compound)\n{\n\tint nr = compound ? hpage_nr_pages(page) : 1;\n\n\tVM_BUG_ON_VMA(address < vma->vm_start || address >= vma->vm_end, vma);\n\t__SetPageSwapBacked(page);\n\tif (compound) {\n\t\tVM_BUG_ON_PAGE(!PageTransHuge(page), page);\n\t\t/* increment count (starts at -1) */\n\t\tatomic_set(compound_mapcount_ptr(page), 0);\n\t\t__inc_node_page_state(page, NR_ANON_THPS);\n\t} else {\n\t\t/* Anon THP always mapped first with PMD */\n\t\tVM_BUG_ON_PAGE(PageTransCompound(page), page);\n\t\t/* increment count (starts at -1) */\n\t\tatomic_set(&page->_mapcount, 0);\n\t}\n\t__mod_node_page_state(page_pgdat(page), NR_ANON_MAPPED, nr);\n\t__page_set_anon_rmap(page, vma, address, 1);\n}"
        }
      },
      {
        "call_info": {
          "callee": "inc_mm_counter",
          "args": [
            "dst_mm",
            "MM_ANONPAGES"
          ],
          "line": 81
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_none",
          "args": [
            "*dst_pte"
          ],
          "line": 78
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_offset_map_lock",
          "args": [
            "dst_mm",
            "dst_pmd",
            "dst_addr",
            "&ptl"
          ],
          "line": 77
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_mkwrite",
          "args": [
            "pte_mkdirty(_dst_pte)"
          ],
          "line": 74
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "pte_mkdirty",
          "args": [
            "_dst_pte"
          ],
          "line": 74
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mk_pte",
          "args": [
            "page",
            "dst_vma->vm_page_prot"
          ],
          "line": 72
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "mem_cgroup_try_charge",
          "args": [
            "page",
            "dst_mm",
            "GFP_KERNEL",
            "&memcg",
            "false"
          ],
          "line": 69
        },
        "resolved": true,
        "details": {
          "function_name": "mem_cgroup_try_charge_delay",
          "container": null,
          "file": "/home/michele/Desktop/ricerca/output_repos_c/CVE-2018-18397/repo/mm/memcontrol.c",
          "lines": "5898-5909",
          "snippet": "int mem_cgroup_try_charge_delay(struct page *page, struct mm_struct *mm,\n\t\t\t  gfp_t gfp_mask, struct mem_cgroup **memcgp,\n\t\t\t  bool compound)\n{\n\tstruct mem_cgroup *memcg;\n\tint ret;\n\n\tret = mem_cgroup_try_charge(page, mm, gfp_mask, memcgp, compound);\n\tmemcg = *memcgp;\n\tmem_cgroup_throttle_swaprate(memcg, page_to_nid(page), gfp_mask);\n\treturn ret;\n}",
          "includes": [
            "#include <trace/events/vmscan.h>",
            "#include <linux/uaccess.h>",
            "#include \"slab.h\"",
            "#include <net/ip.h>",
            "#include <net/sock.h>",
            "#include \"internal.h\"",
            "#include <linux/tracehook.h>",
            "#include <linux/file.h>",
            "#include <linux/lockdep.h>",
            "#include <linux/oom.h>",
            "#include <linux/cpu.h>",
            "#include <linux/swap_cgroup.h>",
            "#include <linux/mm_inline.h>",
            "#include <linux/vmpressure.h>",
            "#include <linux/seq_file.h>",
            "#include <linux/fs.h>",
            "#include <linux/sort.h>",
            "#include <linux/poll.h>",
            "#include <linux/eventfd.h>",
            "#include <linux/spinlock.h>",
            "#include <linux/swapops.h>",
            "#include <linux/swap.h>",
            "#include <linux/slab.h>",
            "#include <linux/rbtree.h>",
            "#include <linux/mutex.h>",
            "#include <linux/export.h>",
            "#include <linux/limits.h>",
            "#include <linux/rcupdate.h>",
            "#include <linux/bit_spinlock.h>",
            "#include <linux/backing-dev.h>",
            "#include <linux/page-flags.h>",
            "#include <linux/smp.h>",
            "#include <linux/pagemap.h>",
            "#include <linux/hugetlb.h>",
            "#include <linux/shmem_fs.h>",
            "#include <linux/sched/mm.h>",
            "#include <linux/mm.h>",
            "#include <linux/cgroup.h>",
            "#include <linux/memcontrol.h>",
            "#include <linux/page_counter.h>"
          ],
          "macros_used": [],
          "globals_used": [
            "static void mem_cgroup_threshold(struct mem_cgroup *memcg);",
            "static void mem_cgroup_oom_notify(struct mem_cgroup *memcg);",
            "static __always_inline struct"
          ],
          "called_functions": [],
          "contextual_snippet": "#include <trace/events/vmscan.h>\n#include <linux/uaccess.h>\n#include \"slab.h\"\n#include <net/ip.h>\n#include <net/sock.h>\n#include \"internal.h\"\n#include <linux/tracehook.h>\n#include <linux/file.h>\n#include <linux/lockdep.h>\n#include <linux/oom.h>\n#include <linux/cpu.h>\n#include <linux/swap_cgroup.h>\n#include <linux/mm_inline.h>\n#include <linux/vmpressure.h>\n#include <linux/seq_file.h>\n#include <linux/fs.h>\n#include <linux/sort.h>\n#include <linux/poll.h>\n#include <linux/eventfd.h>\n#include <linux/spinlock.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/slab.h>\n#include <linux/rbtree.h>\n#include <linux/mutex.h>\n#include <linux/export.h>\n#include <linux/limits.h>\n#include <linux/rcupdate.h>\n#include <linux/bit_spinlock.h>\n#include <linux/backing-dev.h>\n#include <linux/page-flags.h>\n#include <linux/smp.h>\n#include <linux/pagemap.h>\n#include <linux/hugetlb.h>\n#include <linux/shmem_fs.h>\n#include <linux/sched/mm.h>\n#include <linux/mm.h>\n#include <linux/cgroup.h>\n#include <linux/memcontrol.h>\n#include <linux/page_counter.h>\n\nstatic void mem_cgroup_threshold(struct mem_cgroup *memcg);\nstatic void mem_cgroup_oom_notify(struct mem_cgroup *memcg);\nstatic __always_inline struct;\n\nint mem_cgroup_try_charge_delay(struct page *page, struct mm_struct *mm,\n\t\t\t  gfp_t gfp_mask, struct mem_cgroup **memcgp,\n\t\t\t  bool compound)\n{\n\tstruct mem_cgroup *memcg;\n\tint ret;\n\n\tret = mem_cgroup_try_charge(page, mm, gfp_mask, memcgp, compound);\n\tmemcg = *memcgp;\n\tmem_cgroup_throttle_swaprate(memcg, page_to_nid(page), gfp_mask);\n\treturn ret;\n}"
        }
      },
      {
        "call_info": {
          "callee": "__SetPageUptodate",
          "args": [
            "page"
          ],
          "line": 66
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "unlikely",
          "args": [
            "ret"
          ],
          "line": 50
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kunmap_atomic",
          "args": [
            "page_kaddr"
          ],
          "line": 47
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "copy_from_user",
          "args": [
            "page_kaddr",
            "(const void __user *) src_addr",
            "PAGE_SIZE"
          ],
          "line": 44
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "kmap_atomic",
          "args": [
            "page"
          ],
          "line": 43
        },
        "resolved": false,
        "reason": "library_or_external"
      },
      {
        "call_info": {
          "callee": "alloc_page_vma",
          "args": [
            "GFP_HIGHUSER_MOVABLE",
            "dst_vma",
            "dst_addr"
          ],
          "line": 39
        },
        "resolved": false,
        "reason": "library_or_external"
      }
    ],
    "contextual_snippet": "#include \"internal.h\"\n#include <asm/tlbflush.h>\n#include <linux/shmem_fs.h>\n#include <linux/hugetlb.h>\n#include <linux/mmu_notifier.h>\n#include <linux/userfaultfd_k.h>\n#include <linux/swapops.h>\n#include <linux/swap.h>\n#include <linux/rmap.h>\n#include <linux/pagemap.h>\n#include <linux/sched/signal.h>\n#include <linux/mm.h>\n\nstatic int mcopy_atomic_pte(struct mm_struct *dst_mm,\n\t\t\t    pmd_t *dst_pmd,\n\t\t\t    struct vm_area_struct *dst_vma,\n\t\t\t    unsigned long dst_addr,\n\t\t\t    unsigned long src_addr,\n\t\t\t    struct page **pagep)\n{\n\tstruct mem_cgroup *memcg;\n\tpte_t _dst_pte, *dst_pte;\n\tspinlock_t *ptl;\n\tvoid *page_kaddr;\n\tint ret;\n\tstruct page *page;\n\n\tif (!*pagep) {\n\t\tret = -ENOMEM;\n\t\tpage = alloc_page_vma(GFP_HIGHUSER_MOVABLE, dst_vma, dst_addr);\n\t\tif (!page)\n\t\t\tgoto out;\n\n\t\tpage_kaddr = kmap_atomic(page);\n\t\tret = copy_from_user(page_kaddr,\n\t\t\t\t     (const void __user *) src_addr,\n\t\t\t\t     PAGE_SIZE);\n\t\tkunmap_atomic(page_kaddr);\n\n\t\t/* fallback to copy_from_user outside mmap_sem */\n\t\tif (unlikely(ret)) {\n\t\t\tret = -ENOENT;\n\t\t\t*pagep = page;\n\t\t\t/* don't free the page */\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\tpage = *pagep;\n\t\t*pagep = NULL;\n\t}\n\n\t/*\n\t * The memory barrier inside __SetPageUptodate makes sure that\n\t * preceeding stores to the page contents become visible before\n\t * the set_pte_at() write.\n\t */\n\t__SetPageUptodate(page);\n\n\tret = -ENOMEM;\n\tif (mem_cgroup_try_charge(page, dst_mm, GFP_KERNEL, &memcg, false))\n\t\tgoto out_release;\n\n\t_dst_pte = mk_pte(page, dst_vma->vm_page_prot);\n\tif (dst_vma->vm_flags & VM_WRITE)\n\t\t_dst_pte = pte_mkwrite(pte_mkdirty(_dst_pte));\n\n\tret = -EEXIST;\n\tdst_pte = pte_offset_map_lock(dst_mm, dst_pmd, dst_addr, &ptl);\n\tif (!pte_none(*dst_pte))\n\t\tgoto out_release_uncharge_unlock;\n\n\tinc_mm_counter(dst_mm, MM_ANONPAGES);\n\tpage_add_new_anon_rmap(page, dst_vma, dst_addr, false);\n\tmem_cgroup_commit_charge(page, memcg, false, false);\n\tlru_cache_add_active_or_unevictable(page, dst_vma);\n\n\tset_pte_at(dst_mm, dst_addr, dst_pte, _dst_pte);\n\n\t/* No need to invalidate - it was non-present before */\n\tupdate_mmu_cache(dst_vma, dst_addr, dst_pte);\n\n\tpte_unmap_unlock(dst_pte, ptl);\n\tret = 0;\nout:\n\treturn ret;\nout_release_uncharge_unlock:\n\tpte_unmap_unlock(dst_pte, ptl);\n\tmem_cgroup_cancel_charge(page, memcg, false);\nout_release:\n\tput_page(page);\n\tgoto out;\n}"
  }
]